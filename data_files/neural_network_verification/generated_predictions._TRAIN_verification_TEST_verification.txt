This paper presents McNetKAT, a new tool for reasoning about probabilistic network programs written in the guarded and historyfree fragment of Probabilistic NetKAT (ProbNetKAT). ProbNetKAT is an expressive programming language based on Kleene Algebra with Tests, capable of modeling a variety of probabilistic behaviors and properties including randomized routing, uncertainty about the inputs, expected load, and failures. Although the fragment is a restriction of the full language, it is still expressive enough to encode a wide range of practical network
Deep learning has been explored for a wide range of different financial services applications, including credit card default prediction, exchange rate prediction, and anti-money laundering. However, there is still a question as to whether the developed financial deep learning models are fair in their predictions. This is particularly true in light of strong governance and regulatory compliance requirements in the financial services industry, as well as the socioeconomic Preprint. Motivated by the importance of trust in deep learning in general, there has been a new focus in recent years on the design of interpretable metrics for the purpose of trust quantification of a model at different scale
We present a novel technique for modular verification of control planes, leveraging the modularity of the control plane. We leverage the modularity of the control plane to cut a monolithic network into multiple fragments to be verified independently. We do this by leveraging an existing general model for distributed routing, the Stable Routing Problem (SRP). In this paper, we develop an SRP extension called “open SRPs”, in which a network receives routes along a set of input nodes and sends out routes along a different set of input nodes.
Deep neural networks (DNNs) have been successfully applied to both text-dependent and text-independent speaker verification tasks. The earliest DNN-based ASV systems are the dvector and rvector, which use acoustic features and their context as the input to predict the frame-level speaker representation, requiring post-processing. More recently, DNN-based speaker verification systems utilize more efficient methods that directly extract utterance-level speaker representative vectors (also called speaker embeddings) from the hidden layer of a DNN. The stage-wise
Handwritten signature is a biometric authentication method widely used for personal documents and legal contract valida tions. However, the verification of handwritten signatures is a challenging task in image processing. In this work, we propose an approach to the pixel-level segmentation of handwritten signatures on images. Our approach has been trained with ID document images with the same characteristics and interference that can arise in a real-world scenario. The proposed system will be able to acquire signatures with greater fidelity in the strokes regardless of the type of the ink,
We analyze the security properties of the Lightning Network's protocol. The Lightning Network is a payment channel network for Bitcoin. The protocol enables two users to perform transactions between each other without writing to the blockchain. The protocol enables the two users to perform multi-hop transactions without writing to the blockchain. The security model for payment channels requires that honest parties retrieve at least their correct balance even if all other users behave adversarially. To avoid financial loss caused by design flaws in a payment channel protocol, it should be verified that the protocol fulfills the security properties. We formalize the protocol specification of the
Network policy enforcement has been and continues to be a challenging and error-prone task. Recent efforts on network testing and verification (e.g., [26,42,43,44]) offer a promising alternative to existing expensive and manual debugging efforts. However, there are fundamental gaps between the intent of network operators and the capabilities of existing network checking mechanisms. Specifically, stateful data planes and context-dependent policies introduce new challenges that fall outside the scope of existing network checking mechanisms. To address these challenges, we present a network testing framework called Armstrong.
Deep learning has been successfully applied to improve the diversity of the feature space. However, it is well known that no single prior can perfectly disentangle all the underlying variations in the data and lead to a universally good representation. In this work, we propose a novel approach to improve the performance of a state-of-the-art deep neural network based fingerprint recognition model called DeepPrint (DP). The DP model is able to learn a compact fingerprint representation using a combination of domain knowledge (minutiae) and data. The ensemble learning is achieved by augmenting the
Quantum Key Distribution (QKD) is a field of quantum cryptography that aims at securely distributing keys between two parties (say, Alice and Bob) using proper ties of photons (quanta of light). In this work, we aim to obtain a LFSR based Random Number Generator (LRNG) bit stream, which is implementable on low cost, low powered FPGA boards suitable for BB84 protocol. The LRNG bit stream is varied for different parameters, say input seed value and post-
The Beacon Chain is the backbone component of Ethereum 2.0. It is responsible for enforcing consensus among the nodes participating in the network, on the state of the system. The reference implementation of the Beacon Chain is written in Python and provides a detailed operational description of the state machine each Beacon Chain's network participant (node) must implement. As a result, inaccuracies, ambiguities, or bugs in the reference implementation will lead to erroneous and/or buggy clients. We have synthesised functional correctness guarantees
Deep neural networks (DNNs) have been used to solve many computationally difficult problems, including safety-critical tasks. However, DNNs are notorious for producing unexpected results on inputs that are considerably different from those in the training set. In order to overcome these weaknesses, the formal methods community has started devising techniques for DNN verification. In this work, we present a novel proof production mechanism for a broad family of search-based DNN verification algorithms. Whenever the search procedure returns UNSAT (indicating that no counterexample exists), our mechanism produces a proof certificate that can be easily checked
Quantum machine learning algorithms have been widely applied in various fields, including machine learning, but their applicability on real-world problems is less known. In this paper, we study the applicability of quantum and quantuminspired machine learning algorithms to stock return prediction. We conduct a backtesting experiment on a set of stocks in the Japanese stock market, and compare their performance over 10 years. We observe that the tensor network model outperforms the other models, while the quantum neural network model is inferior to the neural network model. We conduct a backtesting experiment
Deep neural networks (DNNs) have achieved unprecedented success in many complex tasks. However, they are also vulnerable to various attacks, such as adversarial attacks. To enable robustness verification, we need to over-approximate the computation of the network. To achieve this, we need to use abstract interpretation, which is a well-known program reasoning framework. In this work, we propose a symbolic reasoning framework for DNN verification. We use quadratic relations to encode the computation and attack constraints, and then translate the quadratic program (QP) into quadratic programs.
In this paper, we study the problems of reachable set estimation and safety verification for dynamical systems equipped with neural network controllers. The controller is a feedforward neural network determining actuation. The controller is a neural network determining actuation. The key step to solve the problem is to soundly estimate the output set of the neural network controller. The output set estimation problem can be transformed into a linear programming (LP) problem for neural networks with a specific class of activation functions called rectified linear unit (ReLU). The reachable set estimation problem can be solved by using
Hypofractionated lung radiotherapy is an increasingly used modality for the treatment of lung cancer. The treatment is a highly ablative therapy, both to the tumors and to the surrounding normal tissue. However, the treatment is highly uncertain due to the respiratory motion of the tumor. During treatment, a sequence of cine EPID images can be acquired without disrupting the treatment routine. In this work, we propose a template matching technique based on cross-correlation coefficients to calculate the similarity between a reference portal image and the
Graph neural networks (GNNs) are generalizations of neural networks that operate on graph structured data, typically in the form of an adjacency matrix or graph laplacian, and feature vectors defined for the nodes. They have found success in tasks such as link prediction, node classification, and graph classification. Along side the empirical success, recent theoretical work has elucidated properties on their depth (Oono & Suzuki (2019)), architectural alignment with algorithms (Xu et al. (2019)), and their discriminative power (Grathwohl et
In this work we consider control systems where the plant model is given as a nonlinear ordinary differential equation (ODE) and the controller is implemented by a neural network. We are interested in reachability properties of such systems: guaranteed reachability of target states or nonreachability of error states. In principle, reachability analysis for NNCS can be implemented by chaining two off-the-shelf tools for analyzing the ODE and the neural network. However, this approach often yields sets that are too conservative to be useful in practice. In this paper we propose a new approach that
Deep Neural Networks (DNNs) have emerged as an effective approach for solving challenging real-world problems. However, they can have “bugs”, e.g., producing unexpected results on inputs that are different from those in training data, and be attacked, e.g., small perturbations to the inputs by a malicious adversary or even sensorial imperfections result in misclassification. To address this question, researchers have developed a variety of techniques and tools to verify DNNs. Constraint-based approaches scale well to large networks, but do not scale to large
Deep neural networks (DNNs) have been proposed for a variety of tasks, including malware detection, abnormal network activity detection, and self-driving cars. However, they are susceptible to adversarial examples, which are inputs which, though initially classied correctly, are misclassified after a minor, perhaps imperceptible, perturbation. In this paper, we propose a novel game-based approach for safety verification of DNNs. We consider two pointwise robustness problems, referred to as the maximum safe radius problem and feature robustness problem. The former problem studies
Deep learning, especially deep neural networks (DNNs), has been successfully adopted in widespread applications for its high effectiveness and efficiency. However, obtaining well-trained DNNs is expensive and requires a large number of high-quality training samples, and many computational resources. Therefore, the adversaries can obtain a functionsimilar copy model of the well-trained victim model to ‘steal’ it. This attack is called model stealing. Currently, there are some methods to defend against model stealing. In this paper, we revisit the verification-based defenses against model
Existing approaches for certifying deep neural networks (DNNs) rely on solving a constraint satisfaction problem, or applying search algorithms over discretised vector spaces. However, these approaches suffer from two major weaknesses. Firstly, their subjects of study are restricted. More specifically, they can only work with linear transformations (such as convolutional and fully connected layers) and simple nonlinear transformations (such as ReLU), and cannot work with other important layers, such as the sigmoid, max pooling and softmax layers. Our approach is a global optimisation algorithm that can compute
Deep neural networks (DNNs) have become one of the most widely used tools for solving complex and challenging problems in numerous domains, such as image classification, function approximation, and natural language translation. However, their behavior can be unpredictable due to slight perturbations in their inputs (i.e., adversarial perturbations). In this paper, we introduce the NNV (Neural Network Verification) tool, which is a software framework that performs set-based verification for DNNs and learning-enable sets of DNNs, known as neural network control systems (NN
Spinal fusion surgery is a high-risk surgery with high economic burden. Despite substantial improvements in operative technique, the number of misplaced pedicle screws remains high, despite the fact that intraoperative 3D conebeam CT (CBCT) imaging is becoming widely available. However, intraoperative CBCT images suffer from substantially stronger metal artifacts around the highlyattenuating titanium implants, which compromise the value of intraoperative CBCT for assessing cortical breach. In this paper, we propose to extend the traditional shortscan trajectory by autonomously adjusting out
This paper presents two fault injection (FI) frameworks for TensorFlow 1 and TensorFlow 2. The frameworks allow the user to model soft errors during the execution of a neural network, analyze the effects of such errors, and identify the most critical parts of the network. The experiments show which erroneous operations or layers have the largest impact on the accuracy, allowing the introduction of efficient selective fault protection mechanisms. The results show which erroneous operations or layers have the largest impact on the accuracy, allowing the
Topology design optimization is a branch of design optimization that aims to determine the optimal distribution of material such that the structure has desired properties (e.g. minimizing the compliance of structure) while satisfying the design constraints. Currently, the training process of convolutional neural networks (CNN) is an inverse problem that emphasizes the existence, uniqueness, and efficiency of the results. To address this problem, we have developed a new topology design procedure to generate optimal structures using a Generative Adversarial Network (CWGAN) that is to improve the convergence stability and mode collapse
We propose a simple, fast yet effective face anti-spoofing system termed Aurora Guard (AG). Its principle is using light reflection to disentangle two auxiliary information, i.e., depth and material, to consolidate discriminative features for real/fake classification. The learned features are robust for both 2D and 3D attacks, which facilitates the liveness judgment in the classification branch. In addition, we leverage the light CAPTCHA, i.e., the random light parameters sequence, to provide an extra security mechanism by providing an additional branch to handle the mod
Deep Neural Network (DNN) is a powerful tool for computer vision, natural language processing and data mining. However, the training process is expensive and requires a vast amount of training data. To protect the valuable training data and the trained DNN models from being illegally copied, redistributed or misused, it becomes a compelling need that motivates our research work reported in this article. To address this need, a unified framework called FedIPR has been proposed to collaboratively train a federated deep neural network (FedDNN) without sharing of the private training data
Convolutional neural networks (CNNs) have achieved state-of-the-art performance for various computer vision tasks, such as object detection, detection, segmentation, and face verification. In the field of face verification, CNNs have already surpassed humans’ abilities on several benchmarks. In the pipeline of face verification, the most common pipeline involves face detection, facial landmark detection, face alignment, feature extraction, and feature comparison. In the feature comparison step, the cosine similarity or equivalently L2normalized Euclidean distance is used to measure the similarity. In this paper, we
We propose a novel loss function called octuplet loss that leverages the advantages of the widespread triplet loss concept and build upon it. Our key innovation is the combination of four triplet loss terms, which exploit the relationship between high and low-resolution images and identity labels. Our proposed octuplet loss fine-tuning strategy can be easily applied to existing networks to improve their robustness against image resolution while maintaining comparable performance on high-resolution images. Our proposed fine-tuning strategy can be easily applied to existing networks
Deep neural networks (DNNs) are a powerful tool to identify patterns in large amounts of data and to make predictions on new, previously unseen data. Due to their high performance and low cost, DNNs are now used in many Deep Learning based Systems (DLS), such as self-driving cars, medical systems, and web services. However, relying solely on the predictions made by a DNN component might be dangerous, as there is always some uncertainty about the correctness of the prediction. The uncertainty is either caused by entropy in the input or by inadequate
We propose a hybrid quantum-classical algorithm for verifying the robustness of neural networks. The hybrid algorithm exploits the combinatorial power of quantum computers and combines it with classical optimization. The hybrid algorithm is an iterative process where the linear program generates cuts for the quadratic unconstrained binary optimization (QUBO) which is solved by a quantum computer or a quantum annealer. The hybrid algorithm is a proof of concept and shows that it is sound in an ideal, simulated setting and converges to the exact verification problem.
Convolutional neural networks (CNNs) have proven successful across many tasks in machine learning and artificial intelligence. However, the standard approach to training a CNN is based on solving a nonconvex optimization problem that is known to be NP-hard. In practice, researchers use some avor of stochastic gradient method, in which gradients are computed via backpropagation. This approach has two drawbacks: (i) the rate of convergence, which is at best only to a local optimum, and (i) the statistical properties of CCNN models can be
Deep Learning (DL) models are increasingly outsourced to the cloud. This is natural, as cloud services can be more fiscally palatable for companies. However, the majority of these investigations are limited in that: 1) they are only applicable to simple shallow network models, 2) they are evaluated with datasets that have a small number of records (such as MNIST and CIFAR10), and 3) they incur a substantial amount of overhead that is unacceptable for real-life DL training workloads. To address these limitations, we introduce GOAT (See Figure
Recently, feedforward deep neural networks have been successfully used for controlling physical systems, such as self-driving cars and unmanned aerial vehicles. The combination of a physical system with a neural network based controller is sometimes known as a neural network controlled system. If such a system is considered as safetycritical, meaning that a failure of the system could have serious consequences, then a particular effort needs to be made to demonstrate its safety. More precisely, one has to show evidence that the system fulfills a set of safety requirements, such as,
Face aging has raised considerable attentions in computer vision and machine learning communities recently. However, the synthesized results in these previous approaches are still far from perfect due to various challeng ing factors, such as heredity, living styles, etc. In this paper, we propose a novel approach to synthesize the faces of a subject at older ages, i.e. age progression, or younger ages, i.e. age regression or deaging. In this paper, we propose a novel approach to synthe
We propose a cross-modal image fusion method based on the Combined Vision System (CVS) image fusion task. Our method uses the effective combination of attention mechanism and nonlinear neural network to simulate the feature selection characteristics of human visual perception system. In addition, our method uses the effective combination of attention mechanism and nonlinear neural network to simulate the nonlinear combination characteristics of human visual perception system. In order to make the results of image fusion more consistent with the mechanism of human brain image fusion, we propose a general image fusion framework (IFCNN) framework
Recurrent neural networks (RNNs) are widely used to model long-term dependencies in lengthy sequential signals. However, their robustness is often questioned in the context of real-world applications, such as speech recognition. In this paper, we present the first precise and scalable verifier for recurrent neural networks based on abstract interpretation. Our method is based on a polyhedral abstraction capturing all speech signals given as input to the model under the given perturbation budget. At each timestep i, the preprocessing operation produces a polyhedral abstraction capturing hidden
Deep neural networks are susceptible to small perturbations applied to their inputs, i.e. it is possible to misguide the model output by applying a designed perturbation to a given input. To overcome such vulnerability, many approaches have been previously employed. These approaches aim to generate adversarial examples, the so-called adversarial attacks, and subsequently apply these inputs in the training process of the neural network. Even though these approaches helped to reduce the vulnerability of the neural networks, these models remained vulnerable to adversarial attacks. The existing formal methods can be classifi
Fullwaveform inversion (FWI) is a widely used inversion method for estimating subsurface velocity structure based on seismic waves recorded at the surface. Although FWI can achieve high accuracy when the full seismic waveform is matched, the nonlinearity of the objective function poses a challenge to the optimization process. One solution is to recover or predict the missing low frequency content of the seismic waveform data, such as through envelope inversion, sparse blind deconvolution, and phase-tracking methods. Another solution is to apply deep learning to FWI to the PDE constraint in
Handwriting verification is a task wherein a forensic document examiner (FDE) provides an explanation for the handwritten evidences provided by the system. The explanations provided by the system are difficult to interpret because the system does not provide explanations for the decision. Hence, we propose an explanation based handwriting verification system which generates human explainable features instead of using vantage writer approach. The proposed system is based on a feature learning network (FLN) which learns to map the input images to human observed features. The system uses a vantage writer approach to generate a
In recent years, fake news has become a hot topic in the news industry. Fake news is widely spread on social networks, and it is difficult to identify fake news. In this paper, we propose a novel Bottom-Up Pattern Matching (BUPM) based verification network for image-to-GPS verification. BUPM directly compares a query image and a reference image collected from a claimed GPS location, and thus completely eliminates the error-prone reference images caused by the lack of critical camera information. BUPM based verification network is designed to detect fake news.
The convolutional neural network (CNN) has shown potential for learning state-of-the-art feature embeddings or deep metrics. However, the two major types of CNN structures, i.e.,verification models and identification models, are different in terms of input, feature extraction and loss function for training. In this work, we propose to combine the strengths of the two networks and leverage their complementary nature to improve the discriminative ability of the learned embeddings. The proposed model is a siamese network that predicts person identities and similarity scores at the
Deep neural networks (DNNs) have been widely applied in various domains, including image classification, natural language processing, and game playing. However, the certification of DNNs requires provable guarantees. Currently, DNN verification techniques include constraintsolving, layer-by-layer exhaustive search, global optimization, abstract interpretation, etc. Abstract interpretation is a theory in static analysis which verifies a program by using an abstract approximation of its semantics. In this paper, we propose a novel symbolic propagation technique to enhance the precision of abstract interpretation. We use a new abstract
Deep neural networks (DNNs) have improved the performance of speaker verification (SV) systems. However, SV systems are vulnerable to various presentation attacks, such as replay attacks, voice conversion, and speech synthesis. These vulnerabilities have inspired research into presentation attack detection (PAD), which classifies given utterances as spoofed or not spoofed. In this paper, we propose two spoofing-aware frameworks for the ISV task, illustrated in Figure 1. The first proposed framework expands existing work by proposing a monolithic end-to-end (E
The softmax loss function is biased to the sample distribution. Unlike contrastive loss and triplet loss which specifically attend to hard samples, the softmax loss maximizes the conditional probability of all the samples in a given minibatch. Hence, it is suited to handle high quality faces, ignoring the rare difficult faces in a training minibatch. In this paper, we propose the Crystal loss function that adds a constraint on the features during training such that their L2norm remains constant. In other words, the Crystal loss functions. The proposed Crystal loss
Deep convolutional networks (CNNs) have been widely used in face recognition, clustering and verification tasks. However, face recognition methods based on deep convolutional networks (CNNs) differ along three primary attributes. The first is the availability of large scale datasets for training deep convolutional networks. The second is the emergence of powerful and scalable network architectures such as Inception ResNet to train on large scale datasets. The third is the development of loss functions to effectively modify inter and intraclass variations such as Contrastive loss. In this paper, we propose a new loss
The Energy Efficiency Directive (EED) has been issued to maximise the energy efficiency of industry. The focus of the Directive is on the implementation of energy conservation measures (ECMs) to minimise consumption in the industrial sector. However, the accuracy of M&V on individual projects is not guaranteed. This paper proposes a machine learning-supported methodology to overcome these challenges. The proposed methodology is based on the IPMVP, which defines a methodological approach that can be applied to quantify uncertainty in a project. The IPMVP is a methodological approach is a
Handwriting recognition is a numeric process of translating handwritten text images into strings of characters. Optical character recognition is a difficult task due to the variability of shapes in handwritten texts. Linguistic processing aims at combining the characters hypotheses together so as to provide the most likely sequence of words in accordance with some high level linguistic rules. There are two types of linguistic knowledge: lexicons and language models. The use of a lexicon is an open problem. The raw performance of lexicon driven recognition is due to the lexicon. The contribution of
In this paper, we propose a novel deep speaker embedding architecture for speaker verification (SV). The speaker embedding architecture is based on deep neural networks (DNNs). The DNNs are trained on a large amount of utterances and generate two-dimensional outputs with time dimension and channel dimension. The speaker embeddings are extracted from the output of fully connected (FC) 3 layers. The speaker embeddings are extracted from the output of fully connected (FC) 3 layers. The a
Authorship verification (AV) is a branch of forensic authorship analysis. It is a branch of forensic authorship analysis that aims to verify whether two text documents are written by the same author while no previous writing samples of their author/authors have been specied. Traditionally, the AV problem considered a closed and limited set of authors and a closed set of documents written by those authors. During the training step some of these documents were observed and the goal was to identify whether the authors of a pair of the given documents are identical. In this paper, we propose two different
Face recognition networks have been shown to exhibit bias against sensitive attributes such as gender, race and skintone. This has raised concerns about bias against sensitive attributes such as gender and race. Several works have explored the issue of bias against gender and skintone in face recognition. While retraining a face recognition network on a dataset which is balanced in terms of these attributes may lead to unbiased systems, there exists a prevalence variation between demographic subgroups with respect to multiple factors such as pose, illumination etc., which may lead to a biased system. In this paper, we propose two novel knowl edge
Deep learning models are treated as valuable intellectual properties. In such a situation, some malicious model user might redistribute licensed models illegally or provide a prediction service using the licensed model without permission. To deal with such leakage, we require a method that allows us to verify the ownership of models externally. One promising solution is digital watermarking, to embed a mechanism into the model for external ownership verification. In this work, we investigate ownership verification of neural networks using a watermark, which enables the owner of a watermarking method
Deep Learning for Image SuperResolution: A Case Study of a Convolutional Neural Network for Face Recognition...............................................