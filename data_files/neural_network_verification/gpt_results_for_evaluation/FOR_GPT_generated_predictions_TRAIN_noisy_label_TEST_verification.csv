Unnamed: 0,titles,abstract,introduction,prediction,result
34,Scalable Verification of Probabilistic Networks.txt,"This paper presents McNetKAT, a scalable tool for verifying probabilistic
network programs. McNetKAT is based on a new semantics for the guarded and
history-free fragment of Probabilistic NetKAT in terms of finite-state,
absorbing Markov chains. This view allows the semantics of all programs to be
computed exactly, enabling construction of an automatic verification tool.
Domain-specific optimizations and a parallelizing backend enable McNetKAT to
analyze networks with thousands of nodes, automatically reasoning about general
properties such as probabilistic program equivalence and refinement, as well as
networking properties such as resilience to failures. We evaluate McNetKAT's
scalability using real-world topologies, compare its performance against
state-of-the-art tools, and develop an extended case study on a recently
proposed data center network design.","Networks are among the most complex and critical com puting systems used today. Researchers have long sought ∗Extended version with appendix. †Work performed at Cornell University. PLDI ’19, June 22–26, 2019, Phoenix, AZ, USA ©2019 Copyright held by the owner/author(s). Publication rights licensed to ACM. This is the author’s version of the work. It is posted here for your personal use. Not for redistribution. The definitive Version of Record was published in Proceedings of the 40th ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI ’19), June 22–26, 2019, Phoenix, AZ, USA , https://doi.org/10.1145/3314221.3314639 .to develop automated techniques for modeling and analyz ing network behavior [ 51], but only over the last decade has programming language methodology been brought to bear on the problem [ 6,7,36], opening up new avenues for reasoning about networks in a rigorous and principled way [ 4,14,25,27,33]. Building on these initial advances, researchers have begun to target more sophisticated net works that exhibit richer phenomena. In particular, there is renewed interest in randomization as a tool for designing protocols and modeling behaviors that arise in largescale systems—from uncertainty about the inputs, to expected load, to likelihood of device and link failures. Although programming languages for describing random ized networks exist [ 13,17], support for automated reasoning remains limited. Even basic properties require quantitative reasoning in the probabilistic setting, and seemingly sim ple programs can generate complex distributions. Whereas stateoftheart tools can easily handle deterministic net works with hundreds of thousands of nodes, probabilistic tools are currently orders of magnitude behind. This paper presents McNetKAT , a new tool for reason ing about probabilistic network programs written in the guarded and historyfree fragment of Probabilistic NetKAT (ProbNetKAT ) [4,13,14,46].ProbNetKAT is an expressive programming language based on Kleene Algebra with Tests, capable of modeling a variety of probabilistic behaviors and properties including randomized routing [ 30,48], uncer tainty about demands [ 40], and failures [ 19]. The historyfree fragment restricts the language semantics to inputoutput be havior rather than tracking paths, and the guarded fragment provides conditionals and while loops rather than union and iteration operators. Although the fragment we consider is a restriction of the full language, it is still expressive enough to encode a wide range of practical networking models. Ex isting deterministic tools, such as Anteater [ 35], HSA [ 25], and Veriflow [ 27], also use guarded and historyfree models. To enable automated reasoning, we first reformulate the semantics of ProbNetKAT in terms of finite state Markov chains. We introduce a bigstep semantics that models pro grams as Markov chains that transition from input to out put in a single step, using an auxiliary smallstep semantics to compute the closedform solution for the semantics ofarXiv:1904.08096v1  [cs.PL]  17 Apr 2019PLDI ’19, June 22–26, 2019, Phoenix, AZ, USA S. Smolka, P. Kumar, D. Kahn, N. Foster, J. Hsu, D. Kozen, and A. Silva the iteration operator. We prove that the Markov chain se mantics coincides with the domaintheoretic semantics for ProbNetKAT developed in previous work [ 13,46]. Our new semantics also has a key benefit: the limiting distribution of the resulting Markov chains can be computed exactly in closed form, yielding a concise representation that can be used as the basis for building a practical tool. We have implemented McNetKAT in an OCaml prototype that takes a ProbNetKAT program as input and produces a stochastic matrix that models its semantics in a finite and explicit form. McNetKAT uses the UMFPACK linear algebra library as a backend solver to efficiently compute limit ing distributions [ 8], and exploits algebraic properties to automatically parallelize the computation across multiple machines. To facilitate comparisons with other tools, we also developed a backend based on PRISM [31]. To evaluate the scalability of McNetKAT , we conducted experiments on realistic topologies, routing schemes, and properties. Our results show that McNetKAT scales to net works with thousands of switches, and performs orders of magnitude better than a stateoftheart tool based on generalpurpose symbolic inference [ 17,18]. We also used McNetKAT to carry out a case study of the resilience of a faulttolerant data center design proposed by Liu et al . [34] . Contributions and outline. The central contribution of this paper is the development of a scalable probabilistic net work verification tool . We develop a new, tractable semantics that is sound with respect to ProbNetKAT ’s original denota tional model. We present a prototype implementation and evaluate it on a variety of scenarios drawn from realworld networks. In §2, we introduce ProbNetKAT using a running example. In §3, we present a semantics based on finite stochas tic matrices and show that it fully characterizes the behavior ofProbNetKAT programs (Theorem 3.1). In §4, we show how to compute the matrix associated with iteration in closed form. In §5, we discuss our implementation, including sym bolic data structures and optimizations that are needed to handle the large state space efficiently. In §6, we evaluate the scalability of McNetKAT on a common data center design and compare its performance against stateoftheart proba bilistic tools. In §7, we present a case study using McNetKAT to analyze resilience in the presence of link failures. We sur vey related work in §8 and conclude in §9. We defer proofs to the appendix. 2 Overview This section introduces a running example that illustrates the main features of the ProbNetKAT language as well as some quantitative network properties that arise in practice. Background on ProbNetKAT. Consider the network in Fig ure 1, which connects a source to a destination in a topology with three switches. We will first introduce a program that Switch 1 Switch 2 Switch 3 Source Destination12313212Figure 1. Network topology for running example. forwards packets from the source to the destination, and then verify that it correctly implements the desired behavior. Next, we will show how to enrich our program to model the possibility of link failures, and develop a faulttolerant forwarding scheme that automatically routes around fail ures. Using a quantitative version of program refinement, we will show that the faulttolerant program is indeed more resilient than the initial program. Finally, we will show how to compute the expected degree of resilience analytically. To a first approximation, a ProbNetKAT program can be thought of as a randomized function that maps input packets to sets of output packets. Packets are modeled as records, with fields for standard headers—such as the source ( src) and destination ( dst) addresses—as well as two fields switch (sw) and port ( pt) encoding the current location of the packet. ProbNetKAT provides several primitives for manipulating packets: a modification f","This paper presents McNetKAT, a new tool for reasoning about probabilistic network programs written in the guarded and history-free fragment of Probabilistic NetKAT (ProbNetKAT). ProbNetKAT is an expressive programming language capable of modeling a variety of probabilistic behaviors and properties including randomized routing, uncertainty about demands, and failures. Although state-of-the-art tools can easily handle deterministic net works with hundreds of thousands of nodes, state-of-the-art tools for probabilistic networks are currently orders of magnitude behind.","90,80"
385,Insights into Fairness through Trust: Multi-scale Trust Quantification for Financial Deep Learning.txt,"The success of deep learning in recent years have led to a significant
increase in interest and prevalence for its adoption to tackle financial
services tasks. One particular question that often arises as a barrier to
adopting deep learning for financial services is whether the developed
financial deep learning models are fair in their predictions, particularly in
light of strong governance and regulatory compliance requirements in the
financial services industry. A fundamental aspect of fairness that has not been
explored in financial deep learning is the concept of trust, whose variations
may point to an egocentric view of fairness and thus provide insights into the
fairness of models. In this study we explore the feasibility and utility of a
multi-scale trust quantification strategy to gain insights into the fairness of
a financial deep learning model, particularly under different scenarios at
different scales. More specifically, we conduct multi-scale trust
quantification on a deep neural network for the purpose of credit card default
prediction to study: 1) the overall trustworthiness of the model 2) the trust
level under all possible prediction-truth relationships, 3) the trust level
across the spectrum of possible predictions, 4) the trust level across
different demographic groups (e.g., age, gender, and education), and 5)
distribution of overall trust for an individual prediction scenario. The
insights for this proof-of-concept study demonstrate that such a multi-scale
trust quantification strategy may be helpful for data scientists and regulators
in financial services as part of the verification and certification of
financial deep learning solutions to gain insights into fairness and trust of
these solutions.","The success of deep learning [ 1] in recent years have led to a signiﬁcant increase in interest by academic and ﬁnancial communities toward the adoption of deep learning solutions for tackling ﬁnancial services applications. Given the powerful predictive modeling capabilities facilitated by deep neural network architectures, ﬁnancial deep learning has been explored for a wide range of different tasks such as stock market prediction [ 2–6], ﬁnancial trading [ 7], credit card fraud detection [ 8,9], credit card default prediction [ 10], exchange rate prediction [ 11,12], and antimoney laundering [ 13,14]. These encouraging studies related to ﬁnancial deep learning have led to ﬁnancial institutions around the world to explore the deployment of such solutions in realworld ﬁnancial practice. One particular question that often arises as a barrier to adopting deep learning for ﬁnancial services in realworld practice is whether the developed ﬁnancial deep learning models are fair in their predictions. Fairness in ﬁnancial models is particularly crucial in light of strong governance and regulatory compliance requirements in the ﬁnancial services industry, as well as the socioeconomic Preprint. Under review.arXiv:2011.01961v1  [cs.LG]  3 Nov 2020implications of leveraging automated decisionmaking tools within the global ﬁnancial ecosystem. While explorations into fairness for ﬁnancial deep learning have been conducted through aspects such as explainability [ 3,15], a fundamental aspect of fairness that has not been explored in ﬁnancial deep learning is the concept of trust, particularly since variations in trust under different scenarios and circumstances can indicate an egocentric view of fairness by a model, which leads to inherent biases in predictions made. It is through this lens of trust that we try to gain insights into the fairness of ﬁnancial deep learning models. Motivated by the importance of trust in deep learning in general, there has been a new focus in recent years on trust quantiﬁcation, where the goal is to quantify the trustworthiness of deep neural networks and the predictions and decisions they make. Methods range from uncertainty estimation [ 16–19] to agreement assessment [ 20] to subjective logic [ 21]. More recently, a number of studies have focused on the design of interpretable metrics for the purpose of trust quantiﬁcation of deep neural networks at different scales [ 22,23]. More speciﬁcally, the trust quantiﬁcation metrics introduced in these studies include (from ﬁnest to coarsest scale): 1.QuestionAnswer Trust : a scalar measure of a model’s trustworthiness for a single question answer pair. 2.Trust Density : distribution of questionanswer trust for a given prediction scenario. An extension of trust density is the notion of conditional trust densities, which further decompose a trust density to gain insight into trust behaviour for a given prediction scenario both correct prediction and incorrect prediction scenarios. 3.Trust Matrix : a matrix representation of the trust level under all possible predictiontruth relationships. 4.Trust Spectrum : a measure of the overall trust in a model across spectrum of possible prediction scenarios. 5.NetTrustScore : a scalar measure of overall trustworthy of a model. An extension of NetTrustScore is the notion of conditional NetTrustScores, which further decompose Net TrustScore to gain insight into overall trust behaviour for a given model under correct prediction and incorrect prediction scenarios. By studying trustworthiness of a deep neural network across multiple scales, one can gain deeper insights into not just how trustworthy a deep neural network is, but also where trust breaks down. These insights into trustworthiness can unveil important insights into the fairness of a deep neural network, particularly by observing the variations in trust under different scenarios at different scales since it may unveil an egocentric view of fairness that can lead to biases in predictions. Motivated by the insights that can be gained with such an approach, in this study we explore the feasibility and utility of multiscale quantiﬁcation for ﬁnancial deep learning to gain insights into the fairness of a model. More speciﬁcally, we conduct proofofconcept multiscale trust quantiﬁcation on a deep neural network for the purpose of credit card default prediction to study: • the overall trustworthiness of the model, • the trust level under all possible predictiontruth relationships, • the trust level across the spectrum of possible predictions, •the trust level across different demographic groups (In this particular study, we study trust levels across age, gender, and education), and • the distribution of overall trust for an individual prediction scenario. We then study the trust quantiﬁcation results produced by this suite of quantitative metrics and the variations observed within these metrics in great detail to gain deeper insights into the fairness of the model. To facilitate this multiscale trust quantiﬁcation, we modify trust quantiﬁcation metrics that were introduced in past studies [ 22,23] to account for demographics in their mathematical formulation, as well as introduce new trust quantiﬁcation metrics in the form of demographic trust spectra. The paper is organized as follows. In Section 2, we discuss the multiscale trust quantiﬁcation strategy being leveraged for ﬁnancial deep learning, particularly discussing the concepts of questionanswer trust, trust density, trust spectrum, and NetTrustScore. We continue by modifying their mathematical 2formulation to account for demographics, and introduce a novel concept of demographic trust spectrum and its associated mathematical formulation. In Section 3, we will also describe the deep neural network for credit card default prediction used to as proofofconcept to illustrate the feasibility and utility of the multiscale trust quantiﬁcation approach, as well as the dataset used. In Section 4, we will discuss the trust quantiﬁcation results produced by the multiscale trust quantiﬁcation process to investigate where trust breaks down for this model at different scales of granularity, and gain some valuable insights on trust and fairness for ﬁnancial deep learning. 2 Methods","Deep learning has been explored for a wide range of different financial services applications, including credit card default prediction, exchange rate prediction, and anti-money laundering. However, one question that often arises as a barrier to adopting deep learning for financial services in real-world practice is whether the developed financial deep learning models are fair in their predictions. While explorations into fairness for financial deep learning have been conducted through aspects such as explainability, a fundamental aspect of fairness that has not been explored in financial deep learning is the concept of trust. In this study, we conduct proof-of-","90,80"
102,Joint Speaker Encoder and Neural Back-end Model for Fully End-to-End Automatic Speaker Verification with Multiple Enrollment Utterances.txt,"Conventional automatic speaker verification systems can usually be decomposed
into a front-end model such as time delay neural network (TDNN) for extracting
speaker embeddings and a back-end model such as statistics-based probabilistic
linear discriminant analysis (PLDA) or neural network-based neural PLDA (NPLDA)
for similarity scoring. However, the sequential optimization of the front-end
and back-end models may lead to a local minimum, which theoretically prevents
the whole system from achieving the best optimization. Although some methods
have been proposed for jointly optimizing the two models, such as the
generalized end-to-end (GE2E) model and NPLDA E2E model, all of these methods
are designed for use with a single enrollment utterance. In this paper, we
propose a new E2E joint method for speaker verification especially designed for
the practical case of multiple enrollment utterances. In order to leverage the
intra-relationship among multiple enrollment utterances, our model comes
equipped with frame-level and utterance-level attention mechanisms. We also
utilize several data augmentation techniques, including conventional noise
augmentation using MUSAN and RIRs datasets and a unique speaker embedding-level
mixup strategy for better optimization.","AUTOMATIC speaker veriﬁcation (ASV), which veriﬁes and compares the speaker identity of an input utterance with enrollment data, is an extensively used biometric method. Depending on whether there are restrictions on the content of the speech, ASV systems can be divided into textdependent ones, where the content of the spoken utterance is speciﬁed, or textindependent ones in which there are no restrictions on the linguistic content. With the development of deep learning, deep neural networks (DNN) have been successfully applied to both textindependent and textdependent ASV tasks. The mainstream ASV models have evolved from statistical gen erative models such as Gaussian mixture models (GMM), universal background models (UBM) [1] and ivectors [2] to DNNbased discriminative models such as dvector [3], [4], Manuscript received XXX. This study was partially supported by JST CREST Grants (JPMJCR18A6 and JPMJCR20D3), MEXT KAKENHI Grants (21K17775, 21H04906, 21K11951, 18H04112), and Google AI for Japan program. (Corresponding author: Chang Zeng.) Chang Zeng, Xiaoxiao Miao, Xin Wang, Erica Cooper and Junichi Yamag ishi are with the National Institute of Informatics, 212 Hitotsubashi Chiyoda ku, Tokyo 1018340, Japan (email: fzengchang, xiaoxiaomiao, wangxin, ecooper, jyamagisg@nii.ac.jp).xvector [5]–[7], and rvector [8]. One of the earliest DNN based approaches is the dvector [3], which takes framelevel acoustic features and their context as the input to predict the framelevel speakerrelated representation, requiring post processing to obtain the prediction of one utterance. More recently, DNNbased ASV systems utilize more efﬁcient meth ods that directly extract utterance or segmentlevel speaker representative vectors (also called speaker embeddings) from the hidden layer of a DNN. Stateoftheart DNNbased ASV systems can be broadly categorized into two groups: stagewise approaches and fully endtoend (E2E) approaches. The stagewise approaches con sist of a neural speaker encoder for extracting speaker em beddings as frontend processing and a backend model for measuring the similarity of speaker embeddings, in which the processes in the two stages are trained separately. The frontend speaker encoder mainly consists of a framelevel feature extractor to capture discriminative speaker information, a pooling layer to accumulate the framelevel features into an utterancelevel representation, and a loss function for the optimization. Two typical stagewise methods are time delay neural network (TDNN)based xvector and residual neural network (ResNet)based rvector. The xvector utilizes TDNN as a framelevel feature extractor, followed by a statistics pooling layer to aggregate framelevel features into an utterance level vector, which is then passed on to the following fully connected classiﬁer. Instead of using TDNN, a 1dimensional convolutional neural network, ResNetbased rvector leverages 2dimensional convolutional neural networks with residual connections, which is beneﬁcial for building deeper neural networks as the framelevel feature extractor. Analogous to xvector, rvector also uses a temporal pooling layer for ag gregating framelevel information into a single utterancelevel speaker vector, and the following classiﬁer uses the aggregated vector as input to categorize speakers. In addition to the frameworks of speaker encoders mentioned earlier, various approaches primarily related to the pooling methods and loss functions have also been proposed to improve the performance further. For example, a selfattention mechanism [7], [9] was introduced into the pooling layer to calculate attentive statistics for more discriminative speaker representations. As for the loss functions of the speaker encoder, both metric learning based loss functions such as triplet loss [10], [11] and margin based softmax loss functions such as angular softmax lossarXiv:2209.00485v1  [eess.AS]  1 Sep 2022JOURNAL OF L ATEX CLASS FILES, VOL. XX, NO. X, XXX 2022 2 Fig. 1. General architecture of ASV . [12], [13] and additive margin softmax loss [14], [15] have shown superior performance in ASV tasks. It should be noted that the loss functions used in the speaker encoder are not veriﬁcationbased ones but classiﬁcationbased ones. A backend model, which measures the similarity of enroll ment utterances and a testing utterance, is another crucial part of a modern ASV system. Cosine similarity is a simple but widely used backend model for the frontend neural speaker encoder with a marginbased softmax loss function. Compared with cosine similarity, PLDA [16] is a more robust backend model that can further disentangle speaker and channel factors in a latent space. Neural networks have also been used as the backend model [17], and it was reported through a challenge competition [18] that this model outperforms the conventional PLDA model [18]. Moreover, there have been attempts to 1) combine a neural speaker encoder with a neural backend, 2) design a fully E2E architecture that takes a pair of utterances as the input and generates the similarity score of trials directly from the inputs, and 3) optimize both of them by means of veriﬁcationbased loss functions [17], [18]. Even though many novel ASV approaches are proposed every year, there is one scenario that has not been fully ex plored: a module that handles multiple enrollment utterances. For practical cases where it is more reliable to use multiple enrollment utterances, the operation of simply concatenating waveforms or averaging speaker embeddings is generally applied to these multiple enrollment utterances to obtain a single speaker representative vector [19]–[21], which is then treated as a single enrollment utterance. In our previous study [22], we demonstrated that widely used simple operations such as concatenation and averaging for multiple enrollment utterances cannot efﬁciently leverage the intrarelationships among them. In order to better handle multiple enrollment utterances, a new neural backend called attention backend, which utilizes a scaleddot selfattention mechanism [23] to learn the acoustic variations among a varying number of enrollment utterances, has been proposed, along with a feedforward selfattention mechanism [24] to aggregate multiple speaker embeddings into a single speaker representative vector by using an adaptive weighted sum. In this paper, to handle the case of multiple enrollment utterances more appropriately, we extend our earlier pro posed attention backend to an E2E approach by jointly ﬁne tuning the frontend speaker encoder and the attention backend simultaneously. We argue that the intraspeaker acoustic variations contained in multiple enrollment utterances can also overcome some of the intrinsic biases of the pretrained speaker encoder introduced by classiﬁcationbased learning [12], [14], [25] or metric learning [10], [11], [26]. Addition ally, considering the problem of heavily unbalanced positive and negative trials existing in the trialssampling method [22], focal loss [27] is selected to replace the binary crossentropy loss to dynamically resample positive and negative trials and emphasize the contribution of difﬁcult trials at the same time. We also introduce a unique embeddinglevel mixup [28], [29] based data augmentation strategy to increase the diversity of the training data. The rest of this paper is presented as follows: In Section II, we provide an overview of representative works, including the details of frontend speaker encoders, frequently used loss functions, and both conventional and neural backend models. Section III introduces the new fully E2E approach extending our previously proposed attention backend to han dle the case of multiple enrollment utterances. The method of sampling training trials for multiple enrollment utterances is also described in detail in this section. Section IV lists the loss functions utilized in both the attention backend and the proposed fully E2E model. Section V describes the signal level and embeddinglevel data augmentation techniques we applied in ASV . In Section VI, we report the experimental results of the proposed fully E2E method on the CNCeleb dataset for the case of multiple enrollments by comparing it with models that use separatelytrained speaker encoder and backend models as well as other SOTA E2E methods. We present an experiment in which we stack our proposed points gradually to determine the individual improvements. A deeper analysis of the effect of the number of enrollment utterances is also provided in this section. We conclude Section VII with a brief summary. II. R ELATED WORK","Automatic speaker verification (ASV) is a widely used biometric method that verifies the speaker identity of an input utterance with enrollment data. With the development of deep neural networks (DNN), DNN-based ASV systems have been successfully applied to both text-dependent and text-independent tasks. The state-of-the-art DNN-based ASV systems can be broadly categorized into two groups: stage-wise approaches and fully end-to-end (E2E) approaches. The stage-wise approaches mainly consist of a speaker encoder for extractings speaker","85,90"
31,FCN+RL: A Fully Convolutional Network followed by Refinement Layers to Offline Handwritten Signature Segmentation.txt,"Although secular, handwritten signature is one of the most reliable biometric
methods used by most countries. In the last ten years, the application of
technology for verification of handwritten signatures has evolved strongly,
including forensic aspects. Some factors, such as the complexity of the
background and the small size of the region of interest - signature pixels -
increase the difficulty of the targeting task. Other factors that make it
challenging are the various variations present in handwritten signatures such
as location, type of ink, color and type of pen, and the type of stroke. In
this work, we propose an approach to locate and extract the pixels of
handwritten signatures on identification documents, without any prior
information on the location of the signatures. The technique used is based on a
fully convolutional encoder-decoder network combined with a block of refinement
layers for the alpha channel of the predicted image. The experimental results
demonstrate that the technique outputs a clean signature with higher fidelity
in the lines than the traditional approaches and preservation of the pertinent
characteristics to the signer's spelling. To evaluate the quality of our
proposal, we use the following image similarity metrics: SSIM, SIFT, and Dice
Coefficient. The qualitative and quantitative results show a significant
improvement in comparison with the baseline system.","Handwritten signature is a biometric authentication method widely used for personal documents and legal contract valida tions. Besides, experts in forensic analysis examine handwrit ten signatures to certify the authenticity of the writing and reveal possible fraud, which in some cases can mean high value ﬁnancial losses. One possible approach to signature authentication is through human operators who must compare the signature present in the document with the signature of the original subscriber. However, this approach can be expensive and timeconsuming, given the amount of data accumulated in institutions that use a handwritten signature as a means of identiﬁcation and authentication [1]. Several approaches have been developed in the ﬁeld of ma chine learning and statistical methods to perform the signature detection and veriﬁcation tasks automatically. Among these approaches, we can mention techniques based on ArtiﬁcialNeural Networks (ANN) [2], Hidden Markov Models (HMM) [3], Support Vector Machines (SVM) [4], and Fuzzy Logic [5]. Among the neural network techniques, it is important to mention Faster Regionbased Convolutional Neural Networks (RCNN) [6] and YOLOv2 [7]. Both models were adapted for logos and signature localization in noisy documents [8]. Many of the techniques that address signature veriﬁcation use public databases [9] [10] [11] [12]. However, such bases as GPDS [13], and MCYT [14] present images with a light background and dark signatures. This characteristic does not present an environment of great complexity for segmenting the signature pixels. Besides, due to the insertion of mobile devices and their growing popularity, several commercial and banking applications, for example, use images captured by smartphones for transactions, payments, account opening, and copies of documents [15] [16]. On the other hand, document images captured by smart phone cameras are usually presented with distortions and back ground noise. Therefore, treating these images in such a way that only handwritten signatures can be extracted for analysis of their characteristics becomes a challenging task in image processing. These images do not always present the desired features or the expected quality, negatively inﬂuencing the process of recognition and classiﬁcation of these handwritten signatures. The situation may become more critical if the image of the source document has unwanted characteristics, such as imperfections, backgrounds, printed text, shape, and variations in size. Another condition that can affect the quality of the attributes of handwritten signatures occurs when the image presents some distortion, such as perspective, inclination, scale, or unexpected resolution, all of them when scanning photos. All these interference can also harm the veriﬁcation systems of handwritten signatures with the increase of false positives or false negatives in the classiﬁcation process. In this work, we propose an approach to the pixellevel segmentation of handwritten signatures on images. Our model has been trained with ID document images with the same characteristics and interference that can arise in a realworld scenario. With this, our model will be able to get around thearXiv:2005.14229v1  [cs.CV]  28 May 2020problems presented during the capture of signature images in different identiﬁcation documents in noisy environments. Our proposal will also enable the acquisition of signatures with greater ﬁdelity in the strokes regardless of the types of pen, ink, background, preserving the graphic characteristics. An other contribution is that the preservation of the characteristics of the signature features will also make it possible to carry out graphotechnical analyzes. These features are used by forensic experts and may be applied in future systems for verifying handwritten signatures with a bias in forensic science. We use a Fully Convolutional Network (FCN) [17] for signature segmentation on identity document images with reﬁnement layers for the alpha channel of the image. The remainder of this paper is organized as follows: The Section II presents the Related Works; in Section III we describe the Proposed system; Section IV presents the Ma terial and Methods; in Section V we present the results and analysis of our proposal; and ﬁnally, the Section VI depict the conclusions obtained from this work. II. R ELATED WORKS","Handwritten signature is a biometric authentication method widely used for personal documents and legal contract valida tions. However, this approach can be expensive and time-consuming, given the amount of data accumulated in institutions that use a handwritten signature as a means of identification and authentication. Several approaches have been developed in the field of machine learning and statistical methods to perform the signature detection and verification tasks automatically. However, such approaches use public databases, which present images with a light background and dark signatures. On the other hand, document images captured by smartphones are usually presented with distortions and background noise","90,80"
47,Towards a Formal Verification of the Lightning Network with TLA+.txt,"Payment channel networks are an approach to improve the scalability of
blockchain-based cryptocurrencies. Because payment channel networks are used
for transfer of financial value, their security in the presence of adversarial
participants should be verified formally. We formalize the protocol of the
Lightning Network, a payment channel network built for Bitcoin, and show that
the protocol fulfills the expected security properties. As the state space of a
specification consisting of multiple participants is too large for model
checking, we formalize intermediate specifications and use a chain of
refinements to validate the security properties where each refinement is
justified either by model checking or by a pen-and-paper proof.","Blockchainbased cryptocurrencies do not scale well with respect to their transaction throughput. One approach to im prove said scalability are Payment Channel Networks – a second layer on top of a blockchain that processes transactions without writing each transaction to the blockchain. A payment channel between two users is opened by performing one transaction on the underlying blockchain. Once a payment channel is open, it allows for performing an unlimited number of transactions between its participating users without writing to the blockchain. Finally, a payment channel is closed by publishing a second transaction on the blockchain. In a pay ment channel network, the participating users are connected by payment channels and can perform multihop transactions so that the sender and the recipient of a transaction do not need to have a payment channel directly connecting them but it suffices that a path between sender and recipient over a set of payment channels exists. The security model for payment channels requires that honest users cannot loose their funds even if all other users behave adversarially. To avoid financial loss caused by design flaws in a payment channel protocol, it should be verified that the protocol is secure. In this paper, we analyze the security of the protocol of the Lightning Network [1], a payment channel network for Bitcoin [2], for which different implementations exist and which is used in practice. Our goal is to verify secu rity properties of the Lightning Networks’ protocol. While this goal has already been approached in previous work [3], we aim at verifying the properties in a largely machinechecked way because the complexity of the Lightning Network’s protocol is difficult to handle. Our general approach is to formalizethe Lightning Network’s protocol in TLA+and verify using model checking that the protocol fulfills the security property that honest parties retrieve at least their correct balance. Due to the complexity of the Lightning Networks’ protocol, we cannot directly model check the protocol specification. Instead, we use model checking for the most difficult proof steps and we provide penandpaper proofs to extend the statements about specifications that we can model check to the whole protocol specification. To concretize, we formalize an ideal functionality of a payment channel that abstracts the behavior of the Lightning Network’s protocol. We show that the formalized protocol specification of a payment channel refines the ideal channel functionality by explicitly specifying a refinement mapping between the formalized protocol specification and the ideal channel functionality. We verify the validity of the refinement mapping using a model checker. By using the ideal chan nel functionality, we specify an abstraction of the Lightning Network’s protocol for multihop payments. We use a model checker to verify that this specification of idealized channel functionalities implements the security properties for multi hop payments (e.g., dishonest parties cannot steal money). As the formalized protocol specification refines the specification of idealized channel functionalities, it follows that the formal ized protocol also implements the security properties. We describe the Lightning Network’s protocol in more detail in Section II and give a brief summary of related work in Section III. We give an overview of our approach in Section IV and describe how we show the individual proof steps. Our work is still inprogress and, thus, not all steps are complete but with this workinprogress report we aim to give an introduction to the overall approach. We do not provide the proof steps in detail but elaborate on the proof ideas. II. F UNDAMENTALS A. Payment Channels: SingleHop Payments A payment channel is a protocol between two users that enables these two users to deposit coins into the payment channel during opening, perform transactions between the two users by updating the payment channel, and retrieving their final funds by closing the payment channel. At every state of the protocol, each user is guaranteed to be able to close the channel to retrieve their current balance independent of cooperation of the other user. Even with an actively maliciousarXiv:2307.02342v1  [cs.LO]  5 Jul 2023channel partner, an honest user cannot loose their funds as long as the user actively monitors the underlying blockchain and reacts to malicious closing attempts. On a high level, a payment channel is implemented as a shared account: The two users open the shared account by depositing coins into the shared account and store the allocation of the funds, i.e., which user owns how many coins, in their current state. To perform a transaction sending xcoins from one user to the other user, both users agree on a new allocation of funds in which xcoins are deducted from the sender’s share of funds and added to the recipient’s share of funds. By updating their state, both users can perform an unlimited amount of transactions between each other just based on communication between each other. To fulfill the security guarantees, it needs to be ensured that the payment channel can be closed only in a state that represents the latest allocation of funds. Particularly, the channel may not be closed with an outdated allocation of funds and an honest user must be able to close a channel in a state with the latest allocation of funds. More technically, a payment channel is opened in the Lightning Network by creating a funding transaction1. The funding transaction has an input spending an output from the funding user (funder)2and the funding transaction has a multi sig output that is spendable only by the two users in the channel together. Just publishing the funding transaction on the blockchain would create a dependence of the funder on the other user for spending the funding transaction’s output as the funding transaction’s output can only be spent by the two users together. To prevent such a dependence, an initial commitment transaction that spends the funding transaction’s output is created by the two users and the nonfunding user sends their signature for the initial commitment transaction to the funder who only publishes the funding transaction after receiving this signature. A commitment transaction has at least two outputs: One output for each user that is redeemable only by this user and has an amount that corresponds to the balance the user currently has. In the initial commitment transaction, all funds are spendable by the funder.3 For a payment from one user to the other, an HTLC (Hash Timelocked Contract) is added to the channel. These HTLCs will also be used for multihop payments. An HTLC is a contract that encodes the agreement that the recipient receives a specified amount if the recipient proves knowledge of a preimage to a specified hash before a specified time has passed. To make a payment using an HTLC, the channel is updated to add the HTLC. The HTLC is added by adding a dedicated output that represents the HTLC to a new commit ment transaction. The amount of coins that are part of the 1See BOLT 2 and BOLT 3, https://github.com/lightning/bolts/blob/master/ 00introduction.md. 2At present, the Lightning Network supports only singlefunded channels, i.e. only one user deposits coins into the channel during opening. 3This is a simplification; the Lightning Network’s specification allows the funder to send a small amount to the nonfunding user already in the initial commitment transaction (see push_msat ).HTLC are deducted from the payment’s sender’s output in the new commitment transaction. After the HTLC is committed to the payment channel, the recipient of the payment fulfills the HTLC by sending the preimage to the sender of the payment. Then, the channel is updated by creating a new commitment transaction without the HTLC output to remove the HTLC and, in the new commitment transaction, the HTLC’s amount is added to the recipient’s balance. If the recipient does not fulfill the HTLC before the timelock, the HTLC is also removed but the HTLC’s amount is added back to sender’s balance. For an update of the channel, the sender of the payment cre ates a new commitment transaction and sends a signature for this new commitment transaction to the payment’s recipient. Now, the recipient has two valid versions of the commitment transaction: The current and the new commitment transaction which are both signed by the payment’s sender. Both versions of the commitment transaction are valid and can be published on the blockchain. As a malicious user might publish an outdated commitment transaction, commitment transactions should be ‘revoked’ so that they cannot be published anymore. As a signature to a commitment transaction cannot be undone, the Lightning Network uses an approach for revocation that relies on incentives: A user can be punished for publishing an outdated commitment transaction. For each commitment transaction there exists a revocation key pair. With knowledge of the private revocation key, one user can spend all outputs of the commitment transaction that the user’s counterpart in the channel has published. In this way, the transaction’s outcome is revoked while the transaction itself is persisted. During an update of a channel, both users send each other their signature for the new commitment transaction and reply by sending the private revocation key for the now outdated commitment transaction to revoke the outdated commitment transaction. As the users do not have the private revocation key for the current commitment transaction of their counterpart, they cannot punish each other for correct behavior like publishing the current commitment transaction. For the security of the protocol it is crucial that each user has the necessary private revocation keys for the states that are outdated and that the other user in the channel does not have the private revocation key for a state that is considered the latest state. B. Payment Channel Networks: MultiHop Payments If two users do not have a common payment channel but they are connected over a path of payment channels of other users, they can make multihop payments between each other. The intermediate users forward the payment over their channels and might receive a small fee for their service. To prevent intermediaries from stealing or loosing coins, it should be guaranteed for a multihop payment that each intermediary receives an incoming payment on one channel iff the intermediary forwards the payment on another channel. Also the sender should send the payment to an intermediary iff the recipient receives the payment from an intermediary. The Lightning Network uses HTLCs for multihop payments to achieve these security properties. The recipient of a paymentdraws a random value xand calculates the hash value y= H(x)using a cryptographic hash function H. The recipient sends yto the sender of the payment. The sender of the payment creates an HTLC with the first intermediary using y as the hash condition for the HTLC. The intermediary creates an HTLC with the next hop and each intermediary repeats this process until the last intermediary creates an HTLC with the recipient of the payment. The recipient knows the preimage xfor the hash condition yand fulfills the HTLC by sending xto the last intermediary. By fulfilling the HTLC, the payment’s recipient receives the payment’s amount from the last intermediary. Again, each intermediary forwards the secret value xfulfilling the HTLCs along the route until the sender receives xand pays the first intermediary. The timelocks of the HTLCs are chosen in a descending order from the sender to the recipient, so that each intermediary has enough time to fulfill the incoming HTLC from the previous hop if the next hop fulfills the outgoing HTLC. C. TLA+ The Temporal Logic of Actions (TLA) [4] is a temporal logic to reason about properties of a system. The language TLA+is based on TLA and can be used to formalize the behavior of system. Using tools like a model checker (TLC) or a theorem prover (TLAPS), invariants and properties can be shown to be valid for a formalized system. In TLA+, the state of a system is described by a set of variables vars . A system is defined by defining a set of initial states for which the formula Init is valid and by defining an action Next that determines which steps are allowed for the system to change its state. Using these components, a system is represented as a formula Init∧2[Next ]vars. An additional conjunct may be a fairness condition that asserts that certain steps must be taken if they are continuously allowed. The Next action is typically a disjunct of multiple subactions the define different ways for the system’s state to be updated. These (sub)actions can be grouped into modules. Each module can be instantiated multiple times for different sets of variables. III. R ELATED WORK","Payment Channel Networks are a second layer on top of a blockchain that processes transactions without writing each transaction to the blockchain. The security model for payment channels requires that honest parties cannot loose their funds even if all other users behave adversarially. To avoid financial loss caused by design flaws in a payment channel protocol, it should be verified that the protocol is secure. In this paper, we analyze the security of the protocol of the Lightning Network, a payment channel network for Bitcoin. To concretize, we formalize an ideal functionality of a","90,80"
366,Scalable Testing of Context-Dependent Policies over Stateful Data Planes with Armstrong.txt,"Network operators today spend significant manual effort in ensuring and
checking that the network meets their intended policies. While recent work in
network verification has made giant strides to reduce this effort, they focus
on simple reachability properties and cannot handle context-dependent policies
(e.g., how many connections has a host spawned) that operators realize using
stateful network functions (NFs). Together, these introduce new expressiveness
and scalability challenges that fall outside the scope of existing network
verification mechanisms. To address these challenges, we present Armstrong, a
system that enables operators to test if network with stateful data plane
elements correctly implements a given context-dependent policy. Our design
makes three key contributions to address expressiveness and scalability: (1) An
abstract I/O unit for modeling network I/O that encodes policy-relevant context
information; (2) A practical representation of complex NFs via an ensemble of
finite state machines abstraction; and (3) A scalable application of symbolic
execution to tackle state space explosion. We demonstrate that Armstrong is
several orders of magnitude faster than existing mechanisms.","Network policy enforcement has been and continues to be a challenging and errorprone task. For instance, a re cent operator survey found that 35% of networks gener ate100 problem tickets per month and onefourth of these take multiple engineerhours to resolve [18]. In this respect, recent efforts on network testing and veriﬁcation (e.g., [26,42,43,44]) offer a promising alternative to existing expensive and manual debugging efforts. Despite these advances, there are fundamental gaps be tween the intent of network operators and the capabilities of these tools on two fronts: (1) data plane elements are com plex and stateful (e.g., a TCP connection state in a stateful ﬁrewall) and (2) actual policies are context dependent ; e.g., compositional requirements to ensure trafﬁc is “chained” through services [20, 22] or dynamically triggered based on observed host behavior [21]. Together, stateful data planes and contextdependent poli cies introduce new challenges that fall outside the scope of existing network checking mechanisms [42, 43, 44, 63]. To understand why, it is useful to revisit their conceptual basis. Essentially, they capture network behavior by modeling each Operator(Armstrong)data(plane(test)packets)proxy(Impl.(high1level)policies))(e.g.,)host)1)traﬃc:)proxy!monitor)) switch((Impl.(monitor(Impl.(switch((Impl.(data(plane(model(proxy(model(monitor(model(switch(model(switch(model(Figure 1: Armstrong takes in highlevel policy intent from the network operator and generates test cases to check the implementation of the policy. network function1(NF) (e.g., a switch) as a “transfer” func tionT(h;port )that takes in a located packet (a header h and a portport) and outputs another located packet.2Then, some search algorithm (e.g., model checking or geometric analysis) is used to reason about the composition of these Tfunctions. Speciﬁcally, we identify three key limitations with respect to expressiveness andscalability (§2): Packets are cumbersome and insufﬁcient: While lo cated packets allow us to compose models of NFs, they are inefﬁcient to capture higherlayer processing seman tics (e.g., proxy at HTTP level). Further, in the presence of dynamic middlebox actions [36], located packets lack the necessary context information w.r.t. a packet’s pro cessing history and provenance, which are critical to rea son about policies beyond reachability. Transfer functions lack state and context: The trans fer abstraction misses key stateful semantics; e.g., reﬂex ive ACLs in a stateful ﬁrewall or a NAT using consistent publicprivate IP mappings. Moreover, the output actions of NFs have richer semantics (e.g., alerts) beyond a lo cated packet that determine the policyrelevant context. Search complexity: Exploring data plane behavior is hard even for reachability properties [42, 44, 63]. With stateful behaviors and richer policies, exploration is even more intractable and existing statespace search algo rithms (e.g., model checking) can take several tens of hours even on small networks with 5 stateful NFs. To address these challenges, we present a network testing framework called Armstrong (Figure 1). We adopt active data plane testing to complement static veriﬁcation [26, 52, 63], because it gives concrete assurances about the behavior “onthewire” [63]. Armstrong takes in highlevel network 1A network function may be stateless (i.e., switches/routers) or stateful (i.e., middleboxes) and can be physical or virtual. 2For concreteness, we borrow terminology from HSA [43]; other efforts share similar ideas at their core [42, 44, 46, 52]. 1arXiv:1505.03356v2  [cs.NI]  9 Jun 2015policies from the operator, generates and injects test trafﬁc into the data plane, and then reports if the observed behav ior matches the policy intent. Note that Armstrong is not (and does not mandate) a speciﬁc policy enforcement sys tem [9, 49, 53]; rather it helps operators to check if the in tended policy is implemented correctly. Armstrong’s design makes three key contributions to ad dress the expressiveness and scalability challenges: ADU I/O abstraction (§5): We propose a new Arm strong Data Unit (ADU) as a common denominator of trafﬁc processing for network models. To improve scala bility an ADU represents an aggregate sequence of pack ets; e.g., a HTTP response ADU coalesces tens of raw IP packets. Furthermore, an ADU explicitly includes the necessary packet processing context; e.g., an ADU that induced an alarm carries this information going forward. FSMsensemble model for NFs (§6): One might be tempted to use a NF’s code or a ﬁnitestate machine (FSM) model as a NF’s model, as they can capture state ful behaviors. However, these are intractable due to the huge number of states and transitions (or code paths). To ensure a tractable representation, we model complex NFs as an ensemble of FSMs by decoupling logically indepen dent tasks (e.g., clientside vs. serverside connection in a NF) and units of trafﬁc (e.g., different TCP connections). Optimized symbolic execution workﬂow (§7): For scalable test generation, we decouple it into two stages: (1) abstract test plan generation at the ADU granularity using symbolic execution (SE) because of its wellknown scalability properties [30, 31] and (2) a translation stage to convert abstract plans into concrete test trafﬁc. We engineer domainspeciﬁc optimizations (e.g., reduce the number and scope of symbolic variables) to improve the scalability of SE in our domain. We have written models for several canonical NFs in C and implement our domainspeciﬁc SE optimizations on top ofKLEE . We prototype Armstrong as an application over OpenDayLight [13]. We implement simple monitoring and test validation mechanisms to localize the NF inducing policy violations (§9). Our evaluation (§10) on a real testbed reveals that Armstrong: (1) can test hundreds of policy sce narios on networks with hundreds of switches and stateful NFs nodes within two minutes; (2) dramatically improves test scalability, providing nearly ﬁve orders of magnitude re duction in time for test trafﬁc generation relative to straw man solutions (e.g., using packets as NFs models I/O, or us ing model checking for search); (3) is more expressive and scalable than the state of the art; (4) effectively localizes in tentional data/control plane bugs within tens of seconds. 2 Motivation In this section, we use small but realistic network scenarios to highlight the types of stateful NFs andcontextdependent policies used by network operators. We also highlight key limitations of existing network test/veriﬁcation efforts. To S1#Is#ﬁrewall#allowing#solicited#and#blocking#unsolicited#Internet#traﬃc?#Internet#Department# Stateful#FW#Intended&Policy&traﬃc#from#Internet#to#Department#Stateful#FW#Allow#unsolicited#TCP#solicited#TCP##Actual&Network&Block#Figure 2: Is the ﬁrewall allowing solicited and blocking unsolicited trafﬁc from the Internet? Internet&Department&S1&Mon&S2& Proxy& Are&both&hit/miss&traﬃc&monitored&correctly?&Intended&Policy&web&traﬃc&from&Department&proxy&Block&Allow&XYZ.com&hit/miss&resp.&to&H2&otherwise&&Actual&Network&Monitor& Figure 3: Are both hit/miss trafﬁc monitored correctly? make the discussion concrete, we use the transfer function and located packet abstraction from HSA [43]/ATPG [63], where each network NF (e.g., a switch) is a “transfer” func tionT(h;p)whose input is a located packet (a header, port tuple) and outputs another located packet.3The behavior of the network is the composition of such functions; i.e., Tn(:::(T2(T1(h;p)))). Our goal here is not to show the limitations of these speciﬁc efforts, but to highlight why the following scenarios fall outside the scope of this class of ver iﬁcation techniques (e.g., [42, 44, 47]). 2.1 Stateful ﬁrewalling While simple ﬁrewalls and OpenFlow ACLs have a simple matchaction operation, real ﬁrewalls capture TCP session semantics. A common use is reﬂexive ACLs [4] shown in Figure 2, where the intent is to only allow incoming pack ets for established TCP connections that have been initiated from “internal” hosts. We depict the intended policy shown as a simple policy graph shown on the top. Unfortunately, even this simple policy cannot be captured by a stateless transfer function T(h;p). In particular, the T behavior depends on the current state of the ﬁrewall for a given connection, and the function needs to update the rel evant internal state variable. A natural extension is a ﬁnite state machine (FSM) abstraction where T(h;p;s)takes in a located packet and the current state, outputs a located packet, and updates the state. In this case, the state is persession, but more generally it can span multiple sessions [39]. 2.2 Dynamic policy violations Next, let us consider Figure 3, where the operator uses a proxy for better performance and also wants to restrict web access; e.g., H2cannot access to XYZ.com. As observed elsewhere [36], there are subtle violations that could oc cur if a cached response bypasses the monitoring device. Prior work has suggested many candidate ﬁxes; e.g., bet ter NF placement, tunnels, or new extended SDN APIs [36]. Our focus here is to check whether such policy enforcement mechanisms implement the policy correctly rather than de 3For brevity, we assume no multicast/broadcast effects. 2S1#Reachability/Isola2on# H2#H1#S2# Remote##server#Department#NAT#Enterprise#NAT#S3#Stateful#FW#Are#we#correctly#ﬁrewalling#based#on#host?#Intended&Policy&traﬃc#from#hosts#H1#or#H2#Block#Allow#H1#accessing#server#otherwise##Actual&Network&Dept.#NAT#Ent.#NAT#Stateful#FW#Figure 4: Are we ﬁrewalling correctly based on host? veloping new enforcement mechanisms. As before, we need to model the stateful behavior of the proxy across connections, so let us consider our extended function T(h;p;s). However, modeling the state alone is not sufﬁcient. Speciﬁcally, the policy violations happen for cached responses, but this context (i.e., cached or not in this example) depends on some internal state variable inside the Tproxy function. To faithfully capture the policy intent of the operator in our network model, we need to expose such relevant trafﬁc’s processing history in our model. This sug gests that we need to further extend the functions to include context as input T(h;p;s;c)because the correct network behavior (e.g., downstream switches and middleboxes in our model) depends on this context. We formalized this deﬁni tions in §3. This example also highlights several other issues. First, different NFs operate at different layers of the network stack; e.g., the monitoring device may operate at L3/L4 but the proxy in terms of HTTP sessions, which makes the “atomic” granularity at which their policyrelevant states/ contexts manifest different. While it may be tempting to choose different granularities of trafﬁc for different NFs, it means that we may no longer compose our Tfunctions if their inputs are different. Second, the policyrelevant con text depends on a sequence of packets rather than on an in dividual packet. While it is not incorrect to think of Tfunc tions operating on packets, it is not an efﬁcient abstraction. Finally, note that just using headers is not sufﬁcient as the behavior of the proxy depends on the actual content. 2.3 Firewalling with cascaded NATs Figure 4 depicts a scenario inspired by prior work that showed cascaded NATs are errorprone [28, 50]. Note that a correct NAT should use a consistent publicprivate IP map ping for a session [59]. To model such network behaviors, we need to both capture the packet provenance (i.e., where it originated from) and the consistent mapping semantics. Unfortunately, existing tools such as HSA/ATPG essen tially model stateful NFs as “black box” functions and do not capture or preserve the ﬂow consistent mapping prop erties. This has two natural implications for our extended transfer function T(h;p;s;c): (1) the context cshould also include the packet provenance, and (2) the function Tmust be expressive enough to capture stateful NFs semantics (e.g., sessionconsistent mappings). S1#S2#Light#IPS#Heavy#IPS#Internet#Are#suspicious#traﬃc#sent#to#heavy#IPS?#Department# Intended&Policy&traﬃc#from#Department#Light#IPS#Block#Allow#bad#conn.##aEempts#>=#10#otherwise##Actual&Network&Heavy#IPS#bad#signature#found#Figure 5: Is suspicious trafﬁc sent to heavy IPS? 2.4 Multistage triggers So far our examples underlined the need for capturing state ful semantics and relevant context inside a transfer function. We end this discussion with a dynamic service chaining ex ample in Figure 5 that combines both effects. The intended policy is to use the lightweight IPS (LIPS) in the common case (i.e., for all trafﬁc) and only subject suspicious hosts ﬂagged by the LIPS (e.g., when a host generates too many scans) to the more expensive HIPS (e.g., for payload signa ture matching). Such multistage detection is useful; e.g., to minimize latency and/or reduce the HIPS load. Such scenarios are implemented today (albeit typically by hard coding the policy into the topology) and enabled by novel SDNbased dynamic control mechanisms [9, 23]. Unfortu nately, we cannot check that this multistage operation works correctly using existing reachability mechanisms [43,63] be cause they ignore the IPSes states (e.g., the current perhost count of bad connections inside the LIPS) and trafﬁc con text related to the sequence of intended actions. Finally, note that the above examples have natural impli cations for a search strategy to explore the data plane be havior. Prior exhaustive search strategies were possible only because a transfer function processes each “header” inde pendently and had no state. Thus they only had to search over the “header space”. Note that this is already hard and requires clever algorithms [63] and/or parallel solvers [64]. Designing a search strategy for the examples above is fun damentally more challenging because we need to consider a bigger “trafﬁc” space (i.e., sequences of packets with pay loads) and we need to efﬁciently explore a state space since processing of a packet by an NF (e.g., a stateful ﬁrewall) can change the behavior of the data plane for future packets. 2.5 Key observations We summarize key expressiveness and scalability challenges that fall outside the scope of existing network veriﬁcation abstractions and search strategies: NFs are stateful (e.g., §2.1) and have complex semantics beyond simple header matchaction operations, and ab stracting them as blackboxes is insufﬁcient (e.g., §2.3); NF actions are triggered on sequences of packets and oc cur at different logical aggregations (e.g., §2.2); The correct behavior depends on trafﬁc context such as provenance and processing history (e.g., §2.2 and §2.3); 3Thespace of possible outcomes in the presence of state ful data planes operating over richer semantics (e.g., pay load) and contextdependent policies can be very large (e.g., §2.4). 3 Problem Formulation In this section, we deﬁne the semantics of a stateful data plane using which we formalize a test trace to test the in tended policies in a data plane. We then use these deﬁnitions to motivate the need for a modelbased testing approach. 3.1 Data Plane Semantics In this subsection we formalize the semantics of stateful data planes and contextdependent policies. This formaliza tion serves two purposes: (1) an understanding of the data plane semantics, where actual trafﬁc is processed, provides insight into the methodology of generating test trafﬁc; in particular, as we will see in this section, this formalization motivates the need for modeling the data plane to bridge the gap between a highlevel policy and its manifestation in the data plane; (2) it serves as a reference point for the fu ture research in the area of stateful data planes and context dependent policies4. DPF: Since test trafﬁc operates on the data plane level, in this subsection we deﬁne the data plane semantics. First, we deﬁne the semantics of a NF and the network. Let Pdenote the set of packets.5Formally, a NF is a 4tuple (S;I;E;) where: (i) Sis a ﬁnite set of states; (ii) I2Sis the initial state; (iii) Eis the set of network edges; and (iv) :SP7! SP Eis the transition relation. Here, is a set of effects that capture the response of a NF to a packet. Each 2provides contextual in formation that the administrator cares about. Each is annotated with the speciﬁc NF generating the effect and its relevant states; e.g., in Figure 5 we can have 1= hLIPS :H1;Alarm;SendToHIPSiwhen the LIPS raises an alarm and redirects trafﬁc from H1to the HIPS, and 2=hLIPS :H1;OK;SendToInternetiwhen the LIPS decides that the trafﬁc from H1was OK to send to the In ternet. Using effects, administrators can deﬁne high level policy intents rather than worry about lowlevel NF states. Note that this NF deﬁnition is general and it encompasses stateful NFs from the previous section and stateless L2L3 devices. Network: Formally, a network data plane netis a pair (N;)where N=fNF1;:::;NF Ngis a set of NFs and  is the topology map. Informally, if (e) =NFithen pack ets sent out on edge eare received by NFi.6We assume that the graph has welldeﬁned sources (with no incoming 4Previous work has modeled network semantics without focusing on stateful data planes and contextdependent policies (e.g., [49, 58]) 5Packets are “located” [43,55], so that the NF can identify and use the incoming network interface information in its processing logic. 6We assume each edge is mapped to unique incoming/outgoing physical network ports on two different NFs.edges), and one more sinks (with no outgoing edges). The data plane state ofnetis a tuple= (s1;:::; sN), wheresi is a state ofNFi. Processing semantics: To simplify the semantics of packet processing, we assume packets are processed in a lockstep (i.e., onepacketperNFattime) fashion and do not model (a) batching or queuing effects inside the network (hence no reordering and packet loss); (b) parallel processing effects inside NFs; and (c) the simultaneous processing of different packets across NFs. Let = ( s1;:::; si;:::; sN)and0= (s1;:::; s0 i;:::; sN)be two states of net. First, we deﬁne a singlehop network state transition from (;i;)to(0;i0;0)labeled by effect , denoted (;i;)","Network policy enforcement has been and continues to be a challenging and error-prone task. Recent efforts on network testing and verification (e.g., [26,42,43,44]) offer a promising alternative to existing expensive and manual debugging efforts. However, there are fundamental gaps between the intent of network operators and the capabilities of existing network checking mechanisms. Specifically, we identify three key limitations with respect to expressiveness and scalability (2): Packets are cumbersome and insufficient: While located packets, they miss key stateful semantics (e.","80,70"
365,Learning an Ensemble of Deep Fingerprint Representations.txt,"Deep neural networks (DNNs) have shown incredible promise in learning
fixed-length representations from fingerprints. Since the representation
learning is often focused on capturing specific prior knowledge (e.g.,
minutiae), there is no universal representation that comprehensively
encapsulates all the discriminatory information available in a fingerprint.
While learning an ensemble of representations can mitigate this problem, two
critical challenges need to be addressed: (i) How to extract multiple diverse
representations from the same fingerprint image? and (ii) How to optimally
exploit these representations during the matching process? In this work, we
train multiple instances of DeepPrint (a state-of-the-art DNN-based fingerprint
encoder) on different transformations of the input image to generate an
ensemble of fingerprint embeddings. We also propose a feature fusion technique
that distills these multiple representations into a single embedding, which
faithfully captures the diversity present in the ensemble without increasing
the computational complexity. The proposed approach has been comprehensively
evaluated on five databases containing rolled, plain, and latent fingerprints
(NIST SD4, NIST SD14, NIST SD27, NIST SD302, and FVC2004 DB2A) and
statistically significant improvements in accuracy have been consistently
demonstrated across a range of verification as well as closed- and open-set
identification settings. The proposed approach serves as a wrapper capable of
improving the accuracy of any DNN-based recognition system.","The choice of data representation plays a critical role in determining the success of a machine learning model because different representations can highlight and/or sup press different factors of variation underlying the data [1]. In ﬁngerprint recognition, domainspeciﬁc prior knowledge has played the dominant role in determining the represen tation scheme, leading to mostly handdesigned features. Since the late 19thcentury [2], it was wellknown that minutiae are important for identifying ﬁngerprints accu rately. Hence, minutiaebased ﬁngerprint representations have become the defacto standard [3] as shown in Figure 1. Figure 1: Sample ﬁngerprint images, their ISO/IEC repre sentations (minutiae points) [3], and heatmap visualizations of 192dimensional deep neural network representation [4] from ﬁve databases: NIST SD4, NIST SD14, NIST SD302 (N2N), NIST SD27 and FVC 2004 DB2A. However, in challenging scenarios such as matching latent ﬁngerprints (see middle column of row 4 in Figure 1), using only minutiaebased representation is clearly inadequate. With the advent of deep learning and its tremendous suc cess in various applications including consumer sentiment analysis [5, 6], biometric recognition [7], natural language processing (NLP) [8], healthcare, and ﬁnance [9], the con cept of datadriven representation learning has come to the fore. It is possible to learn multiple representations fromarXiv:2209.02425v1  [cs.CV]  2 Sep 2022Figure 2: An overview of the DeepPrint architecture [4]. STN stands for Spatial Transformer Network. the same data by applying different priors, which are usu ally determined by the architecture (and depth) of the neural network, groundtruth labels that guide/supervise the learn ing, and the objective/loss function. It is wellknown that no single prior can perfectly disentangle all the underlying variations in data and lead to a universally good representa tion. Consequently, the idea of ensemble learning [10, 11], which refers to learning multiple models/representations (as opposed to using a single representation) has been used to improve the diversity of the feature space. This approach has been successfully employed in many computer vision tasks to boost performance compared to a single model [12]. In the ﬁeld of biometrics, many studies have been con ducted over a wide range of modalities (face, ﬁngerprint, gait, lip, etc.) using different implementations of ensem ble learning [13, 14, 15, 16, 17, 18, 19]. While some of these methods may not ﬁt into the traditional deﬁnition of ensemble learning, they can be considered to be a part of this family since they involve some form of fusion of out puts obtained from different entities. There are two key challenges involved in implementing any ensemble learning approach: (i) generation of multiple representations from the same input that are sufﬁciently discriminative as well as diverse, and (ii) efﬁcient fusion of these representations during the inference process. Typically, the ﬁrst problem is solved by learning multiple representations based on dif ferent augmentations of the training data, different network architectures, or different data partitions [20]. The latter is sue is addressed through a range of early (featurelevel) and late (score or decisionlevel) fusion techniques [21]. In this work, our objective is to improve the perfor mance of a stateoftheart (SOTA) deep neural network based ﬁngerprint recognition model called DeepPrint (DP) [4] through ensemble learning. The core advantage of the DP model is its ability to learn a compact ﬁngerprint repre sentation using a combination of domain knowledge (minu tiae features) and datadriven (texture patterns) supervision techniques. Figure 2 presents an overview of the DP ar chitecture and the third column of Figure 1 shows heatmapvisualizations of the DP representation. Despite its strong ability to extract discriminative information from ﬁnger print images, the performance of DP models still fall short of commercialofftheshelf (COTS) ﬁngerprint recognition systems (which use both minutiae and other proprietary fea tures) in challenging scenarios. We posit that this is primar ily due to the reliance on a single representation, which fails to capture all useful information. To overcome this limita tion, we make the following contributions in this work: • Generating an ensemble of ﬁve ﬁngerprint representa tions from a single image using the DeepPrint architec ture. This is achieved by augmenting the original train ing data with four types of image manipulations (two generic and two domainspeciﬁc transformations). • Evaluation of the DeepPrintbased ensemble of ﬁn gerprint embeddings using decision and score fusion schemes on ﬁve ﬁngerprint databases  NIST SD4, NIST SD14, FVC 2004 DB2A, NIST SD27, and NIST SD302 (N2N) [23, 24, 25, 26, 27]. While this approach improves accuracy, it comes at the cost of increased computational complexity (and lower throughput). • Training a single DeepPrint model on unperturbed im ages, which is capable of learning the diversity present in the ensemble of ﬁngerprint representations. This distilled model can be considered as a feature fusion strategy that learns a single embedding through exter nal supervision at the feature level from the component representations in the ensemble. • Comprehensive experiments in the veriﬁcation and identiﬁcation (both closed and openset) modes to demonstrate that the proposed feature fusion approach can consistently improve the accuracy without compro mising on retrieval or feature extraction times . 2. Related Work","Deep neural network based fingerprint recognition has achieved tremendous success in various applications. However, the choice of data representation plays a critical role in determining the success of a machine learning model because different representations can highlight and/or support different factors of variation underlying the data. In this work, we propose a state-of-the-art (SOTA) deep neural network based fingerprint recognition model called DeepPrint (DP) that can learn an ensemble of five fingerprint representations from a single image. The DP architecture is based on a combination of domain knowledge (minu","85,70"
361,LFSR based RNG on low cost FPGA for QKD applications.txt,"Linear-feedback shift register (LFSR) based pseudo-random number generator
(PRNG) has applications in a plethora of fields. The issue of being linear is
generally circumvented by introducing non-linearities as per the required
applications, with some being adhoc but fulfilling the purpose while others
with a theoretical proof. The goal of this study is to develop a sufficiently
``random"" resource for Quantum Key Distribution (QKD) applications with a low
computational cost. However, as a byproduct, we have also studied the effect of
introducing minimum non-linearity with experimental verification. Starting from
the numerical implementation to generate a random sequence, we have implemented
a XOR of two LFSR sequences on a low-cost FPGA evaluation board with one of the
direct use cases in QKD protocols. Such rigorously tested random numbers could
also be used like artificial neural networks or testing of circuits for
integrated chips and directly for encryption for wireless technologies.","In any digital encryption scheme, random numbers are an indispensable resource, as proposed by Claude Shan non [1]. The applications of random numbers are strati fied from cryptography to simulations and the gambling industry. For cryptographic applications, in an ideal world, one would like to use quantum random number generators (QRNGs), which are innately random. How ever, pertaining to the resource intensiveness, the real time use case for QRNGs is a little far. The next best alternatives available are pseudo random number gener ators (PRNGs) and chaotic random number generators. Chaotic ones cannot be used for security applications pri marily because Eve can exploit the fact that there is no good way of characterising noise. Amongst PRNGs, one of the earliest, extremely fast and easy to generate known techniques for generating random numbers is using lin ear feedback shift registers (LFSRs). Being hardware friendly, they are used in testing for power consumption in integrated circuits. In particular, it is typically used to create test patterns for builtin selftest [2]. On the low power front, LFSR based Random Number genera tors (LRNGs) are widely used in providing encryption to wireless technology such as Bluetooth, where they are used to encrypt frequency hopping spread spectrum sys tems to protect against signal jamming kind of attacks [3]. Such random number generators are easily imple mentable on hardware like Field Programmable Gate Ar ray (FPGA) [4] and, thus, could provide an easy access to “randomness” resources for ongoing applications like Quantum Key Distribution (QKD). Succinctly, QKD is ∗pooja@prl.res.in †vardaan@prl.res.in ‡shaship@prl.res.inthe study of securely distributing keys between two com municating parties (say, Alice and Bob) using proper ties of photons (quanta of light). The field is proposed to takeover the current encryption technique (particu larly, ubiquitously used RivestShamirAdleman (RSA) algorithm) for the latter being inefficient against upcom ing quantum computers. The premise being that laws of quantum physics are more fundamental compared to in creasingly accessible computational resources (built on fundamentals of physics) against an eavesdropper [5]. The major application for LRNG in QKD applications comes into the picture for prepareandmeasure (P&M) protocols. Pertaining to the particular property of pho tons being used, there are different P&M based QKD protocols such as those proposed by Bennet and Bras sard in 1984 (BB84) and coherent oneway protocol. In the context of BB84 protocol, Alice selects the polariza tion degree of freedom as her encoding mechanism. To achieve an unbiased distribution of signals across the four polarization states, Alice requires a random bit stream based on LFSR. It generates random numbers that Al ice utilizes for preparing the four polarization states in a randomized manner, ensuring equal probability and im partiality among the different polarization states. This requirement is a prerequisite for unconditional security of any P&M based QKD protocol. In addition to being used at Alice’s end, Bob could also use LRNG sequence to choose the measurement basis by feeding this random bit stream into a liquid crystal polarisation rotator. This requirement at Bob’s end is true for every QKD protocol (not restraining to P&M protocols). This, however, is not a strict requirement as there are other alternatives with certain tradeoffs. Hence, we focus on a stronger requirement of “randomness” resource at Alice’s end. In this work, we aim to obtain a LRNG bit stream, which is implementable on low cost, low powered FPGA boards suitable for BB84 protocol. It is varied for differ ent parameters, say input seed value and postprocessedarXiv:2307.16431v1  [quantph]  31 Jul 20232 so that it is sufficiently random for QKD applications. The paper is divided into four further sections. Section II discusses preliminaries such as why such random num bers are a good candidate for QKD applications, how it works, and what classifies as a sufficiently random bit stream. In section III, we first discuss our numer ical approach followed by hardware implementation of LFSR based random numbers, where we elaborate on how the randomness gets affected by introducing non linearities. Towards the end, we show one practical ap plication where we have used this in practical BB84 setup for preparing polarisation states randomly. In Section IV, we list possible improvements that are hardware and ap plication dependent. In section V, we conclude the article by summarizing this study. II. METHODOLOGY","Quantum Key Distribution (QKD) is the study of securely distributing keys between two parties (say, Alice and Bob) using properties of photons (quanta of light). The major application for LRNG in QKD comes into the picture for prepare-and-measure (P&M) protocols. In this work, we aim to obtain a LRNG bit stream, which is implementable on low cost, low powered FPGA boards suitable for BB84 protocol. The bit stream is varied for differing parameters, say input seed value and post-processed","85,85"
223,Formal Verification of the Ethereum 2.0 Beacon Chain.txt,"We report our experience in the formal verification of the reference
implementation of the Beacon Chain. The Beacon Chain is the backbone component
of the new Proof-of-Stake Ethereum 2.0 network: it is in charge of tracking
information about the validators, their stakes, their attestations (votes) and
if some validators are found to be dishonest, to slash them (they lose some of
their stakes). The Beacon Chain is mission-critical and any bug in it could
compromise the whole network. The Beacon Chain reference implementation
developed by the Ethereum Foundation is written in Python, and provides a
detailed operational description of the state machine each Beacon Chain's
network participant (node) must implement. We have formally specified and
verified the absence of runtime errors in (a large and critical part of) the
Beacon Chain reference implementation using the verification-friendly language
Dafny. During the course of this work, we have uncovered several issues,
proposed verified fixes. We have also synthesised functional correctness
specifications that enable us to provide guarantees beyond runtime errors. Our
software artefact is available at https://github.com/ConsenSys/eth2.0-dafny.","The Ethereum network is gradually transitioning to a more secure, scalable and energy ecient ProofofStake (PoS) consensus protocol , known as Ethereum 2.0 and based o GasperFFG [2]. The ProofofStake discipline ensures that participants who propose (and vote) for blocks are chosen with a frequency that is proportional to their stakes. Another major feature of Ethereum 2.0 is sharding which enables to split the main blockchain into a number of independent and hopefully smaller and faster chains. The transition from the current Ethereum 1 to the nal version of Ethereum 2.0 (Serenity) is planned over a number of years and will be rolled out in a number of phases. The rst phase, Phase 0, is known as the Beacon Chain. It is the backbone component of Ethereum 2.0 as it coordinates the whole network of stakers and shards. The Beacon Chain. The Beacon Chain (and its underlying protocol) is in charge of en forcing consensus, among the nodes participating in the network, on the state of the system. The participants are called validators and their main role is to propose and vote for new (Beacon) blocks to be appended to the blockchain. The set of validators is dynamic: new validators can register by staking some ETH (Ethereum cryptocurrency). Once registered, validators are eligible to participate and propose and vote for new blocks (of transactions) to be appended to the blockchain. The Beacon Chain shipped on December 1, 2020. At the time of writing (October 14, 2021), close to 250 ;000 validators have staked 7 ;780;000 ETH ($30 Billion USD). Considering the coordination role and the amount of assets managed by the Beacon Chain, it is a missioncritical component of the Ethereum 2.0 ecosystem, and ?This work was partially supported by the Ethereum Foundation, grant FY20285, Q42020arXiv:2110.12909v1  [cs.PL]  22 Oct 2021any bug in it could badly impact the network. At the same time, the operational description of the Beacon Chain in the reference implementation is rather complex and provided in a Pythonlike language. It is the reference for any Beacon Chain client implementer. As a re sult, inaccuracies, ambiguities, or bugs in the reference implementation will lead to erroneous and/or buggy clients that can compromise the integrity, or the performance of the network. Our Contribution. The Beacon Chain reference implementation , developed by the Ethe reum Foundation, is written in Python, and provides a detailed operational description of the state machine each Beacon Chain's network participant (node) must implement. We have formally specied and veried the absence of runtime errors in (a large and critical part of) the Beacon Chain reference implementation using the vericationfriendly language Dafny. During the course of this work, we have uncovered several issues, proposed veried xes, some of which have been integrated in the reference implementation. We have also synthesised functional correctness specications that enable us to provide guarantees beyond runtime errors. Our software artefact with the code and proofs in Dafny is freely available at https://github.com/ConsenSys/eth2.0dafny . Related Work. The Ethereum Foundation has supported several projects related to ap plying formal methods for the analysis of the Beacon Chain (and other components). A foundational project3was undertaken in 2019 by Runtime Verication Inc. and provided a formal and executable semantics in the K framework, to the reference implementation [1]. The semantics was validated and the reference implementation could be tested which resulted in a rst set of recommendations and xes to the reference implementation. Runtime Verication Inc. have also formally specied and veried (in Coq [11]) the underlying GasperFFG [2] protocol. Our work complements these formal verication projects. Indeed, our objective is to provide guarantees for the absence of bugs (runtime errors), and loop termination which goes beyond testing. We have chosen to use a vericationfriendly programming language, Dafny [10], as it enables us to write the code in a more developerfriendly manner (com pared to K). However, we have used the code bases from the previous projects to guide us (e.g., semantics) during the course of this project. 2 The Beacon Chain Reference Implementation In this section we introduce the system we want to formally verify, what are the potential benets and impacts of such of study, and we set out the goals of our experiment. 2.1 Scope of the Study As a robust decentralised system, the Beacon Chain aims to implement a replicated state machine [9] that is faulttolerant to a fraction of unreliable (e.g., they can crash) partici pants. The replicated state machine is implemented with a number of networked identical state machines running concurrently. This provides redundancy and a more reliable system. The state of each machine changes on an occurrence of an event . As the machines operate asynchronously, two dierent machines may receive dierent events that cannot be totally ordered timewise. This is why before processing an event and changing their states, the state machines run a consensus protocol to decide which event they should all process next. The 3https://github.com/runtimeverication/beaconchainspec 2consensus protocol aims to guarantee (under certain conditions) that an agreement will be reached which ensures that events are processed in the same order on each machine. In this project, we are not interested in the verication of the consensus protocol, but rather in the verication of the state machine that is replicated. 2.2 The Beacon Chain Reference Implementation The Beacon Chain (Phase 0) reference implementation [6] describes the state machine that every Beacon node (participant) has to implement. The idea is that anyone is allowed to be a participant in the decentralised Ethereum 2.0 ecosystem when it is fully deployed. However, as the consensus protocol is ProofofStake there must be a mechanism for participants to register and stake, to slash a participant's stake if they are caught4misbehaving, i.e., not following the consensus protocol, and to reward them if they are honest. The Beacon Chain provides these mechanisms. It maintains records about the participants, called validators , ensuring fairness (each honest participant should have a voting power, for new blocks, related to its stake), and safety (a dishonest participant may be slashed and lose part of their stakes). The full Beacon Chain (Phase 0) reference implementation [6] comprises three main sec tions: 1.theBeacon Chain State Transition for the Beacon state machine is the most complex component; 2.The Simple SerialiZe (SSZ) library for how to encode/decode (serialise/dese rialise) data that have to be communicated over the network between nodes; 3.theMerkleise library for how to build ecient encoding of data structures into Merkle trees, and how to use them to verify Merkle proofs; The State Transition. The Beacon Chain state transition part is the most critical part and at the operational level the complexity stems from: {time is logically divided into epochs , and each epoch into a xed number of slots; the state is updated at each slot; {at the beginning of each epoch, disjoint subsets of validators are assigned to each slot to participate in the block proposal for the slot and attest (vote) for links in the chain; {the state updates that apply at an epoch boundary are more complex than the other updates; {the actual state of the chain is a blocktree i.e., a tree of blocks, and the canonical chain is dened as a particular branch in this tree . How this branch is determined is dened by thefork choice rule . {thefork choice rule relies on properties of nodes in the blocktree, namely, justication and nalisation . The state update describes how nodes in the blocktree are deemed justied/nalised. The rules for justication and nalisation are introduced in a separate document, the GasperFFG [2] protocol. The SSZ and Merkleise Libraries. These components are selfcontained and indepen dent from the state transition. We used them as a feasibility study and we had veried them before this project started. We have provided a complete Dafny reference implementation for them in the merkle andsszpackages [3]. 4In a distributed system with potentially dishonest participants, it is not always possible to detect who is dishonest (byzantine). However, sometimes a participant can sometimes be proved to be dishonest. 32.3 Motivation for Formal Verication As mentioned previously, the Beacon Chain shipped on December 1, 2020 and up to date, 250;000 validators have staked 7 ;780;000 ETH ( $30 Billion USD). It is clear that any bug, or logical error, could have disastrous consequences resulting is losses of assets, or downtimes which means losses of rewards for the validators. There are regular opportunities (forks) to update the code of Beacon Chain nodes. So continuously running projects like ours is very valuable as what is important is to nd and x bugs before attackers can exploit them. The operational description of the Beacon Chain in the reference implementation is provided in a Pythonlike language. It was written by several reference implementation writers at the Ethereum Foundation and due to its size it is hard for one person to have a complete picture of it. It is the reference for any Beacon Chain client implementer. Moreover the reference implementation uses a defensive mechanism against unexpected errors: [S1]\State transitions that trigger an unhandled exception (e.g. a failed assert or an outofrange list access) are considered invalid. State transitions that cause a uint64 over ow or under ow are also considered invalid."" However this creates a risk that errors unrelated to the logic of the state transition func tion may introduce spurious exceptions. At the time of writing, there are at least 4 dierent Ethereum 2.0 client softwares that are used by validators. Bugs in the reference implementa tion may be handled dierently in the various clients, and in some cases lead to a split in the network5. The correctness of the consensus mechanism is guaranteed for up to 1 =3 of mali cious nodes that are nodes deviating from the reference implementation, be it intentionally or unintentionally (e.g., because of a bug in the code). Hence, we should try to make sure we reduce (buggy) unintentional malicious nodes. 2.4 Objectives of the Study Our goal is to improve the overall safety, readability and usability of the reference implemen tation. The primary aspect of our project was to make sure that the code was free of runtime errors (e.g., over/under ows, arrayoutofbounds, divisionbyzero, . . . ). This provides more condence that when an exception occurs and a state is left unchanged as per [S1], the root cause is a genuine problem related to the state transition having been given an illformed block: if state_transition(state,signed_block) triggers an exception, it should imply that there is a problem with the signed_block not that some intermediate computations re sulted in runtime errors. A secondary goal was to try and synthesise functional specications from the reference implementation. This can help developers to design tests, and contributes to the specications being languageagnostic. For instance, it can help write a client in a functional language which results in a more inclusive ecosystem. 3 Formal Specication and Verication In this section we present the challenges of the project, motivate our methodology and con clude with our results' breakdown. 5A network split can be caused if some clients reject a chain that is being followed by the other clients, which leads to a hard forklike situation. 43.1 Challenges The main challenges in this formal verication project are in the verication of the code of thestate_transition component of the Beacon Chain. The SSZ and Merkleise libraries are much smaller, simpler, and independent components that can be dealt with separately. The reference implementation for the Beacon Chain [6] introduces data types and algo rithms that should be interpreted as Python 3 code. As a result it may not be straightforward for those who are not familiar with Python to understand the meaning of some parts of the code. More importantly, the reference implementation is not executable and may contain type mismatches, incompatible function signatures, and bugs that can result in runtime errors like underover ows or arrayoutofbounds. A typical function in the reference implementation is written as a sequence of control blocks (including function calls) intertwined with checks in the form of assert statements. The state_transition function (Listing A.1) is the component that computes the update of the Beacon Chain's state. The state (of type BeaconState ) records some information including the validators' stakes, the subsets of validators ( committees ) allocated to a given slot, and the hashes6of the blocks that have already been added to the chain. A state update is triggered when a (signed) block is added to Beacon Chain. The state machine implicitly dened by the reference implementation generates sequences of states of the form: s0b0","The Beacon Chain is the backbone component of Ethereum 2.0. It is responsible for enforcing consensus among the nodes participating in the network. The Beacon Chain is the reference implementation for any Beacon Chain client implementer. The reference implementation is written in Python and provides a detailed operational description of the state machine each Beacon Chain participant (node) must implement. As a result, inaccuracies, ambiguities, or bugs in the reference implementation will lead to erroneous and/buggy clients that could compromise the integrity, or performance of","70,80"
420,Neural Network Verification with Proof Production.txt,"Deep neural networks (DNNs) are increasingly being employed in
safety-critical systems, and there is an urgent need to guarantee their
correctness. Consequently, the verification community has devised multiple
techniques and tools for verifying DNNs. When DNN verifiers discover an input
that triggers an error, that is easy to confirm; but when they report that no
error exists, there is no way to ensure that the verification tool itself is
not flawed. As multiple errors have already been observed in DNN verification
tools, this calls the applicability of DNN verification into question. In this
work, we present a novel mechanism for enhancing Simplex-based DNN verifiers
with proof production capabilities: the generation of an easy-to-check witness
of unsatisfiability, which attests to the absence of errors. Our proof
production is based on an efficient adaptation of the well-known Farkas' lemma,
combined with mechanisms for handling piecewise-linear functions and numerical
precision errors. As a proof of concept, we implemented our technique on top of
the Marabou DNN verifier. Our evaluation on a safety-critical system for
airborne collision avoidance shows that proof production succeeds in almost all
cases and requires only minimal overhead.","Machine learning techniques, and speciﬁcally deep neural networks (DNNs), have been achieving groundbreaking re sults in solving computationally difﬁcult problems. Nowadays, DNNs are stateoftheart tools for performing many safety critical tasks in the domains of healthcare [29], aviation [44] and autonomous driving [19]. DNN training is performed by adjusting the parameters of a DNN to mimic a highly complex function over a large set of inputoutput examples (the training set) in an automated way that is mostly opaque to humans. The Achilles heel of DNNs typically lies in generalizing their predictions from the ﬁnite training set to an inﬁnite input domain. First, DNNs tend to produce unexpected results on inputs that are considerably different from those in the training set; and second, the input to the DNN might be perturbed by sensorial imperfections, or even by a malicious adversary, again resulting in unexpected and erroneous results. These weaknesses have already been observed in many modern DNNs [37], [63], and have even been demonstrated in the real world [30] — thus hindering the adoption of DNNs in safetycritical settings. In order to bridge this gap, in recent years, the formal methods community has started devising techniques for DNN veriﬁcation (e.g., [2], [11], [13], [31], [32], [40], [41], [52], [57], [60], [61], [65], [67], [72], among many others). Typi cally, DNN veriﬁcation tools seek to prove that outputs from a given set of inputs are contained within a safe subspace of the output space, using various methods such as SMT solving [1], [16], [23], abstract interpretation [32], MILP solving [64], andcombinations thereof. Notably, many modern approaches [49], [52], [54], [64] involve a search procedure, in which the veriﬁcation problem is regarded as a set of constraints. Then, various input assignments to the DNN are considered in order to discover a counterexample that satisﬁes these constraints, or to prove that no such counterexample exists. Veriﬁcation tools are known to be as prone to errors as any other program [43], [71]. Moreover, the search procedures applied as part of DNN veriﬁcation typically involve the repeated manipulation of a large number of ﬂoatingpoint equations; this can lead to rounding errors and numerical stability issues, which in turn could potentially compromise the veriﬁer’s soundness [12], [43]. When the veriﬁer discovers a counterexample, this issue is perhaps less crucial, as the counterexample can be checked by evaluating the DNN; but when the veriﬁer determines that no counterexample exists, this conclusion is typically not accompanied by a witness of its correctness. In this work, we present a novel proofproduction mech anism for a broad family of searchbased DNN veriﬁcation algorithms. Whenever the search procedure returns UNSAT (indicating that no counterexample exists), our mechanism produces a proof certiﬁcate that can be readily checked using simple, external checkers. The proof certiﬁcate is produced using a constructive version of Farkas’ lemma, which guaran tees the existence of a witness to the unsatisﬁability of a set of linear equations — combined with additional constructs to support the nonlinear components of a DNN, i.e., its piecewiselinear activation functions. We show how to instru ment the veriﬁcation algorithm in order to keep track of its search steps, and use that information to construct the proof with only a small overhead. For evaluation purposes, we implemented our proof production technique on top of the Marabou DNN veriﬁer [49]. We then evaluated our technique on the ACAS Xu set of benchmarks for airborne collision avoidance [45], [47]. Our approach was able to produce proof certiﬁcates for the safety of various ACAS Xu properties with reasonable overhead (5:7%on average). Checking the proof certiﬁcates produced by our approach was usually considerably faster than dispatch ing the original veriﬁcation query. The main contribution of our paper is in proposing a proofproduction mechanism for searchbased DNN veriﬁers, which can substantially increase their reliability when de termining unsatisﬁability. However, it also lays a foundation for a conﬂictdriven clause learning (CDCL) [73] veriﬁcation scheme for DNNs, which might signiﬁcantly improve the performance of searchbased procedures (see discussion inarXiv:2206.00512v2  [cs.LO]  27 Aug 2022Sec. IX). The rest of this paper is organized as follows. In Sec. II we provide relevant background on DNNs, formal veriﬁcation, the Simplex algorithm, and on using Simplex for searchbased DNN veriﬁcation. In Sec. III, IV and V, we describe the proof production mechanism for Simplex and its extension to DNN veriﬁcation. Next, in Sec. VI, we brieﬂy discuss complexity theoretical aspects of the proof production. Sec. VII details our implementation of the technique and its evaluation. We then discuss related work in Sec. VIII and conclude with Sec. IX. II. B ACKGROUND Deep Neural Networks. Deep neural networks (DNNs) [36] are directed graphs, whose nodes (neurons) are organized into layers. Nodes in the ﬁrst layer, called the input layer , are assigned values based on the input to the DNN; and then the values of nodes in each of the subsequent layers are computed as functions of the values assigned to neurons in the preceding layer. More speciﬁcally, each node value is computed by ﬁrst applying an afﬁne transformation to the values from the preceding layer and then applying a nonlinear activation function to the result. The ﬁnal (output) layer, which corresponds to the output of the network, is computed without applying an activation function. One of the most common activation functions is the rectiﬁed linear unit (ReLU), which is deﬁned as: f(b) =ReLU (b) =( b b> 0 0otherwise. Whenb >0, we say that the ReLU is in the active phase; otherwise, we say it is in the inactive phase. For simplicity, we restrict our attention here to ReLUs, although our approach could be applied to other piecewiselinear functions (such as max pooling ,absolute value ,sign, etc.). Non piecewiselinear functions, such as as sigmoid ortanh, are left for future work. Formally, a DNNN:Rm!Rk, is a sequence of nlayers L0;:::;L n","Deep neural networks (DNNs) have been used to solve a wide range of computationally challenging problems, including safety critical tasks in aviation, healthcare, and autonomous driving. However, the Achilles heel of DNNs lies in generalizing their predictions from the finite training set to an infinite input domain. In this work, we propose a novel proof production mechanism for a broad family of search-based DNN verifiers. Whenever the search procedure returns UNSAT (indicating that no counterexample exists), our mechanism produces a proof certificate that can be easily checked using simple,","90,80"
244,"Kirigami, the Verifiable Art of Network Cutting.txt","We introduce a modular verification approach to network control plane
verification, where we cut a network into smaller fragments to improve the
scalability of SMT solving. Users provide an annotated cut which describes how
to generate these fragments from the monolithic network, and we verify each
fragment independently, using the annotations to define assumptions and
guarantees over fragments akin to assume-guarantee reasoning. We prove this
modular network verification procedure is sound and complete with respect to
verification over the monolithic network. We implement this procedure as
Kirigami, an extension of NV - a network verification language and tool - and
evaluate it on industrial topologies with synthesized policies. We observe a
2-8x improvement in end-to-end NV verification time, with SMT solve time
improving by up to 6 orders of magnitude.","Networks have become incredibly vast and labyrinthine systems. To determine the best paths routers may use to forward trafﬁc, networks typically run distributed routing protocols. Despite advances like softwaredeﬁned networking, these protocols remain widely used. They are controlled by millions of lines of decentralized, lowlevel router conﬁguration code. Operators must individually provision, maintain and reconﬁgure the network’s devices over time. This overwhelmingly complexity has led to many notable outages [42,47,49], with at times devastating pecuniary losses. More often than not, the culprits behind these incidents are subtle network misconﬁgurations. In response, researchers have developed a variety of veriﬁcation tools and tech niques to catch errors before outages occur. Some [4,31,33–35,39,41,44] have targeted the network data plane , which is responsible for forwarding trafﬁc from point A to point B. This work has produced scalable and performant methods for modeling the data plane and checking properties of how packets traverse it. The data plane is produced by the network’s control plane , which uses the afore mentioned routing protocols to decide which routes to use. Occasionally, these proto cols may update their choice of routes — e.g., following a device failure — and recom pute new paths. When this happens, the data plane is regenerated, and the user must 1arXiv:2202.06098v1  [cs.NI]  12 Feb 20222 repeat any data plane analysis. Obscure control plane faults can lead to further issues, and manual veriﬁcation by a human operator is an effort in locating what may be a minuscule typo within a gargantuan morass of router conﬁgurations. To address this problem, researchers have developed another suite of tools to an alyze the control plane [1, 6–8, 14, 16, 19, 21, 23, 50]. Control plane analyses consider what routes will be used by the data plane in given network environments, and check properties of the network in such environments. These tools can uncover bugs in real networks, but unfortunately tend not to scale as well as their data plane counterparts. One branch of control plane veriﬁcation, starting from Minesweeper [6], encodes a network as a Satisﬁability Modulo Theories (SMT) formula and then asks an SMT solver [5] to check properties of the encoded network. While SMTbased veriﬁcation has advantages over other approaches, such as its expressivity or applications in au tomated network repair [18], it nonetheless suffers from scalability issues. Prior work has explored using abstractions to resolve this problem, e.g., using symmetries in net work topologies to compress networks [7,21]. These abstractions offer some relief, but cannot always handle arbitrary nonsymmetrical networks. This paper offers another path forward in scaling SMTbased control plane veriﬁ cation, by being the ﬁrst to leverage the inherent modularity of the control plane to cut a monolithic network into multiple fragments to be veriﬁed independently. Building on prior work on assumeguarantee veriﬁcation of modular programs [20,30], we present a novel technique for modular veriﬁcation of control planes and implement it as Kirigami, an extension to the NV [23] network veriﬁcation language and tool. In a typical assumeguarantee veriﬁcation approach, one can verify a safety property Pover a system of concurrent processes, by verifying each process independently, using assumptions over the environment in which it runs and guarantees over how it modiﬁes this environment. The relationships between assumptions and guarantees (formulated as assumeguarantee rules) are then checked, which allows one to conclude that if all checks pass, then Pholds for the monolithic system. Our veriﬁcation technique mirrors this idea: we verify a property over fragments ( cf.processes) of the control plane, given assumptions over the rest of the network and guarantees over our fragments, to conclude that the monolithic network respects the property. We start from an existing general model for distributed routing, the Stable Routing Problem (SRP) model [7]. In an SRP, each node of the network exchanges routes with its neighbors to compute a locallystable solution. Like other work in control plane veriﬁcation [1, 8, 19, 40], we focus on networks ( i.e.,SRPs) with unique solutions. We develop an SRP extension called “open SRPs”, in which a network receives routes along a set of input nodes and sends out routes along a different set of output nodes . We identify the solutions of our input nodes as our open SRP’s assumptions, and the solutions of our output nodes as its guarantees. We present a procedure C UTwhich, given an interface — a mapping from a cutset of edges to routes — cuts an open SRP Sinto two smaller open SRPs T1andT2covering S, and where each cut edge is replaced by a route assumed in one SRP and guaranteed in the other. Interfaces can follow a network’s natural boundaries, e.g., a data center network interface might be cut according to its levels or hierarchy [2, 28, 29].3 As with the traditional (closed) SRP, we can check that an open SRP satisﬁes a given safety property Pby verifying that Pholds for the SRP’s solutions. We prove that if Pholds on T1andT2’s solutions, then it holds on S’s. This is the basis for our modular network veriﬁcation technique. Starting from a network S, an interface I, and a safety property P, we use C UT(S;I)to obtain a set of Nopen SRPs T1;:::; TNthat are veriﬁed independently. We verify PandTi’s guarantees for each open SRP Ti: if either the property or interface’s guarantees do not hold, we return a counterexample demonstrating the solution that does not satisfy PorI. We believe this to be the ﬁrst work to present a provencorrect general theory for automated modular veriﬁcation of arbitrary properties, and where we check the correctness of the given interface: prior work on modular network veriﬁcation like [31] considered speciﬁc architectures and properties without any guarantee of correctness. As SMTbased veriﬁcation time typically grows superlinearly with the size of the network [6], by verifying Pon each of the Nsmaller open SRPs Ti, we can verify Pin a fraction of the time it takes to do so directly over the monolithic network S. Our experiments demonstrate that this modular veriﬁcation technique works well for a variety of data center, random and backbone networks, with signiﬁcant improvements in SMT solve time: we show for one set of fattree [2] benchmarks that verifying the fattree podbypod cuts SMT time from 90 minutes to under 2 seconds; verifying every node individually reduces SMT time to around a hundredth of a second. Overall, while we are working on improving the engineering in NV for carving out partitions, we already see a 2–8x speedup in endtoend NV veriﬁcation time. We also observe that a modular approach assists in producing more localized errors and debugging feedback in the cases when veriﬁcation fails. In summary, we make the following contributions: A Theory of Network Fragments We develop an extension of the Stable Routing Prob lem (SRP) model [7] for network fragments. Our extension provides a method to cut monolithic SRPs into a set of fragments. We deﬁne interfaces to cut SRPs and map the cut edges to annotations which then deﬁne assumptions andguarantees of our fragments. We prove that under these assumptions, if these guarantees hold, then a property that holds in every fragment also holds in the monolithic network. A Modular Network Veriﬁcation Technique We present a technique to decompose a monolithic network veriﬁcation problem into multiple subproblems. We start from an SRP S, an interface Iand a property P, and cut Sinto a set of fragments. We check each fragment’s guarantees and the given Pindependently and report whether Pholds for S, or if PorIfail to hold. This enables a novel, modular approach to control plane veriﬁcation based on assumeguarantee reasoning. Fast, Scalable and Modular SMT Veriﬁcation We implement Kirigami, a tool based on this theory, as an extension for NV, a network veriﬁcation language and tool [23]. Using Kirigami, we improve on NV veriﬁcation in terms of scalability and perfor mance. SMT solve time using Kirigami is up to six orders of magnitude faster for a selection of NV benchmarks.4 pod 0 pod 1 pod 2 pod 3spines e0a0 e1a1 e2a2 e3a3 e4a4 e5a5 e6a6 da7c0c1c2c3 (a) A fattree topology.1type attribute = int 2let nodes = 20 (* topology *) 3let edges = { 4 0=4; 0=6; 0=8; 0=10;(*...*) 5 10=18; 10=19; 11=18; 11=19; 6} 7 8let merge node x y = ifx < y then xelse y 9let trans edge x = x + 1 10let init node = ifnode = 19n then 0else NULL (b) An NV program fat.nv representing Figure 1a. 1include ""fat.nv"" 2 3(* map each node to its solution (stable route) *) 4let sol = solution { init = init; trans = trans; merge = merge; } 5(* check a property [route <= 4] of every node 's solution *) 6assert foldNodes ( fun node route acc > acc && route <= 4) sol true (c) An NV program asserting that every node can reach 19nin at most 4 hops. Fig. 1: A fattree network Sand its representation in NV. Node d(19nin NV)1propagates an initial route to itself to the rest of the network. 2 Overview The Stable Routing Problem. A network is a graph with nodes Vrepresenting routers and edges Erepresenting the links between them. A distributed control plane uses rout ing protocols to determine paths to routing destinations. Each router deploys its own local rules to broadcast routing announcements (or routes ) and select a “best” route: the form of these rules varies with the protocol, but generally protocols focus on minimiz ing routing costs. These elements — nodes and edges, a set of routes, and a set of rules to initialize, compare and broadcast them — form the basis for our control plane routing model, the SRP [7]. In a welldesigned network, this exchange of routes eventually converges to a stable state , where no node may improve on its current best route by selecting another offered by a neighbor. A mapping from nodes to these stable routes is called a solution Lto the SRP. While it is possible for routing to diverge ( i.e.,have no solution) or converge to multiple solutions, many typical networks have unique solutions ( e.g., when routing costs strictly increase with distance to the destination [19,40]): we restrict our focus in this paper to such networks, like other work [1, 8, 19, 40]. 1NV numbers nodes starting from 0n: our example numbers Figure 1a from left to right, i.e.,0n isc0,4nisa0,12nise0and so on. “ 0=4” refers to a bidirectional edge between 0nand4n.5 An Example SRP. Let’s consider an SRP instance Sof a familiar fattree [2] data cen ter network, as shown in Figure 1a. Routing in fattree networks typically follows a L shape: trafﬁc that starts from an edge switch ( e0;:::; e6;d) travels up along a link to an aggregation switch ( a0;:::; a7), then ascends from the pod to a core switch ( c0;:::; c3) in the spine before descending back down into another pod. For this example, our routes will simply be the number of hops to some routing destination d. Initially dwill know a route with 0 hops to itself; the rest of the network starts with no route to d. Each node broadcasts its route to dto all of its neighbors, incrementing the route by one hop. Nodes will then compare each received route with their current choice and select the one with the fewest hops. The unique solution LS(u)of a node uinSis thus the best route between u’s initial route and the transferred solutions of each of u’s neigh bors. This toy policy elides the complexities of real routing protocols, which may have dozens of ﬁelds, each with particular semantics, but demonstrates all the basic elements of an SRP. Verifying SRPs with NV [23]. We can verify properties of S’s solution to conﬁrm our beliefs about S’s behavior. For instance, we may wish to check that every node’s route todis at most 4 hops. One veriﬁcation tool we can use to do so is NV [23]. NV is a functional programming language for modeling control planes with an associated SMT veriﬁcation engine. An NV program’s components map onto those of an SRP: it has a topology ( nodes andedges ); a type of routes ( attribute ); a function init to initialize routes; a function trans to broadcast routes; and ﬁnally a function merge to compare routes. Figure 1b presents a condensed NV program for Figure 1a. Figure 1c demonstrates how to verify a safety property Pin NV, where Pholds iff8u:L(u)4. We deﬁne the solution (line 4) using init ,trans andmerge from Figure 1b. We then assert (line 6) that Pis true of this solution. When we supply Fig ure 1c to NV’s veriﬁcation engine, NV encodes SandPas an SMT query, and conﬁrms thatPholds for LS. Encoding the network to SMT lets us reason about network states symbolically, avoiding state explosion when analyzing properties like fault tolerance or reasoning about routes arriving from outside the network. Scaling Up SRP Veriﬁcation. SMTbased veriﬁcation is expressive, but has issues when it comes to scalability. Our evaluation in §7 shows that SMT veriﬁcation scales superlinearly for larger fattrees with more complex policies: from 0.03 seconds for a 20node network, to 1.41 seconds for an 80node network, and 1833.66 seconds for a 320node network! To verify the tens of thousands of switches in industrial fattree networks [31], we must ﬁnd a way to scale this technique. Suppose then that we took a large network and cut it into fragments (deﬁned for mally in §4), in order to verify a safety property Pon each fragment independently. In other words, if Pholds for every node in every fragment, then it holds for every node in the monolithic network; and otherwise, we want to observe real counterexam ples as in the monolithic network. To achieve this goal, our cutting procedure must also summarize the network behavior external to each fragment. We incorporate these summaries into the traditional SRP model by generalizing it to open SRPs. Open SRPs extend the SRP model by designating some nodes as input nodes and some others as output nodes . Input and output nodes are annotated with routes representing solutions assumed on the inputs and guaranteed on the outputs. We6 e0a0 e1a1c0c1c2c32 2 2 2 (a) SRP fragment Tp0 a0a1 a2a3 a4a5 a6a7c0c1c2c3 3 3 1 1 3 3 3 3 (b) SRP fragment Tspines Fig. 2: SRP fragments Tp0andTspines , with input nodes in blue, output nodes in yellow and assumptions written in red. express these annotations using an interface : a mapping from each cut edge to a route annotation. Given an open SRP Sand an interface I, we cut Sinto open SRP fragments, where each fragment identiﬁes assumptions on its inputs and guarantees on its outputs. Cutting Down Fattrees. We will now move on to demonstrating this idea for Figure 1. Let’s cut each pod of our network into its own fragment Tp0through Tp3, leaving the spine nodes as a ﬁfth fragment Tspines . Figures 2a and 2b show pod 0 and the spines of Figure 1 as open SRPs Tp0andTspines , respectively. In Tp0, we assume routes from the spines and check guarantees on a0anda1. An assumption in one fragment will be guaranteed by another (and viceversa): we assume a0has a route of 3 hops in Tspines and check that it has a route of 3 hops in Tp0. Verifying Network Fragments. In modular veriﬁcation, we perform an independent veriﬁcation query for each fragment: we encode the open SRP and property, along with an assumptions formula assuming a state of the inputs and a guarantees formula to check on the state of the outputs. We then submit every query to our solver and ask if the network has a solution where, under the given assumptions, either the property is false (as before) or the guarantees formula does not hold. Our solver then searches for a counterexample demonstrating a concrete violation of the property or our guarantees. Guarantee violations provide evidence of possible bugs in our network implementation or mistakes in our beliefs, in the same way that property violations do. Let us consider our fattree network again. Suppose we misconﬁgured a6to black hole (silently drop) trafﬁc, leading nodes a0,a2anda4to reroute via the other nodes a1;a3;a5in their respective pods. Our interface maps c0a0to 2, so we check that Lspines(c0) =2 when verifying Tspines . Due to our bug, this check fails and our solver returns a counterexample: because c0must reroute, Lspines(c0) =6. We can then modify our network conﬁguration to ﬁx the bug, and rerun veriﬁcation to conﬁrm that our guar antees and property hold for all fragments. We prove in §4 that this implies that Pholds for the monolithic network. Our guarantees can thus be thought of as a speciﬁcation of the desired network behavior along its cut points, in addition to P. Veriﬁable Network Cutting with Kirigami. As part of our work, we implemented an extension Kirigami to NV for cutting and verifying networks. Figure 3 shows an NV ﬁle with two new functions, partition andinterface .partition assigns each node to a fragment, while interface adds assertions that check that a route xalong a cross fragment edge is equal to the speciﬁed annotation, e.g., that the route from 0nto4nis 27 1include ""fat.nv"" 2 3let partition node = match node with 4 | 0n | 1n | 2n | 3n > 0 (* spines *)(*...*) 5 | 10n | 11n | 18n | 19n > 4 (* p3 *) 6 7let interface edge x = match edge with 8 | 0~_ | 1~_ | 2~_ | 3~_ > x = 2 9 | 4~_ | 5~_ | 6~_ | 7~_ | 8~_ | 9~_ > x = 3 10 | 10~_ | 11~_ > x = 1 11 12let sol = solution { init = init; trans = trans; merge = merge; interface = interface } 13assert foldNodes ( fun node route acc > acc && route <= 4) sol true Fig. 3: An NV program which cuts Figure 1 into pods (some node and edge cases not shown). hops. Under the hood, we cut the network using partition to generate our fragments, and then annotate the cuts using interface ; veriﬁcation can then proceed as described. A Cut Above the Rest. Podbased cuts suit our highlevel understanding of fattrees, but we can consider many other cuts. We could cut Figure 1 so that every node is in its own fragment. Verifying a single node in SMT is extremely cheap, and hence leads to signiﬁcant performance improvements. The corresponding NV program resembles Figure 3, except every node maps to its own fragment and we annotate every edge. Next Steps. The rest of the paper proceeds as follows. §3 presents prior work formal izing SRPs, and §4 presents our extensions for cutting SRPs, with proofs of soundness and completeness of our procedure. We present our SMT checking procedure in §5, and the implementation of our theory in §6 as Kirigami, an extension of NV. We evaluate Kirigami in §7. We discuss related work in §8, and future work in §9. 3 Background on the Stable Routing Problem We summarize prior work [7] on the Stable Routing Problem (SRP) network model. Many components of this model resemble routing algebras used for reasoning about convergence of routing protocols [11,26,48], but SRPs also include a network topology for reasoning about properties such as reachability between nodes. An SRP instance Sis a 6tuple (V;E;R;init;;trans), deﬁned as follows. Topology. Vis a set of nodes and EVVis a set of directed edges between them. We write uvfor an edge from node uto node v. Edges may not be selfloops: 8v2V:vv=2E. Routes. Ris a set of routes that describe the ﬁelds of routing messages. For example, when modeling BGP, Rmight represent a tuple of an integer local preference, a set of community tags, and a sequence of AS numbers representing the AS path [9, 46].8 a b cd e (a) An open SRP S a b cd e (b) An open SRP T a bd e (c) An open SRP U Fig. 4: A series of successive cuts which produce open SRPs S,TandU. Base nodes are shown in grey, input nodes in blue and output nodes in yellow. Cuts between input and noninput nodes are shown in red. Node Initialization. The initialization function init:V!Rdescribes the initial route of each node. When modeling single destination routing, initmay map a destination node dto some initial route rd, and all other nodes to a null route; in multiple destination routing, we may have many initial routes. Route Update. The merge function :RR!Rdeﬁnes how to compare and merge routes.represents updates of a node’s selected route: we assume is associative and commutative, i.e.,the order in which a sequence of routes are merged does not matter. Route Transfer. The transfer function trans :ER!Rdescribes how routes are modi ﬁed between nodes. Given an edge uvand a route rfrom node u,trans(uv;r)determines the route received at v. Solutions. A solution L:V!Ris a mapping from nodes to routes. Intuitively, a solu tion is deﬁned such that each node is locally stable ,i.e.,it has no incentive to deviate from its currently chosen neighbors. Nodes compute their solution via message ex change, where each node in the SRP advertises its chosen route to each of its neighbors. Formally, an SRP solution Lsatisﬁes the constraint: L(v) =init(v)M uv2Etrans(uv;L(u)) (1) whereLis the sequence ofoperations on each transferred route trans(uv;L(u))from each neighbor uofv. These received routes are merged with v’s initial value init(v). A solution may determine an SRP’s forwarding behavior or another decisionmaking procedure, as shown in [7]. We omit discussing forwarding behavior in this work to fo cus on a general SRP deﬁnition without restricting ourselves only to forwarding. 4 Cutting SRPs We now introduce our original contributions, starting with open SRPs . We deﬁne a frag ment relation between a smaller open SRP and a larger one, and deﬁne a C UTprocedure to decompose one open SRP into a partition of two fragments. We prove soundness and completeness of partition solutions with respect to the larger SRP’s solution. Notation. We introduce some notation in this section that may be unfamiliar. dom(f) is the domain of the function f, and fjXis the restriction offtoXdom(f). We use subscripts to specify SRP components, e.g., initSrefers to SRP S’sinitcomponent.9 Open SRPs. Anopen SRP generalizes our earlier SRP deﬁnition to include assumptions andguarantees . An open SRP instance Sis an 8tuple (V;E;R;init;;trans ;ass;guar). The ﬁrst six elements are deﬁned exactly as for regular (closed) SRPs. The ﬁnal two elements, ass(“assumptions”) and guar (“guarantees”), are partial functions (V,!R) mapping mutually disjoints subsets Vin;VoutVto routes. We use Vin(input nodes) as a shorthand for dom(ass)andVout(output nodes) as a shorthand for dom(guar). All nodes that are neither input nor output nodes are “ base nodes ”Vbase. A closed SRP is an open SRP where Vin=Vout=?. Going forward, we assume an open SRP whenever we write “SRP”, except when the distinction is relevant. Input nodes must be source nodes (indegree =0). Hence, they act as auxiliary nodes, indicating where a ﬁxed incoming route “arrives” from outside the SRP, as spec iﬁed by the assumptions ass. Output nodes correspondingly mark where routes “de part” the SRP, per the guarantees guar. We do not require any connectivity properties of output nodes: we think of them as simply identifying an outgoing route we wish to guarantee, but without requiring the SRP to tell us whither it is announcing that route.2 Figure 4 illustrates this concept with some example open SRPs and cuts. Deﬁnition 1 (Open SRPs). Anopen SRP instance S= (V;E;R;init;;trans ;ass;guar) respects the following properties: –V=Vin[Vout[Vbaseand Vin;Vout;Vbaseare pairwisedisjoint; –ass:Vin!R and guar :Vout!R; and –8v2Vin:indegree (v) =0. Open SRP Solutions. A mapping Lis asolution to an open SRP iff: L(u) =init(u)M vu2Etrans(vu;L(v))8v=2Vin(2) L(u) =ass(u) 8v2Vin(3) L(u) =guar(u) 8v2Vout(4) Note that Equations (2) and (4) both apply for all outputs v2Vout. Solutions for open SRPs resemble closed SRP solutions, with the addition of constraints based on the values of assand guar. For any input node u, its assumption ass(u)determines the node’s solution directly; for an output node u, its solution L(u)must be consistent with both the righthand side of (2) and the righthand side of (4). Hence, if 9u2 Vout:init(u)L vu2Etrans(vu;L(v))6=guar(u), there is no solution to the open SRP. As with closed SRPs, we restrict our focus to open SRPs with unique solutions. Fragments. We now introduce a fragment relation between two open SRPs. We may think of an open SRP as composed of fragments of smaller open SRPs, where each fragment represents its connection to the rest of the larger SRP with assumptions and guarantees. Consider the series of open SRPs in Figure 4. One can think of T(Figure 4b) as a fragment representing part of S(Figure 4a). To go from StoT, we can cut eoff from 2This is partly a design choice: we could have also attached auxiliary nodes to output nodes to indicate where these routes are going, but we found this deﬁnition the most straightforward.10 Sto obtain a network with new input nodes which summarize the rest of the network with assumptions. One can fragment Tfurther by cutting off bfrom the remaining nodes: this produces an even smaller fragment U(Figure 4c). Deﬁnition 2 (Fragments). Let S and T be open SRPs. T is a fragment of S when: VTVS ET=fuvju2VT;v2VT;uv2ES;v=2Vin Tg (5) RT=RST=S (6) initT=initSjVT trans T=trans SjET (7) Vin T= (Vin S[fvjuv2ES;u=2VTg)\VT (8) Vout T= (Vout SnVin T[fujuv2ES;v=2VTg)\VT (9) 8u2(Vin T\Vin S):assT(u) =assS(u) (10) 8u2(Vout T\Vout S):guarT(u) =guarS(u) (11) Informally, the fragment Tis made up of a subgraph of Sover nodes VT, conserv ing all edges from ESbetween them, except any edges into input nodes (5). Routing and routing functions of Sare as before (6) or restricted over T’s topology (7). Fi nally, Tdesignates nodes whose neighbors have been cut as inputs (8) (summarizing the network “outside” T) or outputs (9) (communicating a summary to the “external” network), while preserving any assumptions (10) and guarantees (11) inherited from S. Interfaces and Cutting SRPs. The fragment relation leaves unspeciﬁed how a smaller SRP’s assumptions and guarantees summarize its parent’s routes. We now consider how to cut an SRP Sinto two fragments T1andT2, where T1andT2cover Sand replicate its behavior with the help of their assumptions and guarantees. We do so by selecting a cutset CEof edges in Sand annotating each cut edge uvwith a route that describes the solution transferred from utov. We call this annotated cutset an interface I . Deﬁnition 3 (Interface). Let S be an SRP and let C E be a cutset partitioning V S. I:C!RSis an interface if it maps every element uv of C to a route I (uv)in R S. We now deﬁne a C UTprocedure. Given an SRP Sand an interface I, CUT(S;I) returns a partition of two SRP fragments, T1andT2. Nodes along the cut edges are annotated with assumptions and guarantees. We can recursively C UTan SRP into arbi trarily many fragments. We elide the structural details of how C UTdivides the nodes of Sbetween T1andT2for now: curious readers should see Appendix A. What is most important about C UTis that it deﬁnes T1andT2to have equal assump tions and guarantees along each cut edge. For each edge uvin our interface I, CUT(S;I) adds a guarantee guar(u) =I(uv)inT1and an assumption ass(u) =I(uv)inT2(or vice versa). By requiring this equality, we rely on the stability of an open SRP’s solution to avoid the issue of circularity in assumptions. The edge uvnow shows a route I(uv)“ar riving” in T2after “departing” from T1. Asu’s solution is both assumed in one fragment and guaranteed in the other, we refer to it as an inputoutput node . We illustrate this idea in Figure 5, which shows how an interface deﬁnes assumptions and guarantees for inputoutput nodes c0anda0from Figure 2.11 a0c0 guar(c0) =2 ass(a0) =3Tspines a0c0 ass(c0) =2 guar(a0) =3Tp0 a0c0 I(c0a0) =2 I(a0c0) =3S Fig. 5: A closeup of how C UTdeﬁnes inputoutput nodes c0anda0from I. Deﬁnition 4 (Inputoutput nodes). Let T 1and T 2be two open SRPs with a set (Vin 1\ Vout 2)[(Vin 2\Vout 1)of shared nodes. A node u in this set is an inputoutput node iff ass1(u) =guar2(u)orass2(u) =guar1(u). Because C UTproduces inputoutput nodes, we can reason over the solutions of both fragments separately, using the assumptions and guarantees of our inputoutput nodes to conﬁrm that the solutions coincide along our cut. We can now deﬁne a partition as a relation between T1andT2andS. Deﬁnition 5 (Partition). Let S, T 1and T 2be open SRPs. (T1;T2)is apartition of S when (i)T1and T 2are both fragments of S, (ii)V1[V2=VSand E 1[E2=ES,(iii)every input node in T 1or T 2that is not an input node in S is an inputoutput node. We present the full deﬁnition of a partition — which includes some corner cases for when two fragments share the same input node — in Appendix A: these details are not required to understand our theorems. We prove that our C UTprocedure always produces a partition, and subsequently prove that if T1andT2are a partition of S, then the joined solutions of T1andT2are a solution of S(soundness); and that if Shas a solution, then there always exists an interface Ithat given to C UTproduces a partition of two fragments T1andT2such that the solution of Sis a solution (when appropriately restricted) for T1andT2(completeness). Deﬁnition 6 (C UT).Let S be an SRP and let I be an interface over S. Given S and I, CUT(S;I) = ( T1;T2), where T 1and T 2are a partition of S such that8uv2dom(I), u is an inputoutput node between T 1and T 2. Correctness. We now prove theorems on the relationships between an SRP’s solution and the solutions of its C UTproduced fragments. By showing that the fragments’ so lutions are the same as the monolithic SRP’s, we can use the fragments in place of the monolithic SRP during veriﬁcation of a property P. Proofs can be found in Appendix A. We start by proving that the solutions of the fragments T1;T2are a solution to the monolithic SRP S: each node of Sis mapped to its fragment solution, with S’s input nodes mapping to their expected assumptions. Theorem 1 (C UTis Sound). Let S be an open SRP , and let I be an interface over S. Let CUT(S;I) = ( T1;T2). Suppose T 1has a unique solution L1and T 2has a unique solution L2. Consider a mapping LS0:VS!R, deﬁned such that: 8v2V1:LS0(v) =L1(v) 8v2V2:LS0(v) =L2(v) 8v2Vin S:LS0(v) =assS(v)12 ThenLS0is a solution of S. We can also always ﬁnd a suitable interface Ito cut S, such that T1andT2have the same solution as Sfor each node: we simply annotate each cut edge uvwith the solution LS(u), which would be the solution transferred from utovinS. Theorem 2 (C UTis Complete). Let S be an open SRP , and let I be an interface over S. Let CUT(S;I) = ( T1;T2). Assume S has a unique solution LS. Assume that8uv2 dom(I):I(uv) =LS(u). Consider the following two mappings L10:V1!R and L20: V2!R, deﬁned such that: 8v2V1:L10(v) =LS(v) 8v2V2:L20(v) =LS(v) ThenL10is a solution for T 1andL20is a solution for T 2. Finally, our proof of soundness implies that any property that holds over the solu tions of our fragments will hold over the solutions of our monolithic network. Corollary 1 (C UTPreserves Properties). Let S be an open SRP , and let I be an inter face over S. Let CUT(S;I) = ( T1;T2). Let P 1;P2be formulas such that P 1=8v2V1:Q(v) and P 2=8v2V2:Q(v), where Q is a predicate on L(v). Assume S has a unique solu tionLS, and that T 1has a solution L1and T 2has a solution LS. Then if P 1holds on T 1 and P 2holds on T 2, P1^P2holds on S. 5 Checking Fragments in SMT We now present our threestep modular veriﬁcation methodology: (i)given an SRP S and an interface I, produce Nfragments using C UT(S;I), as deﬁned in §4; then (ii)en code each fragment to SMT and check its guarantees and a safety property Punder the given assumptions; and (iii)if any guarantees fail, let the user reﬁne I or correct net work bugs. By our theoretical results, when our SMT solver veriﬁes Pfor these smaller fragments, we can conclude that it would have veriﬁed Pfor the monolithic SRP. Creating Interfaces. For now, we treat our interfaces as given, meaning they function similarly to userprovided annotations in an annotation checking tool such as Dafny [37]. Hence, our checking algorithm acts as an analogous tool to verify beliefs about the net work. In this sense, interfaces are userprovided speciﬁcations to the veriﬁer. Another way to create interfaces is to infer them: starting from a small amount of given information, say the initial route to a single destination, we could infer routes through the rest of the network. While we do not yet consider interface inference, we believe it is a fruitful direction for future work, and discuss doing so in §9. The Fragment Checking Algorithm. Algorithm 1 shows how we cut an SRP and check the three constraints on open SRP solutions (described in §4) on each of the fragments. We start in the C HECK procedure on line 1.6. C HECK calls C UT(S;I)to cut Sinto fragments, and then calls S OLVE (line 1.1) on each fragment, reporting any S AT result it receives back from the solver. S OLVE encodes (2) on line 1.2, (3) on line 1.313 Algorithm 1 The fragment checking algorithm. 1:proc SOLVE (fragment T, property P) 2: N ENCODE (T) .closed SRP LTconstraints (1) 3: A V u2Vin TLT(u) =assT(u) .assconstraints (3) 4: G V u2Vout TLT(u) =guar T(u) .guar constraints (4) 5: return ASKSAT(A^N^:(G^P)) 6:proc CHECK (SRP S, property P, interface I) 7: T1;:::; TN CUT(S;I) 8: fori 1;Ndo 9: r SOLVE (Ti;P) 10: ifr6=UNSAT then 11: return r 12: return UNSAT and (4) on line 1.4. Since we are interested in knowing if GorPare ever violated, our ﬁnal formula is the conjunction of E NCODE (T)andAwith the negation of G^P(line 1.5). A SKSATasks our solver if this formula is satisﬁable, and returns either S ATwith a model, or U NSAT . This model will be a quasisolution LTtoTwhere the E NCODE (T) andAconstraints hold, but 9u2Vout T:LT(u)6=guarT(u)(guarantee violation) or 9u2 VT::P(u)(property violation). Otherwise, if the solver returns U NSAT , then either S has no solution or the guarantees and property always hold. Reﬁning Interfaces. If every fragment returns U NSAT , by Corollary 1, we conclude that if there exists a solution to each fragment, then PandGhold and the interface is correct . On the other hand, if any fragment returns S AT, we must determine why our property or guarantees were violated. For example, in §2, we considered if our interface correctly captured the intended network behaviour, but a bug in the network policy led to a guarantee violation. If the reverse were true — the network was conﬁgured correctly, but our interface is incorrect — we must reﬁne our interface to correct it. By Theorem 1, we know that any incorrect interface will not deﬁne a solution in T1andT2, meaning our guarantee constraint in S OLVE fails and a counterexample is returned. This counterexample may then inform a new interface we can provide in a successive run of C HECK . Returning to our fattree fragments in Figure 2, suppose our interface provided the incorrect annotation I(a0c0) =1. This generates an unattainable guarantee guar0(a0) =1, meaning we can reach din one hop from a0. SOLVE (Tp0;P) returns S AT, providing L0(a0) =3 as a counterexample which violates this guarantee. We can then create a new interface with I(a0c0) =3 and rerun veriﬁcation: if no further annotations are incorrect, then S OLVE (Tp0;P)will report U NSAT . 6 Implementation Our Kirigami extension adds partition andinterface functions to the NV language: when a user runs NV on a ﬁle that declares these functions, NV cuts the SRP into a set of fragments as part of a partitioning step. Each fragment is generated as described by14 Deﬁnition 6 of C UT. Most of the partitioning step deals with restricting the monolithic initand trans functions. We create Ncopies of the initial NV ﬁle and traverse the AST of each to update any references to the topology. This implementation is currently not optimized and performs redundant work, which can be improved to reduce overhead when partitioning large policies. Beyond assigning nodes and edges to fragments using partition andinterface , Kirigami also decomposes the properties we wish to test. Many useful endtoend prop erties can be expressed as predicates over individual node solutions, including reach ability, path length, waypointing, black holes and fault tolerance [6]. These properties can be decomposed into separate assertions over the nodes of each fragment: if no frag ment reports a property violation, we can then conclude that the property holds for the monolithic network as well, as proven in Corollary 1. Kirigami’s SMT encoding follows Algorithm 1, using NV’s monolithic SRP encod ing as the encoding function E NCODE . As discussed above, the solver returns a S ATor UNSAT response for each fragment to the user. Any fragments that return S ATprovide a solution violating the guarantees or properties, allowing us to determine if the violation indicates a problem with our network policy or interface. 7 Evaluation We evaluated Kirigami on a variety of NV benchmarks representing fattree, random and Internet topologies.3Our questions focus on the scalability and performance of Kirigami in comparison to NV, speciﬁcally: (i)does Kirigami improve on NV veri ﬁcation time across topologies and properties, and (ii)how do different cuts impact Kirigami performance? We consider two metrics for veriﬁcation time: the maximum time reported to verify an SMT query encoding the monolithic network or fragment using the Z3 [12] SMT solver;4and the “total time” of NV, which is the time taken by NV’s pipeline of network transformations, partitioning (for cut networks), encoding to SMT and solving every query sequentially. We ran each benchmark on a computing cluster node with a 2.4GHz processor and up to 24GB of memory per benchmark. Each benchmark tested veriﬁcation of either the monolithic network or a cut network, and we ran each benchmark for 5 trials and took the average time. We used two timeouts: an 8hour timeout on NV as a whole and a 2hour timeout on Z3. The NV timeout prevented fragments from spending too long partitioning or solving multiple Z3 queries, while the Z3 timeout also ensured that benchmarks did not spend too long solving any single fragment’s SMT query. Fattrees. To evaluate Kirigami’s performance for fattrees, we made use of the shortest path policy SPand valleyfree policy FAT described in [23], along with an original faulttolerance policy MAINT .MAINT extends SPby requiring that nodes avoid routing through a nondestination node down which is currently down for maintenance: routes advertised by down will be dropped. We encode down as a symbolic value, meaning that we check that routing bypasses the down node for all concrete choices ofdown . 3All of our benchmarks are available or adapted from those at [22]. 4We take the maximum query time as each fragment SMT query is independent of the others and hence could be parallelized on a multiprocessor platform or a cluster of servers.15 0 200 40010","This paper presents a novel technique for modular verification of control planes. We start from an existing general model for distributed routing, the Stable Routing Problem (SRP). In an SRP, each node of the network exchanges routes with its neighbors to compute a locally-stable solution. We then extend this model to include a new set of input nodes and output nodes, called “open SRPs”. We then implement this extension as a Kirigami extension to the NV network verification language and tool. We present a new technique for modular verification of the control plane",cool!
415,The cross-sectional stock return predictions via quantum neural network and tensor network.txt,"In this paper we investigate the application of quantum and quantum-inspired
machine learning algorithms to stock return predictions. Specifically, we
evaluate performance of quantum neural network, an algorithm suited for noisy
intermediate-scale quantum computers, and tensor network, a quantum-inspired
machine learning algorithm, against classical models such as linear regression
and neural networks. To evaluate their abilities, we construct portfolios based
on their predictions and measure investment performances. The empirical study
on the Japanese stock market shows the tensor network model achieves superior
performance compared to classical benchmark models, including linear and neural
network models. Though the quantum neural network model attains the lowered
risk-adjusted excess return than the classical neural network models over the
whole period, both the quantum neural network and tensor network models have
superior performances in the latest market environment, which suggests
capability of model's capturing non-linearity between input features.","The arrival of real quantum computers and experiments that show the quantum supremacy [1, 2] make it more realistic that the new computational paradigm will come by virtue of quantum computing. It is true that we are currently at the era of NISQ (noisy intermidiate scale quantum computer) [3] and must implement the quantum error correction for full picture of such a new paradigm, but rapid progress of quantum technologies already open a new window to the research in various elds, such as quantum chemistry, optimization, machine learning, and nance. It is therefore worth looking for a practical application of quantum computers even in the NISQ era. The framework of variational quantum algorithms (VQAs) [4] are thought to be an eective approach towards the goal. It has been applied, for instance, to solve machine learning problems [5, 6]. Machine learning techniques developed within the framework of VQAs are essentially equivalent to the ones using tensor networks [7, 8, 9], which is originally invented as a ∗email:nozomu.kobayashi@nomura.com 1arXiv:2304.12501v1  [cs.LG]  25 Apr 2023tool to simulate quantum physics in classical computers [10, 11]. Its ability to utilize an exponentially large tensor into a factorized series of smaller tensors has also allowed the machine learning community to successfully solve various machine learning problems [12, 8, 9]. It can consequently be considered as a quantuminspired machine learning algorithm. Given these growing interests of quantum and quantuminspired machine learning algorithms, it is important to study their applicability on the realworld problems, which are, however, less known so far partly due to the current limitation of computational resource for quantum computers and their simulators. In this work, to address above issue, we consider a realworld nancial problem, namely prediction of stock returns, employing quantum and quantuminspired machine learning algorithms. Stock return prediction has been a principal problem in nance. Ever since the work by Fama and French [13], who have provided the empirical evidence that the notion of socalled factors is eective in return explainability, signicant eorts has been made to nd unseen factors that have predicable powers for stock returns. Among practical investors, multifactor models, which is a linear regression of stock returns by a set of factors, are commonly used thanks to their simplicity and interpretability, though they lack expressibility due to absence of interaction terms between factors. As it is, machine learning has been becoming an alternative to them. Various studies, [14, 15, 16, 17, 18] to name but a few, are conducted on stock return predictions with machine learning methods, which can capture nonlinearity in contrast to multifactor models. Our interest here is to test whether the quantum or quantuminspired techniques can be applied to predict stock returns, and also have competitive advantage over classical ma chine learning algorithms in that task. To this end, using a set of stocks in the Japanese stock market, we conduct portfolio backtesting over 10 years based on stock return predic tions by quantum neural network, tensor network, standard linear regression, and neural network and compare their performances. As a result, we nd that the tensor network model outperforms the other models, while the quantum neural network model are inferior to the neural network model in the whole backtesting period. We also observe that in the latest market environment the quantum neural network model has the better performance than the neural network model, which might be related to the overtting problem. This experiment provides the implication that quantum neural network and tensor network may be able to learn nonlinear and interaction eects among features, and they have potential to use in return predictions beyond the conventional models. This paper is organized as follows. In Section 2, we explain the denition of our problem, the stock return predictions, then describe both classical and quantum machine learning algorithms we use in our analysis. Section 3 presents the methodology to conduct our backtesting experiment and then shows its results, using quantitative metrics that are often used to evaluate an investment performance. Finally, in Section 4 we conclude our analysis and discuss some future directions for further research. 2 Methodology","Quantum computers are a promising tool for many applications, including machine learning. However, the application of quantum computers in real-world problems is less known so far due to the current limitation of computational resource for quantum computers and their simulators. In this work, we consider a real-world financial problem, namely prediction of stock returns, employing quantum and quantuminspired machine learning algorithms. We conduct a backtesting experiment on a set of stocks in the Japanese stock market, and compare the performance of quantum neural network, tensor network, and neural network. We perform backtesting over 10 years",cool!
62,Efficient Symbolic Reasoning for Neural-Network Verification.txt,"The neural network has become an integral part of modern software systems.
However, they still suffer from various problems, in particular, vulnerability
to adversarial attacks. In this work, we present a novel program reasoning
framework for neural-network verification, which we refer to as symbolic
reasoning. The key components of our framework are the use of the symbolic
domain and the quadratic relation. The symbolic domain has very flexible
semantics, and the quadratic relation is quite expressive. They allow us to
encode many verification problems for neural networks as quadratic programs.
Our scheme then relaxes the quadratic programs to semidefinite programs, which
can be efficiently solved. This framework allows us to verify various
neural-network properties under different scenarios, especially those that
appear challenging for non-symbolic domains. Moreover, it introduces new
representations and perspectives for the verification tasks. We believe that
our framework can bring new theoretical insights and practical tools to
verification problems for neural networks.","Deep neural networks (DNN) have achieved unprecedented suc cess in many complex tasks and has been integrated into modern software s ystems [34, 43]. This brings new challenges and opportunities to the program veriﬁcation community to analyze these programs. Like traditional soft ware, DNNs were 1also shown vulnerable to various attacks. Among them, the mo st unique and notable are adversarial attacks. Adversarial examples were ﬁrst identiﬁed in [59, 25]. Later works found that adversarial attacks are common for diﬀerent neuralne twork architec tures and tasks [50, 48, 40]. Adversarial attacks are small p erturbations that can cause a prediction to change when they are applied to the inputs, and these perturbations are unnoticeable to humans. This ca uses serious concerns for DNN safety and reliability because a malicious user can ex ploit these attacks. Researchers invented various defense mechanisms but they were later shown still vulnerable to those attacks [13, 49, 39]. More recently, the community focuses on certiﬁable robustness a gainst adversarial attacks [2, 27, 30, 52]. Neuralnetwork veriﬁcation. To certify a prediction, we need to esti mate the change of the output given an input perturbation. Un fortunately, exact veriﬁcation has been shown NP/coNPhard [29, 30, 61]. To enable ef ﬁcient DNN veriﬁcation, we have to overapproximate the com putation of DNNs. As a result, the key challenge is to balance eﬃciency an d precision. A large body of veriﬁcation works is based on the classical ab stract inter pretation [18]. Veriﬁcation against adversarial attacks r equires capturing all possible executions. Abstract interpretation starts by de ﬁning an abstract domain that can overapproximate all the inputs, and reint erpret the net work execution in terms of the abstract domain [23, 60, 58]. B ecause this reinterpretation is sound, and the execution is compositi onal, abstract inter pretation enables a sound veriﬁcation of the network. Howev er, it remains challenging to verify DNNs with nonlinear perturbations a nd unconventional architectures because the abstract domain is usually deﬁne d in terms of lin ear relations, and reasoning nonlinear computations invo lves many adhoc techniques. Symbolic framework. In this work, we propose a new programreasoning framework for DNN veriﬁcation. We refer to this framework as symbolic rea soning1. Our framework contains two distinguished components: sym bolic domains and quadratic relations. Symbolic domains have ﬂex ible semantics, allowing us to reason tasks that appear challenging for non symbolic domains. We will elaborate on this paradigm and demonstrate its power for DNN ver iﬁcation. Similar to abstract interpretation, this progra m reasoning scheme 1Our symbolic reasoning framework can also be viewed as an abs tract interpretation example with the symbolic domain. 2is also compositional, and can be easily adapted to diﬀerent architectures. We use quadratic relations to encode the computation and att ack con straints rather than the commonly used linear relations. Qu adratic encoding is quite expressive. For example, many intractable combina torial optimiza tion problems can be written as quadratic programs [24]. As w e will demon strate, it can precisely encode various DNN veriﬁcation tas ks as algebraic formulas. The veriﬁcation problem is then translated into a quadratic pro gram (QP). This allows us to use mathematical tools to accura tely analyze those tasks. Meanwhile, this precise representation also e nables us to ask important theoretical questions about the veriﬁcation pro blems. We will provide quadratic encodings for various tasks, such as diﬀe rent attacks and activations. Constructing the QPs for diﬀerent veriﬁcatio n tasks amounts to assembling these components together. Because quadratic encoding is fairly expressive, the resul ting QPs are in general hard to solve. To enable eﬃciency, we consider the se mideﬁnite relax ation of quadratic programs. Semideﬁnite programming (SDP ) is a unique topic where many subjects meet together such as theoretical computer sci ence, optimization, control theory, combinatorics and fun ctional analysis. For example, [54] introduced ﬂag algebras, which uses SDP to der ive bounds for extremal combinatorics problems. In particular, some S DPinduced al gorithms are optimal within polynomial time assuming some c omplexity theoretical conjectures [11, 51]. We believe that formulat ing the veriﬁcation problems as semideﬁnite programs introduces new represent ations and per spectives for the veriﬁcation tasks, and brings more theore tical and practical tools to address those problems. Relevance. There have been a few works on using SDP to verify DNNs [22, 52, 53, 62]. These works appear designed for speciﬁc veriﬁca tion tasks and are less accessible to researchers, as some works [35, 53] cl aimed that one tech nique cannot transfer to another setting (see more discussi on in Section 6.2). We will demonstrate the reasoning framework behind these wo rks to pop ularize them. Moreover, we show that the paradigm is powerfu l and can be applied beyond the application scope of these works. In th e meantime, there are a few other works aiming to understand the quality a nd improve the empirical performance of these works [20, 46, 65, 66]. Ou r paper implies that these works can be more impactful beyond their original scope. We also present a comprehensive discussion of this framework, whic h sheds light on future directions. 3Contributions. To summarize, our paper makes the following contribu tions: 1. We provide a novel systematic neuralnetwork reasoning p aradigm and it provides new representations for many veriﬁcation tasks , i.e., as QPs and SDPs. These representations can bring new theoretical t ools, such as matrix analysis and approximation theory, to those tasks (Sections 3 and 6); 2. We present encodings for various mathematical component s, which allows us to verify diﬀerent properties and network structu res, espe cially those that appear challenging for linearrelationa l nonsymbolic domains (Section 4); 3. We empirically examine our framework on a speciﬁc DNN veri ﬁcation task:ℓ2robustness certiﬁcation. The evaluation shows that the re sult from our framework is consistently precise ( 60%improvement on av erage compared to the benchmark), and it can handle practica lsize DNNs (Section 5). 2 Preliminaries Notations and deﬁnitions. Let[n] ={1,...,n},R+= [0,∞)andZ+ be the set of positive integers. For a matrix M∈Rm×n,MTdenotes its transpose. For any vector v∈Rn, diag(v)is ann×ndiagonal matrix, with diagonal values v. Leten= (1,...,1)∈Rnbe anndimensional vector of all 1’s, andI=diag(en)is the identity matrix. Let ||v||pdenote the ℓpnorm of v: ||v||p=p/radicaltp/radicalvertex/radicalvertex/radicalbtn/summationdisplay i=1|vi|p. The canonical Euclidean norm is then ||v||2, and another commonly consid ered attack on the input is the ℓ∞attack: ||v||∞= max i∈[n]|vi|. Throughout the paper, we consider the ℓpnorm of the input’s perturbation forp≥1. 4For a matrix N,λ(N)denotes the eigenvalues of N. Ann×nsymmetric matrixM/{ollowsequal0means that Mis positive semideﬁnite (PSD). There are three common equivalent conditions for M/{ollowsequal0: 1. All eigenvalues of Mare nonnegative, i.e., λmin(M)≥0; 2.xTMx≥0for allx∈Rn; 3.∃L∈Rn×msuch that LLT=M, wherem∈Z+. Let tr(M)be the trace of a square matrix M: tr(M) =/summationtextn i=1Mii.The Frobenius inner product of two matrices A∈Rm×nandB∈Rm×nis /an}bracketle{tA,B/an}bracketri}htF=tr(ATB) =m/summationdisplay i=1n/summationdisplay j=1AijBij. A vector function f:Rn→Rmis an aﬃne transformation if f(x) =Wx+b forW∈Rm×nandb∈Rm. For two functions fandg,f◦g(x) =f(g(x)) denotes the composition of fandg. Given two metric spaces (X,dX)and(Y,dY), a function f:X→Yis Lipschitz continuous if there exists K >0such that for all x1,x2∈X, dY(f(x2),f(x1))≤KdX(x2,x1). (1) The smallest such Ksatisfying Equation (1), denoted by Kf, is called the Lipschitz constant of f. Feedforward networks. We start with the standard feedforward struc tures. A neural network f:Rm→Rlis a composition of aﬃne transforma tions and activation functions: f1(x) =W(1)x+b(1);fi(x) =W(i)σ(x)+b(i),i= 2,...,d. whereW(i)∈Rni+1×niis the weight matrix between the layers, n1=mand nd+1=l,dis the depth of the network, and b(i)∈Rni+1is the bias term. σ, the activation, is an elementwise nonlinear function. f=fd◦···◦f1. f:Rm→Rlhasloutputs. Let f(i)be theith output of f. The classiﬁcation of an input xisC(f,x) = argmaxi∈[l]f(i)(x). Suppose that the prediction of xisj, thenf(j)(x)> f(k)(x)for allk/ne}ationslash=j. The output of fis called the logit score, and the classiﬁcation model outputs the class with the highest logit score. 5−2 212 b p a˜b˜p ˜a ReLU(x) =/braceleftbigg x, x≥0 0, x <0 Figure 1: An illustration of the ReLU function. pand˜pare on the two diﬀerent branches of ReLU. The slope between any two points o n the function is always within [0,1]. ˜xis anadversarial attack forxif||¯x−x||p≤ǫandC(f,˜x)/ne}ationslash=j. We usezto denote the output of the (d−1)th layer, the representation layer of the network. Let w(i) jbe thejth row of W(i), thenf(i)(x) =w(d) jz+ b(d) j. Verifying whether a prediction changes amounts to maximiz ing(w(d) kz+ b(d) k)−(w(d) jz+b(d) j) = (w(d) k−w(d) j)z+(b(d) k−b(d) j). If the maximum value is negative for all k/ne}ationslash=j, then this prediction is robust. Therefore, we can use a vectorvto denote w(d) k−w(d) jand a scalar cto denote b(d) k−b(d) j. From now on, let us assume l= 1. In this paper, we focus on the ReLU activation function [44], due to its broad applicability, and the veriﬁcation literatures ofte n study it [7, 30, 16]. ReLU(x) = max( x,0)is a piecewise linear function. Figure 1 shows the deﬁnition of ReLU and its plot. In Appendix B, we discuss othe r activation functions than ReLU. Shor’s relaxation scheme. We symbolize the computation components in the network and then constrain them with quadratic relati ons. The ver iﬁcation tasks are exactly encoded as QPs. Unfortunately, Q Ps are gener allyNPhard to solve, because quadratic programs are quite expres sive, and discrete conditions can be captured by them. For example, th e MAXCUT problem can be easily expressed as a QP [24]. To enable eﬃcien t solving, we relax the QP to the SDP that can be solved within polynomial ti me, using 6Shor’s relaxation scheme [57]. Shor’s relaxation comes in t wo forms, which can be viewed as dual to each other [10]. The primal relaxation scheme is to relax each scalar variabl e to a mul tidimensional vector, and the dual form can be viewed as the L agrangian relaxation of the original problem. In this work, we mainly u se the primal form, so we provide some introduction here. The full detail o f both forms of relaxation can be found in Appendix C. Consider a general quadratic program: minf0(x) =xTA0x+2bT 0x+c0 s.t. f i(x) =xTAix+2bT ix+ci≤0,∀i∈[m](2) We deﬁne a dyadic matrix X(x) =/parenleftbigg1 x/parenrightbigg/parenleftbigg1 x/parenrightbiggT . ThenxTAx+2bTx+c=/parenleftbigg 1 x/parenrightbiggT/parenleftbigg c bT b A/parenrightbigg/parenleftbigg 1 x/parenrightbigg =/an}bracketle{t/parenleftbigg c bT b A/parenrightbigg ,X(x)/angbracketrightBig F. X(x)is the inner product of two vectors, so it is PSD and moreover a rank1 matrix. If we drop the rank1 requirement, we can get a n SDP: min X{/an}bracketle{t¯A0,X/an}bracketri}htF:/an}bracketle{t¯Ai,X/an}bracketri}htF≤0,i∈[m];X/{ollowsequal0;X11= 1}, (3) where ¯Ai=/parenleftbiggcibT i biAi/parenrightbigg . The primal form of Shor’s relaxation scheme can be viewed as t he natural con tinuous relaxation for some combinatorial problems. We pro vide a discussion of this in Appendix C. Given these components, we are ready to see how we can use the f rame work to verify the feedforward DNN. We use the twolayer net work as an example, and it is straightforward to extend to multilayer networks within the framework. Let us consider a twolayer network: f:Rm→R, with one hidden layer of dimension n: f(x) =vσ(Wx+b)+c, (4) whereW∈Rn×m,b∈Rn×1,v∈R1×nandc∈R. Letwibe theith row vector of W. Given Shor’s relaxation scheme and SDP solvers, verifying n eural network properties amounts to formulating the tasks as QPs. 73 Methodology","Deep neural networks (DNNs) have achieved unprecedented success in many complex tasks. However, they are also vulnerable to various attacks, such as adversarial attacks. To verify a DNN, we need to estimate the change of the prediction given an input perturbation. To achieve this, we need to over-approximate the computation of the network. To achieve this, we propose a symbolic reasoning framework for DNN verification. This framework consists of symbolic domains and quadratic relations. Symbolic domains have flexible semantics, and compositional, and compositional. We will",cool!
347,Reachability Analysis and Safety Verification for Neural Network Control Systems.txt,"Autonomous cyber-physical systems (CPS) rely on the correct operation of
numerous components, with state-of-the-art methods relying on machine learning
(ML) and artificial intelligence (AI) components in various stages of sensing
and control. This paper develops methods for estimating the reachable set and
verifying safety properties of dynamical systems under control of neural
network-based controllers that may be implemented in embedded software. The
neural network controllers we consider are feedforward neural networks called
multilayer perceptrons (MLP) with general activation functions. As such
feedforward networks are memoryless, they may be abstractly represented as
mathematical functions, and the reachability analysis of the network amounts to
range (image) estimation of this function provided a set of inputs. By
discretizing the input set of the MLP into a finite number of hyper-rectangular
cells, our approach develops a linear programming (LP) based algorithm for
over-approximating the output set of the MLP with its input set as a union of
hyper-rectangular cells. Combining the over-approximation for the output set of
an MLP based controller and reachable set computation routines for ordinary
difference/differential equation (ODE) models, an algorithm is developed to
estimate the reachable set of the closed-loop system. Finally, safety
verification for neural network control systems can be performed by checking
the existence of intersections between the estimated reachable set and unsafe
regions. The approach is implemented in a computational software prototype and
evaluated on numerical examples.","In recent decades, there have been considerable research ac tivities in the use of neural networks for control of complex systems such as stabilizing neural netwo rk controllers [ 1,2] and adaptive neural network controllers [ 3,4]. More recently, neural networks have been deployed in high assurance systems such as selfdriving vehicles [ 5], autonomous systems [ 6], and aircraft collision avoidance [ 7]. Neural network based controllers have been demonstrated to be effe ctive at controlling complex systems. However, such controllers are conﬁned to systems that compl y with the lowest levels of safety in tegrity, since the majority of neural networks are viewed as black boxes lacking effective methods to predict all outputs and assure safety speciﬁcations for clo sedloop systems. In a variety of applications to feedback control systems, there are safetyoriented res trictions that the system states are not allowed to violate while under the control of neural network based feed back controllers. Unfortunately, it has been observed that even welltrained neural networks are someti mes sensitive to input perturbations and might react in unexpected and incorrect ways to even slight pertur bations of their inputs [ 8], thus it could result in unsafe closedloop systems. With the progress of adversa rial machine learning, such matters may only become worse in safetycritical cyberphysical systems (C PS). Hence, methods that are able to provide ∗Authors are with the Department of Electrical Engineering a nd Computer Science, Vanderbilt University, Nashville, Te n nessee 37212, USA. Email: xiangwming@gmail.com (Weiming X iang); taylor.johnson@gmail.com (Taylor T. Johnson). 1formal guarantees are in great demand for verifying speciﬁc ations or properties of systems involving neural network components, especially as such AI/ML compon ents are integrated in safetycritical CPS. The veriﬁcation of neural networks is a computationally har d problem. Even veriﬁcations of simple properties concerning neural networks have been demonstra ted to be nondeterministic polynomial (NP) complete problems as reported in [ 9]. A few results have been reported in the literature for verify ing speciﬁcations in systems consisting of neural networks. In [ 10] satisﬁability modulo theories (SMT) solvers are develope d and utilized for the veriﬁcation of feedforward multilayer neural networks. In [11,12] an abstractionreﬁnement approach is developed for computing output reachable set of neural ne tworks. A simulationbased approach is developed in [ 13], which turns the problem of overapproximating the output set of a neural network into a problem of computing the maximal sensitivity of the neural network, which is formulated in terms of a sequence of convex optimization problems. In particular, for a class of neural networks with a speciﬁc type of activation functions called rectiﬁed linear unit (R eLU), several methods are developed such as mixedinteger linear programming (MILP) based approach [ 14,15,16], linear programming (LP) based approach [ 17], Reluplex algorithm stemmed from Simplex algorithm [ 9], and polytope manipulation based approach [ 18]. In this paper, we study the problems of reachable set estimat ion and safety veriﬁcation for dynamical systems equipped with neural network controllers, where th e plant is represented in its typical modeling formalism of timesampled ordinary differential equation s (ODEs) and the controller is a feedforward neural network determining actuation. The neural network c ontroller considered in this paper is in the form of feedforward neural networks. The key step to solve th is challenging problem is, as we shall see, to soundly estimate the output set of a feedforward neural ne twork. By using a ﬁnite number of hyper rectangular sets to overapproximate the input set, the out put set estimation problem can be transformed into a linear programming (LP) problem for neural networks w ith most of classes of activation functions. Then, as the estimated output set of the neural network contr oller is the input set to the plant described by an ordinary difference/differential equation (ODE), th e reachable set estimation for the closedloop system can be obtained by employing sophisticated reachabi lity analysis methods for ODE models. 1.1 Related Work","In this paper, we study the problems of reachable set estimation and safety verification for closed-loop systems equipped with neural network controllers. The key step is to soundly estimate the output set of a feedforward neural network controller. Then, as the estimated output set is the input set to the plant described by an ordinary difference/differential equation (ODE), reachable set estimation for the closed-loop system can be obtained by employing sophisticated reachability analysis methods for ODE models. The reachable set estimation problem is solved by using a finite number of hyper rectangular sets to",cool!
423,A feasibility study of treatment verification using EPID cine images for hypofractionated lung radiotherapy.txt,"We propose a novel approach for potential on-line treatment verification
using cine EPID (Electronic Portal Imaging Device) images for hypofractionated
lung radiotherapy based on a machine learning algorithm. Hypofractionated
radiotherapy requires high precision. It is essential to effectively monitor
the target to ensure that the tumor is within the beam aperture. We modeled the
treatment verification problem as a two-class classification problem and
applied an Artificial Neural Network (ANN) to classify the cine EPID images
acquired during the treatment into corresponding classes with the tumor inside
or outside of the beam aperture. Training samples were generated for the ANN
using digitally reconstructed radiographs (DRRs) with artificially added shifts
in tumor location to simulate cine EPID images with different tumor locations.
Principal Component Analysis (PCA) was used to reduce the dimensionality of the
training samples and cine EPID images acquired during the treatment. The
proposed treatment verification algorithm was tested on five hypofractionated
lung patients in a retrospective fashion. On average, our proposed algorithm
achieved a 98.0% classification accuracy, a 97.6% recall rate, and a 99.7%
precision rate.","In the United States, lung cancer is the second most  prevalent cancer and the leading cause of  cancer death, accounting for about 30% of all cancer mortality (Jemal  et al  2005).  Hypofractionated lung radiotherapy is being increasingly employed as an alternate modality for the treatment of primary and secondary lung cancer s. This therapy has the important advantages  40  of allowing shortened treatment times while deliv ering higher effective radiobiological doses.  However, normal tissues surroundi ng the tumors are also exposed to highdose levels of  radiation. Furthermore, cancerous tissue can occasion ally move outside the irradiation field, e.g.  when the patient has sudden irregular br eathing or episodes of coughing. Under these  circumstances, malignant tissue will be missed, a nd even more normal tissue than planned will be 45                                                    § This work was first presented at the Seventh International Conference on Machine Learning and  Applications, San Di ego, CA USA, Decem ber 1113, 2008.  2irradiated. A very large fractional dose (e.g., 10 Gy per fraction) is commonly applied in  hypofractionated lung radiotherapy. This is in many ways an ablative therapy, both to the tumors  and to the normal tissues surrounding them. Consequently, the precision requirement of  hypofractionated lung radiotherapy is high. It is absolutely critical to effectively monitor the  target to ensure maximal irradiation of the tu mor with minimal irradiation of surrounding normal 5  tissue.    The major uncertainty in treating lung cancer is the respiratory lung tumor motion, which can be  clinically significant for some patients (e.g., of the order of 2 – 3cm) (Jiang 2006). This  uncertainty must be dealt with when deliveri ng hypofractionated lung ra diotherapy. Typically,  10  margins are added to accommodate respiratory moti on. However, even with margins, tumors, or  portions of them, will occasionally move outside  the irradiation field. Abrupt coughing,  dramatically changing breathing patterns, and sudden occurrences of pain, can all occur during  treatment. Any one of these events can result in moving the tumor (or portions of it) outside the  irradiation field. It is therefore, critically  important to constantly monitor the patients’ 15  treatment—and when the tumor is detected outside the irradiation field, the treatment must be  interrupted. The treatment should be resumed only wh en the tumor returns to the irradiation field  or, in extreme cases, after patient resetup.   EPID acquisition in cine mode does not require any additio nal radiation dose, and yet the  20  technique generates images that carry valuable  information indicating tumor position. Several  methods for monitoring radiation th erapy have been developed using cine EPID images, with or  without implanted markers.  Berbeco et al developed a matching technique for respir atorygated liver radiotherapy treatment  25  verification with an EPID in cine mode (Berbeco  et al  2005, Berbeco  et al  2007). Implanted radio  opaque fiducial markers inside or near the target  were required for this technique. The markers  were contoured on a planning CT set, enabling users to create digitally r econstructed radiographs  (DRRs) for each treatment beam. During the treatment, a sequence of EPID images could be acquired without disrupting the treatment routine.  Implanted markers were visualized in the  30  images and their positions in the beam’s eye view  (BEV) were calculated offline and compared  to the reference position by matching the field apertures in corresponding EPID and DRR images.  Tumor displacement was calculated for one patient with three implanted markers. The case study demonstrated the feasibility of the proposed method.    35  For lung cancer patients, implantation of fiducial markers is not widely acceptable due to the risk  of pneumothorax (Laurent  et al  2000, Arslan  et al  2002, Geraghty  et al  2003, Topal and Ediz  2003, Berbeco  et al  2005). Arimura et al considered using cine EPID images for measurement of  displacement vectors of tumor positions in lung radiotherapy without implanted markers  (Arimura  et al  2007). A template matching technique based on crosscorrelation coefficients was 40  proposed to calculate the similarity between a reference portal image and each cine EPID image.  5 patients with nonsmall cell lung cancer and one patient with metastasis were included for a  validation study. The proposed method worked well for 4 cases but not well for the other 2.  To develop a more robust system, we propose an alternative approach for treatment verification  45  of hypofractionated lung radiotherapy using cine EPID images without implanted markers.  Artificial Neural Network (ANN) based tec hnique will be developed to classify the cine EPID  images into two classes: images with the tumor inside the radiation field and images with the  tumor outside the radiation field.   50  3This paper is organized as follows: section 2 w ill introduce methods and materials used in this  work, including a brief introduction of ANN and a detailed description of how to apply ANN to  our treatment verification problem. Section 3 pr esents experimental results. Section 4 will  conclude this work and plan future work.   5  2. Methods and materials","Hypofractionated lung radiotherapy is an increasingly used modality for the treatment of primary and secondary lung cancers. However, the precision requirement of this therapy is high. Consequently, it is absolutely critical to effectively monitor the target to ensure maximal irradiation of the tumor with minimal irradiation of surrounding normal tissue. The major uncertainty in treating lung cancer is the respiratory lung tumor motion, which can be clinically significant for some patients (e.g., of the order of 2 – 3 cm). During treatment, a sequence of cine EPID images was developed to measure displacement vectors",cool!
516,An Energy-Based View of Graph Neural Networks.txt,"Graph neural networks are a popular variant of neural networks that work with
graph-structured data. In this work, we consider combining graph neural
networks with the energy-based view of Grathwohl et al. (2019) with the aim of
obtaining a more robust classifier. We successfully implement this framework by
proposing a novel method to ensure generation over features as well as the
adjacency matrix and evaluate our method against the standard graph
convolutional network (GCN) architecture (Kipf & Welling (2016)). Our approach
obtains comparable discriminative performance while improving robustness,
opening promising new directions for future research for energy-based graph
neural networks.","Graph neural networks (GNNs) are a generalization of neural networks that operate on graph structured data, typically in the form of an adjacency matrix or graph laplacian, and feature vectors deﬁned for the nodes. They have found success in tasks such as link prediction, node classiﬁcation, and graph classiﬁcation (e.g., Izadi et al. (2020), Wang et al. (2019b), Zhang et al. (2019)). Along side the empirical success, recent theoretical work has elucidated properties on their depth (Oono & Suzuki (2019)), architectural alignment with algorithms (Xu et al. (2019)), and their discriminative power (Xu et al. (2018)). Recently, the work of Grathwohl et al. (2019) proposed viewing tradi tional classiﬁers as energybased models, adjusting the softmax transfer function to the Boltzmann distribution, and adding an inner stochastic Langevin gradient descent (Welling & Teh (2011)) loop over new samples. We extend this framework for GNNs, and introduce a novel method to ensure generation over the adjacency matrix itself along with node features. We evaluate our approach for the node classiﬁcation task on the Cora, Pubmed, and Citeseer datasets and explore its generative capabilities. 2 B ACKGROUND AND PRIOR WORK One of the most popular GNN architectures is the GCN architecture of Kipf & Welling (2016), which utilizes a normalized adjacency matrix with selfconnections. Consider the adjacency matrix of a graph, A2Rnn. We deﬁne ^A=A+In, where Inis thennidentity matrix. Let ^DiiP j^Aij. Layerwise propagation is given by: Hl+1=(^D","Graph neural networks (GNNs) are a generalization of neural networks that operate on graph structured data, typically in the form of an adjacency matrix or graph laplacian, and feature vectors defined for the nodes. They have found success in tasks such as link prediction, node classification, and graph classification. Recent theoretical work has elucidated properties on their depth (Oono & Suzuki, 2019), architectural alignment with algorithms (Xu et al., 2019), and their discriminative power (Grathwohl Grathwohl,",cool!
509,Verification of Neural-Network Control Systems by Integrating Taylor Models and Zonotopes.txt,"We study the verification problem for closed-loop dynamical systems with
neural-network controllers (NNCS). This problem is commonly reduced to
computing the set of reachable states. When considering dynamical systems and
neural networks in isolation, there exist precise approaches for that task
based on set representations respectively called Taylor models and zonotopes.
However, the combination of these approaches to NNCS is non-trivial because,
when converting between the set representations, dependency information gets
lost in each control cycle and the accumulated approximation error quickly
renders the result useless. We present an algorithm to chain approaches based
on Taylor models and zonotopes, yielding a precise reachability algorithm for
NNCS. Because the algorithm only acts at the interface of the isolated
approaches, it is applicable to general dynamical systems and neural networks
and can benefit from future advances in these areas. Our implementation
delivers state-of-the-art performance and is the first to successfully analyze
all benchmark problems of an annual reachability competition for NNCS.","In this work we consider controlled dynamical systems where the plant model is given as a nonlinear ordinary dif ferential equation (ODE) and the controller is implemented by a neural network. We call such systems neuralnetwork control systems (NNCS). We are interested in reachability properties of NNCS: guaranteed reachability of target states or nonreachability of error states. These questions can be veriﬁed by computing a set that overapproximates the reach able states, which is the subject of reachability analysis, with a large body of works for ODEs (Althoff, Frehse, and Girard 2021) and neural networks (Liu et al. 2021). In principle, reachability analysis for NNCS can be im plemented by chaining two offtheshelf tools for analyzing the ODE and the neural network. The output set of one tool is the input set to the other, and this process is repeated for each control cycle. This idea is indeed applied by several approaches (Tran et al. 2020b; Clavi `ere et al. 2021). While correct, such an approach often yields sets that are too con servative to be useful in practice. The reason is that with each switch to the other tool, a conversion between set representa tions is required because the tools use different techniques. Thus some of the dependency information encoded in thesets is lost when the tools are treated as black boxes. This incurs an approximation error that quickly accumulates over time, also known as the wrapping effect (Neumaier 1993). Reachability algorithms at a sweet spot between preci sion and performance in the literature are based on Taylor models for ODEs (Makino and Berz 2003; Chen, ´Abrah ´am, and Sankaranarayanan 2012) and on set propagation via ab stract interpretation (Cousot and Cousot 1977) for neural networks, particularly using zonotopes (Gehr et al. 2018; Singh et al. 2018). In this work we propose a new reacha bility algorithm for NNCS that combines Taylor models and zonotopes. In general, Taylor models and zonotopes are in comparable and cannot be converted exactly. We describe how to tame the approximation error when converting be tween these two set representations with two main insights. First, we identify a special structured zonotope, which can be exactly converted to a Taylor model by encoding the addi tional structure in the socalled remainder. Second, the struc ture of the Taylor model from the previous cycle can be re tained by only updating the control inputs, which allows to preserve the dependencies encoded in the Taylor model. Our approach only acts at the set interface and does not require access to the internals of the reachability tools. They only need to expose the complete set information, which is only a minor modiﬁcation of the blackbox algorithms. Thus our approach makes no assumptions about the ODE or the neural network, as long as there are sound algorithms for their (almost blackbox) reachability analysis available. This makes the approach a universal tool. While our approach is conceptually simple, we demonstrate in our evaluation that it is effective and scalable in practice. We successfully ana lyzed all benchmark problems from an annual NNCS com petition (Johnson et al. 2021) for the ﬁrst time. In summary, this paper makes the following contributions: • We propose structured zonotopes and show how to soundly convert them to Taylor models and back. • We design a sound reachability algorithm for NNCS based on Taylor models and zonotopes. • We demonstrate the precision and scalability of the algo rithm on benchmarks from a reachability competition. 1arXiv:2112.09197v2  [eess.SY]  1 May 2022Related Work","Reachability analysis is a key property of control systems where the plant model is given as a nonlinear ordinary differential equation (ODE) and the controller is implemented by a neural network. In principle, reachability analysis for NNCS can be implemented by chaining two off-the-shelf tools for analyzing the ODE and the neural network. The output set of one tool is the input set of the other tool, and this process is repeated for each control cycle. While correct, such an approach often yields sets that are too conservative to be useful in practice. This incurs an app",cool!
159,A DPLL(T) Framework for Verifying Deep Neural Networks.txt,"Deep Neural Networks (DNNs) have emerged as an effective approach to tackling
real-world problems. However, like human-written software,
automatically-generated DNNs can have bugs and be attacked. This thus attracts
many recent interests in developing effective and scalable DNN verification
techniques and tools. In this work, we introduce a NeuralSAT, a new constraint
solving approach to DNN verification. The design of NeuralSAT follows the
DPLL(T) algorithm used modern SMT solving, which includes (conflict) clause
learning, abstraction, and theory solving, and thus NeuralSAT can be considered
as an SMT framework for DNNs. Preliminary results show that the NeuralSAT
prototype is competitive to the state-of-the-art. We hope, with proper
optimization and engineering, NeuralSAT will carry the power and success of
modern SAT/SMT solvers to DNN verification. NeuralSAT is avaliable from:
https://github.com/dynaroars/neuralsat-solver","Deep Neural Networks (DNNs) have emerged as an effective approach for solving challenging realworld problems. Among many others, they have been used for image recognition [He et al . 2016; Krizhevsky et al .2012], autonomous driving [Rao and Frtunikj 2018; Salay et al .2020], airplane collision control [Julian et al .2016], power grid control [Siano et al .2012], fake news detection [Thota et al .2018], drug synthesis and discovery [Grebner et al .2021], and COVID19 detection and diagnosis [Khan et al. 2020; Ozturk et al. 2020]. However, just like traditional software, DNNs can have “bugs”, e.g., producing unexpected results on inputs that are different from those in training data, and be attacked, e.g., small perturbations to the inputs by a malicious adversary or even sensorial imperfections result in misclassification [Isac et al.2022; Ren et al .2020; Yang et al .2022; Zhang et al .2019; Zügner et al .2018]. These issues, which have been observed in many DNNs [Goodfellow et al .2014; Szegedy et al .2014] and demonstrated in the real world [Eykholt et al .2018], naturally raise the question of how DNNs should be tested, validated, and ultimately verified to meet the requirements of relevant robustness or safety standards [Huang et al. 2020; Katz et al. 2017b]. To address this question, researchers have developed a variety of techniques and tools to verify DNNs (e.g., [Huang et al .2017; Katz et al .2022, 2019; Liu et al .2021; Müller et al .2021; Urban and Miné 2021; Wang et al .2021]). Constraintbased approaches [Ehlers 2017; Huang et al .2017; Katz et al.2017a] aim to both correctly prove and disprove properties, but do not scale to large networks. In contrast, abstractionbased approaches [Müller et al .2021; Singh et al .2018a, 2019b; Wang et al . 2018b, 2021] scale much better, but while modern abstraction verification tools can often refine their abstractions to avoid returning spurious counterexamples they are incomplete. The problem of verifying nontrivial properties of DNNs with piecewise linear activation func tions, such as “ReLU”, has been shown to be reducible [Katz et al .2017a] from the classical satisfiabil ity (SAT) problem [Cook 1971]. Despite this complexity, the ability of satisfiability modulo theories (SMT) solvers to scale to large formulae encoding realworld verification problems [Kroening and Strichman 2016] suggests that a similar approaches might be effective for DNN verification. However, the constraintbased DNN verifiers developed to date [Ehlers 2017; Katz et al .2017a, 2022, 2019] are not among the stateoftheart as determined by DNN verification competitions [Bak et al. 2021; Müller et al. 2022]. Techniques like Planet [Ehlers 2017] and Reluplex [Katz et al .2017a, 2022] demonstrated how the semantics of a trained DNN could be encoded as a constraint in Linear Real Arithmetic (LRA) and 1arXiv:2307.10266v1  [cs.LG]  17 Jul 2023Hai Duong, Linhan Li, ThanhVu Nguyen, and Matthew B. Dwyer combined with a specification also expressed in LRA for verification. In principle, such constraints can be solved by any SMT solver equipped with an LRA theory solver (Tsolver). The DPLL(T) algorithm implemented by modern SMT solvers works by moving back and forth between solving an abstract propositional encoding of the constraint and solving a theoryspecific encoding of a constraint fragment corresponding to a partial assignment of propositional literals. The challenge in solving DNN verification constraints lies in the fact that each neuron gives rise to a disjunctive constraint to encode its nonlinear behavior. In practice, this leads to a combinatorial blowup in the space of assignments the SMT solver must consider at the abstract propositional level. To resolve the exponential complexity inherent in such constraints, both Planet andReluplex chose to push the disjunctive constraints from the propositional encoding down into the theoryspecific encoding of the problem, leveraging a technique referred to as splittingondemand [Barrett et al .2006]. This works to an extent, but it does not scale well to large DNNs [Bak et al .2021; Müller et al .2022]. We observe that the choice to pursue an aggressive splittingondemand strategy sacrifices the benefit of several of the key algorithmic techniques that make SMT solvers scale – specifically conflictdriven clause learning (CDCL) [Bayardo Jr and Schrag 1997; Marques Silva and Sakallah 1996; MarquesSilva and Sakallah 1999] and theory propagation [Kroening and Strichman 2016]. In this paper, we revisit the design of a DPLL(T) solver for DNN verification by developing a T solver that incorporates abstraction to (1) accelerate unsatisfiability checking of partial assignments and to (2) deduce implied literals to realize a form of theory propagation that drives clause learning to accelerate solving at the abstract propositional level. We present the NeuralSAT framework, which consists of a lazy, incremental LRAsolver that can be parameterized by stateoftheart abstractions, such as LiRPA [Wang et al .2021; Xu et al .2020], to efficiently perform exhaustive theory propagation. In §5, we formalize NeuralSAT and prove that it is sound and complete, and that it terminates. We then describe a NeuralSAT prototype that supports neural networks with different layer types, e.g., fullyconnected, convolutional, and residual, and piecewiselinear activation functions, e.g., ReLU. In §7 we present results demonstrating that NeuralSAT establishes the stateoftheart in constraintbased DNN verification improving substantially on Reluplex ’s successor Marabou [Katz et al .2022, 2019], which also employs abstraction and deduction, but does not exploit CDCL. Moreover, despite the fact that NeuralSAT is an early stage prototype, that is not highly optimized, it ranks second to 𝛼𝛽CROWN in solving benchmarks from the VNNCOMP competition. The contributions of this work lie in: (i) developing a domainspecific LRAsolver that allows for the benefits of CDCL to accelerate SMTbased DNN verification,; (ii) proving the soundness, completeness, and termination of the approach; (iii) developing a prototype NeuralSAT imple mentation which we release as open source; and (iv) empirically demonstrating that the approach compares favorably with the stateoftheart in terms of scalability, performance, and ability to solve DNN verification problems. Constraintbased DNN verifiers, like Planet andReluplex , pioneered the application of formal verification to reason about neural network behavior. Subsequent work abandoned completeness in order to scale, but NeuralSAT demonstrates that by leveraging CDCL constraintbased verification can scale and, we believe, it offers a platform for further advances in DNN verification. 2 BACKGROUND 2.1 Satisfiability and DPLL(T) The classical satisfiability (SAT) problem asks if a given propositional formula over Boolean variables can be satisfied [Biere et al .2009]. Given a formula 𝑓, a SAT solver returns satif it can find a satisfying assignment that maps truth values to variables of 𝑓that makes 𝑓evaluate to true, and 2A DPLL(T) Framework for Verifying Deep Neural Networks unsat if it cannot find any satisfying assignments. The problem is NPComplete and research into methods for efficiently solving problem instances has been ongoing for multiple decades. '(&,'(%&3%$&.75$&.$1$/<=(&21)/,&7FRQIOLFWGO! QRFRQIOLFWSDUWLDODVVLJQPHQWIXOODVVLJQPHQWGO6$7816$7&1) Fig. 1. Original DPLL Algorithm.DPLL. Fig. 1 gives an overview of DPLL , a SAT solv ing technique introduced in 1961 by Davis, Putnam, Logemann, and Loveland [Davis et al .1962]. DPLL is an iterative algorithm that takes as input a propositional formula in CNF form and (i) decides an unassigned vari able and assigns it a truth value, (ii) performs Boolean constraint propagation (BCP) (also called Unit Propa gation), which detects single literal clauses that either force a literal to be true in a satisfying assignment or give rise to a conflict; (iii) analyzes the conflict to backtrack to a previous decision level dl; and (iv) erases assignments at levels larger than dlto try new assignments. These steps repeat until DPLL finds a satisfying assignment and returns sat, or decides that it cannot backtrack ( dl=1) and returns unsat . Modern DPLL solving improves the original version with conflictdriven clause learning ( CDCL ) [Ba yardo Jr and Schrag 1997; Marques Silva and Sakallah 1996; MarquesSilva and Sakallah 1999]. DPLL with CDCL can learn new clauses to avoid past conflicts and backtrack more intelligently (e.g., using nonchronologically backjumping). Due to its ability to learn new clauses, CDCL can significantly reduce the search space and allow SAT solvers to scale to large problems. In the following, whenever we refer to DPLL, we mean DPLL with CDCL. DPLL(T). DPLL(T) [Nieuwenhuis et al .2006] extends DPLL for propositional formulae to check SMT formulae involving nonBoolean variables, e.g., real numbers and data structures such as strings, arrays, lists. DPLL(T) combines DPLL with dedicated theory solvers to analyze formulae in those theories1. For example, to check a formula involving linear arithmetic over the reals (LRA), DPLL(T) may use a theory solver that uses linear programming to check the constraints in the formula. Modern DPLL(T)based SMT solvers such as Z3 [Moura and Bjørner 2008] and CVC4 [Barrett et al .2011] include solvers supporting a wide range of theories including linear arithmetic, nonlinear arithmetic, string, and arrays [Kroening and Strichman 2016]. 2.2 The DNN verification problem Aneural network (NN) [Goodfellow et al .2016] consists of an input layer, multiple hidden layers, and an output layer. Each layer has a number of neurons, each connected to neurons from previous layers through a predefined set of weights (derived by training the network with data). A DNN is an NN with at least two hidden layers. The output of a DNN is obtained by iteratively computing the values of neurons in each layer. The value of a neuron in the input layer is the input data. The value of a neuron in the hidden layers is computed by applying an affine transformation to values of neurons in the previous layers, then followed by an activation function such as the popular Rectified Linear Unit (ReLU) activation. For this activation, the value of a hidden neuron 𝑦is𝑅𝑒𝐿𝑈(𝑤1𝑣1+...+𝑤𝑛𝑣𝑛+𝑏), where𝑏is the bias parameter of 𝑦,𝑤𝑖,...,𝑤𝑛are the weights of 𝑦,𝑣1,...,𝑣𝑛are the neuron values of preceding layer,𝑤1𝑣1+···+𝑤𝑛𝑣𝑛+𝑏is the affine transformation, and 𝑅𝑒𝐿𝑈(𝑥)=max(𝑥,0)is the ReLU activation. The values of a neuron in the output layer is evaluated similarly but it may skip the activation function. A ReLU activated neuron is said to be active if its input value is greater than zero and inactive otherwise. 1SMT is Satisfiability Modulo Theories and the T in DPLL(T) stands for Theories. 3Hai Duong, Linhan Li, ThanhVu Nguyen, and Matthew B. Dwyer DNN Verification. Given a DNN 𝑁and a property 𝜙, the DNN verification problem asks if𝜙is a valid property of 𝑁. Typically,𝜙is a formula of the form 𝜙𝑖𝑛⇒𝜙𝑜𝑢𝑡, where𝜙𝑖𝑛is a property over the inputs of 𝑁and𝜙𝑜𝑢𝑡is a property over the outputs of 𝑁. A DNN verifier attempts to find a counterexample input to𝑁that satisfies 𝜙𝑖𝑛but violates 𝜙𝑜𝑢𝑡. If no such counterexample exists, 𝜙is a valid property of 𝑁. Otherwise, 𝜙is not valid and the counterexample can be used to retrain or debug the DNN [Huang et al. 2017]. 0.5 1.01.0 0.51.0 1.01.0 1.01.0 Fig. 2. An FNN with ReLU.Example. Fig. 2 shows a simple DNN with two inputs 𝑥1,𝑥2, two hidden neurons 𝑥3,𝑥4, and one output 𝑥5. The weights of a neuron are shown on its incoming edges , and the bias is shown above or below each neuron. The outputs of the hidden neurons are computed the affine transformation and ReLU, e.g., 𝑥3=𝑅𝑒𝐿𝑈(−0.5𝑥1+0.5𝑥2+1.0). The output neuron is computed with just the affine transformation, i.e., 𝑥5=−𝑥3+𝑥4−1. A valid property for this DNN is that the output is 𝑥5≤0for any inputs𝑥1∈[− 1,1],𝑥2∈[− 2,2]. An invalid property for this network is that 𝑥5>0for those similar inputs. A counterexample showing this property violation is {𝑥1=−1,𝑥2=2}, from which the network evaluates to 𝑥5=−3.5. Such properties can capture safety requirements (e.g., a rule in an collision avoidance system in [Katz et al.2017a; Kochenderfer et al .2012] is “if the intruder is distant and significantly slower than us, then we stay below a certain threshold”) or local robustness [Katz et al .2017b] conditions (a form of adversarial robustness stating that small perturbations of a given input all yield the same output). Abstraction. ReLUbased DNN verification is NPComplete [Katz et al .2017a] and thus can be formulated as a SAT or SMT checking problem. Direct application of SMT solvers does not scale to the large and complex formulae encoding realworld, complex DNNs. While custom theory solvers, like Planet andReluplex , retain the soundness, completeness, and termination of SMT and improve on the performance of a direct SMT encoding, they too do not scale sufficiently to handle realistic DNNs citebak2021second. Applying techniques from abstract interpretation [Cousot and Cousot 1977], abstractionbased DNN verifiers overapproximate nonlinear computations (e.g., ReLU) of the network using linear abstract domains such as interval [Wang et al .2018b], zonotope [Singh et al .2018a], polytope [Singh et al.2019b; Xu et al .2020]. As illustrated in Fig. 8 abstract domains can model nonlinearity with varying degrees of precision using polyhedra that are efficient to compute with. This allows abstractionbased DNN verifiers to sidestep the disjunctive splitting that is the performance bottleneck of constraintbased DNN verifiers. A DNN verification technique using an approximation, e.g., the polytope abstract domain, works by (i) representing the input ranges of the DNN as polytopes, (ii) applying transformation rules to the affine and ReLU computations of the network to compute polytope regions representing values of neurons, and (iii) finally, converting the polytope results into output bounds. The resulting outputs are an overapproximation of the actual outputs. 3 OVERVIEW OF NEURALSAT NeuralSAT is a SMTbased DNN verifier that uses abstraction in its theory solver to accelerate satisfiability checks and the exploration of the space of variable assignments. Fig. 3 gives an overview of NeuralSAT , which follows the DPLL(T) framework (§2) and consists of standard DPLL components (light shades) and the theory solver (dark shade). 4A DPLL(T) Framework for Verifying Deep Neural Networks AnalyzeConﬂictDecideBCPBacktrackDNN + PropertyBoolean Abstraction SATUNSATDEDUCTION Fig. 3. NeuralSAT .NeuralSAT construct a propositional formula over Boolean vari ables that represent the activation status of neurons ( Boolean Abstrac tion). Clauses in the formula assert that each neuron, e.g., neuron 𝑖, is active or inactive, e.g., 𝑣𝑖∨𝑣𝑖. This abstraction allows us to use standard DPLL components to search for truth values satisfying these clauses and a DNNspecific theory solver to check the feasibility of truth assignments with respect to the constraints encoding the DNN and the property of interest. NeuralSAT now enters an iterative process to find assignments satisfying the activation clauses. First, NeuralSAT assigns a truth value to an unassigned variable ( Decide ), detects unit clauses caused by this assignment, and infers additional assignments ( Boolean Constraint Propagation ). Next, NeuralSAT invokes the theory solver or Tsolver ( DEDUCTION ), which uses LP solving and abstraction to check the satisfiability of the constraints of the current assignment with the property of interest. The Tsolver can also infer additional truth assignments. If the Tsolver confirms satisfiability, NeuralSAT continues with new assignments ( Decide ). Otherwise, NeuralSAT detects a conflict ( AnalyzeConflict ) and learns clauses to remember it and backtrack to a previous decision ( Backtrack ). This process repeats until NeuralSAT can no longer backtrack, and return unsat , indicating the DNN has the property, or it finds a total assignment for all boolean variables, and returns sat(and the user can query NeuralSAT for a counterexample). 3.1 Illustration We use NeuralSAT to prove that for inputs 𝑥1∈[− 1,1],𝑥2∈[− 2,2]the DNN in Fig. 2 produces the output𝑥5≤0.NeuralSAT takes as input the formula 𝛼representing the DNN: 𝑥3=𝑅𝑒𝐿𝑈(−0.5𝑥1+0.5𝑥2+1)∧ 𝑥4=𝑅𝑒𝐿𝑈(𝑥1+𝑥2−1)∧ 𝑥5=−𝑥3+𝑥4−1(1) and the formula 𝜙representing the property: 𝜙:−1≤𝑥1≤1∧−2≤𝑥2≤2⇒𝑥5≤0. (2) To prove𝛼⇒𝜙,NeuralSAT shows that novalues of𝑥1,𝑥2satisfying the input properties would result in𝑥5>0. Thus, we want NeuralSAT to return unsat for𝛼⇒𝜙: 𝛼∧−1≤𝑥1≤1∧−2≤𝑥2≤2∧𝑥5>0. (3) In the following, we write 𝑥↦→𝑣to denote that the variable 𝑥is assigned with a truth value 𝑣∈{𝑇,𝐹}. This assignment can be either decided by Decide or inferred by BCP. We also write 𝑥@𝑑𝑙and𝑥@𝑑𝑙to indicate the respective assignments 𝑥↦→𝑇and𝑥↦→𝐹at decision level 𝑑𝑙. Boolean Abstraction. First, NeuralSAT creates two Boolean variables 𝑣3and𝑣4to represent the activation status of the hidden neurons 𝑥3and𝑥4, respectively. For example, 𝑣3=𝑇means𝑥3is active and thus is the constraint −0.5𝑥1+0.5𝑥2+1>0. Similarly,𝑣3=𝐹means𝑥3isinactive and therefore is−0.5𝑥1+0.5𝑥2+1≤0. Next, NeuralSAT forms two clauses {𝑣3∨𝑣3;𝑣4∨𝑣4} indicating these variables are either active orinactive . DPLL(T) Iterations. NeuralSAT searches for an assignment to satisfy the clauses and the con straints they represent. In this example, NeuralSAT uses four iterations, summarized in Tab. 1, to determine that no such assignment exists and the problem is thus unsat . 5Hai Duong, Linhan Li, ThanhVu Nguyen, and Matthew B. Dwyer Tab. 1. NeuralSAT ’s run producing unsat . Iter BCP DEDUCTION DECIDE ANALYZECONFLICT Constraints Bounds Bt Learned Clauses Init  𝐼=−1≤𝑥1≤1;−2≤𝑥2≤2−1≤𝑥1≤1;−2≤𝑥2≤2   𝐶={𝑣3∨𝑣3;𝑣4∨𝑣4} 1  𝐼 𝑥 5≤1 𝑣4@1   2  𝐼;𝑥4=off 𝑥5≤−1  0 𝐶=𝐶∪{𝑣4} 3𝑣4@0 𝐼;𝑥4=on 𝑥3≥0.5;𝑥5≤0.5𝑣3@0   4  𝐼;𝑥3=on;𝑥4=on   1𝐶=𝐶∪{𝑣4} Initeration 1 , as shown in Fig. 3, NeuralSAT starts with BCP, which has no effects because the current clauses and (empty) assignment produce no unit clauses. In DEDUCTION, NeuralSAT uses an LP solver to determine that the current set of constraints, which contains just the initial input bounds, is feasible2.NeuralSAT then uses abstraction to approximate an output upper bound 𝑥5≤1 and thus deduces that satisfying the output 𝑥5>0might be feasible. NeuralSAT continues with DECIDE, which uses a heuristic to select the unassigned variable 𝑣4and sets𝑣4=𝐹.NeuralSAT also increments the decision level ( 𝑑𝑙) to 1 and associates 𝑑𝑙=1to the assignment, i.e., 𝑣4@1. Initeration 2 , BCP again has no effect because it does not detect any unit clauses. In DEDUCTION, NeuralSAT determines that current set of constraints, which contains 𝑥1+𝑥2−1≤0due to the assignment 𝑣4↦→𝐹(i.e.,𝑥4=off), is feasible. NeuralSAT then approximates a new output upper bound𝑥5≤−1, which means satisfying the output 𝑥5>0constraint is infeasible . NeuralSAT now enters ANALYZECONFLICT and determines that 𝑣4causes the conflict ( 𝑣4is the only variable assigned so far). From the assignment 𝑣4@1,NeuralSAT learns a ""backjumping"" clause𝑣4, i.e.,𝑣4must be𝑇.NeuralSAT now backtracks to 𝑑𝑙0and erases all assignments decided after this level. Thus, 𝑣4is now unassigned and the constraint 𝑥1+𝑥2−1≤0is also removed. Initeration 3 , BCP determines that the learned clause is also a unit clause 𝑣4and infers𝑣4@0. In DEDUCTION, we now have the new constraint 𝑥1+𝑥2−1>0due to𝑣4↦→𝑇(i.e.,𝑥4=on). With the new constraint, NeuralSAT approximates the output upper bound 𝑥5≤0.5, which means 𝑥5>0might be satisfiable. Also, NeuralSAT computes new bounds 0.5≤𝑥3≤2.5and0<𝑥4≤2.0, and deduces that 𝑥3must be positive because its lower bound is 0.5 Thus, NeuralSAT has a new assignment 𝑣3@0(𝑑𝑙stays unchanged due to the implication). Note that this process of inferring new assignments from the Tsolver is referred to theory propagation in DPLL(T). Initeration 4 , BCP has no effects because we have no new unit clauses. In DEDUCTION, NeuralSAT determines that the current set of constraints, which contains the new constraint −0.5𝑥1+0.5𝑥2+1>0(due to𝑣3↦→𝑇), isinfeasible . Thus, NeuralSAT enters ANALYZECONFLICT and determines that 𝑣4, which was set at 𝑑𝑙=0(by BCP in iteration 3), causes the conflict. NeuralSAT then learns a clause 𝑣4(the conflict occurs when we have the assignment {𝑣3↦→𝑇;𝑣4↦→𝑇}, but𝑣3 was implied and thus making 𝑣4the conflict). However, because the assignment 𝑣4was assigned at decision level 0, NeuralSAT can no longer backtrack and thus sets 𝑑𝑙=−1and returns unsat . This unsat result shows that the DNN has the property because we cannot find a counterexample violating it, i.e., no inputs 𝑥1∈[− 1,1],𝑥2∈[− 2,2]that results in 𝑥5>0. 4 THE NEURALSAT APPROACH Fig. 4 shows the NeuralSAT algorithm, which takes as input the formula 𝛼representing the ReLU based DNN 𝑁and the formulae 𝜙𝑖𝑛⇒𝜙𝑜𝑢𝑡representing the property 𝜙to be proved. Internally, 2We use the terms feasible, from the LP community, and satisfiable, from the SAT community, interchangeably. 6A DPLL(T) Framework for Verifying Deep Neural Networks input : DNN𝛼, property𝜙𝑖𝑛⇒𝜙𝑜𝑢𝑡 output : unsat if the property is valid and satotherwise 1clauses←BooleanAbstraction (𝛼) 2𝜎←∅ // current assignment 3dl←0 // current decision level 4igraph←none // implication graph 5while truedo 6 while truedo 7 ifBCP(𝜎,dl,igraph)then 8 ifDeduce(𝜎,dl,𝛼,𝜙𝑖𝑛,𝜙𝑜𝑢𝑡)then 9 break // no conflict // conflict at decision level 0, return unsat 10 ifdl≡0then return unsat 11 clause =AnalyzeConflict(igraph) 12 dl←Backtrack(𝜎,clause) 13 clauses←clauses∪{clause} 14 dl←dl+1 15 if!Decide(𝜎,dl)then 16 return sat // total assignment, return sat Fig. 4. The NeuralSAT DPLL(T) algorithm NeuralSAT checks the satisfiability of the formula 𝛼∧𝜙𝑖𝑛∧𝜙𝑜𝑢𝑡. (4) NeuralSAT returns unsat if the formula unsatisfiable, indicating that 𝜙is a valid property of 𝑁, andsatif it is satisfiable, indicating the 𝑁is not a valid property of 𝜙. NeuralSAT uses a DPLL(T)based algorithm to check unsatisfiability. First, the input formula in Eq. 4 is abstracted to a propositional formula with variables encoding neuron activation status (BooleanAbstraction ). Next, NeuralSAT assign values to Boolean variables ( Decide ) and checks for conflicts the assignment has with the realvalued constraints of the DNN and the property of interest ( BCPandDeduce ). If conflicts arise, NeuralSAT determines the assignment decisions causing the conflicts ( AnalyzeConflict ), backtracks to erase such decisions ( Backtrack ), and learns clauses to avoid those decisions in the future ( AddClause ).NeuralSAT repeats these decisions and checking steps until it finds a total or full assignment for all Boolean variables, in which it returns sat, or until it no longer can backtrack, in which it returns unsat . We describe these steps in more detail below. 4.1 Boolean Abstraction BooleanAbstraction (Fig. 4 line 1) encodes the DNN verification problem into a Boolean constraint to be solved by DPLL. This step creates Boolean variables to represent the activation status of hidden neurons in the DNN. Observe that when evaluating the DNN on any concrete input, the value of each hidden neuron before applying ReLU is either >0(the neuron is active and the input is passed through to the output) or ≤0(the neuron is inactive because the output is 0). This allows partial assignments to these variables to represent neuron activation patterns within the DNN. 7Hai Duong, Linhan Li, ThanhVu Nguyen, and Matthew B. Dwyer From the given network, NeuralSAT first creates Boolean variables representing the activation status of neurons. Next, NeuralSAT forms a set of initial clauses ensuring that each status variable is either TorF, indicating that each neuron is either active or inactive, respectively. For example, for the DNN in Fig. 2, NeuralSAT creates two status variables 𝑣3,𝑣4for neurons 𝑥3,𝑥4, respectively, and two initial clauses 𝑣3∨𝑣3and𝑣4∨𝑣4. The assignment{𝑥3=𝑇,𝑥 4=𝐹}creates the constraint 0.5𝑥1−0.5𝑥2−1>0∧𝑥1+𝑥2−2≤0. 4.2 DPLL After BooleanAbstraction ,NeuralSAT iteratively searches for an assignment satisfying the status clauses (Fig. 4, lines 5– 16). NeuralSAT combines DPLL components (e.g., Decide ,BCP, AnalyzeConflict ,Backtrack ) to assign truth values with a theory solver (§4.3), consisting of abstraction and linear programming solving, to check the feasibility of the constraints implied by the assignment with respect to the network and property of interest. NeuralSAT maintains several variables (Fig. 4, lines 1– 4). These include clauses , a set of clauses consisting of the initial activation clauses and learned clauses; 𝜎, atruth assignment mapping status variables to truth values; 𝑖𝑔𝑟𝑎𝑝ℎ , animplication graph used for analyzing conflicts; and 𝑑𝑙, a nonzero decision level used for assignment and backtracking. 4.2.1 Decide. From the current assignment, Decide (Fig. 4, line 15) uses a heuristic to choose an unassigned variable and assigns it a random truth value at the current decision level. We describe our decision heuristic for DNN reasoning in §4.4.2. Note that if the current assignment is full, i.e., all variables have assigned values, Decide returns False (from which NeuralSAT returns sat). 4.2.2 Boolean Constraint Propagation (BCP). From the current assignment and clauses, BCP (Fig. 4, line 7) detects unit clauses3and infers values for variables in these clauses. For example, after the decision 𝑎↦→𝐹,BCP determines that the clause 𝑎∨𝑏becomes unit, and infers that 𝑏↦→𝑇. Moreover, each assignment due to BCP is associated with the current decision level because instead of being “guessed” by Decide the chosen value is logically implied by other assignments. Moreover, because each BCP implication might cause other clauses to become unit, BCP is applied repeatedly until it can no longer find unit clauses. BCP returns False if it obtains contradictory implications (e.g., one BCP application infers 𝑎↦→𝐹while another infers 𝑎↦→𝑇), and returns True otherwise. Implication Graph. BCP uses an implication graph [Barrett 2013] to represent the current assign ment and the reason for each BCP implication. In this graph, a node represents the assignment and an edge𝑖𝑐− →𝑗means that BCP infers the assignment represented in node 𝑗due to the unit clause 𝑐caused by the assignment represented by node 𝑖. The implication graph is used by both BCP, which iteratively constructs the graph on each BCP application and uses it to determine conflict, and AnalyzeConflict (§4.2.3), which analyzes the conflict in the graph to learn clauses. Example. Assume we have the clauses in Fig. 5(a), the assignments 𝑣5@3and𝑣1@6(represented in the graph in Fig. 5(b) by nodes 𝑣5@3and𝑣1@6, respectively), and are currently at decision level𝑑𝑙6. Because of assignment 𝑣1@6, BCP infers 𝑣2@6from the unit clause 𝑐1and captures that implication with edge 𝑣1@6𝑐1−→𝑣2@6. Next, because of assignment 𝑣2@6, BCP infers 𝑣4@6from the unit clause 𝑐3as shown by edge 𝑣2@6𝑐3−→𝑣4@6. Similarly, BCP creates edges 𝑣1@6𝑐2−→𝑣3@6and𝑣5@𝑐2−→𝑣3@6to capture the inference 𝑣3@6 from the unit clause 𝑐2due to assignments 𝑣5@3and𝑣1@6. Now, BCP detects a conflict because 3A unit clause is a clause that has a single unassigned literal. 8A DPLL(T) Framework for Verifying Deep Neural Networks 𝑐1=(𝑣1∨𝑣2) 𝑐2=(𝑣1∨𝑣3∨𝑣5) 𝑐3=(𝑣2∨𝑣4) 𝑐4=(𝑣3∨𝑣4) (a) (b)name cl lit var ante 𝑐4𝑣3∨𝑣4𝑣3𝑣3𝑐2 𝑣4∨𝑣1∨𝑣5𝑣4𝑣4𝑐3 𝑣1∨𝑣5∨𝑣2𝑣2𝑣2𝑐1 𝑐5𝑣1∨𝑣5 (c) Fig. 5. (a) A set of clauses, (b) an implication graph, and (c) learning a new clause. input : implication graph igraph output : clause 1clause =CurrentConflictClause (igraph) 2while¬StopCriterion(clause)do 3 lit=LastAssignedLiteral (igraph,clause) 4 var=LiteralToVariable (lit) 5 ante=Antecedent(igraph,lit) 6 clause =BinRes(clause,ante,var) 7return clause Fig. 6. AnalyzeConflict clause𝑐4=𝑣3∨𝑣4cannot be satisfied with the assignments 𝑣4@6and𝑣3@6(i.e., both𝑣3and𝑣4are 𝑇) and creates two edges to the (red) node 𝜅:𝑣4@6𝑐4−→𝜅and𝑣3@6𝑐4−→𝜅to capture this conflict. Note that in this example BCP has the implication order 𝑣2,𝑣4,𝑣3(and then reaches a conflict). In the current implementation, NeuralSAT makes an arbitrary decision and thus could have a different order, e.g.,𝑣3,𝑣4,𝑣2. 4.2.3 Conflict Analysis. Given an implication graph with a conflict such as the one in Fig. 5(b), AnalyzeConflict learns a new clause to avoid past decisions causing the conflict. The algorithm traverses the implication graph backward, starting from the conflicting node 𝜅, while constructing a new clause through a series of resolution steps. AnalyzeConflict aims to obtain an asserting clause, which is a clause that will force an immediate BCP implication after backtracking. AnalyzeConflict, shown in Fig. 6, first extracts the conflicting clause 𝑐𝑙(line 1), represented by the edges connecting to the conflicting node 𝜅in the implication graph. Next, the algorithm refines this clause to achieve an asserting clause (lines 2– 6). It obtains the literal 𝑙𝑖𝑡that was assigned last in𝑐𝑙(line 3), the variable 𝑣𝑎𝑟associated with 𝑙𝑖𝑡(line 4), and the antecedent clause 𝑎𝑛𝑡𝑒 of that𝑣𝑎𝑟 (line 5), which contains 𝑙𝑖𝑡as the only satisfied literal in the clause. Now, AnalyzeConflict resolves 𝑐𝑙and𝑎𝑛𝑡𝑒 to eliminate literals involving 𝑣𝑎𝑟(line 6). The result of the resolution is a clause, which is then refined in the next iteration. Resolution. We use the standard binary resolution rule to learn a new clause implied by two (resolving ) clauses𝑎1∨...∨𝑎𝑛∨𝛽and𝑏1∨...∨𝑏𝑚∨𝛽containing complementary literals involving the ( resolution ) variable𝛽: (𝑎1∨...∨𝑎𝑛∨𝛽) (𝑏1∨...∨𝑏𝑚∨𝛽) (𝑎1∨...∨𝑎𝑛∨𝑏1∨...∨𝑏𝑚)(BinaryResolution ) (5) 9Hai Duong, Linhan Li, ThanhVu Nguyen, and Matthew B. Dwyer The resulting ( resolvant ) clause𝑎1∨...∨𝑎𝑛∨𝑏1∨...∨𝑏𝑚contains all the literals that do not have complements 𝛽and¬𝛽. Example. Fig. 5(c) demonstrates AnalyzeConflict using the example in §4.2.2 with the BCP implication order 𝑣2,𝑣4,𝑣3and the conflicting clause 𝑐𝑙(connecting to node 𝜅in the graph in Fig. 5(b))𝑐4=𝑣3∨𝑣4. From𝑐4, we determine the last assigned literal is 𝑙𝑖𝑡=𝑣3, which contains the variable𝑣𝑎𝑟=𝑣3, and the antecedent clause containing 𝑣3is𝑐2=𝑣1∨𝑣3∨𝑣5(from the implication graph in Fig. 5(b), we determine that assignments 𝑣1@6and𝑣5@3cause the BCP implication 𝑣3@6 due to clause 𝑐2). Now we resolve the two clauses 𝑐𝑙and𝑐2using the resolution variable 𝑣3to obtain the clause 𝑣4∨𝑣1∨𝑣5. Next, from the new clause, we obtain 𝑙𝑖𝑡=𝑣4,𝑣𝑎𝑟=𝑣4,𝑎𝑛𝑡𝑒=𝑐3and apply resolution to get the clause 𝑣1∨𝑣5∨𝑣2. Similarly, from this clause, we obtain 𝑙𝑖𝑡=𝑣2,𝑣𝑎𝑟= 𝑣2,𝑎𝑛𝑡𝑒=𝑐1and apply resolution to obtain the clause 𝑣1∨𝑣5. At this point, AnalyzeConflict determines that this is an asserting clause, which would force an immediate BCP implication after Backtracking. As will be shown in §4.2.4, NeuralSAT will backtrack to level 3 and erases all assignments after this level (so the assignment 𝑣5@3is not erased, but assignments after level 3 are erased). Then, BCP will find that 𝑐5is a unit clause because 𝑣5@3 and infers𝑣1. Once obtaining the asserting clause, AnalyzeConflict stops the search, and NeuralSAT adds𝑣1∨𝑣5as the new clause 𝑐5to the set of existing four clauses. The process of learning clauses allows NeuralSAT to learn from its past mistakes. While such clauses are logically implied by the formula in Eq. 4 and therefore do not change the result, they help prune the search space and allow DPLL and therefore NeuralSAT to scale. For example, after learning the clause 𝑐5, together with assignment 𝑣5@3, we immediately infer 𝑣1↦→𝐹through BCP instead of having to guess through Decide. 4.2.4 Backtrack. From the clause returned by AnalyzeConflict ,Backtrack (Fig. 4, line 12) computes a backtracking level and erases all decisions and implications made after that level. If the clause is unary (containing just a single literal), then we backtrack to level 0. Currently, NeuralSAT uses the standard conflictdrive backtracking strategy [Barrett 2013], which sets the backtracking level to the second most recent decision level in the clause. Intuitively, by backtracking to the second most recent level, which means erasing assignments made after that level, this strategy encourages trying new assignments for more recently decided variables. Example. From the clause 𝑐5=𝑣1∨𝑣5learned in AnalyzeConflict, we backtrack to decision level 3, the second most recent decision level in the clause (because assignments 𝑣1@6and𝑣5@3were decided at levels 6 and 3, respectively). Next, we erase all assignments from decision level 4 onward (i.e., the assignments to 𝑣1,𝑣2,𝑣3,𝑣4as shown in the implication graph in Fig. 5). This thus makes these more recently assigned variables (after decision level 3) available for new assignments (in fact, as shown by the example in §4.2.2, BCP will immediately infer 𝑣1=𝑇by noticing that 𝑐5is now a unit clause). 4.3 Deduction (Theory Solving) Deduce (Fig. 4, line 8) is the theory solver, i.e., the T in DPLL(T). The main purpose of the theory solver is to check the feasibility of the constraints represented by the current propositional variable assignment; as shown in the formalization in §5 this amounts to just linear equation solving for verifying piecewise linear DNNs. However, NeuralSAT is able to leverage specific information from the DNN problem, including input and output properties, for more aggressive feasibility checking. Specifically, Deduce has three tasks: (i) checking feasibility using linear programming (LP) solving, (i) further checking feasibility with input tightening and abstraction, and (iii) inferring literals that are unassigned and are implied by the abstracted constraint. 10A DPLL(T) Framework for Verifying Deep Neural Networks input : current assignment 𝜎and decision level 𝑑𝑙, DNN𝛼, input property 𝜙𝑖𝑛, output property 𝜙𝑜𝑢𝑡 output : false if infeasibility occurs, true otherwise 1solver =new LPSolver(solver,𝛼,𝜎∧𝜙𝑖𝑛∧𝜙𝑜𝑢𝑡) 2ifSolve(solver)≡INFEASIBLE then return false 3ifisTotal(𝜎)then 4 return true // orig prob (Eq. 4) is satisfiable 5input_bounds =TightenInputBounds (solver,𝜙𝑖𝑛) 6output_bounds ,hidden_bounds =Abstract(𝛼,𝜎, input_bounds ) 7ifCheck(output_bounds ,𝜙𝑜𝑢𝑡)≡INFEASIBLE then 8 return false 9for𝑣∈hidden_bounds do 10𝑥←ActivationStatus (𝑣) 11 if𝑥∈𝜎∨¬𝑥∈𝜎then continue 12 ifLowerBound(𝑣)>0then𝜎←𝜎∪𝑥@𝑑𝑙 13 else if UpperBound(𝑣)≤0then𝜎←𝜎∪𝑥@𝑑𝑙 14return true Fig. 7. Deduce Fig. 7 describes Deduce , which returns False if infeasibility occurs and True otherwise. First, it creates a linear constraint system from the input assignment 𝜎and𝛼∧𝜙𝑖𝑛∧𝜙𝑜𝑢𝑡, i.e., the formula in Eq. 4 representing the original problem (line 1). The key idea is that we can remove ReLU activation for hidden neurons whose activation status have been decided. For constraints in 𝛼associated with variables that are not in the 𝜎, we ignore them and just consider the cutting planes introduced by the partial assignment. For example, for the assignment 𝑣3↦→𝑇,𝑣 4↦→𝐹, the nonlinear ReLU constraints𝑥3=𝑅𝑒𝐿𝑈(−0.5𝑥1+0.5𝑥2+1)and𝑥4=𝑅𝑒𝐿𝑈(𝑥1+𝑥2−1)for the DNN in Fig. 2 become linear constraints 𝑥3=−0.5𝑥1+0.5𝑥2and𝑥4=0, respectively. Next, an LP solver checks the feasibility of the linear constraints (line 2). If the solver returns infeasible, Deduce returns False so that NeuralSAT can analyze the assignment and backtrack. If the constraints are feasible, then there are two cases to handle. First, if the assignment is total (i.e., all variables are assigned), then that means that the original problem is satisfiable (line 4) and NeuralSAT returns sat. ReLU Abstraction. Second, if the assignment is not total then Deduce applies abstraction to check satisfiability (lines 5–8). Specifically, we overapproximate ReLU computations to obtain the upper and lower bounds of the output values and check if the output properties are feasible with respect to these bounds. For example, the output 𝑥5>0isnotfeasible if the upperbound is 𝑥5≤0and might be feasible if the upperbound is 𝑥5≤0.5(“might be” because this is an upperbound). If abstraction results in infeasibility, then Deduce returns False forNeuralSAT to analyze the current assignment (line 8). NeuralSAT uses abstraction to approximate the lower and upper bounds of hidden and output neurons. Fig. 8 compares the interval [Wang et al .2018b] (a), zonotope [Singh et al .2018a] (b), and polytope [Singh et al .2019b; Wang et al .2021; Xu et al .2020] (c,d) abstraction domains to compute the lower 𝑙𝑦(𝑥)and upper𝑢𝑦(𝑥)bounds of a ReLU computation 𝑦=ReLU(x) (nonconvex red line). NeuralSAT can employ any existing abstract domains, though currently it adopts the LiRPA polytope (Fig. 8c) [Wang et al .2021; Xu et al .2020] because it has a good tradeoff between precision and efficiency. 11Hai Duong, Linhan Li, ThanhVu Nguyen, and Matthew B. Dwyer (a) interval  (b) zonotope  (c) LiRPA  (d) DeepPoly Fig. 8. Abstractions for ReLU: (a) interval, (b) zonotope, (c) LiRPA polytope, and (d) DeepPoly polytope. Notice that ReLU is a nonconvex region (red line) while all abstractions are convex regions Note that in some cases we can compute a better abstraction for output bounds by first tightening the input bounds (line 5). We discuss this input bound tightening heuristic in §4.4.1. Inference. If abstraction results in feasible constraints, Deduce next attempts to infer implied literals (lines 9– 13). To obtain the bounds of the output neurons, abstraction also needs to compute the bounds of hidden neurons, including those with undecided activation status (i.e., not yet in𝜎). This allows us to assign the activation variable of a hidden neuron the value True if the lowerbound of that neuron is greater than 0 (the neuron is active) and False otherwise. Since each literal is considered, this would be considered exhaustive theory propagation. Whereas the literature [Kroening and Strichman 2016; Nieuwenhuis et al .2006] suggests that this is an inefficient strategy, we find that it does not incur significant overhead (average overhead is about 4% and median is 2% with outliners being large CIFAR2020 networks described in §6). Example. For the illustrative example in §3.1, in iteration 3, the current assignment 𝜎is{𝑣4=1}, corresponding to a constraint 𝑥1+𝑥2−1>0. With the new constraint, we optimize the input bounds and compute the new bounds for hidden neurons 0.5≤𝑥3≤2.5,0<𝑥4≤2.0and output neuron𝑥5≤0.5(and use this to determine that the postcondition 𝑥5>0might be feasible). We also infer𝑣3=1because of the positive lower bound 0.5≤𝑥3. 4.4 Optimizations NeuralSAT implements several optimizations to quickly deal with ""easy"" problems, such as those with small input sizes or can be easily disproved (of course NeuralSAT does not know this in advance, it just tries the heuristics in hope that it could help). As we will see in §7, these techniques are also employed by many current stateoftheart DNN verification tools. 4.4.1 Input Bounds Tightening. For networks with small inputs (currently set to those with ≤50 inputs), NeuralSAT uses a more aggressive abstraction process in the theory solver described in §4.3. Specifically, we use LP solving to compute the tightest bounds for all input variables from the generated linear constraints. This computation is efficient when the number of inputs is small. After tightening input bounds we apply abstraction (line 6, Fig. 7) to approximate the output bounds, which can be more precise with better input bounds. For networks with large number of inputs, we obtain input bounds from the input property 𝜙𝑖𝑛. 4.4.2 Decision Heuristics. Decision or branching heuristics decide free variables to make assign ments and thus are crucial for the scalability of DPLL by reducing assignment mistakes [Beyer 2022; Kroening and Strichman 2016]. NeuralSAT currently adopts two decision heuristics. 12A DPLL(T) Framework for Verifying Deep Neural Networks For networks with small inputs, NeuralSAT prioritizes variables representing neurons with the furthest bounds from the decision value 0 of ReLU, i.e., the 0 in max(𝑥,0). Such neurons have wider bounds and therefore are more difficult to tighten during abstraction compared to other neurons. This heuristic helps input bounds tightening as described in §4.4.1 (which is also applied only for networks with small inputs). It is also cheap because we can reuse the computed boundaries of hidden neurons during abstraction. For other networks, NeuralSAT applies the Filtered Smart Branching (FSB) heuristic [Bunel et al . 2018; De Palma et al .2021]. For each unassigned variable, FSB assumes that it has been decided (i.e., the corresponding neuron has been split) and computes a fast approximation of the lower and upperbounds of the network output variables. FSB then prioritizes unassigned variables with the best differences among the bounds that would help make the input formula unsatisfiable (which helps prove the property of interest). We note that several wellknown DNN verification techniques and tools [OVALgroup 2023; Wang et al .2021] use variants of FSB with slight difference on the approximation computation. 4.4.3 Multiprocessing. For networks with small inputs, NeuralSAT uses a simple approach to create and solve subproblems in parallel. Given a verification problem 𝑁𝑜𝑟𝑖𝑔=(𝛼,𝜙𝑖𝑛,𝜙𝑜𝑢𝑡), where𝛼is the DNN and𝜙𝑖𝑛⇒𝜙𝑜𝑢𝑡is the desired property, NeuralSAT creates subproblems 𝑁𝑖=(𝛼,𝜙𝑖𝑛𝑖,𝜙𝑜𝑢𝑡), where𝜙𝑖𝑛𝑖is the𝑖th subregion of the input region specified by 𝜙𝑖𝑛. Intuitively, each subproblem checks if the DNN produces the output 𝜙𝑜𝑢𝑡from a smaller input region 𝜙𝑖𝑛𝑖. The combination of these subpropertiesÓ𝜙𝑖𝑛𝑖⇒𝜙𝑜𝑢𝑡is logically equivalent to the original property 𝜙𝑖𝑛⇒𝜙𝑜𝑢𝑡. Given𝑘available threads, NeuralSAT splits the original input region to obtain subproblems as described and and runs DPLL(T) on 𝑘subproblems in parallel. NeuralSAT returns unsat if it verifies all subproblems and satif it found a counterexample in any subproblem. For example, we split the input region {𝑥1∈[− 1,1],𝑥2∈[− 2,2]}into four subregions {𝑥1∈[− 1,0],𝑥2∈[− 2,0]}, {𝑥1∈[− 1,0],𝑥2∈[0,2]},{𝑥1∈[0,1],𝑥2∈[− 2,0]}, and{𝑥1∈[0,1],𝑥2∈[0,2]}. Note that the formula−1≤𝑥1≤1∧−2≤𝑥2≤2representing the original input region is equivalent to the formula(−1≤𝑥1≤0∨0≤𝑥≤1)∧(− 2≤𝑥2≤0∨0≤𝑥2≤2)representing the combination of the created subregions. 4.4.4 Falsification using Adversarial Attacks. Our NeuralSAT tool attempts to disprove or falsify the property before running DPLL(T). This helps solve ""easy"" cases when the properties can be disproved easily and adopted by many stateoftheart DNN verification tools such as ERAN [Müller et al. 2022] and 𝛼𝛽CROWN [Zhang et al. 2022]. NeuralSAT uses two adversarial attack algorithms to find counterexamples to falsify properties. First, we try a randomized attack approach [Das et al .2021], which is a derivativefree sampling based optimization [Yu et al .2016], to generate a potential counterexample. If this approach fails, we then use a gradientbased approach [Madry et al .2017] to create another potential counterexample. If either attack algorithm gives a valid counterexample, NeuralSAT returns sat, indicating that property is invalid. If both algorithms cannot find a valid counterexample or they exceed a predefined timeout, NeuralSAT continues with its DPLL(T) search. 5NEURALSAT DPLL(T) FORMALIZATION In §4 we describe NeuralSAT and its optimizations, here we formalize the NeuralSAT DPLL(T) framework. By abstracting away heuristics, optimizations, and implementation details, we can focus on the core NeuralSAT algorithm and establish its correctness and termination properties. NeuralSAT can be described using the states and transition rules of the standard DPLL(T) framework described in [Nieuwenhuis et al .2006] and therefore inherits the theoretical results established there. We also highlight the differences between NeuralSAT and standard DPLL(T), but 13Hai Duong, Linhan Li, ThanhVu Nguyen, and Matthew B. Dwyer these differences do not affect any of the main results. The section aims to be selfcontained, but readers who are familiar with the work in [Nieuwenhuis et al. 2006] can quickly skim through it. 5.1 Preliminaries Formulae, Theory, and Satisfiability. Let𝑃be a finite set of atoms (e.g., linear constraints in our context). For an atom 𝑝∈𝑃,𝑝is a positive literal and ¬𝑝is a negative literal of 𝑃. Aclause is a set of literals and a CNF formula is a set of clauses. A model 𝑀is a sequence of literals and never contains both a literal and its negation. A literal𝑙istrue in𝑀if𝑙∈𝑀, isfalse in𝑀if¬𝑙∈𝑀, and is undefined otherwise (i.e., 𝑙∉𝑀). 𝑀istotal if every atom 𝑝∈𝑃has a literal in 𝑀, and is partial otherwise. A clause 𝐶is true in𝑀, written as𝑀|=𝐶, if∃𝑙∈𝐶.𝑙∈𝑀, and is false in 𝑀, written as𝑀|=¬𝐶, if∀𝑙∈𝐶.¬𝑙∈𝑀. A CNF 𝐹is true in (or satisfied by) 𝑀, written as𝑀|=𝐹, if all clauses of 𝐹are true in𝑀. In that case, 𝑀is called a model of𝐹. If F has no models then it is unsatisfiable . If𝐹and𝐹′are formulae, then 𝐹entails 𝐹′, written as 𝐹|=𝐹′, if𝐹′is true in all models of 𝐹. Note that we consider literals and clauses as purely boolean variables and check satisfiability using propositional logic (we could also treat literals as syntactical items and check satisfiability using set operations, e.g., 𝑀|=𝐶is𝐶∩𝑀≠∅). A theory T is a set of formulas. A formula F is Tsatisfiable orTconsistent if𝐹∧𝑇is satisfiable. Otherwise, it is called Tunsatisfiable orT inconsistent . An assignment 𝑀can be thought as a conjunction of its literals and hence as a formula. If 𝑀is a Tconsistent and 𝐹is a formula such that 𝑀|=𝐹, then𝑀is also a Tmodel of F, written as 𝑀|=𝑇𝐹. If F and G are formulae, then F entails G in T , written 𝐹|=𝑇𝐺if𝐹∧¬𝐺is Tinconsistent. Note when checking satisfiability in the theory, i.e.,|=𝑇, we use a theory solver to reason about the linear constraints represented by the literals. NeuralSAT Algorithm. ForNeuralSAT , each atom 𝑝𝑖in𝑃={𝑝1,𝑝2,...,𝑝𝑁}is the linear constraint representing activation status of neuron 𝑖, e.g., for the DNN example in Fig. 2, 𝑝3 is−0.5𝑥1+0.5𝑥2+1>0, the constraint that neuron 𝑥3is active (thus 𝑝3is a positive literal and ¬𝑝3is a negative literal). 𝑀represents the (partial) truth assignment 𝜎, and𝐹represents the set or conjunction of clauses that NeuralSAT needs to satisfy. Adding 𝑙to𝑀is the truth assignment 𝑝↦→𝑇if𝑙is𝑝, and is the assignment 𝑝↦→𝐹if𝑙is¬𝑝. Moreover, the theory we consider is LRA (Linear Real Arithmetic) and our customized Tsolver, described in 4.3 uses LP solving and abstraction to decide satisfiability of DNN properties. Note that in NeuralSAT we use Boolean Abstraction to create variables 𝑣𝑖to represent linear constraints capturing activation status. Here we do not use Boolean Abstraction and capture its effects with atoms 𝑝𝑖representing the Boolean variables 𝑣𝑖and adding to 𝑀the literals𝑝𝑖,¬𝑝𝑖 corresponding to truth assignments 𝑣𝑖↦→𝑇,𝑣𝑖↦→𝐹in𝜎, respectively. 5.2 Transition Rules We formalize the NeuralSAT DPLL(T) using transition rules that move from a state to another state of the algorithm. A state is either a assignment 𝑀and a CNF formula 𝐹, written as 𝑀∥𝐹, or the special state Fail , which indicates that the formula is unsatisfiable. We write 𝑆=⇒𝑆′as a transition from state 𝑆to𝑆′. We write𝑆=⇒∗𝑆′to indicate any possible transition from 𝑆to𝑆′ (i.e., reflexivetransitive closure). In a state 𝑀∥𝐹,𝐶, we say the clause 𝐶is conflicting if 𝑀|=¬𝐶. Tab. 2 gives the conditional transition rules for NeuralSAT .Decision literals, written with suffix 𝑙𝑑, are nondeterministically decided (i.e., guessed), while other literals are deduced deterministically through implication. Intuitively, mistakes can happen with decision literals and require backtracking. In contrast, rules that add nondecision literals help prune the search space. The rules Decide, BCP, Fail describe transitions that do not rely on theory solving. Decide non deterministically selects and adds an undefined literal 𝑙to𝑀(i.e.,𝑙is a decision literal and can be backtracked to when conflict occurs). BCP (or UnitPropagate) infers and adds the unit literal 𝑙to𝑀 14A DPLL(T) Framework for Verifying Deep Neural Networks Tab. 2. Transition rules for NeuralSAT DPLL(T) solver. Rule From To ConditionStandard DPLLDecide 𝑀∥𝐹−→𝑀𝑙𝑑∥𝐹 if( 𝑙∉𝑀 𝑙or¬𝑙occurs in𝐹 BCP 𝑀∥𝐹, 𝐶∨𝑙−→𝑀𝑙∥𝐹, 𝐶∨𝑙if( 𝑙∉𝑀 𝑀|=¬𝐶 Fail 𝑀∥𝐹, 𝐶−→ Fail if( 𝑀contains no decision literals 𝑀|=¬𝐶Theory SolvingTBackjump 𝑀𝑙𝑑𝑁∥𝐹, 𝐶−→𝑀𝑙′∥𝐹, 𝐶 if  𝑀𝑙𝑑𝑁|=¬𝐶,and∃𝐶′∨𝑙′. (𝐹,𝐶|=𝑇𝐶′∨𝑙′)∧(𝑀|=¬𝐶′) 𝑙′∉𝑀 𝑙′or¬𝑙′occurs in𝐹or in𝑀𝑙𝑑𝑁 TLearn 𝑀∥𝐹−→𝑀∥𝐹, 𝐶 if( each atom of 𝐶occurs in𝐹or𝑀 𝐹|=𝑇𝐶 TheoryPropagate 𝑀∥𝐹−→𝑀𝑙∥𝐹 if  𝑙∉𝑀 𝑙or¬𝑙occurs in𝐹 𝑀|=𝑇𝑙 to satisfy the clause 𝐶∨𝑙, where𝑀|=¬𝐶.Failmoves to a Fail state (i.e.,𝐹is unsatisfiable) when a conflicting clause 𝐶occurs and𝑀contains no decision literals to backtrack to. The rules TLearn, TForget, TBackjump, TheoryPropagate describe transitions that rely on theory solving, e.g.,|=𝑇.TBackjump analyzes a conflicting clause 𝐶to determine an ""incorrect"" decision literal𝑙𝑑and computes a ""backjump"" clause 𝐶′∨𝑙′(which will be used by Tlearn to ensure that the incorrect decision literal 𝑙will not be added to 𝑀in the future). The rule also adds 𝑙′to𝑀(since 𝑀|=¬𝐶′) and removes 𝑙𝑑and the set𝑁of subsequent literals added to 𝑀after𝑙𝑑(i.e., it backtracks and removes the ""incorrect"" decision 𝑙𝑑and subsequent assignments). TLearn strengthens 𝐹with a clause C that is entailed by 𝐹(i.e., learned clauses are lemmas of𝐹). As mentioned, clause 𝐶is the ""backjumping"" clause 𝐶′∨𝑙′inTBackjump . Finally, TheoryPropagate infers literals that are Tentailed by literals in 𝑀(thus𝑙is a nondecision literal). NeuralSAT Algorithm. The Decide and BCP rules align to the Decide and BCP components of NeuralSAT , respectively. The other rules are also implemented in NeuralSAT through the interac tions of Deduction, AnalyzeConflict, and Backtrack components. For example, the TBackjump rule is implemented as part of Deduction and AnalyzeConflict. Also note that while implication graph is a common way to detect conflicts and derive backjumping clause, it is still an implementation detail and therefore not mentioned in TBackjump (which states there exists a way to obtain a backjumping clause). TLearn, which adds lemmas to existing clauses, is achieved in the main loop of the NeuralSAT algorithm (Fig. 4, line 13). TheoryPropagate is implemented as part of Deduction (Fig. 7, lines 9–13). Finally, theory solving , i.e., |=𝑇, is implemented in Deduction by using LP solving and abstraction to check satisfiability of linear constraints. 15Hai Duong, Linhan Li, ThanhVu Nguyen, and Matthew B. Dwyer Note that DPLL and DPLL(T) algorithms used in modern SAT and SMT solvers often include Restart and TForget rules, which remove learned clauses periodically. To date, we have not seen the need for these in NeuralSAT , but they could easily be incorporated. 5.3 Termination and Correctness of NeuralSAT DPLL(T) In §5.2 we describe NeuralSAT DPLL(T) using transition rules of the standard DPLL(T) approach. This allows us to establish the the formal properties NeuralSAT DPLL(T), which are similar to those of standard DPLL(T). Below we summarize the main results and refer the readers to [Nieuwenhuis et al. 2006] for complete proofs. Note that the work in [Nieuwenhuis et al. 2006] covers multiple variants of DPLL with various rule configurations. Here we focus on the DPLL(T) of NeuralSAT , e.g., no Restart and Forget. This significantly simplify our demonstration of termination and correctness of NeuralSAT DPLL(T). We first establish several invariants for the transition rules of NeuralSAT DPLL(T). Lemma 5.1. If∅∥𝐹=⇒∗𝑀∥𝐺, then the following hold: (1) All atoms in 𝑀and all atoms in 𝐺are atoms of 𝐹. (2)𝑀is indeed an assignment, i.e., it contains no pair of literals 𝑝and¬𝑝. (3)𝐺is equivalent to 𝐹in the theory T. All properties hold trivially in the initial state ∅ ∥𝐹, so we will use induction to show the transition rules preserve them. Consider a transition 𝑀′∥𝐹′=⇒𝑀′′∥𝐹′′. Assume the properties hold for𝑀∥𝐹. Property 1 holds because the only atoms can be added to 𝑀′′and𝐹′′are from𝑀′ and𝐹′, all of which belong to 𝐹. Property 2 preserves the requirement that 𝑀never shares both negative and positive literals of an atom (the condition of each rule adding a new literal ensures this). Property 3 holds because only TLearn rule can modify 𝐹′, but learning a clause 𝐶that is a logical consequence of 𝐹′(i.e.,𝐹′|=𝑇𝐶) will preserve the equivalence between 𝐹′and𝐹′′. Lemma 5.2. If∅∥𝐹=⇒∗𝑆, and𝑆is final state, then 𝑆is either Fail, or of the form 𝑀∥𝐹′, where 𝑀is a Tmodel of 𝐹. This states that if 𝑀|=𝐹′then𝑀|=𝐹. This is true because 𝐹and𝐹′are logical equivalence by Lemma 5.1(3). Now we prove that NeuralSAT DPLL(T) terminates . Theorem 5.3 (Termination). Every derivation∅∥𝐹=⇒𝑆1=⇒...is finite. This proof uses a wellfounded strict partial ordering on states𝑀∥𝐹. First, consider the case without TLearn, in which only the assignment M is modified and the formula F remains constant. Then we can show no infinite derivation by (i) using Lemma 5.1(1,2) that the number of literals in M and M’ are always less than or equal to the number of atoms in F and (ii) show that the number of ""missing"" literals of M is strictly greater than those of M’. Now, consider the case with Tlearn. While F’ can now be modified, i.e., learning new clauses, the number of possible clauses can be added to𝐹′is finite as clauses are formed from a finite set of atoms and the conditions of Tlearn disallow clause duplication. Note that if NeuralSAT involved the Restart and Forget rules, which periodically remove learned clauses, then its termination argument becomes more complicated (but still holds) as shown in the work [Nieuwenhuis et al. 2006]. Now we prove that NeuralSAT DPLL(T) is sound andcomplete . Theorem 5.4. If∅∥𝐹=⇒∗𝑆where the state S is final, then (1)Sound : S is Fail if, and only if, F is Tunsatisfiable 16A DPLL(T) Framework for Verifying Deep Neural Networks Tab. 3. Benchmark instances. U: unsat , S:sat, ?:unknown . BenchmarksNetworks Per Network Tasks Type Networks Neurons Params Props. Inst. U/S/? ACAS Xu FNN 45 FNNs 300 13305 10 139/47/0 MNISTFCMNIST_256x2 512 269322 30 18/12/0 FNN MNIST_256x4 1024 400906 30 20/6/4 MNIST_256x6 1536 532490 30 16/5/9 CIFAR2020CIFAR10_2_255 49402 2133736 82 65/13/4 CNN CIFAR10_8_255 16634 2118856 56 30/22/4 ConvBigRELU 62464 2466864 65 53/8/4 RESNET_A CNN+ResNet RESNET_3B2_ADV 11364 354486 72 20/12/40 RESNET_B CNN+ResNet RESNET_3B2_SSADV 11364 354486 72 28/11/33 Total 53 447 389/136 /98 (2)Complete : If𝑆is of the form 𝑀∥𝐹′, then𝑀is a Tmodel of 𝐹. Property 1 states that NeuralSAT DPLL(T) ends at Fail state iff the problem F is unsatisfiable. Property 2 asserts that if NeuralSAT DPLL(T) ends with an assignment 𝑀, then𝑀is the model of𝐹, i.e,𝐹is satisfiable. This property requires showing that if 𝑀|=𝑇𝐹′, then𝑀|=𝑇𝐹, which is established in Lemma 5.2. Together, these properties of soundness, completeness, and termination make NeuralSAT DPLL(T) a decision procedure. Note that the presented results are independent from the theory under con sideration. The main requirement of Tsolver is its decidability for Tsatisfiability or Tconsistency checking. NeuralSAT uses LRA, a theory of real numbers with linear constraints, including linear equalities and inequalities, which is decidable [Kroening and Strichman 2016]. 6 IMPLEMENTATION AND EXPERIMENTAL SETTINGS Implementation. NeuralSAT is written in Python, and uses PyTorch [Paszke et al .2019] for matrix multiplications and Gurobi [Gurobi Optimization, LLC 2022] for linear constraint solving. We use the LiRPA abstraction library [Wang et al .2021; Xu et al .2020] for bounds approximation and tightening and adapt the randomized [Das et al .2021] and Projected Gradient Descent (PGD) [Madry et al . 2017] adversarial attack techniques for falsification. Note that unlike some other DNN verifiers, NeuralSAT does not require hyperparameter tuning and all of our experiments use its default settings. Currently, NeuralSAT supports feedforward (FNN), convolutional (CNN), and Residual Learning Architecture (ResNet) neural networks that use ReLU. NeuralSAT automatically preprocesses these networks into Boolean variables and linear constraints representing the computation graph of the networks for DPLL(T). This preprocessing step is relatively standard and is used by various tools (e.g.,𝛼𝛽CROWN ,ERAN ,MNBaB ). Moreover, NeuralSAT supports the specification formats ONNX [Bai et al .2023] for neural networks and VNNLIB [Tacchella et al .2023] for properties. These formats are standard and supported by major DNN verification tools. Benchmarks. We evaluate NeuralSAT using five standard, ReLUbased benchmarks obtained VNNCOMP’22 and shown in Tab. 3. In total these benchmarks consist of 53 networks, spanning multiple layer types and architectures, and 447 correctness properties. A problem instance pairs a 17Hai Duong, Linhan Li, ThanhVu Nguyen, and Matthew B. Dwyer property with a network. Across the benchmark 389 problem instances are known to be unsat (U) and 136 are known to be sat(S). For the remaining 98 problem instances no verifier in our study or in VNNCOMP’22 was able to solve the problem. We do not include these unknown (?) problem instances in our study since they add no value in our comparative evaluation of DNN verifier performance. ACAS Xu consists of 45 FNNs to issue turn advisories to aircrafts to avoid collisions. Each FNN has 5 inputs (speed, distance, etc). We use all 10 safety properties as specified in [Katz et al .2017a] and VNNCOMP’22, where properties 1–4 are used on 45 networks and properties 5–10 are used on a single network. MNISTFC consists of 3 FNNs for handwritten digit recognition and 30 robustness properties. Each FNN has 28x28 inputs representing a handwritten image. CIFAR2020 has 3 CNNs for objects detection and 203 robustness properties (each CNN has a set of different properties). Each network uses 3x32x32 RGB input images. For RESNET_A/B , each benchmark has only one network with the same architecture and 72 robustness properties. Each network uses 3x32x32 RGB input images. Tab. 3 provides more details. Column Instances (U/S/?) shows the number of verification instances and U/S/? indicate the number of instances that are unsat (valid property), sat(invalid property), and unknown (cannot be solved by any tools and we also do not know if it is sator unsat ), e.g., CIFAR10_2_255 has 82 instances (65 unsat , 13sat, and 4 unknown ). The last two columns give the sizes of individual networks: neurons are the numbers of hidden neurons and parameters are the numbers of weights and biases. For example, each FNN in ACAS Xu has 5 inputs, 6 hidden layers (each with 50 neurons), 5 outputs, and thus has 300 neurons ( 6×50) and 13305 parameters ( 5×50×50+2×50×5+6×50+5). Observe that networks from ACAS Xu have very few inputs (5), which is leveraged by many DNN verification tools as shown in §7. Verification Tools. We compare NeuralSAT to six wellknown DNN verifiers. 𝛼𝛽CROWN [Wang et al.2021; Zhang et al .2022] employs multiple abstractions and algorithms for efficient analysis (input splitting for networks with small input dimensions and parallel BranchandBound [Bunel et al.2020] (BaB) otherwise). ERAN [Singh et al .2019a, 2018b, 2019b] uses input splitting optimizations with various abstractions. MNBaB uses multiple abstractions and BaB. Marabou’21 (VNNCOMP’21 version) and Marabou’22 (VNNCOMP’22 version) [Katz et al .2022, 2019] are a simplexbased solver that employs various optimizations such as parallel SplitandConquer [Wu et al .2020] (SnC) and uses polytope abstraction [Singh et al .2019b] and MILP/LPbased bound tightening. nnenum [Bak et al .2020] combines optimizations such as parallel case splitting and multiple levels of abstractions, e.g., three types of zonotopes with imagestar/starset [Tran et al. 2019]. Among tools competing in recent VNNCOMPs’21 [Bak et al .2021] and ’22 [Müller et al .2022], 𝛼𝛽CROWN ,MNBaB ,ERAN , and nnenum are consistently considered the top. For example, in VNN COMP’22,𝛼𝛽CROWN is the winner for MNISTFC and also the overall winner, MNBaB ranked 3rd on MNISTFC and second overall, and nnenum was the only one that can solve all instances in ACAS Xu and was 4th overall. Marabou’22 ranked 6th on MNISTFC and 7th overall. We also include Marabou’21 , which only participated in VNNCOMP’21 and ranks 5th overall, because it outperforms Marabou’22 in many cases as shown in §7. Hardware and Setup. Our experiments were run on a Linux machine with an AMD Threadripper 64core 4.2GHZ CPU, 128GB RAM, and a NVIDIA GeForce RTX 4090 GPU with 24 GB VRAM. All tools use multiprocessing (even external tools/libraries including Gurobi, LiRPA, and Pytorch are multithread). ERAN ,𝛼𝛽CROWN , and MNBaB leverage GPU processing for abstraction. The LiRPA library adopted by NeuralSAT uses the GPU for large benchmarks in MNISTFC, CIFAR2020 and RESNET. 18A DPLL(T) Framework for Verifying Deep Neural Networks To maximize the performance of the DNN verifiers in comparisons, we leverage the bench marks and installation scripts available from VNNCOMP (https://github.com/ChristopherBrix/ vnncomp2022_benchmarks). These scripts were tailored by the developers of each verifier to optimize performance on each benchmark. The VNNCOMP setting used varying runtimes for each problem instance ranging from 120 seconds to more than 12 minutes. We experimented with timeouts on our machine and settled on 200 seconds per instance which allowed the verifiers to achieve the scoring performance reported in VNNCOMP’22. For each benchmark instance we run three times and obtain the median results. 7 RESULTS We evaluate NeuralSAT using the following research questions: •(§7.1) How NeuralSAT compares to stateoftheart DNN verifiers? •(§7.2) How it compare to other tools in satand unsat instances? •(§7.3) How NeuralSAT compares to stateoftheart DPLL(T)based DNN verifiers? We note that in our experiments all tools provide correct results . If a tool was able to solve an instance, then it solves it correctly, i.e., no tool returned satforunsat instances and vice versa. 7.1 VNNCOMP Ranking We adopt the rules in VNNCOMP’22 to score and rank tools. This gives an overall view of how NeuralSAT compares to others in a VNNCOMP setting which accounts for both runtime and ability to solve problems. As mentioned in 6, we use the exact scripts from VNNCOMP’22 to setup and run this experiment. Scoring Rules. For each benchmark instance, a tool scores 10 points if it correctly verify an instance, 1 point if it correctly falsifies an instance4, 0 points if it cannot solve (e.g., timeouts, has errors, or returns unknown ), 100 points if it gives incorrect results (does not apply to any tool we consider), 2 points for being the fastest among other tools competing on that instance, 1 point for being the second fastest (runtime within a 0.2s differences are considered the same). Tab. 4 shows the results. Columns #andtool show the rankings of the tools. Note that for some tool do not work on certain benchmarks and therefore are not shown (e.g., for MNISTFC, MNBaB has errors for all problems). The next two columns give the scores andpercent , computed by the score of the tool divided by the highest score (thus the tool with the highest score always has 100%). The last three columns give additional statistics: the number of instances that a tool verified or falsified , and the number of those that the tool ran the fastest – tools with runtimes within 0.2 seconds of each other are considered tied. Across these benchmarks NeuralSAT ranks second to 𝛼𝛽CROWN , which was the top performer in VNNCOMP’22 and thus the stateoftheart. It trails 𝛼𝛽CROWN both in the number of problems verified and in the speed of verification, though it can falsify as many problems as any other verifier across the benchmark. A number of verifiers, e.g., Marabou’21 andnnenum , exhibit good performance on benchmarks with small networks – MNISTFC andACAS Xu – and outperform NeuralSAT . Our goal in developing NeuralSAT was to explore the potential for scaling constraintbased DNN verification andNeuralSAT ’s performance on the CIFAR2020 andRESNET benchmarks, which have networks with an order of magnitude more neurons, indicates the potential of the technique. While it ranks 4VNNCOMP’22 assigns different scores for falsification: 1 point if the tool found a counterexample using an external adversarial attack technique, and 10 points if the tool found a counterexample using its core search algorithm. It is difficult for us to determine how a tool solves individual SAT instances, so we simply assign 1 point for correct falsification results as our experiments in §7.2.1 show that most SAT instances were solved using adversarial attacks. 19Hai Duong, Linhan Li, ThanhVu Nguyen, and Matthew B. Dwyer Tab. 4. Across 5 benchmarks using 47 DNN verifiers ( Tool ) the Score , using Rules from VNNCOMPs, the ranking ( #) based on the score, and the percentage ( %) of top score are shown. For each benchmark, the number of problems verified ( Verify ), falsified ( Falsify ), and on which the tool was Fastest are shown. Benchmarks # Tool Score Percent Verify Falsify FastestACAS Xu1Marabou’21 1684 100.0% 138 46 118 2𝛼𝛽CROWN 1595 94.7% 139 46 46 3 nnenum 1557 92.5% 139 47 28 4NeuralSAT 1555 92.3% 136 47 41 5 ERAN 1473 87.5% 133 45 47 6 MNBaB 1118 66.4% 105 47 0 7Marabou’22 1040 61.8% 85 41 51MNISTFC1𝛼𝛽CROWN 707 100.0% 54 22 71 2 nnenum 428 60.5% 36 12 24 3 ERAN 407 57.6% 36 23 0 4NeuralSAT 381 53.9% 33 23 1 5Marabou’21 374 52.9% 35 20 1 6Marabou’22 307 43.4% 29 17 0CIFAR20201𝛼𝛽CROWN 1890 100.0% 148 42 179 2NeuralSAT 1638 86.7% 148 41 40 3 MNBaB 1515 80.2% 142 35 14 4 ERAN 1301 68.8% 114 43 1 5 nnenum 172 9.1% 16 12 0RESNET_A1𝛼𝛽CROWN 255 100.0% 20 12 12 2NeuralSAT 213 83.5% 17 12 12 3 MNBaB 183 71.8% 13 12 19 4 ERAN 92 36.1% 8 12 0RESNET_B1𝛼𝛽CROWN 342 100.0% 28 11 13 2NeuralSAT 306 89.5% 26 11 13 3 MNBaB 272 79.5% 21 11 24 4 ERAN 185 54.1% 16 11 0Overall1𝛼𝛽CROWN 4789 100.0% 389 133 321 2NeuralSAT 4093 85.5% 360 134 107 3 ERAN 3458 72.2% 307 134 48 4 MNBaB 3088 64.5% 281 105 57 5 nnenum 2157 45.0% 191 71 52 6Marabou’21 2058 43.0% 173 66 119 7Marabou’22 1347 28.1% 114 58 51 second to𝛼𝛽CROWN across those benchmarks it falsifies only 1 fewer property (64/65) and verifies 5 fewer (191/196). We note that the developers of 𝛼𝛽CROWN tuned 10 hyperparameters on average for each benchmark to optimize its performance. In contrast, NeuralSAT has no hyperparameters which suggests that its performance on large models may generalize better in practice. Compared to the other tools, NeuralSAT ranks second to and solves 97.7% of the large problem instances solved by the stateoftheart 𝛼𝛽CROWN . 20A DPLL(T) Framework for Verifying Deep Neural Networks Tab. 5. Results for satandunsat instances. Time are wallclock and in seconds. Each benchmark has two rows listing runtime (solved, unsolved) results for unsat andsatinstances.  means the tool cannot run the benchmark. BM Networks NeuralSAT ERAN MNBaB Marabou’21 Marabou’22 nnenum 𝛼𝛽CROWN ACAS Xu 45 FNNs551.5 (136, 3) 3867.8 (133, 6) 1251.0 (105, 34) 321.1 (138, 1) 533.4 (85, 54) 233.5 (139, 0) 335.5 (139, 0) 63.9 (47, 0) 811.9 (45, 2) 339.0 (47, 0) 75.4 (46, 1) 172.8 (41, 6) 62.9 (47, 0) 132.1 (46, 1) MNISTFCMNIST_256x2151.2 (18, 0) 315.0 (18, 0)  78.4 (17, 1) 430.7 (14, 4) 150.1 (17, 1) 74.6 (18, 0) 10.6 (12, 0) 67.6 (12, 0)  66.0 (12, 0) 85.0 (12, 0) 89.6 (12, 0) 1.5 (11, 1) MNIST_256x415.4 (7, 13) 303.8 (10, 10)  172.6 (10, 10) 30.8 (7, 13) 163.4 (11, 9) 783.3 (20, 0) 5.3 (6, 0) 8.9 (6, 0)  66.9 (6, 0) 346.3 (5, 1)  1.1 (6, 0) MNIST_256x619.7 (8, 8) 18.0 (8, 8)  42.9 (8, 8) 50.2 (8, 8) 26.3 (8, 8) 407.9 (16, 0) 4.6 (5, 0) 11.0 (5, 0)  162.2 (2, 3)   1.1 (5, 0) CIFAR2020CIFAR10_2_255726.1 (65, 0) 784.9 (51, 14) 820.9 (65, 0)    225.2 (65, 0) 15.9 (13, 0) 48.8 (13, 0) 274.3 (11, 2)    17.3 (13, 0) CIFAR10_8_255331.9 (30, 0) 1170.4 (21, 9) 380.7 (28, 2)   1238.4 (16, 14) 253.7 (30, 0) 24.1 (20, 2) 90.9 (22, 0) 87.1 (17, 5)   1730.7 (12, 10) 26.9 (21, 1) ConvBigRELU940.7 (53, 0) 813.4 (42, 11) 668.7 (49, 4)    349.6 (53, 0) 9.9 (8, 0) 33.3 (8, 0) 97.6 (7, 1)    9.9 (8, 0) RESNET_A 3B2_ADV383.7 (17, 3) 132.0 (8, 12) 177.6 (13, 7)    438.4 (20, 0) 14.6 (12, 0) 47.8 (12, 0) 14.0 (12, 0)    27.6 (12, 0) RESNET_B 3B2_SSADV678.4 (26, 2) 405.2 (16, 12) 302.1 (21, 7)    335.0 (28, 0) 13.5 (11, 0) 31.4 (11, 0) 12.5 (11, 0)    25.6 (11, 0) Tab. 6. VNNCOMP results for satinstances. BMs # Tool Score % Falsif. Fast.Overall1NeuralSAT 366 100.0% 134 104 2𝛼𝛽CROWN 341 93.2% 133 87 3 ERAN 233 63.7% 134 32 4 MNBaB 184 50.3% 105 31 5Marabou’22 90 24.6% 58 1 6Marabou’21 87 23.8% 66 3 7 nnenum 80 21.9% 71 2Tab. 7. VNNCOMP results for unsat instances BMs # Tool Score % Verif. Fast.Overall1𝛼𝛽CROWN 4448 100.0% 389 234 2NeuralSAT 3727 83.8% 360 3 3 ERAN 3225 72.5% 307 16 4 MNBaB 2904 65.3% 281 26 5 nnenum 2077 46.7% 191 50 6Marabou’21 1971 44.3% 173 116 7Marabou’22 1257 28.3% 114 50 7.2 SAT vs. UNSAT instances We show more details for the results presented in §7.1, focusing on the performance of tools forsatandunsat instances. Tab. 5 lists the runtime of each tool for each benchmark (median over 3 runs, as mentioned in §6). Each benchmark has two rows showing unsat andsatresults of each tools. The information given in these rows has the form runtime (# problems solved , # problems unsolved ). For example, for ACAS Xu, NeuralSAT took 551.5s, solved 136 unsat instances, and failed 3 unsat instances. The mark  indicates the tool fails to run the benchmark (e.g., both Marabou’21 andMarabou’22 cannot run CIFAR2020). 7.2.1 SAT instances. As shown in Tab. 5, tools are more successful in solving satthan unsat instances (i.e., the number of unsolved satinstances are often 0 or few for most tools). We also found that using external adversarial attacks or random counterexample generation as a quick and cheap way to find satisfying assignment is highly effective as expected. For example, out of the 136satinstances NeuralSAT successfully solved 134, all of which were solved using these quick techniques. We observe this behavior consistently across all tools on all benchmarks. Example of difficult SAT instances (i.e., cannot be solved easily using these random or attack methods) include properties 7 and 8 of ACAS Xu. Both 𝛼𝛽CROWN andMarabou’21 timed out for 21Hai Duong, Linhan Li, ThanhVu Nguyen, and Matthew B. Dwyer property 7 (but NeuralSAT solved it). NeuralSAT took around 34s over multiple DPLL(T) iterations to find a counterexample for property 8. In general, the effectiveness of falsification is mainly due to external techniques, and not part of the main algorithm of DNN verification tool (this explains why most modern tools, including NeuralSAT , runs these external techniques initially). Tab. 6 shows the VNNCOMP rankings over satinstances. Here, NeuralSAT ranked first, 𝛼𝛽CROWN second, and ERAN third. While all three tools was able to solve similar satinstances (133 and 134), NeuralSAT appears to solve them quicker (104 instances) and therefore had the most points. This is rather surprising as we, just like other tools, mainly rely on external adversarial techniques to generate counterexamples as described in §4. 7.2.2 UNSAT instances. Unlike satinstances that can be effectively handled by external techniques, unsat instances truly exercise the power of DNN verification algorithms. As shown in Tab. 5, solving unsat instances often take more time and result in more unsolved results. Both nnenum andMarabou’21 were heavily optimized for networks with small input dimensions. These tools performed well for ACAS Xu networks, e.g., nnenum solved all 139 unsat instances in ACAS Xu and while Marabou’21 solved 1 fewer unsat instances, it has the most fastest solved instances for ACAS Xu. However, these tools failed to run on the larger benchmarks CIFAR2020 or RESNET_A/_B. Note that 𝛼𝛽CROWN ,NeuralSAT ,ERAN also perform well in ACAS Xu because they all have heuristics in some way to leverage low dimension inputs. MNISTFC is difficult and has 10 unsat instances that no tool can solve. 𝛼𝛽CROWN used a MILP solver in a preprocessing step to tighten the bounds of all hidden neurons. This helps 𝛼𝛽CROWN to solve 20 difficult unsat instances on larger MNIST_256x4 and MNIST_256x6 networks that other tools failed. For other benchmarks CIFAR2020 and RESNET_A/B, 𝛼𝛽CROWN ranked first and NeuralSAT followed closely (solved 2 fewer unsat CIFAR2020 instances and 5 fewer RESNET). It is worth recalling that 𝛼𝛽CROWN has custom run scripts that on average tuned 10 hyperparmeters for each benchmark. Tab. 7 shows the VNNCOMP rankings over unsat instances. Here, 𝛼𝛽CROWN ranked first, NeuralSAT second, and ERAN third. Marabou’21 andMarabou’22 ranked last because they fail to run many benchmarks. In summary, for unsat , the overall ranking is consistent with the overall VNNCOMP ranking given in Tab. 4. 7.3 Comparison with DPLL(T)based DNN verification The stateoftheart in DPLL(T)based DNN verification is Marabou . It improves on Reluplex , incorporates abstraction and deduction techniques, and has been entered in VNNCOMP’22 in recent years. This makes it a reasonable point of comparison for NeuralSAT especially in understanding the benefit of the addition of CDCL on the scalability of DNN verification. Overall both versions of Marabou ranked poorly. While Marabou’21 is the best performer for ACAS Xu, which consists of networks with low input dimensions, it does not scale for larger benchmarks and often either cannot handle such networks (CIFAR2020, RESNET_A/B) or ranked last compared to other tools (MNIST). Below we consider the case of smaller and larger networks separately. Small networks. ACAS Xu networks are small in two ways. First, they have very few neurons (300). Second, they only have 5 input dimensions. Marabou’21 employs multiple optimizations to target the scale of these networks. For example, a variant of the Split and Conquer algorithm [Wu et al.2020] subdivides the input space to generate separate verification problems. Partitioning a 5 dimensional input space is one thing, but the number of partitions grows exponentially with input dimension and this approach is not cost effective for the other networks in the benchmarks. 22A DPLL(T) Framework for Verifying Deep Neural Networks Tab. 5 shows how for MNIST networks with larger input dimension (784) the performance of Marabou degrades with increasing number of neurons. As the network sizes increase the number of problems solved by Marabou’21 decreases – from 29, to 16, and then to 10. There is a similar reduction in problems solved, from 30 to 13, for NeuralSAT going from the 512 neuron MNIST network to the 1024 neuron network, but then there is no reduction in problems solved going from the 1024 to the 1536 neuron networks. This is due to the fact that the parameters of the 1536 neuron network define a set of theory constraints that can be efficiently overapproximated. In fact, NeuralSAT only takes a single iteration to prove this property and, consequently, other algorithmic features of NeuralSAT , such as CDCL, do not have a chance to show their benefit. Larger Networks. Marabou could not scale to any of the larger CIFAR2020 or RESNET problems, so a direct comparison with NeuralSAT is not possible. Instead, we observe that NeuralSAT performed well on these problems – ranking better than it did on the smaller problems. We conjecture that this is because problems of this scale give ample time for clause learning and CDCL to significantly prune the search performed by DPLL(T). Evidence for this can be observed in data on the learned clauses recorded during runs of NeuralSAT onunsat problems. Since NeuralSAT ’s propositional encodings have a number of variables proportional to the number of neurons ( 𝑛) in the network the effect of a learned clause of size 𝑐is that it has the potential to block a space of assignments of size2𝑛−𝑐. In other words, as problems grow the reduction through CDCL grows combinatorially. In the largest problem in the benchmarks, with 𝑛=62464 we see clauses on average of size 𝑐=16 which allows BCP to prune an enormous space of assignments – of size 262448. The ability of NeuralSAT to scale well beyond other DPLL(T) approaches to DNN verification suggests that other constraintbased DNN verification approaches may want to incorporate CDCL. 8 RELATED WORK","Deep Neural Networks (DNNs) have emerged as an effective approach for solving challenging real-world problems. However, they can also have ""bugs"", e.g., producing unexpected results on inputs that are different from those in training data, and be attacked, e.g., small perturbations to the inputs by a malicious adversary or even sensorial imperfections result in misclassification. To address this question, researchers have developed a variety of techniques and tools to verify DNNs. However, the state-of-of-of-",cool!
370,A Game-Based Approximate Verification of Deep Neural Networks with Provable Guarantees.txt,"Despite the improved accuracy of deep neural networks, the discovery of
adversarial examples has raised serious safety concerns. In this paper, we
study two variants of pointwise robustness, the maximum safe radius problem,
which for a given input sample computes the minimum distance to an adversarial
example, and the feature robustness problem, which aims to quantify the
robustness of individual features to adversarial perturbations. We demonstrate
that, under the assumption of Lipschitz continuity, both problems can be
approximated using finite optimisation by discretising the input space, and the
approximation has provable guarantees, i.e., the error is bounded. We then show
that the resulting optimisation problems can be reduced to the solution of
two-player turn-based games, where the first player selects features and the
second perturbs the image within the feature. While the second player aims to
minimise the distance to an adversarial example, depending on the optimisation
objective the first player can be cooperative or competitive. We employ an
anytime approach to solve the games, in the sense of approximating the value of
a game by monotonically improving its upper and lower bounds. The Monte Carlo
tree search algorithm is applied to compute upper bounds for both games, and
the Admissible A* and the Alpha-Beta Pruning algorithms are, respectively, used
to compute lower bounds for the maximum safety radius and feature robustness
games. When working on the upper bound of the maximum safe radius problem, our
tool demonstrates competitive performance against existing adversarial example
crafting algorithms. Furthermore, we show how our framework can be deployed to
evaluate pointwise robustness of neural networks in safety-critical
applications such as traffic sign recognition in self-driving cars.","Deep neural networks (DNNs or networks, for simplicity) have been devel oped for a variety of tasks, including malware detection [1], abnormal network activity detection [2], and selfdriving cars [3, 4, 5]. A classication network Ncan be used as a decisionmaking algorithm: given an input , it suggests a decisionN() among a set of possible decisions. While the accuracy of neural networks has greatly improved, matching the cognitive ability of humans [6], they are susceptible to adversarial examples [7, 8]. An adversarial example is an input which, though initially classied correctly, is misclassied after a minor, perhaps imperceptible, perturbation. Adversarial examples pose chal lenges for selfdriving cars, where neural network solutions have been proposed for tasks such as endtoend steering [3], road segmentation [4], and trac sign classication [5]. In the context of steering and road segmentation, an adver sarial example may cause a car to steer o the road or drive into barriers, and misclassifying trac signs may cause a vehicle to drive into oncoming trac. Figure 1 shows an image of a trac light correctly classied by a stateoftheart network, which is then misclassied after only a few pixels have been changed. Though somewhat articial, since in practice the controller would rely on ad ditional sensor input when making a decision, such cases strongly suggest that, before deployment in safetycritical tasks, DNNs' resilience (or robustness) to adversarial examples must be strengthened. Robustness of neural networks is an active topic of investigation and a num ber of approaches have been proposed to search for adversarial examples (see Related Work). They are based on computing the gradients [9], along which a heuristic search moves; computing a Jacobianbased saliency map [10], based on which pixels are selected to be changed; transforming the existence of ad versarial examples into an optimisation problem [11], on which an optimisation algorithm can be applied; transforming the existence of adversarial examples into a constraint solving problem [12], on which a constraint solver can be ap plied; or discretising the neighbourhood of a point and searching it exhaustively in a layerbylayer manner [13]. 2In this paper, we propose a novel gamebased approach for safety verica tion of DNNs. We consider two pointwise robustness problems, referred to as themaximum safe radius problem and feature robustness problem, respectively. The former aims to compute for a given input the minimum distance to an adversarial example, and therefore can be regarded as the computation of an absolute safety radius, within which no adversarial example exists. The latter problem studies whether the crafting of adversarial examples can be controlled by restricting perturbations to only certain features (disjoint sets of input di mensions), and therefore can be seen as the computation of a relative safety radius, within which the existence of adversarial examples is controllable. Both pointwise robustness problems are formally expressed in terms of non linear optimisation, which is computationally challenging for realisticallysized networks. We thus utilise Lipschitz continuity of DNN layers, which bounds the maximal rate of change of outputs of a function with respect to the change of inputs, as proposed for neural networks with dierentiable layers in [14, 15]. This enables safety verication by relying on Lipschitz constants to provide guaranteed bounds on DNN output for all possible inputs. We work with mod ern DNNs whose layers, e.g., ReLU, may not be dierentiable, and reduce the verication to nite optimisation. More precisely, we prove that under the as sumption of Lipschitz continuity [16] it is sucient to consider a nite number of uniformly sampled inputs when the distances between the inputs are small, and that this reduction has provable guarantees, in the sense of the error being bounded by the distance between sampled inputs. We then show that the nite optimisation problems can be computed as the solution of twoplayer turnbased games, where Player Iselects features and Player IIthen performs a perturbation within the selected features. After both players have made their choices, the input is perturbed and the game continues. While Player IIaims to minimise the distance to an adversarial example, Player Ican be cooperative orcompetitive . When it is cooperative, the optimal reward of Player Iis equal to the maximum safe radius. On the other hand, when it is competitive the optimal reward of Player Iquanties feature robustness. Finally, because the state space of the game models is intractable, we employ an anytime approach to compute the upper and lower bounds of Player Ioptimal reward. The anytime approach ensures that the bounds can be gradually, but strictly, improved so that they eventually converge. More specically, we apply Monte Carlo tree search algorithm to compute the upper bounds for both games, and Admissible A* and AlphaBeta Pruning, respectively, to compute the lower bounds for the games. We implement the method in a software tool DeepGame2, and conduct ex periments on DNNs to show convergence of lower and upper bounds for the maximum safe radius and feature robustness problems. Our approach can be congured to work with a variety of feature extraction methods that parti tion the input, for example image segmentation, with simple adaptations. For 2The software package is available from https://github.com/TrustAI/DeepGame 3the image classication networks we consider in the experiments, we employ both the saliencyguided greybox approach adapted from [17] and the feature guided black box method based on the SIFT object detection technique [18]. For the maximum safety radius problem, our experiments show that, on net works trained on the benchmark datasets such as MNIST [19], CIFAR10 [20] and GTSRB [21], the upper bound computation method is competitive with stateoftheart heuristic methods (i.e., without provable guarantees) that rely on whitebox saliency matrices or sophisticated optimisation procedures. Fi nally, to show that our framework is well suited to safety testing and decision support for deploying DNNs in safetycritical applications, we experiment on stateoftheart networks, including the winner of the Nexar trac light chal lenge [22]. The paper signicantly extends work published in [23], where the gamebased approach was rst introduced for the case of cooperative games and evaluated on the computation of upper bounds for the maximum safety radius problem using the SIFT feature extraction method. In contrast, in this paper we additionally study feature robustness, generalise the game to allow for the competitive player, and develop algorithms for the computation of both lower and upper bounds. We also give detailed proofs of the theoretical guarantees and error bounds. The structure of the paper is as follows. After introducing preliminaries in Section 2, we formalise the maximum safety radius and feature robustness problems in Section 3. We present our gamebased approximate verication approach and state the guarantees in Section 4. Algorithms and implementation are described in Section 5, while experimental results are given in Section 6. We discuss the related work in Section 7 and conclude the paper in Section 8. 2. Preliminaries LetNbe a neural network with a set Cof classes. Given an input and a classc2C, we useN(;c) to denote the condence (expressed as a probability value obtained from normalising the score) of Nbelieving that is in class c. Moreover, we write N() = arg max c2CN(;c) for the class into which N classies. We letP0be the set of input dimensions, n=jP0jbe the number of input dimensions, and remark that without loss of generality the dimensions of an input are normalised as real values in [0 ;1]. The input domain is thus a vector space D = [0;1]n: For image classication networks, the input domain D can be represented as [0;1]whch [0;255], wherew;h;ch are the width, height, and number of channels of an image, respectively. That is, we have P0=whch. We may refer to an element in whas a pixel and an element in P0as a dimension . We use[i] fori2P0to denote the value of the ith dimension of . 42.1. Distance Metric and Lipschitz Continuity As is common in the eld, we will work with Lkdistance functions to measure the distance between inputs, denoted jj","Deep neural networks (DNNs) have been developed for a variety of tasks, including malware detection, abnormal network activity detection, and self-driving cars. While the accuracy of DNNs has greatly improved, they are susceptible to adversarial examples, which pose a number of safety-critical challenges. In this paper, we propose a novel game-based approach for safety verification of DNNs. We consider two pointwise robustness problems, referred to as the maximum safe radius problem and feature robustness problem, respectively. We show that the",cool!
185,MOVE: Effective and Harmless Ownership Verification via Embedded External Features.txt,"Currently, deep neural networks (DNNs) are widely adopted in different
applications. Despite its commercial values, training a well-performed DNN is
resource-consuming. Accordingly, the well-trained model is valuable
intellectual property for its owner. However, recent studies revealed the
threats of model stealing, where the adversaries can obtain a function-similar
copy of the victim model, even when they can only query the model. In this
paper, we propose an effective and harmless model ownership verification (MOVE)
to defend against different types of model stealing simultaneously, without
introducing new security risks. In general, we conduct the ownership
verification by verifying whether a suspicious model contains the knowledge of
defender-specified external features. Specifically, we embed the external
features by tempering a few training samples with style transfer. We then train
a meta-classifier to determine whether a model is stolen from the victim. This
approach is inspired by the understanding that the stolen models should contain
the knowledge of features learned by the victim model. In particular, we
develop our MOVE method under both white-box and black-box settings to provide
comprehensive model protection. Extensive experiments on benchmark datasets
verify the effectiveness of our method and its resistance to potential adaptive
attacks. The codes for reproducing the main experiments of our method are
available at \url{https://github.com/THUYimingLi/MOVE}.","DEEPlearning, especially deep neural networks (DNNs), has been successfully adopted in widespread appli cations for its high effectiveness and efﬁciency [1], [2], [3]. In general, obtaining wellperformed DNNs is usu ally expensive for it requires welldesigned architecture, a large number of highquality training samples, and many computational resources. Accordingly, these models are the valuable intellectual properties of their owners. However, recent studies [4], [5], [6] revealed that the adversaries can obtain a functionsimilar copy model of the wellperformed victim model to ‘steal’ it. This attack is called model stealing . For example, the adversaries can copy the victim model directly if they can access its source ﬁles; Even when the victim model is deployed where the adversaries can only query the model, they can still steal it based on its predictions ( i:e:, labels or probabilities). Since the stealing process is usually costless compared with obtaining a welltrained victim model, model stealing poses a huge threat to the model owners. Currently, there are also some methods to defend against model stealing. In general, existing defenses can be roughly divided into two main categories, including the active de fenses and veriﬁcationbased defenses . Speciﬁcally, active de fenses intend to increase the costs ( e:g:, query times and ac Yiming Li, Linghui Zhu, and Yang Bai are with Tsinghua Shenzhen International Graduate School, Tsinghua University, Shenzhen, China (email: liym18@mails.tsinghua.edu.cn, zlh20@mails.tsinghua.edu.cn), y bai17@mails.tsinghua.edu.cn. Xiaojun Jia is with Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China (email: jiaxiaojun@iie.ac.cn). Yong Jiang, and ShuTao Xia are with Tsinghua Shenzhen International Graduate School, Tsinghua University, and also with the Research Center of Artiﬁcial Intelligence, Peng Cheng Laboratory, Shenzhen, China (email: jiangy@sz.tsinghua.edu.cn, xiast@sz.tsinghua.edu.cn). Xiaochun Cao is with School of Cyber Science and Technology, Sun Yatsen University, Shenzhen, China (email: caoxiaochun@mail.sysu.edu.cn).curacy decrease) of model stealing, while veriﬁcationbased defenses attempt to verify whether a suspicious model is stolen from the victim model. For example, defenders can introduce randomness or perturbations in the victim models [4], [7], [8] or watermark the victim model via (targeted) backdoor attacks or data poisoning [9], [10], [11]. However, existing active defenses may lead to poor performance of the victim model and could even be bypassed by advanced adaptive attacks [10], [11], [12]; the veriﬁcationbased meth ods target only limited simple stealing scenarios ( e:g:, direct copy or ﬁnetuning) and have minor effects in defending against more complicated model stealing. Besides, these methods also introduce some stealthy latent shortcuts (e:g:, hidden backdoors) in the victim model, which could be maliciously used. It further hinders their applications. Ac cordingly, how to defend against model stealing is still an important open question. In this paper, we revisit the veriﬁcationbased defenses against model stealing, which examine whether a suspicious model has defenderspeciﬁed behaviors. If the model has such behaviors, the defense treats it as stolen from the victim. We argue that a defense is practical if and only if it is both effective and harmless. Speciﬁcally, effectiveness requires that it can accurately identify whether the suspi cious model is stolen from the victim, no matter what model stealing is adopted; Harmlessness ensures that the model watermarking brings no additional security risks, i:e:, the model trained with the watermarked dataset should have similar prediction behaviors to the one trained with the benign dataset. We ﬁrst reveal that existing methods fail to meet all these requirements and their reasons. Based on the analysis, we propose to conduct model ownership veriﬁcation via embedded external features (MOVE), try ing to fulﬁll both two requirements. Our MOVE defensearXiv:2208.02820v1  [cs.CR]  4 Aug 2022PREPRINT 2 consists of three main steps, including 1) embedding exter nal features, 2) training ownership metaclassiﬁer, and 3) ownership veriﬁcation with hypothesistest. In general, the external features are different from those contained in the original training set. Speciﬁcally, we embed external features by tempering the images of a few training samples based onstyle transfer . Since we only poison a few samples and do not change their labels, the embedded features will not hinder the functionality of the victim model and will not create a malicious hidden backdoor in the victim model. Besides, we also train a benign model based on the original training set. It is used only for training the metaclassiﬁer to determine whether a suspicious model is stolen from the victim. In particular, we develop our MOVE method under both whitebox and blackbox settings to provide comprehensive model protection. The main contribution of this work is ﬁvefold: 1) We revisit the defenses against model stealing from the aspect of ownership veriﬁcation. 2) We reveal the limitations of ex isting veriﬁcationbased methods and their failure reasons. 3) We propose a simple yet effective ownership veriﬁcation method under both whitebox and blackbox settings. 4) We verify the effectiveness of our method on benchmark datasets under various types of attacks simultaneously and discuss its resistance to potential adaptive attacks. 5) Our work could provide a new angle about how to adopt the malicious ‘data poisoning’ for positive purposes. This paper is a journal extension of our conference paper [12]. Compared with the preliminary conference version, we have made signiﬁcant improvements and extensions in this paper. The main differences are from four aspects: 1) We rewrite the motivation of this paper to the signiﬁcance and problems of existing methods in Introduction to better clarify our signiﬁcance. 2) We generalize our MOVE from the whitebox settings to the blackbox settings in Section 5 to enhance its abilities and widen its applications. 3) We analyze the resistance of our MOVE to potential adaptive attacks and discuss its relations with membership inference and backdoor attacks in Section 7.3 and Section 7.4, respec tively. 4) More results and analysis are added in Section 6. The rest of this paper is organized as follows. We brieﬂy review related works, including model stealing and its defenses, in Section 2. After that, we introduce the prelimi naries and formulate the studied problem. In Section 4, we reveal the limitations of existing veriﬁcationbased defenses. We introduce our MOVE under both whitebox and black box settings in Section 5. We verify the effectiveness of our methods in Section 6 and conclude this paper at the end. We hope that our paper can inspire a deeper understanding of model ownership veriﬁcation, to facilitate the intellectual property protection of model owners. 2 R ELATED WORK","Deep neural networks (DNNs) have been widely adopted in many applications for their high effectiveness and efficiency. However, recent studies revealed that adversaries can obtain a functionsimilar copy model of the well-trained victim model to ‘steal’ it. This attack is called model stealing. Currently, there are some methods to defend against model stealing, including the active defenses and verification-based defenses. However, active defenses may lead to poor performance of the victim model and could even be bypassed by advanced adaptive attacks; while verification-based defenses introduce some",cool!
90,Reachability Analysis of Deep Neural Networks with Provable Guarantees.txt,"Verifying correctness of deep neural networks (DNNs) is challenging. We study
a generic reachability problem for feed-forward DNNs which, for a given set of
inputs to the network and a Lipschitz-continuous function over its outputs,
computes the lower and upper bound on the function values. Because the network
and the function are Lipschitz continuous, all values in the interval between
the lower and upper bound are reachable. We show how to obtain the safety
verification problem, the output range analysis problem and a robustness
measure by instantiating the reachability problem. We present a novel algorithm
based on adaptive nested optimisation to solve the reachability problem. The
technique has been implemented and evaluated on a range of DNNs, demonstrating
its efficiency, scalability and ability to handle a broader class of networks
than state-of-the-art verification approaches.","Concerns have been raised about the suitability of deep neural networks (DNNs), or systems with DNN components, for deployment in safetycritical applications, see e.g., [2, 3]. To ease this concern and gain users’ trust, DNNs need to be certiﬁed similarly to systems such as airplanes and automobiles. In this paper, we propose to study a generic reachability problem which, for a given DNN, an input subspace and a function over the outputs of the network, computes the upper and lower bounds over the values of the function. The function is generic, with the only requirement that it is Lipschitz continuous. We argue that this problem is fundamental for certiﬁcation of DNNs, as it can be instantiated into several key correctness problems, including adversarial ex ample generation [4, 5], safety veriﬁcation [6, 7, 8], output range analysis [9, 10], and robustness comparison. *This is the long version of the conference paper accepted in IJCAI2018, see [1]. 1arXiv:1805.02242v1  [cs.LG]  6 May 2018To certify a system, a certiﬁcation approach needs to provide not only a result but also a guarantee over the result, such as the error bounds. Existing approaches for analysing DNNs with a guarantee work by either reducing the problem to a constraint satisfaction problem that can be solved by MILP [9, 11, 12, 13], SAT [14] or SMT [7, 12] techniques, or applying search algorithms over discretised vector spaces [6, 15]. Even though they are able to achieve guarantees, they suffer from two major weaknesses. Firstly, their subjects of study are restricted. More speciﬁcally, they can only work with layers conducting linear transformations (such as convolutional and fullyconnected layers) and simple nonlinear transformations (such as ReLU), and cannot work with other important layers, such as the sigmoid, max pooling and softmax layers that are widely used in stateoftheart networks. Secondly, the scalability of the constraintbased approaches is signiﬁcantly limited by both the capability of the solvers and the size of the network, and they can only work with networks with a few hundreds of hidden neurons. However, stateoftheart networks usually have millions, or even billions, of hidden neurons. This paper proposes a novel approach to tackle the generic reachability problem, which does not suffer from the above weaknesses and provides provable guarantees in terms of the upper and lower bounds over the errors. The approach is inspired by re cent advances made in the area of global optimisation [16, 17]. For the input subspace deﬁned over a set of input dimensions, an adaptive nested optimisation algorithm is de veloped. The performance of our algorithm is not dependent on the size of the network and it can therefore scale to work with large networks. Our algorithm assumes certain knowledge about the DNN. However, instead of di rectly translating the activation functions and their parameters (i.e., weights and bias) into linear constraints, it needs a Lipschitz constant of the network. For this, we show that several layers that cannot be directly translated into linear constraints are actu ally Lipschitz continuous, and we are able to compute a tight Lipschitz constant by analysing the activation functions and their parameters. We develop a software tool DeepGO1and evaluate its performance by comparing with existing constraintbased approaches, namely, SHERLOCK [10] and Reluplex [7]. We also demonstrate our tool on DNNs that are beyond the capability of existing tools. 2 Related Works","In this paper, we propose a novel approach to tackle the generic reachability problem, which, for a given DNN, an input subspace and a function over the outputs of the network, computes the upper and lower bounds over the values of the function. The function is generic, with the only requirement that it is Lipschitz continuous. Existing approaches for analysing DNNs with a guarantee suffer from two major weaknesses. Firstly, their subjects of study are restricted. More specifically, they can only work with linear transformations, and cannot scale to work with large networks.",cool!
225,NNV: The Neural Network Verification Tool for Deep Neural Networks and Learning-Enabled Cyber-Physical Systems.txt,"This paper presents the Neural Network Verification (NNV) software tool, a
set-based verification framework for deep neural networks (DNNs) and
learning-enabled cyber-physical systems (CPS). The crux of NNV is a collection
of reachability algorithms that make use of a variety of set representations,
such as polyhedra, star sets, zonotopes, and abstract-domain representations.
NNV supports both exact (sound and complete) and over-approximate (sound)
reachability algorithms for verifying safety and robustness properties of
feed-forward neural networks (FFNNs) with various activation functions. For
learning-enabled CPS, such as closed-loop control systems incorporating neural
networks, NNV provides exact and over-approximate reachability analysis schemes
for linear plant models and FFNN controllers with piecewise-linear activation
functions, such as ReLUs. For similar neural network control systems (NNCS)
that instead have nonlinear plant models, NNV supports over-approximate
analysis by combining the star set analysis used for FFNN controllers with
zonotope-based analysis for nonlinear plant dynamics building on CORA. We
evaluate NNV using two real-world case studies: the first is safety
verification of ACAS Xu networks and the second deals with the safety
verification of a deep learning-based adaptive cruise control system.","Deep neural networks (DNNs) have quickly become one of the most widely used tools for dealing with complex and challenging problems in numerous domains, such as image classication [10, 16, 25], function approximation, and natural language translation [11, 18]. Recently, DNNs have been used in safetycritical cyberphysical systems (CPS), such as autonomous vehicles [8, 9, 47] and air trac collision avoidance systems [21]. Although utilizing DNNs in safetycritical applications can demonstrate considerable performance benets, assuring the safety and robustness of these systems is challenging because DNNs possess complex nonlinear characteristics. Moreover, it has been demonstrated thatarXiv:2004.05519v1  [eess.SY]  12 Apr 2020Fig. 1: An overview of NNV and its major modules and components. their behavior can be unpredictable due to slight perturbations in their inputs (i.e., adversarial perturbations) [35]. In this paper, we introduce the NNV ( Neural Network Verication) tool, which is a software framework that performs setbased verication for DNNs and learningenabled CPS, known colloquially as neural network control systems (NNCS) as shown in Figure 23. NNV provides a set of reachability algorithms that can compute both the exact and overapproximate reachable sets of DNNs and NNCSs using a variety of set representations such as polyhedra [38,48{51], star sets [28,36,37,39], zonotopes [31], and abstract domain representations [32]. The reachable set obtained from NNV contains all possible states of a DNN from bounded input sets or of a NNCS from sets of initial states of a plant model. NNV declares a DNN or a NNCS to be safe if, and only if, their reachable sets do not violate safety properties (i.e., have a nonempty intersection with any state satisfying the negation of the safety property). If a safety property is violated, NNV can construct a complete set of counterexamples demonstrating the set of all possible unsafe initial inputs and states by using the starbased exact reachability algorithm [36, 39]. To speed up computation, NNV uses parallel computing, as the majority of the reachability algorithms in NNV are more ecient when executed on multicore platforms and clusters. NNV has been successfully applied to safety verication and robustness anal ysis of several realworld DNNs, primarily feedforward neural networks (FFNNs) and convolutional neural networks (CNNs), as well as learningenabled CPS. To highlight NNV's capabilities, we present brief experimental results from two case studies. The rst compares methods for safety verication of the ACAS Xu networks [21], and the second presents safety verication of a learningbased adaptive cruise control (ACC) system. 3The source code for NNV is publicly available: https://github.com/verivital/ nnv/. A CodeOcean capsule is also available: https://doi.org/10.24433/CO. 1314285.v1 , which will be updated with a new DOI and the latest reproducibil ity results if accepted. The latest version of the CodeOcean capsule with all aspects described in this paper is available at: https://codeocean.com/capsule/1314285/ , which requires a username (taylor.johnson@uta.edu) and password (cav2020ae) to access. This account has readonly permission, so to rerun the results shown in the capsule, you can select Capsule then Duplicate from the menu bar, which will clone the capsule to allow rerunning and editing if desired. Detailed instructions for the artifact evaluation are available at: https://github.com/verivital/run_nnv_ comparison/blob/cav2020/README_AE.mdFig. 2: Architecture of a typical neural network control system (NNCS). 2 Overview and Features NNV is an objectoriented toolbox written in Matlab, which was chosen in part due to the prevalence of Matlab/Simulink in the design of CPS. It uses the MPT toolbox [26] for polytopebased reachability analysis and visualization [38], and makes use of CORA [3] for zonotopebased reachability analysis of nonlinear plant models [36]. NNV also utilizes the Neural Network Model Transformation Tool (NNMT) for transforming neural network models from Keras and Tensor  ow into Matlab using the Open Neural Network Exchange (ONNX) format, and the Hybrid Systems Model Transformation and Translation tool (HyST) [5] for plant conguration. The NNV toolbox contains two main modules: a computation engine and ananalyzer , shown in Figure 1. The computation engine module consists of four subcomponents: 1) the FFNN constructor , 2) the NNCS constructor , 3)the reachability solvers , and 4) the evaluator . The FFNN constructor takes a net work conguration le as an input and generates a FFNN object. The NNCS constructor takes the FFNN object and the plant conguration, which describes the dynamics of a system, as inputs and then creates an NNCS object. Depend ing on the application, either the FFNN (or NNCS) object will be fed into a reachability solver to compute the reachable set of the FFNN (or NNCS) from a given initial set of states. Then, the obtained reachable set will be passed to the analyzer module. The analyzer module consists of three subcomponents: 1) avisualizer , 2) a safety checker , and 3) a falsier . The visualizer can be called to plot the obtained reachable set. Given a safety specication, the safety checker can reason about the safety of the FFNN or NNCS with respect to the specica tion. When an exact (sound and complete) reachability solver is used, such as the starbased solver, the safety checker can return either ""safe,"" or ""unsafe"" along with a set of counterexamples. When an overapproximate (sound) reachability solver is used, such as the zonotopebased scheme or the approximate starbased solvers, the safety checker can return either ""safe"" or "" uncertain "" (unknown). In this case, the falsier automatically calls the evaluator to generate simula tion traces to nd a counterexample. If the falsier can nd a counterexample, then NNV returns unsafe. Otherwise, it returns unknown. A summary of NNV's major features is given in Table 1. 3 Set Representations and Reachability Algorithms NNV implements a set of reachability algorithms for sequential FFNNs and CNNs, as well as NNCS with FFNN controllers as shown in Figure 2. The reach able set of a sequential FFNN is computed layerbylayer. The output reachable set of a layer is the input set of the next layer in the network.Feature Exact Analysis Overapproximate Analysis Components FFNN, CNN, NNCS FFNN, CNN, NNCS Plant dynamics (for NNCS) Linear ODE Linear ODE, Nonlinear ODE Discrete/Continuous (for NNCS) Discrete Time Discrete Time, Continuous Time Activation functions ReLU, Satlin ReLU, Satlin, Sigmoid, Tanh CNN Layers MaxPool, Conv, BN, AvgPool, FC MaxPool, Conv, BN, AvgPool, FC Reachability methods Star, Polyhedron, ImageStar Star, Zonotope, Abstractdomain, ImageStar Reachable set/Flowpipe Visualization Yes Yes Parallel computing Yes Partially supported Safety verication Yes Yes Falsication Yes Yes Robustness verication (for FFNN/CNN) Yes Yes Counterexample generation Yes Yes Table 1: Overview of major features available in NNV. Links refer to relevant les/classes in the NNV codebase. BN refers to batch normalization layers, FC to fullyconnected layers, AvgPool to average pooling layers, Conv to convolutional layers, and MaxPool to max pooling layers. 3.1 Polyhedron [38] The polyhedron reachability algorithm computes the exact polyhedron reach able set of a FFNN with ReLU activation functions. The exact reachability computation of layer Lin a FFNN is done as follows. First, we construct the ane mapping Iof the input polyhedron set I, using the weight matrix Wand the bias vector b, i.e., I=WI+b. Then, the exact reachable set of the layerRLis constructed by executing a sequence of stepReLU operations, i.e., RL=stepReLU n(stepReLU n","Deep neural networks (DNNs) are a powerful tool for solving a variety of challenging problems, including image classification, function approximation, and natural language translation. However, their behavior can be unpredictable due to slight perturbations in their inputs (i.e., adversarial perturbations). In this paper, we introduce the NNV (Neural Network Verification) tool, which is a software framework that performs set-based verification for DNNs and learning-enabled CPS, known collotopes. NNV declares a DNN or",cool!
455,Learning to Avoid Poor Images: Towards Task-aware C-arm Cone-beam CT Trajectories.txt,"Metal artifacts in computed tomography (CT) arise from a mismatch between
physics of image formation and idealized assumptions during tomographic
reconstruction. These artifacts are particularly strong around metal implants,
inhibiting widespread adoption of 3D cone-beam CT (CBCT) despite clear
opportunity for intra-operative verification of implant positioning, e.g. in
spinal fusion surgery. On synthetic and real data, we demonstrate that much of
the artifact can be avoided by acquiring better data for reconstruction in a
task-aware and patient-specific manner, and describe the first step towards the
envisioned task-aware CBCT protocol. The traditional short-scan CBCT trajectory
is planar, with little room for scene-specific adjustment. We extend this
trajectory by autonomously adjusting out-of-plane angulation. This enables
C-arm source trajectories that are scene-specific in that they avoid acquiring
""poor images"", characterized by beam hardening, photon starvation, and noise.
The recommendation of ideal out-of-plane angulation is performed on-the-fly
using a deep convolutional neural network that regresses a detectability-rank
derived from imaging physics.","Background: Spinal fusion surgery is an operative therapy for chronic back pain with high economic burden [12] that is projected to further increase due to our aging society and our increasingly inactive lifestyle. Despite substantial im provements in operative technique, spinal fusion surgery remains highrisk: In addition to usual complications, pedicle screws that breach cortex can result in nerve damage [5]. Surprisingly, the number of misplaced pedicle screws re mains high [5,2]: Cortical breach occurs in up to 31% and 72% of the cases for freehand and  uoroscopyguided techniques, respectively. Even when sur gical navigation is employed, up to 19% of the screws are not fully contained in cortex [5]. Currently, screw placement is assessed on postoperative CT im ages, such that immediate repositioning of implants is not possible. Although intraoperative 3D conebeam CT (CBCT) imaging using mobile and roboticarXiv:1909.08868v1  [eess.IV]  19 Sep 20192 JN. Zaech et al. Fig. 1: Highlevel overview of our taskaware trajectory recommendation. Carm Xray systems is becoming widely available, it is not currently being used for spinal fusion 3D imaging, because compared to CT, Carm CBCT images suer from substantially stronger metal artifacts around the highlyattenuating titanium implants, which compromise the value of intraoperative CBCT for assessing cortical breach [2]. The obvious implication is that image quality must be improved, before CBCT is ready for primetime in highvolume applications, such as spinal fu sion. Most current methods that seek to lift CBCT reconstruction quality to the ""clinical acceptance threshold"" limit themselves to contain artifact propaga tion (e. g. via masking) or imageenhancement (e. g. streak reduction) [6]. These methods have in common that they try to deal with artifacts after acquisition of the CBCT shortscan is already completed, and are thus limited by the already corrupted information present in the acquired Xray projection images. This somewhat straightforward realization implies that there lies huge, unex ploited potential in ""simply acquiring better data"" to push the limits of CBCT image quality. In a more formal way, metal artifacts arise from a mismatch between the forward and inverse model, i. e. physical eects governing image formation and idealized assumptions made in the tomographic reconstruction algorithm. Sampling data that is less aected by unexplained corruption pro cesses during reconstruction will yield a better conditioned inverse problem, and as an immediate consequence, improved image quality without any addi tional postprocessing. The rst step towards the envisioned task and anatomy aware CBCT imaging protocol can be realized easily. The traditional shortscan CBCT trajectory [3] is embedded in a single plane, and therefore, provides lit tle room for scenespecic adjustment. We propose to extend this trajectory by autonomously adjusting outofplane angulation, which enables Carm source trajectories that are taskaware and scenespecic in that they avoid acquiring images with substantial corruption (beam hardening and noise) as shown in Fig. 1. The recommendation and adjustment of ideal outofplane angulation is performed onthe y using a deep convolutional neural network (ConvNet) that only relies on the current 2D Xray projection image. Related Work: Overall, there is little work on acquisition parameterside im age quality enhancement. Previous work on taskbased trajectories [9] leveraged preoperative CT scans and optimization techniques to select optimal parame ters. During application, these approaches would require registration between preoperative CT volume and intraoperative Carm system, which cannot beTowards Taskaware Carm Conebeam CT Trajectories 3 achieved easily in practice. Besides this requirement, an even more important limitation is the fact that surgery will alter the patient's anatomy represented by preoperative CT in an unpredictable way. Therefore, computing taskoptimality based on preoperative CT volumes can only serve as a coarse approximation of the true optimal trajectory. These assumptions become even stronger as surgical tools may still be present in the scene [9], as tools will strongly aect the optimal solution due to their high attenuation. The prospect of altering acquisition parameters to improve image quality has recently also been recognized for magnetic resonance imaging [1], where the undersampling pattern in kspace can be optimized via endtoend learning with respect to fully sampled image. The approach closest to ours considers nding an optimal acoustic window for cardiac ultrasound [7], where the current im age is interpreted by a reinforcement learning agent that suggests an ultrasound probe displacement towards a better acoustic window. While both previous ap proaches have some similarity from a conceptual standpoint, they focus on image appearance rather than imaging physics and both the magnetic resonance and ultrasound acquisition protocols are substantially dierent from CBCT. 2 Methods","Spinal fusion surgery is a high-risk surgery with high economic burden and high risk of cortical breach. Despite substantial improvements in operative technique, intraoperative 3D conebeam CT (CBCT) imaging is not currently being used for spinal fusion, because compared to CT, Carm CBCT images suffer from substantially stronger metal artifacts around the highly-attenuating titanium implants. This compromises the value of intraoperative CBCT for assessing cortical breach. In this work, we propose to extend the traditional shortscan trajectory by autonomously adjusting",cool!
372,Fault Injectors for TensorFlow: Evaluation of the Impact of Random Hardware Faults on Deep CNNs.txt,"Today, Deep Learning (DL) enhances almost every industrial sector, including
safety-critical areas. The next generation of safety standards will define
appropriate verification techniques for DL-based applications and propose
adequate fault tolerance mechanisms. DL-based applications, like any other
software, are susceptible to common random hardware faults such as bit flips,
which occur in RAM and CPU registers. Such faults can lead to silent data
corruption. Therefore, it is crucial to develop methods and tools that help to
evaluate how DL components operate under the presence of such faults. In this
paper, we introduce two new Fault Injection (FI) frameworks InjectTF and
InjectTF2 for TensorFlow 1 and TensorFlow 2, respectively. Both frameworks are
available on GitHub and allow the configurable injection of random faults into
Neural Networks (NN). In order to demonstrate the feasibility of the
frameworks, we also present the results of FI experiments conducted on four
VGG-based Convolutional NNs using two image sets. The results demonstrate how
random bit flips in the output of particular mathematical operations and layers
of NNs affect the classification accuracy. These results help to identify the
most critical operations and layers, compare the reliability characteristics of
functionally similar NNs, and introduce selective fault tolerance mechanisms.","Nowadays, Artiﬁcial Intelligence (AI) is exploited all over the industry, including safetycritical ap plications in the automotive, aerospace, and med ical sectors. As part of AI, computer vision is an essential task in autonomous driving, robotics, and healthcare. The autonomous driving use cases vary from the recognition of pedestrians and traf ﬁc signs to the identiﬁcation of lane markings. In robotics, AI helps with object classiﬁcation and visual navigation. Furthermore, AI supports doc tors in patient monitoring, diagnosing tasks, and development of treatment protocols for personal ized medicine. The mentioned applications are based on image recognition using Convolutional Neural Networks (CNN). CNNs are considered to be state of the art for this task as this type of net work takes the lead in the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) [11]. One of the commonly used opensource machine learning frameworks for the development of neu ral networks is TensorFlow [1], which has proven to be a stable and reliable platform. The ﬂex ible architecture of TensorFlow allows for easydeployment across a variety of platforms, includ ing embedded devices. TensorFlow version 1.0 has been released by the Google Brain team in Februray 2017, the second version 2.0 became ofﬁcially available in September 2019. Currently, both versions are in use. Neural networks, like any software, are suscep tible to common random hardware faults such as bit ﬂips. Lowering the voltage, increasing heat, radiation, electromagnetic induction, or other neg ative environmental impacts can corrupt CPU or RAM and change the value of a stored variable. This affects the classiﬁcation accuracy of the net work. Safetycritical applications that utilize AI based methods have to prove their reliability ac cording to industrial safety standards. Therefore, investigating the effects of such soft errors is crucial to ensure the correct operation of the AI application under the effect of such errors. Contribution: This paper presents two FI frameworks for TensorFlow 1 and TensorFlow 2. The frameworks allow the user to model soft errors during the execution of a neural network, analyze the effects of such errors, and identify the Proceedings of the 30th European Safety and Reliability Conference and the 15th Probabilistic Safety Assessment and Management Conference. Edited by Piero Baraldi, Francesco Di Maio and Enrico Zio Copyright © 2020 by ESREL 2020 PSAM 15 Organizers. Published by Research Publishing, Singapore ISBN: 9819730000000 :: doi: 10.3850/9819730000000 main 1arXiv:2012.07037v1  [cs.LG]  13 Dec 20202 M. Beyer et al. most critical parts of the network. To demonstrate the feasibility of the developed frameworks, we conducted four largescale FI ex periments. These experiments yield the classi ﬁcation accuracy of four neural networks under varying circumstances. The tested networks in clude two VGGs (VGG16 and VGG19) [13], an opensource VGGbased network, and a simple CNN based on general design guidelines. For the experiments the German Trafﬁc Sign Recogni tion Benchmark (GTSRB) [14] and ImageNet [11] datasets have been used. The results show which erroneous operations or layers have the largest impact on the accuracy, allowing the introduction of efﬁcient selective fault protection mechanisms. The remainder of the paper is structured as follows. First, the developed FI frameworks for TensorFlow 1and2are presented in Section 2. Section 3 gives an overview of the experimental setup. The results are shown and discussed in Section 4. Afterward, an overview of related work is given in Section 5. Finally, this work is concluded in Section 6. 2. Fault injection frameworks We present two new FI frameworks. InjectTF for TensorFlow 1 and InjectTF2 for TensorFlow 2. The key capabilities of both frameworks are out lined in Table 1. They are designed in a modular way and can therefore easily be expanded with additional features. A highlevel overview of the ﬁrst framework, InjectTF, was already presented in our twopage abstract [2]. Table 1. Comparison of the two fault injection frameworks InjectTF InjectTF2 TensorFlow versionVersion 1, lowlevel TF APIVersion 2, highlevel Keras API FI style Operationwise Layerwise Supported fault typesZero, random value, random bit ﬂipSpeciﬁc or random bit ﬂip Supported operations/ model structuresAdd, Sub, Mul, ReLU1 Sequential2 1The operation list can be easily extended by the user. 2Parallel structures will be supported in the next version. In this full paper we give a detailed and up todate description. InjectTF injects errors into the outputs of individual operations of neural net works and has been developed using the low level TensorFlow 1 API. TensorFlow 2.0 brought signiﬁcant changes to its Python API. With the integration of the highlevel Keras API, designing neural networks becomes more abstract as theparadigm has been shifted from the operation wise development to a layerwise. Now the layers are the basic building blocks instead of the indi vidual operations that compose a layer. InjectTF could not be adopted to TensorFlow 2.0, therefore a complete redesign was required. We follow this trend of increasing abstraction and focus on injecting faults into the output of layers instead of individual operations. Since the updated version of InjectTF fundamentally changes the behavior of the framework, it is developed under a new name: InjectTF2 . Both frameworks, including examples, are available on GitHuba. 2.1. InjectTF Architecture: InjectTF is built on top of the standard TensorFlow 1library and takes a conﬁg uration ﬁle as well as a trained neural network as inputs to create a fault injected counterpart of the original TensorFlow model. The network has to be provided either as a checkpoint and a meta ﬁle or as a frozen graph. Conﬁguration: In the conﬁguration ﬁle, the user lists TensorFlow operation type(s) along with FI probabilities. It is possible to choose between three types of faults that will be injected with the chosen probability into the output of the listed operation(s): (i) change one random value of the operation’s result to zero, (ii) change one random value of the operation’s result to a random num ber, or (iii) ﬂip one random bit of a random value of the operation’s result. Working principle: The process of creating the injected model is sketched in the middle of Fig ure 1a. Here the TensorFlow operation Add is selected for injection. InjectTF iterates over all operations within the graph of the “original” net work. All operations that are not listed by the user are just copied to a new “injected” graph. However, if an operation type is in the list, then an injected counterpart of that operation is generated and added to the injected graph. The new opera tion is essentially the wrapped “original” Tensor Flow operation. Therefore, when executing the injected network, only the result of the underlying computation is altered according to the parameters deﬁned in the conﬁguration ﬁle. During runtime, both neural networks can be used for inference. 2.2. InjectTF2 Architecture: InjectTF2 is built on top of the standard TensorFlow 2library and requires a con ﬁguration ﬁle, a trained neural network, and a dataset as input. In Figure 1b the inputs required for initialization of the framework are shown on the left side. The network and the dataset should be provided as a HDF5 model and a TensorFlow aSource code available at https://github.com/mbsatudFault Injectors for TensorFlow: Evaluation of the Impact of Random Hardware Faults on Deep CNNs 3 (a) Working principle of the fault injection framework InjectTF. The operation selected for injection is shown in orange. Source code available at https://github.com/mbsatud/InjectTF . (b) Working principle of the fault injection framework InjectTF2. The layer selected for injection is shown in orange. Source code available at https://github.com/mbsatud/InjectTF2 . Fig. 1. Working principle overview of both fault injection frameworks. dataset, respectively. The latter is used to save the intermediate output values of the layer that is to be injected with errors in the experiments. As of now, the framework only works with sequential models that have been developed with the high level Keras API. Conﬁguration: In the conﬁguration ﬁle, the layer that is to be injected is speciﬁed along with the injection probability. Currently, only bit ﬂips can be injected by the framework. However, it is possible to choose between ﬂipping a random bit or a speciﬁc bit of a random value of a layer’s output. Working principle: In the middle of Figure 1b, the working principle of InjectTF2 is shown. When initializing the framework, we execute the model up to the layer where the errors are to be injected, using the provided data set. The output values of the injected layer are collected and stored. Afterward, we continue the analysis from the selected layer onward using the gathered values. Errors are injected into the stored values of the selected layer according to the parameters deﬁned in the conﬁguration ﬁle. Splitting the model and executing the two re sulting parts separately drastically reduces the ex ecution time of the experiments, since the net work is not executed from bottom to top each time. During runtime, however, only the original model exists. Compared to InjectTF, InjectTF2is therefore more dynamic, since it neither alters the structure of the network nor creates a new model with injected faults. However, a substantial amount of memory is required to store the inter mediate values of the selected layer. Depending on the layer and dataset size, this can quickly reach 100GB. 3. Experimental setup Three image classiﬁcation experiments with CNNs have been conducted using the two pre sented FI frameworks. An overview of the ex perimental setup is given in Table 2. The ﬁrst experiment has been done with InjectTF and an opensource trafﬁc sign classiﬁer [9] that is based on the VGGNet. For the second one, we de veloped a simple CNNbased trafﬁc sign classi ﬁer with TensorFlow 2and injected faults into it with InjectTF2. In the last experiment, we con centrate on publicly available networks integrated into TensorFlow, in order to identify common vulnerabilities of neural networks. Since previous experiments were based on the VGGNet, we use pretrained VGG16 and VGG19 networks and in ject errors into those with InjectTF2. To ensure the statistical conﬁdence of our ex periments, we compute the Cumulative Moving Average (CMA) for the resulting classiﬁcation accuracy in each experiment.4 M. Beyer et al. Table 2. Overview of the experimental setup. Operationwise FI Layerwise FI FI framework InjectTF InjectTF2 InjectTF2 Neural network VGGbased [9] Custom CNN VGG16, VGG19 Dataset GTSRB GTSRB ImageNet ExperimentEvaluate classiﬁcation accuracy with a varying probability for FIEvaluate classiﬁcation accuracy with a varying probability for FI and with 100 % probability for FIEvaluate classiﬁcation accuracy with 100 % probabilty for FI Injected operations/layersOperations Add, Sub, and Mul (separately)All layers (separately) All layers (separately) 3.1. Operationwise FI Experiment Neural network: In this experiment, a VGG based trafﬁc sign classiﬁer is used. It consists of a localization network with a spatial trans former and a VGGlike network for classiﬁcation. The network has been trained on an augmented GTSRB dataset that was split into three subsets for training, testing, and validation. The subsets contain 129 100 ,12 630 , and 4 410 images with 3232RGB pixels that belong to 43different types of road signs. After training the network can classify trafﬁc signs with an accuracy of approxi mately 96 % . The network’s most common TensorFlow oper ations are Add,Sub, and Mul, which together form part of the main components of the Parametric ReLU (PReLU) activation function, that is used in most layers of the network, see Figure 3. FI setup: Each of the previously mentioned op erations is investigated in a set of separate experi ments, whereby bit ﬂips are injected with a vary ing probability into the output of the respective operation. Depending on the probability of FI, one random bit of a random element of the operation’s output is ﬂipped. Since the selected operations occur multiple times in the network, multiple bit ﬂips might be injected during inference. Each of the selected probabilities is tested 100times. The classiﬁcation accuracy is determined in each ex periment using the GTSRB testing subset with the corresponding ground truth. This helps to evaluate the effect of random faults in those operations on the performance of the network. 3.2. Layerwise FI Experiments Neural networks: In the layerwise FI exper iments, we use three different neural networks. The ﬁrst is a selfdeveloped simple CNN based on general design guidelines. It consists of 12 layers and uses the ReLU activation function for all convolutional and dense layers except the last, which uses the Softmax function. As the network in the ﬁrst experiment, our simple CNN has been trained on the augmented GTSRB dataset and is capable of classifying trafﬁc signs with an ac curacy of approximately 96 % . Additionally, we conduct experiments with pretrained VGG16 andVGG19 networks with ImageNet weights. FI setup: The experiments using our simple CNN network can be further divided into two cate gories: (i) Stochastic experiments with varying probability and (ii) deterministic experiments with a ﬁxed 100 % probability of error injection. In the ﬁrst category, the performance of the network is evaluated by calculating the classiﬁca tion accuracy using the GTSRB testing subset’s ground truth. Similar to the experiment of Sec tion 3.1, each layer of the network is analyzed in a set of separated experiments, whereby one bit ﬂip is injected with a varying probability into the output of the respective layer. Depending on the probability of error injection, one random bit of one random element of the layer’s output is ﬂipped. Each of the selected probabilities is tested 100times. In the second category, each layer of the net work is investigated in a set of separate exper iments, whereby the probability for injecting a random bit ﬂip into the output of the respective layer is 100 % . The performance (accuracy) is determined according to the network’s golden run predictions, i.e., the predictions of the neural net work without FI. In the experiments with the VGG networks, the performance of both networks is determined using a random sample of 5000 224 224RGB images from the 2012 ImageNet testing subset. As in the second category mentioned above, a set of 100bit ﬂip injection experiments is conducted for each layer. In these experiments, one random bit in one random element of the layer’s output is ﬂipped. The ground truth of the ImageNet test subset is not available. Thus, the only option is to compare the performance of the networks to the predictions of the neural network without faults. We call this prediction the golden run . 4. Results of the Experiments 4.1. Operationwise FI Experiment Figure 2 shows the results of the operationwise FI experiments for each of the operations mentioned in Section 3.1. The varying FI probabilities are denoted on the Xaxes. The mean classiﬁcation accuracy and standard deviation for the 100indiFault Injectors for TensorFlow: Evaluation of the Impact of Random Hardware Faults on Deep CNNs 5 vidual experiments are shown in blue. The refer ence classiﬁcation accuracy without FI is shown in red. The resulting classiﬁcation accuracy decreases linearly with an increasing probability for FI for all three investigated operations. However, faults in some operations affect the resulting classiﬁ cation accuracy more than others. The second plot in Figure 2 shows that for this network, the classiﬁcation accuracy decreases the least in case of errors in the Sub operation. Intuitively, one would expect a multiplication to have a signiﬁcant impact. As the third plot in Figure 2 shows, faults in the Mul operation indeed have a considerable inﬂuence on the resulting classiﬁcation accuracy. However, compared to the ﬁrst plot in Figure 2, theAdd operation has a much more signiﬁcant impact, although there are fewer Add operations in the network. This unexpected result can be explained by investigating the implementation of the PReLU activation function, which is used throughout the neural network used in this ex periment. Figure 3 shows the implementation of the PReLU function with TensorFlow operations. The graph is executed from bottom to top and can be split into two branches. The left part con sists of the standard TensorFlow ReLU operation, which corresponds to the positive domain of the PReLU activation function. In the right part the negative domain of the function is realized by a combination of multiple operations. alpha is a trainable parameter, bis a constant value equal to0:5. The result of this branch has to be zero for all positive values. Therefore, by subtract ing the input’s absolute value from the input and multiplying the overall result with 0:5, the desired result is obtained. The sum of both branches determines the output of each layer with a PReLU activation function. Consequently, errors in the Add operation can have a signiﬁcant impact on the classiﬁcation accuracy. Also, these errors can cause important features to disappear when a max pooling layer follows an erroneous Addoperation. Therefore, this type of operation can be consid ered as the most critical one in this network. The CMA for all tested operations converges to a ﬁnite value. Thus, the sample size for the experiment is considered to be sufﬁcient. Key points of the operationwise experiments: The experiments help to identify the most criti cal operation type in the network under test. Add is the most critical investigated operation, presumably because of the PReLU function’s structure. Efﬁcient selective operationwise fault toler ance mechanisms can be introduced, based on the obtained information. The classiﬁcation accuracy tends to drop lin early with an increasing FI probability. Fig. 2. Results of the operationwise bit ﬂip FI experiments into the VGGbased CNN from Section 3.1. It has been trained on an augmented GTSRB dataset [2] © 2019 IEEE. Fig. 3. Visualization of the PReLU activation function im plementation with TensorFlow operations in TensorBoard. 4.2. Layerwise FI Experiments Figure 4a shows the results of the ﬁrst category of experiments on our simple CNN, described in Section 3.2. The FI probabilities are denoted on the Xaxis. The reference classiﬁcation accuracy without FI is shown in red. For each layer, the6 M. Beyer et al. resulting mean classiﬁcation accuracy and stan dard deviation for each of the individual 100ex periments per probability have been computed. Overall, the standard deviation is negligibly small across all tested probabilities. For the sake of readability, we only show the mean classiﬁcation accuracy and standard deviation for the “best” and “worst” layer (i.e. layer 6and layer 12). For all other layers we show only the linear ﬁt, which is colorcoded according to the layer type. The corresponding layer numbers for each linear ﬁt are shown on the right side. Compared to the results of the operationwise FI, discussed in Section 4.1, the overall drop in classiﬁcation accuracy is signiﬁcantly less. This can be explained by the fact that in the operation wise FI experiments, more than one fault can be injected during the execution of the network. Con sequently, the results presented in Figure 4a are not as severe as those in Section 4.1. Nevertheless, the linear relationship between the probability for FI and the resulting classiﬁcation accuracy is still apparent. As in the ﬁrst experiment, the CMA has been computed for the tested probabilities and all layers in the network. The sample size of this experiment can be considered as sufﬁcient. The results of the second category of experi ments mentioned in Section 3.2 are shown in Fig ure 4b. The mean value and standard deviation of the resulting classiﬁcation accuracy for each layer are shown in blue alongside the minimum and maximum values that are shown in grey. The layer numbers are shown on the Yaxis. As before, the results have been colorcoded based on the layer types, which are also listed inside Figure 4b to gether with the corresponding output dimensions of the respective layer. Note that the resulting accuracies are better than those in Figure 4a. Because in this case, the performance is determined using the networks golden run predictions rather than the ground truth of the dataset. Here, the last layer of the network can be considered the most critical, since an error in this layer can directly inﬂuence the output of the network. This is also reﬂected in the resulting classiﬁcation accuracy. Furthermore, the stacked convolutional layers in layers 1–2and5–6show a recurring pattern, which raises the question of whether the position of individual layers in rela tion to each other and their parameters determine the reliability of the neural network. As expected, faults in Dropout and Flatten lay ers have the same drop in classiﬁcation accuracy as their preceding layer, since those layer types are not used during inference or do not inﬂuence the values of the previous layer. Again, the CMA has been computed to verify the experiment, with a similar result as in the previous experiments. Figure 5 depicts the resulting classiﬁcation accuracies for the layerwise bit ﬂip injection exper iments on the VGG networks. For each layer, the average value and corresponding standard devia tion are shown in blue alongside the minimum and maximum values that are shown in grey. The layer numbers are shown on the Yaxes. The results have been colorcoded based on the layer types, which are also listed inside Figure 5 together with the corresponding output dimensions of the respective layer. Overall, the performance of both networks with fault injections is similar. Regardless of the net work depth, the ﬁrst layers tend to be more critical than deeper layers. This behavior is different to our simple CNN. However, a general fault tol erance is observed in each case, which conﬁrms the inherent fault tolerance of neural networks mentioned in the literature [6; 7; 8]. The ﬁrst MaxPooling layers are the most crit ical ones in both VGG networks, as they play a key role in the extraction of feature maps. Fur thermore, it can be observed that the criticality of the convolutional layers tends to decrease with each subsequent convolutional block. Presum ably, this is because the essential features have already been extracted in the deeper layers of the network. The ﬁrst six and last three layers in Figures 5a and 5b show the same pattern in the classiﬁcation accuracy drop. This is because the ﬁrst four convolutional layers and the last three dense layers have been initialized with the same weights before training. Only the intermediate layers were initialized randomly. However, the plots of the VGG networks still look similar in general. Those results and the dif fernt behavior of our simple CNN further support the theory that the overall reliability of a neural network depends on its general architecture, the position of the layers relative to each other, and the parameters (i.e., the number of ﬁlters, kernel size, and output dimension) of each layer. Also, the CMA has been computed for all layers of both the VGG16 and the VGG19 to conﬁrm that the sample size is large enough. Key points of the layerwise experiments: The experiments help to identify the most criti cal layers in the network under test. For our simple CNN, the last layer is the most critical one. For the VGG networks, the ﬁrst MaxPooling layers are the most critical ones. The criticality of the convolutional layers tends to decrease with with each subsequent convolu tional block. Efﬁcient selective layerwise fault tolerance mechanisms can be introduced based on the obtained information. The classiﬁcation accuracy tends to drop lin early with an increasing FI probability.Fault Injectors for TensorFlow: Evaluation of the Impact of Random Hardware Faults on Deep CNNs 7 Layer 2Layer 1Layer 3Layer 5Layer 4Layer 6 Layer 10Layer 9 Layer 11Layer 8Layer 7 Layer 12Layer number: (a) Resulting classiﬁcation accuracies with a varying prob ability for fault injection. ConvConvMaxPoolConvDropoutConvDenseFlattenDropoutDropoutMaxPoolDense 32×32×3232×32×3216×16×3216×16×6416×16×3216×16×6425640962568×8×648×8×6443 Layer type:Dimension:(b) Resulting classiﬁcation accuracies with a 100 % proba bility for fault injection. Fig. 4. Resulting classiﬁcation accuracies for layerwise bit ﬂip injection using InjectTF2. The network used is our selfdeveloped CNN trafﬁc sign classiﬁer from Section 3.2 which has been trained on an augmented GTSRB data set. Dense ConvConvMaxPoolConvConvMaxPoolMaxPoolConvConvConvConvConvMaxPoolConvConvConvDenseFlattenDenseMaxPoolConv1000 224×224×64224×224×64112×112×64112×112×128112×112×12856×56×12828×28×25656×56×25628×28×51256×56×25656×56×25614×14×51214×14×51214×14×51228×28×51228×28×51240962508840967×7×51214×14×512 Layer type:Dimension: (a) Resulting classiﬁcation accuracies for the VGG16 CNN. FlattenDense ConvConvMaxPoolConvConvMaxPoolConvConvMaxPoolConvConvConvConvMaxPoolConvConvConvConvMaxPoolConvConvDenseDense250884096 224×224×64224×224×64112×112×64112×112×128112×112×12856×56×12856×56×25656×56×25628×28×25656×56×25656×56×25628×28×51228×28×51214×14×51228×28×51228×28×51214×14×51214×14×5127×7×51214×14×51214×14×51240961000 Layer type:Dimension: (b) Resulting classiﬁcation accuracies for the VGG19 CNN. Fig. 5. Results of the layerwise bit ﬂip fault injection experiments using InjectTF2 and a ﬁxed fault injection probability of 100 % . The networks used are pretrained VGG16 and VGG19 CNN’s with ImageNet weights. 5. Related work","This paper presents two fault injection (FI) frameworks for TensorFlow. The frameworks allow the user to model soft errors during the execution of a neural network, analyze the effects of such errors, and identify the most critical parts of the network. The results show which erroneous operations or layers have the largest impact on the accuracy of the neural network. The FI frameworks are designed in a modular way and can therefore easily be expanded with additional features. The FI frameworks are designed in a modular way and can be easily extended with additional features.",cool!
376,A New CGAN Technique for Constrained Topology Design Optimization.txt,"This paper presents a new conditional GAN (named convex relaxing CGAN or
crCGAN) to replicate the conventional constrained topology optimization
algorithms in an extremely effective and efficient process. The proposed crCGAN
consists of a generator and a discriminator, both of which are deep
convolutional neural networks (CNN) and the topology design constraint can be
conditionally set to both the generator and discriminator. In order to improve
the training efficiency and accuracy due to the dependency between the training
images and the condition, a variety of crCGAN formulation are introduced to
relax the non-convex design space. These new formulations were evaluated and
validated via a series of comprehensive experiments. Moreover, a minibatch
discrimination technique was introduced in the crCGAN training process to
stabilize the convergence and avoid the mode collapse problems. Additional
verifications were conducted using the state-of-the-art MNIST digits and
CIFAR-10 images conditioned by class labels. The experimental evaluations
clearly reveal that the new objective formulation with the minibatch
discrimination training provides not only the accuracy but also the consistency
of the designs.","Topo logy optimiz ation [1 4], a branch of design optimization, is a mathematical method to solve  a material layout problem constrained for a given design domain, loading, and boundary  conditions. This method determines the optimal distribution of material such that the structure has  desired properties (e.g. minimizing the compliance of structure) while satisfying the design  constraints. Indeed, t opology design optimization offers a tremendous opportunity in design and                                                                  1 Corresponding Author, email: shen.1@osu.edu   2   manufacturing freedoms by designing and prod ucing a part from the ground up without a  meaningful initial design as required by conventional shape design optimization approaches.  Ideally, with adequate problem statements, to formulate and solve the topology design problem  using a standard topology op timization process, such as Simplified Isotropic Materi al with  Penalization (SIMP) is possible. However, the conventional optimization approach is in general  impractical or computationally unachieva ble for real world applications due to over  thousands of  design iterations are often required f or just a few design variables. There is, therefore, a need for  a different approach that will be able to optimize the initial design topology effectively and rapidly.      There have been many studies to improve the topol ogy optimization algorithms and reduce the  computational costs using convolutional  neural networks  (CNN) [57]. The training process  of the  CNNs, mathematically, is an inverse problem that emphasizes the existence, uniqueness, and  efficiency of the results.  Currently, the primary obstacle to  the development of C NN is the  requirement of an extensive  amount of data , often unavailable  in real world applications , for  training to achieve the best results . To this end, our previous efforts [8, 9]  have  deve loped  a new  topology design procedure  to generate optimal structures us ing CNN  architecture  trained with  large data sets generated by a Generative Adversarial Network (GAN) . The discriminator in the  GAN  as we ll as the CNN were initially trained through the dataset of 3024 true optimized planar   structure images generated from a convent ional topology design approach SIMP . The  discriminator maps the optimized structure to the key topology design parameters such as volume  fraction, penalty and radius of the smoothening filter. Once the GAN is trained, the generator  produced a large number of new unseen planar  structures satisfying t he design requirements and  boundary conditions.  This work has been extended to accommodate the des ign requirements   and/or constraints  in our recent effort [1 0] based on conditional Wasserstein generative adversarial  networks (CWGAN) . With CWGANs, the topology optimization conditions can be set to a  required value before generating samples. CWGAN truncates the global design space by  introducing an equality constraint by the designer. However,  mode collapse was observed in the  CWGAN trai ning process  which is responsible for the lack of diversity in the generated output  structures  as discussed in [10] .     The purpose of this paper is to present  a new  constrained topology optimization approach based  on a new conditional generative adversari al network  (crCGAN)  to not only replicate the  conventional topology optimization algorithms in an extremely effective and efficient way  but also  completely resolve convergence instability and mode collapse  problems of GAN  training . The idea  is to introduce  a third term in the new objective function  creating  an in consistency of the training  samples and the constraint s which in turn stream lines th e training  process. As previously stated,  the crCGAN was  created  to improve convergence speed, stability,  and accuracy of the topology  design process  while maintaining  the simplicity. In addition, a minibatch discrimination technique   proposed in [11] was applied  in the crCGAN training process  to stabilize the convergen ce and 3   avoid the mode collapse . The approach has been  validated by generatin g planar  structures  constra ined by a desired volume ratio with the  topology planar structures produced from the  conventional algorithm SIMP.  Additional experiments were conducted on the  stateofthe art  MNIST digits and CIFAR 10 images  conditioned by class label. The work presented in this  paper  will provide a  new conditional GAN technique that can enhance the convergence of the CGANs  and providing signific ant accuracy and uniqueness of the results.  The aim of this work, as w ell as  our previous efforts [8 10], is to demonstrate a proof of concept and further scale research efforts  to amalgamating deep learning with topology design optimization as well as explore a new  direction in general  design optimization processes.     2   Topology Optimization Problem Statement     Topology optimization is a modern optimization algorithm which aims to distribute material inside  a given design domain [5 ]. Concepts of finite element method along with optimizing techniques  like genetic algorithm, method of moving asymptotes, optimality criteria and level set method are  utilized in this algorithm. Mathematically, it is an integer optimization problem w here each finite  element of the discretized design domain constitute a design variable. This design variable  represents the density of that element  which takes a value of either 0 (with no material) or 1 (with  material), hence named a binary density variable at times.  This p roblem can be relaxed by using  converting the discrete integer problem into a co ntinuous variable problem  SIMP.  In SIMP, non  binary solutions are penalized with a factor p. Mathematically, the topology optimization  implementation suing SIMP can be defined  as:    min ∶  𝑥 𝑐(𝑥)=  𝑈𝑇𝐾𝑈 = ∑ (𝑥𝑒 )𝑝 𝑁 𝑒=1  𝑢𝑒𝑘𝑜𝑢𝑒                 (1)            𝑠𝑢𝑏𝑗𝑒𝑐𝑡𝑒𝑑  𝑡𝑜:    𝑉(𝑥) 𝑉0 =𝑓,                                             KU=F,  0< 𝑥𝑚𝑖𝑛 ≤𝑥≤1    where c(x) is the objective function, U and F are the global displacement and force vectors  respectively. K is the global stiffness matrix, 𝑢𝑒 and 𝑘𝑜 are the element displacement vector and   stiffness matrix, respectively.  x is the vector of design variables .  minx  is a vector of minimum  relative densities ( nonzero to avoid singularity). N (= nelx×nely)   xy N    is the number of  elements used to discretize the design domain, p is the penali zation power (typically p = 3). V (x)  and V 0 is the material volume and des ign domain volume, respectively. Finally, f (volfrac) is th e  prescribed volume fraction . This exis ting method was  used to generate a dataset of 3024 s amples . 4       3   Related Work","Topology design optimization is a mathematical method to solve a material layout problem constrained for a given design domain, loading, and boundary conditions. The method determines the optimal distribution of material such that the structure has desired properties (e.g. minimizing the compliance of structure) while satisfying the design constraints. The conventional topology optimization approach is in general impractical or computationally unattainable for real world applications due to over thousands of design iterations are often required for just a few design variables. To this end, we have developed a new conditional Wasserstein generative adversarial network (",cool!
451,Aurora Guard: Reliable Face Anti-Spoofing via Mobile Lighting System.txt,"Face authentication on mobile end has been widely applied in various
scenarios. Despite the increasing reliability of cutting-edge face
authentication/verification systems to variations like blinking eye and subtle
facial expression, anti-spoofing against high-resolution rendering replay of
paper photos or digital videos retains as an open problem. In this paper, we
propose a simple yet effective face anti-spoofing system, termed Aurora Guard
(AG). Our system firstly extracts the normal cues via light reflection
analysis, and then adopts an end-to-end trainable multi-task Convolutional
Neural Network (CNN) to accurately recover subjects' intrinsic depth and
material map to assist liveness classification, along with the light CAPTCHA
checking mechanism in the regression branch to further improve the system
reliability. Experiments on public Replay-Attack and CASIA datasets demonstrate
the merits of our proposed method over the state-of-the-arts. We also conduct
extensive experiments on a large-scale dataset containing 12,000 live and
diverse spoofing samples, which further validates the generalization ability of
our method in the wild.","Face antispooﬁng has been a promising topic in com puter vision research, which is regarded as a very chal lenging problem in industry especially in remote scenar ios without speciﬁc hardware equipped. The existing meth ods (Yi et al. 2014; Zhang et al. 2019a; 2019b) on face antispooﬁng are paying more attention on exploiting multi modality information, e.g., RGB images, depth or infrared light. With the development of depth sensors, recent meth ods and commercial systems mainly rely on hardwares em bedded with structured light ( e.g., FaceID on iphone X), light ﬁeld (Xie et al. 2017) or LIDAR to reconstruct ac curate 3D shape, which can well address the limitation of 2D methods towards highlevel security (Li et al. 2016; 2017). Although good antispooﬁng performance can be achieved, these methods highly rely on the customized hard ware design, which unavoidably increases the system cost. Considering the cost of additional sensors, recent ad vances on Presentation Attack Detection (PAD) estimate depth directly from a single RGB image as a replacement. In particular, since 3D reconstruction from a single image Figure 1: Framework of our proposed system .D/Mdenotes the recovered depth/material map from the reﬂection frames, which improves our antispooﬁng performance against unlimited 2D/3D spooﬁng. The whole system then imposes liveness checking on these two auxiliary information. rdenotes the light CAPTCHA generated and casted by light source and ^rdenotes the light CAPTCHA estimated by our method. The light CAPTCHA check ing mechanism further improves our system’s security. is highly underconstrained due to the lack of strong prior of object shapes, such methods introduce certain prior by recovering sparse (Wang et al. 2013) or dense (Atoum et al. 2017; Liu et al. 2019) depth features. However, on one hand, these methods still suffer from the missing of solid depth clue, leading to the lack of generalization capability. On the other hand, the system is easily vulnerable to 3D attack ( e.g., silicon/paper mask) if depth information is determinant to the ﬁnal judgment. Towards solving various attacks without using additional sensors, we propose a simple, fast yet effective face anti spooﬁng system termed Aurora Guard (AG). Its principle is using light reﬂection to disentangle two auxiliary infor mation, i.e., depth and material, to consolidate discrimina tive features for real/fake classiﬁcation, as shown in Fig. 1. Those two information can be reliably extracted from nor mal cues deﬁned in this paper, which are the pixelwise sub traction of two contiguous reﬂection frames. In addition, we further leverage the light CAPTCHA ,i.e., the random light parameters sequence, to provide an extra security mecha nism by checking the consistency of our prediction with the ground truth. By only incorporating a single extra light source to generate the reﬂection frames, our method ensures both the efﬁciency andportability in a costfree softwarearXiv:2102.00713v1  [cs.CV]  1 Feb 2021manner, which has already been deployed on smart phones and embedded terminals that serves for millions of users . In particular, our method consists of three parts: ( 1) We adopt the Lambertian model to cast dynamic changing light speciﬁed by the random light CAPTCHA, and then ex tract the normal cues from every two contiguous reﬂection frames. The solid depth and material information are then embodied in the normal cues. ( 2) We use a compact encoder decoder structure to conduct disentanglement of depth and material simultaneously. With two regression branches re covering depth and material maps respectively, the learned features are robust for both 2D and 3D attacks, which facil itate the liveness judgment in the classiﬁcation branch. ( 3) We provide an additional branch to estimate the light pa rameter sequence, which forms a light CAPTCHA check ing mechanism to handle the special attack named modality spooﬁng , a very common attack in real scenarios. Moreover, since the imaging qualities (resolution, device) and the types of Presentation Attack Instruments (PAI) are essential to the performance evaluation of practical face au thentication, we further build a dataset containing videos of facial reﬂection frames collected by our system, which is the most comprehensive andlargest one of its kind compared with other public datasets. On this dataset, we demonstrate that our depth reconstruction is competitive to the profes sional 3D sensor qualitatively and quantitatively. Also, our material reconstruction serves as a powerful tools to block a large proportion of 3D attacks. As a result, without extra hardware designs, our model achieves comparable perfor mance against the expensive hardware on face antispooﬁng. To sum up, the main contributions of this work include: A simple, fast yet effective face antispooﬁng method is proposed, which is practical in real scenarios without the requirement on speciﬁc depth hardwares. Acostfree disentangle net is proposed to recover the depth and material maps via the normal cues extracted from two contiguous reﬂection frames for liveness classiﬁcation. A novel light CAPTCHA checking mechanism is pro posed to signiﬁcantly improve the security against the at tacks, especially the modality spooﬁng. A dataset containing comprehensive spoof attacks on various imaging qualities and mobile ends is built. 2 Related Work","Face anti-spoofing is a challenging problem in computer vision especially in remote scenarios without specific hardware equipped. Recent methods mainly rely on hardwares embedded with structured light, light field or LIDAR to reconstruct 3D shape. However, these methods suffer from the lack of strong prior of object shapes, leading to the lack of generalization capability. In this paper, we propose a simple yet effective face anti-spoofing system termed Aurora Guard (AG). Its principle is using light reflection to disentangle two auxiliary information, i.",cool!
363,FedIPR: Ownership Verification for Federated Deep Neural Network Models.txt,"Federated learning models are collaboratively developed upon valuable
training data owned by multiple parties. During the development and deployment
of federated models, they are exposed to risks including illegal copying,
re-distribution, misuse and/or free-riding. To address these risks, the
ownership verification of federated learning models is a prerequisite that
protects federated learning model intellectual property rights (IPR) i.e.,
FedIPR. We propose a novel federated deep neural network (FedDNN) ownership
verification scheme that allows private watermarks to be embedded and verified
to claim legitimate IPR of FedDNN models. In the proposed scheme, each client
independently verifies the existence of the model watermarks and claims
respective ownership of the federated model without disclosing neither private
training data nor private watermark information. The effectiveness of embedded
watermarks is theoretically justified by the rigorous analysis of conditions
under which watermarks can be privately embedded and detected by multiple
clients. Moreover, extensive experimental results on computer vision and
natural language processing tasks demonstrate that varying bit-length
watermarks can be embedded and reliably detected without compromising original
model performances. Our watermarking scheme is also resilient to various
federated training settings and robust against removal attacks.","THEsuccessful applications of deep neural network (DNN) to computer vision, natural language processing and data mining tasks come at the cost of the expensive train ing process: a) the training incurs substantial efforts and costs in terms of expertise, dedicated hardware, and exceedingly long time for the designing and training DNN models ; b) it requires a vast amount of training data to boost the model performance, which often increases monotonically with the volume of training data [1], [2], [3], [4]. To protect both the valuable training data and the trained DNN models from being illegally copied, redistributed or misused, therefore, becomes a compelling need that motivates our research work reported in this article. To protect the Intellectual Property Rights (IPR) of Deep Neural Network, DNN watermarking techniques have been proposed in [5], [6], [7], [8], [9], [10], [11], [12] to embed designated watermarks into DNN models. Subsequently, DNN ownership is veriﬁed by robustly extracting the embedded watermarks from the model in question. Note that both featurebased watermarks [9], [10], [11] and backdoorbased watermarks [12] have been proposed to verify ownership of DNN models. In order to protect valuable training data in a collaborative learning setting whereas semihonest adversaries may attempt to espy participants’ private information, a se Bowen Li and Jie Li are with the Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai 200240, China. The work is done when Bowen Li is an intern at WeBank. Email: flibowen, lijiecsg@sjtu.edu.cn. Lixin Fan and Hanlin Gu are with WeBank AI Lab, WeBank, China. Email: lixinfan@webank.com, fLixin.Fan01, ghltsl123 g@gmail.com. Qiang Yang is with the Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Hong Kong and WeBank AI Lab, WeBank, China. Email: qyang@cse.ust.hk. Corresponding author: Lixin Fan.cure federated learning (SFL) framework has been proposed [13], [14], [15] to collaboratively train a federated deep neural network (FedDNN) without giving away to adversaries private training data [16] and data feature distribution [17]. Therefore, each client in federated learning must a) notdis close to other parties any information about private training data; and b) prove ownership of the trained model without disclosing their private watermarks. The ﬁrst requirement has been fulﬁlled by protecting the exchanged local models using techniques such as homomorphic encryption (HE) [18], differential privacy (DP) [19] or secret sharing [20] albeit at cost of degraded model performances [21]. The second requirement is one of the open problems considered in this work. Taking into consideration threat models in both DNN watermarking and secure federated learning, we propose a uniﬁed framework called FedIPR which consists of two separate processes along with standard SFL learning proce dures: a) a watermark embedding process that allows multiple parties to embed their secret featurebased and backdoor based watermarks; b) a veriﬁcation process that allows each party to independently verify the ownership of FedDNN model. Two technical challenges for embedding watermarks into FedDNN model are investigated in this paper: Challenge A: how to ensure that private watermarks embedded by different clients into the same FedDNN model do not discredit each other? This challenge is unique in a federated learning setting whereas different client’s watermarks may potentially conﬂict with each other (see Fig. 3 for an example). As a solution to the challenge, theoretical analysis in Theorem 1 elucidates conditions under which multiple featurearXiv:2109.13236v3  [cs.LG]  24 Aug 20222 based watermarks can be embedded into the same FedDNN model without bringing each other into discredit, and based on the theoretical analysis, a featurebased watermarking method dedicated for horizontal federated learning is proposed. (see Sect. 5.3 for details). Challenge B: how to ensure that embedded watermarks are robust to privacypreserving learning strategies? This challenge is due to modiﬁcations of model parameters brought by various privacy preserving methods e.g., differential privacy [19], defensive aggregation [22], [23], [24] and client selection [13]. As a solution, FedIPR adopts robust clientside training to embed both featurebased and backdoorbased watermarks. Our empirical results in Sect. 6 show that robust featurebased and backdoorbased watermarks are persistent under various federated learning strategies. Moreover, extensive experiments on computer vision and natural language processing tasks demonstrate that feature based watermarks embedded in normalization scale parameters (see Sect. 5.3 for details) are highly reliable, while backdoor based watermarks can be reliably detected for blackbox ownership veriﬁcation. In short, main contributions of our work are threefold: We put forth the ﬁrst general framework called FedIPR for ownership veriﬁcation of DNN models in a secure federated learning setting. FedIPR is designed in such a way that each client can embed his/her own private featurebased and backdoor based watermarks and verify watermarks to claim ownership independently. We demonstrate successful applications of FedIPR for various DNN model architectures trained in the semi honest federated learning setting. Theoretical analysis of the signiﬁcance of featurebased watermarks and superior performance with extensive experimental results showcase the efﬁcacy of the proposed FedIPR framework. FedIPR also provides an effective method to detect freeriders [25], [26] who do not contribute data or computing resources but participate in federated learning to get for free the valuable model. Due to the lack of rightful watermarks embedded in the FedDNN model, freeriders can be discerned from benign participants. To our best knowledge, the FedIPR framework is the ﬁrst technical solution that supports the protection of DNN ownerships in a secure federated learning setting such that secret watermarks embedded in FedDNN models do not disclose to semihonest adversaries. The rest of the paper is organized as follows: Section 2 brieﬂy reviews previous work related to secure feder ated learning and DNN ownership veriﬁcation. Section 3 describes the preliminary background for FedIPR. Section 4 illustrates the proposed FedIPR framework formulation. Section 5 delineates the watermark embedding approaches both in whitebox and blackbox modes, and Section 6 presents experimental results and showcases the robustness of FedIPR. We discuss and conclude the paper in Section 7.2 R ELATED WORK","Deep neural network (DNN) is a powerful machine learning tool that has been widely used in computer vision, natural language processing and data mining tasks. However, successful applications of DNN come at the cost of the expensive training process and the need to protect the valuable training data and the trained DNN models from being illegally copied, redistributed or misused. To address this need, a secure federated learning (SFL) framework has been proposed to collaboratively train a federated deep neural network (FedDNN) without sharing of private training data. However, this requirement has",cool!
494,NormFace: L2 Hypersphere Embedding for Face Verification.txt,"Thanks to the recent developments of Convolutional Neural Networks, the
performance of face verification methods has increased rapidly. In a typical
face verification method, feature normalization is a critical step for boosting
performance. This motivates us to introduce and study the effect of
normalization during training. But we find this is non-trivial, despite
normalization being differentiable. We identify and study four issues related
to normalization through mathematical analysis, which yields understanding and
helps with parameter settings. Based on this analysis we propose two strategies
for training using normalized features. The first is a modification of softmax
loss, which optimizes cosine similarity instead of inner-product. The second is
a reformulation of metric learning by introducing an agent vector for each
class. We show that both strategies, and small variants, consistently improve
performance by between 0.2% to 0.4% on the LFW dataset based on two models.
This is significant because the performance of the two models on LFW dataset is
close to saturation at over 98%. Codes and models are released on
https://github.com/happynear/NormFace","In recent years, Convolutional neural networks (CNNs) achieve stateoftheart performance for various computer vision tasks, such as object recognition [ 12,29,32], detection [ 5], segmentation ∗Alan L. Yuille’s visiting student. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro/f_it or commercial advantage and that copies bear this notice and the full citation on the /f_irst page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior speci/f_ic permission and/or a fee. Request permissions from permissions@acm.org. MM ’17, October 23–27, 2017, Mountain View, CA, USA. ©2017 ACM. ISBN 9781450349062/17/10. . . $15.00 DOI: https://doi.org/10.1145/3123266.3123359[19] and so on. In the /f_ield of face veri/f_ication, CNNs have already surpassed humans’ abilities on several benchmarks[20, 33]. The most common pipeline for a face veri/f_ication application involves face detection, facial landmark detection, face alignment, feature extraction, and /f_inally feature comparison. In the feature comparison step, the cosine similarity or equivalently L2normalized Euclidean distance is used to measure the similarities between features. The cosine similarityh;i kkkkis a similarity measure which is independent of magnitude. It can be seen as the normalized version of innerproduct of two vectors. But in practice the inner product without normalization is the most widelyused similarity measure when training a CNN classi/f_ication models [ 12,29,32]. In other words, the similarity or distance metric used during training is diﬀerent from that used in the testing phase. To our knowledge, no researcher in the face veri/f_ication community has clearly explained why the features should be normalized to calculate the similarity in the testing phase. Feature normalization is treated only as a trick to promote the performance during testing. To illustrate this, we performed an experiment which compared the face features without normalization, i.e.using the unnormalized innerproduct or Euclidean distance as the similarity measurement. The features were extracted from an online available model [ 36]1. We followed the standard protocol of unrestricted with labeled out side data [9] and test the model on the Labeled Faces in the Wild (LFW) dataset[10]. The results are listed in Table 1. Table 1: Eﬀect of Feature Normalization Similarity Before Normalization After Normalization InnerProduct 98.27% 98.98% Euclidean 98.35% 98.95% As shown in the table, feature normalization promoted the per formance by about 0.6% 0.7%, which is a signi/f_icant improvement since the accuracies are already above 98%. Feature normalization seems to be a crucial step to get good performance during testing. Noting that the normalization operation is diﬀerentiable, there is no reason that stops us importing this operation into the CNN model to perform endtoend training. 1https://github.com/ydwen/caﬀefacearXiv:1704.06369v4  [cs.CV]  26 Jul 2017same  Identity different  Identity Training : Testing : aligned  image 2fff ‖‖CNN normalizeinner  product feature 1feature 2 feature weights          classification thresholdingFigure 1: Pipeline of face veri/f_ication model training and testing using a classi/f_ication loss function. Previous works did not use the normalization after feature extraction dur ing training. But in the testing phase, all methods used a normalized similarity, e.g. cosine, to compare two features. Some previous works[ 23,28] successfully trained CNN models with the features being normalized in an endtoend fashion. How ever, both of them used the triplet loss, which needs to sample triplets of face images during training. It is diﬃcult to train be cause we usually need to implement hard mining algorithms to /f_ind nontrivial triplets[ 28]. Another route is to train a classi/f_ication network using softmax loss[ 31,38] and regularizations to limit the intraclass variance[ 16,36]. Furthermore, some works combine the classi/f_ication and metric learning loss functions together to train CNN models[ 31,41]. All these methods that used classi/f_ication loss functions, e.g. softmax loss, did not apply feature normalization, even though they all used normalized similarity measure, e.g. co sine similarity, to get the con/f_idence of judging two samples being of the same identity at testing phase(Figure 1). We did an experiment by normalizing both the features and the weights of the last innerproduct layer to build a cosine layer in an ordinary CNN model. After suﬃcient iterations, the network still did not converge. After observing this phenomenon, we deeply dig into this problem. In this paper, we will /f_ind out the reason and propose methods to enable us to train the normalized features. To sum up, in this work, we analyze and answer the questions mentioned above about the feature normalization and the model training: (1)Why is feature normalization so eﬃcient when comparing the CNN features trained by classi/f_ication loss, especially for soft max loss? (2)Why does directly optimizing the cosine similarity using soft max loss cause the network to fail to converge? (3)How to optimize a cosine similarity when using softmax loss? (4)Since models with softmax loss fail to converge after normaliza tion, are there any other loss functions suitable for normalized features? For the /f_irst question, we explain it through a property of softmax loss in Section 3.1. For the second and third questions, we provide a bound to describe the diﬃculty of using softmax loss to optimize a cosine similarity and propose using the scaled cosine similarity in Section 3.3. For the fourth question, we reformulate a set of loss functions in metric learning, such as contrastive loss and triplet loss to perform the classi/f_ication task by introducing an ‘agent’strategy (Section 4). Utilizing the ‘agent’ strategy, there is no need to sample pairs and triplets of samples nor to implement the hard mining algorithm. We also propose two tricks to improve performance for both static and video face veri/f_ication. The /f_irst is to merge features ex tracted from both original image and mirror image by summation, while previous works usually merge the features by concatenation[ 31, 36]. The second is to use histogram of face similarities between video pairs instead of the mean[ 23,36] or max[ 39] similarity when making classi/f_ication. Finally, by experiments, we show that normalization during training can promote the accuracies of two publicly available state oftheart models by 0:20:4%on LFW[ 10] and about 0:6%on YTF[37]. 2 RELATED WORKS","Convolutional neural networks (CNNs) have achieved state-of-the-art performance in various computer vision tasks, such as object detection, detection, segmentation, and so on. In the field of face verification, the most common pipeline involves face detection, landmark detection, feature extraction, and feature comparison. In the feature comparison step, the cosine similarity or equivalently L2normalized Euclidean distance is used to measure the similarities between features. In practice, the inner product without normalization is the most widely-used similarity measure during training. To illustrate this, we performed an experiment",cool!
180,Octuplet Loss: Make Face Recognition Robust to Image Resolution.txt,"Image resolution, or in general, image quality, plays an essential role in
the performance of today's face recognition systems. To address this problem,
we propose a novel combination of the popular triplet loss to improve
robustness against image resolution via fine-tuning of existing face
recognition models. With octuplet loss, we leverage the relationship between
high-resolution images and their synthetically down-sampled variants jointly
with their identity labels. Fine-tuning several state-of-the-art approaches
with our method proves that we can significantly boost performance for
cross-resolution (high-to-low resolution) face verification on various datasets
without meaningfully exacerbating the performance on high-to-high resolution
images. Our method applied on the FaceTransformer network achieves 95.12% face
verification accuracy on the challenging XQLFW dataset while reaching 99.73% on
the LFW database. Moreover, the low-to-low face verification accuracy benefits
from our method. We release our code to allow seamless integration of the
octuplet loss into existing frameworks.","In recent years, the continuous development of face recognition systems has opened various applications such as automatic phone unlocking, border control, public surveillance, and many more convenient applications. Current state oftheart face recognition systems [1, 2] achieve impressive performance on popular benchmark datasets as LFW [3], MegaFace [4], or IJBB [5]. However, these systems are primarily designed to operate in controlled environments, e.g., on images with high quality or resolution, and their performance signiﬁcantly deteriorates in uncontrolled environments, e.g., on lowresolution images [6]. With the advances towards ever more robust face recognition systems applicable in such crucial scenarios, more and more approaches are being published. Various approaches focus on robust face recognition against age gaps, head pose variances, alignments, adversarial attacks, occlusions, and masks. Only a few authors focus on image resolution (cf. Sec. 2). Knoche et al. [7] extensively analyzed the susceptibility of face recognition systems to image resolution. Their work demonstrates that face veriﬁcation accuracy for the popular ArcFace [1] approach with a ResNet50 [8] as the backbone network is dropping signiﬁcantly for image resolutions below about 5050px. As illustrated later in our experiments, we conﬁrm this effect also on other architectures such as MobileNet [9] or iResNet50 [10]. In [7], the authors also stated that the face transformer structure [11] is less affected by varying image resolution, which is in line with our ﬁndings in Sec. 4. 1Code available on https://github.com/martlgap/octupletlossarXiv:2207.06726v2  [cs.CV]  21 Mar 2023Octuplet Loss A P REPRINT HIGH R ESOLUTION LOW  R ESOLUTION  Octuplet Loss  Figure 1: The proposed octuplet loss exploits the relation between four highresolution images (upper left) and four lowresolution images (lower right) incorporating four triplet loss ( Ltri) terms. Generally, one can distinguish between two face recognition scenarios concerning image resolution: 1) Lowresolution face veriﬁcation considers two facial images with the same low resolution. 2) The validation of two images with different resolutions is described as crossresolution face veriﬁcation. Despite the increased amount of information present in highresolution images, the latter problem is even more challenging due to the distinct inherent visual properties of high and lowresolution images. This emerges in the context of surveillance applications where, e.g., lowresolution surveillance images are compared with highquality passport images. Another example is the automatic tagging of people in movies or social media, where image resolution is often compromised due to compression. In this work, we tackle crossresolution face recognition with a novel metric learning approach called octuplet loss ﬁnetuning. This objective constitutes ﬁnetuning an existing network to increase its robustness against image resolution while maintaining its performance in controlled scenarios. As depicted in Fig. 1, we exploit the advantages of the widespread triplet loss [12] and build upon it. Our key innovation is the combination of four triplet loss terms, which exploit the relationship between high and lowresolution images and identity labels. Our main contributions are summarized as follows: •We propose a novel loss function called octuplet loss that leverages four triplet loss terms to capture the relationships between high and lowresolution faces. •A ﬁnetuning strategy is introduced, which can be easily applied to existing networks to improve their robustness against image resolution while maintaining comparable performance on highresolution images. •We demonstrate that ﬁnetuning several stateoftheart networks with our proposed octuplet loss leads to signiﬁcant improvements for crossresolution and lowresolution face veriﬁcation on numerous popular datasets. The rest of our paper is organized as follows: in Sec. 2, we review the literature related to this area; Sec. 3 introduces the triplet loss concept, describes the applied mining strategy, and presents the octuplet loss function in detail; in Sec. 4, we describe datasets and experimental settings, followed by quantitative results, i.e., improvements on existing networks with our approach and ablation studies; ﬁnally, Sec. 5 concludes this work and indicates possible directions for further research. 2Octuplet Loss A P REPRINT 2 Related Work","In this work, we address the challenge of cross-resolution face recognition with a novel metric learning approach called octuplet loss finetuning. This objective constitutes fine-tuning an existing network to increase its robustness against image resolution while maintaining its performance in controlled scenarios. We propose a novel loss function called octuplet loss that leverages four triplet loss terms to capture the relationship between high-resolution and low-resolution images and identity labels. We demonstrate that fine-tuning several state-of-of-of-art networks with our",cool!
482,Fail-Safe Execution of Deep Learning based Systems through Uncertainty Monitoring.txt,"Modern software systems rely on Deep Neural Networks (DNN) when processing
complex, unstructured inputs, such as images, videos, natural language texts or
audio signals. Provided the intractably large size of such input spaces, the
intrinsic limitations of learning algorithms, and the ambiguity about the
expected predictions for some of the inputs, not only there is no guarantee
that DNN's predictions are always correct, but rather developers must safely
assume a low, though not negligible, error probability. A fail-safe Deep
Learning based System (DLS) is one equipped to handle DNN faults by means of a
supervisor, capable of recognizing predictions that should not be trusted and
that should activate a healing procedure bringing the DLS to a safe state. In
this paper, we propose an approach to use DNN uncertainty estimators to
implement such a supervisor. We first discuss the advantages and disadvantages
of existing approaches to measure uncertainty for DNNs and propose novel
metrics for the empirical assessment of the supervisor that rely on such
approaches. We then describe our publicly available tool UNCERTAINTY-WIZARD,
which allows transparent estimation of uncertainty for regular tf.keras DNNs.
Lastly, we discuss a large-scale study conducted on four different subjects to
empirically validate the approach, reporting the lessons-learned as guidance
for software engineers who intend to monitor uncertainty for fail-safe
execution of DLS.","Deep neural networks (DNNs) are a powerful tool to identify patterns in large amounts of data and to make predictions on new, previously unseen data. Thanks to the increased hardware capabilities, DNNs can be run even on small, battery powered hardware and can be trained in performanceoptimized GPUs. Correspondingly, the use of DNNs has gained a lot of popularity in the last decade. Moreover, the introduction of high level APIs such as tf.keras (see tensorﬂow.org) allows even software engineers withou t previous experience in artiﬁcial intelligence to deﬁne, tr ain This work was partially supported by the H2020 project PRECR IME, funded under the ERC Advanced Grant 2017 Program (ERC Grant A greement n. 787703). Accepted at ICST2021. © 2021 IEEE. Personal use of this mater ial is permitted. Permission from IEEE must be obtained for all oth er uses, in any current or future media, including reprinting/republishi ng this material for advertising or promotional purposes, creating new collect ive works, for resale or redistribution to servers or lists, or reuse of any copyri ghted component of this work in other works.and use custom DNNs. DNNs are now used in many Deep Learning based Systems (DLS) , like self driving cars, to interpret observed sensor measurements and control the car ’s actuators, in medical systems, to support physicians to mak e their diagnosis, and in web services, for image processing a nd analysis. Relying solely on the predictions made by a deep learning component might be dangerous, as there is always some uncertainty about the correctness of the prediction. In fact, thecontract between the overall system and its DNN based components is necessarily a probabilistic one, and while th e probability of an error can be low, it is never zero. The uncertainty intrinsic with DNNs is either caused by entropy in the input or by inadequate training. While the ﬁrst type of uncertainty is inherent to a problem and cannot be avoided by deﬁnition, the latter cannot also be avoided for practical reasons: in most applications, the input spac e consists of a huge number of input contexts (e.g., the differ ent weather or light conditions in which a car is driven), and it is impossible to collect data which perfectly represents al l of them. Faced with a problem for which a prediction is subject to high uncertainty, a human intelligence may consider to refu se to make a prediction and instead say ‘I do not know’. DNNs on the other hand, will calculate a prediction for any given input, independently of the uncertainty of the prediction. If such predictions are trusted by a DLS, the DLS may fail due to a wrong prediction, as is best illustrated by the followin g two examples: a selfdriving car has recently crashed into an overturned truck. A likely explanation for such a crash is that overturned trucks are not sufﬁciently represented i n the cars training data. [1] Second, an online photo storage serv ice classiﬁed an image of a black person as a a picture of a gorilla , leading to negative press, which deemed the service as racis t. Again, such error is likely caused by insufﬁcient training d ata of the machine learning component which classiﬁed the image . [2] The fact that problems like these happen even in software from leading companies in the machine learning domain shows that preventing such errors is quite challenging. Even more so, in the second example the solution put in place was a drastic workaround: the label Gorilla was removed from the set of possible predictions for any input. We propose that DLS include a supervisor , which monitorsthe DNN uncertainty for any given input at runtime, such that the system can ignore predictions for highuncertainty inp uts and can run a safe fallback process instead, such as stopping the selfdriving car at the side of the street or, in the secon d example, delegating the classiﬁcation of the image to a huma n. The machine learning community has investigated uncertaintyaware types of DNNs, which support the deployment of such a supervisor. This paper aims at closing the gap between uncertaintyaware DNNs and the deployment of an effective supervisor in a DLS. Speciﬁcally, it makes th e following contributions: Metrics Comparison Description and comparison of the most investigated uncertainty metrics for DNNs, with a discussion of their advantages and disadvantages. UNCERTAINTY WIZARD Python library which allows zero knowledge, transparent implementation of uncertainty aware DNNs. Evaluation Framework We present existing and propose novel metrics to evaluate DLS which include a supervisor. Lessons learned We discuss key ﬁndings from our empirical evaluation of various uncertainty metrics applied to four different case studies. II. B ACKGROUND In this section, we discuss the different root causes of DNN faults which can be understood as types of uncertainty and deﬁne the task of DNN fault prediction as a problem of uncertainty quantiﬁcation. A. Sources of Uncertainty We distinguish between two types of uncertainty; uncer tainty caused by a suboptimal DNN model and uncertainty caused by randomness in the prediction target. A detailed discussion of these types is provided by Kendall et al. [3]. Deﬁnition 1 (Epistemic Uncertainty): Epistemic uncertainty is caused by the suboptimal training or conﬁguration of the model . Epistemic uncertainty is sometimes also referred to as model uncertainty . There are many possible reasons for epistemic uncertainty, such as insufﬁcient training data, which does not represent the entire possible input space, suboptimal training hyperparameters and inadequate DNN architectur e. In theory, epistemic uncertainty could be avoided, provide d good enough training data and optimal model conﬁguration. However, ﬁnding such optimal training conﬁgurations and da ta is impossible in most real world applications, as real input spaces, as well as the space of the possible hyperparameter s and architectural choices, are typically too large. The second type of uncertainty, which not even an optimal training set and model conﬁguration can avoid, is called aleatoric uncertainty : Deﬁnition 2 (Aleatoric Uncertainty): Aleatoric uncertainty is the uncertainty present in the true (unknown) distributi on we are making predictions about. Thus, aleatoric uncertainty can be seen as randomness, ambiguity or entropy in the prediction target. When predict ing (a)  (b)  (c)  (d)  (e) Fig. 1: Examples of uncertainties in digits classiﬁcation: (a) and (b) cause no uncertainty, (c) causes aleatoric uncertai nty, (d) and (e) cause epistemic uncertainty. a random event, even an optimal model will make wrong predictions. As aleatoric uncertainty is independent of th e model, but instead depends on the predicted data, it is also referred to as data uncertainty orirreducible uncertainty . Aleatoric Uncertainty can be further distinguished betwee n homoscedastic uncertainty , where the uncertainty applies to all data, and heteorscedastic uncertainty , where the uncertainty is more prevalent amongst some subsets of the data. Figure 1 provides a visual example of the difference be tween aleatoric and epistemic uncertainty. The input to a classiﬁer DNN is the image of a handwritten digit to be recognized. Figures 1a and 1b illustrate regular inputs wit h low uncertainty. Figure 1c is an example of a ﬁgure with high heteroscedastic aleatoric uncertainty: Clearly, the imag e shows either a 1 or a 4, but it is impossible to say with certainty which one the writer intended. Figure 1d illustrates a commo n reason for epistemic uncertainty: A small perturbation of t he image background, if not present in the training data, may lead the model to be incapable of predicting the correct labe l. Similarly, 1e shows an unexpected input leading to epistemi c uncertainty. While the true label is unambiguously 4, a mode l which was not trained on roman number representations will not be capable to make a correct prediction. B. Uncertainty Quantiﬁcation Ideally, instead of predicting a single value as output, a DNN should calculate a probability density function for regression problems or a likelihood for every outcome in a classiﬁcation problem. As such, every outcome would have its uncertainty quantiﬁed (e.g., by the variance of the outp ut probability distribution). We will discuss models capable of calculating such outputs in Section III. However, for the scope of this paper, we consider a less general formulation of uncertainty quantiﬁcation, which is sufﬁcient for netwo rk supervision [4]: Deﬁnition 3 (Uncertainty Quantiﬁcation): Uncertainty Quantiﬁcation (UQ) is the task of calculating a scalar metri c strictly monotonically increasing in the likelihood (for c lassi ﬁcation tasks) or severity (for regression tasks) of a devia tion between the DNN prediction and the ground truth, given a particular input and the DNN used to do the prediction. We are thus limiting our interest to the correctness of the chosen prediction, as opposed to the distribution of all pos sible predictions in the output space. The supervisor will reject inputs for which the uncertainty is above a certain threshol d. 2Consistently, we deﬁne conﬁdence as the opposite of uncer tainty, s.t. a conﬁdence metric is supposed to strictly mono  tonically decrease in the likelihood or severity of a predic tion error. III. U NCERTAINTY AWARE NEURAL NETWORKS While regular DNNs, also called PointPrediction DNNs (PPNN) , predict a single scalar value for every output vari able, from the perspective of uncertainty quantiﬁcation it would be preferable if the DNN calculated a distribution ove r possible output values, which would allow the extraction of the network’s conﬁdence in the prediction. In this section we discuss the various DNN architectures which allow the calculation of such distributions: ﬁrst, we provide an over view onBayesian Neural Networks (BNN) , which are the standard approach in the machine learning literature about uncertai nty quantiﬁcation.1Second, we discuss other approaches, which typically have some theoretical disadvantages when compar ed to BNNs, but showed good results in practice. [6] A. Pure Bayesian Neural Networks BNNs are neural networks in which weights are proba bilistic, instead of scalar as in PPNN, and are represented a s probability density functions. To train a BNN, ﬁrst, a prior distribution p(θ)over weights θhas to be deﬁned. Then, given some data D, the posterior distribution p(θ|D), i.e., the trained BNN is inferred using Bayes rule: p(θ|D) =p(D|θ)p(θ) p(D)=p(D|θ)p(θ)/integraltext p(D|θ)p(θ)dθ(1) Since weights are probabilistic, any output of the BNN is also probabilistic and thus allows a statistically wellfo unded uncertainty quantiﬁcation. Besides that, these BNNs in the ir pure form have other advantages over PPNN, among which: they are robust to overﬁtting [7] and allow to distinguish between epistemic and aleatoric uncertainty [5]. BNNs in the pure form presented above quickly become intractable due to the large number of integrations require d. There has been a long search for mechanisms which make BNN easier to compute, with papers dating back to the early 1990s [7], [8]. To do so, some approaches make additional assumptions, e.g., a normal distribution of the weights, wh ich may cause the BNN to lose some of the advantages listed above. Still, despite many advances in the ﬁeld, even recent approaches are considered not to scale sufﬁciently well [9] and are not yet widely used in practice [5]. Other, more scalable approaches have been shown to outperform Bayesian approaches [6] on practical benchmarks. B. MCDropout based Bayesian Neural Networks In their very inﬂuential paper2, Gal et al. [10] proposed to approximate BNNs though regular PPNNs. Many PPNNs 1For a more precise discussion of BNN, we recommend the compre hensive and usageoriented article by Jospin et al. [5]. 2More than 2300 citations in the four years since its publicat ion, according to Google Scholar.usedropout layers for regularization. During training, in a dropout layer each neuron activation can be set to 0 with some probability p. This helps to avoid overﬁtting and can lead to better model performance in general [11]. In their paper, Ga l et al. have shown that a PPNN trained with dropout enabled can be interpreted as a BNN, due to the variation induced by the randomized dropout layers. While traditionally the dro pout functionality is disabled at prediction time, a dropoutba sed BNN keeps the random dropping of neuron activations enabled even during predictions and calculates an output distribut ion by MonteCarlo sampling of the results in multiple randomiz ed predictions. This approach is thus often referred to as MC Dropout . Despite its high popularity, MCDropout is not without criticisms: Osband [12] claimed the inability of MCDropou t to capture every type of uncertainty and several papers have shown that it can be outperformed by other approaches [6], [13]. Also, despite the fact that ”the forward passes can be done concurrently, resulting in constant running time” [10], concurrent processing may not be possible in resource  constrained environments, making MCDropout clearly slow er than a single prediction of the corresponding PPNN. C. Deep Ensemble Neural Networks Lakshminarayanan et al. proposed a fundamentally different approach to quantify uncertainty called Deep Ensembles , or Ensemble for short, i.e., a collection of multiple atomic models for the same problem, differing only in their initializatio n and trained independently. For every input, a prediction would be made on every atomic model. The predictive distribution cou ld then be inferred from these samples. While deep ensembles are not inherently BNNs, it is possible to interpret them as BNN after applying some minor changes to the parameter regularization [14]. Nonetheless, even in their plain form , they have been shown to outperform MCDropout on the task of uncertainty quantiﬁcation [6], [13]. Deep Ensembles are, compared to a single PPNN, slow to train if executed sequentially and memory intensive if used concurrently. This may prevent the use of ensembles in some constrained environments. A variety of improvements and modiﬁcations have been proposed for Deep Ensembles (Ilg et al. [9] provide a good overview of them). D. Point Predictor Classiﬁers DNNs used for classiﬁcation typically have a softmax output layer, including one output neuron per class. The output for each class is between 0and1, with the sum of all outputs being exactly 1. These outputs are often interpreted as probability distributions over the classes and are used f or network supervision by means of the following quantiﬁers: Deﬁnition 4 (MaxSoftmax (SM)): The highest softmax score is used as conﬁdence quantiﬁcation (also referred to a s Vanilla [6] or Softmax Prediction Probability [15] quantiﬁca tion). Deﬁnition 5 (Prediction Conﬁdence Score (PCS) [16]): The difference between the two highest softmax outputs is used a s conﬁdence quantiﬁcation. 3Uncertainty aware DNNClassiﬁ cationRegre ssionBNNCustom LayersTraining EffortPrediction EffortMain AdvantageMain Disadvantage Variants of pure BNNYes Yes YesWeight distributionsHigh or intractable*High or intractable*Theoretically well foundedCustom architecture, computationally hard* MC Dropout Yes Yes Yes Dropout Minimal HighFastest BNN approximationSampling for predictions is costly Deep EnsemblesYes Yes No* No High HighGood practical results, no major architecture requirementsComputationally and storage intensive PPNNSoftmax basedYes No No Softmax Miminal Minimal Fast and SimpleMisleading and no regression TABLE I: Overview of popular uncertaintyaware DNN techniq ues (* = approach dependent) Deﬁnition 6 (SoftmaxEntropy (SME)): The entropy over the outputs of the softmax layer is used as conﬁdence quantiﬁca tion. These quantiﬁers are often criticized as a poor approach to uncertainty quantiﬁcation: As opposed to BNNs and BNN approximations, PPNN based quantiﬁers are not theoretical ly well founded, and can be shown to severely overestimate a network’s conﬁdence [10]. As a further disadvantage, such a PPNN based approach can not be directly applied to regressio n problems. E. Inferring Prediction and Uncertainty from Samples In MCDropout and Deep Ensembles, samples need to be aggregated into a point prediction and uncertainty quantiﬁ ca tion, and the literature provides a variety of quantiﬁers ab le to do so. In this Section, we ﬁrst discuss the quantiﬁers applic able to regression problems, and then the ones for classiﬁcation problems. a) Regression Problems: In their proposition of MC Dropout, Gal et al. [10] propose to use the average of the observed samples as prediction, and their predictive varia nce as uncertainty: Deﬁnition 7 (Predictive Variance): The predictive variance is the sample variance over the observed samples plus the inverse model precision. The inverse model precision is constant for a given model. Thus, for the purpose of network supervision, where strictl y monotonic transformations of uncertainty quantiﬁcation s cores do not change the supervisor performance, using predictive variance is equivalent to using the sample variance or the sa m ple standard deviation. An alternative approach was propos ed by Lakshminarayanan et al. [13]. For their deep ensembles, they propose that the atomic models are adapted s.t. they hav e a second output variable for every regression output which predicts the variance [17]. The uncertainty of the ensemble can then be quantiﬁed by averaging these variances. b) Classiﬁcation Problems: The following quantiﬁers are proposed to derive an overall prediction and uncertainty: Deﬁnition 8 (MeanSoftmax (MS)): The overall prediction is the class with the highest sum of softmax scores over all samples and the corresponding conﬁdence is the average softmax score of this class over all samples.model=wizard.models.StochasticSequential() # Use as a regular tf.keras model model.add(tf.keras.layers.Dense(100) model.add(tf.keras.layers.Dropout( 0.2) model.add(tf.keras.layers.Softmax( 10) model.compile( ...) model.fit(...) # Use as standard (nonwizard) model regular_nn_output =model.predict(x_test) # Predict as PointPredictor w/ confidence pred_pp, pcs =model.predict_quantified(x_test, quantifier ='pcs') # Predict as Bayesian Model w/ uncertainty pred_b, var_r =model.predict_quantified(x_test, num_samples =100, quantifier ='var_ratio' ) Listing 1: KerasSyntax Stochastic Model model= ...# load or create plain keras model model=wizard.models.stochastic_from_keras(model) # model can now be used as pointpredictor # and as bayesian model, i.e., model.predict( ...) model.predict_quantified( ...) Listing 2: Convert PreTrained Model MS has been proposed and is often used with Deep En sembles. It is thus also called ensembling [5]. Three other quantiﬁers have been proposed to be used with MCDropout [10], [18], [19]: Variation Ratio (VR) , which is deﬁned as the percentage of samples for which the overall chosen class is not the class with the highest softmax output; Predictive Entropy (PE) , which measures the average amount of information in the predicted distributions; and the Mutual Information (MI) between a prediction and the models posterior (see Gal, 2016 [10], Section 3.3.1 for a precise description and for examples of these three uncertainty quantiﬁers). IV. UNCERTAINTY WIZARD With 148’742 stars and 82’784 forks on github.com, Ten sorﬂow is presumably the most popular deep learning frame work.3[20] In its recent versions, a large part of its API, tf.keras , is based on the popular Keras API, a simple yet powerful highlevel API to develop, train and deploy DNNs. The simplicity of the tf.keras API allows researchers and practitioners outside of the machine learning community to get 3Its main alternative, PyTorch has 42’621 stars and 11’102 forks. 4started with deep learning easily. Unfortunately, such sim ple API does not expose equally simple methods to quantify uncer  tainty. Thus, we release UNCERTAINTY WIZARD , an extension oftf.keras which allows developers to easily create Stochastic and Ensemble DNNs and apply all uncertainty quantiﬁers described in Section III. The core features of UNCERTAINTY  WIZARD are: Sequential API Sequential models are the most straightfor ward way to use tf.keras and are thus very popular. However, the sequential API does not allow dropout at prediction time. Hence, it also does not allow the implementation of MCDropout. UNCERTAINTY WIZARD closes this gap by supporting the creation of stochastic models using the sequential, as well as the functional, API in plain tf.keras syntax. An example of this is given in Listing 1. Dynamic Randomness Intf.keras , the dropout behavior at prediction time is unchangeable for a given model: Either it is disabled (as required in point predictors) or enabled (as required in stochastic models). Thus, despite relying on the same architecture and weights, a tf.keras model cannot be used both as stochastic model and as point predictor. Converting them is nontrivial and includes the creation of a new model, which is memory and per formance intensive. UNCERTAINTY WIZARD ’s sequential models dynamically enable and disable stochastic be havior based on whether the passed quantiﬁer expects a point prediction or sampled predictions. This is shown in Listing 1 as well. Conversion from Keras Often, the user of a DNN is not the same person or group that trained the model. To allow users to use such a model for MCDropout nonethe less, UNCERTAINTY WIZARD supports the import of any tf.keras model (which has at least one dropout layer) as a stochastic model. Parallelized Ensembles tf.keras API does not expose simple functionality for parallel training of multiple models. Especially with smaller models, which do not require the full use of the existing hardware to be loaded and executed, sequential training of an ensembles atomic models has a large negative impact on training and prediction time. Additionally, it can also lead to pollutio n of the global tensorﬂow runtime due to memory leaks and eager processing.4UNCERTAINTY WIZARD treats ensembles lazily: every atomic model is stored on the ﬁle system, and lazily loaded into its own tensorﬂow runtime during execution. This allows faster, parallelize d execution without runtime pollution. DependencyLight pip install UNCERTAINTY WIZARD is platform independent, importable through pip install uncertaintywizard and has only one dependency: Tensorﬂow version 2.3.0 or later. Due to space constraints, the description of UNCERTAINTY  WIZARD at this place is brief. We provide a more extensive 4See e.g. tensorﬂow issues 33030 and 37505.discussion in a technical tool paper [21]. UNCERTAINTY  WIZARD and a comprehensive user guide can be found online: github.com/testingautomatedusi/uncertaintywizard V. S UPERVISED NEURAL NETWORK ASSESSMENT Network supervision can be viewed as a binary classi ﬁcation task: malicious samples , i.e., inputs which lead to a misclassiﬁcation (for classiﬁcation problems) or to seve re imprecision (in regression problems) are positive samples that have to be rejected. Other samples, also called benign samples , are negative samples in the binary classiﬁcation task. An uncertainty based supervisor accepts an input ias a benign sample if its uncertainty u(i)is lower than some threshold t. The choice of tis a crucial setting, as a high twill fail to reject many malicious samples (false negatives) and a low t will cause too many false alerts (false positives). Differently from standard binary classiﬁcation tasks, the choice of tfor network supervision cannot rely on the op timization of an aggregate metric that accounts for both fal se positives and false negatives, such as the F1metric, becau se negative samples are either completely unknown at training time, or, in case some negative samples are known, they canno t be assumed to be representative of all unknown execution conditions that will give raise to uncertainty at runtime. H ence, the choice of tis solely based on the false positives observed in the validation set. In practice, given the uncertainties me asured on the validation set, tshall ensure that at runtime under similar conditions only an acceptable false positive rate ǫis expected to occur [22]. Existing metrics allow the individual assessment of the supervisor’s performance separately from the assessment o f the model performance [23]. However, such measurements do not take into account the interaction between the two: since the output of the model is not used by the DLS when the supervisor activates the fail safe procedure ( u(i)≥t), it does not make any sense to evaluate the performance of the model in such scenarios. For this reason, we propose a new approach for the joint assessment of model and supervisor, which we call supervised metrics . In the next two sections we ﬁrst summarize the state of the art metrics for the separate, individual assessment of model and supervisor, followed by a description of our proposal of a new joint assessment approach. A. Existing Metrics for the Individual Assessment of Model and Supervisor There are well established metrics for the individual as sessment of performance of a model m. These are based on some objective function obj(I,m), such as accuracy (ACC) (for classiﬁers) or meansquared error (MSE) (for regression models), computed on a test dataset I.5 Classically, the supervisor’s performance would be assess ed individually using performance metrics designed for binar y 5We assume that objhas to be maximized. The extension to an objthat should be minimized is straightforward. Also note that objdoes not have to be the same function used to optimize the DNN during training . 5classiﬁers. For a given t, the available metrics include true positive rate (TPR) ,false positive rate (FPR) ,true negative rate (TNR) andfalse negative rate (FNR) ,F1score and ac curacy (ACC) . To use these metrics with regression problems, anacceptable imprecision would have to be deﬁned, allowing to divide inputs into benign (negative cases) and malicious (positive cases). Alternatively, the effect of the predict ions on the overall DLS system could be monitored to only treat input s leading to system failures as malicious ones [22]. There are also existing, classical metrics to assess a binar y classiﬁer independently of the threshold t. For instance, the average precision score (AVGPR) computes the average of the precision values obtained when varying t, weighted by the recall measured at t. Another popular threshold independent metric is the area under the receiver operating characteristic curve (AUROC) [15], [19], [22]. When individually assessing the performance of a supervisor, A VGPR should be preferred over AUROC as, amongst other advantages [24], it is better suited for the unbalanced datasets [25] typically observed dur ing malicious input detection. Threshold independent anal ysis of the supervisor in a regression problem is straightforwar d and can be done using pointbiserial correlation between th e quantiﬁed uncertainty and the observed prediction error, g iven some objective function (e.g. MSE). Independent analysis of model’s performance, considered i n isolation without supervision, and of the supervisor’s per for mance, again in isolation, results in measurements that do n ot capture the overall goal of the interaction between supervi sor and model under supervision: ensuring high model perfor mance on the samples considered safe by the supervisor, whil e keeping the amount of samples considered unsafe as small as possible. To capture such goal, we propose novel metrics for joint model and uncertainty quantiﬁcation assessment i n a supervised DLS. B. Supervised Metrics for the Joint Assessment of Model and Supervisor When considering model and supervisor jointly, we can still use the objective function used to assess the model in isolation, but we evaluate it in a supervised context: given a test setIand an objective function obj(I,m)for model m with uncertainty quantiﬁer uand supervisor threshold t, the supervised objective function obj(I,m)is deﬁned as: obj(m,I) =obj({i|i∈Iandu(i)< t}) i.e., the objective is applied only to the subset of inputs which is accepted by the supervisor. By decreasing t, assuming that the cardinality of the resulting subset of inputs remai ns big enough to calculate a statistically signiﬁcant obj(I), we may generally get higher values of the supervised objective function obj(I). However, such high values of obj(I)are likely associated with a high false alarm rate of the supervi sor. Thus, any obj(I)should always be regarded in conjunction with the acceptance rate ∆u(I)of the supervisor: ∆u(I) =| {i|i∈Iandu(i)< t} | |I|Similar to the popular F1score, the following combination of these two metrics allows to capture the effectiveness of t he collaboration between supervised model and supervisor: Deﬁnition 9 (SScore): TheS1Score measures the harmonic mean of a supervised objective function, normalized betwee n zero and one, and the supervisors acceptance rate as S1(m,u,I) =2 obj+ obj(I,m)−obj−+∆u(I)−1 whereobj−andobj+are the lower and upper bounds used for normalization of the objective function. For classiﬁer s, if accuracy is the objective function, obj−:= 0 andobj+:= 1. For regression problems, or more generally for unbounded objective functions, obj−andobj+have to be estimated empirically (e.g., based on the empirical distribution of t he objective function values), independently from mandu. TheS1scores weights ∆u(I)andobj(m,I)equally. Equiv alent to the popular F1score, other Sβscores can be used, whereβ >0is the weighting parameter [26]: Sβ(m,u,I) = (1+ β2)·obj(I,m)−obj− obj+·∆u(I) (β2·obj(I,m)−obj− obj+)+∆u(I) VI. C ASE STUDIES We assess the uncertainty quantiﬁcation capabilities of po int predictors, deep ensemble and MC dropout using different quantiﬁers. We intentionally focus our study on uncertaint y quantiﬁers which can be applied to traditional and widely used DNN architectures, and we exclude those implement ing the pure Bayesian form of uncertainty estimation, since they require the adoption of dedicated architectures where the network weights encode a probability distribution, not just a scalar value. This restriction, in combination with UNCERTAINTY WIZARD , allows developers to measure uncer tainty at minimal effort, given a traditional DNN. The goal of our empirical evaluation is to assess the usefulness of th e uncertainty quantiﬁers supported by UNCERTAINTY WIZARD when used as supervisors, as well as to collect lessons learn ed that practitioners can follow when applying UNCERTAINTY  WIZARD to their DNNs. A. Research Questions We consider the following research questions: RQ 1(effectiveness): How effective are supervisors at increas ing the supervised model’s performance? This is the key research question of our empirical study, since the main hypothesis behind supervisors is that they ca n prevent usage of a model when its performance is predicted to be low. Hence, we expect an increase of the supervised model’ s performance objas compared to the unsupervised one obj. RQ 2(comparison): Is there a supervisor and quantiﬁer type which yield optimal performance across subjects and across alternative choices of the uncertainty threshold? We consider three types of uncertainty estimators, Point Pr e dictors, MCDropout and Ensemble, and several uncertainty 6Nominal (regular test data) Out of Distribution (corrupted test data) ǫ= 0.01 ǫ= 0.1 ǫ= 0.01 ǫ= 0.1 Technique ACC SC ACC ∆uS1 SC ACC ∆uS1ACC SC ACC ∆uS1 SC ACC ∆uS1Cifar10 Point Pred.SM 0.82 0.67 0.83 0.97 0.90 0.67 0.90 0.80 0.85 0.82 0.47 0. 83 0.98 0.90 0.52 0.89 0.81 0.85 PCS 0.82 0.71 0.83 0.97 0.90 0.70 0.90 0.80 0.85 0.82 0.49 0 .83 0.97 0.90 0.54 0.89 0.81 0.85 SME 0.82 0.64 0.84 0.97 0.90 0.61 0.91 0.80 0.85 0.82 0.50 0 .83 0.97 0.90 0.54 0.89 0.80 0.84MC DropoutVR 0.82 0.68 0.84 0.98 0.90 0.68 0.90 0.82 0.86 0.82 0.63 0. 83 0.98 0.90 0.62 0.89 0.82 0.85 PE 0.82 0.70 0.84 0.97 0.90 0.63 0.90 0.82 0.86 0.82 0.59 0. 83 0.97 0.90 0.43 0.88 0.83 0.85 MI 0.82 0.76 0.84 0.97 0.90 0.64 0.89 0.82 0.86 0.82 0.57 0. 83 0.98 0.90 0.54 0.88 0.83 0.86 MS 0.82 0.66 0.84 0.97 0.90 0.67 0.91 0.81 0.86 0.82 0.56 0. 83 0.98 0.90 0.52 0.89 0.81 0.85Ensem bleVR 0.86 0.66 0.87 0.97 0.92 0.78 0.93 0.83 0.88 0.87 0.67 0. 87 0.98 0.92 0.74 0.93 0.83 0.87 PE 0.86 0.78 0.87 0.98 0.92 0.81 0.92 0.84 0.88 0.87 0.69 0. 87 0.98 0.92 0.63 0.91 0.85 0.88 MI 0.86 0.78 0.87 0.98 0.92 0.83 0.92 0.84 0.88 0.87 0.68 0. 87 0.98 0.92 0.72 0.91 0.84 0.87 MS 0.86 0.73 0.87 0.97 0.92 0.80 0.94 0.83 0.88 0.86 0.67 0. 87 0.98 0.92 0.64 0.93 0.83 0.88Mnist Point Pred.SM 0.96 0.80 0.97 0.99 0.98 0.89 0.99 0.88 0.93 0.74 0.13 0. 84 0.82 0.83 0.88 0.96 0.48 0.64 PCS 0.96 0.79 0.97 0.99 0.98 0.86 0.99 0.88 0.93 0.74 0.32 0 .80 0.88 0.84 0.87 0.96 0.49 0.65 SME 0.96 0.90 0.97 0.99 0.98 0.92 1.00 0.88 0.93 0.74 0.20 0 .85 0.79 0.82 0.90 0.96 0.47 0.63MC DropoutVR 0.97 0.63 0.97 0.98 0.98 0.77 0.99 0.87 0.93 0.74 0.15 0. 82 0.85 0.84 0.64 0.95 0.51 0.67 PE 0.97 0.73 0.97 0.99 0.98 0.81 1.00 0.87 0.93 0.74 0.10 0. 85 0.79 0.82 0.81 0.97 0.45 0.62 MI 0.97 0.72 0.97 0.98 0.98 0.87 0.99 0.87 0.93 0.74 0.15 0. 79 0.88 0.83 0.61 0.91 0.55 0.69 MS 0.96 0.71 0.97 0.99 0.98 0.84 1.00 0.88 0.93 0.74 0.03 0. 84 0.82 0.83 0.76 0.96 0.47 0.64Ensem bleVR 0.97 0.74 0.98 0.98 0.98 0.81 0.98 0.95 0.97 0.74 0.30 0. 86 0.78 0.82 0.75 0.91 0.65 0.76 PE 0.97 0.89 0.97 0.99 0.98 0.93 0.99 0.88 0.93 0.74 0.34 0. 86 0.77 0.81 0.89 0.97 0.45 0.61 MI 0.97 0.82 0.97 0.98 0.98 0.87 1.00 0.87 0.93 0.74 0.45 0. 87 0.71 0.78 0.86 0.98 0.42 0.59 MS 0.97 0.87 0.97 0.98 0.98 0.89 1.00 0.88 0.93 0.75 0.48 0. 86 0.79 0.82 0.91 0.96 0.46 0.63Trafﬁc Point Pred.SM 0.81 0.02 0.90 0.89 0.89 0.27 0.97 0.75 0.85 0.79 0.02 0.9 0 0.85 0.88 0.16 0.97 0.70 0.81 PCS 0.81 0.04 0.90 0.89 0.89 0.21 0.97 0.75 0.84 0.79 0.03 0.9 0 0.85 0.88 0.20 0.97 0.70 0.81 SME 0.81 0.09 0.90 0.89 0.89 0.38 0.98 0.72 0.83 0.79 0.00 0. 90 0.86 0.88 0.36 0.98 0.66 0.79MC DropoutVR 0.81 0.24 0.91 0.87 0.89 0.42 0.98 0.70 0.82 0.79 0.40 0. 91 0.84 0.88 0.42 0.98 0.66 0.79 PE 0.81 0.18 0.90 0.89 0.89 0.40 0.98 0.70 0.81 0.79 0.14 0. 89 0.86 0.88 0.42 0.98 0.65 0.78 MI 0.81 0.23 0.90 0.88 0.89 0.44 0.98 0.70 0.81 0.79 0.37 0. 89 0.87 0.88 0.44 0.98 0.65 0.78 MS 0.81 0.09 0.91 0.87 0.89 0.38 0.98 0.70 0.81 0.79 0.19 0. 91 0.84 0.88 0.37 0.98 0.65 0.78Ensem bleVR 0.81 0.56 0.94 0.84 0.89 0.57 0.97 0.76 0.86 0.80 0.47 0. 93 0.82 0.87 0.64 0.97 0.73 0.83 PE 0.81 0.46 0.92 0.85 0.89 0.47 0.98 0.69 0.81 0.80 0.55 0. 93 0.82 0.87 0.51 0.99 0.63 0.77 MI 0.81 0.59 0.94 0.84 0.89 0.46 0.98 0.69 0.81 0.80 0.64 0. 94 0.82 0.87 0.56 0.99 0.63 0.77 MS 0.81 0.47 0.93 0.85 0.89 0.48 0.98 0.69 0.81 0.80 0.45 0. 93 0.82 0.87 0.52 0.99 0.63 0.77Imagent Point Pred.SM 0.74 n.a. 0.77 0.95 0.85 n.a. 0.84 0.79 0.81 0.50 n.a. 0.61 0 .79 0.69 n.a. 0.75 0.54 0.63 PCS 0.74 n.a. 0.76 0.97 0.85 n.a. 0.84 0.79 0.81 0.50 n.a. 0.55 0.89 0.68 n.a. 0.72 0.57 0.64 SME 0.74 n.a. 0.76 0.96 0.85 n.a. 0.83 0.80 0.81 0.50 n.a. 0.60 0.80 0.68 n.a. 0.73 0.55 0.63MC DropoutVR 0.74 0.37 0.76 0.96 0.85 0.73 0.84 0.78 0.81 0.50 0.69 0. 56 0.87 0.68 0.84 0.71 0.57 0.63 PE 0.74 0.12 0.76 0.96 0.85 0.43 0.83 0.79 0.81 0.50 0.48 0. 61 0.78 0.69 0.51 0.75 0.53 0.62 MI 0.74 0.39 0.75 0.98 0.85 0.52 0.82 0.81 0.81 0.50 0.52 0. 52 0.93 0.67 0.76 0.67 0.58 0.62 MS 0.74 0.07 0.77 0.96 0.85 0.17 0.85 0.78 0.81 0.50 0.40 0. 61 0.79 0.69 0.37 0.76 0.52 0.62 TABLE II: Overview of supervision capabilities of differen t techniques, i.e., model types and quantiﬁer combinations for different thresholds. quantiﬁers, respectively [SM, PCS, SME], [VR, PE, MI, MS], [VR, PE, MI, MS] (see Section III). We want to investigate whether any combination of estimator type and quantiﬁer dominates all the others in terms of S1score. To investigate how performance changes with the uncertainty threshold t, we consider different acceptable rates ǫof false positives on the nominal data and we compute the threshold tthat ensures such FPR on the validation set, so that we can compare alternative estimators/quantiﬁers at equal FPR on the validation set of the nominal data. RQ 3(sample size): How many samples are required in stochastic and ensemble models to get reliable uncertainty quantiﬁcation? Since the main cost associated with the usage of MC Dropout and Ensemble is the collection of multiple samples f or each individual prediction, we want to understand what is th e minimum sample size that ensures good performance of each different supervisor. In particular, we study the converge nce of supervised accuracy to its asymptotic value as the sample size is increased. RQ 4(sensitivity): How sensitive are supervisors to changes in their main hyperparameters? With this research question we want to understand whetherthe choice of hyperparameters is critical to get optimal performance, or on the contrary if they can be chosen in the neighbourhood of the optimal choice with minor impact on the resulting performance of the supervisor. For Point Predictors, we consider the number of training epochs as the main hyperparameter; for MCDropout, the number of trainin g epochs and the number of samples; for Ensemble, the number of training epochs and the number of atomic models. We measure the standard deviation of the supervised objective function (e.g., supervised accuracy) in the neighbourhood of each hyperparameter choice, so as to identify the regions where such standard deviation is low. B. Subjects We use the following classiﬁcation problems as case study subjects, aiming to increase diversity and practical relev ance. Mnist [27] Classiﬁcation of handwritten digits, formatted as small grayscale images. This is the most popular dataset in machine learning testing [4], and a relatively easy problem, where even simple models achieve high accuracy. We took the DNN architecture from a Keras tutorial [28]. 7Cifar10 [29] Classiﬁcation of colored images into ten differ ent classes. It is also very popular in DLS testing [4] and it represents a more challenging task than Mnist. We use the model architecture proposed in the Brownlees Cifar10 tutorial [30]. Trafﬁc [31] Classiﬁcation of images of European trafﬁc signs [32]–[39]. The different sources the data was col lected from, combined with the fact that the dataset is unbalanced and many images are of bad quality, reﬂect a quite realistic, highuncertainty setup. Since trafﬁc si gn recognition is a core component of selfdriving cars, this is also a very interesting case study from the software and system engineering point of view. The model archi tecture we use was proposed alongside the release of this dataset [31]. Imagenet [40] (Pretrained) Image classiﬁcation problem with as many as 1,000 classes. We use eight pretrained Efﬁcientnet models [41]. As for this subject we rely on pretrained models (which include dropout layers), we can test them only as MCDropout and Point Predictor models, but not as Ensembles. C. Experimental Setup Except for the pretrained ones, models were trained for 200 epochs. After every epoch, we assessed the models’ per formance on both a nominal and an outofdistribution (OOD) dataset, for every quantiﬁer. To do so, we used Mnistc [42] a s OOD test set for Mnist and the colorimage transformations proposed by Hendrycks [43] to generate OOD samples for the other subjects. We used three different thresholds, calcul ated on the nominal validation set to ensure the lowest possible FPR above ǫ, withǫ∈ {.01,.5,.1}respectively. To measure the sensitivity to the number of samples, quantiﬁers of deep ensembles were assessed with every number of atomic models between 2 and 50, Similarly, MCDropout was assessed on every number of samples between 2 and 100. Counting atomic models individually, this procedure re quired the training of 153 DNNs, and the calculation of 2’121’600 DNN predictions6. Due to the high workload, the training and prediction processes were distributed on thre e different workstations using Windows or Ubuntu and four dif  ferent GPUs (one workstation had two GPUs). UNCERTAINTY  WIZARD was used for training, prediction and uncertainty quantiﬁcation.7 D. Results We organize the analysis of the results obtained in our experiments by research question. 1) RQ1 (Effectiveness): An overview of our results is provided in Table II. Due to space constraints, the results f or ǫ= 0.05are omitted in the table and the values for the 8 6Predictions were cached, such that for the evaluation of dif ferent sample sizes and different numbers of atomic models, previous pred ictions could be reused. 7Replication package available at: github.com/testingautomatedusi/repliicst2021unce rtaintyPer Subject Overall mnist cifar10 trafﬁc Trained PreTrained Technique N=6 N=6 N=6 N=18 N=48Point Pred.SM 3.33 9.67 2.42 5.14 3.56 PCS 2.67 9.83 3.17 5.22 3.5 SME 5.67 10.0 2.92 6.19 4.42MC DropoutVR 5.83 5.83 5.67 5.78 3.55 PE 7.0 6.67 5.5 6.39 4.5 MI 6.67 6.83 5.75 6.42 5.12 MS 5.33 7.17 6.58 6.36 3.34Ensem bleVR 4.17 3.17 4.5 3.94 n.a. PE 8.17 1.33 10.25 6.58 n.a. MI 10.17 3.0 10.25 7.81 n.a. MS 7.0 2.5 9.0 6.17 n.a. TABLE III: RankOrder Analysis: S1Score ranks, averaged overǫ∈ {0.01,0.05,0.1}, nominal and OOD datasets different Imagenet models are averaged. The full set of resu lts can be found in the online replication package. Our results suggest that all supervisors lead to supervised accuracies ACC which are at least as high, but typically much higher than the accuracy ACC of the unsupervised model. Thus, supervisors are effective. The effectiveness is particularly strong on the OOD datasets: For example, on Mnist, where the unsupervised point predictor has an accura cy of 74%, the supervised accuracy at ǫ= 0.1, is above 95% with most supervisors. In other words, a DLS using an unsupervise d model will experience six times more faulty predictions tha n the unsupervised one. Also notable are the results on the nominal Mnist dataset, where even simple supervisors based on point predictors turn an unsupervised accuracy of 96% (at ǫ= 0.1) into that of a nearly perfect predictor while still accepting around 88% of the inputs. Summary (RQ1) :All tested supervisors are, in gen eral, effective at increasing the supervised accuracy compared to the unsupervised accuracy. 2) RQ2 (Comparison): If we look at the S1Score in Table II, it is apparent that there is no uncertainty quantiﬁ er which outperforms all the other ones on every subject/datas et and for every threshold ( ǫ). To allow for an overall comparison of the quantiﬁers, we computed the average ranks of the quantiﬁers when ordered by S1Score. Results are shown in Table III, where Nindicates the number of data points on which average ranks have been computed. While there is no absolute dominant supervisor, i.e., the ideal choice o f supervisor remains problem dependent, Ensembles can be considered the overall best performing supervisors (in lin e with existing literature [6]), because when they do not have the lowest rank, they still have quite low rank values. Actually , even without supervision Ensembles often achieve higher accuracy than Point Predictors and MCDropout based models . Interestingly, in most cases the sophisticated quantiﬁers PE and MI, grounded on information theory, do not perform better and often perform worse than the simpler quantiﬁers VR and AS. Despite the theoretical disadvantages of Point Predict ors, in our experiments this simple approach outperformed the 8(a)  (b) Fig. 2: Inﬂuence of sample size in MCDropout (a) and number of atomic models in Ensemble (b) on supervised accuracy acc; values taken with ǫ= 0.1and MS quantiﬁer on nominal dataset theoretically well founded MCDropout. So, in practical ca ses as those considered in our experiments, Point Predictors ma y represent a good tradeoff between performance and compu tational cost. Summary (RQ2) :There is no dominant supervisor, i.e., no supervisor which performs best for every test subject, data source and threshold. Ensembles are ranked generally well across subjects and thresholds, while Point Predictors offer a valuable trade off be tween performance and execution cost. 3) RQ3 (Sample size): We ﬁnd that for both MCDropout and Ensembles the relatively low number of 20 samples is already sufﬁcient to get a similar supervised accuracy as wi th a much higher number of samples. This is shown in Figure 2 for the MS quantiﬁer and ǫ= 0.1. 20 samples, while still higher than what’s recommended in related literature [6], is proba bly small enough to be used in practice in many applications. The other quantiﬁers behave similarly, with one notable except ion, which is the VR quantiﬁer: VR can only take a ﬁnite set of discrete values, which can be easily shown to be equal to the number of samples. Hence, a low sample size makes it impossible to set thresholds well ﬁt to the target ǫ, because thresholds are correspondingly also discrete and limited t o the number of samples. So, to achieve the target FPR ǫprecisely, we might need substantially more than 20 samples. Summary (RQ3) :A few ( /tildelow20) samples are enough to get good supervision results with most quantiﬁers (VR represents an exception, due to the discretization of the values it can take). 4) RQ4 (Sensitivity): The number of training epochs and the number of samples/atomic models can be visualized as a 200 (number of epochs) by 100 (number of samples) or 50 (number of atomic models) grid. To assess the sensitivity of supervisors, we calculate the standard deviation ( std) of (a)  (b) Fig. 3: Average (a) and standard deviation (b) of the Ensem ble’s supervised accuracy accwithǫ= 0.1on OOD data, computed for the Trafﬁc subject inside a 5x5 neighbourhood of each conﬁguration ACC within a 5x5 ﬁlter applied to this grid. In this way, we account for the variability of the supervised accuracy in a 5x5 neighbourhood of each hyperparameter conﬁguration. The higher the std, the higher the sensitivity to small hyper  parameter changes in the neighbourhood. We also calculate the average ACC in such 5x5 neighbourhood. The result is a pair of heatmaps, an example of which is shown in Figure 3. This ﬁgure suggests that hyperparameter sensitiv ity negatively correlates with ACC : Hyperparameters leading to low accuracy (bright colors in Figure 3a) typically show high sensitivity to hyperparameter changes (dark colors in Figure 3b). We do indeed observe this negative correlation f or all case studies. The values of pointbiserial correlation , shown in the SC (SensitivityCorrelation) columns of Table II, are strongly negative in most cases, with pvalue<0.05in 358 out of 390 cases. In low accuracy cases, small changes to number of samples and number of epochs have a high effect on accuracy. Summary (RQ4) :For a given supervisor and model, for what concerns the number of training epochs and samples used for quantiﬁcation, the higher the supervised accuracy, the lower the model’s sensitivity to small hyperparameter changes. E. Lessons Learned Based on our answers to the RQs, we distilled the following primary lessons learned, possibly useful for a practical us age of uncertaintyquantiﬁers based uncertainty monitoring f or DLS robustness: Anything is better than nothing: While the selection of the ideal supervisor is problem dependent, all the supervisors we tested showed some capability to increase the accu racy of the DNN when supervised. Thus including any uncertainty monitoring supervisor in a DLS increases its failsafety. 9Ensembles are powerful: Not only did Ensembles show the best average rank on the S1score (ignoring the pre trained Imagenet studies), in many cases even the unsu pervised accuracy increased. Furthermore, the relatively low number of 20 atomic models was sufﬁcient to achieve good results in our study. Thus, provided sufﬁcient system resources, we suggest software architects to use Ensem bles instead of Point Predictors. On the other hand, the latter may represent a good compromise solution when computational resources are severely constrained. Number of samples affects choice of quantiﬁer: For Ensembles and MCDropout, VR was the best quantiﬁer on average, but it requires a large number of samples to allow for precise threshold selection. Thus, if computational resources allow the calculation of a high number of samples, our experiments suggest to use VR as quantiﬁer. Otherwise, MS showed good performance, despite its simplicity. Inproduction supervisor assessment is needed: Since there is no uncertainty quantiﬁer which performs best in all cases, we want to emphasize the importance of inproduction assessment of the supervisors performance on the actual system to be supervised, by comparing different supervisors for optimal selection. The metrics that we propose in Section V are speciﬁcally designed for such assessment. F . Threats to Validity External Validity : While we considered only four subjects, we diversiﬁed them as much as possible. In particular, besid es the benchmark subjects often used in DNN testing (Mnist, Cifar10 and Imagenet), we included an additional subject, Trafﬁc, which consists of unbalanced data, partially of low quality. It implements a functionality (trafﬁc sign recogn ition) commonly integrated in autonomous vehicles. Internal Validity : The selection of hyperparameters for DNN training might be critical and the selected values may no t be representative of other contexts. To address this threat , we refrained from selecting any hyperparameter for the case st udy models ourselves, wherever possible, and instead relied on architectures available from the literature. For what conc erns the internal hyperparameters of the supervisors, we evalua ted the sensitivity of the results to their choice in a dedicated research question (RQ4). Another threat to the internal validity of our study is that the OOD inputs used in our experiments might not be representative of the uncertainties that may be observed in practice. Indeed, this is unavoidable and intrinsic to the p rob lem of DNN supervision, as unexpected conditions occurring in practice cannot be by deﬁnition simulated ahead of time. VII. R ELATED WORK","Deep neural networks (DNNs) are a powerful tool to identify patterns in large amounts of data and to make predictions on new, previously unseen data. However, relying solely on the predictions made by a DNN component might be dangerous, as there is always some uncertainty about the correctness of the prediction. The uncertainty intrinsic with DNNs is either caused by entropy in the input or by inadequate training. In this paper, we propose that Deep Learning based Systems (DLS) include a supervisor, which monitors the DNN uncertainty for any given input at runtime",cool!
128,Quantum Robustness Verification: A Hybrid Quantum-Classical Neural Network Certification Algorithm.txt,"In recent years, quantum computers and algorithms have made significant
progress indicating the prospective importance of quantum computing (QC).
Especially combinatorial optimization has gained a lot of attention as an
application field for near-term quantum computers, both by using gate-based QC
via the Quantum Approximate Optimization Algorithm and by quantum annealing
using the Ising model. However, demonstrating an advantage over classical
methods in real-world applications remains an active area of research. In this
work, we investigate the robustness verification of ReLU networks, which
involves solving a many-variable mixed-integer programs (MIPs), as a practical
application. Classically, complete verification techniques struggle with large
networks as the combinatorial space grows exponentially, implying that
realistic networks are difficult to be verified by classical methods. To
alleviate this issue, we propose to use QC for neural network verification and
introduce a hybrid quantum procedure to compute provable certificates. By
applying Benders decomposition, we split the MIP into a quadratic unconstrained
binary optimization and a linear program which are solved by quantum and
classical computers, respectively. We further improve existing hybrid methods
based on the Benders decomposition by reducing the overall number of iterations
and placing a limit on the maximum number of qubits required. We show that, in
a simulated environment, our certificate is sound, and provide bounds on the
minimum number of qubits necessary to approximate the problem. Finally, we
evaluate our method within simulation and on quantum hardware.","Despite recent breakthroughs of machine learning models, they have been shown to be brittle to adversarial examples – small perturbations added to an input designed by an adversary to deceive the model [1, 2]. Such adversarial examples differ only by anto the original input measured by some norm, e.g., in the image domain these perturbations are often imperceptible to the human eye. This vulnerability raises questions about the applicability of machine learning models in highrisk areas such as autonomous driving [3] or fraud detection [4]. The project/research is supported by the Bavarian Ministry of Economic Affairs, Regional Development and Energy with funds from the Hightech Agenda Bayern.Consequently, research on (adversarial) robustness of ma chine learning models has gained importance. Even though empirical defenses, like speciﬁc training techniques [5] or architectures [6] improve the robustness of the neural networks and provide little inference time overhead, they are easy to break [7, 8, 9]. Provable certiﬁcates for robustness are advantageous as they guarantee the robustness of an instance to any adversarial attack with an admissible perturbation set, e.g., in our case being the inﬁnity norm ball around the input. However, they come at a large computational cost as the search space grows exponentially with increasing network sizes. Even for ReLU networks, which are especially attractive due to the simple nature of their activation function, the complete veriﬁcation problem has been shown to be NPcomplete [10]. The development of quantum computing (QC) hardware and software has seen signiﬁcant progress over the recent years, e.g., recently quantum supremacy has been shown in an academic sample [11]. However, practical applications of QC remain an active area of research as current quantum computers belong to the category of Noisy Intermediate Scale Quantum (NISQ) devices. They are characterized by their relatively small number (around 100) qubits, noise and relatively small connectivity between the qubits. Therefore, it is infeasible to perform large and complex calculation solely on a quantum computer. Instead, current algorithms are of hybrid nature and require an interaction between classical and quantum computers. With the motivation of exploiting the superposition of the exponentially large space of qubits, entanglement and interference effects, combinatorial optimization has received a lot of attention both within the gatebased QC and quantum annealing (QA) via the Quantum Approximate Optimization Algorithm (QAOA) [12] and the Ising model, respectively [13]. In this work, we propose to leverage the combinatorial power of QC to verify the robustness of ReLU networks by proposing a hybrid quantumclassical algorithm. Since the ReLU non linearity may be reformulated as a binary variable, one can represent the veriﬁcation problem as a mixedinteger program (MIP) [14, 15]. We apply Benders decomposition to partition the MIP into a quadratic unconstrained binary optimization (QUBO) and a linear program (LP) [16, 17]. Thus, the resulting ©20xx IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works.arXiv:2205.00900v2  [quantph]  12 Aug 2022algorithm is an iterative process where the LP generates cuts for the QUBO which is solved by a quantum computer or a quantum annealer. To the best of our knowledge, this is the ﬁrst work of certifying neural networks with quantum computers. As the current hardware cannot compete with classical solvers, this algorithm should be understood as a proof of concept. However, as the availability of increasingly more powerful computers increases, we may see polynomial speedups [18]. Moreover, we show that our method is sound in an ideal, simulated setting and converges to the exact solution in the limit. For the modiﬁcations required for current QC hardware, we show that our optimization objective is conservative, i.e., the objective value of our approach is a lower bound to the one of the exact veriﬁcation. Additionally, we derive bounds for the minimum number of qubits necessary and provide an experimental evaluation of our approach on a conventional computer, a quantum annealing simulation as well as real QC hardware. In summary, our core contributions are: 1)Introducing the ﬁrst Hybrid QuantumClassical Robust ness Algorithm for Neural network veriﬁcation HQ CRAN . 2) Proving the soundness of the certiﬁcate. 3)Estimating the number of qubits necessary to achieve reasonable certiﬁcate quality, absent in Chang, Jones, and Graf [17]. 4)Decreasing the overall number of qubits and required amount of iterations to converge compared to Chang, Jones, and Graf [17] and Zhao, Fan, and Han [19]. 5)Evaluating HQCRAN on quantum annealers and com puters. II. R ELATED WORK","In this work, we propose a hybrid quantum-classical algorithm for verifying the robustness of ReLU neural networks. The verification problem is a mixed-integer program (MIP) with a quadratic unconstrained binary optimization (QUBO) and a linear program (LP). The MIP is then partitioned into a quadratic unconstrained binary optimization (QUBO) and a linear program (LP). The LP generates cuts for the QUBO which is solved by a quantum computer or a quantum computer. We derive bounds for the",cool!
307,Convexified Convolutional Neural Networks.txt,"We describe the class of convexified convolutional neural networks (CCNNs),
which capture the parameter sharing of convolutional neural networks in a
convex manner. By representing the nonlinear convolutional filters as vectors
in a reproducing kernel Hilbert space, the CNN parameters can be represented as
a low-rank matrix, which can be relaxed to obtain a convex optimization
problem. For learning two-layer convolutional neural networks, we prove that
the generalization error obtained by a convexified CNN converges to that of the
best possible CNN. For learning deeper networks, we train CCNNs in a layer-wise
manner. Empirically, CCNNs achieve performance competitive with CNNs trained by
backpropagation, SVMs, fully-connected neural networks, stacked denoising
auto-encoders, and other baseline methods.","Convolutional neural networks (CNNs) [28] have proven successful across many tasks in machine learning and articial intelligence, including image classication [28, 25], face recognition [26], speech recognition [21], text classication [45], and game playing [32, 37]. There are two principal advantages of a CNN over a fullyconnected neural network: (i) sparsity|that each nonlinear convolutional lter acts only on a local patch of the input, and (ii) parameter sharing|that the same lter is applied to each patch. However, as with most neural networks, the standard approach to training CNNs is based on solving a nonconvex optimization problem that is known to be NPhard [6]. In practice, researchers use some  avor of stochastic gradient method, in which gradients are computed via backpropaga tion [7]. This approach has two drawbacks: (i) the rate of convergence, which is at best only to a local optimum, can be slow due to nonconvexity (for instance, see the paper [19]), and (ii) its statistical properties are very dicult to understand, as the actual performance is determined by some combination of the CNN architecture along with the optimization algorithm. In this paper, with the goal of addressing these two challenges, we propose a new model class known as convexied convolutional neural networks (CCNNs). These models have two desirable features. First, training a CCNN corresponds to a convex optimization problem, which can be solved eciently and optimally via a projected gradient algorithm. Second, the statistical properties of CCNN models can be studied in a precise and rigorous manner. We obtain CCNNs by convexifying Computer Science Department, Stanford University, Stanford, CA 94305. Email: zhangyuc@cs.stanford.edu . yComputer Science Department, Stanford University, Stanford, CA 94305. Email: pliang@cs.stanford.edu . zDepartment of Electrical Engineering and Computer Science and Department of Statistics, University of California Berkeley, Berkeley, CA 94720. Email: wainwrig@eecs.berkeley.edu . 1arXiv:1609.01000v1  [cs.LG]  4 Sep 2016twolayer CNNs; doing so requires overcoming two challenges. First, the activation function of a CNN is nonlinear. In order to address this issue, we relax the class of CNN lters to a reproducing kernel Hilbert space (RKHS). This approach is inspired by our earlier work [48], involving a subset of the current authors, in which we developed this relaxation step for fullyconnected neural networks. Second, the parameter sharing induced by CNNs is crucial to its eectiveness and must be preserved. We show that CNNs with RKHS lters can be parametrized by a lowrank matrix. Further relaxing the lowrank constraint to a nuclear norm constraint leads to our nal formulation of CCNNs. On the theoretical front, we prove an oracle inequality on generalization error achieved by our class of CCNNs, showing that it is upper bounded by the best possible performance achievable by a twolayer CNN given innite data|a quantity to which we refer as the oracle risk|plus a model complexity term that decays to zero polynomially in the sample size. Our results show that the sample complexity for CCNNs is signicantly lower than that of the convexied fullyconnected neural network [48], highlighting the importance of parameter sharing. For models with more than one hidden layer, our theory does not apply, but we provide encouraging empirical results using a greedy layerwise training heuristic. We then apply CCNNs to the MNIST handwritten digit dataset as well as four variation datasets [43], and nd that it achieves the stateoftheart performance. On the CIFAR10 dataset, CCNNs outperform CNNs of the same depths, as well as other baseline methods that do not involve nonconvex optimization. We also demonstrate that building CCNNs on top of existing CNN lters improves the performance of CNNs. The remainder of this paper is organized as follows. We begin in Section 2 by introducing convolutional neural networks, and setting up the empirical risk minimization problem studied in this paper. In Section 3, we describe the algorithm for learning twolayer CCNNs, beginning with the simple case of convexifying CNNs with a linear activation function, then proceeding to convexify CNNs with a nonlinear activation. We show that the generalization error of a CCNN converges to that of the best possible CNN. In Section 4, we describe several extensions to the basic CCNN algorithm, including averaging pooling, multichannel input processing, and the layerwise learning of multilayer CNNs. In Section 5, we report the empirical evaluations of CCNNs. We survey related work in Section 6 and conclude the paper in Section 7. Notation. For any positive integer n, we use [n] as a shorthand for the discrete set f1;2;:::;ng. For a rectangular matrix A, letkAkbe its nuclear norm, kAk2be its spectral norm (i.e., maximal singular value), and kAkFbe its Frobenius norm. We use `2(N) to denote the set of countable dimensional vectors v= (v1;v2;:::) such thatP1 `=1v2 `<1. For any vectors u;v2`2(N), the inner producthu; vi:=P1 `=1uiviand the`2normkuk2:=p hu; uiare well dened. 2 Background and problem setup In this section, we formalize the class of convolutional neural networks to be learned and describe the associated nonconvex optimization problem. 22.1 Convolutional neural networks. At a high level, a twolayer CNN1is a particular type of function that maps an input vector x2Rd0 (e.g., an image) to an output vector in y2Rd2(e.g., classication scores for the d2classes). This mapping is formed in the following manner: First, we extract a collection of Pvectorsfzp(x)gP j=1of the full input vector x. Each vector zp(x)2Rd1is referred to as a patch , and these patches may depend on overlapping components ofx. Second, given some choice of activation function :R!Rand a collection of weight vectors fwjgr j=1inRd1, we compute the functions hj(z) :=(w> jz) for each patch z2Rd1. (1) Each function hj(forj2[r]) is known as a lter, and note that the same lters are applied to each patch|this corresponds to the parameter sharing of a CNN. Third, for each patch index p2[P], lter index j2[r], and output coordinate k2[d2], we introduce a coecient k;j;p2Rthat governs the contribution of the lter hjon patchzp(x) to outputfk(x). The nal form of the CNN is given by f(x) : = (f1(x);:::;fd2(x)), where the kth component is given by fk(x) :=rX j=1PX p=1k;j;phj(zp(x)): (2) Taking the patch functions fzpgP p=1and activation function as xed, the parameters of the CNN are the lter vectors w:=fwj2Rd1:j2[r]galong with the collection of coecient vectors :=fk;j2RP:k2[d2];j2[r]g. We assume that all patch vectors zp(x)2Rd1are contained in the unit`2ball. This assumption can be satised without loss of generality by normalization: By multiplying a constant   >0 to every patch zp(x) and multiplying 1 = to the lter vectors w, the assumption will be satised without changing the the output of the network. Given some positive radii B1andB2, we consider the model class Fcnn(B1;B2) :=n fof the form (2) : max j2[r]kwjk2B1and max k2[d2];j2[r]kk;jk2B2o : (3) When the radii ( B1;B2) are clear from context, we adopt Fcnnas a convenient shorthand. 2.2 Empirical risk minimization. Given an inputoutput pair ( x;y) and a CNN f, we letL(f(x);y) denote the loss incurred when the output yis predicted via f(x). We assume that the loss function Lis convex and LLipschitz in its rst argument given any value of its second argument. As a concrete example, for multiclass classication with d2classes, the output vector ytakes values in the discrete set [ d2] =f1;2;:::;d 2g. 1Average pooling and multiple channels are also an integral part of CNNs, but these do not present any new technical challenges, so that we defer these extensions to Section 4. 3For example, given a vector f(x) = (f1(x);:::;fd2(y))2Rd2of classication scores, the associated multiclass logistic loss for a pair ( x;y) is given byL(f(x);y) :=","Convolutional neural networks (CNNs) have been widely used in machine learning and artificial intelligence. However, the standard approach to training a CNN is based on solving a nonconvex optimization problem that is known to be NP-hard. In practice, researchers use some form of stochastic gradient method, in which gradients are computed via backpropagation. However, this approach has two drawbacks: (i) the rate of convergence, which is at best only to a local optimum, can be slow due to nonconvexity, and (i",cool!
67,GOAT: GPU Outsourcing of Deep Learning Training With Asynchronous Probabilistic Integrity Verification Inside Trusted Execution Environment.txt,"Machine learning models based on Deep Neural Networks (DNNs) are increasingly
deployed in a wide range of applications ranging from self-driving cars to
COVID-19 treatment discovery. To support the computational power necessary to
learn a DNN, cloud environments with dedicated hardware support have emerged as
critical infrastructure. However, there are many integrity challenges
associated with outsourcing computation. Various approaches have been developed
to address these challenges, building on trusted execution environments (TEE).
Yet, no existing approach scales up to support realistic integrity-preserving
DNN model training for heavy workloads (deep architectures and millions of
training examples) without sustaining a significant performance hit. To
mitigate the time gap between pure TEE (full integrity) and pure GPU (no
integrity), we combine random verification of selected computation steps with
systematic adjustments of DNN hyper-parameters (e.g., a narrow gradient
clipping range), hence limiting the attacker's ability to shift the model
parameters significantly provided that the step is not selected for
verification during its training phase. Experimental results show the new
approach achieves 2X to 20X performance improvement over pure TEE based
solution while guaranteeing a very high probability of integrity (e.g., 0.999)
with respect to state-of-the-art DNN backdoor attacks.","Every day, Artiﬁcial Intelligence (AI) and Deep Learning (DL) are incorporated into some new aspects of the society. As a result, numerous industries increasingly rely on DL models to make decisions, ranging from computer vision to natural language processing [ 1,2,3,4,5,6,7,8]. The training process for these DL models requires a substantial quantity of computational resources (often in a distributed fashion) for training, which traditional CPUs are unable to fulﬁll. Hence, special hardware, with massive parallel computing capabilities such as GPUs, is often utilized [ 9]. At the same time, the DL model building process is increasingly outsourced to the cloud. This is natural, as applying cloud services (e.g., Amazon EC2, Microsoft Azure or Google Cloud) for DL training can be more ﬁscally palatable for companies by enabling them to focus on the software aspect of their products. Nevertheless, such outsourcing raises numerous concerns with respect to the privacy and integrity of the learned models. In recognition of the privacy and integrity concerns around DL (and Machine Learning (ML) in general), a considerable amount of research has been dedicated to applied cryptography, in three general areas: 1) MultiParty Computation (MPC) (e.g., [ 10]), 2) Homomorphic Encryption (HE) (e.g., [ 11]), and 3) Trusted Execution Environment (TEE) (e.g., [ 12,13]). However, the majority of these investigations are limited in that: 1) they are only applicable to simple shallow network models, 2) they are evaluated with datasets that have a small number of records (such as MNIST [ 14] and CIFAR10 [ 15]), and 3) they incur a substantial amount of overhead that is unacceptable for reallife DL training workloads. In their effort to mitigate some of these problems, and securely move from CPUs to GPUs, Slalom [16] mainly focus on the computational integrity at the testphase while depending on the application context. It can also support enhanced data privacy, however, at a much greater performance cost. To address these limitations, we introduce GOAT (See Figure 1); a framework for integritypreserving learning as a service that provides integrity guarantees in outsourced DL model training in TEEs. We assume that only the TEE running in the cloud is trusted, and all the other resources such as GPUs can be controlled by an attacker to launch an attack (e.g., insert a trojan). In this context, our goal is to support the realistic deep learning training workloadsarXiv:2010.08855v1  [cs.CR]  17 Oct 2020APREPRINT Randomness ∇tW0 Wt+1 Batch Forward BackwardSGD(0) SGD(t) W1W2Wt Forward Backward Forward BackwardForward BackwardUpdate Clip ∇t Figure 1: The main architecture of GOAT . The TEE handles minibatch selection, layer speciﬁc randomness, and parameter initialization. The GPU performs forward and backward passes over the minibatch and reports the computed gradients to TEE for gradient clipping, weight updates, and preserving intermediate reports in case this step is selected for veriﬁcation inside the TEE. while ensuring data and model integrity. To achieve this goal, we focus on the settings where maintaining the learning process’s integrity is critical, while the training data may not contain privacy sensitive information. For example, we may want to build a trafﬁc sign detection model on public trafﬁc sign images and may still like to prevent attacks that can insert trojan during the training phase. Furthermore, we want to provide assurances that the model is trained on the speciﬁed dataset, with known parameters so that the performance of the model can be replicated and audited for accountability and integrity. The trivial approach of executing the entire learning process inside a TEE is not scalable since TEEs are much slower compared to GPUs. Furthermore, even the existing performance improvement techniques (e.g., random matrix veriﬁcation provided in [16]) are not enough to scale up to large DL model learning settings. To alleviate the TEE bottleneck, we propose incorporating random veriﬁcation of the computation steps. This strategy is based on the observation that it is unnecessary to verify all of the GPU’s computation steps. Rather, we only need to verify occasionally to catch any deviation with a very high likelihood. Given that random veriﬁcation may itself be insufﬁcient (theoretically, an attacker can launch a successful attack by modifying only a single unconstrained gradient update), we further show how parts of the DL hyperparameter setting process, such as clipping rate should be modiﬁed to prevent single step attacks, and require a larger number of malicious updates by an attacker that controls the GPU. Simply, GOAT limits the amount of change an adversary can inﬂict on a model through a single SGD step. As a consequence, the adversary is forced to keep attacking while randomly being veriﬁed by the TEE. Using the stateoftheart backdoor attacks, we illustrate that random veriﬁcation technique can detect attacks with a high probability (e.g., 0.99) while enabling 2x20x performance gains compared to pure TEE based solutions. The speciﬁc contributions of this paper are as follows: •We introduce the ﬁrst approach to support integritypreserving DL training by random veriﬁcation of stochastic gradient (SGD) steps inside TEE to ensure the integrity of training pipeline data, parameters, computation function, etc. with a high probability. •We illustrate how gradient clipping can be used as a defensive measure against single (or infrequent) step attack in combination with random veriﬁcation. •We show the effectiveness of our TEE random veriﬁcation and gradient clipping through extensive experimen tation on DNN backdoor attacks. 2 Background Our system combines deep learning training on specialized fast hardware such as Graphical Processing Units (GPU) with Intel Software Guard Extensions (SGX) based TEE to ensure the produced model’s integrity. Details on SGD training and gradient clipping are provided in Appendices B and C. 2APREPRINT 2.1 Attacks on DNN Models in Training Phase Attacks on DNN models can be realized during both training ortestphases. However, GOAT is concerned with integrity/accountability issues during the training phase of DNN models, such that attacks related to testing are out of the scope of this paper since test time attacks ( [ 17,18]) have been addressed before (e.g., Slalom [16]). In the literature, particularly in the computer vision domain, targeted trojan attacks on DNN classiﬁcation models have become a real concern as deep learning has grown in its adoption. These attacks tend to alter the prediction of models if a speciﬁc condition in the input is met. These conditions may be featurebased [19,20,21] orinstancebased [22,23]. Recently, trojan attacks have been extended to Reinforcement Learning (RL) and text classiﬁcation models [24, 25]. In practice, these attacks are implemented by manipulating samples during training through data poisoning. For instance, stamping images with a pattern and modifying its label. Interestingly, these models provide similar competitive classiﬁcation test accuracy compared to clean models (i.e., models have not been attacked). As a consequence, it is nontrivial to distinguish these trojaned models from nontrojaned ones based on model accuracy alone. To make matters worse, even if the model owner was aware of examples of the trojan trigger pattern, the owner would need to patch the model through retraining to dampen the efﬁcacy of the trojan trigger pattern. Retraining does not always guarantee complete removal of the trojan behavior from the model. To date, various techniques have been proposed to diagnose and mitigate of trojaned models. However, all approaches are either based on unrealistic assumptions or are excessively costly. For instance, the Neural Cleanse [ 26] requires access to a sizable sample of clean inputs to reverseengineer the backdoor and has shown to be successful only for trigger patterns with a relatively small size. ABS [ 27] improves upon Neural Cleanse in that requires a signiﬁcantly smaller number of samples; however, it assumes that the responsible trojan neurons can activate trojan behavior independently from each other, which is unlikely to be true in practice. Attacking the training pipeline to inject a trojan(s) in the ﬁnal model is the cheapest and, thus, is likely the most desirable form of attack for realworld adversaries to launch. As such, throughout this work, we mainly focus on showing our methods’ effectiveness in preventing this type of attack from happening. It should be noted that our method isorthogonal toattack type and is sufﬁciently generic to catch any continuous attack during the training of a DNN model. GOAT relies upon proactive training as opposed to posttraining ordeploymenttime methods to assess the health of a DNN model. As we explain later in section 3, we assume that the initial training dataset is provided by an honest user and is free of manipulation. With this as a basis, GOAT limits the amount of change an adversary can inﬂict on a model through a single SGD step. As a consequence, the adversary is forced to keep attacking while randomly being veriﬁed by the TEE. 2.2 Integrity for DNN Training GOAT’s main goal is to enable highintegrity training pipeline so that end users are assured that the model is built on the speciﬁed dataset, using speciﬁed parameters without modiﬁcation. Thus, the ﬁnal model users know who built the model, what dataset was used for training, and what algorithms were put in place for building the model. If, at any point during training, GOAT detects a deviation from the speciﬁed execution, it will not sign the ﬁnal model to ascertain its validity. [ 16] took a ﬁrst step towards achieving both fastandreliable execution in the testphase but neglected the training phase. The training phase is far more computationally demanding than the test phase, such that veriﬁcation of all steps in training requires a substantially longer time. Since parameters keep changing, we cannot beneﬁt from precomputation. Second, backward pass involves computing gradients for both the inputs and the parameters and takes longer than forward pass. Despite the mentioned hurdles, as our investigation shows, it may not be necessary to verify every step to achieve integrity guarantees with high probability. 2.3 Intel SGX SGX [ 28] is an example of a common TEE that is available in many modernday computers. As outlined in Table 2, it provides a secluded hardware reserved area, namely, processor reserved memory (PRM), that is kept private (i.e., it is not readable in plaintext) from the host, or any privileged processes, and is free from direct undetected tampering. It also supports remote attestation , such that users can attest the platform and the running code within enclave before provisioning their secrets to a remote server. Calls from routines that should transition to/from enclave are handled through predeﬁned entry points that are called Ecall/Ocall that must be deﬁned in advance, before building the enclave image. While it provides security and privacy for numerous applications (e.g., [ 29,30,31]), due to its limited memory and computational capacity, directly running unmodiﬁed applications inside SGX can induce a signiﬁcant hit on performance. This is especially the case for applications that require large amounts of memory, such as training DNNs. 3APREPRINT 3 Threat Model Attacks on the integrity of DNNs can be orchestrated at different stages of the model learning pipeline (e.g., data collection or training). We assume the TEE node in GOAT is trusted, and the bytes stored on the PRM are always encrypted and authenticated before they are fetched inside the CPU. We assume that the data sent to GOAT comes from honest users via a secure/authenticated channel and is devoid of malicious samples.1For the training phase, we assume that the adversary has complete knowledge about the network structure, learning algorithm, and inputs (after TEE performs an initial preprocessing) to the model. In our threat model, the adversary is in complete control of the host system’s software stack, and hardware (unprotected RAM, GPU), except for the CPU package and its internals. Therefore, the code that runs inside the enclave is free from tampering, and the data that is accessed inside the cachelines or registers are not accessible to the adversary. For the inputs supplied to DNN tasks, the adversary is capable of performing insertion, modiﬁcation, and deletion to inﬂuence the ﬁnal model towards her advantage. As a result, an attacker may report wrong gradients as opposed to correctly computed ones. 4 System Design GOAT offers integrity and accountability for the training phase of a DNN model while inducing limited computational overhead. An overview of GOAT is illustrated in ﬁgure 1, and we refer the reader to table 2 for symbol descriptions and abbreviations. Before the training phase initiates, the training dataset is decrypted and validated inside the TEE. Besides, for each SGD step, the randomness regarding the minibatch selection and the network layers [ 32] are derived within the TEE and supplied to the GPU. As a result, the adversary will face a more constrained environment. Moreover, in our design, the GPU always performs a forward and a backward pass and reports the computed gradients to the TEE. At this point, the TEE clips the gradients and updates the parameters (low overhead operation). Finally, GOAT randomly decides to verify the SGD steps within the TEE or not. GOAT is optimized to guarantee a high level of integrity and the correctness of the model while providing an infrastructure that does not suffer from the substantial computational requirements of pure TEEbased solutions. We assume an honest and authenticated user will send her data encryption key Kclient (after remoteattestation) to the TEE. Next, the TEE decrypts/veriﬁes the initial encrypted dataset using the Kclient and supplies the trainer (GPU) the plaintext of the training set. If the TEE fails to detect any violations of the protocol during training, it will sign a message that certiﬁes the ﬁnal model.(Please see Appendix A for more details of the signed message). Then, during testing and deployment, the user can verify the digital signature of the model. Training with GOAT At the beginning of minibatch iteration i, TEE supplies the untrusted GPU with the randomness for that iteration. After completion of the forward and backward passes over the minibatch, the computed gradients are sent to the TEE for clipping and updating the parameters. Next, the TEE integrates the clipped gradients with the parameters of the previous step. GOAT always clips the reported gradients and ensures that they are within a narrow range so that evolving the model towards the attacker’s intended model requires a prolonged malicious intervention by the attacker . GOAT accepts the reported gradients and only applies the clipped version to the snapshot taken at the speciﬁc iteration. If the computation at that step is selected for random veriﬁcation, then the faulty behavior can be detected. If not, the chance that the model evolved towards the attacker’s desired optima will likely require multiple rounds providing ample opportunity for detection. The veriﬁcation is done randomly to prevent an attacker from guessing which step is veriﬁed. Probabilistic Veriﬁcation with GOAT The TEE randomly decides whether or not to verify the computation over each minibatch. If the minibatch is selected for veriﬁcation, then the intermediate results are saved, and the veriﬁcation task is pushed into a veriﬁcation queue. Veriﬁcation by the TEE can take place asynchronously and it does not halt the computation for future iterations on the GPU. The authenticity of snapshots is always veriﬁed with a key that is derived from a combination of the TEE’s session key, SKsession SGX and the corresponding iteration. When the TEE veriﬁes step i, it populates the network parameters with the snapshot it created for the step i","Deep Learning (DL) is a class of machine learning models that require a substantial quantity of computational resources (often in a distributed fashion) for training. At the same time, the DL model building process is increasingly outsourced to the cloud. However, the majority of these investigations are limited in that they only address the computational integrity at the test phase while depending on the application context. To address these limitations, we introduce GOAT (Goat for Integrity-preserving Learning as a Service), a framework for integrity-preserving learning as a service that provides integrity guarantees in outsourced DL",cool!
334,Safety Verification of Neural Network Controlled Systems.txt,"In this paper, we propose a system-level approach for verifying the safety of
neural network controlled systems, combining a continuous-time physical system
with a discrete-time neural network based controller. We assume a generic model
for the controller that can capture both simple and complex behaviours
involving neural networks. Based on this model, we perform a reachability
analysis that soundly approximates the reachable states of the overall system,
allowing to achieve a formal proof of safety. To this end, we leverage both
validated simulation to approximate the behaviour of the physical system and
abstract interpretation to approximate the behaviour of the controller. We
evaluate the applicability of our approach using a real-world use case.
Moreover, we show that our approach can provide valuable information when the
system cannot be proved totally safe.","Recently, feedforward deep neural networks have been successfully used for controlling physical systems, such as selfdriving cars [17, 5, 28] and unmanned aerial vehicles [16]. The combination of a physical system with a neural network based controller is sometimes known as a neural network controlled system . If such a system is considered as safetycritical , meaning that a failure of the system could have serious consequences, then a particular eort needs to be made to demonstrate its safety. More precisely, one has to show evidence that the system fullls a set of safety requirements, such as, in aeronautics, \A catastrophic failure shall occur with a probability less than 10","Feedforward deep neural networks have been successfully used for controlling physical systems, such as self-driving cars and unmanned aerial vehicles. In the case of a safety-critical system, such as a self-driving car, a particular effort needs to be made to demonstrate its safety. More precisely, one has to show evidence that the system fulfills a set of safety requirements, such as, in aeronautics, A catastrophic failure shall occur with a probability less than 10. In this paper, we propose a",cool!
493,Learning from Longitudinal Face Demonstration - Where Tractable Deep Modeling Meets Inverse Reinforcement Learning.txt,"This paper presents a novel Subject-dependent Deep Aging Path (SDAP), which
inherits the merits of both Generative Probabilistic Modeling and Inverse
Reinforcement Learning to model the facial structures and the longitudinal face
aging process of a given subject. The proposed SDAP is optimized using
tractable log-likelihood objective functions with Convolutional Neural Networks
(CNNs) based deep feature extraction. Instead of applying a fixed aging
development path for all input faces and subjects, SDAP is able to provide the
most appropriate aging development path for individual subject that optimizes
the reward aging formulation. Unlike previous methods that can take only one
image as the input, SDAP further allows multiple images as inputs, i.e. all
information of a subject at either the same or different ages, to produce the
optimal aging path for the given subject. Finally, SDAP allows efficiently
synthesizing in-the-wild aging faces. The proposed model is experimented in
both tasks of face aging synthesis and cross-age face verification. The
experimental results consistently show SDAP achieves the state-of-the-art
performance on numerous face aging databases, i.e. FG-NET, MORPH, AginG Faces
in the Wild (AGFW), and Cross-Age Celebrity Dataset (CACD). Furthermore, we
also evaluate the performance of SDAP on large-scale Megaface challenge to
demonstrate the advantages of the proposed solution.","The problem of face aging targets on the capabilities to aes thetically synthesize the faces of a subject at older ages, i.e.age progression , or younger ages, i.e. age regression or deaging . This problem is applicable in various realworld applications from age invariant face veriﬁcation, ﬁnding miss ing children to cosmetic studies. Indeed, face aging has raised considerable attentions in computer vision and machine learn ing communities recently. Several breakthroughs with nu merous face aging approaches, varying from anthropologyarXiv:1711.10520v4  [cs.CV]  2 Feb 20192 Chi Nhan Duong et al. Table 1: The comparison of the properties between our SDAP approach and other age progression methods. Deep learn ing (DL), Inverse Reinforcement Learning (IRL), Dictionary (DICT), Prototype (PROTO), Probabilistic Graphical Models (PGM), Loglikelihood (LL), Adversarial (ADV). Note that 7indicates unknown ornot directly applicable properties. Our SDAP TNVP (Duong et al, 2017)Pyramid GANs (Yang et al, 2018)CAAE (Zhang et al, 2017)RNN (Wang et al, 2016)TRBM (Duong et al, 2016)HFA (Yang et al, 2016) Subjectdependent Aging Path 3 7 7 7 7 7 7 Multiple Input Optimization 3 7 7 7 7 7 7 Tractable 3 3 3 3 3 7 3 NonLinearity 3 3 3 3 3 3 7 Model Type DL + IRL DL DL DL DL DL DICT Architecture PGM+CNN PGM+CNN CNN CNN CNN PGM Bases Loss Function LL LL ADV+`2 ADV+`2`2 LL LL+`0 theories to deep learning structures have been presented in literature. However, the synthesized results in these previous approaches are still far from perfect due to various challeng ing factors, such as heredity, living styles, etc. In addition, face aging databases used in most methods to learn the ag ing processes are usually limited in both number of images per subject and the covered age ranges of each subject. Both conventional and deep learning methods usually in clude two directions, i.e. direct andstepbystep aging syn thesis , in exploring the temporal face aging features from training databases. In the former direction, these methods directly synthesize a face to the target age using the relation ships between training images and their corresponding age labels. For example, the prototyping approaches (Burt and Perrett, 1995; Kemelmacher Shlizerman et al, 2014; Row land et al, 1995) use age labels to organize images into age groups and compute average faces for their prototypes. Then, the difference between sourceage and targetage prototypes is applied directly to the input image to obtain the age pro gressed face at the target age. Similarly, the Generative Ad versarial Networks (GAN) approach (Zhang et al, 2017) mod els the relationship between highlevel representation of in put faces and age labels by constructing a deep neural net work generator. This generator is then incorporated with the target age labels to synthesize the outputs. Although these kinds of models are easy to train, they are limited in capa bilities to synthesize faces much older than the input faces of the same subject, e.g. directly from ten to 60 years old. Indeed, the progression of a face at ten years old to the one at 60 years old in these methods usually ends up with a syn thesized face using 10yearold features plus wrinkles. Meanwhile, the latter approaches (Duong et al, 2017, 2016; Shu et al, 2015; Wang et al, 2016; Yang et al, 2016) decompose the longterm aging process into shortterm de velopments and focus on the aging transform embedding be tween faces of two consecutive development stages. Using learned transformation, these methods stepbystep gener ate progressed faces from one age group to the next until reaching the target. These modeling structures can ef ﬁciently learn the temporal information and provide more age variation even when a target age is very far from the in put age of a subject. However, the main limitation of these methods is the lackof longitudinal face aging databases. The longest training sequence usually contains only three or four images per subject. Limitations of previous approaches. In either directions, i.e. direct or stepbystep aging synthesis, the aging approach falls in, these previous approaches still suffer from many challenging factors and remain with lots of limitations. Ta ble 1 compares the properties of different aging approaches. – Nonlinearity. Since human aging is a complicated and highly nonlinear process, the linear models mostly used in conventional methods, i.e. prototype, AAMsbased and 3DMMbased approaches, are unable to efﬁciently inter pret the aging variations and the quality of their synthe sized results is very limited. – Loss function of deep structure. The use of a ﬁxed re construction loss function, i.e. `2norm, in the proposed deep structures (Wang et al, 2016; Yang et al, 2016) usu ally produces blurry synthesis results. – Tractability. Exploiting the advantages of probabilistic graphical models has introduced a potential direction for deep model design and produced prominent synthesized results for the age progression task (Duong et al, 2016). – Data usability. Even though a subject in training/testing set has multiple images at the same age, there is only one image used to learn/synthesize in these methods. The other images are usually wastefully ignored . In addition, the aging transformation embedding in these approaches is only able to proceed on images from twoage groups. – Fixed aging development path. The learned aging de velopment path is identically applied for all subjects which is not true in reality. Instead, each subject should have his/her own aging development.Learning from Longitudinal Face Demonstration  Where Tractable Deep Modeling Meets Inverse Reinforcement Learning 3 Contributions of this work. The paper presents a novel Subjectdependent Deep Aging Path (SDAP) model to face age progression, which is an extension of our previous work (Duong et al, 2017). In that work, TNVP structure is pro posed to embed the pairwise transformations between two consecutive age groups. In this work, the SDAP structure is introduced to further enhance the capability to discover the optimal aging development path for each individual. This goal can be done by embedding the transformation over the whole aging sequence of a subject under an IRL framework. Our contributions can be summarized as follows. 1. The aging transformation embedding is designed using (1) a tractable loglikelihood density estimation with (2) Convolution Neural Network (CNN) structures and (3) anage controller to indicate the amount of aging changes for synthesis. Thus, the proposed SDAP is able to pro vide a smoother synthesis across faces and maximize the usability of aging data, i.e. all images of a subject in dif ferent or the same ages are utilized. 2. Unlike most previous methods, our proposed SDAP model further enhances the capability to ﬁnd the optimal aging development path for individual. This goal can be done by embedding the transformation over the whole aging sequence of a subject under an IRL framework. 3. Instead of using predeﬁned or addhoc aging reward and objective functions as in most previous work, our proposed approach allows the algorithm to automatically come up with the optimal objective formulation and pa rameters via a data driven strategy in training. We believe that this is the ﬁrst work that designs an IRL framework to model the longitudinal face aging. 2 Related work","Face aging has raised considerable attentions in computer vision and machine learning communities recently. However, the synthesized results in these previous approaches are still far from perfect due to various challeng ing factors, such as heredity, living styles, etc. In this paper, we propose a novel face aging progression method, namely the SDAP. This method directly synthesizes a face to the target age using the relation ships between training images and their corresponding age labels. In contrast, the step-by-step approach aging transform embedd between two consecutive development stages. In addition",cool!
41,A Cross-Modal Image Fusion Method Guided by Human Visual Characteristics.txt,"The characteristics of feature selection, nonlinear combination and
multi-task auxiliary learning mechanism of the human visual perception system
play an important role in real-world scenarios, but the research of image
fusion theory based on the characteristics of human visual perception is less.
Inspired by the characteristics of human visual perception, we propose a robust
multi-task auxiliary learning optimization image fusion theory. Firstly, we
combine channel attention model with nonlinear convolutional neural network to
select features and fuse nonlinear features. Then, we analyze the impact of the
existing image fusion loss on the image fusion quality, and establish the
multi-loss function model of unsupervised learning network. Secondly, aiming at
the multi-task auxiliary learning mechanism of human visual perception system,
we study the influence of multi-task auxiliary learning mechanism on image
fusion task on the basis of single task multi-loss network model. By simulating
the three characteristics of human visual perception system, the fused image is
more consistent with the mechanism of human brain image fusion. Finally, in
order to verify the superiority of our algorithm, we carried out experiments on
the combined vision system image data set, and extended our algorithm to the
infrared and visible image and the multi-focus image public data set for
experimental verification. The experimental results demonstrate the superiority
of our fusion theory over state-of-arts in generality and robustness.","The human visual perception system has better per formance than the existing derived algorithms in object detection [1] [2], image caption [3], object tracking and other tasks. Therefore, we believe that the human vision system is also robust to image fusion tasks .According to the research of cognitive psychology and neuroscience theory [4], [5], [6], the information processing of human visual perception system has the characteristics of feature selection, nonlinear combination and multitask auxiliary learning mechanism. We believe that based on these three characteristics of human brain, human brain is more robust than existing derivative algorithms in image fusion task or other visual task processing tasks, as veriﬁed in Sect.4. However, in the task of image fusion, the existing image fusionmethods have paid few research attention on the char acteristics of human visual perception system. By contrast, more researches have been conducted from the technology perspective, without considering the characteristics of hu man visual perception and information processing mecha nism. We can divide image fusion methods into traditional image fusion methods and image fusion methods based on deep learning. Traditional image fusion methods mainly include multiscale transformation [7], [8], [9] [10] and visual signiﬁcance [8], [9], [11], [12], [13], [14] et al. There are three main approaches to image fusion based on deep learning. 1) The ﬁrst one is the combination of image transformation and deep learning feature, which only uses the convolutional Corresponding author: Xinbo Zhao (email: xbozhao@nwpu.edu.cn)neural network model of pretraining to provide deep learn ing feature maps [15], [16], [17], [18], [19]. 2) The second is the endtoend convolution neural network method based on the twin networks, which uses the objective function for iterative optimization learning strategy [20], [21], [22], [23]. 3) The third is to build an endtoend deep convolution neural network (CNN), which is different from the second one in that it transforms image fusion into image classiﬁca tion. This method is more applicable to multifocus image fusion tasks [24], [25]. In terms of image fusion criteria , both traditional image fusion algorithm and deep learning image fusion method mainly adopt maximum fusion, sum fusion and weighted average fusion [15], [16], [17], [18], [19], [21]. From the perspective of the universality of image fusion, a general image fusion framework (IFCNN) proposed by Zhang [26] based on multiexposure fusion (MEF) frame work [21]. This method uses supervised learning method in multifocus data set, and then applies training weight to different image fusion tasks according to different fusion rules. This method focuses more on the generality of fusion framework than on the robustness of fusion algorithm. Although the existing image fusion theory has made remarkable achievements, it still has a big gap with the human brain image fusion effect. In order to make the results of image fusion more consistent with the mechanism of human brain image fusion and narrow the gap between human brain image fusion and human brain image fusion, we propose an crossmodal image fusion method basedarXiv:1912.08577v4  [cs.CV]  20 Jun 2020IEEE TRANSACTIONS ON MULTIMEDIA 2 Fig. 1. Combined vision system (CVS) image fusion. From left to right: the enhanced vision system image (EVS), the synthetic vision system image (SVS), the fusion result of a classic method, and the fusion result of ours. Our method has a good fusion effect for image details, and the fusion effect is more coincident with the human visual perception mechanism. on human visual perception characteristics. In order to demonstrate the superiority of our fusion method in existing mainstream algorithm, we give a representative example in Fig. 1. We use the EVS and SVS images in CVS image fusion data set to do qualitative comparison experiments. The two images on the left are EVS image and SVS image, the third image is the fusion effect of traditional operator, and the last image is the fusion result of our algorithm. From the fusion images of different algorithms, we can see that our algorithm is superior to the mainstream image fusion algorithm in subjective vision. Our image fusion method uses multitasks loss function to op timize image fusion weight, and through the effective combination of attention mechanism and nonlinear neural network to simulate the feature selection characteristics and nonlinear combination characteristics of human brain image fusion , which effectively improves the robustness of image fusion. The image fusion method we proposed is not a simple combination of existing deep learning methods. In the task of crossmodal image fusion, we make full use of the strong feature representation ability and nonlinear ﬁtting ability of convolutional neural network, We use network architecture to simulate the char acteristics of human visual system. The main contributions of our work include the following four points: Firstly , we analyze the nonlinear characteristics and fea ture selection characteristics of human vision system, simu late the characteristics, and introduce the characteristics into the image fusion task. Secondly , we introduce human brain auxiliary learning mechanism into image reconstruction task and multifocus image fusion task, and study the inﬂuence of auxiliary learning mechanism on image fusion task. Thirdly , based on the above theoretical research, we propose a robust multitask loss function collaborative opti mization learning image fusion method. To a certain extent, the method overcomes the difﬁculty of modeling the objec tive function of the crossmodal image, and provides a new fusion idea for the crossmodal image fusion task through the cooperative optimization of multitask loss. Finally , code and dataset. In order to speed up the research progress of researchers in the ﬁeld of image fusion, more than 20 latest image fusion algorithm codes and 8 image fusion algorithm codes that have not been compared in this paper will be summarized on my GitHub homepage after paper is accepted. The rest of this paper is laid out as follows. In section2, we discusses three characteristics of human visual per ception system. In section 3, we will analyze our proposed image fusion method based on the three characteristics of human visual perception system. In section 4, experiments and results analysis of different algorithms on different public datasets. And the results are qualitatively analyzed and discussed in section 5, and the experimental conclusions are summarized in section 6. 2 RELATED WORK",We propose a novel cross-modal image fusion method based on the human visual perception system. Our method combines the enhanced vision system (EVS) and synthetic vision system (SVS) images in CVS image fusion data set to achieve a good fusion effect for image details. Our method uses the effective combination of attention mechanism and nonlinear neural network to simulate the feature selection characteristics and nonlinear combination characteristics of human visual perception system. We also use the effective combination of attention mechanism and nonlinear neural network to simulate the nonlinear combination of attention mechanism of human visual perception system. We,cool!
433,Scalable Polyhedral Verification of Recurrent Neural Networks.txt,"We present a scalable and precise verifier for recurrent neural networks,
called Prover based on two novel ideas: (i) a method to compute a set of
polyhedral abstractions for the non-convex and nonlinear recurrent update
functions by combining sampling, optimization, and Fermat's theorem, and (ii) a
gradient descent based algorithm for abstraction refinement guided by the
certification problem that combines multiple abstractions for each neuron.
Using Prover, we present the first study of certifying a non-trivial use case
of recurrent neural networks, namely speech classification. To achieve this, we
additionally develop custom abstractions for the non-linear speech
preprocessing pipeline. Our evaluation shows that Prover successfully verifies
several challenging recurrent models in computer vision, speech, and motion
sensor data classification beyond the reach of prior work.","Recurrent neural networks (RNNs) are widely used to model longterm depen dencies in lengthy sequential signals [ 11,27,43]. Prior work has demonstrated the susceptibility of RNNs to adversarial perturbations of its inputs [ 28], exposing security vulnerabilities of stateoftheart RNNs when used in domains such as speech recognition [ 8,22], malware detection [ 16], and others. Thus, verifying the robustness of recurrent architectures is critical for their safe deployment. While there has been considerable interest in certifying the robustness of feedfor ward image classiﬁers [ 4,12,13,23,32,37,39,47], less attention has been given to recurrent architectures. As a result, current certiﬁcation solutions do not scale beyond simple models and datasets, which limits their practical applicability. Further, there has been no work on verifying realworld use cases of RNNs. In this paper, we address both of these challenges and present the ﬁrst precise and scalable veriﬁer for RNNs based on abstract interpretation [ 10], which enables us to certify robustness of realistic speech recognition systems.arXiv:2005.13300v3  [cs.LG]  10 Jun 20212 W. Ryou et. al. LSTM (i)LSTM (T) LSTM 0(i)LSTM 0(T)Preprocess Postproc Postproc“st... ...op” “go” “stop” “go” “stop”Ls(i)s(T) x(i)x(T) h(i−1)h(i)h(T−1)h(T)z 0=−α∇L x(i)x(T) h/prime(i−1)h/prime(i)h/prime(T−1)h/prime(T)z/prime Fig.1: Certiﬁcation of recurrent architectures using Prover : utterance “stop” with perturbations is correctly classiﬁed. Possible perturbations are captured and propagated through the system, then reﬁned backward for improved precision. We illustrate the problem setting and overall ﬂow in Fig. 1. Here, a speech recognition model based on the Long ShortTerm Memory (LSTM) architecture [15] receives a signal encoding the utterance of “stop” by a human. As such models are usually employed in noisy environments, they must robustly classify variations (e.g., voice changes) to the utterance “stop”. However, recent work [8] has shown the model may be fooled into classifying the utterance as “go”. It is important to prove such misclassiﬁcations are not possible, thus avoiding a potential exploitation by an adversary, for instance in automated traﬃc control settings (which can lead to accidents). Our goal is to design a veriﬁer that can formally establish the robustness of such models against noiseinduced perturbations. We focus on LSTMs, as they are the most widely used form of RNNs, but our methodology can be easily extended to other architectures (e.g., Gated Recurrent Unit (GRU) [ 9]). Fig. 1 shows how our proposed veriﬁer, called Prover, (Polyhedral Robustness Veriﬁer of RNNs) automatically veriﬁes the robustness of the model. Here, the labeled rectangles represent operations in the network. The “Preprocess” box captures domainspeciﬁc preprocessing operations (typically present when using RNNs, e.g., speech processing). In our method, we ﬁrst compute a polyhedral abstraction capturing all speech signals given as input to the model under the given perturbation budget. At each timestep i, the preprocessing operation receives a polyhedron s(i)and produces an output polyhedronx(i). This shape is then propagated symbolically through the LSTM and the postprocessing stage, resulting in a polyhedral output shape, denoted asz(blue shape in Fig. 1). Keychallenge:polyhedralabstractionsforLSTMs Themainchallenge in certifying LSTMs is the design of precise and scalable polyhedral abstract transformers for the nonlinear operations employed in LSTMs: given a polyhedralScalable Polyhedral Veriﬁcation of Recurrent Neural Networks 3 shape capturing hidden states h(i−1), to produce the shape capturing the next set of hidden states h(i). A recent method [ 21] computes this based on gradient based optimization but suﬀers from two main limitations. First, the optimization procedure is computationally expensive and does not scale to realistic use cases. Second, the method lacks convergence and optimality guarantees. To address these issues, we introduce a novel technique based on a combination of sampling, linear programming, and Fermat’s theorem [ 1], which signiﬁcantly improves the precision and scalability compared to prior work [21], while oﬀering asymptotic guarantees of convergence towards the optimal solution. Reﬁnement via optimization To certify robustness, we must verify that each concrete point in the output shape zcorresponds to the correct label “stop”. However,zcan contain, due to overapproximation, spurious incorrect concrete points (it intersects the red region representing incorrect outputs). To address this issue, we form a loss based on the output shape, backpropagate the gradient of this loss through the timesteps and adjust the polyhedral abstractions in each LSTM unit to decrease the loss. The goal is to reﬁne the abstraction, guided by the certiﬁcation task. We illustrate this process in Fig. 1 using the purple backward arrow with the reﬁned polyhedral abstraction shown in purple. Using the reﬁned abstraction, the new output shape z/prime(purple polygon) lies completely inside the green region of the output space, meaning it provably contains only correct output vectors (corresponding to “stop”), and hence certiﬁcation succeeds. Overall, our method signiﬁcantly increases the precision of endtoend RNN certiﬁcation without introducing high runtime costs. Key contributions Our main contributions are: –A new and eﬃcient method to certify the robustness of RNNs to adversar ial perturbations. Our method relies on novel polyhedral abstractions for handling nonlinear operations in these architectures. –A novel method that automatically reﬁnes the abstraction for each input example being certiﬁed guided by the certiﬁcation task. –An implementation of the method in a system called Prover and evaluation on several benchmarks and datasets. Our results show that Prover is precise and scales to larger models than prior work. Prover is also the ﬁrst veriﬁer able to certify realistic RNNbased speech classiﬁers. The code is available in https://github.com/ethsri/prover . 2 Related work","Recurrent neural networks (RNNs) are widely used to model long-term dependencies in lengthy sequential signals. However, prior work has shown the susceptibility of RNNs to adversarial perturbations of its inputs, exposing their safe deployment. As a result, certifying the robustness of recurrent architectures is critical for their safe deployment. In this paper, we address both these challenges and present the first precise and scalable verifier for recurrent neural networks based on abstract interpretation. Our method, called Prover, we first compute a polyhedral abstraction",cool!
162,Vertex-based reachability analysis for verifying ReLU deep neural networks.txt,"Neural networks achieved high performance over different tasks, i.e. image
identification, voice recognition and other applications. Despite their
success, these models are still vulnerable regarding small perturbations, which
can be used to craft the so-called adversarial examples. Different approaches
have been proposed to circumvent their vulnerability, including formal
verification systems, which employ a variety of techniques, including
reachability, optimization and search procedures, to verify that the model
satisfies some property. In this paper we propose three novel reachability
algorithms for verifying deep neural networks with ReLU activations. The first
and third algorithms compute an over-approximation for the reachable set,
whereas the second one computes the exact reachable set. Differently from
previously proposed approaches, our algorithms take as input a V-polytope. Our
experiments on the ACAS Xu problem show that the Exact Polytope Network Mapping
(EPNM) reachability algorithm proposed in this work surpass the
state-of-the-art results from the literature, specially in relation to other
reachability methods.","Regardless of the success of deep neural networks in computer vision and natural language processing, these models are susceptible to small perturbations applied to their inputs, i.e. it is possible to misguide the model output by applying a designed perturbation to a given input. For instance, the ACAS Xu model [1] (explained later in detail), that responded dierently from expected while under specic circumstances. The inputs purposefully designed to force a misbehavior of the neural network are denoted as adversarial examples [2]. To overcome such vulnerability many dierent approaches have been previously employed. One proposed the application of algorithms that were able to generate adversarial examples, the so called adversarial attacks, and subsequently applied these inputs in the training process of the network [2, 3, 4, 5]. There were also those approaches that aim to identify the adversarial examples before feeding them as input to the neural network [6, 7, 8, 9]. Even though these procedures helped to reduce the vulnerability of the neural networks, these models remained vulnerable to adversarial attacks. ∗joao.zago@posgrad.ufsc.br †eduardo.camponogara@ufsc.br ‡eric.antonelo@ufsc.br 1arXiv:2301.12001v1  [cs.LG]  27 Jan 2023Formal methods were also applied to certify or guarantee that the model behaves as expected under some circumstances or within a specied domain region, nevertheless [10] showed that the verication problem is NPhard, leaving the process of certifying large models still an open problem. The existing formal procedures can be classied into three dierent categories: 1) reachability methods; 2) optimization methods; and 3) search methods. The rst one relies on calculating the output mapping of an input set [11, 12, 13], the second one comprises the application of math ematical optimization (Mixed IntegerLinear Programming or Convex Optimization) to identify counterexamples [14, 15, 16, 17], and the third makes use of both reachability and optimization approaches in conjunction with search methods for identifying counterexamples [10, 18]. In this paper, we propose three novel reachability algorithms: APNM and PAPNM algorithms that compute an overapproximation for the output, while EPNM which computes the exact map ping. We present demonstrations on the behavior and correctness of these algorithms and case studies of their applications for comparison with existing algorithms from the literature. We also show that the algorithms proposed in this work are highly parallelizable. The rest of this paper is organized into ve sections: Section 2 gives an overview of the existing algorithms and related works; Section 3 describes the proposed algorithms; Section 4 addresses the demonstrations regarding the completeness and soundness of the proposed algorithms; Section 5 presents a study case for application and comparison; and nally Section 6 discusses the outcome of the procedures presented in this work. 2 Related Works","Deep neural networks are susceptible to small perturbations applied to their inputs, i.e. it is possible to misguide the model output by applying a designed perturbation to a given input. To overcome such vulnerability many approaches have been previously employed. To reduce the vulnerability of the neural networks, some formal procedures have been proposed to certify or guarantee that the model behaves as expected under some circumstances or within a specied domain region. However, these procedures remained vulnerable to adversarial attacks. In this paper, we propose three novel reachability algorithms: APNM and",cool!
462,"Integrating Deep Neural Networks with Full-waveform Inversion: Reparametrization, Regularization, and Uncertainty Quantification.txt","Full-waveform inversion (FWI) is an accurate imaging approach for modeling
velocity structure by minimizing the misfit between recorded and predicted
seismic waveforms. However, the strong non-linearity of FWI resulting from
fitting oscillatory waveforms can trap the optimization in local minima. We
propose a neural-network-based full waveform inversion method (NNFWI) that
integrates deep neural networks with FWI by representing the velocity model
with a generative neural network. Neural networks can naturally introduce
spatial correlations as regularization to the generated velocity model, which
suppresses noise in the gradients and mitigates local minima. The velocity
model generated by neural networks is input to the same partial differential
equation (PDE) solvers used in conventional FWI. The gradients of both the
neural networks and PDEs are calculated using automatic differentiation, which
back-propagates gradients through the acoustic PDEs and neural network layers
to update the weights of the generative neural network. Experiments on 1D
velocity models, the Marmousi model, and the 2004 BP model demonstrate that
NNFWI can mitigate local minima, especially for imaging high-contrast features
like salt bodies, and significantly improves the inversion in the presence of
noise. Adding dropout layers to the neural network model also allows analyzing
the uncertainty of the inversion results through Monte Carlo dropout. NNFWI
opens a new pathway to combine deep learning and FWI for exploiting both the
characteristics of deep neural networks and the high accuracy of PDE solvers.
Because NNFWI does not require extra training data and optimization loops, it
provides an attractive and straightforward alternative to conventional FWI.","Fullwaveform inversion (FWI) is a high resolution inversion method in exploration seis mology (Tarantola, 1984, 2005; Virieux and Operto, 2009), commonly used for estimating subsurface velocity structure based on seismic waves recorded at the surface. FWI falls within the class of PDEconstrained optimization problems. It solves the wave equation, in the acoustic or elastic approximation, to predict seismic waves based on the velocity model. Through the PDE solver, FWI determines the optimal velocity model by minimizing the mist between predicted and observed seismic waveforms. The gradient of the mist func tion can be eciently calculated by the adjointstate method (Plessix, 2006). Although FWI can achieve high accuracy when the full seismic waveform is matched, the nonlinearity of the objective function poses a challenge to the optimization process. The inversion result of FWI suers from local minima due to cycle skipping in the wave oscillations used to form the objective function, i.e., a L2norm loss. This is particularly challenging when either a good initial model is lacking or low frequency content of the waveform data is missing. Noise in real seismic recording can also contaminate the inversion results. Because artifacts originating from local minima interfere with imaging results and can lead to misinterpreta tion of geological structures, a great deal of research has focused on improving the stability of FWI. One solution is to recover or predict the missing low frequency content, such as through envelope inversion (Bozda g et al., 2011; Wu et al., 2014), sparse blind deconvolution (Zhang et al., 2017), and phasetracking methods (Li and Demanet, 2016). Another solution is to add regularization and preconditioning, such as Laplacian smoothing (Burstedde and Ghattas, 2009), l2norm penalty (Hu et al., 2009), l1norm penalty (total variation) (Guitton, 2012; Esser et al., 2018; Kalita et al., 2019), and prior information as constraints (Asnaashari et al., 2013). Many other solutions have also been proposed and tested such as: multiscale inversion (Bunks et al., 1995), waveequation traveltime inversion (Luo and Schuster, 1991), tomographic fullwaveform inversion (Biondi and Almomin, 2014), model extension (Barnier et al., 2018), model reduction (Barnier et al., 2019), model reparameterization (Guitton et al., 2012), and dictionary learning (Zhu et al., 2017; Li and Harris, 2018),. In addition to the strong nonlinearity of FWI, uncertainty analysis of FWI results is challenging due both to the high dimensionality of the model space and to the demanding computational cost of solving the wave equation (Gebraad et al., 2020). In recent studies, the success of deep learning in computer vision, natural language pro cessing, and many other elds has drawn attention to its potential application in FWI (Adler et al., 2021). One research direction is to build a direct inverse mapping from observations to subsurface structure by training neural networks on paired data of seismic waveforms and velocity models (Wu et al., 2018; Yang and Ma, 2019; Li et al., 2019; Kazei et al., 2021). This approach does not rely on solving the wave equation but instead treats FWI as a datadriven machine learning problem similar to that in image recognition. The accuracy and generaliza tion of this approach, however, cannot be guaranteed without the PDE constraint in FWI. Another research direction is to apply deep learning as an eective signal processing tool to improve the optimization process of conventional FWI. For example, several studies applied neural networks to extrapolate the missing low frequencies and help mitigate the cycle skip ping problem (Ovcharenko et al., 2019; Sun and Demanet, 2020; Hu et al., 2021). In addition to these datadriven approaches, another promising direction is to combine neural networks 2and PDEs to formulate FWI as a physicsconstrained machine learning problem. Richard son (2018a) and Mosser et al. (2020) trained a generative adversarial network (GAN) to build an a prior model of subsurface geological structures and optimized a lowerdimensional latent variable to t observed data. Wu and McMechan (2019) and Wu and McMechan (2020) proposed a CNNdomain FWI, which reparameterizes the velocity model or the gra dient eld by a convolutional neural network (CNN) and minimizes the loss by updating the neural network weights. He and Wang (2021) further analyzed the adaptive regularization eect from the convolutional neural network. However, these works relied on pretraining convolutional neural networks on initial velocity models and attributed the regularization eect to the prior information coming from tting these initial velocity models. In contrast, Ulyanov et al. (2018)'s work on deep image prior demonstrated that the CNN architecture without pretraining can be used as a prior with excellent results in inverse problems of computer vision, such as denoising, superresolution, and inpainting. Their results showed that although a highcapacity neural network can t both structured objects and unstruc tured noise, the parametrization of the neural network oers high impedance to noise during optimization and learns much more quickly towards naturallooking images. Another limi tation of the CNNdomain FWI approach is the complex inversion work ow combining two optimization processes of neural network training and fullwaveform inversion. Richardson (2018b) and Zhu et al. (2020) have implemented FWI using deep learning frameworks so that reversemode automatic dierentiation and various eective optimization tools in deep learning frameworks can be used for FWI. The similarity between neural network training and FWI demonstrated by these works makes it possible to greatly simplify the previous inversion work ows within one unied framework for both deep learning and FWI. In this study, we propose a method, NNFWI, to integrate deep neural networks with fullwaveform inversion. Similar to Wu and McMechan (2019)'s idea, we use deep neural networks to generate a physical velocity model, which is then fed to a PDE solver to sim ulate seismic waveforms. The training process of NNFWI is similar to that of conventional FWI, but with gradients calculated by automatic dierentiation instead of by the adjoint state method. Thus we can easily optimize the two systems of neural networks and PDEs together. Unlike conventional FWI, which directly estimates the velocity model, NNFWI reparametrizes the velocity model with a generative neural network model and optimizes the neural network's weights. In contrast to previous work that learns prior information from pretraining, NNFWI does not require pretraining neural networks on the initial ve locity model. As demonstrated by Ulyanov et al. (2018)'s work on the deep image prior, the inductive bias captured by deep convolutional networks is an eective image prior and can be used as regularization for tasks such as denoising and superresolution. Due to the regularization eect of neural networks, NNFWI mitigates the eects of local minima and is robust with respect to noise in the data. Furthermore, NNFWI can model uncertainty by adding dropout layers in the neural network. Dropout not only prevents overtting during training deep neural networks, but can also approximate Bayesian inference to capture model uncertainty without much extra computational cost (Gal and Ghahramani, 2016). NNFWI has the potential to provide uncertainty quantication for FWI, which otherwise remains a challenging problem. NNFWI exploits the unique advantages of deep neural networks and the high accuracy and generalization of PDEs to improve inversion and uncertainty analysis in FWI. 3In the following, we rst describe the two components of NNFWI including a generative neural network to parametrize the inversion target (i.e., velocity model) and an acoustic PDE to predict accurate waveforms same as that used conventional FWI. We then compare the performance of NNFWI with conventional FWI and FWI with TV regularization on three benchmark models: 1D velocity proles, the Marmousi model, and the 2004 BP model. Last, we present an uncertainty estimation method using the Monte Carlo dropout technique and analyzed the computational cost of NNFWI. Additional comparison results are provided in the appendix. 2 Method","Full-waveform inversion (FWI) is a high resolution inversion method in exploration seismology. It is commonly used for estimating subsurface velocity structure based on seismic waves recorded at the surface. Although FWI can achieve high accuracy when the full seismic waveform is matched, the nonlinearity of the objective function poses a challenge to the optimization process. One solution is to recover or predict the missing low frequency content of the seismic waveform data, such as through envelope inversion, sparse blind deconvolution, l2norm penalty (total variation),",cool!
292,Explanation based Handwriting Verification.txt,"Deep learning system have drawback that their output is not accompanied with
ex-planation. In a domain such as forensic handwriting verification it is
essential to provideexplanation to jurors. The goal of handwriting verification
is to find a measure of confi-dence whether the given handwritten samples are
written by the same or different writer.We propose a method to generate
explanations for the confidence provided by convolu-tional neural network (CNN)
which maps the input image to 15 annotations (features)provided by experts. Our
system comprises of: (1) Feature learning network (FLN),a differentiable
system, (2) Inference module for providing explanations. Furthermore,inference
module provides two types of explanations: (a) Based on cosine
similaritybetween categorical probabilities of each feature, (b) Based on
Log-Likelihood Ratio(LLR) using directed probabilistic graphical model. We
perform experiments using acombination of feature learning network (FLN) and
each inference module. We evaluateour system using XAI-AND dataset, containing
13700 handwritten samples and 15 cor-responding expert examined features for
each sample. The dataset is released for publicuse and the methods can be
extended to provide explanations on other verification taskslike face
verification and bio-medical comparison. This dataset can serve as the basis
and benchmark for future research in explanation based handwriting
verification. The code is available on github.","Handwritten evidences provided by expert forensic document examiners (FDE) has long been admissible in the court of law. FDE subjectively specify the characteristics of the handwritten samples like word formations, pen pressure and pen lifts which uniquely iden tiﬁes an individual writer. The premise for ﬁnding unique characteristics is based on the hypothesis that every individual has a unique way of writing [12]. The examination of the handwritten samples involves comparison of the questioned handwritten sample submitted for examination with the known handwritten sample under investigation. Therefore, the task of handwriting veriﬁcation is to ﬁnd a measure of conﬁdence whether the questioned and known handwritten samples are written by the same writer or different writer. An example of handwriting veriﬁcation evidence as presented by FDE is shown in Figure 1. [5] Forensic handwritten evidences has received skepticism on the reliability of the reasoning methodologies and the subjective nature of the judgments provided by FDE. This is due to c 2019. The copyright of this document resides with its authors. It may be distributed unchanged freely in print or electronic forms.arXiv:1909.02548v1  [cs.CV]  14 Aug 20192 CHAUHAN, SHAIKH ET AL .: EXPLANATION BASED HANDWRITING VERIFICATION Figure 1: Explanation with evidence provided to the court of law by a QD examiner. Red arrow indicates a dissimilarity in staff of ’a’. The two green arrows indicates similarity between staff of ’n’ and exit stroke of ’d’ respectively. A green bar over d indicates simi larity between staff of ’d’. The explanations provides a conﬁdence that the two handwritten samples were written by same writer. the nonexact nature of the conclusions drawn from the explanations provided by different FDE’s. Researchers have implemented handwriting veriﬁcation systems using conventional ma chine learning techniques [1] [12] [6] as well as deep learning techniques [11] [3]. FDE’s are still unconvinced with the handwriting veriﬁcation systems because: (1) The output of such systems is difﬁcult to interpret because the system does not provide explanations for the decision. (2) The system is opaque and the innerworking of the system is unclear. Hence, our goal is to provide an explanation based handwriting veriﬁcation system which provides a decision report for the FDE to interpret the output. Vantage writer approach [2] was pro posed to generate comprehensible reports for providing explanations for the task of writer veriﬁcation and identiﬁcation. The idea used in [2] is that an individual handwriting can be seen as a mixture of handwritings of typical writers, the vantage writers. The vantage pro ﬁle describes the features for a handwritten sample. The proﬁle is created using similarity between features of a handwritten sample and all vantage handwritten samples. We have proposed a different approach wherein we generate human explainable features instead of using vantage proﬁle. The proposed system consists of two modules:(1) Feature Learning Network (FLN) which learns to map the input images to expert human observed features (2) The decision inference interface which uses cosine similarity and probabilistic graphical network to provide rational behind the decision made by the system. In the next section, we describe XAIAND, a dataset speciﬁcally created for explainable handwriting veriﬁcation. Element Explainable Features Form Entry/Exit Stroke Pressure Pen Pressure Speed Constancy Dimension Word Dimension, Word Size Continuity Is Cursive Direction Tilt, Slantness Order Formation Table 1: Seven Elements of Handwriting 2 Dataset XAIAND dataset is a publicly available dataset for handwriting veriﬁcation, comprising of 15,518 “AND” image fragments extracted from CEDAR Letter Dataset [12] written by 1567 writers. Each “AND” image fragment is labeled by a questioned document (QD) examinerCHAUHAN, SHAIKH ET AL .: EXPLANATION BASED HANDWRITING VERIFICATION 3 Pen Pressure Tilt Entry Stroke of ""a"" Is Lowercase Is Continuous Strong (40.6%) Normal (81.24%) No Stroke (94.32%) No (1.5%) No (33.38%) Medium (59.4%) Tilted (18.76%) Downstroke (5.68%) Yes (98.5%) Yes (66.62%) Table 2: Examples and Class Distribution with 15 explainable discrete features. QD examiners have speciﬁed these handwriting fea tures based on years of training using seven fundamental elements of handwriting [4] as shown in Table 1. We have created a web based truthing tool for QD examiners to enter the values for the 15 features for “AND” images fragments. The data entry work using the truthing tool was shared primarily between 89 external examiners. The data entered by the external examiners was veriﬁed by 2 QD examiners. The resultant dataset serves as a good resource for explanation based handwriting veriﬁcation. Table 2, 3 and 4 shows classwise examples and distribution for each explainable feature. Data Partitioning We follow three approaches to partitioning the writers in training ( Dtrain), validation ( Dval) and testing( Dtest) set [11]: Unseen Writer Partitioning : No data partitions share any sample from same writer Dtrain\ Dval\ Dtest=/ 0 (1) Shufﬂed Writer Partitioning : Data partitions randomly share different samples from writers Dtrain\ Dval\ Dtest=Xwhere X6=/ 0 (2) Seen Writer Partitioning : Each data partition contains different samples of the same writer Dtrain=N[ i=10:6Si;Dval=N[ j=10:2Sj;Dtest=N[ k=10:2Sk;Dtrain[ Dval[ Dtest=S(3) where Sdenotes a set of all the writers and i;j;kdenote different samples from each writer 3 Methods",Handwriting evidences provided by expert forensic document examiners (FDE) has long been admissible in the court of law. The premise for finding unique characteristics of the handwritten samples is based on the hypothesis that every individual has a unique way of writing. The task of handwriting verification is to find a measure of confidence whether the questioned and known handwritten samples are written by the same writer or different writer. The output of handwriting verification systems is difficult to interpret because the system does not provide explanations for the decision. We propose a new approach wherein,cool!
438,Image-to-GPS Verification Through A Bottom-Up Pattern Matching Network.txt,"The image-to-GPS verification problem asks whether a given image is taken at
a claimed GPS location. In this paper, we treat it as an image verification
problem -- whether a query image is taken at the same place as a reference
image retrieved at the claimed GPS location. We make three major contributions:
1) we propose a novel custom bottom-up pattern matching (BUPM) deep neural
network solution; 2) we demonstrate that the verification can be directly done
by cross-checking a perspective-looking query image and a panorama reference
image, and 3) we collect and clean a dataset of 30K pairs query and reference.
Our experimental results show that the proposed BUPM solution outperforms the
state-of-the-art solutions in terms of both verification and localization.","In recent years we have seen many fake news stories, including but not limited to elections, natural disasters, protests, and riots. With the rapid growth of social networks and easytouse publishing applications on mobile devices, fake news can easily be produced and spread to social networks, and consequently to the entire world. Publishing fake news became a \digital gold rush,""1and detection tools need to be developed. Many posts on social media are textonly, but it is common to see posts composed of both text and image/video (see samples in Fig. 1), which is preferred by fake news posters, possibly because appealing photos makes fake news more convincing. However, this provides us extra opportunities to identify fake news, because one needs to tell more lies to make up one lie, but we only need to recognize one lie to conclude he/she is a lier. In this paper, we are interested in identifying fake news by testing location consistency { whether an image is taken at a claimed location. Here, a claimed position could be inferred or obtained from dierent sources in a social media 1https://www.wired.com/2017/02/velesmacedoniafakenewsarXiv:1811.07288v1  [cs.CV]  18 Nov 20182 Cheng Jiaxin et al. Fig. 1. Shall we trust these social network posts? Are these images taken at the claimed places? post, e.g.associated text description, Global Positioning System (GPS) infor mation in image metadata, scene text in an image like street signs/landmark names, etc. A straightforward solution to this problem is to use the GPS estimation approach, which estimates a query image's GPS according to visually similar images with known GPS locations in a large, geotagged reference database and compares the estimated GPS to the claimed one to make the decision. Depend ing on the used features, one may further classify existing approaches into two families: (1) 2Donly, which uses image features [14,6,12,13,15,17,5] e.g.Invariant Feature Transform (SIFT), SpeededUp Robust Features (SURF) [14,6,12,13], bagofwords representation [15], and vocabulary trees [17], to eciently and ef fectively retrieve visually similar images rst, and estimate the query GPS from nearest neighbors; 2) 2Dto3D [26,19,25,20], which reconstructs 3D structures of images in a reference database oine, and performs online 2Dto3D matching for a query. Unfortunately, this approach does not t well in the context of imagetoGPS verication for three reasons. First, the premise of a large enough, uptodate, oine reference database is dicult to achieve for most users because such a database is too expensive to create or maintain. Second, we only have one query image instead of a collection or a sequence of images, and thus violate the working assumptions of methods like [2,28]. Third, similaritybased retrieval works well for city landmarks, but not for visually similar locations, e.g. Starbucks stores in dierent places all over the world. Alternatively, we approach this problem following the classic image verica tion paradigm { given a pair of images, one query and one reference, we use a network to decide whether or not they are from the same location, where the reference image can be retrieved at the claimed GPS location from a thirdparty GPSbased image database e.g. Google Street View [3] and Bing Street Side . Of course, many existing works on image verication, e.g.face verication [1] and object verication [10], can be directly applied to this problem because verica tion nature does not change, but they are unsuitable since the critical camera information like shooting angle and focal length is unknown and this raises dif culty to retrieve an appropriate reference image to compare against the query.ImagetoGPS Verication 3 The potential mismatch roots in the fact that a query image is a 2D projection of a 3D scene, while a GPS location is a 2D point. In this paper, we propose a novel BottomUp Pattern Matching (BUPM) based verication network. It directly compares a query image and a panorama reference image collected from a claimed GPS location, and thus completely get rid of the errorprone reference images caused by unknown shooting angle and focal length and largely simplies the data preparation. It estimates the potential matched patches in both reference and query in a bottomup manner and makes the decision upon the number of matched patches in a soft way. All modules in the BUPM network are therefore dierentiable and learnable. In this way, the BUPM network can be used not only for verication but also for localization, i.e.nding the query image in a panorama reference image. The remainder of this paper is organized as follows: Sec. 2 brie y reviews recent related works; Sec. 3 introduces the imagetoGPS verication problem and proposes the BUPM verication network solution; Sec. 4 discusses the details of training and dataset; Sec. 5 compares performances of dierent verication solutions; and we conclude this paper in Sec. 6. 2 Related Works","In this paper, we are interested in identifying fake news by testing location consistency  whether an image is taken at a claimed location. Currently, existing methods rely on GPS estimation to make this decision, but they are unsuitable for the context of image-to-GPS verification because the critical camera information like shooting angle and focal length is unknown, and this raises a problem to retrieve an appropriate reference image to compare against the query image. In this paper, we propose a novel Bottom-Up Pattern Matching (BUPM) based verification network to compare a query image and a",cool!
270,A Discriminatively Learned CNN Embedding for Person Re-identification.txt,"We revisit two popular convolutional neural networks (CNN) in person
re-identification (re-ID), i.e, verification and classification models. The two
models have their respective advantages and limitations due to different loss
functions. In this paper, we shed light on how to combine the two models to
learn more discriminative pedestrian descriptors. Specifically, we propose a
new siamese network that simultaneously computes identification loss and
verification loss. Given a pair of training images, the network predicts the
identities of the two images and whether they belong to the same identity. Our
network learns a discriminative embedding and a similarity measurement at the
same time, thus making full usage of the annotations. Albeit simple, the
learned embedding improves the state-of-the-art performance on two public
person re-ID benchmarks. Further, we show our architecture can also be applied
in image retrieval.","PErson reidentiﬁcation (reID) is usually viewed as an image retrieval problem, which matches pedestrians from different cameras [1]. Given a personofinterest (query), per son reID determines whether the person has been observed by another camera. Recent progress in this area has been due to two factors: 1) the availability of the largescale pedestrian datasets. The datasets contain the general visual variance of pedestrian and provide a comprehensive evaluation [2], [3]. 2) the learned embedding of pedestrian using a convolutional neural network (CNN). Recently, the convolutional neural network (CNN) has shown potential for learning stateoftheart feature embed dings or deep metrics [2], [4], [5], [6], [7], [8], [9]. As shown in Fig. 1, there are two major types of CNN structures, i.e.,veriﬁcation models and identiﬁcation models. The two models are different in terms of input, feature extraction and loss function for training. Our motivation is to combine the strengths of the two models and learn a more discriminative pedestrian embedding. Veriﬁcation models take a pair of images as input and determine whether they belong to the same person or not. A number of previous works treat person reID as a binary class classiﬁcation task or a similarity regression task [2], [4], [5], [6]. Given a label s2f0;1g, the veriﬁcation network forces two images of the same person to be mapped to nearby Zhedong Zheng, Liang Zheng and Yi Yang are with Faculty of Engi neering and IT, University of Technology Sydney, NSW, Australia. Email: zdzheng12@gmail.com, liangzheng06@gmail.com, yee.i.yang@gmail.com Fig. 1. The difference between the veriﬁcation and identiﬁcation models. Green blocks represent nonlinear functions by CNN. a) Identiﬁcation models treat person reID as a multiclass recognition task, which take one image as input and predict its identity. b) Veriﬁcation models treat person reID as a twoclass recognition task or a similarity regression task, which take a pair of images as input and determine whether they belong to the same person or not. Here we only show a twoclass recognition case. points in the feature space. If the images are of different people, the points are far apart. However, the major problem in the veriﬁcation models is that they only use weak reID labels [1], and do not take all the annotated information into consideration. Therefore, the veriﬁcation network lacks the consideration of the relationship between the image pairs and other images in the dataset. In the attempt to take full advantages of the reID labels, identiﬁcation models which treat person reidentiﬁcation as a multiclass recognition task, are employed for feature learning [1], [7], [8], [9]. They directly learn the nonlinear functions from an input image to the person ID and the crossentropy loss is used following the ﬁnal layer. During testing, the feature is extracted from a fully connected layer and then normalized. The similarity of two images is thus computed by the Euclidean distance between their normalized CNN embed dings. The major drawback of the identiﬁcation model is that the training objective is different from the testing procedure, i.e.,it does not account for the similarity measurement between image pairs, which can be problematic during the pedestrian retrieval process. The abovementioned observations demonstrate that the two types of models have complementary advantages andarXiv:1611.05666v2  [cs.CV]  3 Feb 2017JOURNAL OF L ATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 2 Method Strong LabelSimilarity ReID Estimation Performance Veriﬁcation Models  X fair Identiﬁcation Models X  good Our Model X X good TABLE I THE ADVANTAGES AND DISADVANTAGES OF VERIFICATION AND IDENTIFICATION MODELS ARE LISTED . W E ASSUME SUFFICIENT TRAINING DATA IN ALL MODELS . OUR MODEL TAKES THE ADVANTAGES OF THE TWO MODELS . limitations as shown in Table I. Motivated by these properties, this work proposes to combine the strengths of the two networks and leverage their complementary nature to improve the discriminative ability of the learned embeddings. The proposed model is a siamese network that predicts person identities and similarity scores at the same time. Compared to previous networks, we take full advantages of the annotated data in terms of pairwise similarity and image identities. During testing, the ﬁnal convolutional activations are extracted for Euclidepdfan distance based pedestrian retrieval. To sum marize, our contributions are: We propose a siamese network that has two losses: identiﬁcation loss and veriﬁcation loss. This network simultaneously learns a discriminative CNN embedding and a similarity metric, thus improving pedestrian re trieval accuracy. We report competitive accuracy compared to the state ofart methods on two largescale person reID datasets (Market1501 [3] and CUHK03 [2]) and one instance retrieval dataset (Oxford5k [10]). The paper is organized as follows. We ﬁrst review some related works in Section II. In Section III, we describe how we combine the two losses and deﬁne the CNN structure. The implementation details are provided. In Section IV, we present the experimental results on two largescale person re identiﬁcation datasets and one instance retrieval dataset. We conclude this paper in Section V. II. R ELATED WORK","The problem of person re-identification (re-ID) is a challenging task that requires the identification of a person from a large-scale dataset. The problem is usually viewed as an image retrieval problem, which matches pedestrians from different cameras. Recent works have shown that the convolutional neural network (CNN) has the potential to learn state-of-the-art feature embeddings or deep metrics. However, the two models are different in terms of input, feature extraction and loss function for training. In this work, the two types of models, the",cool!
524,Analyzing Deep Neural Networks with Symbolic Propagation: Towards Higher Precision and Faster Verification.txt,"Deep neural networks (DNNs) have been shown lack of robustness for the
vulnerability of their classification to small perturbations on the inputs.
This has led to safety concerns of applying DNNs to safety-critical domains.
Several verification approaches have been developed to automatically prove or
disprove safety properties of DNNs. However, these approaches suffer from
either the scalability problem, i.e., only small DNNs can be handled, or the
precision problem, i.e., the obtained bounds are loose. This paper improves on
a recent proposal of analyzing DNNs through the classic abstract interpretation
technique, by a novel symbolic propagation technique. More specifically, the
values of neurons are represented symbolically and propagated forwardly from
the input layer to the output layer, on top of abstract domains. We show that
our approach can achieve significantly higher precision and thus can prove more
properties than using only abstract domains. Moreover, we show that the bounds
derived from our approach on the hidden neurons, when applied to a
state-of-the-art SMT based verification tool, can improve its performance. We
implement our approach into a software tool and validate it over a few DNNs
trained on benchmark datasets such as MNIST, etc.","During the last few years, deep neural networks (DNNs) have been broadly applied in various domains including nature language processing [1], image classiﬁcation [16], game playing [27], etc. The performance of these DNNs, when measured with the pre diction precision over a test dataset, is comparable to, or even better than, that of man ually crafted software. However, for safetycritical applications, it is required that the DNNs are certiﬁed against properties related to its safety. Unfortunately, DNNs have been found lack of robustness. Speciﬁcally, [30] discovers that it is possible to add a small, or even impcerceptible, perturbation to a correctly classiﬁed input and make it misclassiﬁed. Such adversarial examples have raised serious concerns on the safety ofarXiv:1902.09866v2  [cs.LG]  23 Feb 2021DNNs. Consider a selfdriving system controlled by a DNN. A failure on the recog nization of a trafﬁc light may lead to a serious consequence because human lives are at stake. Algorithms used to ﬁnd adversarial examples are based on either gradient descent, see e.g., [30,2], or saliency maps, see e.g., [23], or evolutionary algorithm, see e.g., [22], etc. Roughly speaking, these are heuristic search algorithms without the guarantees to ﬁnd the optimal values, i.e., the bound on the gap between an obtained value and its ground truth is unknown. However, the certiﬁcation of a DNN needs provable guaran tees. Thus, techniques based on formal veriﬁcation have been developed. Up to now, DNN veriﬁcation includes constraintsolving [24,15,18,8,20,34,6], layerbylayer ex haustive search [12,33,32], global optimization [25], abstract interpretation [10,29,28], etc. Abstract interpretation is a theory in static analysis which veriﬁes a program by using sound approximation of its semantics [3]. Its basic idea is to use an abstract do main to overapproximate the computation on inputs. In [10], this idea has ﬁrst been developed for verifying DNNs. However, abstract interpretation can be imprecise, due to the nonlinearity in DNNs. [28] implements a faster Zonotope domain for DNN ver iﬁcation. [29] puts forward a new abstract domain specially for DNN veriﬁcation and it is more efﬁcient and precise than Zonotope. The ﬁrst contribution of this paper is to propose a novel symbolic propagation tech nique to enhance the precision of abstract interpretation based DNN veriﬁcation. For every neuron, we symbolically represent, with an expression, how its activation value can be determined by the activation values of neurons in previous layers. By both il lustrative examples and experimental results, we show that, comparing with using only abstract domains, our new approach can ﬁnd signiﬁcantly tighter constraints over the neurons’ activation values. Because abstract interpretation is a sound approximation, with tighter constraints, we may prove properties that cannot be proven by using only abstract domains. For example, we may prove a greater lower bound on the robustness of the DNNs. Another contribution of this paper is to apply the value bounds derived from our ap proach on hidden neurons to improve the performance of a stateoftheart SMT based DNN veriﬁer Reluplex [15]. Finally, we implement our approach into a software tool and validate it with a few DNNs trained on benchmark datasets such as MNIST, etc. 2 Preliminaries We recall some basic notions on deep neural networks and abstract interpretation. For a vector x2Rn, we usexito denote its ith entry. For a matrix W2Rmn,Wi;j denotes the entry in its ith row andjth column. 2.1 Deep neural networks We work with deep feedforward neural networks, or DNNs, which can be represented as a function f:Rm!Rn, mapping an input x2Rmto its corresponding out puty=f(x)2Rn. A DNN has in its structure a sequence of layers, including anx1 x2   xmy1 y2   ynHidden layerInput layerOutput layer Fig. 1: A fully connected network: Each layer performs the composition of an afﬁne transformation Ane(x;W;b)and the activated function, where on edges between neu rons the coefﬁcients of the matrix Ware recorded accordingly. input layer at the beginning, followed by several hidden layers, and an output layer in the end. Basically the output of a layer is the input of the next layer. To unify the representation, we denote the activation values at each layer as a vector. Thus the trans formation between layers can also be seen as a function in Rm0!Rn0. The DNNfis the composition of the transformations between layers, which is typically composed of an afﬁne transformation followed by a nonlinear activation function. In this paper we only consider one of the most commonly used activation function – the rectiﬁed linear unit (ReLU) activation function, deﬁned as ReLU(x) = max(x;0) forx2RandReLU(x) = (ReLU( x1);:::; ReLU(xn))forx2Rn. Typically an afﬁne transformation is of the form Ane(x;W;b) =Wx+b:Rm! Rn, whereW2Rnmandb2Rn. Mostly in DNNs we use a fully connected layer to describe the composition of an afﬁne transformation Ane(x;W;b)and the activation function, if the coefﬁcient matrix Wis not sparse and does not have shared parame ters. We call a DNN with only fully connected layers a fully connected neural network (FNN). Fig. 1 gives an intuitive description of fully connected layers and fully con nected networks. Apart from fully connected layers, we also have afﬁne transformations whose coefﬁcient matrix is sparse and has many shared parameters, like convolutional layers . Readers can refer to e.g. [10] for its formal deﬁnition. In our paper, we do not special deal with convolutional layers, because they can be regarded as common afﬁne transformations. In the architecture of DNNs, a convolutional layer is often followed by a nonlinear max pooling layer , which takes as an input a three dimensional vector x2Rmnrwith two parameters pandqwhich divides mandnrespectively, deﬁned as MaxPool p;q(x)i;j;k= maxfxi0;j0;kji02(p(i","Deep neural networks (DNNs) have been widely used in various domains, including image classification, natural language processing, and game playing. However, for safety-critical applications, it is required that the DNNs are certified against properties related to its safety. Unfortunately, DNNs have been found lack of robustness. For example, it is possible to add a small, or even imperceptible, perturbation to a correctly classified input and make it misclassified. Such adversarial examples have raised serious concerns on the safety of DNNs.",cool!
65,Integrated Replay Spoofing-aware Text-independent Speaker Verification.txt,"A number of studies have successfully developed speaker verification or
presentation attack detection systems. However, studies integrating the two
tasks remain in the preliminary stages. In this paper, we propose two
approaches for building an integrated system of speaker verification and
presentation attack detection: an end-to-end monolithic approach and a back-end
modular approach. The first approach simultaneously trains speaker
identification, presentation attack detection, and the integrated system using
multi-task learning using a common feature. However, through experiments, we
hypothesize that the information required for performing speaker verification
and presentation attack detection might differ because speaker verification
systems try to remove device-specific information from speaker embeddings,
while presentation attack detection systems exploit such information.
Therefore, we propose a back-end modular approach using a separate deep neural
network (DNN) for speaker verification and presentation attack detection. This
approach has thee input components: two speaker embeddings (for enrollment and
test each) and prediction of presentation attacks. Experiments are conducted
using the ASVspoof 2017-v2 dataset, which includes official trials on the
integration of speaker verification and presentation attack detection. The
proposed back-end approach demonstrates a relative improvement of 21.77% in
terms of the equal error rate for integrated trials compared to a conventional
speaker verification system.","Recent advances in deep neural networks (DNNs) have improved the performance of speaker veriﬁcation (SV) systems, including shortduration and farﬁeld scenarios [ 1–5]. However, SV systems are known to be vulnerable to various presentation attacks, such as replay attacks, voice conversion, and speech synthesis. These vulnerabilities have inspired research into presentation attack detection (PAD), which classiﬁes given utterances as spoofed or not spoofed [ 6–8] where many DNNbased systems have achieved promising results [9–11]. Table 1 demonstrates the vulnerability of conventional SV systems when faced with presentation attacks. The performance is reported using the three types of equal error rates (EERs) described in Table 2 [12]. Table 2 shows the target and nontarget trials for calculating the EER, which are represented by 1 and 0, respectively. Zeroeffort (ZE)EER describes the conventional SV performance without considering the presence of presentation attacks. PADEER denotes the EER for PAD which only considers whether an input is spoofed. Integrated speaker veriﬁcation (ISV)EER describes overall performance, considering both speaker identity and spooﬁng. We refer to “replay spooﬁngaware SV” as an ISV task and report its performance using ISVEER. Results show that the EER of SV degrades to 33.72% with replayed utterances; this fatal performance degradation supports the necessity of a spooﬁngaware ISV system. In this paper, PAD refers to replay attacks, because the ASVspoof2017 dataset only focuses on replay attack detectionarXiv:2006.05599v2  [eess.AS]  27 Sep 20202 of 10 Table 1. Difference in equal error rate (EER) according to the existence of replay nontarget trials. Results demonstrate the vulnerability of speaker veriﬁcation systems that are unaware of PAD. ZEEER PADEER ISVEER SV baseline 9.58 33.72 19.98 Table 2. Three types of EERs reported in this paper. Enrollment utterance is always bonaﬁde (i.e. genuine, not replayed). Target: enrollment and test utterances are uttered by an identical speaker and are bonaﬁde; ZE nontarget: enrollment and test utterances are uttered by different speakers and are bonaﬁde; Replay nontarget: enrollment and test utterances are uttered by an identical speaker and test utterance is replay spoofed. TargetZE Replay nontarget nontarget ZEEER 1 0 PADEER 1 0 ISVEER 1 0 0 which is known to be the easiest yet effective attack. Therefore, the following three tasks are considered: SV , PAD, ISV , and performance is evaluated using ZEEER, PADEER, and ISVEER. While a number of studies have worked to develop independent systems for SV and PAD, few have sought to integrate the SV and PAD systems [ 12–17]. More speciﬁcally, this handful of studies proposed approaches such as cascaded, parallel [ 12,13], and joint systems [ 14,16,17]. Most existing studies used common features to integrate the two tasks for system efﬁciency. Section 2 further takes up this existing body of work. In this paper, we propose two spooﬁngaware frameworks for the ISV task, illustrated in Figure 1. We use a light cnn (LCNN) architecture [ 18] for both frameworks; this choice is based on its success in various PAD studies [ 11,19]. The ﬁrst proposed framework expands existing work by proposing a monolithic endtoend (E2E) architecture. More speciﬁcally, it conducts speaker identiﬁcation (SID) and PAD to train a common feature using multitask learning (MTL) [ 20]. Concurrently, it uses the embeddings to compose trials and conduct the ISV task. Using the sum of SID, PAD, and ISV losses, the entire DNN is jointly optimized. However, based on tendencies observed during internal experiments, we hypothesize that training a common feature for the ISV task may not be ideal because the properties required for each task differ: the PAD task representation uses device and channel information while SV needs to remove it (further discussed in Section 3). Based on our hypothesis, we propose a novel modular approach using a separate DNN. This approach inputs two speaker embeddings (for enrollment and test each) and a PAD prediction to make the ISV decision. It adopts a twophase approach. In the ﬁrst phase, the speaker identiﬁer and PAD system are trained separately. In the second phase, speaker embeddings are extracted from a pretrained speaker identiﬁer [ 21], and the embeddings and PAD prediction results are fed to a separate DNN module. Using this framework, we achieved a 21.77% relative improvement in terms of ISVEER (We use the trial in [ 22] for calculating ISVEER). The contributions of this paper are as follows: 1. Propose a novel E2E framework that jointly optimizes SID, PAD, and the ISV task; 2.Experimentally validate the hypothesis that the discriminative information required for the SV and the PAD task may be distinct, requiring separate frontend modeling;3 of 10 Figure 1. (a): An endtoend architecture that trains embeddings (used for speaker identiﬁcation (SID) and presentation attack detection (PAD)). LCNN and MTL refer to the light cnn and multitask learning, respectively; (b): a separate architecture that inputs speaker embeddings from SID and PAD results and outputs the Integrated result of speaker veriﬁcation (SV) and PAD. 3.Propose a separate modular backend DNN that takes speaker embeddings and PAD predictions as an input to make ISV decisions. The remainder of the paper is organized as follows. Section 2 details related work on the integrated system of SV and PAD. Section 3 introduces the two proposed frameworks. Section 4 presents our experiments and results and the paper is concluded in Section 5. 2. Related work","Deep neural networks (DNNs) have been used to improve the performance of speaker verification (SV) systems. However, SV systems are vulnerable to various presentation attacks, such as replay attacks, voice conversion, and speech synthesis. These attacks have inspired research into presentation attack detection (PAD), which classifies given utterances as spoofed or not spoofed. In this paper, we propose two spoofing-aware frameworks for the ISV task. The first proposes a monolithic end-to-end-to-end (E2E) architecture",cool!
507,Crystal Loss and Quality Pooling for Unconstrained Face Verification and Recognition.txt,"In recent years, the performance of face verification and recognition systems
based on deep convolutional neural networks (DCNNs) has significantly improved.
A typical pipeline for face verification includes training a deep network for
subject classification with softmax loss, using the penultimate layer output as
the feature descriptor, and generating a cosine similarity score given a pair
of face images or videos. The softmax loss function does not optimize the
features to have higher similarity score for positive pairs and lower
similarity score for negative pairs, which leads to a performance gap. In this
paper, we propose a new loss function, called Crystal Loss, that restricts the
features to lie on a hypersphere of a fixed radius. The loss can be easily
implemented using existing deep learning frameworks. We show that integrating
this simple step in the training pipeline significantly improves the
performance of face verification and recognition systems. We achieve
state-of-the-art performance for face verification and recognition on
challenging LFW, IJB-A, IJB-B and IJB-C datasets over a large range of false
alarm rates (10-1 to 10-7).","FACE veriﬁcation in unconstrained settings is a challenging problem. Despite the excellent performance of recent face veriﬁcation systems on datasets like Labeled Faces in the Wild (LFW) [20], it is still difﬁcult to achieve similar accuracy on faces with extreme variations in viewpoints, resolution, occlusion and image quality. This is evident from the performance of traditional algorithms on the publicly available IJBA [23] dataset. Data quality imbalance in the training set is one of the reasons for this performance gap. Existing face recognition training datasets contain large amount of high quality and frontal faces, whereas the unconstrained and difﬁcult faces occur rarely. Most of the DCNN based methods trained with softmax loss for classiﬁcation tend to overﬁt to the high quality data and fail to correctly classify faces acquired in difﬁcult conditions. Using the softmax loss function for training face veriﬁcation system has its own advantages and disadvantages. On the one hand, it can be easily implemented using inbuilt functions from the publicly available deep leaning toolboxes such as Caffe [22], Torch [12] and TensorFlow [1]. Unlike triplet loss [43], it does not have any restrictions on the input batch size and converges quickly. The learned features are discriminative enough for efﬁ cient face veriﬁcation without any metric learning. On the other R. Ranjan, A. Bansal, H. Xu, S. Sankaranarayanan and R. Chel lappa are with the Department of Electrical and Computer Engineer ing, University of Maryland, College Park, MD, 20742 USA email: frranjan1,ankan,hyxu,swamiviv,rama g@umiacs.umd.edu. JC Chen and C. D. Castillo are with UMIACS, University of Maryland, College Park, MD, 20742 USA email: fpullpull,carlosg@umiacs.umd.edu. Fig. 1. A general pipeline for training and testing a face veriﬁcation system using DCNN. hand, the softmax loss is biased to the sample distribution. Unlike contrastive loss [44] and triplet loss [43] which speciﬁcally attend to hard samples, the softmax loss maximizes the conditional probability of all the samples in a given minibatch. Hence, it is suited to handle high quality faces, ignoring the rare difﬁcult faces in a training minibatch. We observe that the L2norm of features learned using softmax loss is informative of the quality of the face [35]. Features for good quality frontal faces have a highL2norm while blurry faces with extreme pose have low L2norm (see Figure 2(b)). Moreover, the softmax loss does not optimize the veriﬁcation requirement of keeping positive pairs closer and negative pairs far from each other. In order to addressarXiv:1804.01159v2  [cs.CV]  4 Feb 2019JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 2 this limitation, many methods either apply metric learning on top of softmax features [7], [9], [37], [42] or train an auxiliary loss [44], [49], [50] along with the softmax loss to achieve enhanced veriﬁcation performance. In this paper, we provide a symptomatic treatment to issues associated with using softmax loss. We propose the Crystal loss function that adds a constraint on the features during training such that their L2norm remains constant. In other words, we restrict the features to lie on a hypersphere of a ﬁxed radius. The proposed Crystal loss has two advantages. Firstly, it provides equal attention to both good and bad quality faces since all the features have the same L2norm now, which is essential for improved performance in unconstrained settings. Secondly, it strengthens the veriﬁcation features by forcing the same subject features to be closer and features from different subjects to be far from each other in the normalized space. Therefore, it maximizes the margin for the normalized L2distance or cosine similarity score between negative and positive pairs. In this way, the proposed Crystal loss overcomes the limitations of the regular softmax loss. The Crystal loss also retains the advantages of the regular softmax loss. Similar to the softmax loss, it is a one network, one loss system. It doesn’t necessarily require any joint supervision as used by many recent methods [37], [44], [49], [50]. It can be easily implemented using inbuilt functions from Caffe [22], Torch [12] and TensorFlow [1], and converges very fast. It intro duces just a single scaling parameter to the network. Compared to the regular softmax loss, the Crystal loss gains a signiﬁcant improvement in the performance. It achieves new stateoftheart results on IJBA, IJBB, IJBC and LFW datasets, and competitive results on YouTube Face datasets. It surpasses the performance of several stateoftheart systems, which use multiple networks or multiple loss functions or both. Moreover, the gains from Crystal Loss are complementary to metric learning (eg: TPE [42], jointBayes [7]) or auxiliary loss functions (eg: center loss [50], contrastive loss [44]). We show that applying these techniques on top of the Crystal Loss can further improve the veriﬁcation performance. We also address the problem of face veriﬁcation and recog nition using videos or imagesets. A video may contain mul tiple frames with faces of a person of interest. An imageset, sometimes interchangeable with template, may contain multiple images/frames of a person of interest, captured from differ ent sources. In a videobased or templatebased face veriﬁca tion problem, we need to determine whether a given pair of videos/templates belong to the same identity. A traditional way to solve this problem is to represent a video or a template using a set of features, each corresponding to its constituent images or frames. This approach is not memoryefﬁcient and does not scale with large number of videos. Additionally, computing similarity scores between two videos for every framepair is of a high time complexity. Owing to these limitations, researchers have focused on generating a single feature representation from a given video or a template. A simple approach is to represent the video/template with arithmetic mean of the features of the constituent frames/images. This approach may lead to suboptimal feature representation since the features for both good as well as bad quality faces get weighted equally. To this end, we propose Quality Pooling, which obtains the weight coefﬁcients using the face detection scores. We show that these probability scores from a face detector could be treated as a measure of the face quality. A goodquality frontal face has a higher detection probability scorecompared to a blurry and proﬁle face. Using the precomputed de tection score does not require any additional training and improves the performance of video/templatebased face veriﬁcation. In addition, we focus on improving the face veriﬁcation per formance at low False Accept Rates (FARs). We propose Quality Attenuation, that rescales the similarity score based on maximum of the detection score of the veriﬁcation pair. It helps in reducing the score for a dissimilar pair if the face quality of both images in the pair is poor, thus increasing the True Accept Rate (TAR) at a given FAR. Experiments on challenging IJBB and IJBC datasets show that Quality Attenuation signiﬁcantly improves the TARs at very low FARs. In summary, this paper makes the following contributions: 1) We propose a simple, novel yet effective Crystal Loss for face veriﬁcation that restricts the L2norm of the feature descriptor to a constant value . 2) We study the variations in the performance with respect to the scaling parameter and provide suitable bounds on its value for achieving consistently high performance. 3) We propose Quality Pooling, which generates a compact feature representation for a video or template using face detection score. 4) We propose Quality Attenuation, which rescales the sim ilarity scores based on the face detection scores of the veriﬁcation pairs. 5) The proposed methods yields consistent and signiﬁcant improvements on all the challenging face veriﬁcation datasets namely LFW [20], YouTube Face [28], and IJB A [23], IJBB [51] and IJBC [33] 2 R ELATED WORK","Face verification in unconstrained settings is a challenging problem. Recent face verification systems have achieved excellent performance on datasets like Labeled Faces in the Wild (LFW). However, it is still difficult to achieve similar accuracy on faces with extreme variations in viewpoints, resolution, occlusion and image quality. Most of the DCNN based methods trained with softmax loss tend to overfit to the high quality data and fail to correctly classify faces acquired in difficult conditions. In this paper, we propose the Crystal loss function that adds a constraint on the features during training such that their L2",cool!
314,Git Loss for Deep Face Recognition.txt,"Convolutional Neural Networks (CNNs) have been widely used in computer vision
tasks, such as face recognition and verification, and have achieved
state-of-the-art results due to their ability to capture discriminative deep
features. Conventionally, CNNs have been trained with softmax as supervision
signal to penalize the classification loss. In order to further enhance the
discriminative capability of deep features, we introduce a joint supervision
signal, Git loss, which leverages on softmax and center loss functions. The aim
of our loss function is to minimize the intra-class variations as well as
maximize the inter-class distances. Such minimization and maximization of deep
features are considered ideal for face recognition task. We perform experiments
on two popular face recognition benchmarks datasets and show that our proposed
loss function achieves maximum separability between deep face features of
different identities and achieves state-of-the-art accuracy on two major face
recognition benchmark datasets: Labeled Faces in the Wild (LFW) and YouTube
Faces (YTF). However, it should be noted that the major objective of Git loss
is to achieve maximum separability between deep features of divergent
identities.","The current decade is characterized by the widespread use of deep neural networks for dif ferent tasks [18, 25, 30]. Similarly, deep convolutional networks have brought about a rev olution in face veriﬁcation, clustering and recognition tasks [6, 18, 19, 27, 29]. Majority of face recognition methods based on deep convolutional networks (CNNs) differ along three primary attributes as explained in [6, 7]. The ﬁrst is the availability of large scale datasets for training deep neural networks. Datasets such as VGGFace2 [4], CASIAWebFace [31], UMDFaces [2], MegaFace [13] and MSCeleb1M [8] contain images ranging from thou sands to millions. The second is the emergence of powerful and scalable network architec tures such as InceptionResNet [10] to train on large scale datasets. The last attribute is the c/circlecopyrt2018. The copyright of this document resides with its authors. It may be distributed unchanged freely in print or electronic forms. *Equal contribution of these authors to this work. 1See code at https://github.com/kjanjua26/GitLossForDeepFaceRecognition arXiv:1807.08512v4  [cs.CV]  28 Jul 20182 CALEFATI ET AL.: GIT LOSS FOR DEEP FACE RECOGNITION Figure 1: A toy example depicting the aim of our work: a CNN trained for face recognition supervised by our Git loss function that maximizes the distance d2 between features and cen troids of different classes and minimizes the distance d1 between features and the centroid of the same class. development of loss functions to effectively modify inter and intraclass variations such as Contrastive loss [20], Triplet loss [19] and Center loss [27], given that softmax penalizes only the overall classiﬁcation loss. In this paper, we employ all three attributes associated with face recognition. We use a large scale publicly available dataset, VGGFace2, to train the powerful Inception ResNet V1 network. We propose a new loss function named Git loss to enhance the discriminative power of deeply learned face features. Speciﬁcally, the Git loss simultaneously minimizes intraclass variations and maximizes interclass distances. A toy example that explains our approach is shown in Figure 1. The name of the loss function is inspired from two common Git version control software commands, ""push"" and ""pull"", which are semantically similar to the aim of this work: push away features of different identities while pulling together features belonging to the same identity. In summary, main contributions of our paper include: – A novel loss function which leverages on softmax and center loss to provide segrega tive abilities to deep architectures and enhance the discrimination of deep features to further improve the face recognition task – Easy implementation of the proposed loss function with standard CNN architectures. Our network is endtoend trainable and can be directly optimized by fairly standard optimizers such as Stochastic Gradient Descent (SGD). – We validate our ideas and compare Git loss against different supervision signals. We evaluate the proposed loss function on available datasets, and demonstrate stateof theart results. The organization of the paper is as follows: we review the literature on face recognition in Section 2 and introduce our supervision signal with details in Section 3. We discuss experimental results in Section 4 followed by conclusion and future work in Section 5 and 6. 2 Related Work","Deep convolutional networks (CNNs) have been widely used in face recognition tasks. However, face recognition is a challenging task due to the lack of large scale datasets and the emergence of powerful and scalable network architectures such as Inception ResNet to train on large scale datasets. In this paper, we employ all three attributes associated with face recognition. We use a large scale publicly available dataset, VGGFace2, to train the powerful Inception ResNet V1 network. We propose a novel loss function named Git loss to enhance the discriminative power of deep features. The name",cool!
492,Development and application of a machine learning supported methodology for measurement and verification (M&V) 2.0.txt,"The foundations of all methodologies for the measurement and verification
(M&V) of energy savings are based on the same five key principles: accuracy,
completeness, conservatism, consistency and transparency. The most widely
accepted methodologies tend to generalise M&V so as to ensure applicability
across the spectrum of energy conservation measures (ECM's). These do not
provide a rigid calculation procedure to follow. This paper aims to bridge the
gap between high-level methodologies and the practical application of modelling
algorithms, with a focus on the industrial buildings sector. This is achieved
with the development of a novel, machine learning supported methodology for M&V
2.0 which enables accurate quantification of savings.
  A novel and computationally efficient feature selection algorithm and
powerful machine learning regression algorithms are employed to maximise the
effectiveness of available data. The baseline period energy consumption is
modelled using artificial neural networks, support vector machines, k-nearest
neighbours and multiple ordinary least squares regression. Improved knowledge
discovery and an expanded boundary of analysis allow more complex energy
systems be analysed, thus increasing the applicability of M&V. A case study in
a large biomedical manufacturing facility is used to demonstrate the
methodology's ability to accurately quantify the savings under real-world
conditions. The ECM was found to result in 604,527 kWh of energy savings with
57% uncertainty at a confidence interval of 68%. 20 baseline energy models are
developed using an exhaustive approach with the optimal model being used to
quantify savings. The range of savings estimated with each model are presented
and the acceptability of uncertainty is reviewed. The case study demonstrates
the ability of the methodology to perform M&V to an acceptable standard in
challenging circumstances.","There are many widely recognised and well established methodologies for the measurement and veriﬁcation (M&V) of energy savings. These include the International Perfor mance Measurement and Veriﬁcation Protocol (IPMVP) [1], the American Society of Heating, Refrigerating and Air Conditioning Engineers’ (ASHRAE) Guideline 14 [2] and ISO 500152014 [3]. These methodologies are intertwined with one another and provide guidance on applying universal approaches to the wide spectrum of energy saving projects. Despite this, the lack of a rigid calculation process has been highlighted as a signiﬁcant shortcoming of these methodologies [4]. This is less of an issue in residential and commercial applications as the nature of the energy systems in place are more simplistic. In contrast to this, industrial buildings contain complex energy I©2018. This manuscript version is made available under the CCBYNC ND 4.0 licence https://creativecommons.org/licenses/byncnd/ 4.0/ Corresponding Author Email address: c.v.gallagher@umail.ucc.ie (Colm V . Gallagher) URL: www.ucc.ie/en/ierg (Colm V . Gallagher)systems with many variables impacting on energy consumption. ASHRAE Guideline 14 states that its procedures do not include major industrial loads. The lack of a prescribed, analytical pro cess that can be applied has implications on the accuracy and reliability of energy savings. In 2015, industry accounted for 25.3% of total ﬁnal energy consumption in the European Union (EU) [5] and 20.9% in Ire land in 2016 [6]. The European Parliament have issued the Energy E ciency Directive in an attempt to maximise the ef ﬁciency with which energy is consumed in industry [7]. Un der the terms of the Directive, member states are obligated to achieve 20% energy e ciency savings by 2020. The success of energy conservation measures (ECMs) implemented to achieve this target can only be measured using M&V . Thus, accurate M&V is a necessity for ECMs to be conﬁdently relied upon when assessing progress towards EU targets. The focus on en ergy e ciency is set to continue post2020 with proposals to update the Directive that include a new 30% energy e ciency target for 2030 [8]. M&V has a critical role to play in the deliv ery of this energy e ciency policy. The major focal point of legislation has been the implemen tation of ECMs to minimise consumption in the industrial sec Preprint submitted to Energy and Buildings January 26, 2018arXiv:1801.08175v1  [cs.AI]  24 Jan 2018tor. For this to be a success, the M&V performed on each in dividual ECM must be of su cient accuracy so that the sav ings estimated can be relied upon. The cumulative impact of these ECMs will be evidence of the success of the Directive. There is a signiﬁcant danger that over estimation of savings on an individual project level could hinder attempts to limit cli mate change. This has created a need for a methodology that is capable of overcoming the barriers that impede accurate M&V in industrial facilities. These challenges include cost, resources and the time required to perform M&V . Earlier research aimed at addressing these issues identiﬁed the potential of machine learning as a suitable tool to achieve this [9]; hence, this paper proposes a machine learning supported methodology to popu late this knowledge gap. A clearly deﬁned, prescriptive process focused on harnessing the power of energy data in an e cient manner is presented. There are three periods of interest in any M&V project: the baseline, implementation and reporting periods. Although they always occur sequentially, the length of each period will vary depending on individual project parameters. The baseline pe riod occurs prior to the implementation of an ECM, with the reporting period taking place following the implementation pe riod. A crucial step in M&V is the estimation of the adjusted baseline in the reporting period. This is found by normalis ing the reporting period energy consumption to baseline period conditions. Typically, engineering or statistical methods are ap plied to construct a baseline model capable of performing this normalisation. Consequently, M&V is not an exact science and maintaining accuracy throughout the process is critical to its success. The three principle sources of uncertainty are sam pling, measuring and modelling. The IPMVP deﬁnes a method ological approach that can be applied to quantify uncertainty in a project. In this, the minimum acceptable level of uncertainty is deﬁned as the point at which savings are larger than twice the standard error of the baseline value [10]. Lee et al. identiﬁed uncertainty of baseline measurements as a key risk to energy service companies in energy performance contracting [11]. In recent years, M&V 2.0 represents an area of signiﬁcant in terest and it is being used to further develop the commonly used practices. M&V 2.0 di ers from traditional M&V as it uses large data sets and automated advanced analytics to streamline and scale the process [12]. The automated analytics can provide ongoing savings estimates in close to realtime. This enables M&V to progress from a static, retrospective process to a more dynamic state in which savings can be maximised. The added complexity of modelling has been driven by the increased avail ability of granular energy data from advanced metering infras tructure (AMI) systems. The use of this data coupled with au tomated processing has been identiﬁed as the most opportune manner with which to progress M&V [13]. The increased ac curacy, certainty and standardisation of savings calculations of fered by M&V 2.0 is hugely beneﬁcial. To enable this, there is a need to establish guidelines and best practices in order to fully realise the potential of these advancements. The formal methodology presented in this paper seeks to become this re source for the industrial sector.2. Research questions To date, artiﬁcial intelligence (AI) has been proven to be ad vantageous in building energy load prediction [14], with ma chine learning being a subﬁeld of AI. The primary objective of this research is the development of a replicable, robust and detailed methodology to enable the use of machine learning for the purposes of M&V in industrial facilities. The following re search questions were used to lead the analysis: 1. Can a deﬁnitive methodology be developed to provide ex plicit guidance on the application of machine learning in M&V? 2. Is it possible for such a methodology to be robust enough to harness the power of available data across the spectrum of dierent M&V projects? 3. Can machine learning algorithms be employed on large data sets without increasing the resources required for M&V? 4. An extended boundary of analysis is proposed to increase the baseline energy model accuracy in circumstances with limited system speciﬁc metering infrastructure. Can M&V be completed with acceptable accuracy using this novel boundary of analysis? 3. Related work","This paper presents a machine learning-supported methodology for the measurement and verification of energy savings in industrial facilities. The methodology is based on the IPMVP, which is a widely recognised and well-established methodology for the measurement and verification of energy savings. The IPMVP defines a methodological approach that can be applied to quantify uncertainty in a project. The IPMVP is a widely recognised and well-established methodology for the measurement and verification of energy savings. However, the lack of a prescribed, analytical process has been highlighted as a significant shortcoming in the industry.",cool!
298,Handwriting recognition using Cohort of LSTM and lexicon verification with extremely large lexicon.txt,"State-of-the-art methods for handwriting recognition are based on Long Short
Term Memory (LSTM) recurrent neural networks (RNN), which now provides very
impressive character recognition performance. The character recognition is
generally coupled with a lexicon driven decoding process which integrates
dictionaries. Unfortunately these dictionaries are limited to hundred of
thousands words for the best systems, which prevent from having a good language
coverage, and therefore limit the global recognition performance. In this
article, we propose an alternative to the lexicon driven decoding process based
on a lexicon verification process, coupled with an original cascade
architecture. The cascade is made of a large number of complementary networks
extracted from a single training (called cohort), making the learning process
very light. The proposed method achieves new state-of-the art word recognition
performance on the Rimes and IAM databases. Dealing with gigantic lexicon of 3
millions words, the methods also demonstrates interesting performance with a
fast decision stage.","Handwriting recognition is the numeric process of translating handwritten text images into strings of characters. The handwriting recognition process traditionally involves two steps [1]: optical character recognition and linguistic processing. Optical character recognition is a hard task due to the variability of shapes in handwritten texts, since every human has his own personal writing style. Therefore, even when using state of the art classiﬁers like deep neural net works to recognize characters [2], a considerable amount of errors would occur by considering only the optical model. Linguistic processing aims at combining the characters hypotheses together so as to provide the most likely sequence of words in accordance with some high level linguistic rules. There are two types of linguistic knowledge: lexicons and language models. A language model is a probabilistic modelization of a language which generally provides word sequence likelihood, allowing to rank the recognition hypothesis provided by the optical model. Nowadays, the use of linguistic knowledge is an open problem. Lexi con driven approaches aim at recognizing words thanks to the use of a lexicon. They search for the most likely word that belongs to the working lexicon, by concatenating the character hypotheses. There is currently no eﬃcient alterna tive to the use of lexicon driven recognition methods either for isolated words or for text recognition. Which lexicon resource should be used, which corpora should be selected for training the language model ? These choices directly af fect the recognition performance. In the case of lexicon driven methods, where the characters are aligned on the lexicon words, too small lexicons fail to cover the test dataset, thus missing solutions. However, using a large lexicon (1000 words and more) requires many computations and generally produces precision loss [3]. To the best of our knowledge, the largest lexicon used in the literature was composed of 200K words [4] (60K words for [5]), and there could still occur out of vocabulary words (named entity, numbers, etc). During the last years, signiﬁcant progress in handwriting recognition and especially in optical models have been made thanks to deep learning advances 2[6], namely with the Long Short Term Memories (LSTM) Recurrent Neural Networks (RNN) [7]. The LSTM recurrent neural networks achieve state of the art performance in various applications involving sequence recognition, such as speech recognition [8], protein predictions [9], machine translation [10], and op tical character recognition [11, 12]. Performance of complete systems including both LSTM networks and linguistic resources [13] is due to the very high raw performance of the optical model (i.e. without using additional linguistic re source). For example, the raw performance of the optical model is about 35% WER on the RIMES dataset when using a BLSTM optical model solely. The contribution of the language model is then to penalize the wrong hypotheses produced by the optical model, so as to favor the most likely word sequences from the language model point of view. We believe that the raw performance of the LSTM based optical models provide hints that such networks should be used in a more speciﬁc way, and not only as a character classiﬁer using a lexicon directed recognition approach, as it is the case in most of the actual studies reported in the literature. Breaking the standard use of LSTM RNN as a simple classiﬁer introduced in a lexicon driven decoding scheme, this work proposes a new recognition paradigm that improves handwriting recognition state of the art performance. This new paradigm is based on word classiﬁers combination using an eﬃcient decision rule operating at word level, which consists in lexicon veriﬁcation. Lex icon veriﬁcation consists in accepting a word recognition hypothesis if it belongs to the lexicon, and rejecting it otherwise. The underlying idea is that it is very unlikely that a wrong word recognition hypothesis belongs to the lexicon. The major advantage of this strategy is that it constitutes an extremely fast deci sion process, especially when compared to the tedious lexicondriven decoding process which generally consists in a Viterbi beam search [14]. Classiﬁer com bination is introduced using a cascade framework for combining multiple word classiﬁers. It is based on two key points: i) a lexicon veriﬁcation decision pro cess ii) a pool of complementary recognizers. We introduce a very eﬃcient way to produce hundreds of complementary word recognizers in a very reasonable 3training time. Following the recent theoretical results in deep learning[15], we observed that multiple complementary networks can be obtained during a single training stage. We exploit this theoretical result to produce hundreds of com plementary LSTM networks using a single training. We show that the proposed strategy reaches very high performance regardless the size of the lexicon. As a consequence, the approach has no limitation regarding the lexicon size, as demonstrated by the results obtained using a gigantic lexicon of more than 3 million words. This article starts by a review of the state of the art of handwriting recogni tion highlighting the latest results obtained with BLSTM networks and Hidden Markov Models. In the second part, we present our approach made of a cascade of LSTM recurrent neural networks. We show how to get complementary LSTM RNN during training. In the third part of the paper, the implementation of the method is described. Finally the results are presented on the Rimes and IAM datasets, and then discussed before concluding. 2. Related works","Handwriting recognition is a numeric process of translating handwritten text images into strings of characters. The recognition process traditionally involves two steps: optical character recognition and linguistic processing. Optical character recognition is a hard task due to the variability of shapes in handwritten texts. Linguistic processing aims at combining the characters hypotheses together so as to provide the most likely sequence of words in accordance with some high level linguistic rules. There is currently no efficient alternative to the use of lexicon driven recognition methods, either for isolated words or for text recognition. The contribution of the",cool!
4,RSKNet-MTSP: Effective and Portable Deep Architecture for Speaker Verification.txt,"The convolutional neural network (CNN) based approaches have shown great
success for speaker verification (SV) tasks, where modeling long temporal
context and reducing information loss of speaker characteristics are two
important challenges significantly affecting the verification performance.
Previous works have introduced dilated convolution and multi-scale aggregation
methods to address above challenges. However, such methods are also hard to
make full use of some valuable information, which make it difficult to
substantially improve the verification performance. To address above issues, we
construct a novel CNN-based architecture for SV, called RSKNet-MTSP, where a
residual selective kernel block (RSKBlock) and a multiple time-scale statistics
pooling (MTSP) module are first proposed. The RSKNet-MTSP can capture both long
temporal context and neighbouring information, and gather more
speaker-discriminative information from multi-scale features. In order to
design a portable model for real applications with limited resources, we then
present a lightweight version of RSKNet-MTSP, namely RSKNet-MTSP-L, which
employs a combination technique associating the depthwise separable
convolutions with low-rank factorization of weight matrices. Extensive
experiments are conducted on two public SV datasets, VoxCeleb and Speaker in
the Wild (SITW). The results demonstrate that 1) RSKNet-MTSP outperforms the
state-of-the-art deep embedding architectures by at least 9%-26% in all test
sets. 2) RSKNet-MTSP-L achieves competitive performance compared with baseline
models with 17%-39% less network parameters. The ablation experiments further
illustrate that our proposed approaches can achieve substantial improvement
over prior methods.","Speaker veriﬁcation (SV) aims to verify whether a given utterance belongs to speciﬁc speaker according to his/her voice, which is widely used in s peech related ﬁelds. To cater to diﬀerent application scenarios, two typic al categories of SV tasks can be speciﬁed, namely textdependent SV (TDSV) a nd text independent SV (TISV). TDSV restrains the texts of utteranc es from being ﬁxed; while TISV has no restrictions on the recording utterances . From the implementation algorithms, the SV algorithms can be categorized into stage wise and endtoend ones [1]. The statewise SV systems consist of a frontend to extract speaker characteristics and a backend to calculate t he similarity score of speaker features. While the endtoend systems combin e the two stages together and calculate the similarity score directly for two input utt erances. In this paper, we mainly focus on the statewise TISV systems. In the last few years, the deep learning based approaches have sh own great success in SV tasks and achieved signiﬁcant improvement over the t raditional ivector[2] based methods. They adopt deep neural networks(D NNs) to extract speakerfeatureswhicharealsocalleddeep speakerembeddings. A typicalDNN based TISV system is shown in Figure 1, which can be generalized as f ollows. First, a large amount of utterances are labeled to train a speaker discriminative DNN architecture. Then, the trained DNN model takes both the en rollment utterance and the test utterance as input, and generates corr esponding speaker embeddings respectively. After that, the two speaker embedding s are fed into a backend model, such as probabilistic linear discriminant analysis (PLD A) [3] or 2Enrollment UtteranceTest UtteranceDeep Neural NetworkSpeaker EmbeddingSpeaker EmbeddingBackend   Model Threshold Training  Utterances  Yes No Figure 1: A DNNbased TISV system. cosine similarity, to compute a similarity score. Finally, the veriﬁcation result can be obtained by comparing the score with a predeﬁned thresho ld. Fromthedescription,theessentialpartofaDNNbasedSVsyste mistobuild an eﬀective deep embedding architecture for extracting discrimina tive features between diﬀerent speakers. Currently, the deep embedding arch itectures can be categorized into two types: framelevel structure and segment level structure [4]. The former one extracts framelevel features for each fram e and generate a twodimensional output with time dimension and channel dimension. Time delay neural network (TDNN) [5, 6, 7, 8, 9] and onedimensional co nvolutional neural network (CNN) along the time axis, are representative fra melevel struc tures. The segmentlevel structure [10, 11, 12, 13, 14, 15] con sider the input acoustic features as a grayscale image which has three dimensions f or time, fre quency and channel, respectively, and employ twodimensional CNN to produce threedimensional outputs. In segmentlevel structure, with t he downsampling operation,the dimensionnumberoftime andfrequencydimensionsw ill decrease along with the increase of channel dimensions. After obtaining the o utputs, both two types of structures need a pooling layer to aggregate th e variable length features into a ﬁxeddimensional utterancelevel vector . Eventually, the speaker embeddings are extracted from the output of the fully co nnected (FC) 3layers. Due to the limitations of GPU memory and convergence speed, most T ISV systemsuseshortspeechsegmentsoftrainingutterances(afe w seconds)totrain the DNN while adopt the fulllength utterances to extract speaker embeddings, which leads to a mismatch between training and extraction [16]. In ad dition, since the speech signal is a variablelength sequence in TISV, capt uring long temporal context with short training segments is a challenging task , which af fects the performance of TISV systems especially for CNN archit ectures. Obvi ously, the CNN units could not interact with the regions outside their receptive ﬁelds and are hard to model long context [17]. Although some works [1 8, 19] use dilated convolution to enlarge the receptive ﬁelds, they still lose some neigh boring information for CNN units, resulting in performance degrada tion [20]. Another problem in CNNbased models is the information loss of speak er char acteristics. As the downsamplingoperationisapplied (e.g. stridedco nvolution), some temporal information is lost due to the reduced time dimensions . To ad dress this problem, multiscale aggregation methods [21, 22, 23] ar e gradually introduced into CNN models. However, these methods usually perfo rm global average pooling (GAP) to aggregate features, leading to informat ion loss of speaker characteristics in both time and frequency dimension. On the other hand, with the application for access control in mobile d evices [24], the design of SV systems tends to be lightweight and eﬃcient. Ex isting DNNbased SV models, comprising of millions of parameters, require im mense computational resources and are hard to achieve the lightweight g oal. Thus, it is required for researchers to design more portable models for mob ile devices. Under above insights, we ﬁrst propose an eﬀective CNNbased dee p em bedding architecture called RSKNetMTSP, which consists of residu al selective kernel blocks (RSKBlocks) and a multiple timescale statistics pooling (MTSP) module. For constructing the RSKBlock, the selective kernel conv olution is in troduced(SKConv)[25]. EachRSKBlockcomposesoftwoSKConvmo dulesand a 1×1convolutionallayerwith residual connections. The SKConvcan allo w the CNN units to capture both long temporal context and neighbouring informa 4tion, and provides a soft attention mechanism to adaptively adjust the weight between short and long context. In addition, an MTSP module is desig ned to further capture the useful speaker information, which extra cts multiscale speaker features in terms of temporal variations over longterm context from multiple layers of the network. Based on RSKNetMTSP, we then propose a lightweight architectur e for real applications only with limited resources, called RSKNetMTSPL. Com pared with RSKNetMTSP, the RSKNetMTSPL adopts two other le arning techniques: depthwise seperable convolution and lowrank factor ization. The depthwise separable convolutions is used to reduce the number of p arameters at convolutional layers; while the number of parameters of FC layers is decreased via lowrank matrix factorization of the weight matrices. The experiments are conducted on two public TISV datasets, Vox Celeb [26, 27] and Speakers in the Wild (SITW) [28]. Experimental results de mon strate that the RSKNetMTSP achieves superior results than sta teoftheart deep speaker embedding architectures and the RSKNetMTSPL a lso achieves competitive performance compared with baseline models with less net work pa rameters. In addition, the results of ablation experiments furthe r indicate the eﬀectiveness of the components within the constructed architec tures. The main contributions of this work can be concluded as follows: 1) An eﬀective CNNbased deep embedding architecture RSKNetM TSP is proposed to improve the performance on SV tasks. 2) A lightweight architecture RSKNetMTSPL is presented for rea l applica tions only with limited resources. 3) Extensive experiments conducted on two public SV datasets dem onstrate the eﬀectiveness of our proposed architectures. The remainder of this paper is organized as the follows. Section 2 des cribes the related work on DNNbased TISV systems. Sections 3 presen ts the pro posed model. The experimental setup is introduced in Section 4. The results 5and analysis are shown in Section 5. Finally, Section 6 concludes the pa per. 2. Related work","In this paper, we propose a novel deep neural network-based speaker verification (TISV) system which extracts speaker features from a large number of utterances. The TISV system uses a deep neural network (DNN) to extract speaker features. The DNN model takes both the enrollment utterance and the test utterance as input, and generates corresponding speaker embeddings. Then, the two speaker embeddings are fed into a backend model, such as probabilistic linear discriminant analysis (PLDNN) to compute a similarity",cool!
247,Experiments with Neural Networks for Small and Large Scale Authorship Verification.txt,"We propose two models for a special case of authorship verification problem.
The task is to investigate whether the two documents of a given pair are
written by the same author. We consider the authorship verification problem for
both small and large scale datasets. The underlying small-scale problem has two
main challenges: First, the authors of the documents are unknown to us because
no previous writing samples are available. Second, the two documents are short
(a few hundred to a few thousand words) and may differ considerably in the
genre and/or topic. To solve it we propose transformation encoder to transform
one document of the pair into the other. This document transformation generates
a loss which is used as a recognizable feature to verify if the authors of the
pair are identical. For the large scale problem where various authors are
engaged and more examples are available with larger length, a parallel
recurrent neural network is proposed. It compares the language models of the
two documents. We evaluate our methods on various types of datasets including
Authorship Identification datasets of PAN competition, Amazon reviews, and
machine learning articles. Experiments show that both methods achieve stable
and competitive performance compared to the baselines.","In this paper, we consider the problem of Authorship Verication (AV) which is a branch of forensic authorship analysis. When given two text documents, we look to verify whether the two documents are written by the same author while no previous writing samples of their author/authors have been specied. Majority of online services work on textual communications between users. Their overall reliability and performance can be impacted by someone who abuses the application and provides scripts while hiding their real identity and pretending to be someone else. To preserve the reliability of such services, the identity of the users should be monitored based on their provided scripts. The au thorship verication techniques match the identity of the users with their writing styles. Indeed, authorship verication has an important impact on online doc ument analysis such as plagiarism analysis, sockpuppet detection, blackmailing and email spoong prevention, to name a few [6].arXiv:1803.06456v1  [cs.CL]  17 Mar 2018Traditionally, the studies on AV problem considered a closed and limited set of authors and a closed set of documents written by those authors. During the training step some of these documents (which were sometimes as long as a whole novel) were observed. Then, the problem was to identify whether the authors of a pair of the documents from the rest of the document set were identical [1,2,5]. This type of AV problem benets from having access to the writing samples of future authors during the training step which is not always realistic. Actually, this structure is static and is not compatible with new future unseen authors. Recently, the structure of AV problem has changed and became more challenging. Based on the new structure, we are given some document pairs with their binary authorship status. The sameauthorship status indicates that both are written by one author while the dierentauthorship status shows the pairs are written by two individual authors. Based on this binary structure the goal is no longer to learn the writing style of each underlying authors individually (like in the traditional AV methods) but is to learn the dierence or similarity of the writing styles of the two types of document pairs. In this paper we dene two dierent schemas to study the AV problem. Under the rst schema we address the following challenges: 1 writing samples of available authors are quite limited during the training step as the length of the given text documents is short (a few hundred to a few thousand words) and size of the training set is so small (from 10 to 200 examples). So, it is quite hard to infer the same or dierentauthorship status of given pairs. 2 The test and train documents are from dierent genera and/or topics which makes the learning and prediction process much harder as the word distribution might dier considerably. 3 No writing samples of the future authors is specied to us during the training and we may have seen no samples by the future authors at all. Under the second schema the scale of the training data is larger compared to the rst schema. However, we address the problem of identifying the dierence in documents from identical domains in two ways: 1 authorship diversity insimilar contents by utilizing Amazon reviews from 300 distinct authors. 2 Scientic documents from the same area of research by dierent authors who have almost identical level of expertise in the eld. It also can be considered as an application of plagiarism detection. We analyze authorship verication on several datasets with binary structure. To our knowledge this amount of analysis has not been done in authorship verication on diverse types of datasets. Two models are proposed. First, a Transformation Encoder (TE) to model error feature vectors for classication inspired by the idea of autoencoders. TE is compatible with the AV problems with smallscale training sets. Giving a pair of input documents, TE transforms one input into the other. In this process, the transformation loss is observed as a reasonable measure of closeness of the two inputs to be used by a classier. The second model is a parallel recurrent neural network (PRNN) that is inspired by the popular similarity measures in Statistical Machine Learning (ML). Being based on language models, it is mostly applicable for relatively larger datasets. PRNN compares the proximity of the language model of its two input sequencesto investigate their authorship. We also propose the summary vector to adapt our problem to a common binary classication style to create strong baselines as there are limited studies in authorship verication according to the literature. Applying this adaptation we are able to employ the recognized classiers as well as similarity measures that are widely used in ML to build our baselines. Besides, the two preexisting datasets, Amazon reviews and MPLA400, are mapped to the binary structure to be used for our large scale AV problem. Experimental results on evaluation datasets show that both methods achieve stable and competitive performance compared to the baselines. 2 System Design LetP= (S;T) denotes a pair of documents, indicating Sas the source and T as the target. Here, the task is to investigate whether SandTare written by the same author. We map this problem into a binary classication paradigm. Accordingly, if SandTare authored by the same person, Pbelongs to the positive class. Nevertheless ( SandThave dierent authors) Pbelongs to the negative class. In the rst step, we explain the Transformation Encoder which is a feature extractionbased method designed for the smallscale datasets with 200 labeled samples at most. However, many AV problems might have a larger scale with much more examples. So, we introduce the Parallel Recurrent Neural Network (PRNN) for large scale datasets in the second step. 2.1 Transformation Encoder (TE) TE is inspired by the idea of an autoencoder. A typical autoencoder neural network is a kind of unsupervised learner exploiting backpropagation in order to reconstruct a given input. In other words, it tries to approximate the identity function. Given an unlabeled input x2Rd, the goal is to learn Wandbsuch thatfw;b(x) =x. It is usually a threelayer neural network, with one input, one hidden and one output layer. W2Rdd0is a transformation matrix that encodes addimensional input vector xinto the mostly lower dimension d0. Then, a nonlinear function ssuch as sigmoid will apply to the sum of the transformed vector and a bias bto make the new vector hin the hidden layer. Finally, the outputzwill be decoded by applying the same process on hwithW02Rd0d, usuallyW0=WT, and biasb0. Therefore, the goal is to minimize the loss, also known as reconstruction error. To build the Transformation Encoder (Figure 1) we add a new input to the structure of autoencoder and modify its reconstruction process. So, TE has two inputs known as source and target. Let xs2Rdbe the rst andxt2Rdbe the second input of TE. However, the goal is no longer the reconstruction of one input similar to itself but is to learn a transformation functiongthat reconstructs the source input xssimilar to the target input xt, i.e.,gw;b(xs;xt) =xt. Indeed, only the source ( xs) passes the reconstruction process (encoding and decoding layers). So, the following steps are kept intact according to a typical autoencoder: hs=s(WTxs+b) andzs=s(W0hs+b0)Fig. 1: Transformation Encoder (TE). xs i: feature vector of document iaf ter expansion of the source document S,xT: average feature vector of ex panded target document T. The dotted line emphasizes that the reconstructed source should be similar to the target. Fig. 2: PRNN architecture. The net work takes two input S;T in parallel and fuses them after passing word em bedding and recurrent layers. wherezs2Rdis the reconstructed input and must be transformed into the target (zsxt). This can be done by setting TE's objective function as the minimization of the transformation loss. We set the TE transformation loss Er to be the crossentropy between reconstructed input ( zs) and the target input (xt) as:Er(xt;zs) =","Authorship verification (AV) is a branch of forensic authorship analysis. Traditionally, the problem of AV considered a closed and limited set of authors and a closed set of documents written by those authors. During the training step some of these documents were observed. Then, the problem was to identify whether the authors of a pair of documents from the rest of the document set were identical. However, this structure is static and not compatible with new future unseen authors. In this paper, we propose two different schemas to study the AV problem. We propose two models:",cool!
272,Distill and De-bias: Mitigating Bias in Face Verification using Knowledge Distillation.txt,"Face recognition networks generally demonstrate bias with respect to
sensitive attributes like gender, skintone etc. For gender and skintone, we
observe that the regions of the face that a network attends to vary by the
category of an attribute. This might contribute to bias. Building on this
intuition, we propose a novel distillation-based approach called Distill and
De-bias (D&D) to enforce a network to attend to similar face regions,
irrespective of the attribute category. In D&D, we train a teacher network on
images from one category of an attribute; e.g. light skintone. Then distilling
information from the teacher, we train a student network on images of the
remaining category; e.g., dark skintone. A feature-level distillation loss
constrains the student network to generate teacher-like representations. This
allows the student network to attend to similar face regions for all attribute
categories and enables it to reduce bias. We also propose a second distillation
step on top of D&D, called D&D++. Here, we distill the `un-biasedness' of the
D&D network into a new student network, the D&D++ network, while training this
new network on all attribute categories; e.g., both light and dark skintones.
This helps us train a network that is less biased for an attribute, while
obtaining higher face verification performance than D&D. We show that D&D++
outperforms existing baselines in reducing gender and skintone bias on the
IJB-C dataset, while obtaining higher face verification performance than
existing adversarial de-biasing methods. We evaluate the effectiveness of our
proposed methods on two state-of-the-art face recognition networks: ArcFace and
Crystalface.","The accuracy of face recognition networks [15, 17, 45, 52, 62] has signiﬁcantly improved in the last few years. Be cause of this, such face recognition systems are being used in a large number of applications. This has raised concerns about bias against sensitive attributes such as age, gender or race. A recent study from NIST [27] has shown that charac teristics such as gender and ethnicity impact the veriﬁcation Dissimilarattn. regions [Crystalface]Avg. attention map for dark skintoneAvg. attention mapfor light skintoneSimilarattention regions [D&D++(s)]Avg. attention map for dark skintoneAvg. attention map for light skintone FalsePositiveRate0.8750.9000.9250.9500.9751.000TruePositiveRate104 103102 0.8750.9000.9250.9500.9751.000TruePositiveRate 104103 102Reduced SkintonebiasSkintone bias in IJBC 1:1 Face Verification FalsePositiveRateCrystalface(lightlight pairs)Crystalface(darkdark pairs) D&D++(s) (lightlight pairs)D&D++(s) (darkdark pairs)100 100 Figure 1. (Top row) Face recognition networks attend to different spatial regions in faces, depending on protected attributes (here, shown for skintone attribute). Here, we show the average atten tion maps generated using the pretrained Crystalface network for frontal faces with light and dark skintone. This difference in pro cessing faces with light and dark skintone might contribute to skin tone bias. (Bottom row) Our proposed method D&D++ enforces a network to attend to similar spatial regions for both light and dark skintones, and consequently reduces skintone bias. We report sim ilar ﬁndings with respect to the gender attribute. and matching performance of existing algorithms. Several works [8, 12, 38, 39, 47, 50, 66] have explored the issue of bias against gender, race and skintone in face recognition. A possible approach to mitigate gender or skintone bias would be to retrain a large scale face recognition net work on a dataset which is balanced in terms of these at tributes. However, as shown in [5, 20, 67], training a net work on a balanced dataset does not always lead to unbi ased systems. [20] points out that while we can balance the dataset in terms of gender or skintone, there exists ap pearance variation between demographic subgroups with respect to multiple factors such as pose, illumination etc., which may lead to a biased system. Some works [19, 25] have proposed adversarial strategies to prevent face recogni tion networks from encoding sensitive attributes like gender and race. However, since gender and race are integral to the face identity, removing such attributes from face recogni tion features generally reduces their face veriﬁcation accu racy. Among nonadversarial methods, GAC [26] proposes an adaptive ﬁltering technique to mitigate racial bias. How ever, the effectiveness of GAC applied to other attributesarXiv:2112.09786v3  [cs.CV]  16 Apr 2022(such as gender) is currently unclear. Similar to GAC, we propose nonadversarial techniques to mitigate bias in face recognition. More speciﬁcally, we present two novel knowl edge distillationbased techniques called D&D and D&D++ to incrementally learn different categories of a given sensi tive attribute while signiﬁcantly reducing bias with respect to that attribute. We show that our proposed methods can be used to reduce bias with respect to either gender or skintone, and are therefore likely to generalize for other attributes. Our methods also generalize to different face recognition models. Buolamwini et al. [11] introduced skintone as an alter native to race. It can be difﬁcult to quantify the race cat egory of multiracial faces. Skintone, on the other hand, is more scientiﬁcally deﬁned by the Fitzpatrick scale [24]. Therefore, following previous works [19, 42], we mitigate skintone bias, as opposed to racial bias. In summary, we make the following contributions in our work: 1. We observe that face recognition networks attend to dif ferent regions of the face, depending on the gender or skintone category. We illustrate this observation with GradCAM [60] generated attention maps (Figs. 1,3, Section 5.3.1). These differences in how algorithms pro cess faces from different demographic categories may lead to bias in face recognition. 2. Building on this observation, we propose a method, called Distill and Debias (D&D), that enforces a net work to attend to similar spatial regions in both male and female faces (and in both faces with light and dark skin tones). We show the ability of D&D to reduce gender and skintone bias in two stateoftheart face recognition networks: ArcFace [15] and Crystalface [52]. To the best of our knowledge, we are the ﬁrst to use knowledge dis tillation for designing bias mitigation strategies in face recognition . 3. We propose D&D++ to further improve the face veriﬁca tion performance, while inheriting the ‘unbiasedness’ of D&D. D&D++, while being debiased, achieves higher face veriﬁcation performance than stateoftheart adver sarial debiasing methods on the IJBC [44] dataset. 2. Related Work","Face recognition networks have significantly improved over the last few years. However, this has raised concerns about bias against sensitive attributes such as gender, skintone and age. In this paper, we propose two novel non-adversarial techniques to mitigate bias in face recognition. More specifically, we propose two novel know-edge distillation-based techniques called D&D and D&D++ to incrementally learn different categories of a given sensitive attribute while significantly reducing bias with respect to that attribute. We observe that face recognition networks attend to different regions of the skintone attribute. We show that our methods can be used to",cool!
350,Robust Watermarking of Neural Network with Exponential Weighting.txt,"Deep learning has been achieving top performance in many tasks. Since
training of a deep learning model requires a great deal of cost, we need to
treat neural network models as valuable intellectual properties. One concern in
such a situation is that some malicious user might redistribute the model or
provide a prediction service using the model without permission. One promising
solution is digital watermarking, to embed a mechanism into the model so that
the owner of the model can verify the ownership of the model externally. In
this study, we present a novel attack method against watermark, query
modification, and demonstrate that all of the existing watermark methods are
vulnerable to either of query modification or existing attack method (model
modification). To overcome this vulnerability, we present a novel watermarking
method, exponential weighting. We experimentally show that our watermarking
method achieves high verification performance of watermark even under a
malicious attempt of unauthorized service providers, such as model modification
and query modification, without sacrificing the predictive performance of the
neural network model.","Deep learning has been achieving top performance on many tasks such as object recognition[ 9,16], speech recognition[ 1,8], natural language processing[ 2], and so on. Training of a deep learning model requires a great deal of cost: preparation of a largescale labeled training dataset, a massive amount of computer resources for model training, and human resources spent on parameter tuning and model architecture design. For these reasons, neural network models are treated as valuable intellectual properties. Shortly, neural network models or prediction APIs with using neural network models will be distributed only to licensed model users as a charged software or service. In such a situation, one concern is that some malicious model user who obtains a high performance model might redistribute licensed models illegally or provide a prediction service using the licensed model without permission. Also, some model user might leak the architecture and weight parameters of the licensed model in public unintentionally. To deal with such leakage, we require a method that allows us to verify the ownership of models externally. One promising solution is digital watermarking, to embed a mechanism into the model for external ownership verification. Suppose a service provider obtains a neural network model from a model owner, and the service provider provides a prediction service using the model. Here, the prediction service means that, given a sample (e.g., image) as a query, the service provider returns the result of inference (e.g., recognition result) of the query using the neural network model. When the service provider provides aprediction service without the permission of the model owner, we call such a user an unauthorized service provider . We investigate ownership verification of neural networks using a watermark, which enables the owner of a watermarked model to prove whether or not a service provider provides his prediction service using the watermarked model obtained by the model owner. In this study, we focus on ownership verification in the blackbox setting. In this setting, ownership verification is performed only by interactions between a model owner and an unauthorized service provider throughout the prediction service; the model owner cannot verify the model used by the unauthorized service provider directly. The unauthorized service provider might attempt to invalidate the verification process at verification time so that the illegal use of the model is not revealed to the model owner. The objective of this work is to establish a watermarking method for neural networks that allows the model owner to verify the ownership of the model with high probability in the blackbox setting even when the unauthorized service provider attempts to collapse the verification process in various ways. 1.1 Related Work","Deep learning models are treated as valuable intellectual properties. In the future, licensed models will be distributed only to licensed model users as a charged software or service. In such a situation, one concern is that some malicious model user who obtains a high performance model might redistribute licensed models illegally or provide a prediction service using the licensed model without permission. To deal with such leakage, we require a method that allows us to verify the ownership of models externally. One promising solution is digital watermarking, to embed a mechanism into the model",cool!
515,Analysis and evaluation of Deep Learning based Super-Resolution algorithms to improve performance in Low-Resolution Face Recognition.txt,"Surveillance scenarios are prone to several problems since they usually
involve low-resolution footage, and there is no control of how far the subjects
may be from the camera in the first place. This situation is suitable for the
application of upsampling (super-resolution) algorithms since they may be able
to recover the discriminant properties of the subjects involved. While general
super-resolution approaches were proposed to enhance image quality for
human-level perception, biometrics super-resolution methods seek the best
""computer perception"" version of the image since their focus is on improving
automatic recognition performance. Convolutional neural networks and deep
learning algorithms, in general, have been applied to computer vision tasks and
are now state-of-the-art for several sub-domains, including image
classification, restoration, and super-resolution. However, no work has
evaluated the effects that the latest proposed super-resolution methods may
have upon the accuracy and face verification performance in low-resolution
""in-the-wild"" data. This project aimed at evaluating and adapting different
deep neural network architectures for the task of face super-resolution driven
by face recognition performance in real-world low-resolution images. The
experimental results in a real-world surveillance and attendance datasets
showed that general super-resolution architectures might enhance face
verification performance of deep neural networks trained on high-resolution
faces. Also, since neural networks are function approximators and can be
trained based on specific objective functions, the use of a customized loss
function optimized for feature extraction showed promising results for
recovering discriminant features in low-resolution face images.",1.1 Hypotheses . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17 1.2 Objectives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17 1.3 Thesis Structure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18 2 Technical Background . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19 2.1 Convolutional Neural Networks and Deep Learning . . . . . . . . . . . . . . . 19 2.1.1 Residual Networks . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20 2.1.2 Generative Adversarial Networks . . . . . . . . . . . . . . . . . . . . . 22 2.1.3 Coordinate Convolutions . . . . . . . . . . . . . . . . . . . . . . . . . 23 2.2 SuperResolution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24 2.2.1 Operating Channels . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25 2.2.2 SuperResolution Benchmarking . . . . . . . . . . . . . . . . . . . . . 26 2.2.3 Deep Learning for Image SuperResolution . . . . . . . . . . . . . . . 27 2.3 Face Recognition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28 2.3.1 Face Detection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28 2.3.2 Feature Extraction and Face Veriﬁcation . . . . . . . . . . . . . . . . . 29 2.4 Final Considerations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30 3 Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31,"SuperResolution is a new paradigm in image processing that aims to improve the accuracy of face recognition. It is a powerful tool for image classification and image processing, and it is a powerful tool for image super-resolution. It is a powerful tool for image super-resolution, and it is a powerful tool for image super-resolution.",cool!