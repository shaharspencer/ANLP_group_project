Unnamed: 0,titles,abstract,introduction
204,Cortex Neural Network: learning with Neural Network groups.txt,"Neural Network has been successfully applied to many real-world problems,
such as image recognition and machine translation. However, for the current
architecture of neural networks, it is hard to perform complex cognitive tasks,
for example, to process the image and audio inputs together. Cortex, as an
important architecture in the brain, is important for animals to perform the
complex cognitive task. We view the architecture of Cortex in the brain as a
missing part in the design of the current artificial neural network. In this
paper, we purpose Cortex Neural Network (CrtxNN). The Cortex Neural Network is
an upper architecture of neural networks which motivated from cerebral cortex
in the brain to handle different tasks in the same learning system. It is able
to identify different tasks and solve them with different methods. In our
implementation, the Cortex Neural Network is able to process different
cognitive tasks and perform reflection to get a higher accuracy. We provide a
series of experiments to examine the capability of the cortex architecture on
traditional neural networks. Our experiments proved its ability on the Cortex
Neural Network can reach accuracy by 98.32% on MNIST and 62% on CIFAR10 at the
same time, which can promisingly reduce the loss by 40%.","Researchers have been focused a lot on neural networks. In recent years, a series of neural networks have been introduced. Many of the neural networks can reach a satisfying performance in simple cognitive tasks [1]. Examples would be the convolutional neural network in the Ô¨Åeld of image object recognition, recurrent neural network in speech recognition, and LSTM in machine translation. However, currently, it is still difÔ¨Åcult for a neural network to solve complex cognitive tasks [2, 10]. A complex cognitive task describes a more difÔ¨Åcult task which requires cognitive process compared to a simple cognitive task. In this paper, it includes multicognitive task processing and learning with reÔ¨Çection. Firstly, multicognitive task processing is nearly impossible. Using a single deep neural network to process image, audio and video together might lead a miserable performance and require a large amount of training data. In the current research, the Multitask learning mainly focused on an approach to inductive transfer that improves learning for one task by using the information contained in the training signals of other related tasks [13], like transfer learning. Also, in a learning process, based on the current architecture, we miss the part of reÔ¨Çection. Human will perform a reÔ¨Çection when approaching its limit in performance [11]. The current neural network architecture cannot perform reÔ¨Çection. For solving the complex cognition tasks, a key is missing here. In the architecture of the brain, biological neural networks are not the only structure that is important for processing of intellectual activities. In the cerebral cortex, the sensory area will recognize different Preprint. Work in progress.arXiv:1804.03313v1  [cs.NE]  10 Apr 2018Figure 1: Schematic representation of cortex in brain[7] inputs based on sensations and then different neural networks located in association cortex will be active to process different tasks (in Figure 1). In fact, the architecture of cortex is necessary for the brain to handle complex cognitive tasks [5, 7]. Since it is necessary for the human brain to let its biological neural network to perform complex cognition task with the architecture of cortex, for the ArtiÔ¨Åcial Neural Network, as a simulated logical architecture of the biological neural network, should also require the architecture of cortex to perform complex cognition tasks [3]. In this paper, we would like to introduce the Cortex Neural Network (CrtxNN). CrtxNN is an architecture that can empower artiÔ¨Åcial neural network to process complex cognitive tasks. It is a system that learns with neural network groups based on the architecture cerebral cortex. We view this as the missing key for ArtiÔ¨Åcial Neural Networks to solve complex cognitive tasks. In our implementation, the CrtxNN is able to solve the complex cognitive tasks: multicognition tasks learning and reÔ¨Çection, in following methods: 1. Multicognition tasks learning and processing . Multicognition task learning and processing is important for a powerful learning system. In our architecture, CrtxNN is possible to learn multiple different cognitive tasks with mixed datasets. The CrtxNN will separate task by different sensations, such as image, audio and video, and train a series of neural networks for different tasks. After the learning phase, it is able to recognize different tasks and to process them with a different solution using the corresponding neural network. 2. ReÔ¨Çection . ReÔ¨Çection is a complex cognitive task and an important learning process [11]. In the CrtxNN, a single neural network will be initially trained for a task, which will be viewed as a general situation processor. Then, a series of neural networks will be trained on exceptional situations which are the parts where the general situation processor has a bad performance. Normally, after training and reÔ¨Çecting, the CrtxNN will be able to perform a strategy decision: to decide which network to be used based on the incoming data. This is able to get a higher performance for a single neural network when a single neural network is approaching its performance limit. We provided a series of experiments. The CrtxNN was built on typical neural networks. We compared the CrtxNN with the typical neural network. We tested the result on two tasks: approximation of twodimensional functions, and mixed image datasets. Our experiment reached a satisfying result. For the approximation of twodimensional function, we reduced the loss at most by 99%. For the mixed image datasets, out model can process MNIST and CIFAR10 at the same time and lower the loss by 40% in average. Our contribution of this paper can be summarized as the following points: 1.Using the architecture of Cortex in the brain as a method for artiÔ¨Åcial neural networks to solve complex cognitive tasks. 2.Purpose the learning theory and algorithm of Cortex Neural Network to provide a solution for multicognitive tasks learning and reÔ¨Çection. 3.Design and conduct experiments to test the feasibility of the architecture and theory. The experiment result showed the positive effect of Cortex Neural Network. 2Figure 2: CrtxNN‚Äôs architecture. 2 Cortex Neural Network Architecture 2.1 Model Architecture Our design of CrtxNN is learned from the architecture of Cortex in the human brain. The cerebral cortex is very important for brain to perform complexcognitive process, such as perception, attention, cognition and so on [7]. When a human is performing a cognitive task, the brain is using the corresponding neural network which locates in the association cortex areas to process the tasks [8].The cortex is divided into different functional areas for modular functionality [7]. Basically, the cortex is combined by different neural networks located in association areas that are speciÔ¨Åed on different tasks. For example, the visual cortex is active when looking at a cat but when the brain tries to understand a stop sign, both the language and visual association area will be active to process the image and understand the sign. There is three important structure in the cerebral cortex that we use in CrtxNN. Sensory area, or the primary somatosensory cortex. For human beings, at the primary somatosensory cortex, the perception areas are orderly arranged from the toe to mouth. [14] Association area. They enable us to interact differently to the world, and support logical thinking, understanding and language. The association areas are combined by distributed networks in cortex. [8] Biological neural network. The artiÔ¨Åcial neural network was designed based on the biological neural network. In the CrtxNN, we are trying to model the Cortex in the human brain to allow complex cognition tasks to be performed by ArtiÔ¨Åcial Neural Networks. As it is shown in Figure 2, we extracted several important structures for our implementation. Sensory cortex receives all sensory input from the body and sends information to responding network to handle the signal. 2.2 Model Description Sensory cortex This is the sensory phase of CrtxNN which plays the same role as the Primary somatosensory cortex. The sensory cortex is designed to classify the data by senses. It is a simulation of the way that human brain is used to separate tasks by different sensory organs, such as vision, hearing and smell. In our case, we classify the data by its shape of input and output tensor to represent different senses [future work]. The sensory cortex will initialize a new task classiÔ¨Åer during the learning process and will assign data to the corresponding task classiÔ¨Åer during the predicting process. The input Set S=x1;x2;x3;:::;xn, the sensory cortex can produce a series of set X1;X2;:::;Xn which8m;8a;b2Xm;shape (xa) =shape (xb), andX1[X2[:::[Xn=S. The sets X1;X2;:::;Xnwill be separately trained by a series of base neural networks. 3Association cortex area The association cortex area contains a set of base neural networks and task classiÔ¨Åers(see Figure 3). It is the place to process the task based on recognized types. It is used to learn different tasks, reÔ¨Çect to get better performance and, Ô¨Ånally, predict the input data using the series of base neural networks. The learning and reÔ¨Çection algorithm will be discussed in the next part. Task classiÔ¨Åer There will be a new Task ClassiÔ¨Åer when the Sensory Cortex Ô¨Ånd a data with different dimension appears. A task classiÔ¨Åer represents a metatask in CrtxNN. After reÔ¨Çection, it is used for the Cortex to decide which is the best network to use when predicting the label of the input data. The core of the task classiÔ¨Åer is a decision tree. The input Set X=fx1;x2;x3;:::;xng, output Set Y=fy1;y2;y3;:::;yng. The output set Yis deÔ¨Åned by reÔ¨Çection, it is labeled by the id of the corresponding neural network. The decision tree is using a number as a threshold for splitting the data into different clusters. The method that we are using for evaluating the performance of a expand is Gran Ratio. The Gran Ratio is deÔ¨Åned by the entropy of the split data and the entropy of the clusters. The entropy of a discrete set can be descried as: H(P) ="
234,Minimal Multi-Layer Modifications of Deep Neural Networks.txt,"Deep neural networks (DNNs) have become increasingly popular in recent years.
However, despite their many successes, DNNs may also err and produce incorrect
and potentially fatal outputs in safety-critical settings, such as autonomous
driving, medical diagnosis, and airborne collision avoidance systems. Much work
has been put into detecting such erroneous behavior in DNNs, e.g., via testing
or verification, but removing these errors after their detection has received
lesser attention. We present here a new tool, called 3M-DNN, for repairing a
given DNN, which is known to err on some set of inputs. The novel repair
procedure implemented in 3M-DNN computes a modification to the network's
weights that corrects its behavior, and attempts to minimize this change via a
sequence of calls to a backend, black-box DNN verification engine. To the best
of our knowledge, our method is the first one that allows repairing the network
by simultaneously modifying multiple layers. This is achieved by splitting the
network into sub-networks, and applying a single-layer repairing technique to
each component. We evaluated 3M-DNN tool on an extensive set of benchmarks,
obtaining promising results.","The popularity of deep neural networks (DNNs ) [19] has increased signicantly over the past few years. DNNs are machinelearned artifacts, trained using a nite training set of examples; and they are capable of correctly handling previouslyunseen inputs. DNNs have shown great success in many application domains, such as image recognition [8, 36], audio transcription [46], language translation [48], and even in safetycritical domains such as medical diagno sis [35], autonomous driving [4], and airborne collision avoidance [25]. Despite their evident success, DNNs can sometimes contain bugs. This has been demonstrated repeatedly: in one famous example, Goodfellow et al. [20] showed that slight perturbations to a DNN's input could lead to misclassication | a phenomenon now known as susceptibility to adversarial perturbations . In another case, Liu et al. [41] showed how DNNs are vulnerable to Trojan attacks. These issues, and others, combined with the increasing integration of DNNs into safetycritical systems, have created a surge of interest in establishing their correctness. A great deal of eort has been put into developing methods for testing DNNs [52], and, more recently, also into verifying them [12,31,55]. ThesearXiv:2110.09929v2  [cs.LG]  20 Oct 2021verication methods could play a signicant role in the future certication of DNNbased systems. Here, we deal with the case where we already know that a given DNN is malfunctioning; specically, we assume we have a nite set of concrete inputs which are handled erroneously (discovered by testing, verication, or any other method). In this situation, we would like to modify the network, so that it produces correct predictions for these inputs. A na ve approach for accomplishing this is to add these faulty inputs to the training set used to create the DNN, and then retrain it, but this is often too computationally expensive [22]. Also, retraining may change the network signicantly, potentially introducing new bugs on inputs that were previously correctly handled. Finally, retraining might be impossible when the original training set is inaccessible, e.g., due to its privacy or sensitivity [25]. Instead, we advocate an approach that requires no retraining, and which has recently gained some attention [9, 40, 54, 57]: we present a new tool, called 3MDNN (Minimal, Multilayer Modications for DNNs ), which can directly nd a modication to the network and correct the erroneous behavior. In this context, a modication means changing the networks weights | the set of real values that determine the DNN's output, and which are initially selected during training. Further, because we assume the original network is mostly correct, we seek to nd a modication which is also minimal . The motivation is that such a change would maintain as much as possible of the network's behavior on other inputs. In other words, our goal is to improve the DNN's overall accuracy | the percentage of correctly handled inputs, which is normally measured with respect to a test set of examples | by improving its handling of problematic inputs, and without harming its handling of other inputs. A DNN is, by denition, a layered artifact; and to the best of our knowledge, all previous work on nding minimal modications to a DNN's weights focused on changing the weights of a single layer [9, 18, 54]. Intuitively, and as we later demonstrate, this signicant restriction could prevent one from nding poten tially smaller (and thus preferable) changes to the network. In 3MDNN , we seek to lift this restriction by proposing and implementing a novel method for themultilayer modication of a DNN, with the goal of nding smaller modi cations than could be otherwise possible. The key idea of our approach is to split the network into multiple subnetworks along certain layers, which we refer to as separation layers ; and then attempt to nd a minimal change for each of these subnetworks separately, in a way that brings about the desired overall change to the network. More concretely, 3MDNN is comprised of two logical levels. In the top, search level , the tool conducts a heuristic search through possible changes to the values computed by the separation layers. Each possible change to these values that we consider, translates into a possible x to the DNN; it naturally gives rise to a sequence of problems on the bottom, singlelayer modication level , each involving a single subnetwork. Solving these singlelayer modication problems can be performed using existing techniques; and the changes discovered to the subnetworks modify the values of the separation layers as selected by the toplevel. Thus, the process as a whole allows 3MDNN to reduce the problem of multilayer changes into a sequence of singlelayer change problems, which can be dispatched using existing DNN modication tools as backends. In its search for a minimal change, 3MDNN alternates between the two levels: each time the toplevel examines a potential change to the separation layers, and invokes the lower level in order to compute the overall cost of using that change (by combining the costs of changing each individual subnetwork). The toplevel always maintains the minimal change it has encountered so far, and uses search heuristics in order to nd new, better options. The search space is innite, and so our tool is anytime | it is designed to be run with a timeout, and whenever it is stopped, it returns the best (smallest) change discovered so far. The search heuristic used by the toplevel can have a crucial impact on per formance. The approach implemented in 3MDNN is general, in the sense that any search heuristic can be plugged in; and here, we consider and implement three such heuristics. The rst is a random search, in which the top level ran domly explores possible changes; this heuristic serves as a baseline. The second is a greedy search heuristic, in which the search always progresses in the di rection that produces the most immediate gain. The third heuristic is a Monte Carlo Tree Search (MCTS) approach [5], which attempts to balance between exploration of the search space and the explorations of regions already known to produce good solutions. The3MDNN tool will be made publicly available with the nal version of this paper. It is designed in a modular fashion, so that additional search heuristics can be plugged in; it currently uses the Marabou DNN verication tool [31, 56] as a backend, although other tools could be used as well. We used 3MDNN to compare the dierent aforementioned heuristic strategies, and to compare our method to a singlelayer modication method, with respect to the accuracy and minimal change size found. In our experiments, 3MDNN achieved favorable results when compared to singlelayer modication techniques. The greedy and MCTS heuristics both performed better than the random one; and while the greedy approach generally outperformed MCTS, there were cases where the latter proved superior. Finally, we also used 3MDNN to nd threelayers modication to a network, as a proofofconcept that demonstrates its ability to modify any number of layers simultaneously. The rest of this paper is organized as follows. In Section 2 we provide the necessary background on DNNs and repairing DNNs with minimal modications. In Section 3 we describe 3MDNN 's algorithm for multilayer modication in greater detail, and explain its dierent strategies for the heuristic search. Then, in Section 4 we provide additional technical details on our implementation of 3MDNN . We describe our experiments and results in Section 5. In Section 6 we review relevant related work, and nally in Section 7 we conclude and describe our plans for future work.2 Background Deep Neural Networks. A deep neural network (a model) Nis comprised of nlayers,L1;:::;Ln. Each layer Liis comprised of sinodes, also called neurons . The rst layer, L1, is the input layer , and is used to provide the network with an input vector v12Rs1. The network is then evaluated by iteratively computing the assignment viof layerLifori= 2;:::;n , each time using the assignment vi"
182,An Experimental Evaluation of Covariates Effects on Unconstrained Face Verification.txt,"Covariates are factors that have a debilitating influence on face
verification performance. In this paper, we comprehensively study two covariate
related problems for unconstrained face verification: first, how covariates
affect the performance of deep neural networks on the large-scale unconstrained
face verification problem; second, how to utilize covariates to improve
verification performance. To study the first problem, we implement five
state-of-the-art deep convolutional networks (DCNNs) for face verification and
evaluate them on three challenging covariates datasets. In total, seven
covariates are considered: pose (yaw and roll), age, facial hair, gender,
indoor/outdoor, occlusion (nose and mouth visibility, eyes visibility, and
forehead visibility), and skin tone. These covariates cover both intrinsic
subject-specific characteristics and extrinsic factors of faces. Some of the
results confirm and extend the findings of previous studies, others are new
findings that were rarely mentioned previously or did not show consistent
trends. For the second problem, we demonstrate that with the assistance of
gender information, the quality of a pre-curated noisy large-scale face dataset
for face recognition can be further improved. After retraining the face
recognition model using the curated data, performance improvement is observed
at low False Acceptance Rates (FARs) (FAR=$10^{-5}$, $10^{-6}$, $10^{-7}$).","FACE VeriÔ¨Åcation has been receiving consistent attention in computer vision community for over two decades [52]. The task of face veriÔ¨Åcation is to verify whether a given pair of face images/templates belongs to the same subject. Recently, due to the rapid development of deep convolutional neural networks (DCNNs), face veriÔ¨Åcation performance has surpassed human performance in most controlled situations and some unconstrained cases [10], [42], [46], [49]. Although deep features have proven to be more robust to moderate variations in pose, aging, occlusion and other factors than handcrafted features, some recent works have noticed that face veriÔ¨Åcation performance is still signiÔ¨Åcantly affected by many covariates [12], [35], [39], [47]. Covariates are factors that usually have an undesirable in Ô¨Çuence on face veriÔ¨Åcation performance (e.g., gender induces different human facial appearance characteristics in nature.). Some covariates represent different aspects of faces such as pose, ex pression and age, while some other covariates represent subject speciÔ¨Åc intrinsic characteristics like gender, race and skin tone, and other covariates reÔ¨Çect extrinsic factors in images, such as illuminations, occlusion and resolution. Analyzing the effects of these covariates can not only help understand fundamental problems in face veriÔ¨Åcation, but also provide insights to improve existing face veriÔ¨Åcation algorithms. Previous studies have analyzed many covariates effects on face recognition performance [1], [7], [30], [34]. However, most B. Lu is with the Department of Electrical and Computer Engineering, Univer sity of Maryland, College Park, 20742, USA (email: bylu@umiacs.umd.edu) J. Chen is with the Center for Automation Research, University of Maryland, College Park, 20742, USA (email: pullpull@cs.umd.edu) C. D. Castillio is with the Center for Automation Research, University of Maryland, College Park, 20742, USA (email: carlos@umiacs.umd.edu) R. Chellappa is with the Department of Electrical and Computer Engineering and the Center for Automation Research, University of Maryland, College Park, 20742, USA (email: rama@umiacs.umd.edu)of them are outdated, and there are several reasons why a new study on these covariates is needed. First, most studies have been conducted before the emergence of deep networks. Since deep networks have signiÔ¨Åcantly improved the robustness of features against many covariates, it is unclear whether the results of covariate effects concluded from handcrafted features are still valid when deep features are used. Second, most datasets studied in previous works are small (e.g., 41,368 images from 68 people in CMU PIE [44] dataset.) and the class distribution of some co variates is severely imbalanced. In this situation, some conclusions may become statistically biased. Moreover, due to the absence of large data, very few experiments have studied covariate effects at extremely low FARs ( 10"
269,Robotic and Generative Adversarial Attacks in Offline Writer-independent Signature Verification.txt,"This study explores how robots and generative approaches can be used to mount
successful false-acceptance adversarial attacks on signature verification
systems. Initially, a convolutional neural network topology and data
augmentation strategy are explored and tuned, producing an 87.12% accurate
model for the verification of 2,640 human signatures. Two robots are then
tasked with forging 50 signatures, where 25 are used for the verification
attack, and the remaining 25 are used for tuning of the model to defend against
them. Adversarial attacks on the system show that there exists an information
security risk; the Line-us robotic arm can fool the system 24% of the time and
the iDraw 2.0 robot 32% of the time. A conditional GAN finds similar success,
with around 30% forged signatures misclassified as genuine. Following fine-tune
transfer learning of robotic and generative data, adversarial attacks are
reduced below the model threshold by both robots and the GAN. It is observed
that tuning the model reduces the risk of attack by robots to 8% and 12%, and
that conditional generative adversarial attacks can be reduced to 4% when 25
images are presented and 5% when 1000 images are presented.","To forge a signature with the aim of deceiving is a serious crime throughout the world [1, 2] with Ô¨Ånancial implications and risks to personal identity. There are countless examples of signature forgery and the issues it causes such as fake historical documents fraudulently signed with Abraham Lincoln‚Äôs signature [3], the forgery and subsequent sale of celebrity signatures [4], as well as the forging and cashing of cheques [5]. To have a signature veriÔ¨Åed by a human expert is an expensive endeavour, and is thus oftentimes another step in the process which bares even further Ô¨Ånancial implications for an individual or a business. In the UK alone, cheque fraud resulted in losses of ¬£12.3 million in 2020 following ¬£53.6 million losses in 2019 [6]. The COVID19 lockdown introduced a level of fraud that had not been seen for several years. In this study, losses of ¬£558.8 million were also shown to be prevented from cheque fraud in 2019. According to the American Bankers Association, cheque fraud amounted to $15.1 billion in 2018 and affected around half a million individuals [7]. Modern computing proposes several solutions to the detection of forged signatures through autonomous veriÔ¨Åcation as an added layer of protection against such attempts. Much stateoftheart work in signature veriÔ¨Åcation is to detect when a human being has forged another‚Äôs signature. Given the rapid growth of consumer robotics due to their ease of use and low cost, the level of detail now possible via robotic signature forgery is a growing concern. Rapid analysis https://jordanjamesbird.com/arXiv:2204.07246v1  [cs.RO]  14 Apr 2022Robotic and Generative Adversarial Attacks in Signature VeriÔ¨Åcation A P REPRINT and nearperfect replication of a signature is now possible by machines that cost a fraction of the price of the average smartphone. In terms of generative approaches, it is possible to train models such as GANs on home computers; that is, with hardware already found in the home, signature veriÔ¨Åcation systems can be succesfully attacked and fooled by data generated by a neural network. In this study, we explore how robots and generative adversarial methods can be used to fool ofÔ¨Çine writerindependent signature veriÔ¨Åcation systems. Following this, efforts are made to tune and improve such systems to provide a preliminary line of defence against such adversarial attacks. The multiple scientiÔ¨Åc contributions presented by this work are as follows: (i) tuning of a visionbased system inspired by the current StateoftheArt for accurate signature veriÔ¨Åcation. (ii) a pipeline to analyse signatures (raster images), produce vectors, and then Gcode for execution of two penholding robotic arms (Lineus and iDraw 2.0). (iii) a Conditional Generative Adversarial Network to discern and generate real and forged signatures. (iv) Successful adversarial attacks on the veriÔ¨Åcation system by both robots and generative approaches. (v) Successful defence of the veriÔ¨Åcation system by Ô¨Ånetune transfer learning from examples produced during adversarial attack. To the author‚Äôs knowledge, this article proposes the Ô¨Årst case of an attack on a signature veriÔ¨Åcation system by using robots to physically copy and write signatures. The remainder of this article is as follows: Section 2 reviews the background of the Ô¨Åeld, including the state of the art in signature veriÔ¨Åcation and adversarial attacks. Following this, Section 3 outlines the method followed by the experiments in this work, and the results are presented and discussed in Section 3. Finally, concluding remarks and future work are discussed in Section 5. 2 Background This section explores the current state of the art related to this work. This includes biometrics, signature veriÔ¨Åcation with visual and deep learning approaches, and methods of attacking veriÔ¨Åcation methods. Biometrics are systems that recognise an individual based on a given input. For example, recognition of an individual based on their Ô¨Ångerprint [8], speech patterns [9, 10], EEG [11] and ECG [12] signals, or the iris of their eye [13] to name a few. Signature veriÔ¨Åcation is a biometric for the recognition and veriÔ¨Åcation of an individual based on the way that they sign their name [14]. Given the ability that a genuine signature has, successful forgeries can therefore have major implications related to personal identity and Ô¨Ånances. Online signature veriÔ¨Åcation deals with smart devices, such as tablets and pens, that record the resultant signature along with features such as pressure, azimuth, velocity, and inclination [15]. OfÔ¨Çine signature veriÔ¨Åcation is based on the resultant signature alone, and is more common given that signed paper documents are often signed. Earlier works such as Kalera et al. [16] proposed methods such as distance metrics between examples of real and forged signatures. The identiÔ¨Åcation of two data sets was found to reach an accuracy of around 93%, while veriÔ¨Åcation was possible for around 78% of the data objects in one dataset and around 68% in the second set. In [17], the authors proposed a machine learning approach for leastsquares support vector machines with respect to the greylevel features observed. Consideration of grey levels within pixel values provides pseudoonline insight into pen velocity and pressure. Such features are noted to be important given that a human will sign their own signature quickly, while a forgery is oftentimes more thoughtout and therefore takes longer to replicate. Stateoftheart research on signature veriÔ¨Åcation relies largely on deep learningbased approaches. In 2019, Sam et al. [18] proposed an ofÔ¨Çine veriÔ¨Åcation technique with the Inceptionv3 Convolutional Neural Network (CNN) that achieved 88% validation accuracy on 170 images after training on 370 signatures. A similar approach was explored in [19], with a CNN model achieving 62.5% writerindependent and 75% writerdependent signature veriÔ¨Åcation. In this study, the writerindependent dataset contained 300 images for training and 240 for validation, and the writerdependent dataset contained 30 images for training and 24 for validation. In 2018, Souza et al. [20] proposed a feature extraction technique with a CNN prior to classiÔ¨Åcation by Support Vector Machines; achieving an equal error rate of 1.48% on the Brazilian PUCPR dataset. Given that there is a growing reliance on automated systems for veriÔ¨Åcation, therein lies the risk of attack. An adversarial attack is a method of fooling a machine learning model by engineering input data to force a chosen output prediction. In signature veriÔ¨Åcation, a successful attack would allow for an individual to pass another‚Äôs signature without their participation or knowledge. Work by the Autonomous University of Madrid‚Äôs Biometric Recognition Group showed that a Bayesian hillclimbing attack could overcome a signature veriÔ¨Åcation system 95% of the time [21]. Similarly, Li et al. [22] proposed generating invisible perturbations on signatures which led to a veriÔ¨Åcation system being succesfully attacked in 92.1% of cases. In [23] the authors proposed to generate synthetic signatures by spectral analysis of trajectory functions, presenting results of up to 0.04% bruteforce attack successes. Scheidat et al. [24] proposed a strategy of distancelevel fusion to overcome bruteforce attacks on veriÔ¨Åcation systems, noting a lower error rate when 2Robotic and Generative Adversarial Attacks in Signature VeriÔ¨Åcation A P REPRINT Real signature   (Raster image)Centerline T race  (Vector image)Convert to G Code   (Robot Actions) Physical signature for gery RS274 Figure 1: The general approach for robotic signature forgery. The raster image is converted to a centerline vector, which is then in turn converted to GCode. The robots then execute the code and physically forge the given signature with a pen. The outputs of this diagram are the paper signatures scanned and preprocessed. Figure 2: An example of a signature before (left) and after (right) preprocessing. combining online veriÔ¨Åcation experts into a uniÔ¨Åed system. In [25], an attack is described which can implement digital signatures into documents, by embedding PDF and TIFF Ô¨Åles within a Ô¨Åle which goes largely undetected. In another related study, AlonsoFernandez et al. [26] described how forgeries do not only simply attack a system while remaining static, rather, forger skills are improved over time. This is similar to a generative adversarial learning framework, which inspired the added approach to this study alongside the two robots. 3 Method "
144,Training face verification models from generated face identity data.txt,"Machine learning tools are becoming increasingly powerful and widely used.
Unfortunately membership attacks, which seek to uncover information from data
sets used in machine learning, have the potential to limit data sharing. In
this paper we consider an approach to increase the privacy protection of data
sets, as applied to face recognition. Using an auxiliary face recognition
model, we build on the StyleGAN generative adversarial network and feed it with
latent codes combining two distinct sub-codes, one encoding visual identity
factors, and, the other, non-identity factors. By independently varying these
vectors during image generation, we create a synthetic data set of fictitious
face identities. We use this data set to train a face recognition model. The
model performance degrades in comparison to the state-of-the-art of face
verification. When tested with a simple membership attack our model provides
good privacy protection, however the model performance degrades in comparison
to the state-of-the-art of face verification. We find that the addition of a
small amount of private data greatly improves the performance of our model,
which highlights the limitations of using synthetic data to train machine
learning models.","In recent times, the availability and power of large data sets has increased rapidly in a va riety of different communities. With this inÔ¨Çux of data come new challenges. Many data sets include sensitive information, in particular medical, biometric and Ô¨Ånancial data. It is insufÔ¨Åcient to deidentify these data sets, as it has been shown that it is possible to reidentify entries in the data set using comparison with thirdparty data sets [7]. One solution to these privacy problems in the application of training machine learning algorithms is to create a sanitised synthetic data set in place of a real one. As there is no requirement that a data set consists of real samples, the synthetic data set merely needs to have the same statistical properties as its source. ¬© 2021. The copyright of this document resides with its authors. It may be distributed unchanged freely in print or electronic forms.arXiv:2108.00800v1  [cs.CV]  2 Aug 20212 CONWAY, JURIE, SIMON, LECHERVY: TRAINING FROM GENERATED DATA There are then two matters of interest: Ô¨Årstly, how well does the synthetic data set ap proximate the real data set that it replaces, and secondly, how well does the sanitised data set protect the sensitive data of the real data set. The Ô¨Årst question can be evaluated by com paring the performance of an algorithm trained on the synthetic data set with one trained on the underlying real data set. We would like to have both methods to give similar levels of performance, as this would show that for our intended application the two data sets have similar statistical properties. In terms of the second question, it is difÔ¨Åcult to ascertain the level of privacy gained by creating a synthetic data set. If a method is used which employs e"
174,Analysis of Length Normalization in End-to-End Speaker Verification System.txt,"The classical i-vectors and the latest end-to-end deep speaker embeddings are
the two representative categories of utterance-level representations in
automatic speaker verification systems. Traditionally, once i-vectors or deep
speaker embeddings are extracted, we rely on an extra length normalization step
to normalize the representations into unit-length hyperspace before back-end
modeling. In this paper, we explore how the neural network learns
length-normalized deep speaker embeddings in an end-to-end manner. To this end,
we add a length normalization layer followed by a scale layer before the output
layer of the common classification network. We conducted experiments on the
verification task of the Voxceleb1 dataset. The results show that integrating
this simple step in the end-to-end training pipeline significantly boosts the
performance of speaker verification. In the testing stage of our L2-normalized
end-to-end system, a simple inner-product can achieve the state-of-the-art.","Speaker recognition (SR) task can be deÔ¨Åned as an utterance level ‚Äúsequencetoone‚Äù learning problem. It is problem in that we are trying to retrieve information about an entire utterance rather than speciÔ¨Åc word content [1]. Moreover, there is no constraint on the lexicon words thus training utterances and testing segments may have completely different contents [2]. Therefore, given the input speech data, the goal may boil down to transform them into utterancelevel representations, among them the interclass variability is maximized and simultane ously the intraclass variability is minimized [3]. Typically, SR can be categorized as speaker identiÔ¨Åcation (SID) task and speaker veriÔ¨Åcation (SV) task [4]. The former classiÔ¨Åes a speaker to a speciÔ¨Åc identity, while the latter deter mines whether a pair of utterances belongs to the same person. For the openset protocol, speaker identities in the testing set are usually disjoint from the ones in training set, which makes the SV more challenging yet closer to practice. Since it is impossi ble to classify testing utterances to known identities in training set, we need to map speakers to a discriminative feature space. In this scenario, openset SV is essentially a metric learning problem, where the key is to learn discriminative largemargin speaker embeddings. There are generally two categories commonly used to ob tain utterancelevel speaker representations. The Ô¨Årst consists This research was funded in part by the National Natu ral Science Foundation of China (61401524,61773413), Natural Science Foundation of Guangzhou City (201707010363), Science and Technology Development Foundation of Guangdong Province (2017B090901045), National Key Research and Development Program (2016YFC0103905).of series of separated statistical models. The represent is the classical ivector approach [5]. Firstly, framelevel feature se quences are extracted from raw audio signals. Then, selected feature frames in training dataset are grouped together to esti mate a Gaussian Mixture Model (GMM) based universal back ground model (UBM) [6]. SufÔ¨Åcient statistics of each utterance on the UBM is accumulated, and a factor analysis based ivector extractor is trained to project the statistics into a lowrank total variability subspace [5]. The other category relies on a model trained by a down stream procedure through endtoend deep neural network [7, 8, 9, 10]. First, in the same way as the ivector approach, frame level feature sequences are extracted as well. Then an auto matic framelevel feature extractor such as convolution neural network (CNN) [8, 11], timedelay neural network (TDNN) [9] or Long Short Term Memory (LSTM) network [7, 12] is des ignated to get highlevel abstract representation. Afterward, a statistic pooling [9] or encoding layer [13] is built on top to extract the Ô¨Åxeddimensional utterancelevel representation. This utterancelevel representation can be further processed by fullyconnected (FC) layer, and Ô¨Ånally connected with an output layer. All the components in the endtoend pipeline are jointly learned with a uniÔ¨Åed loss function. In classical ivector approach, an extra length normal ization step is necessary to normalize the representations into unitlength hyperspace before backend modeling [14]. When it turns into endtoend system, once we have extracted deep speaker embeddings from theneural network, such as x vector [15], this length normalization step is also required when calculating pairwise scores. In this paper, we explore endtoend SV system where length normalization step is builtin inherently within the deep neural network. Therefore, the neural network can learn speaker embeddings being lengthnormalized in an endtoend manner. 2. Related works "
242,DiffRNN: Differential Verification of Recurrent Neural Networks.txt,"Recurrent neural networks (RNNs) such as Long Short Term Memory (LSTM)
networks have become popular in a variety of applications such as image
processing, data classification, speech recognition, and as controllers in
autonomous systems. In practical settings, there is often a need to deploy such
RNNs on resource-constrained platforms such as mobile phones or embedded
devices. As the memory footprint and energy consumption of such components
become a bottleneck, there is interest in compressing and optimizing such
networks using a range of heuristic techniques. However, these techniques do
not guarantee the safety of the optimized network, e.g., against adversarial
inputs, or equivalence of the optimized and original networks. To address this
problem, we propose DIFFRNN, the first differential verification method for
RNNs to certify the equivalence of two structurally similar neural networks.
Existing work on differential verification for ReLUbased feed-forward neural
networks does not apply to RNNs where nonlinear activation functions such as
Sigmoid and Tanh cannot be avoided. RNNs also pose unique challenges such as
handling sequential inputs, complex feedback structures, and interactions
between the gates and states. In DIFFRNN, we overcome these challenges by
bounding nonlinear activation functions with linear constraints and then
solving constrained optimization problems to compute tight bounding boxes on
nonlinear surfaces in a high-dimensional space. The soundness of these bounding
boxes is then proved using the dReal SMT solver. We demonstrate the practical
efficacy of our technique on a variety of benchmarks and show that DIFFRNN
outperforms state-of-the-art RNN verification tools such as POPQORN.","Deep neural networks, and in particular, recurrent neural networks (RNNs), have been successfully used in a wide range of applications including image classiÔ¨Åcation, speech recognition, and natural language processing. However, their rapid growth in safetycritical applications such as autonomous driving [1] and aircraft collision avoidance [2] is accompanied by safety concerns [3]. For example, neural networks are known to be vulnerable to adversarial inputs [4, 5], which are security exploits designed to fool the neural networks [6‚Äì9]. In addition, trained neural networks typically go through changes before deployment, thus raising concerns that the changes may introduce new behaviors. SpeciÔ¨Åcally, since neural networks are computationally and memory intense, they are difÔ¨Åcult to deploy on resourceconstrained devices [10, 11]. Network compression techniques (such as edge pruning, weight quantization, and neuron removal) are often needed to reduce the network‚Äôs size [11]. Compression techniques typically use meansquared error over sampled inputs as a performance measure to test equivalence. Such a measure is statistical, and does not provide formal worstcase guarantees on the deviation between behaviors of two networks.arXiv:2007.10135v1  [cs.LG]  20 Jul 2020APREPRINT  JULY 21, 2020 Figure 1: The differential veriÔ¨Åcation Ô¨Çow of DIFFRNN .is the difference interval, and is the bound on the output differences of the compressed and original networks. While there are recent efforts on applying differential testing [12 ‚Äì14] and fuzzing [15 ‚Äì17] techniques to neural networks, they can only increase the conÔ¨Ådence that the networks behave as expected for some of the inputs. However, they cannot prove the equivalence of the networks for all inputs. To the best of our knowledge, RELUDIFF[18] is the only tool that aims to prove the equivalence of two neural networks for all inputs. RELUDIFFtakes as input two feedforward neural networks with piecewise linear activation functions known as rectiÔ¨Åed linear units ( ReLU ). The ReLU activation essentially allows the neural network to be treated as a piecewise linear (PWL) function (with possibly many facets/pieces). RELUDIFFexploits the PWL nature of activations, and hence cannot natively handle nonPWL activation functions like Sigmoid ,Tanh , and ELU , let alone the more complex operations of LSTMs, which take the product of these nonlinear functions, e.g. SigmodTanh . This poses signiÔ¨Åcant limitations because popular libraries ‚Äúhardcode‚Äù Tanh andSigmoid for some, or all of the activation functions in the network. For example, Fig. 3 shows the LSTM structure hardcoded into TensorÔ¨Çow. Thus, for RNNs, we need a technique that can handle these challenging and arbitrary nonlinearities. In addition, we face several other unique challenges when considering RNNs, including how to soundly and efÔ¨Åciently handle (1) sequential inputs, (2) the complex feedback structures, and (3) interactions between the gates and states. To overcome these challenges, we propose DIFFRNN , the Ô¨Årst differential veriÔ¨Åcation technique for bounding the difference of two structurally similar RNNs. Formally, given two RNNs that only differ in numerical values of their edge weights, denoted y=f(x)andy0=f0(x), where x2Xis an input,Xis an input region of interest, and y;y0 are the outputs, D IFFRNN aims to prove that 8x2X :jf0(x)"
480,Branch and Bound for Piecewise Linear Neural Network Verification.txt,"The success of Deep Learning and its potential use in many safety-critical
applications has motivated research on formal verification of Neural Network
(NN) models. In this context, verification involves proving or disproving that
an NN model satisfies certain input-output properties. Despite the reputation
of learned NN models as black boxes, and the theoretical hardness of proving
useful properties about them, researchers have been successful in verifying
some classes of models by exploiting their piecewise linear structure and
taking insights from formal methods such as Satisifiability Modulo Theory.
However, these methods are still far from scaling to realistic neural networks.
To facilitate progress on this crucial area, we exploit the Mixed Integer
Linear Programming (MIP) formulation of verification to propose a family of
algorithms based on Branch-and-Bound (BaB). We show that our family contains
previous verification methods as special cases. With the help of the BaB
framework, we make three key contributions. Firstly, we identify new methods
that combine the strengths of multiple existing approaches, accomplishing
significant performance improvements over previous state of the art. Secondly,
we introduce an effective branching strategy on ReLU non-linearities. This
branching strategy allows us to efficiently and successfully deal with high
input dimensional problems with convolutional network architecture, on which
previous methods fail frequently. Finally, we propose comprehensive test data
sets and benchmarks which includes a collection of previously released
testcases. We use the data sets to conduct a thorough experimental comparison
of existing and new algorithms and to provide an inclusive analysis of the
factors impacting the hardness of verification problems.","Despite their success in a wide variety of applications, Deep neural networks have seen limited adoption in safetycritical settings. The main explanation for this lies in their reputation for being blackboxes whose behaviour cannot be predicted. Current approaches to evaluate trained models mostly rely on testing using heldout data sets. However, as Edsger W. Dijkstra said ‚Äútesting shows the presence, not the absence of bugs‚Äù (Buxton and Randell, 1970). If deep learning models are to be deployed in applications such as autonomous driving cars, we need to be able to verify safetycritical behaviours. To this end, some researchers have tried to use formal methods. To the best of our knowledge, Zakrzewski (2001) was the Ô¨Årst to propose a method to verify simple, one hidden layer neural networks. However, only recently were researchers able to work with nontrivial models by taking advantage of the structure of ReLUbased networks (Cheng et al., 2017b; Katz et al., 2017a). Even then, these works are not scalable to the large networks encountered in most real world problems. This paper advances the Ô¨Åeld of NN veriÔ¨Åcation by making the following key contributions: 1.By taking advantage of the Mixed Integer Linear Programming (MIP) formulation of the problem, we introduce the BranchandBound framework for NN veriÔ¨Åcation. The framework contains state of the art veriÔ¨Åcation methods as special cases. 2.We identify the weakness and strengths of previous veriÔ¨Åcation methods from the aspects of the way bounds are computed, the type of branching that are considered and the strategies guiding the branching. By retaining the strengths and correcting the identiÔ¨Åed Ô¨Çaws, we propose new methods that achieve considerable performance improvements when compared to the previous state of the art. In some cases, a speedup of almost two orders of magnitudes is obtained. SpeciÔ¨Åcally, we develop a new branching strategy that supports branching over ReLU nonlinearities. Previous BaB based veriÔ¨Åcation methods mainly focus on designing heuristics for branching over input domains. These heuristics, although they perform well on smallscale problems, are either computationally expensive for high dimensional input problems or ineÔ¨Äective for problems with convolutional network architecture. Similar issues are faced by the existing ReLU branching strategies. Our designed branching strategy is computationally cheap and explores the underlying network architecture to make a decision. Using on high dimensional input problems with convolutional network architectures, we demonstrate the beneÔ¨Åts of our branching strategy over various veriÔ¨Åcation methods that employ either inputdomain branching or ReLU branching strategies. 3.We introduce comprehensive data sets consisting of trained as well as synthetic networks with fully connected and/or convolutional layers. Convolutional networks are widely used in computer vision tasks and should be an indispensable component for fair and complete evaluations of veriÔ¨Åcation methods. Only recently did convolutional network data start to be included in the evaluation of veriÔ¨Åcation methods. This takes the form of veriÔ¨Åcation properties attempting to prove adversarial robustness on a L1 ball with a Ô¨Åxed perturbed distance . The diÔ¨Éculty level of a veriÔ¨Åcation property is mainly determined by its network size. Our curated convolutional data sets diÔ¨Äer from these data sets and are able to bring new insights by verifying properties on range of  2Branch and Bound for PLNN Verification values on the same network. We make two observations to strengthen our statement. Firstly, the diÔ¨Éculty of a veriÔ¨Åcation property not only relies on the size of the network, but also the value of . Secondly, one bottleneck for BaB based methods is the time required for solving linear programs (LPs), which could increase signiÔ¨Åcantly with the size of the network. Our data sets consist of veriÔ¨Åcation properties with various diÔ¨Éculty levels on relatively small network architecture. This means they allow eÔ¨Äective evaluations of branching heuristics or bounding decisions without suÔ¨Äering from the LP bottleneck. Additionally, we have introduced the synthetic TwinStream data set to facilitate the study of the relationship between bounding and branching strategies. Overall, the extensive test data sets not only allow thorough experimental analyses of existing methods, but also facilitate the understanding of veriÔ¨Åcation problems and encourage the development of new methods. A preliminary version of this work appeared in the proceedings of NeurIPS, 2018. The article signiÔ¨Åcantly diÔ¨Äers from the previous work by (i) improving the clarity of the BaB framework by providing a running toy example; (ii) designing novel branching strategies for the important class of NN with convolutional layers; (ii) introducing new data sets with convolutional networks and synthetic models; and (iv) including new baseline algorithms. Section 2 and 3 specify the problem of veriÔ¨Åcation and present diÔ¨Äerent formulations of veriÔ¨Åcation processes respectively. Section 4 presents the BaB framework, showing that previous methods can be seen as special cases of it. Section 5 builds on the observations in section 4 to highlight possible improvements within the BaB framework. New methods are proposed accordingly. The last two sections conduct detailed experimental studies of veriÔ¨Åcation methods on our comprehensive data sets. SpeciÔ¨Åcally, section 6 discusses the experimental setup and section 7 analyses the results. 2. Problem SpeciÔ¨Åcation We now specify the problem of formal veriÔ¨Åcation of neural networks. Given a network that implements a function ^ xn=f(x0), a bounded input domain Cand a property P, we want to prove x02C;^ xn=f(x0) =)P(^ xn): (1) For example, the property of robustness to adversarial examples in L1norm around a training sample awith labelyawould be encoded by using C,fx0jkx0"
44,Recognizing and Verifying Mathematical Equations using Multiplicative Differential Neural Units.txt,"Automated mathematical reasoning is a challenging problem that requires an
agent to learn algebraic patterns that contain long-range dependencies. Two
particular tasks that test this type of reasoning are (1) mathematical equation
verification, which requires determining whether trigonometric and linear
algebraic statements are valid identities or not, and (2) equation completion,
which entails filling in a blank within an expression to make it true. Solving
these tasks with deep learning requires that the neural model learn how to
manipulate and compose various algebraic symbols, carrying this ability over to
previously unseen expressions. Artificial neural networks, including recurrent
networks and transformers, struggle to generalize on these kinds of difficult
compositional problems, often exhibiting poor extrapolation performance. In
contrast, recursive neural networks (recursive-NNs) are, theoretically, capable
of achieving better extrapolation due to their tree-like design but are
difficult to optimize as the depth of their underlying tree structure
increases. To overcome this issue, we extend recursive-NNs to utilize
multiplicative, higher-order synaptic connections and, furthermore, to learn to
dynamically control and manipulate an external memory. We argue that this key
modification gives the neural system the ability to capture powerful transition
functions for each possible input. We demonstrate the effectiveness of our
proposed higher-order, memory-augmented recursive-NN models on two challenging
mathematical equation tasks, showing improved extrapolation, stable
performance, and faster convergence. Our models achieve a 1.53% average
improvement over current state-of-the-art methods in equation verification and
achieve a 2.22% Top-1 average accuracy and 2.96% Top-5 average accuracy for
equation completion.","Mathematical reasoning is one problem domain that crucially requires understanding the composition between symbols and arithmetic operators. In demonstrating that it has an ‚Äúunderstanding‚Äù of basic mathematical and logical concepts, an agent must solve new equations or resolve expressions that might become increasingly more complex with time. This entails understanding the structure of equations, as well as their underlying grammar, in order to properly and effectively extrapolate to unseen examples. With respect to this kind of reasoning, artiÔ¨Åcial neural networks (ANNs) have been shown to experience great difÔ¨Åculty achieving the robustness, adaptability, and Ô¨Çexibility exhibited by human agents [ 10]. SpeciÔ¨Åcally, for tasks requiring the ability to compose knowledge, where complex expressions or structures are created by learning and manipulating rules that permit combination and usage of atomic elements of knowledge (such as the operations of addition or multiplication), ANNs struggle to work correctly and reliably. Indeed, it is often argued that ANNs are incapable of learning to perform the compositional actions needed to mathematically reason [10]. Nonetheless, in this paper, we argue that the limitations in an ANN‚Äôs ability to learn compositionality is due (at least in part) to several limitations in their current structural design. First, ANNs do not possess the right inductive bias (or prior, in the form of structural constraints) that would allow them to more readily and naturally extract the compostionality in various symbolic languages. Second, standard ANNs, even those that are stateful, e.g., recurrent neural networks (RNNs), lack a proper (interpretable) memory structure that would be allow them to properly handle the arrangements of symbols that compose mathematical expressions of increasing depth (complexity) and length.arXiv:2104.02899v1  [cs.LG]  7 Apr 2021Preprint, Work in Progress Since mathematical equations are derived from contextfree languages related to mathematical identities [ 3], it would make sense to manipulate an external memory when processing equations. For example, a model trained on (p 11y) +x= (1y) +xshould be capable of generally understanding structure that includes equality and inequality. Furthermore, a memory structure would allow a network to better generalize to unseen equations of different depths, since memory can ofÔ¨Çoad some of the memorization that a network typically does using its shortterm synapses for [2]. For instance, a model augmented with external memory should be capable of understanding the following equation (without any need to train it directly on it): y 11(3 + ("
357,Simple Attention Module based Speaker Verification with Iterative noisy label detection.txt,"Recently, the attention mechanism such as squeeze-and-excitation module (SE)
and convolutional block attention module (CBAM) has achieved great success in
deep learning-based speaker verification system. This paper introduces an
alternative effective yet simple one, i.e., simple attention module (SimAM),
for speaker verification. The SimAM module is a plug-and-play module without
extra modal parameters. In addition, we propose a noisy label detection method
to iteratively filter out the data samples with a noisy label from the training
data, considering that a large-scale dataset labeled with human annotation or
other automated processes may contain noisy labels. Data with the noisy label
may over parameterize a deep neural network (DNN) and result in a performance
drop due to the memorization effect of the DNN. Experiments are conducted on
VoxCeleb dataset. The speaker verification model with SimAM achieves the 0.675%
equal error rate (EER) on VoxCeleb1 original test trials. Our proposed
iterative noisy label detection method further reduces the EER to 0.643%.","In the past few years, deep learning has signiÔ¨Åcantly improved the performance of automatic speaker veriÔ¨Åcation (ASV) sys tems. Neural network structures such as timedelay neural network (TDNN) [1, 2], residual convolutional neural net work (ResNet) [3] and Res2Net [4] have been explored and successfully applied to the ASV task. In addition to the im provement of the network structures, the availability of large scale datasets as well as the carefully designed data augmen tation strategies also improve the robustness of the ASV sys tems in many challenging scenarios, e.g., crosschannel [5], Corresponding Author: Ming Li ming.li@whu.edu.cn. This research is funded in part by the National Natural Science Foundation of China (62171207), Tencent AI Lab RhinoBird Gift Fund, Fundamental Research Funds for the Central Universities (2042021kf0039), Key Research and De velopment Program of Jiangsu Province (BE2019054) and Science and Tech nology Program of Guangzhou City (201903010040,202007030011).crosslingual [6, 7], and farÔ¨Åeld setting [8]. In this paper, we further improve the performance of the speaker veriÔ¨Åca tion system with two strategies, i.e., improving the network structures with a new attention module and data cleaning for a potentially noisy dataset. One important improvement of neural network structure is the application of the attention mechanism. Under the branch of convolutional neural networks (CNN), the squeezeand excitation (SE) module [9] employs the channelwise atten tion to capture the taskrelevant features. Convolutional block attention module (CBAM) [10] extends the attention to the spatial dimension. CBAM sequentially infers 1dimensional (1D) and 2dimensional (2D) attention weights for the chan nel and spatial dimensions. Since the spectrogram of a speech signal is a time series, the 2D weights for spatial dimensions may not extract enough temporal information. Recently, SimAM [11] proposes to Ô¨Ånd the importance of each neuron by optimizing an energy function without adding extra modal parameters. The SimAM module generates 3D attentions weights for the feature map in a layer of CNN, which are more suitable for speechrelated tasks. This paper uses the SimAM module in the deep speaker veriÔ¨Åcation framework to achieve better performance. Supervised learning methods usually require data with ac curate annotations. Data with the noisy label may over param eterize a deep neural network (DNN) and lead to performance degradation due to the memorization effect of the DNN. How ever, the problem of data mislabeling is inevitable in the real world scenario, and relabeling can be timeconsuming. To this end, we propose a simple method to iteratively Ô¨Ålter out the noisy label and improve the performance with noisy train ing data. SpeciÔ¨Åcally, we extract the speaker embeddings of all utterances in the same speaker. Cosine similarities of each training utterance are calculated with other segment av erage embeddings of the corresponding speaker. Our pro posed noisy label detection method Ô¨Ålters out audios with av erage cosine similarities below the predeÔ¨Åned threshold. To sum up, our main contributions are: ‚Ä¢ We introduce a 3D attention module that designs an energy function to compute the weight for the ASV sysarXiv:2110.06534v1  [cs.SD]  13 Oct 2021(a) aWtugEAkhtM/00074  (b) aWtugEAkhtM/00076  (c) aWtugEAkhtM/00078  (d) hqE1mX1V99k/000104 Fig. 1 . Visualization of noisy labeled faces. The four face images are all selected from speaker ‚Äòid00244‚Äô. Figure (a), (b), (c) are from the ‚ÄòaWtugEAkhtM‚Äô segment and the (d) is from the ‚ÄòhqE1mX1V99k‚Äô segment. The face identity of (a) is dominant in the selected speaker and is considered as correct identity. Utterances from segment (b), (c) and (d) are with noisy labels. tem. This plugandplay module achieves the stateof theart (SOTA) results in the V oxCeleb test set. ‚Ä¢ We also propose an iterative noisy label detection method to Ô¨Ålter out data with unreliable labels. Com pared to the strong baseline systems, this method has an additional 7% relatively improvement. 2. ATTENTION MODULES In this section, we will introduce the attention modules that have been successfully used in ASV and the SimAM module. 2.1. Related works "
442,Canonical Face Embeddings.txt,"We present evidence that many common convolutional neural networks (CNNs)
trained for face verification learn functions that are nearly equivalent under
rotation. More specifically, we demonstrate that one face verification model's
embeddings (i.e. last-layer activations) can be compared directly to another
model's embeddings after only a rotation or linear transformation, with little
performance penalty. This finding is demonstrated using IJB-C 1:1 verification
across the combinations of ten modern off-the-shelf CNN-based face verification
models which vary in training dataset, CNN architecture, method of angular loss
calculation, or some combination of the 3. These networks achieve a mean true
accept rate of 0.96 at a false accept rate of 0.01. When instead evaluating
embeddings generated from two CNNs, where one CNN's embeddings are mapped with
a linear transformation, the mean true accept rate drops to 0.95 using the same
verification paradigm. Restricting these linear maps to only perform rotation
produces a mean true accept rate of 0.91. These mappings' existence suggests
that a common representation is learned by models despite variation in training
or structure. We discuss the broad implications a result like this has,
including an example regarding face template security.","THElast decade of research into neural networks can be coarsely categorized into efforts toward: 1) advancing the stateoftheart as expressed through accuracy, and 2) better un derstanding and analyzing what networks learn. Efforts toward understanding have been far ranging: from comparisons to human vision [1], [2], to investigations into the quality and content of learned features [3], to detailed breakdowns of what causes networks to fail [4]. Even research areas as distinct as style transfer [5], [6] and transfer learning [7] are all, from a certain vantage, centered around understanding the nature of what CNNs learn and, in turn, how what they learn separates and semantically organizes information. Indeed, such fundamental understanding is crucial in the pursuit of better performing and more predictable machine learning models. Our work here focuses speciÔ¨Åcally on the embeddings gener ated by different CNNs. To avoid confusion based on a number of conÔ¨Çicting deÔ¨Ånitions for neural network ‚Äúembeddings,‚Äù we use the term embedding to refer to the feature vector generated by the pooled output of the Ô¨Ånal, typically convolutional, layer. In closedset classiÔ¨Åcation tasks, these embeddings are typically fed to a Ô¨Ånal linear and fullyconnected classiÔ¨Åcation layer with one output unit for each class label in the dataset. In openset face recognition, these embeddings are typically used in a distance based nearestneighbors approach instead. Face recognition is an excellent domain for measuring if embeddings from different networks are equivalent, i.e. related through a simple linear mapping, in part because it is a do main with strongly established protocols, available data, and an emphasis on direct comparison of embeddings. In particular, the openset veriÔ¨Åcation protocol (i.e. no people in common between training and testing) removes the risk that measured equivalence is a consequence of a common Ô¨Ånal logit layer with Ô¨Åxed labels All authors are with the Department of Computer Science, Colorado State University, Fort Collins, Colorado. Email:fdavid.white, ben.sattelberg, nathaniel.blanchard, ross.beveridgeg@colostate.edu Code to reproduce these Ô¨Åndings will be released upon publication. Manuscript received XXXXXXXX. Fig. 1: CNNbased facial recognition systems produce embedding spaces which are typically used for distancebased face veriÔ¨Å cation. The embedding spaces generated by different networks are outofthebox not directly comparable. However, our work demonstrates the existence of an underlying common geometry such that we are able to compute a linear mapping to recover the embeddings of one network from another. This allows direct meaningful comparison between pairs of embeddings originating from different networks. shared between all networks. Indeed, our prior work [8], [9] has established that networks trained on matching label sets such as ImageNet have linear mappings between embedding spaces which may be computed directly from the Ô¨Ånal layer weights of the two networks. Going further, the nowstandard use of unit normalized features compared by cosine distance [10], [11], [12], [13] provides a clear sense in which network outputs are the same or not. In essence, this allows us to ask questions of the kind ‚ÄòIs this geometric object A the same as object B?‚Äù. For rigid objects, if B is just A rotated, the common answer is they are the same. The work here takes this basic concept of ‚Äúsame‚Äù (or equivalent) and applies it to face embeddings from two CNNs. Using as few as a hundred embedding pairs generated from two nets for the same faces, our approach computes mappings using leastsquares regression in order to align, as much as is possible, the corresponding embedding vectors. These mappings are evaluated by comparing the embeddings of one CNN to thearXiv:2106.07822v3  [cs.CV]  27 Oct 2021IEEE TRANSACTIONS ON BIOMETRICS, BEHAVIOR, AND IDENTITY SCIENCE, VOL. X, NO. X, APRIL 2021 2 mapped embeddings of another using a standard face veriÔ¨Åcation paradigm. Despite differences in training dataset, CNN archi tecture, and angular loss function, crossCNN face veriÔ¨Åcation using these mappings drops very little. These results demonstrate a fundamental underlying near equivalence between the embed ding spaces produced by diverse models. We describe this near equivalence through the lens of a canonical embedding space, i.e. that different models‚Äô embedding sets are sampled from linear transformations of a single underlying embedding space. As we discuss in Section 7, the existence of this canonical embedding space suggests that task is the primary driver in determining the content of learned representations. We want to emphasize that we essentially never see improved veriÔ¨Åcation results using features mapped between networks, nor do we expect such improvement. Our goal is not to build a better algorithm. Instead, when interpreting the results which follow and which take advantage of established standard evaluation protocols, the point is to demonstrate the relatively small drop in recognition performance when mapping between spaces and use this obser vation as very strong evidence for the existence of a common underlying embedding space geometry. Our work complements a growing sense that different archi tectures applied to the same data are converging upon similar solutions. For example, some within the neural architecture search community have shifted their focus from improving the architec ture itself to Ô¨Ånding new data augmentation strategies [14], [15], [16]. Our discovery of an underlying canonical embedding space also strongly suggests that recovery of identities from embeddings is possible, and even arguably easy in some cases: for example using embeddings from the speciÔ¨Åc CNNs studied here. 2 R ELATED WORK "
426,LG4AV: Combining Language Models and Graph Neural Networks for Author Verification.txt,"The automatic verification of document authorships is important in various
settings. Researchers are for example judged and compared by the amount and
impact of their publications and public figures are confronted by their posts
on social media platforms. Therefore, it is important that authorship
information in frequently used web services and platforms is correct. The
question whether a given document is written by a given author is commonly
referred to as authorship verification (AV). While AV is a widely investigated
problem in general, only few works consider settings where the documents are
short and written in a rather uniform style. This makes most approaches
unpractical for online databases and knowledge graphs in the scholarly domain.
Here, authorships of scientific publications have to be verified, often with
just abstracts and titles available. To this point, we present our novel
approach LG4AV which combines language models and graph neural networks for
authorship verification. By directly feeding the available texts in a
pre-trained transformer architecture, our model does not need any hand-crafted
stylometric features that are not meaningful in scenarios where the writing
style is, at least to some extent, standardized. By the incorporation of a
graph neural network structure, our model can benefit from relations between
authors that are meaningful with respect to the verification process. For
example, scientific authors are more likely to write about topics that are
addressed by their co-authors and twitter users tend to post about the same
subjects as people they follow. We experimentally evaluate our model and study
to which extent the inclusion of co-authorships enhances verification decisions
in bibliometric environments.","Evaluation of research strongly depends on bibliometric databases. Today, they are used for the assessment of productivity and im pact of researchers, conferences and affiliations. This implies an increasing importance of search engines and web services that store, present and collect bibliometric data. Because of their rising relevance for the evaluation of the scientific output of individ ual authors, it is crucial that the information which is stored and collected by scholarly search engines, databases and knowledge graphs is complete and accurate. However, with the rapid growth of publication output [ 8], automatic inspections and corrections of information in bibliometric databases is needed. One of the major challenges in this area is authorship verification (AV), which aims to verify if a document is written by a specific author. In general, AV is widely investigated [ 18,29,39]. Available approaches range from the use of handcrafted features which are based on lexical or syntactic patterns [ 22,24,34] to methods that make use of neural networks and language models (LMs) [2, 3]. A majority of existing work handles author verification by cap turing writing styles [ 12,18], assuming that they are unique among different authors. This assumption does not hold in environments where the available texts are short and contain uniform language patterns. An example of this is given by verification tasks for scien tific documents. In such settings, the availability of full texts is rare because bibliometric databases often contain only abstracts and titles. In such scenarios the variety of writing styles and linguistic usage is rather limited. Hence, methods that are solely based on stylometric features are less promising. Additionally, the focus in AV research is on documents with one author, while verification of multiauthor documents is seldom done. In such scenarios, the information about known multiauthorships can enhance the verification process because it provides a graph structure between the authors which is meaningful with respect to the verification process. There are many scenarios where verifica tion decisions can benefit from such graph structures. For example, scientific authors are more likely to write papers that would also fit to their coauthors and twitter users are expected to post about the same topics as the persons they follow. The incorporation of such graph structures is rarely investigated. Most of the current approaches are based on an a setting which breaks the AV problem down to either ‚ÄúAre the documents ùëë1and ùëë2by the same author?‚Äù or ‚ÄúIs the unknown document ùëëfrom thearXiv:2109.01479v1  [cs.LG]  3 Sep 2021XXX, XXX, XXX Maximilian Stubbemann and Gerd Stumme same author as the set of known documents ùê∑?‚Äù. Here,ùê∑is assumed to be of small cardinality. In the PAN@CLEF1tasks on AV, which most approaches are focused on, the set of known documents for each unknown document was never larger then 10elements. Hence, the developed methods are in general not fitted to scenarios where larger sets of known documents are possible. For example, estab lished researches can have hundred publications or more which can reflect a variety of different topics that they have worked on over time. Thus, a large amount of publications of these research can be relevant for the verification of potential papers. This makes approaches unfeasible which need to compare or combine the un known document explicitly with the known documents. Here we step in with LG4AV. Our novel architecture combines language models and graph neural networks (GNNs) to verify whether a document belongs to a potential author. This is done without the explicit recap of the known documents of this author at decision time which can be a bottleneck with respect to the compu tation time. This is especially true for authors with a large amount of known documents. Additionally, LG4AV does not rely on any handcrafted stylometric features. By incorporating a graph neural network structure into our ar chitecture, we use known relations between potential authors to enhance the verification process. In this way, we are able to account for the fact that authors are more likely to turn to topics that are present in their social neighborhood. We experimentally evaluate the ability of our model to make verification decisions in biblio metric environments and we review the influence of the individual components on the quality of the verification decisions. Applica tions of LG4AV to other data sources where texts are connected with graph information, such as for example social networks, are possible. Our contribution is as follows. ‚Ä¢We study authorship verification in a setting where informa tion of known documents is only used at training time. An explicit recap of the known documents to verify authorships of specific authors with new documents is not needed. ‚Ä¢We present LG4AV, a novel network architecture that incor porates language models and graph neural networks. LG4AV does not depend on any stylometric handcrafted features and allows to incorporate meaningful relations between au thors into the verification process. ‚Ä¢We evaluate LG4AV in bibliometric environments and study how the different forms of information and the different parts of the module enhance the verification process. ‚Ä¢We additionally investigate to which extent LG4AV is capable of verifying potential publications of authors that were not seen at training time. LG4AV is available at https://github.com/mstubbemann/LG4AV. 2 RELATED WORK "
52,Designing Neural Speaker Embeddings with Meta Learning.txt,"Neural speaker embeddings trained using classification objectives have
demonstrated state-of-the-art performance in multiple applications. Typically,
such embeddings are trained on an out-of-domain corpus on a single task e.g.,
speaker classification, albeit with a large number of classes (speakers). In
this work, we reformulate embedding training under the meta-learning paradigm.
We redistribute the training corpus as an ensemble of multiple related speaker
classification tasks, and learn a representation that generalizes better to
unseen speakers. First, we develop an open source toolkit to train x-vectors
that is matched in performance with pre-trained Kaldi models for speaker
diarization and speaker verification applications. We find that different
bottleneck layers in the architecture variedly favor different applications.
Next, we use two meta-learning strategies, namely prototypical networks and
relation networks, to improve over the x-vector embeddings. Our best performing
model achieves a relative improvement of 12.37% and 7.11% in speaker error on
the DIHARD II development corpus and the AMI meeting corpus, respectively. We
analyze improvements across different domains in the DIHARD corpus. Notably, on
the challenging child speech domain, we study the relation between child age
and the diarization performance. Further, we show reductions in equal error
rate for speaker verification on the SITW corpus (7.68%) and the VOiCES
challenge corpus (8.78%). We observe that meta-learning particularly offers
benefits in challenging acoustic conditions and recording setups encountered in
these corpora. Our experiments illustrate the applicability of meta-learning as
a generalized learning paradigm for training deep neural speaker embeddings.","Audio speaker embeddings refer to Ô¨Åxeddimensional vector representations extracted from variable duration audio utter ances and assumed to contain information relevant to speaker characteristics. In the last decade, speaker embeddings have emerged as the most common representations used for speaker identity relevant tasks such as speaker diarization (speaker segmentation followed by clustering: who spoke when? ) [1] and speaker veriÔ¨Åcation (does an utterance pair belong to same speaker? ) [2]. Such applications are relevant across a variety of domains such as voice biometrics [3], [4], automated meeting analysis [5], [6], and clinical interaction analysis [7], [8]. Recent technology evaluation challenges [9]‚Äì [12] have drawn attention to these domains by incorporating natural and simulated inthewild speech corpora exemplifying the many diverse technical facets that need to be addressed. M. Kumar, T. J. Park and S. Narayanan are with Signal Analysis and Inter pretation Laboratory, University of Southern California, Los Angeles, USA email: (prabakar@usc.edu;taejinpa@usc.edu;shri@ee.usc.edu). S. Bishop is with Department of Psychiatry, University of California, San Francisco, USA email:(somer.bishop@ucsf.edu)While initial efforts toward training speaker embeddings had focused on generative modeling [13], [14] and factor analysis [15], deep neural network (DNN) representations extracted at bottleneck layers have become the standard choice in recent works. The most widely used representations are trained using a classiÔ¨Åcation loss (dvectors [16], xvectors [17], [18]), while other training objectives such as triplet loss [19], [20] and contrastive loss [21] have also been explored. More recently, endtoend training strategies [22]‚Äì[24] have been proposed for speaker diarization to address the mismatch between train ing objective (classiÔ¨Åcation) and test setup (clustering, speaker selection, etc). A common factor in the classiÔ¨Åcation formulation is that all the speakers from training corpora are used throughout the training process for the purpose of loss computation and minimization. Typically, categorical crossentropy is used as the loss function. While the number of speakers (classes) can often be large in practice ( O(103)), the classiÔ¨Åcation objective represents a single task, i.e., the same speaker set is used to minimize crossentropy at every training minibatch. This entails limited task diversity during the training process and offers scope for training better speakerdiscriminative embeddings by introducing more tasks. We note that a few approaches exist which introduce multiple objectives for em bedding training, such as metriclearning with cross entropy [25], [26] and speaker classiÔ¨Åcation with domain adversarial learning [27], [28]. While these approaches demonstrate im provements over a single training objective, the speaker set is often common across objectives (except in domain adversarial training where target speaker labels are assumed unavailable). In this work we use the classiÔ¨Åcation framework while training neural speaker embeddings, however we decompose the original classiÔ¨Åcation task into multiple tasks wherein each training step optimizes on a new task. A common encoder is learnt over this ensemble of tasks and used for extracting speaker embeddings during inference. At each step of speaker embedding training, we construct a new task by sampling speakers from the training corpus. For a large training speaker set available in typical training corpora, generating speaker subsets results in a large number of tasks. This provides a natural regularization to prevent task overÔ¨Åtting. Our approach is inspired by the metalearning [29] paradigm, also known aslearning to learn . Metalearning optimizes at twolevels: within each task and across a distribution of tasks [30]. This is in contrast to conventional supervised learning which opti mizes a single task over a distribution of samples. In addition to beneÔ¨Åts from increased task variability metalearning hasarXiv:2007.16196v1  [eess.AS]  31 Jul 20202 demonstrated success in unseen classes [30]‚Äì[32]. This forms a natural Ô¨Åt for applications such as speaker diarization and speaker veriÔ¨Åcation which often evaluate on speakers unseen during embedding training. We compare our metalearned models with xvectors, which have established stateoftheart performance in multiple ap plications [17], [18] including recent evaluation challenges such as DIHARD [33] and VOiCES [10]. First, we develop a competitive wideband xvector baseline using the PyTorch toolkit (calibrated with identical performance with the Kaldi V oxceleb recipe1). Next, we use two different metriclearning objectives to metalearn the speaker embeddings: prototypical networks and relation networks. While both approaches share the task sampling strategy during the training phase, they differ in the choice of the comparison metric between samples. We evaluate our approaches on two different applications: speaker diarization and speaker veriÔ¨Åcation to illustrate the generalized speaker discriminability nature of metalearned embeddings. The contributions of this work are as follows: we de velop new speaker embeddings using metalearning that are not restricted to an application. Within each application, we demonstrate improvements using multiple corpora obtained under controlled as well as naturalistic speech interaction settings. Furthermore, we identify conditions where meta learning demonstrates beneÔ¨Åts over conventional crossentropy paradigm. We analyze diarization performance across different domains in the DIHARD corpora. We also consider the special case of impact of child age groups using internal child adult interaction corpora from the Autism domain. We study the effect of data collection setups (nearÔ¨Åeld, farÔ¨Åeld and obstructed microphones) and the level of degradation artifacts on the speaker veriÔ¨Åcation performance. While we present results using prototypical networks and relation networks, the proposed framework is independent of the speciÔ¨Åc metric learning approach and hence offers scope for incorporating nonclassiÔ¨Åcation objectives such as clustering. It should be noted however that the application of relation networks has not been explored in speaker embedding research. Finally, we present an open source implementation of our work, including xvectors baselines, based on a generic machine learning toolkit (PyTorch)2. II. B ACKGROUND A. MetaLearning for Task Generalization Early works on metalearning focused on adaptive learning strategies such as combining gradient descent with evolu tionary algorithms [34], [35], learning gradient updates using a metanetwork [36] and using biologically inspired con straints for gradient descent [37], [38]. Recent metalearning approaches have addressed the issue of rapid generalization in deep learning, by learning to learn for a new task [30]‚Äì[32]. This concept is inspired by the human ability to learn using a handful of examples. For instance children learn to recognize a new animal when presented with a few images as opposed to conventional DNNs which require thousands of samples for a 1https://github.com/kaldiasr/kaldi/tree/master/egs/voxceleb 2https://github.com/manojpamk/pytorch xvectorsnew class. The ability to quickly generalize to unseen classes is achieved by generating diversity in training tasks, for instance by using different sets of classes at each training step (see Fig. 1 in [30]). Further, the classiÔ¨Åcation setup (in terms of number of classes and samples per class) is controlled to match with that of the test task [39]. Metalearning has been successfully applied to achieve task generalization in computer vision [30], [31], [39] and more recently in natural language processing [40]‚Äì[42]. Drawing parallels with the above applications, we train speaker embeddings with a large number of speaker classiÔ¨Åcation tasks to improve over the conventional model which uses a single classiÔ¨Åcation task. Since speaker sets differ between training steps, we replace the conventional softmax nonlinearity and crossentropy loss combination with metric learning objectives used in previous metalearning works [39], [43]‚Äì[45]. B. MetaLearning Speaker Embeddings Few recent approaches have used a variant of metalearning to train speaker embeddings, speciÔ¨Åcally the metriclearning objective from prototypical networks (protonets). In [46], the authors extend angular softmax objective to protonets and compare with various metric learning approaches for speaker veriÔ¨Åcation. Across different architectures, angular prototyp ical loss outperforms other methods including conventional softmax objective. The authors in [47] applied protonets for short utterance speaker recognition and introduced global prototypes that mitigate the need for class sampling. In related applications, [48] and [49] used protonets for small foot print speaker veriÔ¨Åcation and fewshot speaker classiÔ¨Åcation, respectively. In [50], the protonet loss was compared with triplet loss and evaluated on (open and close set) speaker ID and speaker veriÔ¨Åcation tasks. However, previous approaches seldom compare embeddings trained using protonets with existing benchmarks based on xvectors, except for [48] where a modiÔ¨Åed architecture was used owing to the nature of the task. Further, the class sampling strategy is not always used with protonets (e.g., [46], [47]) which might inhibit task diversity during training. An exception from the above metric learning approaches is [51], where the authors train deep speaker embeddings using the modelagnostic metalearning strategy to mitigate domain mismatch for speaker veriÔ¨Åcation. To the best of our knowledge, metalearning is yet to be applied for generalpurpose speaker diarization, except for the speciÔ¨Åc case of dyadic speaker clustering in childadult interactions in our recent work [52]. III. M ETHODS "
274,AutoSpeech: Neural Architecture Search for Speaker Recognition.txt,"Speaker recognition systems based on Convolutional Neural Networks (CNNs) are
often built with off-the-shelf backbones such as VGG-Net or ResNet. However,
these backbones were originally proposed for image classification, and
therefore may not be naturally fit for speaker recognition. Due to the
prohibitive complexity of manually exploring the design space, we propose the
first neural architecture search approach approach for the speaker recognition
tasks, named as AutoSpeech. Our algorithm first identifies the optimal
operation combination in a neural cell and then derives a CNN model by stacking
the neural cell for multiple times. The final speaker recognition model can be
obtained by training the derived CNN model through the standard scheme. To
evaluate the proposed approach, we conduct experiments on both speaker
identification and speaker verification tasks using the VoxCeleb1 dataset.
Results demonstrate that the derived CNN architectures from the proposed
approach significantly outperform current speaker recognition systems based on
VGG-M, ResNet-18, and ResNet-34 back-bones, while enjoying lower model
complexity.","Speaker recognition aims to retrieve the identity of the speaker given his/her utterances. According to the content similarity of the utterances, speaker recognition can be categorized into text dependent and textindependent, the latter being more general and realistic for practical applications. Additionally, accord ing to different application settings, speaker recognition usually fall into one of the two categories: speaker identiÔ¨Åcation (SID) and speaker veriÔ¨Åcation (SV). SID identiÔ¨Åes the speaker of an utterance from a known speaker set, and SV determines if the speaker of an utterance matches its given enrollment. Endtoend speaker recognition systems [1, 2, 3, 4, 5, 6] have emerged in recent years and achieved the stateof theart performance. These models usually admit a three stage pipeline : (1) A deep neural network, typically Convolu tional Neural Networks (CNNs) or Recurrent Neural Networks (RNNs), as a feature extractor to generate framewise speaker embedding; (2) a temporal aggregation layer, to produce Ô¨Åxed length speaker embedding (i.e., dvector); (3) A loss function to optimize the entire network. In testing stage, the network along with the temporal aggregation layer are Ô¨Årst used to pro duce dvectors for the testing utterances, and then a similar ity metric (e.g., cosine similarity) follows to generate the Ô¨Ånal same/different speaker decision based on the dvectors. Most CNN/RNNbased speaker recognition works focus on improving the effectiveness of the speaker embedding through * Equal contribution.advanced training objectives and temporal aggregation strate gies [7, 8, 3, 9, 5]. By contrast, network architecture design has received relatively less attention. Existing studies usually use offtheshelf backbones that have been shown to be successful in standard tasks such as image classiÔ¨Åcation (e.g., VGGNet [10], ResNet [11]). However, these backbones are not designed for and may not be optimal for speaker recognition. Meanwhile, in other speech processing tasks such as speech recognition and speech synthesis, the improved design of network architecture has already yielded evident performance gains [12, 13]. In view of those, we conjecture that enhancing network architecture design matters for improving speaker recognition perfor mance too . Yet as the major hurdle for improving the backbone of any new task, manually exploring the gigantic design space of deep networks is notoriously tedious and adhoc. This paper proposes an automated approach to identify the optimal CNN architecture for textindependent speaker recog nition, named as AutoSpeech . It is inspired by recent advances on neural architecture search (NAS) [14, 15, 16, 17, 18], which has proven success in designing deep networks that outperform handdesigned best performers in various tasks [19, 20, 21, 22]. We evaluated the effectiveness of AutoSpeech on both SID and SV tasks using V oxCeleb1 dataset [23]. Our derived CNN ar chitectures signiÔ¨Åcantly outperforms several networks used in stateoftheart speaker recognition systems (based on VGGM, ResNet18, and ResNet34), at lower model complexities. 2. Literature Review 2.1. Speaker Recognition Earlier speaker recognition systems used spectral features (e.g., MFCCs) as the speaker embedding [24, 25], but these sys tems have been superseded by systems based on ivectors [26, 27, 28]. An ivector takes speech from a speaker and uses it to adapt a speakerindependent Gaussian Mixture Model (GMM, referred to as a Universal Background Model). The means of the adapted GMM are concatenated to form a su pervector, which is then reduced in dimensionality using joint factor analysis. More recently, endtoend speaker recognition [1, 2, 3, 4, 5] systems have been shown to surpass the ivector based systems and achieve stateoftheart performance. Variani et al. Ô¨Årst proposed a neural network based speaker recognition system. In their work, they used maxout fullyconnected net work to produce dvectors, and then they used cosine similarity to make the Ô¨Ånal decision. Following this, advanced network architectures such as CNNs [3, 5, 9, 8, 29] and RNNs [5, 2] are used for feature extracts. Additionally, advanced training objec tives [2, 8, 29] and temporal aggregation strategies [7, 3, 9, 5] are also proposed to improve speaker recognition performance.arXiv:2005.03215v2  [eess.AS]  31 Aug 2020Figure 1: Illustration of a neural cell. During the search pro cess, the intermediate nodes ( x2tox5) are densely connected (red arrows), and the optimal combination of the operations on these edges are found at the end of the searching process. Dur ing architecture derivation, only the two operations with high est softmax probabilities (excepting zero operation) are retained for each intermediate node. 2.2. Neural Architecture Search The goal of neural architecture search is to search for an opti mal network architecture for a given task. To accomplish this, a search space will be constructed Ô¨Årstly, which may vary across different tasks and objectives. Towards accurate image classi Ô¨Åcation, many previous work [14, 15, 16] adopt a cellbased search space with complicated inner connection. To improve its efÔ¨Åciency, [30, 31, 32] adopts a sequentialbased search space, beneÔ¨Åting a lot in reducing latency and FLOPs inher ently. More recently, neural architecture search has also been applied to other tasks (e.g., image segmentation [20, 33], gen erative adversarial network [21], and phone recognition [19]), where taskspeciÔ¨Åc search spaces are usually designed. To con duct architecture search over the deÔ¨Åned search space, various optimization methods are proposed. Barret and Quoc Ô¨Årst use the reinforcement learning (RL) to search for architecture[17], where a RNN serves as an architecture sampler. However, it is quite timeconsuming (2,000 GPU days). To address this lim itation, Hieu et al. propose to use weight sharing (ENAS[16]) to accelerate RLbased search method. Furthermore, Liu et al. present a gradientbased method [14] to accelerate the searching process. 3. Methods "
135,BDD4BNN: A BDD-based Quantitative Analysis Framework for Binarized Neural Networks.txt,"Verifying and explaining the behavior of neural networks is becoming
increasingly important, especially when they are deployed in safety-critical
applications. In this paper, we study verification problems for Binarized
Neural Networks (BNNs), the 1-bit quantization of general real-numbered neural
networks. Our approach is to encode BNNs into Binary Decision Diagrams (BDDs),
which is done by exploiting the internal structure of the BNNs. In particular,
we translate the input-output relation of blocks in BNNs to cardinality
constraints which are then encoded by BDDs. Based on the encoding, we develop a
quantitative verification framework for BNNs where precise and comprehensive
analysis of BNNs can be performed. We demonstrate the application of our
framework by providing quantitative robustness analysis and interpretability
for BNNs. We implement a prototype tool BDD4BNN and carry out extensive
experiments which confirm the effectiveness and efficiency of our approach.","Deep neural networks (DNNs) have achieved humanlevel performance in several tasks, and are increasingly being incorporated into various application domains such as au tonomous driving [ 4] and medical diagnostics [ 49]. Modern DNNs usually contain a great many parameters which are typically stored as 32 /64bit Ô¨Çoatingpoint numbers, and require a massive amount of Ô¨Çoatingpoint operations to compute the output for a single input [ 56]. As a result, it is often challenging to deploy them on resource constrained, embedded devices. To mitigate the issue, quantization, which quantizes 32/64bit Ô¨Çoatingpoints to low bitwidth Ô¨Åxedpoints (e.g., 4bits) with little accuracy loss [ 21], emerges as a promising technique to reduce resource requirements. In par ticular, binarized neural networks (BNNs) [ 26] represent the case of 1bit quantization using the bipolar binaries 1. BNNs can drastically reduce memory storage and exe cution time with bitwise operations, hence substantially improve the time and energy eciency. BNNs have been demonstrated to achieve high accuracy for a wide variety of applications [33,48,38]. DNNs have been shown to often lack robustness against adversarial samples. There fore, various formal techniques have been proposed to analyze DNNs, but most of them focus on realnumbered DNNs only. VeriÔ¨Åcation of quantized DNNs has not been thoroughly explored so far, although recent results have highlighted its importance: it was shown that a quantized DNN does not necessarily preserve the properties satisÔ¨Åed by the realnumbered DNN before quantization [ 12,20]. Indeed, the Ô¨Åxedpoint numberarXiv:2103.07224v1  [cs.LG]  12 Mar 20212 Yedi Zhang, Zhe Zhao, Guangke Chen, Fu Song, and Taolue Chen semantics e ectively yields a discrete state space for the veriÔ¨Åcation of quantized DNNs whereas realnumbered DNNs feature a continuous state space. The discrepancy could invalidate current veriÔ¨Åcation techniques for realnumbered DNNs when they are directly applied to quantized counterparts (e.g., both false negative and false positive could occur). Therefore, specialized techniques are required for rigorously verifying quantized DNNs. Broadly speaking, the existing techniques for quantized DNNs make use of con straint solving which is based on either SAT /SMT or (reduced, ordered) binary decision diagrams (BDDs). A majority of work resorts to SAT /SMT solving. For the 1bit quan tization (i.e., BNNs), typically BNNs are transformed into Boolean formulas where SAT solving is harnessed [ 42,10,32,41]. Some recent work also studies variants of BNNs [ 44,27], for instance, threevalued BNNs. For quantized DNNs with multiple bits (i.e., Ô¨Åxedpoints), it is natural to encode them as quantiÔ¨Åerfree SMT formulas, e.g., using bitvector and Ô¨Åxedpoint theories [ 7,20,23], so that o theshelf SMT solvers can be leveraged. In another direction, BDDbased approaches currently can tackle BNNs only [ 50]. In a nutshell, they encode a BNN and an input region as a BDD, based on which various analyses can be performed via queries on the BDD. The crux of the ap proach is how to generate the BDD e ciently. In the work [ 50], the BDD is constructed by BDD learning [ 40], thus, currently limited to toy BNNs (e.g., 64 input size, 5 hidden neurons, and 2 output size) with relatively small input regions. On the other hand, existing work mostly focuses on qualitative veriÔ¨Åcation, which asks whether there exists an input x(in a speciÔ¨Åed region) for a neural network such that a property (e.g., local robustness) is violated. In many practical applications, checking only the existence is not su cient. Indeed, for local robustness, such an (adversarial) input almost surely exists which makes a qualitative answer less meaningful. Instead, quantitative veriÔ¨Åcation, which asks how often a property is satisÔ¨Åed or violated, is far more useful as it could provide a probabilistic guarantee of the behavior of neural networks. Such a quantitative guarantee is essential to certify, for instance, certain imple mentations of neural network based perceptual components against safety standards of autonomous vehicles [ 28,31]. Quantitative analysis of general neural networks, however, is challenging, hence received little attention and for which the results are rather limited so far. DeepSRGR [ 68] presented an abstract interpretation based quantitative robustness veriÔ¨Åcation approach for DNNs which is sound but incomplete. For BNNs, approximate SAT modelcounting solvers ( ]SAT) are leveraged [ 6,43] based on the SAT encoding for the qualitative counterpart. Though probably approximately correct (PAC) style guarantees can be provided, veriÔ¨Åcation cost is usually prohibitively high to achieve higher precision and conÔ¨Ådence. Main contributions. We propose a BDDbased framework BDD4BNN to support quan titative analysis of BNNs. The main challenge is how to e ciently build BDDs from BNNs [ 43]. In contrast to previous work [ 50] which is learningbased and largely treats the BNN as a blackbox, we directly encode a BNN and the associated input region into BDDs. In a nutshell, a BNN is a sequential composition of multiple internal blocks and one output block. Each block comprises a handful of layers and captures a function f:f+1;"
266,Space-Time Tradeoffs for Distributed Verification.txt,"Verifying that a network configuration satisfies a given boolean predicate is
a fundamental problem in distributed computing. Many variations of this problem
have been studied, for example, in the context of proof labeling schemes (PLS),
locally checkable proofs (LCP), and non-deterministic local decision (NLD). In
all of these contexts, verification time is assumed to be constant. Korman,
Kutten and Masuzawa [PODC 2011] presented a proof-labeling scheme for MST, with
poly-logarithmic verification time, and logarithmic memory at each vertex.
  In this paper we introduce the notion of a $t$-PLS, which allows the
verification procedure to run for super-constant time. Our work analyzes the
tradeoffs of $t$-PLS between time, label size, message length, and computation
space. We construct a universal $t$-PLS and prove that it uses the same amount
of total communication as a known one-round universal PLS, and $t$ factor
smaller labels. In addition, we provide a general technique to prove lower
bounds for space-time tradeoffs of $t$-PLS. We use this technique to show an
optimal tradeoff for testing that a network is acyclic (cycle free). Our
optimal $t$-PLS for acyclicity uses label size and computation space $O((\log
n)/t)$. We further describe a recursive $O(\log^* n)$ space verifier for
acyclicity which does not assume previous knowledge of the run-time $t$.","A fundamental problem in distributed computing is to determine if a network conguration satises some predicate. In the distributed setting, a network con guration is represented by an underlying graph, where each vertex represents a processor, edges represent communication links between processors, and each vertex has a state. For example, the state of every vertex can be a color, and ?Research supported in part by NSF grant 1619348, DARPA, USIsrael BSF grant 2012366, OKAWA Foundation Research Award, IBM Faculty Research Award, Xe rox Faculty Research Award, B. John Garrick Foundation Award, Teradata Research Award, and LockheedMartin Corporation Research Award. The views expressed are those of the authors and do not re ect position of the Department of Defense or the U.S. Government. ??Partially supported by Apple Graduate Fellowship.arXiv:1605.06814v2  [cs.DC]  21 Aug 2017the predicate signies that the coloring is proper, i.e., that every edge has its endpoints colored dierently. Processors learn about the network by exchang ing messages along the edges. Some properties are local by nature and easy to verify, yet many natural problems|for example, testing if the network contains cycles|cannot be tested in less than diameter time, even if message size and local computational power are unbounded. In order to cope with strong time lower bounds, Korman, Kutten, and Peleg introduced in [16] a computational model, called prooflabeling schemes (PLS), where vertices are given auxiliary global information in the form of labels . This auxiliary information may allow vertices to verify that a property is satised more eciently than could be achieved without the aid of labels. Specically, a PLS consists of two components, a prover and a verier . The prover is an oracle which assigns labels to vertices. The verier is a distributed algorithm which runs on the labeled conguration and outputs true orfalse at each vertex as a function of its state, its label, and the labels it receives. A PLS is complete if for every legal conguration (satisfying the predicate), prover can assign labels such that all vertices output true . The PLS is sound if for every illegal conguration (which does not satisfy the predicate) for every labeling, some vertex outputs false . Schemes for verifying a predicate are useful in many applications. One such application is checking the output of a distributed algorithm [3,11]. For exam ple, if a procedure is meant to output a spanningtree of the network, it may be useful to periodically verify that the output does indeed not contain cycles. If the original procedure which nds the spanningtree can additionally produce labels, verication may be achieved substantially faster than diameter time re quired without the aid of labels. A simple procedure for checking the legality of the current state is very useful in the construction of self stabilizing algo rithms [2,1,15,6]. Other applications include estimating the complexity of logics required for distributed runtime verication [11], establishing a general dis tributed complexity theory [10], and proving lower bounds on the time required for distributed approximation [7]. Local verication was recently applied in the design and analysis of software dened networks (SDN) in [17]. Distributed verication has been formalized in various models to suit its myr iad applications. These models include prooflabeling schemes (PLS) [16], locally checkable proofs (LCP) [12], and nondeterministic local decision (NLD) [10]. We refer the reader to [8] for a detailed comparison of these models. All three of these models are local in the sense that verication requires a constant number of rounds, independent of the size of the graph. PLS diers from LCP and NLD in that verication in (traditional) PLS occurs in a single communication round, while the LCP and NLD models allow verication in a xed constant number of rounds. While a fast procedure is certainly a desirable feature in verication algorithms, it may be the case that other computational resources|space or communication|must also be considered. For example, in the case of PLS, de terministically verifying a subgraph is acyclic requires labels of size  (logn) per vertex [16]. However, specifying a subgraph only requires O() space (themaximum degree of a vertex) per vertex. Thus, if we restrict attention to local verication algorithms, the space requirement to store labels may be unbound edly larger than the space required to specify the instance. Korman, Kutten and Masuzawa [15] presented a PLS for minimum spanning tree with polylogarithmic verication time and logarithmic memory at each vertex. In the present work we also consider superconstant time verication and address tradeos between computational resources in distributed verication algorithms: label size, communication, computation space, and time. Specically, we address the following questions: If verication algorithms are allowed to run in superconstant time, can labels be signicantly shorter? What are the tradeos between label size and verication time? Can verication be achieved using (per processor) space which is linear in the label size? We focus on the acyclicity problem and prove that labels can indeed be shortened by a factor of t|the runtime of the algorithm|compared to constantround verication. Moreover, computation space for each vertex can be made linear in the label size. Note that in this model it does not trivially hold that each message contains exactly one label, since in each round every vertex receives a (potentially dierent) label from each neighbor, and the scheme should specify the message to be sent in the following round. We show that in our schemes messages are small enough so that the total communication is the same as in oneround verication. 1.1 Our Contributions In this paper we consider prooflabeling schemes with superconstant verication time, and analyze tradeos between time, label size, message size, and compu tation space. Many of the results presented here were announced without proof in [5]. In Subsection 3.1, we describe a universal scheme which can verify any propertyP. SupposeGs, withnvertices,medges, and each state can be repre sented using sbits. Then for every t2O(diam(Gs)), our scheme veries Pint rounds using labels and messages of size O((ns+minfn2;mlogng)=t). Fort= 1 this is the known universal scheme [16,12,4]. When t2 (n), we obtain labels and messages of size O(s+minfn;(m=n) logng). Overall, labels are signicantly smaller, and total communication is the same. Subsection 3.2 proves a general lower bound technique for label size of tround schemes. In Section 4 we consider the problem determining if a graph is acyclic. Using the lower bound technique of Subsection 3.2, we prove in Subsection 4.1 that labels of size  ((logn)=t) are required for the acyclic problem. Subsection 4.2 shows that this lower bound is tight. Our scheme for acyclic additionally uses optimal space and messages of size O((logn)=t). In particular, by taking tto be a suciently large constant, our upper bound (along with the  (logn) lower bound for acyclic in [16]) implies separation between the PLS and LCP models for acyclicity (see [8]). The verier for acyclic assumes that vertices are given some truthful information about the round number, for example, by being told when (a multiple of) trounds have elapsed. We prove that such information is necessary for anysuperconstant and sublinear time distributed algorithm in Appendix A. In Subsection 4.3, we describe a recursive scheme for acyclicwhich uses space O(logn) and constant communication per vertex per round. The recursive verier runs in time O(n) in the worst case, but there are always correct labels which will be accepted in time O(log diam(G)). We note that in order to break the logarithmic space barrier, our schemes in Subsections 4.2 and 4.3 crucially do not rely upon unique identiers for the vertices. Conversely, the lower bounds of Subsections 3.2 and 4.1 hold for a stronger model where vertices have unique identiers, and labels may depend on the unique identiers. 1.2 Related Work "
414,Deep multi-frame face super-resolution.txt,"Face verification and recognition problems have seen rapid progress in recent
years, however recognition from small size images remains a challenging task
that is inherently intertwined with the task of face super-resolution. Tackling
this problem using multiple frames is an attractive idea, yet requires solving
the alignment problem that is also challenging for low-resolution faces. Here
we present a holistic system for multi-frame recognition, alignment, and
superresolution of faces. Our neural network architecture restores the central
frame of each input sequence additionally taking into account a number of
adjacent frames and making use of sub-pixel movements. We present our results
using the popular dataset for video face recognition (YouTube Faces). We show a
notable improvement of identification score compared to several baselines
including the one based on single-image super-resolution.","Face recognition systems have seen a great progress over the last several years with superhuman recog nition accuracy attainable in many scenarios. How ever, the accuracy of recognition degrades very signif icantly when dealing with very low resolution faces. In such conditions, the tasks of recognition and in creasing the eective resolution ( superresolution ) be come intertwined and necessitate joint solution. In deed, developing superresolution techniques without regard for recognition often leads to face hallucina tion, i.e. a process that creates plausibly looking faces lacking personal specics. On the other hand, super Figure 1: Results of dierent superresolution con volutional networks on samples from the Youtube Faces (YTF) dataset. From left to right: ground truth, bicubic upsampling, singleframe superresolu tion, superresolution from 25 frames without align ment (ours), superresolution from 25 frames with warping subnetwork (ours). resolution has been known to benet from recognition for a long time [1]. While singleimage superresolution has recently drawn considerable attention [21, 18], super resolution over large magnication factors can ben et signicantly from information accumulated over multiple images, e.g. using adjacent frames in a surveillance stream or a video. Traditionally, multi frame superresolution has required rigid or non rigid alignment with subpixel accuracy [2]. At the same time, faces have complex and deformable shapes leading to complex twodimensional motion patterns which makes motion estimation hard to accomplish at subpixel precision. Generally, such precise align 1arXiv:1709.03196v2  [cs.CV]  15 Oct 2017ment cannot be accomplished using lowlevel cues alone, and therefore requires highlevel understand ing/recognition of face geometry. Motivated by all these observations, we present a system that performs multiframe superresolution by tackling all three interrelated problems, namely superresolution, nonrigid alignment, and recogni tion, jointly and simultaneously. The tasks are im plemented as modules of a deep neural network ar chitecture that is trained in an endtoend fashion on a dataset of realistic face videos [19]. The forward pass in our network involves pairwise alignment of pairs of frames performed in parallel with feature ex traction, while the superresolution is accomplished by a subsequent reconstruction module that takes warped features of the multiple frames into account. The learning process is driven by a combination of loss functions that includes the recognitionrelated loss ensuring that the superresolution process recon structs personspecic traits. Overall, while individual components of our sys tem have been proposed in previous works, to the best of our knowledge, our work is the rst that builds a systems that combines face superresolution, recognition and alignment in a holistic manner. We evaluate the proposed architecture on the holdout part of the YouTube Faces (YTF) dataset ([19]). We demonstrate good face verication performance for the restored images using standard protocols adopted for the YTF dataset. We also show benets of us ing multiple frames along with Face Warping sub network over the singleimage approach. We addi tionally compare our approach with stateoftheart face hallucination method [21] and nd our method to perform better on the YouTube Faces dataset. In the remainder of this work, we review the most related approaches in 2 describe the components of the proposed system in 3 and 4 demonstrate the superresolution results in 5 and conclude with a short summary in 6.2 Related work "
226,Deep Ensemble Learning with Frame Skipping for Face Anti-Spoofing.txt,"Face presentation attacks (PA), also known as spoofing attacks, pose a
substantial threat to biometric systems that rely on facial recognition
systems, such as access control systems, mobile payments, and identity
verification systems. To mitigate the spoofing risk, several video-based
methods have been presented in the literature that analyze facial motion in
successive video frames. However, estimating the motion between adjacent frames
is a challenging task and requires high computational cost. In this paper, we
rephrase the face anti-spoofing task as a motion prediction problem and
introduce a deep ensemble learning model with a frame skipping mechanism. In
particular, the proposed frame skipping adopts a uniform sampling approach by
dividing the original video into video clips of fixed size. By doing so, every
nth frame of the clip is selected to ensure that the temporal patterns can
easily be perceived during the training of three different recurrent neural
networks (RNNs). Motivated by the performance of individual RNNs, a meta-model
is developed to improve the overall detection performance by combining the
prediction of individual RNNs. Extensive experiments were performed on four
datasets, and state-of-the-art performance is reported on MSU-MFSD (3.12%),
Replay-Attack (11.19%), and OULU-NPU (12.23%) databases by using half total
error rates (HTERs) in the most challenging cross-dataset testing scenario.","Face recognition technology has been used in various fields, such as automated teller machines (ATMs), retail and market ing, automatic border control, security and law enforcement [1]. However, there are various physical and digital attacks, such as 3D mask attacks [2], deep fake face swapping [3], face morphing [4], face adversarial attacks [5], and so on, that can limit the applications of facial recognition technology. Therefore, developing robust countermeasures to detect face representation attacks is critical to improving the security of biometric systems and ensuring the widespread adoption of this technology. The main issue for face PAD is to identify and ana lyze the unique visual and behavioral characteristics of both live and spoofed facial images because both classes contain spatiotemporal information. Recent studies show that video based methods [8, 9, 10] can potentially be more effective than imagebased methods [11, 12, 13]. This is due to the fact that video provides additional information and context that can help discriminate real and fake faces. For instance, a real face not only exhibits the appearance of the face but also small and subtle movements, such as eye blinks and Fig. 1: Illustration of the necessity of using the frame skipping mechanism. The top four rows show sequence [6] and clip prediction [7]. In this work, we exploit temporal coherence in videos by proposing a frame skipping mechanism that requires a single frame in a video clip. In this way, the natural motion of the object along the time axis provides rich information to recurrent neural networks for temporal cue prediction and improves presentation attack detection. facial expressions, which can reveal important cues about the authenticity of the face [14]. Moreover, temporal cues (i.e., the temporal consistency of the face over time) provide additional information, whereas a fake face may appear rigid and static. Despite the success of videobased methods, domain gener alization is one of the main challenges that still need to be addressed in the face antispoofing domain. In our work, we define generalizability as the extent to which a model is trained and tuned on one or multiple databases and then applied to outofsample unseen data. There are many generalizationrelated research topics such as ensemble learning, data augmentation, transfer learning, metalearning, and so on. In particular, domain generalization is important in face antispoofing because new datasets are expensive and timeconsuming to collect and annotate in real world scenarios. Moreover, testing data can come from differarXiv:2307.02858v2  [cs.CV]  11 Jul 2023Fig. 2: Flowchart of our proposed method. First, a video Xis divided into nonoverlapping segments of smaller length xto perform uniform frame sampling. Then, every nth frame of the segment is selected for training the model. As the remaining frames of the segment are skipped, we train multiple recurrent neural networks to predict the temporal cues and form a metamodel to improve generalization of PAD. ent illumination conditions or environments than the training data. Therefore, in order to improve the generalization, vari ous methods, such as adversarial learning [15], meta pattern learning [16], generative domain adaptation [17], hypothesis verification [18], or crossadversarial learning [19], have been proposed that train the model on multiple datasets, but the detection performance remains limited due to a substantial distribution difference among source domains. In a typical PAD video, not all the frames are equally important, and processing every frame is computationally expensive [1]. Thus, frame selection approaches have been often used to reduce the computational cost. For instance, Usman et al. [20] proposed to convert the video sequences into a single RGB frame based on the Gaussian weighting function. The authors claimed that frame aggregation can amplify motion cues, such as head movements, and surface edges. Another approach to frame selection is to identify key frames that capture important moments or events in the video sequence [21]. In particular, the optical flow has been used for motion analysis and to identify significant changes between two adjacent frames [22]. It provides a set of motion vectors that represent the motion between frames. Moreover, the global motion was found to be critical in face anti spoofing that discriminates camera motion and natural motion of the objects along the time axis [23]. The frame selection methods that rely on clip order prediction [7] or a sequence sorting task [6] in selfsupervised learning enable the model to learn meaningful representations from unlabeled video data. However, these approaches extract features from all the frames of the video. We argue that a frame selection approach that involves motion estimation [22, 23, 1] between the frames can be costly to train and may lead to potential stability issues. Thus, effective handling of such spatiotemporal variations is pivotal to improving the performance of face antispoofing systems. As mentioned above, most of the motion estimation methodsare designed to satisfy the PAD performance, while compu tational cost is mostly ignored. In an attempt to fill this gap, we propose to use a subset of frames by selecting a uniform sampling that does not require estimating the motion between adjacent frames and assumes that selected frames convey relevant information about human faces. Fig. 1 illustrates our approach. In particular, we attempt to make an alternative way of predicting the temporal changes through training different recurrent neural networks (RNNs) that model the sequential information across the video frames. Motivated by this, we also address the domain generalization issue by combining the predictions of each RNN and then develop a metamodel based on the idea of stackingbased ensemble learning [24]. Intuitively, this idea has at least three main advantages. First, using 4 to 7 frames is sufficient, since it does not require any additional analysis or processing of the video frames. Second, the computational cost is significantly reduced because only a few images will be enough for subsequent analysis, instead of all frames during both training and test phases. Third, we can easily control the number of frames selected from the video sequence by adjusting the sampling rate. The rest of this paper is organized as follows. Section II explains all the steps of the proposed method. Section III discusses the details of experimental results with stateofthe art performance comparison. Finally, Section IV summarizes the main outcomes with conclusive statements and perspective works. II. M ETHODOLOGY "
445,Regularizing Face Verification Nets For Pain Intensity Regression.txt,"Limited labeled data are available for the research of estimating facial
expression intensities. For instance, the ability to train deep networks for
automated pain assessment is limited by small datasets with labels of
patient-reported pain intensities. Fortunately, fine-tuning from a
data-extensive pre-trained domain, such as face verification, can alleviate
this problem. In this paper, we propose a network that fine-tunes a
state-of-the-art face verification network using a regularized regression loss
and additional data with expression labels. In this way, the expression
intensity regression task can benefit from the rich feature representations
trained on a huge amount of data for face verification. The proposed
regularized deep regressor is applied to estimate the pain expression intensity
and verified on the widely-used UNBC-McMaster Shoulder-Pain dataset, achieving
the state-of-the-art performance. A weighted evaluation metric is also proposed
to address the imbalance issue of different pain intensities.","Obtaining accurate patientreported pain intensities is impor tant to effectively manage pain and thus reduce anesthetic doses and inhospital deterioration. Traditionally, caregivers work with patients to manually input the patients‚Äô pain in tensity, ranging among a few levels such as mild, moder ate, severe and excruciating. Recently, a couple of concepts have been proposed such as active, automated and objec tive pain monitoring over the patient‚Äôs stay in hospital, with roughly the same motivation: Ô¨Årst to simplify the pain report ing process and reduce the strain on manual efforts; second to standardize the feedback mechanism by ensuring a single metric that performs all assessments and thus reduces bias. There indeed exist efforts to assess pain from the observa tional or behavioral effect caused by pain such as physiologi cal data. ¬©Medasense has developed medical devices for ob jective pain monitoring. Their basic premise is that pain may cause vital signs such as blood pressure, pulse rate, respiration * Corresponding author (email: xxiang@cs.jhu.edu ) Fig. 1 . Example testing result of estimated pain intensities (see the continuous red curve) of one patient in one video from the ShoulderPain dataset [1] which provides perframe observerrated labels (see the blue curve connected from dis crete points of (frame;intensity )). Best viewed in color. rate, SpO2 from EMG, ECG or EEG, alone or in combination to change and often to increase. Nevertheless, it takes much more effort to obtain physiological data than videos of faces. Computer vision and supervised learning have come a long way in recent years, redeÔ¨Åning the stateoftheart using deep Convolutional Neural Networks (CNNs). However, the ability to train deep CNNs for pain assessment is limited by small datasets with labels of patientreported pain intensities, i.e., annotated datasets such as EmoPain [2], ShoulderPain [1], BioVid Heat Pain [3]. Particularly, ShoulderPain is the only dataset available for visual analysis with perframe la bels. It contains only 200 videos of 25 patients who suffer from shoulder pain and repeatedly raise their arms and then put them down (onsetapexoffset). While all frames are la beled with discretevalued pain intensities (see Fig. 1), the dataset is small, the label is discrete and most labels are 0. Although the small dataset problem prevents us from di rectly training a deep pain intensity regressor, we show thatarXiv:1702.06925v3  [cs.CV]  1 Jun 2017Ô¨Ånetuning from a dataextensive pretrained domain such as face veriÔ¨Åcation can alleviate this problem. Our solutions are Ô¨Ånetuning a welltrained face veriÔ¨Åcation net on additional data with a regularized regression loss and a hidden full connected layer regularized using dropout, regularizing the regression loss using a center loss, and resampling the training data by the population propor tion of a certain pain intensity w.r.t. the total population. While our work is not the Ô¨Årst attempt of this regulariza tion idea [4], to our knowledge we are the Ô¨Årst to apply it to the pain expression intensity estimation. Correspondingly, we propose three solutions to address the four issues mentioned above. In summary, the contributions of this work include addressing limited data with expression intensity labels by relating two mappings from the same input face space to dif ferent output label space where the identity labels are rich, pushing the pain assessment performance by a large margin, proposing to add center loss regularizer to make the re gressed values closer to discrete values, and proposing a more sensible evaluation metric to address the imbalance issue caused by a natural phenomena where most of the time a patient does not express pain. 2. RELATED WORKS "
405,Tighter Abstract Queries in Neural Network Verification.txt,"Neural networks have become critical components of reactive systems in
various domains within computer science. Despite their excellent performance,
using neural networks entails numerous risks that stem from our lack of ability
to understand and reason about their behavior. Due to these risks, various
formal methods have been proposed for verifying neural networks; but
unfortunately, these typically struggle with scalability barriers. Recent
attempts have demonstrated that abstraction-refinement approaches could play a
significant role in mitigating these limitations; but these approaches can
often produce networks that are so abstract, that they become unsuitable for
verification. To deal with this issue, we present CEGARETTE, a novel
verification mechanism where both the system and the property are abstracted
and refined simultaneously. We observe that this approach allows us to produce
abstract networks which are both small and sufficiently accurate, allowing for
quick verification times while avoiding a large number of refinement steps. For
evaluation purposes, we implemented CEGARETTE as an extension to the recently
proposed CEGAR-NN framework. Our results are very promising, and demonstrate a
significant improvement in performance over multiple benchmarks.","Deep neural networks (DNNs) have become stateoftheart technology in many elds [58], including image processing [37], computational photography [13], speech recognition [1, 35], natural language processing [23], video processing [10,45], autonomous driving [16], and many others. Nowadays, they are even increasingly being used as critical components in various systems [55,60,74,79], and society's reliance on them is constantly increasing. Despite these remarkable achievements, neural networks suer from multiple limitations, which undermine their reliability: the training process of DNNs is based on assumptions re garding the data, which may fail to hold later on [36, 43]; the training process might cause overtting of the DNN to specic data [77, 91]; and, independently of the above, there are various attacks that can fool a DNN into performing unwanted actions [72,87]. In order to overcome these diculties and ensure the correctness and safety of DNNs, the formal methods community has been devising techniques for verifying them [26, 46, 48, 62, 83]. Techniques for neural network verication (NNV) receive as input a neural network and a set of constraints over its input and output, and check whether there exists an input/output pair that satises these constraints. Typically, the constraints encode the negation of some desirable property, and so such a pair constitutes a counterexample (the SATcase); whereas if no such pair exists, the desired property holds (the UNSAT case). NNV has been studied extensively in Equal ContributionarXiv:2210.12871v2  [cs.LG]  14 May 2023Tighter Abstract Queries in Neural Networks Verication Cohen, Elboher, Barrett and Katz recent years, and many dierent veriers have been proposed [24{26,46,48,62,67,83]. However, scalability remains a fundamental barrier, both theoretical and practical, which limits the use of NNV engines: generally, increasing the number of neurons of the veried neural network implies an exponential increase in the complexity of the verication problem [40,46]. In order to alleviate this scalability limitation, recently there have been attempts to apply abstraction techniques within NNV [11,27,28,57,69,76], often focusing on the counterexample guided abstraction renement (CEGAR) framework [21]. CEGAR is a wellknown approach, aimed at expediting the solving of complex verication queries, by abstracting the model being veried into a simpler one | in such a way that if the simpler model is safe, i.e. the query isUNSAT , then so is the original model. In case of a SATanswer from the verier, we check whether the satisfying assignment of the abstract model is also a satisfying assignment of the original. If so, the original query is declared SAT, the satisfying assignment is returned, and the process ends. Otherwise, the satisfying assignment is called spurious (orerroneous ), indicating that the abstract query is too coarse, and should be rened into a slightly \less abstract"" query, which is a bit closer to the original model (but is hopefully still smaller). CEGAR has been successfully used in various formal method applications [9,15,42,65,73], and also in the context of NNV [27, 28, 57]. Typically, these approaches generate an abstract neural network , which is smaller than the original, and is created by the merging of neurons of the original network. The renement, accordingly, is performed by splitting previously merged neurons. Other related approaches have also considered abstracting the ranges of values obtained by neurons in the network [11,69,70,76]. The general motivation for abstraction schemes is that smaller, abstract networks are easier to verify. While this is often true, smaller networks tend to be far less precise, and verifying them often requires multiple renement steps [28, 70]. In extreme cases, these multiple renement steps can render the verication process slower than directly verifying the original network [28]. Here, we seek to tackle this problem, by improving the abstract verication queries. We propose a novel verication scheme for DNNs, wherein abstraction and renement operations include altering not only the network (as in [21, 27, 28, 57, 70]), but also the property being veried. The motivation is to render the abstract properties more restrictive , in a way that will reduce the number of spurious counterexamples encountered during the verication process; but at the same time, ensure that the abstract queries still maintain the overapproximation property: if the abstract query is UNSAT , the original query is UNSAT too. The key idea on which our approach is based is to compute a minimal dierence between the outputs of the abstract network and the original network, and then use this minimal dierence to tighten the property being veried, in a sound manner. Our approach is not coupled to any specic DNN verication method, and can use multiple DNN veriers as blackbox backends. For evaluation purposes, we implemented it on top of the Marabou DNN verier [48]. We then tested our approach on the ACASXu benchmarks [44] for airborne collision avoidance, and also on MNIST benchmarks for digit recognition [54]. Our results indicate that property abstraction aords a signicant increase in the number of queries that can be veried within a given timeout, as well as a sharp decrease in the number of renement steps performed. To summarize, our contributions are as follows: (i) we present CEGARETTE , a novel CEGAR framework for DNN verication, that abstracts not only the network but also the property being veried; (ii) we provide a publicly available implementation of our approach, CEGARETTENN ; and (iii) we use our implementation to demonstrate the practical usefulness of our approach. The rest of this paper is organized as follows. In Section 2, we provide a brief background on neural networks and their verication, followed by an explanation of the CEGAR framework 2Tighter Abstract Queries in Neural Networks Verication Cohen, Elboher, Barrett and Katz and its implementation for neural network verication. In Section 3, we describe our novel verication framework CEGARETTE . In Section 4, we discuss how to apply this framework for abstracting and rening DNNs, followed by an evaluation in Section 5. Related work is discussed "
353,Making Neural Networks FAIR.txt,"Research on neural networks has gained significant momentum over the past few
years. Because training is a resource-intensive process and training data
cannot always be made available to everyone, there has been a trend to reuse
pre-trained neural networks. As such, neural networks themselves have become
research data. In this paper, we first present the neural network ontology
FAIRnets Ontology, an ontology to make existing neural network models findable,
accessible, interoperable, and reusable according to the FAIR principles. Our
ontology allows us to model neural networks on a meta-level in a structured
way, including the representation of all network layers and their
characteristics. Secondly, we have modeled over 18,400 neural networks from
GitHub based on this ontology, which we provide to the public as a knowledge
graph called FAIRnets, ready to be used for recommending suitable neural
networks to data scientists.","Researchers of various sciences and data analysts reuse but also retrain neural network models according to their needs.3Providing pretrained neural network models online has the following advantages. First, as a provider, you can ben eÔ¨Åt from users improving your neural network and circulating your research. Second, as a user of an already trained neural network, you can o vercome the cold start problem as well as save on training time and costs. Furthe rmore, pro viding trained neural network models gets increasingly important in t he light of the research community eÔ¨Äorts to make research results more transparent and explainable (see FAIR principles [ 21]). As a result, more and more trained models areprovidedonlineat sourcecode repositoriessuch asGitHu b. The mod els provided serve not only to reproduce the results but also to inte rpret them (e.g., by comparing similar neural network models). Lastly, providing and us ing pretrained models gets increasingly important via transfer lear ning in other domains. To ensure the highquality reuse of data sets and infrastructure , theFAIR Guiding Principles for scientiÔ¨Åc data management and stewa rdship[21] have been proposed. These guidelines are designed to make digital asset sFindable, Accessible, Interoperable, and Reusable. They have been widely accepted by ‚ãÜThese authors contributed equally to the work. 3https://trends.google.com/trends/explore?date=all&q =transfer%20learning2 A. Nguyen et al. severalscientiÔ¨Åccommunitiesnowadays(e.g.,[ 22]).MakingdigitalassetsFAIRis essential to deal with a datadrivenworld and thus keeping pace wit h an increas ing volume, complexity, and creation speed of data. So far, the FAI R principles have been mainly applied when providing data sets and code [ 22,3], but not ma chine learning models, such as neural network models. In this paper , we bring the FAIR principles to neural networks by (1) proposing a novel sc hema (i.e., ontology) which enables semantic annotations to enhance the infor mation basis (e.g., for search and reasoning purposes) and (2) representing a wide range of existing neural network models with this schema in a FAIR way. As we o utline in Sec.3.1, extracting metadata from neural networks automatically is a non trivial task due to heterogeneous code styles, dynamic coding, and vary ing versioning. The key idea is that the information contained in these networks sho uld be pro vided according to the FAIR principles. This comprises several step s which not onlyconsist ofhavingidentiÔ¨Åers but providing(meta)data in amachin ereadable way in order to enable researchers and practitioners (e.g., data sc ientists) easy access to the data. We facilitate this by using semantic web technolo gies such as OWL and RDF/RDFS. Overall, we provide the following contributions: 1. We providean ontology, calledFAIRnets Ontology , for representingneu ral networks. It is made available using a persistent URI by w3id and r egis tered at the platform Linked Open Vocabularies (LOV). Ontology URI: https://w3id.org/nno/ontology LOV:https://lov.linkeddata.es/dataset/lov/vocabs/nno 2. We provide a knowledge graph , calledFAIRnets , representing over 18,400 publicly availableneuralnetworks,followingtheFAIR principles. FAIRnets is available using a persistent URI by w3id and is uploaded to Zenodo. Knowledge Graph URI: https://w3id.org/nno/data Zenodo: https://doi.org/10.5281/zenodo.3885249 Our contribution is beneÔ¨Åcial in several application areas (see Sec. 5). For in stance, we already provide an online search system called FAIRnets Search [13] by which users can explore and analyze neural network models. The paper is structured as follows. Sec. 2describes the structure of FAIR nets Ontology and Sec. 3describes the knowledge graph FAIRnets . Sec.4 explains the reason why the neural networks in FAIRnets follow the FAIR principles. Sec. 5describes the impact of FAIRnets . Sec.6gives an overview of related work. Lastly, the contributions are summarized. 2 FAIRnets Ontology 2.1 Creation Process TheFAIRnets Ontology is dedicated to model metadata for neural network models on a schema level. We developed the ontology by using Prot¬¥ eg ¬¥ e [12]. ToMaking Neural Networks FAIR 3 Fig.1.Visualization of FAIRnets Ontology .4 A. Nguyen et al. the best ofourknowledge,there isno existingvocabularyforthe s peciÔ¨Åc descrip tion of neural networks. That is why several senior researchers use best practices [6] to construct the ontology. We identify researchers, especially b eginners, as potential users. The use cases we envision can be found in Sec. 5. In addition to the consideration of the Predictive Model Markup Lan guage (PMML) in the development of the ontology (especially in describing th e archi tecture), Ô¨Åndings from further work were also considered. In pa rticular, model cards [11] were taken into account to validate relevant concepts. Model ca rds encourage transparent model reports concerning machine learn ing models and are used for outlining the intended use of a model. These cards deÔ¨Ån e minimal information needed to suÔ¨Éciently describe a machine learning model ( in our case, a neural network) that is relevant to the intended applicatio n domains. As suggestedfrom modelcards,weincluded modeldetailssuch asper sondeveloping model, model date, model type, and licenses. Characteristics. The structure of the FAIRnets Ontology can be seen in Fig.1. Overall, the ontology consists of a total of 516 axioms and uses a t otal of 77 classes where 70 are subclasses. It also consists of four obje ct properties, 23 data properties, and 29 individuals. The ontology enables representing three diÔ¨Äerent aspects of info rmation. (1) Neural networkrelated general metadata and (2) neural netw orkdependent fea tures can be modeled, such as the type of layer, loss function, and optimizer. (3) LayerspeciÔ¨Åc metadata is used to enhance the information basis o f the speciÔ¨Åc layers, e.g., its keywords and parameters. In the following, we will de scribe these three components of the FAIRnets Ontology correspondingly.4 General information describe general components of the neural network, as well as the intended use. For instance, the owner/developer of th e (trained) neural network is modeled by using the property dc:creator . This attribute makes it possible to search for repositories by the author in the dom ain of neural networks. Following the Linked Data Principles, the author is repres ented via a URI. In this way, the authors are uniquely identiÔ¨Åed. Therefore, it is possible to link it to the Microsoft Academic Knowledge Graph [ 5] which models scholarly data such as scientiÔ¨Åc publications in which some of the represented neural network models are proposed and evaluated. Moreover, a name ( rdfs:label ) and a description ( dc:description ) of the trained neural network are stored. The data property nno:dataset of type URI allows us to specify the data set that was used to train the neural network. This information alread ygives a more detailed insight into the neural network as well as the intended use o f it. Furthermore, the timestamp of creation date ( dc:created ) or last mod iÔ¨Åcation ( dc:modified ) allows assessing the currency of the neural network. dc:license indicates the rights to modify and redistribute that network. Be sides, the property nno:hasRepositoryLink allows linking to the repository in which the neural network is located. Likewise, references to publis hed papers can be included using dc:references . 4We will use nnoas the preÔ¨Åx for the namespace https://w3id.org/nno/ontology#Making Neural Networks FAIR 5 ModelspeciÔ¨Åc information covers modelspeciÔ¨Åc components of the neural network, such as optimization function denoted by nno:hasOptimizer .The on tology covers modeling various loss functions, such as binary cross entropy and mean squared error, via the property nno:hasLossFunction .Loss functions are subdivided into classiÔ¨Åcation and regressionloss functions in the ont ologyto fur ther indicate the intended use of the neural network. The informa tion about ex isting layers of the neural network can be linked via the property nno:hasLayer . The loss functions and layer types available in Keras, an opensourc e deep learn ing framework to model neural networks, served as a basis to mod el available loss functions and layers. LayerspeciÔ¨Åc metadata outline additional information about the individual layer. The layers of neural networks are subdivided into subclasse s such as core, recurrent,andconvolutionallayer.Theseclassesarefurthers ubdividedintomore speciÔ¨Åc layer classes. This speciÔ¨Åcation derived from Keras enables to categorize the neural networks. For example, a neural network with a layer f rom class convolutional layer can be assigned to the type convolutional neur al network. Furthermore, the hyperparameters (e.g., kernel size, stride, a nd padding) are denoted by nno:hasLayerKeywords and saved as a dictionary. Additional values in the layer are denoted by nno:hasLayerParameter . Most of the categories, properties, and instances are annotate d with a label (rdfs:label ),adescription( rdfs:comment ),and,ifgiven,alink( rdfs:seeAlso ) which make it easy for ontology users to identify the intended use of categories, properties, and instances, therefore supporting the reusability . 2.2 Provisioning The World Wide Web Consortium (W3C) Permanent IdentiÔ¨Åer Communit y Group service is used to provide secure and permanent URL forwar ding to the ontology. The FAIRnets Ontology in syntax turtle is accessible under https://w3id.org/nno/ontology . Moreover, the ontology has been registered at LOV.5The ontology is licensed under Creative Commons BY 4.06which al lows its wide usage. Furthermore, the ontology follows the 5Star L inked Data Principles7and can, therefore, be easily reused. A VoID Ô¨Åle is provided under https://w3id.org/nno/fairnetsvoid including provisioning information. 3 FAIRnets Knowledge Graph Apart from the ontology, we provide the FAIRnets knowledge graph, which is based on the FAIRnets Ontology . The knowledge graph allows us to store knowledge (in our case, detailed metadata for neural network mod els) intuitively as a graph. Existing and widely used W3C standards and recommenda tions, such as RDF and SPARQL, can be used to query the knowledge graph and to 5https://lov.linkeddata.es/dataset/lov/vocabs/nno , last acc. 20201015 6https://creativecommons.org/licenses/by/4.0/ , last acc. 20201015 7https://5stardata.info/en/ , last acc. 202010156 A. Nguyen et al. integrate relatively easily into existing frameworks and systems. Fo r instance, FAIRnets is already integrated into KBox [ 10] which is a data management framework, allowing users to share resources among diÔ¨Äerent app lications. 3.1 Creation Process The previous online available neural network repositories such as Ke ras,8CaÔ¨Äe Model Zoo,9and Wolfram Alpha10are rather small (under one hundred neural networks) and not suÔ¨Écient to present trends in the development and usage of neuralnetworks.Generalpurposeonlinecodesharingservices ,suchas GitHub11 and Bitbucket,12in contrast, contain many repositories of diÔ¨Äerent nature. We, thus, decided to use GitHub since it is the largest host of repositorie s. Details about the nontrivial extraction process are given in the following. Data Source. We extract and represent metadata of publicly available, trained neural network models in RDF* (i.e. RDF and RDFS) based on the FAIRnets Ontology . Information from SemanGit [ 9] and GHTorrent [ 7] can be used to identify GitHub repositories. SemanGit and GHTorrent provide a colle ction of dataextractedfromGitHub. Intotaltherearemorethan119millio nrepositories available in the GHTorrent data collection. However, SemanGit and GH Torrent have a diÔ¨Äerent focus and do not provide all the information which we wanted to provide in the FAIRnets knowledge graph. For instance, information about the architectures of neural networks within the repositories, th e creation date of the repositories, as well as the watcher count is not included. We , therefore, directly accessed the GitHub Repository API and queried available ne ural net work repositories. We used the search term ‚Äòneural network‚Äô and Ô¨Åltered for repositories that use Python as a programming language. We acces sed these repositories13and extracted the neural network metadata. Extraction Process. The diÔ¨Éculty lies in the extraction of the architecture in formation from the code. We narrowed our extraction down on neu ral networks implemented in Python. Still, it is diÔ¨Écult to identify the Python Ô¨Åle which models a neural network. Therefore, we started with h5 Ô¨Åles which are an open source technology for storing trained machine learning models. Neu ral networks that have been trained with Keras, for example, can be stored in th is format. The h5 Ô¨Åle contains information about the neural network, e.g., the sequence of layers, used activation functions, optimization function, and los s function. Accessing the information in the h5 Ô¨Åle makes it easier to identify and e xtract the architecture of the neural network. However, not every re pository contains 8https://keras.io , last acc. 20201015 9https://github.com/BVLC/caffe/wiki/ModelZoo , last acc. 20201015 10https://resources.wolframcloud.com/NeuralNetReposit ory,last acc. 20201015 11https://www.github.com , last acc. 20201015 12https://www.bitbucket.org , last acc. 20201015 13ExemplaryGitHubAPIRequest: https://api.github.com/repos/dmnelson/sentimentana lysisimdb , last acc. 20201015.Making Neural Networks FAIR 7 Table 1. Mapping of GitHub REST API values to the general components i nFAIR nets. GitHub API FAIRnets Ontology createdat dc:created description, readme dc:description htmlurl nno:hasRepositoryLink license dc:license owner[‚Äòhtml url‚Äô] dc:creator updated at dc:modified watchers count nno:stars name rdfs:label topics[‚Äònames‚Äô] doap:category trained neural networks in h5 Ô¨Åles. The reason is that trained neur al networks often take up a lot of storage space. Thus, our contribution is the information extraction from the code directly which will be described below. General Information: The mapping of the values from the Github API with the corresponding general component properties in FAIRnets can be seen in Tab.1. We use the fullnameof the GitHub REST API as a unique identiÔ¨Åer (e.g., ‚Äòdmnelson/sentimentanalysisimdb‚Äô in note 13). Thefullnameconsists of the GitHub username combined with the name of the repository. T he owner of the repository is also the owner of the neural network. Moreov er, we store the link ( nno:hasRepositoryLink ),the time of creation ( dc:created ), and the last modiÔ¨Åcation ( dc:modified ) of the repository. As a description of the neu ral network ( dc:description ), we extracted automatically the description and readme Ô¨Åle of the GitHub repository. This gives a summary of the pos sible use of the neural network. Furthermore, license information about the neural network is extracted and modeled in the knowledge graph, if available. This info rmation is crucial regarding the reusability of neural networks. Given this in formation, it is possible to Ô¨Ålter neural networks by license ‚Äì which is often an impo rtant constraint in industrial settings. To enrich the knowledge graph FAIRnets with informationaccordingtothe usageofaneuralnetwork,weextra ctthe topics14of each repository from the GitHub repositories and store them as doap:category . Additionally, we extract arXiv HTTP links within the readme Ô¨Åle and map them todc:references . If BibTex Ô¨Åle codes can be found in the readme Ô¨Åle, we extract the URL information from the BibTex entry and link it by us ing the property dc:references .The property dc:references is only intended for scientiÔ¨Åc contributions. By linking it with URLs from BibTex entries and arXiv links, we ensure this condition. Other links in the readme Ô¨Åle are linked t o the neural network using rdfs:seeAlso . Model & Technical Information: The main feature of FAIRnets is the modeling of neural networks. We can model the structure and tec hnical compo 14https://developer.github.com/v3/repos/#listalltop icsforarepository , last acc. 20201015.8 A. Nguyen et al. nents of neural networks by employing the FAIRnets Ontology . To extract the neural network information from the repositories we consider all Python Ô¨Åles in the repositories. Each repository can contain several mode ls of a neural network. In general, it is diÔ¨Écult to extract the architecture infor mation auto matically without executing the source code. By executing the code , you can save the neural network model, for example in h5, and retrieve the information easier. We seek a more elegant way by saving execution costs and us e language processing to extract the information. Due to that, we focus on P ython Ô¨Åles with static variables. Despite this restriction, there are still challen ges because of various programming styles such as inconsistent naming of variab les, com plex loop constructions, diÔ¨Äerent structures of code, and other logic statements. Another challenge is changing parameter naming due to diÔ¨Äerent fra mework versions which are usually not stated. To solve these tasks, a gene ral method is generated using Python Abstract Syntax Trees (AST) module.15The AST module helps Python applications to process trees of the Python ab stract syn tax grammar. We focused on Keras applications of neural network s to extract the architecture because it is the most used deep learning framewo rk among the topwinners on Kaggle.8The information on the architecture of the neural network is then modeled by using the schema and properties provide d by the FAIRnets Ontology . Also, the individual layers and their hyperparameters are stored in our knowledge graph. Likewise, the used optimization f unction and loss function are stored, among other things, allowing us to infer wh ether the neural network is used for classiÔ¨Åcation or regression. Our code c an be found on GitHub.16 Evaluation. Toevaluatethe accuracyofourinformationextraction,wemanua lly went through 50 examples where we judged the extraction of the G itHub Repos itory API in Tab. 1. The evaluation was in all cases correct. In the case of the neural network architecture, we used the h5 Ô¨Åles, if available, in th e repositories. We were able to evaluate over 1,343 h5 Ô¨Åles with architecture informa tion (i.e., layer information) which overlap with the architecture extracted f rom the code with 54% accuracy. Due to later modiÔ¨Åcations in the code it is possible t hat the overlap with the h5 Ô¨Åle does not apply anymore (e.g., if a layer is commen ted out). 3.2 Provisioning Just like the FAIRnets Ontology , the knowledge graph FAIRnets is also based on the 5Star Linked Data Principles. The knowledge graph is a ccessi ble under a persistent URI from w3id and additionally provided on Zeno do. In combining FAIR principles and Linked Data Principles using URIs to ident ify things, providing information using RDF*, and linking to other URIs, it is pos sible to easily reference and use FAIRnets (see Sec. 5). Machinereadablemeta data allows us to describe and search for neural networks. The kn owledge graph 15https://docs.python.org/3/library/ast.html , last acc. 20201015 16https://github.com/annugyen/FAIRnetsMaking Neural Networks FAIR 9 Table 2. Statistical key Ô¨Ågures about FAIRnets . Key Figure Value repositories 9,516 unique users 8,637 neural networks 18,463 FFNN 8,924 (48%) CNN 6,667 (36%) RNN 2,872 (16%) FAIRnets , like the Ontology , is published under the Creative Commons BY 4.0 license.6A VoID Ô¨Åle describing the knowledge graph in a machinereadable format is provided under https://w3id.org/nno/fairnetsvoid . 3.3 Statistical Analysis of the FAIRnets Knowledge Graph Tab.2shows some key Ô¨Ågures about the created knowledge graph. It co nsists of 18,463 neural networks, retrieved from 9,516 repositories, and p rovided by 8,637 unique users. The creation time of the neural networks in our know ledge graph ranges from January 2015 to June 2019. All these networks have a link to the respective repository and owner. Based on the used layers, we ca n infer the type of neural network. If a network uses a convolutional layer, it is inf erred that the network is a convolutional neural network (CNN). Likewise, if a network contains a recurrent layer, it is inferred that the network is a recu rrent neural network (RNN). For simplicity, if none of those two layer types are u sed, the default claim for the network is a feedforward neural network (F FNN). Of the total 18,463 neural networks, FFNN is most represented in the kn owledge graph comprising half of the neural networks. CNNs follows with 36% and RN N with 16% of the total number of neural networks. 4 FAIR Principles for Neural Networks WithFAIRnets , we treat neural networks as research data. As such, to ensur e good scientiÔ¨Åc practice, it should be provided according to the FAIR principles, thatis,thedatashouldbeÔ¨Åndable,accessible,interoperable,and reusable.While the GitHub repositories themselves do not satisfy the FAIR principle s (e.g., the metadata is not easily searchable and processable by machines), th e modeling of theneuralnetworksinthe FAIRnets knowledgegraphismade FAIRasweshow in the following. SpeciÔ¨Åcally, in this section, we identify the factors th at make the neural network representations in FAIRnets FAIR. This was achieved by following the FAIRiÔ¨Åcation process .17Our FAIRiÔ¨Åcation process is aligned with 17https://www.gofair.org/fairprinciples/fairificati onprocess/ , last acc. 20201015.10 A. Nguyen et al. Table 3. Evaluation of FAIRnets according to the Generation2 FAIRMetrics (Note: ‚úì= passed, ( ‚úì)= should pass, ‚úó= not passed). Principle FAIRMetric Name Result FindableGen2FMF1AIdentiÔ¨Åer Uniqueness ‚úì Gen2FMF1BIdentiÔ¨Åer persistence ‚úì Gen2FMF2Machinereadability of metadata ‚úì Gen2FMF3Resource IdentiÔ¨Åer in Metadata ‚úì Gen2FMF4Indexed in a searchable resource ‚úó AccessibleGen2FMA1.1Access Protocol ‚úì Gen2FMA1.2Access authorization ‚úì Gen2FMA2Metadata Longevity ( ‚úì) InteroperableGen2FMI1Use a Knowledge Representation Language ‚úì Gen2FMI2Use FAIR Vocabularies ‚úì Gen2FMI3Use QualiÔ¨Åed References ‚úì ReusableGen2FMR1.1Accessible Usage License ‚úì Gen2FMR1.2Detailed Provenance ( ‚úì) Gen2FMR1.3Meets Community Standards ( ‚úì) theFAIRMetrics18outlined in Tab. 3. In the following, we point out how the single FAIR metrics are met by our knowledge graph. Findable describes the property that metadata for digital assets is easy f or both humans and machines to Ô¨Ånd. Our approach ensured that, Ô¨År stly, by re trieving the metadata available in the repository, secondly, struct uring its meta data in the readme Ô¨Åle, and thirdly, obtaining the architecture infor mation from the code Ô¨Åle according to the FAIRnets Ontology . The neural networks we model have unique identiÔ¨Åers (i.e., fulÔ¨Ålling Gen2FMF1A) and a persistent URI (Gen2FMF1B). As a result, the process for a human to Ô¨Ånd a suitable neural network through resource identiÔ¨Åers in the metadata ( Gen2FMF3) is improved. By using RDF as the data model and by providing a schema in OWL as well as a VoID Ô¨Åle as a description of the knowledge graph, the met adata is machinereadable ( Gen2FMF2). Thus, the knowledge graph can be auto matically Ô¨Åltered and used by services. An exemplary service suppor ting this statement is presented in Sec. 5.FAIRnets allows for querying information about and within the architecture of the neural networks which wa s not possi ble previously. Now, complex queries are feasible (e.g., list all recurre nt neural networks published in 2018), which cannot be solved by traditional k eyword searches. The metric Gen2FMF419‚Äì ‚Äòindexed in a searchable resource‚Äô ‚Äì was not passed by FAIRnets although we indexed it on Zenodo. The reason is that the resource on Zenodo is not Ô¨Åndable in the search engine Bing which the au 18https://fairmetrics.org , last acc. 20201015 19https://github.com/FAIRMetrics/Metrics/blob/master/ FM_F4,lastacc.202010 15Making Neural Networks FAIR 11 thors of the FAIRMetrics use as ground truth. However, FAIRnets is indexed by the search engine Google. Accessible describes that users can access (meta)data using a standardize d communication protocol. The protocol must be open, free, and un iversally im plemented. FAIRnets Ontology and knowledge graph is located on a web server and can be accessed using the HTTPS protocol ( Gen2FMA1.1). The neural networks in the repositories can also be accessed using the HTTPS protocol( Gen2FMA1.2). In addition to the open protocol,the accessible prop erty requires that metadata can be retrieved, even if the actual digital assets are no longer available. Due to the separation of the information in FAIRnets and the actual neural networks on GitHub, this property is fulÔ¨Ålled, sin ce the infor mation in FAIRnets is preserved even if the neural networks on GitHub are no longeravailable( Gen2FMA2).Theservicetoevaluatethemetric Gen2FMA2 ‚Äì ‚Äòmetadata longevity‚Äô ‚Äì could not be executed because it only tests Ô¨Åles that are less than 300kb20whereasFAIRnets has more than 80MB. This test checks for the existence of the ‚Äòpersistence policy‚Äô predicate. This predic ate is available inFAIRnets , which should pass the test. Interoperable refers to the capability of being integrated with other data as well as being available to applications for analysis, storage, and furt her pro cessing. We make use of Linked Data by applying RDF ( Gen2FMI1) and SPARQL to represent the information. This makes the data machine readable, even without the speciÔ¨Åcation of an adhoc algorithm or mapping. Ad dition ally, the FAIRnets Ontology and the respective knowledge graph use wellestablished and commonly used vocabularies to represent the in formation. Amongothers,DublinCore,VocabularyofaFriend(VOAF),Creativ eCommons (CC), and avocabularyforannotatingvocabularydescriptions(V ANN) areused for annotations and descriptions ( Gen2FMI2). As a further requirement of the FAIR guideline, qualiÔ¨Åed references to further metadata are r equired. This requirement is fulÔ¨Ålled by rdfs:seeAlso anddc:references (Gen2FMI3). dc:references statements provide scientiÔ¨Åc references between the neural ne t worksandscientiÔ¨Åccontributions.Thesereferencestothe scien tiÔ¨Åccontributions are provided via globally unique and persistent identiÔ¨Åers, such as DO Is. Reusable aims at achieving welldeÔ¨Åned digital assets. This facilitates the repli cability and usage in other contexts (i.e., reproducibility), as well as Ô¨Å ndability. Due to the architecture and metadata extraction, the process o f Ô¨Ånding and reusinganeuralnetworkbyanenduserbecomessigniÔ¨Åcantlyeas ierandcannow be performed systematically. By using best practices in ontology bu ilding, the properties and classes of FAIRnets Ontology provided are selfexplanatory with labels and descriptions ( Gen2FMR1.3). The neural networks in FAIR netscontain structured detailed metadata such as creator and GitHub link (see Gen2FMR1.2) for easy Ô¨Åndability and reuse. At the same time, most neural networks in FAIRnets have an assigned license which is important for reusabil ity (Gen2FMR1.1). For passing Gen2FMR1.2, (meta)data must be associ 20https://github.com/FAIRMetrics/Metrics/blob/master/ FM_A2,lastacc.202010 1512 A. Nguyen et al. ated with detailed provenance reusing existing vocabularies such as Dublin Core which we included in our knowledge graph. Gen2FMR1.3tests a certiÔ¨Åcation saying that the resource is compliant with a minimum of metadata. FAIRnets is described by using LOV standards for publication. Therefore, we assume that these metrics are fulÔ¨Ålled. Overall, the neural networks modeled in FAIRnets fulÔ¨Åll all requirements of the FAIR principles, see Tab. 3. 5 Impact We see high potential of FAIRnets Ontology and the knowledge graph FAIRnets in the areas of transparency ,recommendation ,reusability ,education , andsearch. In the following, we outline these application areas in more detail. Transparency. Neural networks are applied in many diÔ¨Äerent areas such as Ô¨Å nance [16], medical health [ 8], and law [ 14]. Transparency plays a major role in these areas when it comes to trust the output of a used neural ne twork model. We claim that our contribution which makes neural networks more tr ansparent can increase trust and privacy [ 17]. Additionally, using semantic annotations can even enhance interpretability by distributional semantics [ 18]. Another aspect is the transparency of scientiÔ¨Åc work regarding n eural net works. Researchers publishing a model should provide it according t o the FAIR principlestostrengthentheirscientiÔ¨Åccontribution.Ourknowledg egraphFAIR netscan pave the way for this. Recommendation. Neural Architecture Search (NAS) is used to Ô¨Ånd the best suitable neural network architecture based on existing architect ures [4]. How ever, the search is performed purely based on metrics like accurac y ignoring explainability aspects concerning the best Ô¨Åtting model. Our knowled ge graph allows us to have a search for the best suitable neural network mod els on a metalevel, using modeled usecases, data sets, and scientiÔ¨Åc pap ers. Knowledge graphs have also been used to provide explanations for recommend ation to the user [19,23]. Additionally, we can apply explainable reasoning [ 20] given the ontology and the knowledge graph and infer some rules. Doing this, we might reaso n which neural network models are reasonable or which components of the architecture stand in conÔ¨Çict with each other. Reusability. Transfer learning is a method in deep learning to reuse pretrained models on new tasks. Our contribution facilitate the search of pre trained neural networks and provide metadata needed to choose a speciÔ¨Åc neura l network. We can envision FAIRnets linked with other knowledge bases to enrich reusability of neural networks by applying Linked Data Principles.7For example, training data sets can be linked with Neural Data Server,21Wikidata,22and Zenodo23 21http://aidemos.cs.toronto.edu/nds/ , last acc. 20201015 22https://www.wikidata.org , last acc. 20201015 23https://zenodo.org , last acc. 20201015Making Neural Networks FAIR 13 through schema.org,24scientiÔ¨Åc papers can be linked with the Microsoft Aca demic Knowledge Graph [ 5], and metadata can be extended with OpenAIRE.25 On the other hand, providing a model and encouraging its reuse can improve it by revealing limitations, errors, or suggestions to other tasks. Education. OurFAIRnets knowledge graph can be used for educational pur poses [2], for instance, to learn best practices regarding designing a neura l net work model. Another aspect is to learn the usages of diÔ¨Äerent arch itectures and their approaches (e.g., via linked papers). Our knowledge graph inclu des train ing parameters that can help setting up the training process of a ne ural network (e.g., when facing the cold start problem). SearchWe provide online the search system FAIRnets Search26[13], which is based on the proposed FAIRnets Ontology andknowledge graph . Users can search for neural network models through search terms. Ad ditional infor mation can be retrieved by using SPARQL as query language on top of our knowledge graph, which enables faceted and semantic search capa bilities. The SPARQL endpoint is also available to the public. The search system sho ws how a semantic search system can be realized which improved the limited ca pabili ties of keyword searches on GitHub. Furthermore, developers ca n provide their GitHub repository to run the FAIRiÔ¨Åcation process on their neural networks. Until now, we have over 550 visits to the website FAIRnets Search with over 4,800 page views, 1,400 searches on our website with an average dur ation of twelve minutes, and the maximal actions in one visit is 356. 6 Related Work "
53,who is snoring? snore based user recognition.txt,"Snoring is one of the most prominent symptoms of Obstructive Sleep
Apnea-Hypopnea Syndrome (OSAH), a highly prevalent disease that causes
repetitive collapse and cessation of the upper airway. Thus, accurate snore
sound monitoring and analysis is crucial. However, the traditional monitoring
method polysomnography (PSG) requires the patients to stay at a sleep clinic
for the whole night and be connected to many pieces of equipment. An
alternative and less invasive way is passive monitoring using a smartphone at
home or in the clinical settings. But, there is a challenge: the environment
may be shared by people such that the raw audio may contain the snore
activities of the bed partner or other person. False capturing of the snoring
activity could lead to critical false alarms and misdiagnosis of the patients.
To address this limitation, we propose a hypothesis that snore sound contains
unique identity information which can be used for user recognition. We analyzed
various machine learning models: Gaussian Mixture Model (GMM), GMM-UBM
(Universial Background Model), and a Deep Neural Network (DNN) on MPSSC - an
open source snoring dataset to evaluate the validity of our hypothesis. Our
results are promising as we achieved around 90% accuracy in identification and
verification tasks. This work marks the first step towards understanding the
practicality of snore based user monitoring to enable multiple healthcare
applicaitons.","Snoring is a common symptom of sleep disorder breath ing (SDB). It is caused by repeated bouts of decreased and stopped airÔ¨Çow during sleep. According to an earlier in vestigation, about 50% of the adult population frequently snores [1]. It has become a signiÔ¨Åcant reason for poor sleep quality, degraded memory, and diseases such as sleep distur bance and high blood pressure [2, 3]. Previous studies have revealed that analysis of snore sound is crucial for respiratory and cardiopulmonary diseases at an early stage. Detected snores can be further analyzed to extract more detailed at tributes such as upper airway condition. Thus, snore sound analysis is vital for passive health monitoring systems. The most prevalent and reliable technique for snor ing sound monitoring and diagnosis is polysomnography(PSG) [4]. Yet it is also confounded by problems like long reservation lists, high nursing costs, and the ‚ÄùÔ¨Årstnight ef fect‚Äù due to environmental changes [2]. Recently, acous tic monitoring using a smartphone at home or ward has aroused considerable interest for its noninvasiveness and costeffectiveness. However, this raise an issue if the space is shared by a bed partner or other patients since the raw audio may contain interfering snore sounds which can cause false alarms and impact the performance of the health monitors. Previous studies have focused on snore sound classiÔ¨Åca tion of the four types of snoring sounds (Velum, Oropharyn geal, Tongue, and Epiglottis) based on their excitation source. For example, Wang et al. [5] proposed an architecture based on Convolutional Neural Network combined with Gated Re current Unit (CNNGRU) to extract features solely from the training set in the corpus, and then processed them through the Channel Slice Model to obtain an Unweighted Average Recall (UAR) of 63.8%. Kun Qian et al. [6] carried out a multifeature analysis of the snore sounds. They applied those features to several classiÔ¨Åers to rank the features based on their importance and achieved an UAR of 78%. In order to analyze the snoring sound in a shared environ ment, we must deal with the snorer recognition problem in the Ô¨Årst place. Inspired by the idea that the feature of a subject‚Äôs cough is determined by the lung tissue and vocal cord [7], we assume that the snoring sound may contain a unique signa ture, which can be utilized to determine who actually snored. In this paper, our main aim is to determine if users can be identiÔ¨Åed/veriÔ¨Åed on the basis of their snore sounds. To this end, we created machine learning models based on GMM, GMMUBM, and Deep Neural Network (DNN) to extract snore patterns and evaluated them on MPSCC data corpus. Our results are promising as all three classiÔ¨Åers achieved an identiÔ¨Åcation rate of more than 90% and less than 15% equal error rate (EER) with just four snoring during the enrollment per user. As for veriÔ¨Åcation performance, snore embeddings derived from DNN produce the best results by achieving over 95% speciÔ¨Åcity and sensitivity. Our work is the Ô¨Årst to show that snoring sounds have unique signatures and can poten tially be used for user monitoring in shared environments. 2. RELATED WORK "
434,Distributed Runtime Verification of Metric Temporal Properties for Cross-Chain Protocols.txt,"Transactions involving multiple blockchains are implemented by cross-chain
protocols. These protocols are based on smart contracts, programs that run on
blockchains, executed by a network of computers. Because smart contracts can
automatically transfer ownership of cryptocurrencies, electronic securities,
and other valuable assets among untrusting parties, verifying the runtime
correctness of smart contracts is a problem of compelling practical interest.
Such verification is challenging since smart contract execution is
time-sensitive, and the clocks on different blockchains may not be perfectly
synchronized. This paper describes a method for runtime monitoring of
blockchain executions. First, we propose a generalized runtime verification
technique for verifying partially synchronous distributed computations for the
metric temporal logic (MTL) by exploiting bounded-skew clock synchronization.
Second, we introduce a progression-based formula rewriting scheme for
monitoring \MTL specifications which employ SMT solving techniques and report
experimental results.","Blockchain technology [1], [2] is a blockbuster in this era. It has drawn extensive attention from both industry and academia. With blockchain technology, people can trade in a peertopeer manner without mutually trusting each other, removing the necessity of a trusted centralized party. The concept of decentralization appears extremely appealing, and the transparency, anonymity, and persistent storage provided by blockchain make it more attractive. This revolutionary tech nology has triggered many applications in industry, ranging from cryptocurrency [3], nonfungible tokens [4], internet of things [5] to health services [6], etc. Besides the huge success of cryptocurrencies known as blockchain 1.0, especially Bitcoin [2], blockchain 2.0, known assmart contracts [7], is also promising in many scenarios. Smart contract is a program running on the blockchain. Its execution is triggered automatically and enforced by condi tions preset in the code. In this way, the transfer of assets can be automated by the rules in the smart contracts, and human intervention cannot stop it. A typical smart contract implemen tation is provided by Ethereum [8], which uses Solidity [8], which is a Turingcomplete language. However, automating the transactions by smart contracts also has its downsides. If the smart contract has bugs and does not do what is expected, then lack of human intervention may lead to massive Ô¨Ånancial losses. For example, as pointed out by [9], the Parity Multisig Wallet smart contract [10] version 1.5 included a vulnerability which led to the loss of 30 million US dollars. AliceBobApricot BlockchainBanana Blockchain Escrowùë•apricot coins‚Ñé,ùë°!Escrow ybanana coins‚Ñé,ùë°""Send  s:ùêªùë†=‚Ñéto redeemDeposit premium ùëù#+ùëù$Deposit premium ùëù$ Send  s:ùêªùë†=‚Ñéto redeemFig. 1: Hedged Twoparty Swap Thus, developing effective techniques to verify the correctness of smart contracts is both urgent and important to protect against possible losses. Furthermore, when a protocol is made up of multiple smart contracts across different blockchains, the correctness of protocols also need to be veriÔ¨Åed. In this paper, we advocate for a runtime veriÔ¨Åcation (RV) approach, to monitor the behavior of a system of blockchains with respect to a set of temporal logic formulas. Applying RV to deal with multiple blockchains can be reduced to distributed RV, where a centralized or decentralize monitor observes the behavior of a distributed system in which processes do not share a global clock. Although RV deals with Ô¨Ånite executions, the lack of a common global clock prohibits it from having a unique ordering of events in a distributed setting. Put it another way, the monitor can only form a partial order of event which may result in different veriÔ¨Åcation verdicts. Enumerating all possible ordering of events at run time incurs in an exponential blow up, making the approach not scalable. To add to this already complex task, most speciÔ¨Åcation for verifying blockchain smart contracts, come with a time bound. This means, not only the ordering of the events are at play when verifying, but also the actual physical time of occurrence of the event dictates the veriÔ¨Åcation verdict. In this paper, we propose an effective, sound and complete solution to distributed RV for timed speciÔ¨Åcations expressed in the metric temporal logic (MTL) [11]. To present a high level view of MTL, consider the twoparty swap protocol [4] shown in Fig 1. Alice and Bob, each in possession of Apricot and Banana blockchain assets respectively, wants to swap their assets between each other without being a victim of sore loser attack. There is a number of requirements that should be followed by conforming parties to discourage any attack 1arXiv:2204.09796v1  [cs.DC]  20 Apr 2022Apr BanSetUp 1Deposit (pb) 3 SetUp 1Deposit (pa+pb) 4Apr BanEscrow (h;tA) 5Redeem (bob) 7 Escrow (h;tB) 6Redeem (alice ) 7 seg1 seg2 Fig. 2: Progression Example on themselves. We use the metric temporal logic (MTL) [11] to express such requirements. One such requirement, where Alice should not redeem her asset before Bob within eight time units can be represented by the MTL formula: 'spec=:Apr.Redeem (bob)U[0;8)Ban.Redeem (alice): We consider a fault proof central monitor which has the complete view of the system but has no access to a global clock. In order to limit the blowup of states posed by the absence of a global clock, we make a practical assumption about the presence of a bounded clock skew between the local clocks of every pair of processes. This is guaranteed by a synchronization algorithm (e.g. NTP [12]). This setting is known to be partially synchronous when we do not assume any presence of a global clock and limit the impact of asynchrony within clock drifts. Such an assumption limits the window of partial orders of events only within time units and signiÔ¨Åcantly reduces the combinatorial blowup caused by nondeterminism due to concurrent. Existing distributed RV techniques either assume a global clock when working with time sensitive speciÔ¨Åcations [13], [14] or use untimed speciÔ¨Åcations when assuming partial synchrony [15], [16]. We introduce an SMT1based progressionbased formula rewriting technique over distributed computations which takes into consideration the events observed thus far to rewrite the speciÔ¨Åcations for future extensions. Our monitoring algorithm accounts for all possible orderings of events without explicitly generating them when evaluating MTL formulas. For example, in Fig. 2, we see the events and the time of occurrence in the two blockchains, Apricot( Apr) and Banana( Ban ) divided into two segments, seg1andseg2for computational purposes. Considering maximum clock skew = 2and the speciÔ¨Åcation 'spec, at the end of the Ô¨Årst segment, we have two possible rewritten formulas for the next segment: 'spec1=:Apr.Redeem (bob)U[0;4)Ban.Redeem (alice ) 'spec2=:Apr.Redeem (bob)U[0;3)Ban.Redeem (alice ) This is possible due to the different ordering and different time of occurrence of the events Deposit (pb)andDeposit (pa+ pb). In other words, the possible time of occurrence of the event Deposit (pb)(resp. Deposit (pa+pb)) is either 2, 3 or 4 (resp. 3, 4, or 5) due to the maximum clock skew of 2. Likewise, at the end of seg2, we have'spec1evaluate to true where as'spec2evaluate to false . This is because, even if we 1SatisÔ¨Åability modulo theories (SMT) is the problem of determining whether a formula involving Boolean expressions comprising of more complex formulas involving real numbers, integers, and/or various data structures is satisÔ¨Åable.consider the scenario when Ban.Redeem(alice) occurs before Apr.Redeem(bob) , a possible time of occurrence ofBan.Redeem(alice) is8(resp. 6) which makes 'spec2 (resp.'spec1) evaluate to false (resp. true ). We have fully implemented our technique2and report the results of rigorous experiments on monitoring synthetic data, using benchmarks in the tool UPPAAL [17], as well as monitoring correctness, liveness and conformance conditions for smart contracts on blockchains. We put our monitoring algorithm to test studying the effect of different parameters on the runtime and report on each of them. Using our technique we learn not to use a value of (transaction deadline) that is comparable to the value of clock skew when designing the smart contract. Organization: Section II presents the background con cepts. Formal statement of our RV problem is discussed in Section III. The formula progression rules and the SMTbased solution are described in Sections IV and V, respectively, while experimental results are analyzed in Section VI. Related work is discussed in Section VII before we make concluding remarks in Section VIII. The appendix includes more details about our case studies. II. P RELIMINARIES In this section, we present an overview of the distributed computations and the metric temporal logic ( MTL). A. Distributed Computation We consider a loosely coupled asynchronous message pass ing system, consisting of nreliable processes (that do not fail), denoted byP=fP1;P2;;Png. As a system, the processes do not share any memory or have a common global clock. Channels are assumed to be FIFO and lossless. In our model, we represent each local state change by an event and a message activity (send or receive) is represented by an event as well. Message passing does not change the state of the process and we disregard the content of the message as it is of no use for our monitoring technique. Here, we refer to a global clock which will act as the ‚Äúreal‚Äù timekeeper. It is to be noted that the presence of this global clock is just for theoretical reasons and it is not available to any of the individual processes. We make an assumption about a partially synchronous system. For each process Pi, wherei2[1;n], the local clock can be represented as a monotonically increasing function ci:Z0!Z0, whereci(G)is the value of the local clock at global time G. Since we are dealing with discrete time systems, for simplicity and without loss of generality, we represent time with nonnegative integers Z0. For any two processes PiandPj, wherei6=j, we assume: 8G2Z0:jci(G)"
485,Unified Hypersphere Embedding for Speaker Recognition.txt,"Incremental improvements in accuracy of Convolutional Neural Networks are
usually achieved through use of deeper and more complex models trained on
larger datasets. However, enlarging dataset and models increases the
computation and storage costs and cannot be done indefinitely. In this work, we
seek to improve the identification and verification accuracy of a
text-independent speaker recognition system without use of extra data or deeper
and more complex models by augmenting the training and testing data, finding
the optimal dimensionality of embedding space and use of more discriminative
loss functions. Results of experiments on VoxCeleb dataset suggest that: (i)
Simple repetition and random time-reversion of utterances can reduce prediction
errors by up to 18%. (ii) Lower dimensional embeddings are more suitable for
verification. (iii) Use of proposed logistic margin loss function leads to
unified embeddings with state-of-the-art identification and competitive
verification accuracies.","Speaker recognition is an area of research with more than 50 years of history and applications ranging from forensics an d security to humancomputer interaction in consumer electr on ics. Speaker recognition can be categorized into two tasks o f textdependent and textindependent speaker recognition with regard to the similarity of the uttered content between utte r ances. Textindependent speaker recognition task is the mo st general and nontrivial of the both that if performed accu rately, can be used in everyday situations. Moreover, speak er recognition can be classiÔ¨Åed into two tasks of identiÔ¨Åcatio n and veriÔ¨Åcation. In identiÔ¨Åcation, an utterance from one of the speakers within our training set will be given and the sys  tem needs to identify which speaker the utterance belongs to . In veriÔ¨Åcation, two utterances from speakers not within our training corpora will be given and the predictor needs to de cide whether these two utterances come from the same person and with what probability. The process of training a speaker 1https://github.com/MahdiHajibabaei/uniÔ¨Åedembeddingrecognition embedding, in both veriÔ¨Åcation and identiÔ¨Åcat ion, can be summarized as Ô¨Ånding a functional mapping into a space in which utterances of the same speaker are embedded as close to each other as possible and as far away as possible from utterances of the other speakers. Conventionally, utterances with various lengths, content and amount of environmental noise were transformed into variable number of vectors (or points) in a space spanned by features extracted from Ô¨Åxed length frames. The resulting vectors were then pooled together to evaluate a mean, mix ture model or so called Supervectors. The elaborate choice of features depended on the amount of environmental noise, variations in recording setups, level of cooperation expec ted from speakers and etc. However, with immense increase in the amount of data that can be collected from the Internet and computation power provided by GPUs, optimality of conven tional feature extraction and speaker modelling methods ar e under question. However, availability of datasets for speaker recognition with ever increasing sizes cannot be taken for granted. Un til recently that Nagrani et al. [1] collected a dataset with more than two weeks of interviews in English with 1,251 celebrities, there was a lack of large publicly available da taset needed to train a deep model. Even though, the recently re leased VoxCeleb2 [2] dataset includes more than 100 days of recordings from almost 6,000 speakers which is large enough to train a 50 layer Residual Network [3], methods improving the prediction accuracy without requiring more data or more parameters to be tuned can be used complementary to known methods to improve the prediction accuracies even further. 2. RELATED WORKS "
321,A$^3$: Accelerating Attention Mechanisms in Neural Networks with Approximation.txt,"With the increasing computational demands of neural networks, many hardware
accelerators for the neural networks have been proposed. Such existing neural
network accelerators often focus on popular neural network types such as
convolutional neural networks (CNNs) and recurrent neural networks (RNNs);
however, not much attention has been paid to attention mechanisms, an emerging
neural network primitive that enables neural networks to retrieve most relevant
information from a knowledge-base, external memory, or past states. The
attention mechanism is widely adopted by many state-of-the-art neural networks
for computer vision, natural language processing, and machine translation, and
accounts for a large portion of total execution time. We observe today's
practice of implementing this mechanism using matrix-vector multiplication is
suboptimal as the attention mechanism is semantically a content-based search
where a large portion of computations ends up not being used. Based on this
observation, we design and architect A3, which accelerates attention mechanisms
in neural networks with algorithmic approximation and hardware specialization.
Our proposed accelerator achieves multiple orders of magnitude improvement in
energy efficiency (performance/watt) as well as substantial speedup over the
state-of-the-art conventional hardware.","Neural networks (NNs) are currently one of the most popular techniques to perform complex AI tasks in various domains such as computer vision, natural language process ing, robotics, etc. With a large amount of data, NNs can effectively solve a wide range of AI challenges and can often surpass human performance in many domains. However, these advantages of NNs come at a high computational cost involving tens of billions of Ô¨Çoatingpoint operations. In order to minimize the energy cost of such a large number of operations and maximize the throughput of NN processing, many prior works proposed various FPGA or ASIC based accelerators [1], [2], [3]. These prior works are indeed very effective in improving the performance and energy efÔ¨Åciency of the popular NN types such as convolutional neural networks (CNNs) or recurrent neural networks (RNNs). However, such accelerators do not provide full support for an emerging NN primitive such as attention mechanisms. Attention mechanisms are one of the most important recent advancements in neural networks. Unlike CNNs and RNNs, which has a limited capacity to utilize information fromthe past or external knowledge, attention mechanisms (also called memory mechanisms) enable NNs to access and utilize such information by providing extra connections to past state cells, explicit memory cells, and so on. Naturally, not all information from past state cells or explicit memory cells is equally relevant to what NN is currently processing. Hence, the attention mechanism determines what is relevant to the currently processed information through contentbased similarity search and decides where to attend . This attention mechanism has been recently adopted in many domains of NNs such as computer vision [4], [5], [6] and natural language processing [7], [8], [9], [10]. In addition, this mechanism is also used to enable NNs to solve a class of complex problems that were previously difÔ¨Åcult for conventional NNs due to their lack of ability to memorize and retrieve data [11], [12]. In the conventional hardware, an attention mechanism is usually implemented as dense matrix operations and softmax operations. A dense matrixvector multiplication operation computes the similarity across all search targets and thus the computational complexity of this operation is proportional to the number of search targets. In other words, attention mechanism requires more computation when a NN model wants to retrieve relevant information over the larger external knowledgebase, over a longer period of past information, or from a longer sequence of data. To make it even worse, in some NN models utilizing selfattention mechanisms [7], [13], [14], the computational complexity of attention mechanism is proportional to the square of the search targets (e.g., a length of the reading passage in the reading comprehension task). Naturally, this large computational cost of attention mechanism becomes a limiting factor for the capacity of the NN models and accounts for a signiÔ¨Åcant portion of the performance and energy cost of existing models. To address this challenge and mitigate the bottlenecks aris ing from the computational cost of attention mechanisms, we architectA3, a hardware accelerator for attention mechanisms in NNs. To design an efÔ¨Åcient accelerator, we not only focus on the efÔ¨Åcient implementation of the attention mechanism in hardware but also focus on reducing the amount of computation in attention mechanism through algorithmic optimization and approximation. In particular, based on the observation that not all search targets are equally likely to be relevant, our design presents an approximate candidatearXiv:2002.10941v1  [cs.DC]  22 Feb 20201 // key: nd, value:nd, query, output: d 2float []attention _mechanism (float key[][], 3 float value[][], float query[]) { 4 / *Step 1 : DotProduct Computation */ 5 for i = 0 to n: 6 sum = 0 7 for j = 0 to d: 8 sum += key[i][j] *query[j] 9 dot _product[i] = sum 10 / *Step 2 : Softmax Computation */ 11 score = softmax(dot _product) 12 / *Step 3 : Output Computation */ 13 for j = 0 to d: 14 sum = 0 15 for i = 0 to n: 16 sum += score[i] *value[i][j] 17 output[j] = sum 18 return output 19 } 20 float []softmax (float input[]) { 21 sum = 0 22 for i = 0 to n: 23 sum += exp(input[i]) 24 for i = 0 to n: 25 output[i] = exp(input[i]) / sum 26 return output 27 } Figure 1. Pseudocode for an attention mechanism. selection mechanism to reduce the number of search targets, and thus the amount of computation. Furthermore, we propose a specialized hardware pipeline exploiting parallelism to accelerate approximated attention mechanisms while making it even more efÔ¨Åcient. With this algorithmhardware co design, our proposed accelerator offers signiÔ¨Åcant perfor mance improvements and orders of magnitudes improvements in energy efÔ¨Åciency (performance/W), thereby enabling existing NN models with attention mechanisms to utilize larger external knowledge or a longer sequence of data. Our contributions are summarized as follows. We quantify the attention mechanism bottlenecks in NN models and identify that a substantial portion of time in NN models is spent on attention mechanisms. We exploit the potential for approximation in attention mechanisms and present an approximation scheme which enables our proposed hardware to Ô¨Ånd potentially relevant search targets while avoiding an exhaustive search. We design a specialized hardware pipeline for an attention mechanism exploiting parallelism and datapath specializa tion to signiÔ¨Åcantly improve the performance and energy efÔ¨Åciency of the attention mechanism. We demonstrate that our proposed accelerator achieves multiple orders of magnitude speedup and energy efÔ¨Å ciency over conventional hardware. Furthermore, with our specialized hardware for the approximation scheme, A3 achieves even higher speedup and energy efÔ¨Åciency while minimizing the degradation of the model accuracy. II. B ACKGROUND AND MOTIVATION A. Attention Mechanism Operation. Attention mechanism is essentially a content based search. Figure 1 represents the computation of the attention mechanism in pseudocode. Given a query vector John travelled to the hallway. Mary journeyed to the bathroom. Smith went to the bedroom. John moved to the garden.Statements Where is John ?Query [ 0.57  0.53  ‚Ä¶   0.02][ 1.10   0.72  ‚Ä¶   0.27] [ 0.37   0.27  ‚Ä¶   0.40] [ 0.40   0.10  ‚Ä¶   0.05] [ 1.10   0.88  ‚Ä¶   0.57]Attention  Mechanism Embedded QueryEmbedded Statements 0.01 0.790.030.17Figure 2. Example application of attention mechanism (Step 1 and 2 in Figure 1) from Facebook bAbI QA [15]. withddimensions and a key matrix with nvectors where each vector has ddimensions, the attention mechanism Ô¨Årst computes a similarity score (i.e., dotproduct) for each entry in the key matrix (Step 1 in Figure 1). After this process, anndimensional vector (i.e., dot_product[] ) is obtained. This array is then processed with softmax function (Step 2 in Figure 1). Finally, the normalized score is used as a weight to retrieve the weighted sum of vectors from the ndvalue matrix (Step 3 in Figure 1). In short, the set of indices for the set of vectors in the key matrix which are similar to the query vector is Ô¨Årst obtained, and these indices (along with weight values) are used to obtain the weighted sum for the set of vectors from the value matrix. This mechanism is often called softattention mechanism since it only consists of differentiable computations, which makes this mechanism wellsuited for NNs which are trained with backpropagation. Example Application. Figure 2 introduces a very simple example which shows how the attention mechanism is utilized to enable a NN to Ô¨Ånd a sentence that is relevant to the question in the Facebook bAbI QA task [15]. In this task, a list of statements and a question are provided in a natural language. The goal is to Ô¨Ånd the right answer to the question. Note that not all provided statements are necessary to answer a question. In many NN models solving this task, an attention mechanism is utilized to identify the most relevant statements among these provided statements. For example, EndtoEnd Memory Network [8] Ô¨Årst embeds (i.e., converting natural language into vector representation as in Word2Vec [16], Glove [17], FastText [18]) each statement sentence and query sentence. Then, using the attention mechanism, it Ô¨Ånds the most relevant sentence to the query from the set of statements. For example, as shown in Figure 2, the attention mechanism can identify that ‚Äú John moved to the garden. ‚Äù is the most relevant sentence for a query ‚Äú Where is John? ‚Äù by performing a similarity search using the embeddings. If multiple sentences are required to answer the question, it updates the query with the relevant sentence found in the previous iteration and utilizes the attention mechanism again to retrieve other relevant sentences from the set. After obtaining all relevant sentences, it utilizes a Ô¨Ånal weight matrix to generate the Ô¨Ånal answer. B. Cost of Attention Mechanism For a given nandd, an attention operation requires i) ndmultiplications and n(d"
283,ReluDiff: Differential Verification of Deep Neural Networks.txt,"As deep neural networks are increasingly being deployed in practice, their
efficiency has become an important issue. While there are compression
techniques for reducing the network's size, energy consumption and
computational requirement, they only demonstrate empirically that there is no
loss of accuracy, but lack formal guarantees of the compressed network, e.g.,
in the presence of adversarial examples. Existing verification techniques such
as Reluplex, ReluVal, and DeepPoly provide formal guarantees, but they are
designed for analyzing a single network instead of the relationship between two
networks. To fill the gap, we develop a new method for differential
verification of two closely related networks. Our method consists of a fast but
approximate forward interval analysis pass followed by a backward pass that
iteratively refines the approximation until the desired property is verified.
We have two main innovations. During the forward pass, we exploit structural
and behavioral similarities of the two networks to more accurately bound the
difference between the output neurons of the two networks. Then in the backward
pass, we leverage the gradient differences to more accurately compute the most
beneficial refinement. Our experiments show that, compared to state-of-the-art
verification tools, our method can achieve orders-of-magnitude speedup and
prove many more properties than existing tools.","As deep neural networks (DNNs) make their way into safety critical systems such as aircraft collision avoidance [ 17] and autonomous driving [ 3], where errors may lead to catastrophes, there is a grow ing need for formal verification. The situation is further exacerbated byadversarial examples [11,42], which are security exploits cre ated specifically to cause erroneous classifications [ 22,31,32,51]. There is also a growing need for reducing the size of the neural networks deployed on energy and computationconstrained de vices. Consequently, compression techniques [ 14] have emerged to prune unnecessary edges, quantize the weights of remaining edges, and retrain the networks, but they do not provide any formal guarantee ‚Äì typically the accuracy of a compressed network is only demonstrated empirically . While empirical evidence or statistical analysis may increase our confidence that a network behaves as expected for most of the inputs, they cannot prove that it does so for all inputs. Similarly, Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. ICSE ‚Äô20, May 23‚Äì29, 2020, Seoul, Republic of Korea ¬©2020 Association for Computing Machinery. ACM ISBN 9781450371216/20/05. . . $15.00 https://doi.org/10.1145/3377811.33803371.0 1.0 Œ¥n1,2 n1,1 n‚Ä≤ 1,1n‚Ä≤ 1,2 n‚Ä≤ 2,2n‚Ä≤ 2,1 n‚Ä≤ 3,1n3,1n2,1 n2,2n0,1 n0,2f f‚Ä≤ Figure 1: Differential verification of deep neural networks. while heuristic search and dynamic analysis techniques, including testing [ 25,35,43] and fuzzing [ 33,49,50], may quickly discover ad versarial examples, they cannot prove the absence of such examples. At the same time, while stateoftheart verification techniques [ 8‚Äì 10,16,19,29,37,40,44], including Reluplex [18],ReluVal [45] andDeepPoly [39], can provide formal proofs, they are designed for analyzing a single network as opposed to the relationship between two networks. In this work, we focus on differential verification of two closely related networks. In this problem domain, we assume that fand f‚Ä≤are two neural networks trained for the same task; that is, they accept the same input xand are expected to produce the same out put. They are also structurally the same while differing only in the numerical values of edge weights (which allows us to analyze com pression techniques such as quantization and edge pruning [ 14]). In this context, differential verification is concerned with proving ‚àÄx‚ààX.|f‚Ä≤(x)‚àíf(x)|<œµ, where Xis an input region of inter est andœµis some reasonably small bound. This problem has not received adequate attention and, as we will show in this work, existing tools are illsuited for solving this problem. The key limitation of existing tools is that, since they are de signed to analyze the behavior of a single network, they do not have the ability to exploit the structural similarities of two closely related networks. They also have difficulty handling the constraint that the inputs to both fand f‚Ä≤are identical. Typically, these tools work by computing the conservative value ranges of all neurons from input to output in a layerbylayer style. In the early layers, they may be able to maintain relationships between the inputs, but as the functions become increasingly nonlinear in subsequent layers, approximations must be made. This ‚Äúeager‚Äù approximation means relationships between the inputs of fandf‚Ä≤are mostly lost, causing extremely large overapproximations in the output layer. 1arXiv:2001.03662v2  [cs.LG]  29 Jan 2020ICSE ‚Äô20, May 23‚Äì29, 2020, Seoul, Republic of Korea Brandon Paulsen, Jingbo Wang, and Chao Wang . . .x1 x2 y1y2. . .x1 x2 y‚Ä≤ 1y‚Ä≤ 2Parameters x1‚ààX1, x2‚ààX2, œµ Forward ‚àÜInterval Analysis Checkingœµ Safe VerifiedSampling Input SpaceBackward ‚àÜ‚àíRefinementX1 X2 ViolatedNo Violation CounterexampleDNN 1 DNN 2 ‚àÜ‚àíInterval Violation Figure 2: The differential verification flow of ReluDiff . In fact, stateoftheart verification tools that we have investi gated ( ReluVal [45] and DeepPoly [39]) struggle to verify that two identical networks are the same . To carry out this litmus test without drastically altering these tools, we construct a combined network as shown in Figure 1, where fandf‚Ä≤are actually the same network (i.e. same structure and edge weights). Since they share the same input x, we expect f(x)‚àíf(x)to be 0 regardless of the input region forx. While our method can easily prove that |f(x)‚àíf(x)|<œµ for an arbitrarily small œµin less than a second, none of the existing tools are able to do so. In fact, DeepPoly cannot verify it no matter how much time is given (it is not a complete method) and ReluVal times out after several hours. Figure 2 shows the overall flow of our method, ReluDiff , whose input consists of the two networks (DNN1 and DNN2), an input re gion ( x1‚ààX1andx2‚ààX2), and a bound œµon the output difference. There are three possible outcomes: (1) verified , meaning that the output difference is proved to be less than œµ; (2)falsified , meaning a counterexample is found; or (3) unknown , meaning that verification remains inconclusive due to bounds on the computing resources. Internally, ReluDiff iterates through two steps: a forward pass and a backward pass. The forward pass computes overapproximated value differences of corresponding neurons in the two networks, and propagates them layer by layer from the input to the output. If the output difference is within the region [‚àíœµ,œµ], the property is verified. Otherwise, ReluDiff samples a fixed number of concrete examples from the input space and tests if they violate the property. If a violation is found, the property is falsified; otherwise, ReluDiff enters the refinement phase. The goal of refinement is to identify an input region that should be divided into subregions. By using these subregions to perform the forward pass again, some of the forced overapproximations may be avoided, thus leading to significant accuracy increase. To identify the right input region for refinement, the backward pass computes the difference of the gradients of the two networks and uses it to find input regions that, once divided into subregions, are more likely to result in accuracy increase. While iterative interval analysis has been used in verifying neu ral networks before [ 45], the focus has always been on a singlenetwork. In this work, we show that, by focusing on both networks simultaneously, we can be more efficient and accurate compared to analyzing each network in isolation. Note that, in differential verification, the two networks have identical structures and simi lar behaviors; therefore, we can easily develop a correspondence between neurons in fand f‚Ä≤, thus allowing a lockstep style veri fication. Lockstep verification allows us to directly compute the differences in values of neurons and propagate these differences through edges. It also allows symbolic intervals to be used to avoid some of the approximations. Since error caused by approximation grows quickly, sometimes exponentially [ 44], as it is propagated through edges and neurons, this can significantly increase accuracy. When approximation must be made, e.g., due to nonlinearity of ReLU, we can handle them better by focusing on the value differ ences instead of the absolute values. For example, in ReluVal [45], if a symbolic expression that represents the ReLU input may be both positive and negative, the symbolic expression must be replaced by an interval with concrete upper and lower bounds, which intro duces additional error. In contrast, we can be more accurate: even if the input value of a neuron may be both positive and negative, in many cases we still can avoid introducing error into the difference. We have implemented ReluDiff in a tool and evaluated it on a number of feedforward neural network benchmarks, including ACAS Xu for aircraft collision avoidance [ 17], MNIST for hand written digit recognition [ 24], and HAR for human activity recog nition [ 1]. We also experimentally compared ReluDiff with state oftheart tools, including ReluVal [45] and DeepPoly [39]. Our experimental results show that, in almost all cases, ReluDiff out performs these existing tools in both speed and accuracy. In total, we evaluate on 842 properties over our benchmark networks. Re luDiff was often one to two ordersofmagnitude faster, and was able to prove 745 out of the 842 properties whereas none of the other tools can prove more than 413 properties. To summarize, we make the following contributions: ‚Ä¢We propose the first iterative symbolic interval analysis for differential verification of two neural networks. ‚Ä¢We develop a forward pass algorithm for more accurately computing the value differences for corresponding neurons. ‚Ä¢We develop a backward pass algorithm, based on gradient difference, for computing the refinement. ‚Ä¢We implement the method and demonstrate its advantages over existing tools in terms of both speed and accuracy. The remainder of the paper is organized as follows. First, we use examples to motivate our method in Section 2. Then, we review the basics of neural networks and interval analysis in Section 3. Next, we present our method for the forward pass in Section 4, followed by our method for the backward pass in Section 5. We present our experimental results in Section 6. We review the related work in Section 7. Finally, we give our conclusions in Section 8. 2 MOTIVATION We illustrate the problems of existing verification tools using ex amples and then highlight our main contributions. 2ICSE ‚Äô20, May 23‚Äì29, 2020, Seoul, Republic of Korea 1.9 1.1 2.1 1.02.1 0.9 1.11.01.0 1.0n0,1 n0,2 n1,2n1,1 n2,1 n2,2n3,1x1 x2y=f(x1,x2) Figure 3: A neural network with two inputs and one output. 2.1 Differential Verification Figure 3 shows a feedforward neural network with one input layer, two hidden layers, and one output layer. The input layer has two nodes n0,1andn0,2, corresponding to the two input variables x1 andx2. Each hidden layer consists of two neurons, n1,1,n1,2in one layer and n2,1,n2,2in the other layer. Each of these neurons has two computation steps: the affine transformation and the ReLU activation. For example, inside n1,1, the affine transformation is 1.9x1‚àí2.1x2and the ReLU activation is max(0,1.9x1‚àí2.1x2). The output layer has one node, representing the value of y=f(x1,x2). In general, fis a nonlinear function over x1andx2. In differential verification, we are concerned with the relation ship between f(x1,x2)and another network f‚Ä≤(x1,x2). For the sake of example, we focus on a network compression technique called quantiziation [14] in which the edge weights of fare rounded to the nearest whole number to obtain f‚Ä≤. However, we note that our method can be used on anytwo networks with similar struc tures, e.g., when f‚Ä≤is created using other techniques including edge pruning andnetwork retraining [14, 15, 17, 38]. These techniques, in general, raise the concern on how they affect the network‚Äôs behavior. In particular, we would like to verify that the new network produces outputs within some bound relative to the original network. Formally, let f‚Ä≤:X‚ÜíYbe the second network and f:X‚ÜíYbe the first network. We would like to verify that|f‚Ä≤(x)‚àíf(x)|<œµfor all x‚ààX, where X‚äÜXis some region of importance in the input domain X. 2.2 Existing Approaches Existing tools for verifying neural networks target only a single network at a time, and are often geared toward proving the absence ofadversarial examples . That is, given an input region of interest, they decide if the output stays in a desired region. For the network in Figure 3, in particular, the input region may be x1‚àà[4,6]and x2‚àà[1,5], and the desired output may be f(x1,x2)<15. However, these tools are not designed for verifying the relationship between two networks. While we could try and reuse them for our purpose, they lack the ability to exploit the similarities of the two networks. For example, we could use the existing tool ReluVal [45] on both fandf‚Ä≤to compare the concrete output intervals it computes for an input region of interest, e.g., [flow,fup]and[f‚Ä≤ low,f‚Ä≤up]. In order to conservatively estimate the difference between fand f‚Ä≤, we must assume the maximum difference falls in the interval [f‚Ä≤ low‚àífup,f‚Ä≤up‚àíflow]. In Figure 3, the interval difference would be[‚àí25.76,22.93], which is too large to be useful. Even though ReluVal could tighten the interval by refining the input intervals, this naive approach cannot even verify that1.9 2.1 1.1 1.02.1 0.9 1.11.01.0 1.0 2 1 111 12 12 1n0,1 n0,2n1,1 n1,2n2,1 n2,2n3,1 n‚Ä≤ 1,1 n‚Ä≤ 1,2n‚Ä≤ 2,1 n‚Ä≤ 2,2n‚Ä≤ 3,1Œ¥1 1x1 x2f‚Ä≤‚àíf Figure 4: Naive differential verification of the two networks. two identical networks always produce the same output, since the output intervals do not capture that the corresponding inputs to f and f‚Ä≤(i.e., values of x1andx2) are always the same. To compensate, we could encode the constraint that values of the corresponding inputs are always the same by composing fand f‚Ä≤ into a single feedforward network equivalent to f‚Ä≤‚àíf, as shown in Figure 4. In theory, a sound and complete technique would be able to verify, eventually , that the output difference is bounded by an arbitrarily small œµ, but with a caveat. That is, to maintain the relationships between the input variables and the difference in the outputs of the two networks, each neuron must remain in a linear state across the entire input region; other wise, approximation must be made to maintain the soundness of the interval analysis. However, approximation inevitably loses some of the relationships between the inputs and the outputs. Indeed, we constructed some merged networks in the same way as in Figure 4 and then fed them to existing tools. Unfortunately, they all exhibit the ‚Äúworstcase‚Äù value range blowup in the output. The key reason is that existing tools such as ReluVal are forced to approximate ReLU activations by concretizing, which is then followed by interval subtractions, thus causing error introduced by these approximations to be quickly amplified. The forward pass over fcomputes an output interval of [‚àí1.2x1‚àí1.1x2,‚àí1.1x1‚àíx2+19.53], and for f‚Ä≤it computes[‚àíx1‚àíx2,‚àíx1‚àíx2+20]. Although the equations are symbolic, the difference [‚àí21.36,19.13], computed conservatively by ReluVal , is still too large to be useful. 2.3 Our Method Existing tools cannot exploit structural and behavioral similarities of the two networks in differential verification. Our insight is to leverage such similarities to drastically improve both the efficiency and the accuracy of the verification tool. Specifically, in this work, we pair neurons and edges of the first network with those of the second network and then perform a lock stepverification. This allows us to focus on the value differences of the corresponding neurons as opposed to their absolute values. The benefit is that doing so results in both fewer and tighter ap proximations and more error reduction due to the use of symbolic 3ICSE ‚Äô20, May 23‚Äì29, 2020, Seoul, Republic of Korea Brandon Paulsen, Jingbo Wang, and Chao Wang n0,2n0,1 n1,2n1,1 n2,1 n2,2n3,11.9 1.1 2.1 1.02.1 0.9 1.11.01.0 1.0S(n1,1)=[‚àí2.2,9.3] S(n2,1)=[‚àí4.7,11.8] S(n1,2)=[5.4,11.6] S(n2,2)=[‚àí.2,2.6]x1‚àà[4,6] x2‚àà[1,5]Œ¥(x1)=[0,0] Œ¥(x2)=[0,0]Œ¥(n1,1)=[0,1.1] Œ¥(n1,2)=[‚àí.6,‚àí.4]Œ¥(n2,1)=[‚àí.53,3.02] Œ¥(n2,2)=[‚àí3.8,0]Œ¥(n3,1)=[‚àí.53,6.81] Figure 5: Forward interval analysis of a neural network. intervals. We also perform better refinement by focusing on inputs that have the greatest influence on the output difference, rather than the absolute output values. While focusing on the difference as opposed to absolute val ues seems to be a straightforward idea, there are many technical challenges. For example, there will be significantly more complex ReLU activation patterns to consider since we have to handle both networks simultaneously, instead of one network at a time. Approx imating symbolic intervals when considering the output difference of two ReLU activations (i.e., ReLU( x‚Ä≤)  ReLU( x)) has yet to be studied and is nontrivial. Furthermore, how to determine which input neuron to refine when the goal is to reduce error in the output difference between two networks has not been considered either. In this work, we develop solutions to overcome these challenges. During forward interval analysis, we carefully consider the ReLU activation patterns, and propose a technique for handling each pattern soundly while minimizing the approximation error. During the refinement, we compute the difference between gradients of the two networks, and use it to identify the input neuron most likely to increase the accuracy of the differential verification result. As a result, our method can solve the differential verification problems much more efficiently. Consider the litmus test of veri fying the equivalence of two identical networks. Our method can obtain a formal proof (that |f‚Ä≤‚àíf|<œµ) after performing the for ward interval analysis once; in contrast, all other existing tools have failed to do so. For the example in Figure 5, we can prove the output difference Œ¥(n3,1)is bounded by[‚àí0.53,6.81]after only the first pass. It also outperforms existing tools on other verification problems where f‚Ä≤is obtained from fthrough quantization; details of the experimental comparisons are in Section 6. 3 PRELIMINARIES First, we review the basics of interval analysis for neural networks. 3.1 Neural Networks We consider a neural network as a nonlinear function that takes some value in Rnas input and returns some value in Rmas output, where nis the number of input variables and mis the number of output variables. Let the network fbe denoted f:X‚ÜíY, where X‚äÜRnis the input domain and Y‚äÜRmis the output domain. In image recognition applications, for instance, Xmay be a vector of pixels representing an image and Ymay be a vector of probabilitiesfor class labels. In aircraft collision detection, on the other hand, X may be sensor data and Ymay be a set of actions to take. In this work, we consider fullyconnected feedforward networks with rectified linear unit (ReLU) activations, which are the most popular in practical hardware/software implementations. Thus, y=f(x)is a series of affine transformations (e.g., x¬∑W1=Œ£ixiw1,i) followed by pointwise ReLU (e.g., ReLU(x¬∑W1)=max(0,x¬∑W1)). LetWk, where 1‚â§k‚â§l, be the weight matrix associated with the kth layer, and lbe the number of layers; the affine transformation in the kth layer is a standard matrix multiplication, followed by the pointwise application of ReLU. Formally, f=fl(fl‚àí1(...f2(f1(x¬∑W1)¬∑W2))...¬∑Wl‚àí1), where each fk,1‚â§k‚â§l, is a pointwise ReLU. For the network in Figure 3, in particular, the input is a vector x={x1,x2}, the weight matrix W3={1.0,‚àí1.0}T, and x¬∑W1={1.9x1‚àí2.1x2,1.1x1+1.0x2}. For ease of presentation, we denote the weight of the edge from theith neuron of layer k‚àí1to the jth neuron of layer kasWk[i,j]. We also denote the jth neuron of layer kasnk,j. 3.2 Interval Analysis To ensure that our analysis is overapproximated, we use interval analysis [ 30], which can be viewed as a specific instantiation of the general abstract interpretation [ 5] framework. Interval analysis is wellsuited for analyzing ReLU neural networks as it has well defined transformers over addition, subtraction, and scaling (i.e., multiplication by a constant). Interval addition as denoted [a,b]+[c,d]=[a+c,b+d]does not lead to loss of accuracy. Scaling as denoted [a,b]‚àóc=[a‚àóc,b‚àóc] when c‚â•0, or[a,b]‚àóc=[b‚àóc,a‚àóc]when c<0, does not lead to loss of accuracy either. Interval subtraction as denoted [a,b]‚àí[c,d]=[a‚àíd,b‚àíc], however, may lead to accuracy loss. To illustrate, consider f(x)=2.1xand f‚Ä≤(x)=2x, and say we want to approximate their difference for the input region x‚àà [‚àí1,1]. Using interval arithmetic, we would compute f([‚àí1,1])‚àí f‚Ä≤([‚àí1,1])=[‚àí2.1,2.1]‚àí[‚àí 2,2]=[‚àí4.1,4.1]. Clearly this is far from the exact interval of f(x)‚àíf‚Ä≤(x)=2.1x‚àí2x=0.1xover x‚àà[‚àí1,1], which is[‚àí0.1,0.1]. The reason for such loss of accuracy is that, during interval arithmetic, the relationship between values of2.1xand2x(i.e., they are for the same value of x) is lost. 3.3 Symbolic Interval One way to overcome the accuracy loss is using symbolic inter vals [45], which can encode the constraint that inputs to fand f‚Ä≤are actually related. With this technique, we would use the symbol xwith the constraint x‚àà[‚àí 1,1]to initialize the input intervals. Then, the computation becomes f([x,x])‚àí f‚Ä≤([x,x])= [2.1x,2.1x]‚àí[2x,2x]=[0.1x,0.1x]. Finally, we would compute the upper and lower bounds for x‚àà[‚àí1,1]and return the precise interval[‚àí0.1,0.1]. Unfortunately, symbolic intervals depend on fand f‚Ä≤being linear in the entire input region in order to be sound. Indeed, if we add ReLU to the functions, i.e., ReLU(f(x))=max(0,2.1x)and ReLU(f‚Ä≤(x))=max(0,2x), where x‚àà[‚àí1,1], then the lower and upper bounds are no longer precise nor sound. The reason is because max(0,2.1x)is nonlinear in x‚àà[‚àí1,1]. Thus, we have to approx imate using the concrete interval [0,2.1]. Similarly, max(0,2x)is approximated using [0,2]. Thus,[0,2.1]‚àí[0,2]=[‚àí2,2.1]. 4ICSE ‚Äô20, May 23‚Äì29, 2020, Seoul, Republic of Korea . . .nk‚àí1,1 nk,j nk‚àí1,iWk[1,j] Wk[i,j]layer k‚àí1 layer k Figure 6: Diagram of weight notations. 3.4 Refinement To improve the accuracy of the symbolic interval analysis, we need to divide the input region into subregions. The intuition is that, within a smaller subregion, the ReLU is less likely to exhibit non linear behavior and force the analyzer to overapproximate. Con sider ReLU(2.1x)=max(0,2.1x), where x‚àà [‚àí 1,1]. After the input region is divided into subregions x‚àà[‚àí1,0]‚à™[0,1], we have max(0,2.1x)=[0,0]forx‚àà[‚àí1,0]andmax(0,2.1x)=[2.1x,2.1x] forx‚àà[0,1]. In both cases, the intervals are precise ‚Äì there is no approximation at all. When we only have one input variable, we do not have a choice on which variable to refine. However, neural networks have many inputs, and refining some of them will not always yield benefit. Thus, we have to identify the right input to split. Consider f(x1,x2)=ReLU(5x1)+ReLU(2x2)‚àíReLU(x2), where x1‚àà[1,3]andx2‚àà[‚àí1,1]. The initial analysis is not very accu rate due to approximations caused by the ReLU: ReLU(5‚àó[1,3])+ ReLU(2‚àó[‚àí1,1])+ReLU([‚àí1,1])=ReLU([5,15])+ReLU([‚àí2,2])+ ReLU([‚àí1,1])=[5,15]+[0,2]‚àí[0,1]=[4,17]. If we split x1‚àà[1,3]into x1‚àà[1,2]‚à™[2,3]and perform interval analysis for both subregions, the output would be [4,12]‚à™[9,17]= [4,17], which does not improve over the initial result. In contrast, if we split x2‚àà[‚àí1,1]into x2‚àà[‚àí1,0]‚à™[0,1], the accuracy would improve significantly. Since the ReLU is always activated for x2‚àà[0,1],ReLU(2x2)andReLU(x2)can be repre sented by[2x2,2x2]and[x2,x2], respectively, and ReLU(2x2)‚àí ReLU(x2)=[x2,x2]=[0,1]. Since the ReLU is always deactivated forx2‚àà[‚àí1,0], we have ReLU(2x2)‚àíReLU(x2)=[0,0]. Thus, the combined output[5,15]‚à™[5,16]=[5,16]is more accurate than the initial approximation [4,17]. While how to analyze nonlinear activation functions such as ReLU has been studied in prior work [ 19,39,44], none of the ex isting techniques touch upon the complex scenarios arising from differential verification of two closely related networks. Our work fills the gap. Specifically, we propose a more accurate forward pass for the interval analysis (Section 4) and a more accurate backward pass for the refinement (Section 5). 4 FORWARD INTERVAL ANALYSIS In this section, we describe our forward pass for computing the value differences between neurons in the two networks. Recall that network fhasllayers and weight matrices Wk,1‚â§k‚â§l, and nk,jis the jth node in the kth layer. Furthermore, Wk[i,j]is the weight of the edge from nk‚àí1,itonk,j. We illustrate these notations in Figure 6. Similarly, network f‚Ä≤has weight matrices W‚Ä≤ k, nodesInput: network f, network f‚Ä≤, input region X Result: difference{Œ¥(nl,j)}for output Initialize{S(n0,j)},{S(n‚Ä≤ 0,j)}to input region Xand{Œ¥(n0,j)}to0 forkin1..NLayerdo // Affine transformer forjin1..layerSize[k] do Sin(nk,j)‚Üê√ç iS(nk‚àí1,i)¬∑Wk[i,j] Sin(n‚Ä≤ k,j)‚Üê√ç iS(n‚Ä≤ k‚àí1,i)¬∑W‚Ä≤ k[i,j] Œ¥in(nk,j)‚Üê√ç i(S(nk‚àí1,i)¬∑W‚àÜ k[i,j]+Œ¥(nk‚àí1,i)¬∑W‚Ä≤ k[i,j]) end ifk =NLayerthen return {Œ¥in(nk,j)} end // ReLU transformer forjin1..layerSize[k] do ‚ü®S(nk,j),S(n‚Ä≤ k,j),Œ¥(nk,j)‚ü©‚Üê ReLuTransform(Sin(nk,j),Sin(n‚Ä≤ k,j),Œ¥in(nk,j)) end end Algorithm 1: Forward symbolic interval analysis. n‚Ä≤ k,j, and weights W‚Ä≤ k[i,j]. Let W‚àÜ k[i,j]be the weight difference, i.e W‚àÜ k[i,j]=W‚Ä≤ k[i,j]‚àíWk[i,j]. We now define notations for the interval values of neurons. Since each neuron nk,jhas an affine transformation (multiplying by the incoming weights) and a ReLU, we denote the input interval to the neuron (after applying the affine transform) as Sin(nk,j), and we denote the output interval of the neuron (after applying the ReLU) asS(nk,j). We denote the interval bound on the difference between the inputs to n‚Ä≤ k,jandnk,jasŒ¥in(nk,j), and we denote the interval difference between the outputs as Œ¥(nk,j). Finally, we denote the symbolic upper and lower bound of any value using the notation UB"
213,PRIMA: General and Precise Neural Network Certification via Scalable Convex Hull Approximations.txt,"Formal verification of neural networks is critical for their safe adoption in
real-world applications. However, designing a precise and scalable verifier
which can handle different activation functions, realistic network
architectures and relevant specifications remains an open and difficult
challenge. In this paper, we take a major step forward in addressing this
challenge and present a new verification framework, called PRIMA. PRIMA is both
(i) general: it handles any non-linear activation function, and (ii) precise:
it computes precise convex abstractions involving multiple neurons via novel
convex hull approximation algorithms that leverage concepts from computational
geometry. The algorithms have polynomial complexity, yield fewer constraints,
and minimize precision loss. We evaluate the effectiveness of PRIMA on a
variety of challenging tasks from prior work. Our results show that PRIMA is
significantly more precise than the state-of-the-art, verifying robustness to
input perturbations for up to 20%, 30%, and 34% more images than existing work
on ReLU-, Sigmoid-, and Tanh-based networks, respectively. Further, PRIMA
enables, for the first time, the precise verification of a realistic neural
network for autonomous driving within a few minutes.","The growing adoption of neural networks (NNs) in many safety critical domains highlights the importance of providing formal, deterministic guarantees about their safety and robustness when deployed in the real world [Szegedy et al .2014]. While the last few years have seen significant ‚àóEqual contribution Authors‚Äô addresses: Mark Niklas M√ºller, Department of Computer Science, ETH Zurich, Zurich, Switzerland, mark.mueller@ inf.ethz.ch; Gleb Makarchuk, Department of Computer Science, ETH Zurich, Zurich, Switzerland, gleb.makarchuk@gmail. com; Gagandeep Singh, UIUC and VMware Research, United States, ggnds@illinois.edu, gasingh@vmware.com; Markus P√ºschel, Department of Computer Science, ETH Zurich, Switzerland, pueschel@inf.ethz.ch; Martin Vechev, Department of Computer Science, ETH Zurich, Zurich, Switzerland, martin.vechev@inf.ethz.ch. Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for thirdparty components of this work must be honored. For all other uses, contact the owner/author(s). ¬©2022 Copyright held by the owner/author(s). 24751421/2022/1ART43 https://doi.org/10.1145/3498704 Proc. ACM Program. Lang., Vol. 6, No. POPL, Article 43. Publication date: January 2022.arXiv:2103.03638v3  [cs.AI]  28 Feb 202243:2 Mark Niklas M√ºller, Gleb Makarchuk, Gagandeep Singh, Markus P√ºschel, and Martin Vechev SingleNeuron (a)Disjunct MultiNeuron (b)Overlapping MultiNeuron (c)Optimal Convex (d) Fig. 1. Illustration of the tightness of different abstraction strategies, for a layer of four neurons (grey dots). Strong interdependencies between neurons that can be captured directly or indirectly are shown as solid or dashed lines, respectively. Individual singleneuron, multineuron or optimal convex abstractions are illustrated in blue and the resulting overall layerwise abstraction in green. progress in formal verification of NNs, existing deterministic methods (see Urban and Min√© [2021] for a survey) still either do not scale to or are too imprecise when handling realistic networks. ùë•ùë¶ ùëôùë• ùë¢ùë•ùë¶‚â§ùë¢ùë• ùë¢ùë•‚àíùëôùë•(ùë•‚àíùëôùë•) ùë¶‚â•0ùë¶‚â•ùë•ùë¶=max(0,ùë•) Fig. 2. Convex singleneuron approximation (blue) of a ReLU (black) with bounded inputs ùë•‚àà[ùëôùë•,ùë¢ùë•].Key challenge: handling nonlinearities. Neural networks interleave affine and nonlinear activa tion layers (e.g., ReLU, Sigmoid), leading to highly nonlinear behaviours. Because affine layers can be captured exactly using linear constraints, the key challenge in neural network verification rests in designing methods that can handle the effect of these nonlinear activations in a precise and scalable manner. Exact verification, e.g., [Anderson et al .2019, 2020; Bunel et al .2020b; Ehlers 2017; Katz et al . 2017; Singh et al .2019c; Tjeng et al .2019; Wang et al .2018, 2021], has, in the worstcase, exponential complexity in the (large) number of nonlinear activations due to a combinatorial blowup of case distinctions (e.g., for ReLUs) and complex shapes for general activations (e.g., for Sigmoids). Therefore exact verifiers typically only handle piecewise linear activations and do not scale to larger networks. To overcome this limitation, stateoftheart verifiers, e.g., [Singh et al .2019a,b; Tjandraatmadja et al.2020; Weng et al .2018; Xu et al .2020; Zhang et al .2018], often sacrifice completeness for scalability and leverage abstract interpretation [Cousot 1996] to overapproximate the effect of each activation layer with convex polyhedra. Naturally, the scalability and precision of these incomplete methods are tied to the particular polyhedral fragment they utilize. Below, we contrast different stateoftheart abstraction approaches with our work by comparing the strong interneuron dependencies they can capture directly or indirectly, illustrated as solid or dashed lines, respectively, in Figure 1 for a layer of four neurons. Individual abstractions are visualized in blue and the resulting layerwise shape in green. Optimal convex approximation. Assume a layer of ùëõneurons, each applying the scalar, univariate, nonlinear activation function ùëì:R‚ÜíRand the most precise polyhedral abstraction Pof the layer‚Äôs inputs ùíô. The most precise convex abstraction of the layer output is then given by the convex hull of all inputoutput vector pairs conv({(ùíô,ùíá(ùíô))|ùíô‚ààP‚äÜ Rùëõ}), illustrated in Figure 1 (d), where all interactions are fully captured. Computing this 2ùëõdimensional convex hull, however, is intractable due to the exponential cost O(ùëõùë£log(ùëõùë£)+ùëõùëõ ùë£)[Chazelle 1993] in the number of neurons ùëõ, where the number of vertices ùëõùë£=O(ùëõùëõ ùëê)of the input polytope Pis at worst also exponential in ùëõ[Seidel 1995] ( ùëõùëêis the number of constraints of the input polytope P). Proc. ACM Program. Lang., Vol. 6, No. POPL, Article 43. Publication date: January 2022.PRIMA: General and Precise Neural Network Certification via Scalable Convex Hull Approximations 43:3 SingleNeuron approximation. Most incomplete verifiers are fundamentally based on single neuron convex abstractions, i.e., activations are approximated separately. The tightest singleneuron abstractions maintain upper and lower bounds ùëôùë•,ùë¢ùë•for each input ùë•and compute convex hulls of all inputoutput tuples: conv({(ùë•,ùëì(ùë•))|ùë•‚àà[ùëôùë•,ùë¢ùë•]‚äÜR}), as illustrated in Figure 2 for a ReLU. The union of the obtained constraints is the final abstraction of the layer. Geometrically, it is the Cartesian product of the convex hulls for each ReLU. This abstraction is significantly larger in volume (exponential in ùëõ) than the optimal convex hull discussed earlier, the key reason being that the interdependencies between neurons in the same layer are ignored, as illustrated in Figure 1 (a). Thus, the approximation error can grow exponentially with each layer, accumulating significant imprecision. MultiNeuron approximation. To mitigate this limitation for ReLU networks, recent works [Palma et al.2021; Singh et al .2019a; Tjandraatmadja et al .2020] introduced multineuron abstractions as a first compromise between the optimal but intractable layerwise and the imprecise but scalable neuronwise abstraction. Singh et al .[2019a] partition the neurons of an activation layer into small sets of size ùëõùë†‚â§5, form groups of ùëò‚â§3neurons for each partition, approximate the group‚Äôs input with octahedra [Claris√≥ and Cortadella 2007], and then compute exact convex hulls jointly approximating the output ofùëòReLUs for this input. These exact convex hull computations are computationally expensive and yield complex constraints, limiting the approach to only a few, mostly disjoint neuron groups, and restricting the number of captured dependencies, see Figure 1 (b). Tjandraatmadja et al .[2020] and Palma et al .[2021] merge the activation layer with the preceding affine layer and compute a convex approximation over the resulting multivariate activation layer for a hyperbox approximation of its input. This coarse input abstraction effectively restricts their approach to interactions over a single affine layer at a time. While both approaches currently yield stateoftheart precision, they are limited to ReLU activations and lack scalability as they require small instances of the NPhard convex hull problem to be solved exactly or large instances to be solved partially. They also do not address the problem of capturing enough neuron interdependencies within a layer to come as close as possible to the optimal convex abstraction. This work: precise multineuron approximations. In this work, we present the first general verifi cation framework for networks with arbitrary, bounded, multivariate activation functions called Prima (PRecIse Multineuron Abstraction). Prima builds on the groupwise approximations from Singh et al .[2019a] and leverages the key insight that most interdependencies between neurons can be captured by considering a large number of relatively small, overlapping neurongroups. While not achieving the tightness of the optimal convex approximation, Prima yields much tighter layerwise approximations than previous methods, as shown in Figure 1 (c). The key technical contributions of our work are: (i) PDDM (Partial Double Description Method) ‚Äì a general, precise, and fast convex hull approximation method for polytopes that enables the consideration of many neuron groups, and (ii) SBLM (SplitBoundLift Method) ‚Äì a novel decompo sition approach that builds upon the PDDM to quickly compute multineuron constraints. While we combine these methods with abstraction refinement approaches in Prima , we note that they are also of general interest (beyond neural networks) and can be used independently of each other. Prima can be applied to any network with bounded, multivariate activation functions and arbitrary specifications expressible as polyhedra such as individual fairness [Ruoss et al .2020b]; global safety properties [Katz et al .2017]; and acoustic [Ryou et al .2020], geometric [Balunovic et al.2019], spatial [Ruoss et al .2020a], and ‚Ñìùëùnorm bounded perturbations [Gehr et al .2018]. Our experimental evaluation shows that Prima achieves stateoftheart precision on the majority of our ReLUbased classifiers while remaining competitive on the rest. For Sigmoid and Tanhbased networks, Prima significantly outperforms prior work on all benchmarks. Further, Prima enables, for the first time, precise and scalable verification of a realistic architecture for autonomous driving Proc. ACM Program. Lang., Vol. 6, No. POPL, Article 43. Publication date: January 2022.43:4 Mark Niklas M√ºller, Gleb Makarchuk, Gagandeep Singh, Markus P√ºschel, and Martin Vechev containing >100k neurons in a regression setting. Finally, while Prima is incomplete, it can be used for boosting the scalability of stateoftheart complete verifiers [Singh et al .2019c; Wang et al. 2021] for ReLUbased networks that benefit from more precise convex abstractions. Main contributions. Our key contributions are: (1)PDDM, a precise method for approximating the convex hull of polytopes, with worstcase polynomial time and spacecomplexity and exactness guarantees in low dimensions. (2)SplitBoundLift Method, a technique which efficiently computes joint constraints over groups of nonlinear functions, by decomposing the underlying convex hull problem into lowerdimensional spaces. (3)Prima , a novel verifier combining these approaches with a sparse neuron grouping technique and abstraction refinement, to obtain the first multineuron verifier for arbitrary, bounded, multivariate nonlinear activations (e.g., ReLU, Sigmoid, Tanh, and MaxPool). (4)An evaluation of Prima on a range of activations and network architectures (e.g., fully connected, convolutional, and residual). We show that Prima is significantly more precise than stateoftheart, with gains of up to 20%, 30%, and 34% for ReLU, Sigmoid, and Tanh based networks, while being effective in a regression setting, scaling to large networks, and enabling verification in realworld settings such as autonomous driving. We release our code as part of the opensource framework ERAN at https://github.com/ethsri/eran. 2 BACKGROUND In this section, we establish the terminology we use to discuss polyhedra, neural networks (NNs) and their verification. Notation. We use lower case Latin or Greek letters ùëé,ùëè,ùë•,...,ùúÜ,... for scalars, bold for vectors ùíÇ, capitalized bold for matrices ùë®, and calligraphicAor blackboard bold Afor sets. Similarly, we denote scalar functions as ùëì:Rùëë‚ÜíRand vector valued functions bold as ùíá:Rùëë‚ÜíRùëò. Neural networks. We focus our discussion on networks ùíâ(ùíô):X‚ÜíR|Y|that map input samples (images) ùíô‚ààXto numerical scores ùíö‚ààR|Y|. For a classification task, the network ùíâclassifies an input ùíôby applying argmax to its output: ùëê(ùíô)=arg maxùëóùíâ(ùíô)ùëó. While our methods can refine the abstraction of activation functions in arbitrary neural architectures [Xu et al .2020], for simplicity, we discuss a feedforward architecture which is an interleaved composition of affine functions ùíà(ùíô)=ùëæùíô+ùíÉ, such as normalization, linear, convolutional, or average pooling layers, with nonlinear activation layers ùíá(ùíô)such as ReLU, Tanh, Sigmoid, or MaxPool: ùíâ(ùíô)=ùíàùêø‚ó¶ùíáùêø‚ó¶ùíàùêø‚àí1‚ó¶...‚ó¶ùíá1‚ó¶ùíà0(ùíô). 2.1 Neural Network Verification Prima is an optimizationbased verification approach and supports any safety specification (pre and postcondition) which can be expressed as a convex polyhedron. Examples of such specifications include but are not limited to individual fairness [Ruoss et al .2020b], global safety properties [Katz et al.2017], acoustic [Ryou et al .2020], geometric [Balunovic et al .2019], spatial [Ruoss et al .2020a], and‚Ñìùëùnorm bounded perturbations [Gehr et al. 2018]. At its core, Prima is based on accumulating linear constraints encoding the whole network for a given (convex) precondition, defining a linear optimization objective representing the property to be verified, and finally using an LP solver to derive a bound on this objective. If this bound satisfies a predetermined threshold (that depends on the property), the property is verified. While all affine layers (e.g., linear, convolutional, and normalization layers) can be encoded exactly using linear constraints, nonlinearities have to be overapproximated via constraints in their inputoutput space. That is, for an activation layer ùíá:Rùëõ‚ÜíRùëëand a given set of inputs Proc. ACM Program. Lang., Vol. 6, No. POPL, Article 43. Publication date: January 2022.PRIMA: General and Precise Neural Network Certification via Scalable Convex Hull Approximations 43:5 Pin‚äÜRùëõ, we need to derive sound output constraints, that represent a set Pinout‚äÜRùëë+ùëõwhich includes all possible inputoutput pairs that can be obtained by applying ùíáto the inputs inPin. We show an overapproximation for a single ReLU in Figure 2. In the concrete, the ReLU maps inputùë•toùë¶=max(0,ùë•). If the bounds 0>ùëôùë•‚â§ùë•‚â§ùë¢ùë•>0are known, the best convex approximation is given by the blue triangle. In this work we present novel methods to compute tighter shapes by considering multiple neurons jointly in a higher dimensional space. 2.2 Overview of Convex Polyhedra We now introduce the necessary background on polyhedra. A polyhedron can be represented as the convex hull of its extremal points, called the vertex or Vrepresentation, or as the subspace satisfy ing a set of linear constraints, called the halfspace constraint or Hrepresentation. Simultaneously maintaining both representations of the same polyhedron is called double description. Vertex representation. A polyhedronP‚äÜRùëëis the closed convex hull of a set of generators called verticesR={ùë•ùëñ‚ààRùëë}: P=P(R) =‚àëÔ∏Å ùëñùúÜùëñùíôùëñ|ùíôùëñ‚ààR,‚àëÔ∏Å ùëñùúÜùëñ=1, ùúÜùëñ‚ààR+ 0 , where R+ 0are the positive real numbers including 0. A polyhedral cone P‚äÜRùëëis the positive linear span of a set of generators called rays R={ùë•ùëñ‚ààRùëë}and always includes the origin: P=P(R) =‚àëÔ∏Å ùëñùúÜùëñùíôùëñ|ùíôùëñ‚ààR, ùúÜùëñ‚ààR+ 0 . Halfspace representation. Alternatively, a polyhedron can be described as the set P‚äÜRùëësatisfying a system of linear inequalities (or constraints) defined by ùë®‚ààRùëö√óùëëandùíÉ‚ààRùëö: P=P(ùë®,ùíÉ)‚â°{ ùíô‚ààRùëë|ùë®ùíô‚â•ùíÉ}. Geometrically,Pis the intersection of ùëöclosed affine halfspaces Hùëñ={ùë•‚ààRùëë|ùíÇùëñùíô‚â•ùëèùëñ}with ùíÇùëñ‚ààRùëëandùëèùëñ‚ààR. For a polyhedral cone we have ùíÉ=0. For convenience, a polyhedron P(ùë®,ùíÉ) can be equivalently described in socalled homogenized coordinates ùíô‚Ä≤=[1,ùíô], where it can be expressed asP(ùë®‚Ä≤)={ùíô‚Ä≤‚ààRùëë+1|ùë®‚Ä≤ùíô‚Ä≤‚â•0}with the new constraint matrix ùë®‚Ä≤=[‚àíùíÉ,ùë®]. AùëòfaceFof aùëëdimensional polyhedron is a ùëòdimensional subset F ‚äÜP satisfyingùëë‚àíùëò linearly independent constraints1with equality. We call a 0face a vertex and a ( ùëë‚àí1)face a facet [Edelsbrunner 2012]. The rank of a ray or vertex in a ùëëdimensional polyhedron is the number of linearly independent constraints it satisfies with equality. We call a ray of rank ùëë‚àí1and a vertex of rankùëëextremal. A ray of rank ùëë‚àíùëõcan be represented as the positive combination of ùëõextremal rays and a vertex of rank ùëë‚àíùëõas the convex combination of ùëõ+1extremal points. Double description. Polyhedra static analysis [Fukuda and Prodon 1995; Motzkin et al .1953; Singh et al.2017] usually maintains both representations ( HandV) in a pair(ùë®‚Ä≤,R), called double description. This is useful as computing the convex hull in the Vrepresentation is trivial (union of generator sets), but computing intersections is NPhard. Conversely, computing intersections in theHrepresentation is trivial (union of constraints), but computing the convex hull is NPhard. The transformation from the V to theHrepresentation is called the convex hull problem and the reverse the vertex enumeration problem. Both are NPhard in general. Inclusion. We define the inclusion of a polytope Qin a polytopePas:Q‚äÜP or equivalently, ‚àÄùíô‚ààQ,ùíô‚ààP. In this setting, we say Poverapproximates QandQunderapproximates P. 1We call a set of constraints ùíÇùëñùíô‚â•ùëèùëñlinearly independent, if the ùíÇùëñare linearly independent. Proc. ACM Program. Lang., Vol. 6, No. POPL, Article 43. Publication date: January 2022.43:6 Mark Niklas M√ºller, Gleb Makarchuk, Gagandeep Singh, Markus P√ºschel, and Martin Vechev 3 OVERVIEW OF PRIMA We now present an overview of Prima , our framework for faster and more precise verification of neural networks with arbitrary, bounded, multivariate, nonlinear activations. We provide a complete formal description of its main components PDDM and SBLM in Sections 4 and 5, and of Prima in Section 6. In our explanations, we follow the setup outlined in Section 1: an activation layer consisting of ùëõneurons representing nonlinear activations ùëì(ùë•)(e.g., ReLU, Tanh, Sigmoid). Computing a convex approximation of a whole layer. Conceptually, given an ùëõdimensional polytopeSconstraining the input to the activation layer, Prima computes a set of multineuron constraints, forming a convex overapproximation of this layer, as follows: (1)Group decomposition: Decompose the set of ùëõactivations in the layer into overlapping groups (subsets) of size ùëò. (2)Octahedral projection: For each such group ùëñ, compute an octahedral overapproximation Pùëñ of the projection of Sto the inputspace of group ùëñ. (3)SplitBoundLift Method (SBLM): Then, for each polytope Pùëñ, compute a joint convex over approximationKùëñof the group output in the Hrepresentation using our novel SBLM method. This method decomposes the problem into lower dimensions and leverages our novel Partial Double Description Method (PDDM) with polynomial complexity to compute fast and scalable convex hull approximations. Both SBLM and PDDM are also key to making Prima applicable to nonpiecewiselinear activations. (4)Combine constraints: Finally, take the intersection of all output constraints Kùëñ(a union of all constraints) to obtain an overapproximation of the entire layer output. Verification is performed by solving an LP problem which combines the generated multineuron constraints with an LP encoding of the whole network (evaluated in Section 7). We now explain the basic workings of each step and illustrate the key concepts on a running example. Group decomposition. Computing convex hulls for large sets of activations (e.g., a whole layer) is infeasible. Thus, we consider groups of size ùëò, typicallyùëò=3or4. The key idea here is to capture dependencies between activation inputs and outputs ignored by neuronwise approximations and thus achieve tighter approximations. The tightness increases with the number of groups and, importantly, the degree of overlap between them. Considering all possible"
489,Anti-Neuron Watermarking: Protecting Personal Data Against Unauthorized Neural Networks.txt,"We study protecting a user's data (images in this work) against a learner's
unauthorized use in training neural networks. It is especially challenging when
the user's data is only a tiny percentage of the learner's complete training
set. We revisit the traditional watermarking under modern deep learning
settings to tackle the challenge. We show that when a user watermarks images
using a specialized linear color transformation, a neural network classifier
will be imprinted with the signature so that a third-party arbitrator can
verify the potentially unauthorized usage of the user data by inferring the
watermark signature from the neural network. We also discuss what watermarking
properties and signature spaces make the arbitrator's verification convincing.
To our best knowledge, this work is the first to protect an individual user's
data ownership from unauthorized use in training neural networks.","Recent advances in machine learning techniques have put personal data at sig nificant risk. For example, in the scandal of ‚ÄúCambridge Analytica‚Äù [45], millions of users‚Äô data are collected without consent to train machine learning models for political advertising. To protect personal data and privacy, there have been some legislations in place, such as Europe General Data Protection Regulation [12] (ef fective in May 2018), California Privacy Act [2] (effective in January 2021), and China Data Security Law [40] (effective in July 2021). They often require that personal data should be ‚Äúprocessed lawfully, fairly and in a transparent manner‚Äù and can only be used ‚Äúadequately, relevantly and limited to what is necessary in relation to the purposes (‚Äòdata minimisation‚Äô)‚Äù [12]. However, there is a lack of methods for detecting personal data breaches from machine learning models, which have increasingly become the primary motivation for a violator to break a user‚Äôs data ownership because the models‚Äô efficacy heavily depends on data. This paper studies personal image protection (PIP) from unauthorized usage in training deep neural networks (DNNs). The need for PIP arises when users expose their images to digital products and cloud services. In the era of big data and deep learning, a critical concern is that DNN learners may violate users‚Äô intents by using their data to train DNNs without authorization. It becomes worse when the DNN models consequently leak private user information [1, 10, 33,37]. However, how can ordinary users know whether their images, which couldarXiv:2109.09023v2  [cs.CR]  1 Aug 20222 Z. Zou et al. be a tiny portion of the DNN learner‚Äôs complete training set, have been used to train a DNN model? Traditionally, PIP aims to prevent a user‚Äôs images from duplicating, remixing, or exploiting (e.g., for a financial incentive) without the user‚Äôs consent and relies on digital watermarking [5,23,29,42,49,54]. The digital watermarking enables a user to imprint images with unique patterns, such as signatures, logos, or stamps, to track and identify unauthorized copies of their pictures. However, the rise of datadependent deep learning poses another need for PIP, namely, protecting a user‚Äôs images from unauthorized use in training DNNs. Could watermarking still fulfill this need? One inspiring observation is that some DNNs do ‚Äúmemorize‚Äù certain training examples [1,9,10] in various ways, offering a user an opportunity to watermark their images to make them memorizable by the DNNs. We say this watermark ing scheme is ‚Äúantineuron‚Äù because its objective is to facilitate a thirdparty arbitrator to verify a DNN‚Äôs use of a user‚Äôs images in training and then hold the DNN learner accountable. However, we have to resolve two questions to make this antineuron watermarking work in practice. What watermarks make a user‚Äôs images memorizable by DNNs? How can the thirdparty arbitrator verify that the user‚Äôs images were indeed part of a DNN model‚Äôs training set? Fig. 1. Illustration of the antineuron watermarking for personal image protection (PIP) against unauthorized neural learners. To answer the above questions, we first use Figure 1 to formalize the anti neuron watermarking for PIP against unauthorized DNN learners. First, a user watermarks images using a private signature before sharing them with the pub lic (e.g., social media). An unauthorized learner then collects the user‚Äôs water marked images, along with images from other sources, to construct a training set to train a DNN image classifier. Finally, the user turns to a thirdparty ar bitrator to check whether their images were used to train the DNN model. TheAntiNeuron Watermarking 3 arbitrator tries to recover the user‚Äôs private signature for watermarking from the DNN model and the user‚Äôs original images with no watermark ‚Äî crucially, the arbitrator does not use the user‚Äôs private signature to recover it. The arbitrator concludes that the user‚Äôs images were part of the DNN‚Äôs training set if the user‚Äôs private signature can be recovered without knowing it in advance. This paper proposes an empirically effective approach to the antineuron wa termarking, and we leave more rigorous analyses to future work. In particular, a linear color transformation (LCT) in the hue space can be effectively used as a watermarking method. The resultant images remain as appealing as the original ones visually, so the unauthorized learner would not detect this type of water mark. Moreover, the LCT method is resilient to standard image augmentation techniques used in training neural models. Finally, we show that a DNN classifier indeed tends to memorize the LCT watermarking using extensive experiments. The arbitrator‚Äôs verification method is simply iterating over the signature space, watermarking the user‚Äôs original images using each signature, and returning the signature that reaches the lowest DNN classification loss. In summary, our main contribution is to formalize the problem of userfocused antineuron watermarking for personal image protection from unauthorized us age in training DNNs. Moreover, we propose the LCT watermarking for ordinary users and a straightforward verification method for the thirdparty arbitrator, demonstrating a successful antineuron watermarking scenario for PIP. Addi tionally, we raise some critical questions for furthering the study of PIP against DNN learners: 1) What types of watermarking can imprint DNNs the best, es pecially when a user‚Äôs watermarked images are only a tiny part of the training set? 2) What makes the imprinting of DNNs possible? Is it the DNN‚Äôs mem orization of training examples? 3) How can a trustworthy arbitrator recover a user‚Äôs private watermark from DNN and the user‚Äôs unwatermarked images? 4) How can antineuron watermarking work for multiple users? To the best of our knowledge, this work is the first to protect an individual user‚Äôs data ownership from unauthorized use in training neural networks. 2 Related Work "
28,Quantitative Verification With Neural Networks For Probabilistic Programs and Stochastic Systems.txt,"We present a machine learning approach to quantitative verification. We
investigate the quantitative reachability analysis of probabilistic programs
and stochastic systems, which is the problem of computing the probability of
hitting in finite time a given target set of states. This general problem
subsumes a wide variety of other quantitative verification problems, from the
invariant and the safety analysis of discrete-time stochastic systems to the
assertion-violation and the termination analysis of single-loop probabilistic
programs. We exploit the expressive power of neural networks as novel templates
for indicating supermartingale functions, which provide general certificates of
reachability that are both tight and sound. Our method uses machine learning to
train a neural certificate that minimises an upper bound for the probability of
reachability over sampled observations of the state space. Then, it uses
satisfiability modulo theories to verify that the obtained neural certificate
is valid over every possible state of the program and conversely, upon
receiving a counterexample, it refines neural training in a
counterexample-guided inductive synthesis loop, until the solver confirms the
certificate. We experimentally demonstrate on a diverse set of benchmark
probabilistic programs and stochastic dynamical models that neural indicating
supermartingales yield smaller or comparable probability bounds than existing
state-of-the-art methods in all cases, and further that the approach succeeds
on models that are entirely beyond the reach of such alternative techniques.","Probabilistic Programs. Probabilistic programs extend imperative programs with the ability to sample from probability distributions [ 18,27,38,48], which provide an expressive language for modelling applications such as randomised algorithms [ 11,23], robot motion planning [ 60], cryptographic protocols [ 10], and more generally for modelling and simulation of discretetime stochastic processes [35]. Quantitative Reachability Analysis. A fundamental problem in the formal verification of prob abilistic programs is to compute reachability probabilities [8,15,16,59]. More concretely, this requires us to compute the probability that an execution of a probabilistic program will reach a given subset of program configurations. By selecting the appropriate set of program configurations, we can express a variety of interesting quantitative verification questions in terms of computing reachability probabilities, such as computing the probability that a probabilistic loop terminates or violates an assertion [ 22,33,36,55,64], and computing the probability that a discretetime stochastic system, such as a robot moving across an environment, remains within a set of its safe configurations [ 13,16,64]. However, as we might expect for a question of such generality, the prob lem of determining exact reachability probabilities for probabilistic loops over infinite state spaces is an uncomputable problem, as it can be instantiated to the decision problem of (deterministic) termination. Therefore, algorithmic methods for reachability analysis of probabilistic programs consider the problem of bounding the probability of reaching a predetermined subset of states. 1arXiv:2301.06136v1  [cs.LO]  15 Jan 2023Abate et al. Supermartingale Certificates for Quantitative Reachability Analysis. A recent framework for bounding reachability probabilities for probabilistic programs is to provide a supermartingale that decreases in expectation outside of the target set , and serves as an indicator function for when the program state is in the target set. In previous literature, this is referred to as a non negative repulsing supermartingale [59], or stochastic invariant indicator [15], but here which we name indicating supermartingale (ISM) for clarity. The approach taken by stateoftheart tools for bounding reachability probabilities for probabilistic programs is to assume a template for the certificate (such as a linear or polynomial function over the variables in the program state), and then to reduce the synthesis problem to linear programming (for linear templates), or semidefinite programming (for polynomial templates). However, we note it is possible to construct simple programs that lack linear or polynomial indicating supermartingales, and that, even when they exist, they may yield a probability bound on the reachability probability that is too conservative. Neural Certificates in Verification. To overcome these limitations related to templatebased syn thesis of indicating supermartingales, we consider neural certificates for quantitative reachability. That is, we consider indicating supermartingales expressed as neural networks, which we refer to as neural indicating supermartingales . Widely applied in many areas of artificial intelligence, neural networks are increasingly used as representations of formal certificates for the correctness of systems. Previous work has applied machine learning to the formal verification of computer programs [3, 26, 40, 43, 45, 51, 61], and of dynamical and control systems [2, 14, 34, 44, 46, 53]. Our contribution is threefold. Theory We define the neural indicating supermartingale as a function of program state that allows deriving an upper bound for the probability of reachability. This neural certificate exclusively relies on knowledge of the postexpectation of the program and does not require additional pure invariants. Unlike previous approaches which rely on compact invariants for the formal synthesis of reachability certificates, we show our model exploits neural architectures with nonnegative output to guarantee soundness without using invariants. Methods We design an approach for synthesising neural indicating supermartingales that decou ples the task of finding a certificate, for which we use machine learning, from that of checking a certificate, for which we use SMT solving. We provide a programaware approach which exploits a symbolic description of the postexpectation to train neural indicating supermartin gales [ 24], and a programagnostic learning approach which estimates the postexpectation statistically. We instantiate our machine learning approach in a CEGIS loop that guarantees soundness. Experiments We build a prototype implementation of our method and compare the efficacy of neural indicating supermartingales with a stateoftheart method for the synthesis of indicating supermartingales entirely based on symbolic reasoning [ 15]. We demonstrate the advantage of using machine learning and neural indicating supermartingales certificates: they allow one to verify programs that lack polynomial certificates, and provide greater flexibility that attains tighter probability bounds. 2 QUANTITATIVE VERIFICATION OF PROBABILISTIC PROGRAMS 2.1 Infinitely Running Probabilistic Programs We consider quantitative verification questions for probabilistic programs that operate over real valued variables and that are defined in terms of the grammar in Fig. 1. Specifically, our probabilistic programs consist of the following components: 2Quantitative Verification With Neural Networks ùë£‚ààVars (variables) ùëÅ‚ààR (numerals) ùê∏::=ùë£|ùëÅ|ùê∏|ùê∏+ùê∏|ùê∏‚àíùê∏|ùê∏‚àóùê∏|... (arithmetic expressions) ùëÉ::=Bernoulli( ùê∏)|Gaussian(ùê∏,ùê∏)|... (probability distributions) ùêµ::=true|!ùêµ|ùêµ&&ùêµ|ùêµ||ùêµ|ùê∏==ùê∏|ùê∏<ùê∏|ùê∏<=ùê∏|... (Boolean expressions) ùê∂::=skip (update commands) |ùë£=ùê∏ (deterministic assignment) |ùë£‚àºùëÉ (probabilistic assignment) |ùê∂;ùê∂ (sequential composition) |ifùêµthenùê∂elseùê∂fi (conditional composition) Fig. 1. Grammar of update commands, Boolean and arithmetic expressions. Variables An ordered set Vars of realvalued variables with ùëõ=|Vars|, which in turn defines the state space Rùëõ. Under this definition, a state ùë†‚ààRùëõis anùëõdimensional tuple of reals. Initial Condition A Boolean expression ùêµ0, which in turn defines the initial set ùëÜ0‚äÜRùëõ, as the set of states for which expression ùêµ0evaluates to true. Update Command An update command ùê∂ùëàgenerated by the grammar of Fig. 1, where we consider every distribution associated with a probabilistic assignment as being obtained by applying the appropriate inverse transformation to a random variable uniformly distributed in the interval[0,1]. This defines the update function ùëì:Rùëõ√ó[0,1]ùëò‚ÜíRùëõ, whereùëòis the number of syntactic probabilistic assignment statements occurring in ùê∂ùëà. Altogether, our probabilistic program defines a stochastic process, whose behavior is determined by the update equations ùë†ùë°+1=ùëì(ùë†ùë°,ùëüùë°), ùëüùë°‚àºUùëò, ùë† 0‚ààùëÜ0, (1) where Uùëòdenotes the uniform distribution over the ùëòdimensional hypercube [0,1]ùëò. The state at time 0 is determined by the initial condition, and each subsequent state is determined by the previous state and ùëòrandom numbers sampled from the uniform distribution over [0,1]. We remark that our model of infinitely running probabilistic programs encompasses state dependent distributions (cf. Fig. 1, probability distributions). Probability distributions can be either discrete or continuous and may depend not only on constant parameters, but also on parameters that are determined from the system state. As such, parameters may depend on other distributions and thus define joint, multivariate and hierarchicallystructured distributions. To formalise our quantitative verification questions, we first describe the semantics of our probabilistic programs as a Markov chain over the probability space of infinite words of random samples. Namely, this is the probability space defined as (Œ©,F,P), where ‚Ä¢Œ©is the set of infinite sequences"
194,Automated Reachability Analysis of Neural Network-Controlled Systems via Adaptive Polytopes.txt,"Over-approximating the reachable sets of dynamical systems is a fundamental
problem in safety verification and robust control synthesis. The representation
of these sets is a key factor that affects the computational complexity and the
approximation error. In this paper, we develop a new approach for
over-approximating the reachable sets of neural network dynamical systems using
adaptive template polytopes. We use the singular value decomposition of linear
layers along with the shape of the activation functions to adapt the geometry
of the polytopes at each time step to the geometry of the true reachable sets.
We then propose a branch-and-bound method to compute accurate
over-approximations of the reachable sets by the inferred templates. We
illustrate the utility of the proposed approach in the reachability analysis of
linear systems driven by neural network controllers.","As the use of neural networks has expanded into safetycritical applications such as autonomous systems and automated healthcare, there is a growing need to develop efÔ¨Åcient and scalable methods to rigorously verify neural networks against input uncertainties. The canonical problem is to verify that for a bounded set of inputs, the reachable set of a trained model does not intersect with an unsafe set. From an optimization perspective, this problem can be formulated as a constraint satisfaction feasibility problem, where the goal is to either verify the constraint or Ô¨Ånd a counterexample. Going beyond machine learning, neural networks also arise as function approximators in feed back control. Compared to openloop settings, veriÔ¨Åcation of neural networks in closedloop sys tems is a more challenging problem, as it requires an explicit characterization of the reachable sets at each iteration. Computation of reachable sets for dynamical systems is a fundamental problem that arises in, for example, safety veriÔ¨Åcation and robust control synthesis‚Äìsee Althoff et al. (2021) for an overview. Formally, given the dynamical system xk+1=F(xk)x02X0, whereX0is a bounded set of initial conditions, the reachable set at time k+ 1is deÔ¨Åned as Xk+1=F(Xk) =fF(x)jx2Xkg; (1) Since it is generally difÔ¨Åcult to compute the reachable sets exactly, these sets are often over approximated iteratively by a sequence of template sets (Xk)k0: starting with X0=X0, we over ¬© 2023 T. Entesari & M. Fazlyab.arXiv:2212.07553v3  [eess.SY]  15 May 2023AUTOMATED REACHABILITY ANALYSIS OF NEURAL NETWORK CONTROLLED SYSTEMS approximate the image ofXkunderFusing a set propagation algorithm to ensure that F(Xk) Xk+1fork= 0;1;. If the overapproximated sets do not intersect with a set of unsafe states (e.g., obstacles), then safety can be guaranteed. However, the overapproximation error can quickly accumulate over time (known as the wrapping effect Neumaier (1993)), leading to overly conser vative bounds for long time horizons. This challenge becomes even more pronounced when neural networks are involved in the feedback loop (e.g., when Fis itself a neural network approximation of an ODE). The choice of template sets can have a crucial effect on the accuracy of computations. Indeed, any potential mismatch between the shape of the template set and the actual reachable set can lead to conservative bounds (shape mismatch error). To minimize this error, it is essential to use dynamic template sets that can adapt to the geometry of the reachable sets based on the structure ofF. Furthermore, the method by which we propagate the sets through Fcan incur conservatism due to the underlying relaxations (propagation error). This error can be mitigated by using less conservative relaxations in the propagation method and/or by partitioning the input set. Our Contributions In this paper, we propose a novel method for reachability analysis of discrete time afÔ¨Åne systems in feedback with ReLU1neural network controllers. Using bounded polyhedra to represent the template sets, we propose a method that dynamically adapts the geometry of the tem plate sets to that of reachable sets based on the structure of the closedloop map. Thus, this approach eliminates the manual selection of the template directions, making the procedure fully automated. Based on the chosen template directions, we then compute tight2polyhedral overapproximations of the reachable sets using efÔ¨Åcient branchandbound (BnB) algorithms. Our method is modular in that it can incorporate any bound propagation method for neural networks. Our code is available at https://github.com/o4lc/AutomatedReach.git . 1.1. Related Work "
323,Reachable Polyhedral Marching (RPM): An Exact Analysis Tool for Deep-Learned Control Systems.txt,"We present a tool for computing exact forward and backward reachable sets of
deep neural networks with rectified linear unit (ReLU) activation. We then
develop algorithms using this tool to compute invariant sets and regions of
attraction (ROAs) for control systems with neural networks in the feedback
loop. Our algorithm is unique in that it builds the reachable sets by
incrementally enumerating polyhedral regions in the input space, rather than
iterating layer-by-layer through the network as in other methods. When
performing safety verification, if an unsafe region is found, our algorithm can
return this result without completing the full reachability computation, thus
giving an anytime property that accelerates safety verification. Furthermore,
we introduce a method to accelerate the computation of ROAs in the case that
deep learned components are homeomorphisms, which we find is surprisingly
common in practice. We demonstrate our tool in several test cases. We compute a
ROA for a learned van der Pol oscillator model. We find a control invariant set
for a learned torque-controlled pendulum model. We also verify specific safety
properties for multiple deep networks related to the ACAS Xu aircraft collision
advisory system. Finally, we apply our algorithm to find ROAs for an
image-based aircraft runway taxi problem. Algorithm source code:
https://github.com/StanfordMSL/Neural-Network-Reach .","In this paper we present the Reachable Polyhedral March ing (RPM) algorithm for computing forward and backward reachable sets of deep neural networks with rectiÔ¨Åed linear unit (ReLU) activation. Our algorithm provides a building block for proving safety properties for autonomous systems with learned perception, dynamics, or control components in the loop. SpeciÔ¨Åcally, given a set in the input space, RPM computes the set of all corresponding outputs (the forward reachable set, or image, of the input set). Similarly, given a set of outputs, RPM computes the set of all corresponding inputs under the ReLU network (the backward reachable set, or preimage, of the output set). We use these capabilities to compute Ô¨Ånitetime reachable sets, as well as inÔ¨Ånitetime invariant sets and regions of attraction (ROAs). It is well known that for any ReLU network there exists an equivalent continuous piecewiseafÔ¨Åne (PWA) function, that is, the input space for a ReLU network can be tessellated into polyhedra, and over each polyhedron the neural network evaluates to an afÔ¨Åne function. RPM explicitly Ô¨Ånds this equivalent PWA representation for a given ReLU network. Figure 1 illustrates 1Department of Aeronautics and Astronautics, Stanford University, Stan ford, CA 94305, USA, fjosephav, schwager g@stanford.edu The Ô¨Årst author was supported in part by a Dwight D. Eisenhower Transportation Fellowship. The NASA University Leadership Initiative (grant #80NSSC20M0163) provided funds to assist the authors with their research, but this article solely reÔ¨Çects the opinions and conclusions of its authors and not any NASA entity. We are grateful for this support. Fig. 1: This Ô¨Ågure shows how RPM incrementally explores polyhedra corresponding to afÔ¨Åne regions of a ReLU neural network (left column) and the corresponding forward reach able set of these regions under the neural network map (right column). This example uses a randomly initialized network with 2 inputs, 2 outputs, and 2 hidden layers of 10 neurons each; resulting in 166 afÔ¨Åne regions. how RPM works. The algorithm iteratively enumerates the polyhedra and afÔ¨Åne functions deÔ¨Åning the PWA function by solving a series of Linear Programs (LPs), and follow ing analytical edge Ô¨Çipping rules to determine neighboring polyhedra. The algorithm starts with a random polyhedron, then solves for its neighboring polyhedra, then neighbors of neighbors, etc., until the whole input space is tessellated. In this way, our method is geometrically similar to fast marching methods in optimal control [1], path planning [2], [3], and graphics [4], [5]. We then use computational methods for PWA reachability to compute forward and backward reachable sets for each polyhedron and associated afÔ¨Åne function. Finally, we also propose an accelerated 1arXiv:2210.08339v2  [cs.LG]  25 Oct 2022backward reachability procedure in the case that the deep network is a homeomorphism (a continuous bijection with continuous inverse). We Ô¨Ånd, surprisingly, that a variety of organically trained ReLU networks are homeomorphisms, even through they are not constructed or trained with this property in mind (e.g. the closedloop TaxiNet network trained for autonomous aircraft runway taxiing), therefore backward reachability and ROA computations with RPM can be signiÔ¨Åcantly accelerated for these systems. All existing algorithms that compute exact reachable sets of neural networks iterate through the network layerbylayer [6], [7], [8]. The layerbylayer approaches obtain the entire reachable set at once at the end of the computation, rather than revealing the reachable set piece by piece throughout the computation. Consequently, if the computation must end early due to memory constraints or a computer fault, no us able result is obtained. In contrast, RPM builds the reachable set one polyhedron at a time, leading to a partial, but still potentially useful result if computation is halted before the algorithm runs to completion. Incremental computation is better suited to Ô¨Ånding counterexamples to safety properties and terminating early, as well as providing a more memory efÔ¨Åcient approach where a region of the reachable set already computed can be saved externally to free up memory for remaining computation. Furthermore, for learned dynamical systems, RPM can be used to certify local asymptotic sta bility, compute nonconvex ROAs, compute intricate control invariant sets, and verify inputoutput safety properties, as we demonstrate in this paper. These factors are the core motivation for RPM. In numerical examples, we compute ROAs for a learned van der Pol oscillator, and show this computation enjoys a 16x speedup because the learned dynamics are homeo morphic. We then pair RPM with the MPT3 [9] Matlab toolbox to Ô¨Ånd an a control invariant set for a learned torque controlled pendulum. We also show faster identiÔ¨Åcation of unsafe inputs compared to a state of the art reachability method [8] in a safety veriÔ¨Åcation problem involving ACAS Xu, a neural network policy for aircraft collision avoidance. Finally, we apply our algorithm to Ô¨Ånd ROAs for an image based airplane runway taxiing system, TaxiNet [10]. The closedloop system is PWA with 100;000 regions, two orders of magnitude larger than PWA systems for which other approaches have been demonstrated. The contributions of this paper are An incremental method for computing the explicit PWA representation of a ReLU network. A theorem to analytically determine an input space polyhedron from its neighbor by Ô¨Çipping neuron ac tivations in the ReLU network. An accelerated PWA backward reachability algorithm for homeomorphic PWA functions. Application of PWA analysis tools to compute regions of attraction for equilibria, and inÔ¨Ånite time forward invariant and controlinvariant sets for ReLU networks. Examples demonstrating the computation of exact ROAs and control invariant sets, safety property veriÔ¨Åcation, and ROA computation for a ReLU network with two orders of magnitude more afÔ¨Åne regions than other examples in the literature. This paper builds upon an earlier conference version [11], which Ô¨Årst introduced the RPM algorithm to convert a ReLU network into a PWA representation. This paper improves upon [11] by (i) adding a formal proof of correctness for the main RPM algorithm, (ii) extending the RPM framework to compute invariant sets and ROAs, (iii) introducing an accelerated method for computing ROAs for homeomorphic neural networks, and (iv) demonstrating the computation of invariant sets and ROAs in three new examples. The paper is organized as follows. We give related work in Section II and give background and state the problem in Section III. Section IV presents our main algorithm, RPM, and explains its derivation. In Section V we use RPM to perform forward and backward reachability computations for ReLU networks over multiple time steps. Next, in Section VI we summarize existing results on computing robust control invariant sets for PWA dynamical systems. In Section VII we use RPM to compute ROAs using these PWA invariant set tools. Finally, Section VIII presents numerical results using RPM in the aforementioned examples, and we offer conclusions in Section IX. A proof for the main theorem on the correctness of RPM is presented in the Appendix. II. R ELATED WORK "
98,HRFA: High-Resolution Feature-based Attack.txt,"Adversarial attacks have long been developed for revealing the vulnerability
of Deep Neural Networks (DNNs) by adding imperceptible perturbations to the
input. Most methods generate perturbations like normal noise, which is not
interpretable and without semantic meaning. In this paper, we propose
High-Resolution Feature-based Attack (HRFA), yielding authentic adversarial
examples with up to $1024 \times 1024$ resolution. HRFA exerts attack by
modifying the latent feature representation of the image, i.e., the gradients
back propagate not only through the victim DNN, but also through the generative
model that maps the feature space to the image space. In this way, HRFA
generates adversarial examples that are in high-resolution, realistic,
noise-free, and hence is able to evade several denoising-based defenses. In the
experiment, the effectiveness of HRFA is validated by attacking the object
classification and face verification tasks with BigGAN and StyleGAN,
respectively. The advantages of HRFA are verified from the high quality, high
authenticity, and high attack success rate faced with defenses.","In recent years, deep learning has achieved an extraordinary success in computer vision, natural language processing and other Ô¨Åelds [1]. However, because of its blackbox character istics, the robustness and reliability of DNNs have long been suspected. One evidence that DNNs are far from perfect, is the existence of adversarial examples [2, 3, 4, 5, 6], where DNNs are easily fooled by elaboratelycrafted but impercep tible perturbations on the input and make false predictions at a high conÔ¨Ådence. Generally, adversarial attacks Ô¨Åx the network parameters and optimize the input to maximize a training loss. The cur rent mainstream of adversarial attacks adds perturbations di rectly in image space [3, 5, 7], i.e., the attack gradients back propagate to the input image and modify it to become adver sarial. In this way, the calculated perturbations are without ?These authors contribute equally. yCorresponding author.semantic meanings like random noise, leading to noisebased attacks . Though effective, these attacks do not produce au thentic adversarial samples, i.e., images in the distribution of natural photos [8]. Thus, noisebased adversarial examples could be easily detected [9]. Inspired by our Type I attack [4] and AoA attack [5], it will be more interesting to link the attack perturbations with semantic meanings. In contrast to noisebased attacks, featurebased attacks produce interpretable perturbations, which could not be inhibited by defense methods like noise based attacks. As shown in Fig. 1, perturbations of our highresolution featurebased method capture the outline of the object and highlight the most sensitive regions of the image, e.g., the leap and eyes, revealing weaknesses of the networks in a structured and explainable manner. However, previous featurebased attacks [10, 11] can only generate lowresolution examples as in the middle column of Fig.1, which is signiÔ¨Åcantly not authentic compared to our attack in the right column. Fig. 1 . Comparison among the mainstream noisebased at tacks (e.g., PGD [12] here), lowresolution featurebased at tack (e.g., [11] here) and our highresolution featurebased attack from left to right. The top row is adversarial examples, and the bottom row is the corresponding perturbations, which are equally multiplied for a clear presentation.arXiv:2001.07631v2  [cs.LG]  22 Oct 2020In this paper, we propose HighResolution Featurebased Attack (HRFA). HRFA adopts the image loss to guarantee the imperceptibility of input and the net loss to mislead the vic tim DNN. We optimize the total loss by modifying the latent feature representation of the image, i.e., the gradients back propagate not only through the victim DNN, but also through the generative model that maps the feature space to the image space. Because we directly manipulate the lowdimensional latent feature map to attack, the resulting image perturbations are continuous and interpretable. HRFA is a universal attack framework applicable to various tasks. We conduct compre hensive experiments to attack classiÔ¨Åcation and face veriÔ¨Å cation with BigGAN [13] and StyleGAN [14], respectively. Results show that HRFA produces authentic adversarial ex amples with resolution up to 10241024 . Furthermore, they are immune to several defenses compared to existing attacks. 2. METHOD "
165,A Multi-Task Comparator Framework for Kinship Verification.txt,"Approaches for kinship verification often rely on cosine distances between
face identification features. However, due to gender bias inherent in these
features, it is hard to reliably predict whether two opposite-gender pairs are
related. Instead of fine tuning the feature extractor network on kinship
verification, we propose a comparator network to cope with this bias. After
concatenating both features, cascaded local expert networks extract the
information most relevant for their corresponding kinship relation. We
demonstrate that our framework is robust against this gender bias and achieves
comparable results on two tracks of the RFIW Challenge 2020. Moreover, we show
how our framework can be further extended to handle partially known or unknown
kinship relations.","Kinship relationship between two people is usually deter mined using the persons‚Äô physical features, which can be divided into DNA, body and facial features. In contrast to the very reliable DNAanalysis, facial and body features a re used to obtain an initial and quick estimate of whether two people are related or not. Imagebased kinship veriÔ¨Åcation [1]‚Äì[23] relies only on information present in facial images to estimate whether th ey are related. Due to the inherent Ô¨Çexibility of only needing a face image compared to more invasive DNAsample, kinship veriÔ¨Åcation with visual media has an abundance of practical uses: e.g., forensic investigations, genealogical studie s, social mediabased analysis and photo library management. As proposed in the RFIW Challenge 2020 [24], one can state three problems concerning kinship veriÔ¨Åcation: 1) Determine whether two persons are consanguine given a kinship relation. 2) Decide whether a person is the child of given parents. 3) Identifying relatives of a person in a gallery. Lately, the emergence of bigger image kinship veriÔ¨Åcation datasets, including CornellKinFace [2], KinFaceW [25], [2 6], TSKinFace [27], and FIW[16], has given more and more at tention to kinshiprelated tasks and allowed the developme nt of more reliable databased approaches. Kinship veriÔ¨Åcati on from face images focuses on consanguinity kinship, which can be divided into three groups: ‚Ä¢Samegeneration pairs: brotherbrother BB, brother sister SIBS and sistersister SS ‚Ä¢Firstgeneration pairs: fatherson FS, fatherdaughter FD, motherson MSand motherdaughter MD ‚Ä¢Secondgeneration pairs: grandfathergrandson GFGS , grandfathergranddaughter GFGD , grandmother grandson GMGS and grandmothergranddaughter GMGDFace Feature ExtractorKinship  Comparatorkin or nonkin? Kinship Relation Fig. 1. Overview of the kinship recognition comparator fram ework: Features f1,f2are extracted from two input faces, which are then combined in the comparator network to estimate whether the f aces are related according to a given kinship relation. 0.3 0.4 0.5 0.60200400600800 Cosine Distance# Pairsmotherdaughter 0.3 0.4 0.5 0.6 Cosine Distancefatherdaughter Fig. 2. Histogram of the cosine distance of face identiÔ¨Åcati on features f1andf2forkin(blue) and nonkin (orange) pairs for parentsdaughter kinship relations on the RFIW validation dataset. Best view ed in color. As illustrated in Fig. 1, typical kinship veriÔ¨Åcation ap proaches consist of a convolutional neural network, which extracts facial features for each image separately. These features are then fed into a kinship comparator in order to distinguish between kinornonkin . Several methods [11], [17], [24] rely on metrics like cosine distance between ex tracted features to determine kinship. However, as shown in the histogram in Fig.2, kinandnonkin pairs from opposite gender kinship relations are hardly separable compared to samegender kinship relations, which is due to the high inÔ¨Çuence of gender on the feature. Motivated by this Ô¨Ånding and in contrast to training the feature extractor on kinship recognition [11], [14], [22], [28], [29], we propose a comparator framework, which is robust against this gender bias as we demonstrate later. Our neural kinship comparator framework is not only capable of solving typical kinshiprelated tasks beneÔ¨Åting from separated lo cal expert networks for each kinship relation but can also be further extended with an attention module to predict the kinship relation and leverage it for tasks with unknown kinship relation.ResNet 50 Kinship Comparator Kinship RelationTaskdependent  Kinship Relation  Encoder Fig. 3. Our multitask kinship comparator framework: Faces are embedded separately into a feature space using a ResNet 50 (ResNet blocks in green). The concatenation of both output features fcis used by a cascaded local expert network, which uses multip le fully connected layers (orange) to reÔ¨Åne the information and focus it into a single neuron (orange cir cle) for each kinship relation. The taskdependent kinship relation encoder selects the output neuron corresponding to the given kinship layer, which will be forwarded to the output z. Best viewed in color. II. RELATED WORK "
238,Image-to-Video Person Re-Identification by Reusing Cross-modal Embeddings.txt,"Image-to-video person re-identification identifies a target person by a probe
image from quantities of pedestrian videos captured by non-overlapping cameras.
Despite the great progress achieved,it's still challenging to match in the
multimodal scenario,i.e. between image and video. Currently,state-of-the-art
approaches mainly focus on the task-specific data,neglecting the extra
information on the different but related tasks. In this paper,we propose an
end-to-end neural network framework for image-to-video person reidentification
by leveraging cross-modal embeddings learned from extra information.Concretely
speaking,cross-modal embeddings from image captioning and video captioning
models are reused to help learned features be projected into a coordinated
space,where similarity can be directly computed. Besides,training steps from
fixed model reuse approach are integrated into our framework,which can
incorporate beneficial information and eventually make the target networks
independent of existing models. Apart from that,our proposed framework resorts
to CNNs and LSTMs for extracting visual and spatiotemporal features,and
combines the strengths of identification and verification model to improve the
discriminative ability of the learned feature. The experimental results
demonstrate the effectiveness of our framework on narrowing down the gap
between heterogeneous data and obtaining observable improvement in
image-to-video person re-identification.","With widespread use of surveillance cameras and enhanced awareness of public security, person reidentiÔ¨Åcation(re id), the task of recognizing people in a nonoverlapping camera network, has attracted especial attention of computer visi on and pattern recognition communities(Wu et al., 2017, 2018c ). Given an image/video of a personofinterest(query), person identiÔ¨Åcation identiÔ¨Åes the person from images /videos taken from a diÔ¨Äerent camera. After many years of great e Ô¨Äorts, per son reid still remains a notably challenging task. The main reason is that a person‚Äôs appearance will dramatically chan ge across camera views due to the large variations in illumina tion, poses, viewpoints and cluttered background(Zhang et al., 2017). According to the scenarios of the reidentiÔ¨Åcation, exist ing person reidentiÔ¨Åcation works can be roughly divided ‚àó‚àóCorresponding author: Lin Li Tel.: +862787216780; fax: +8627 87216780; email:cathylilin@whut.edu.cn (Zhongwei Xie)into two categories: imagebased and videobased person re  identiÔ¨Åcation. The former focuses on the matching between a probe image of one person and the image of the person with the same ID in the gallery sets, which is mainly based on image content analysis and matching, while the latter focuses on t he matching between video and video, which can exploit di Ô¨Äerent information such as temporal and motion. A gallery is a colle c tion of images cropped from a di Ô¨Äerent view of unknown peo ple. In both kinds of approaches, the two objects to be matche d are homogeneous. However, in many practical cases, beneÔ¨Åting from the more and more surveillance cameras installed in public places, p er son reidentiÔ¨Åcation needs to be conducted between image an d video. For example, given an image of criminal suspect, the p o lice want to rapidly locate and track suspect from masses of c ity surveillance videos. The reidentiÔ¨Åcation under this scen ario is called imagetovideo person reidentiÔ¨Åcation, where the probe is an image and the gallery consists of videos captured by non  overlapping cameras. Although more information can be obtained from videos, imagetovideo reidentiÔ¨Åcation shares the same common2 challenges with imagebased and videobased person re identiÔ¨Åcation(e.g. similar appearance, low resolution, l arge variation in poses, occlusion and di Ô¨Äerent viewpoints) and ex ists its own diÔ¨Éculty: how to match between two di Ô¨Äerent modalities, i.e. image and video. Image and video are usuall y represented with di Ô¨Äerent features. SpeciÔ¨Åcally speaking, both visual features and spatiotemporal features can be extract ed from a video while only visual features can be obtained from a single image. Recently, convolutional neural networks(CNN) has shown potential for learning stateoftheart image featu re embedding(Varior et al., 2016; Xiao et al., 2016) and recurr ent neural networks(RNN) yield promising performance in obtai n ing spatiotemporal feature from video(Mclaughlin et al., 2 016; Yan et al., 2016). In general, there are two major types of dee p learning structures for person reidentiÔ¨Åcation, i.e. ver iÔ¨Åcation models and identiÔ¨Åcation models. VeriÔ¨Åcation models take a pair of data as input and determine whether they belong to the same person or not, which only leverage weak reid labels and can be regarded as a binaryclass classiÔ¨Åcation or similari ty regression task(Yi et al., 2014), while identiÔ¨Åcation mode ls aim at feature learning by treating person reidentiÔ¨Åcatio n as a multiclass classiÔ¨Åcation task(Xiao et al., 2016), but la ck direct similarity measurement between input pairs. Due to t he complementary advantages and limitations, the two models a re combined to improve the performance(Zheng et al., 2016). However, in the imagetovideo person reidentiÔ¨Åcation ta sk, a crossmodal system, directly using deep neural networks and the information provided by target task still cannot per  fectly bridge the ‚Äúmedia gap‚Äù, which means that representat ions of diÔ¨Äerent modalities are inconsistent. There have been ef forts (Long et al., 2015; Yosinski et al., 2014) reported to r euse existing models trained mostly for other tasks to construct a new model, which inspires us that presumably we can reuse the extra information learned from the di Ô¨Äerent but related task to help cross the ‚Äúmedia gap‚Äù. For most of the works, they direct ly use the weights from pretrained deep networks as initial va lues for the target model, and kick o Ô¨Äthe pretrained network struc ture that in fact can help train the new deep model. Currently , Fixed Model Reuse(FMR) is proposed in Yang et al. (2017) to incorporate the helpful Ô¨Åxed model into the training of a new convolutional model. In order to address the aforementioned limitations, we pro pose a novel endtoend neural network framework for image tovideo person reidentiÔ¨Åcation by reusing crossmodel e m beddings from diÔ¨Äerent but related tasks. Concretely speaking, the proposed framework consists of convolutional neural ne t works and long short term memory networks(LSTM) for im age feature extraction and video spatiotemporal feature ex trac tion, and combines the strengths of identiÔ¨Åcation model and veriÔ¨Åcation model to improve the discriminative ability of the learned feature representation. Furthermore, crossmoda l em beddings, i.e. imagetotext and videototext embedding lay ers are reused to help imagetovideo person reid narrow do wn the ‚Äúmedia gap‚Äù and improve the performance. Our main contributions can be summarized as follows. ‚Ä¢We propose an endtoend crossmodal framework forimagetovideo reid, which leverages CNN and LSTM to extract the visual features and spatiotemporal motion fea tures. Additionally, identiÔ¨Åcation loss and veriÔ¨Åcation l oss are combined so that the framework can simultaneously learn discriminative feature representations and a simila r ity metric. ‚Ä¢Crossmodal embedding from di Ô¨Äerent but related tasks are reused in our proposed framework, i.e. imageto text and videototext embeddings. Experimental results demonstrate that making text be the intermediate between image and video before the similarity learning may help narrow down the ‚Äúmedia gap‚Äù and improve pedestrian re trieval accuracy. The remainder of this paper is organized as follows. Sec tion 2 brieÔ¨Çy reviews some related work about person re identiÔ¨Åcation in recent years. Then we elaborate on the pro posed framework for imagetovideo person reid and presen t its each part at length in Section 3, followed by experiments in Section 4 together with conclusions and future work in Sec  tion 5. 2. Related work "
236,Spatial-temporal Graph Based Multi-channel Speaker Verification With Ad-hoc Microphone Arrays.txt,"The performance of speaker verification degrades significantly in adverse
acoustic environments with strong reverberation and noise. To address this
issue, this paper proposes a spatial-temporal graph convolutional network (GCN)
method for the multi-channel speaker verification with ad-hoc microphone
arrays. It includes a feature aggregation block and a channel selection block,
both of which are built on graphs. The feature aggregation block fuses speaker
features among different time and channels by a spatial-temporal GCN. The
graph-based channel selection block discards the noisy channels that may
contribute negatively to the system. The proposed method is flexible in
incorporating various kinds of graphs and prior knowledge. We compared the
proposed method with six representative methods in both real-world and
simulated environments.
  Experimental results show that the proposed method achieves a relative equal
error rate (EER) reduction of $\mathbf{15.39\%}$ lower than the strongest
referenced method in the simulated datasets, and $\mathbf{17.70\%}$ lower than
the latter in the real datasets. Moreover, its performance is robust across
different signal-to-noise ratios and reverberation time.","SPEAKER verification is to identify whether a speaker is the target speaker. It finds important applications in privacy protection, identity authentication, smart home, etc. The research on speaker verification dates back to the 1960s [1], followed by a series of statisticalmodelbased approaches, such as the Gaussianmixturemodelbased universal back ground model (GMMUBM) [2] and ivectors [3]. With the rise of deep learning era, speaker feature extraction with neural networks becomes the mainstream [4]‚Äì[6]. Although the deep learningbased speaker verification has achieved a significant breakthrough, farfield speaker verification is still challenging. When a microphone is placed far away from a speaker, the recorded speech signal is not only severely attenuated but also corrupted by background noise, reverberation and other interfering sound sources. Eventually, the performance of a speaker verification system in the farfield conditions drops sharply. To compensate the negative effect caused by noise and reverberation, a common approach for speaker verification is Yijiang Chen and XiaoLei Zhang are with the School of Marine Science and Technology, Northwestern Polytechnical University, 127 Youyi West Road, Xi‚Äôan, Shaanxi 710072, China (email: orangechen@mail.nwpu.edu.cn, xiaolei.zhang@nwpu.edu.cn). Chenegdong Liang is currently with the Horizon Robotics, Beijing, China. The work was done when Chengdong Liang was with the Northwestern Polytechnical University, China (email: chengdong01.liang@horizon.ai).to add a deeplearningbased speech noise reduction front end [7]‚Äì[12]. For example, Kolboek et al. [9] first used a maskingbased frontend to compute the posterior probability of a frame vector belonging to a speaker for the GMMUBM based speaker verification system. Then, Chang and Wang [10] used long shortterm memory as a maskingbased frontend to estimate clean speech for speaker recognition. Novotny et al. [13] learned a mapping from noisy speech to clean speech us ing an encoder, and subsequently applied the estimated speech to extract segmentlevel speaker representations. Another class of approaches treat farfield speaker recognition as a domain mismatch problem. It regards clean speech as the source domain and noisy data as the target domain, and solves the domain mismatching problem by domain adaptation methods [14]‚Äì[16]. The aforementioned methods are based on a single channel microphone, which does not explore important spatial information. To address this issue, multichannel speaker verification based on fixed arrays utilize azimuth information for fur ther performance improvement. Taherian et al. [17] used a deeplearningbased minimum variance distortionless response to get the enhanced speech for speaker verification, where the deep neural network is used to learn a timefrequency mask for estimating the noise component of each channel. Then, they further explored the effect of combining different beamforming frontends with ivector/xvectorbased recog nition backends. Yang and Chang [18] jointly optimized the deeplearningbased beamforming and speaker verifica tion. Cai et al. [19] took the multichannel noisy speech as the input of a twodimensionalconvolutionalneuralnetwork based endtoend speaker recognition directly, which yields lower equal error rate (EER) than singlechannel speaker recognition systems. He et al. [20] extracted vocal pattern information and orientation information simultaneously by a multichannel frontend, and applied the orientation informa tion to a directionofarrival (DOA) estimation for speaker identification. Similar works which combine other orientation information for speaker identification were also developed in [21], [22]. Wang et al. [22] obtained spatially encoded s vectors by DOA estimation of the multichannel input, and identified speakers according to the similarity matrix of the s vectors and xvectors. It is worthy noting that the above multi channel methods used fixed arrays with small array apertures. When a speaker is far from the array, then serious signal attenuation and strong interference of reverberation are still hard to prevent.arXiv:2307.01386v1  [cs.SD]  3 Jul 2023JOURNAL OF L ATEX CLASS FILES, VOL. 18, NO. 9, SEPTEMBER 2020 2 To reduce the occurrence probability of extremely hard far field problems, grouping multiple distributed devices together as an adhoc microphone array becomes a new type of effective methods, where each device in the adhoc micro phone array, denoted as an adhoc node , contains either a single microphone or a conventional fixed microphone array. Compared to the fixed arrays, a key advantage of the deep learningbased adhoc microphone array processing is that it is able to utilize spatial distance information via channel reweigting and selection. An early work used a deep neural network to estimate the signaltonoise ratio at each ran domly placed microphone array for the channel reweighting and selection [23]. However, the channel selection approach is not optimized. Recently, many works explored advanced channel selection approaches for speech enhancement [24], [25], speech separation [26]‚Äì[28], speech recognition [29], and speaker recognition [30], [31]. Particularly, Liang et al. [30] and Cai et al. [31] independently proposed endtoend speaker verification with adhoc microphone arrays, where an interchannel attentionbased channel reweighting method was developed to fuse utterancelevel speaker features from all channels. However, the spatialtemporal connection between the nodes were not fully explored by simply the attention mechanism. Furthermore, because the adhoc nodes that are far away from speech sources might be too noisy to contribute negatively to the system, taking all channels into account may not be the best choice. Recently, some methods explored graphs to reweight and fuse the multichannel signals collected by distributed microphone arrays for speech enhancement [32], [33]. However, they simply used complete graphs without further exploring different kinds of graphs that can incorporate flexible prior knowledge. Their effectiveness was not studied in speaker verification as well. To fully exploit the spatialtemporal information, in this paper, we propose an endtoend multichannel speaker ver ification framework based on graph convolutional networks (GCN). It includes a graphbased spatialtemporal multi channel feature aggregation block and a graphbased channel selection block. The former learns to enhance the speaker characteristics of each frame of a channel by aggregating spatialtemporal information from its neighboring frames and channels, while the latter discards stronglynoisy channels to further improve the performance. The core contributions of the paper are as follows. ‚Ä¢A graphbased spatialtemporal aggregation frame work is proposed for multichannel speaker verifica tion with adhoc microphone arrays. Unlike existing works [32], [33] which regard microphones as vertices of a graph for noise reduction, the proposed method takes both channels and time frames as vertices of a graph for speaker verification. It can capture the rela tionship between time frames across channels and thus has stronger modeling capability than simply modeling the relationship between channels. ‚Ä¢Several spatialtemporal GCNs that not only ac celerate the modeling process significantly but also are flexible in incorporating prior knowledge areproposed under the framework. Unlike the methods [32]‚Äì[34] which focus on applying graph neural networks (GNNs) without exploring adjacent matrices of graphs, this paper constructs adjacent matrices of graphs that are flexible in utilizing more abundant prior information, such as the spatial labeling information of datasets, temporal labeling information of speakers. Moreover, this paper describes two efficient backbone spatialtemporal GCNs. Experimental results showed that proposed methods outper form six representative comparison methods significantly in highlyreverberant and low signaltonoise ratio environments on both a simulated dataset and two realworld datasets. This paper differs from our preliminary work [34] in several major aspects, which includes the design of the channel selection block and various methods to construct graphs (but not in [34]), which improves the performance over [34] vitally. Consequently, many new experimental scenarios were studied beyond that in [34]. The rest of the paper is organized as follows. Section II briefly reviews the research progress of graph neural net works and introduces some preliminaries of modeling adhoc microphone arrays with graph neural networks. Section III introduces the proposed framework. Detailed description of the proposed algorithm is presented in Section VI, V, VI respectively. Section VII describes the experimental settings. Section VIII reports experimental results. Finally, Section IX concludes the paper. II. R ELATED WORK "
325,Vcash: A Novel Reputation Framework for Identifying Denial of Traffic Service in Internet of Connected Vehicles.txt,"Trust management of Internet of connected vehicles has been a hot topic
during the recent years with the rapid development of UGV technologies.
However, existing resolutions based on trustworthiness verification among
vehicles make the traffic event transmission quite inefficient. In this paper,
we assume that the deployed RSUs can provide efficient communication between
any pair of RSU and vehicle, and propose Vcash, a reputation framework for
identifying denial of traffic service, to resolve the trustworthiness problem
in the application level of the Internet of connected vehicles. In our
reputation framework, every vehicle communicates with the RSU directly for
traffic event verification, and spread verified traffic event notification. We
borrow the idea of market trading, and set up trading rules to restrict the
malicious vehicle's spread of false message, and to encourage vehicles to
contribute to the traffic event monitoring and verification. To evaluate the
effectiveness of our reputation framework, we conduct simulation experiment.
Our experiment results indicate that our proposal manages to avoid bogus event
spread, and a vehicle in our framework has to contribute to the traffic event
detection to normally employ the traffic service.","ith the rapid development of smart city techniques, a  growing quantity  of mobile equipment get s involved in  people ‚Äôs daily life, bringing great convenience together  with huge risk.  Vehicles with on board units are typical  examples among such mobile equipment.  During  recent years,  the infrastructure of the vehicular network is developing rapidly,  leading to growing interest on  the Internet of connected vehicles.   However, it is still very hard to identify the malicious  information  sent from neighboring vehicles [15]. When a  vehicle broadcasts a false  message in the Vehicular networks,  the vehicles in the same network may take the wro ng actions,  leading to a bad traffic accident . Herein, to construct a robust  and secure trust management framework  [1527] for the  Internet of connected vehicle s turns out to be a critic al problem   for the actual deployment of UGV.    The r eputation based mechanism is a commonly used  technique for the defense of attacks on traffic service. Based on    Zhihong Tian , Shen Su , and Jing Qiu are with the Cyberspace Institute of  Adva nced Technology, GuangZhou University, GuangZhou, China  the cooperation o f vehicles , researchers evaluate the  trustworthiness  of traffic warning messages  accord ing to the  trustworthiness between vehicles (entity centric methods [15 18]), or according to the message content itself (data centric  methods [2224]). In spite of the rationality of such two kinds of  methods, existing resolutions always involve  V2V (vehicle to vehicle) network  whose trustworthiness  is not guaranteed . Thus  message broadcast upon such network always  needs an  additional method to ensure that no bogus events are spread.  However, due to the high mob ility of the V2V networks, the  schemes to ensure V2V network ‚Äôs trustworthiness are costly   [2224].   The existing resolutions assume  that the quantity of RSUs   (Road Side Unit)  is limited  [2230], and V2V network  communication is very important  to ensure the network  connectivity. As a result, the communication  between the RSU  and the vehicle could be badly delayed , and turns out to be the  bottleneck if it involves in the  process of verifying the  trustworthiness of a traffic event message. However, with the  growing deployment of vehicular  network infrastructure and  the huge demand on  the Internet of connected vehicles , the  quantity of RSUs is turning  out to be sufficient for a quick  response  to the vehicle request , especially in the down town area  of cities . Thus, we believe that  the communication between  RSUs and vehicles could be efficient enough for traffic events  verification in the near future.  Therein, w e propose to verify the  traffic events based on RSU s, i.e. to ensure all traffic events  message sent by RSUs are verified  to be trustworthy, and  conduct traffic event verification on the RSUs.    Considering the advantages of both entity centric methods  and data centric methods, and few existing  works propose to  evaluate the reputation  of both entity and data, in this paper, we  propose a reputation framework which manages  the reputation  of both vehicles and the generated traffic events. Our reputation  framework is based on an incentive  mechanism . All vehicles in  our framework are encouraged to contribute to the traffic event   detection as much as possible. For each vehicle, the  detected  traffic event s have to be correct, or the vehicle would be  punished. To that end,  each vehicle is initialized with a certain  amount of capital (noted as vehicle cash), and a vehicle  has to  invest on each traffic  event it spreads to make it accepted by the  RSUs. The RSUs sell the traffic event for the generator if the  traffi c event could  be verified . Thus t he invested traffic events  Xiangsong Gao is with China Academy of Engineer Physics, Mianyang,  Sichuan, China.   Corresponding author:  Shen Su , Email: johnsuhit@gmail.com  Vcash: A Novel Reputation Framework for   Identifying Denial of Traffic Service  in Internet  of Connected Vehicles   Zhihong Tian , Xiangsong Gao,  Shen Su *, and Jing Qiu   W 23274662 (c) 2019 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/JIOT.2019.2951620, IEEE Internet of Things Journal IEEE INTERNET OF THINGS J OURNAL  2  could be profit able if it is a de facto traffic event. However, for  malicious vehicles which send bogus event s, they would  quickly run out of their vehicle cash , and could send no more  bogus event s since none of their generated traffic events are  profitable. For vehicles which send no messages, they would  also run out of vehicle cash, and could employ the traffic service  no more since every traffic event warning costs.    Our proposed reputation framework could b e taken as a  combination of the  entity centric methods and data centric  methods . Every vehicle ‚Äôs Vcash indicates its capability to  spread invest ed traffic events, thus could reveal the reputation  of the vehicle. The investment of each traffic event is used to  decide whether the RSUs should  accept the traffic events, thus  could reveal the reputation  of the data, and determine the  management conducted to the data.    Our contribution in this paper includes three folds :   First, we propose vehicle cash, a reputation framework f or  the identifying denial of traffic service , which applies for the  trend of growing deployment of RSUs , and growing interest in  the Internet of connected vehicles .   Second, we discuss the multiple threaten modes for the d enial  of tra ffic service attack, including the selfish attack mode. We  also propose a corresponding resolution to restrict the spread of  false message, and to encourage contribution of traffic  condition monitoring and verification.    Third, we conduct simulation experi ments to prove the  effectiveness of our reputation framework. Our experiments  indicate that Vcash could efficiently reduce the bogus event   spread, and encourage all vehicles involving in traffic event  monitoring and verification .  In the rest of this paper,  we will first introduce the related  works in Section2. Then will give the problem statement in  Section 3, and we present our reputation framework in Section  4. We evaluate  the effectiveness of our reputation framework in  Section 5 , and conclude our proposal with future work in  Section 6.   II. RELATED WORKS   "
450,SpeechNAS: Towards Better Trade-off between Latency and Accuracy for Large-Scale Speaker Verification.txt,"Recently, x-vector has been a successful and popular approach for speaker
verification, which employs a time delay neural network (TDNN) and statistics
pooling to extract speaker characterizing embedding from variable-length
utterances. Improvement upon the x-vector has been an active research area, and
enormous neural networks have been elaborately designed based on the x-vector,
eg, extended TDNN (E-TDNN), factorized TDNN (F-TDNN), and densely connected
TDNN (D-TDNN). In this work, we try to identify the optimal architectures from
a TDNN based search space employing neural architecture search (NAS), named
SpeechNAS. Leveraging the recent advances in the speaker recognition, such as
high-order statistics pooling, multi-branch mechanism, D-TDNN and angular
additive margin softmax (AAM) loss with a minimum hyper-spherical energy (MHE),
SpeechNAS automatically discovers five network architectures, from SpeechNAS-1
to SpeechNAS-5, of various numbers of parameters and GFLOPs on the large-scale
text-independent speaker recognition dataset VoxCeleb1. Our derived best neural
network achieves an equal error rate (EER) of 1.02% on the standard test set of
VoxCeleb1, which surpasses previous TDNN based state-of-the-art approaches by a
large margin. Code and trained weights are in
https://github.com/wentaozhu/speechnas.git","There are numerous measurements and signals, such as Ô¨Ån gerprint, face, iris and voice, being investigated for biometric recognition systems [5]. Among these most popular measure ments, voice has been one of the most compelling biometrics, because 1) the microphone system has been one of the most widely adopted intelligent agent to extract the speech signal in various hardwares, and 2) the speech sample can be widely accepted and does not considered threatening by users. Most importantly, the speaker recognition area has been well stud ied for over Ô¨Åfty years, and there is a rich scientiÔ¨Åc basis and extensive development over the area. *Equal contributions. https://github.com/wentaozhu/speechnas.git Fig. 1 . SpeechNAS achieves better cosine EERs with lower number of parameters. Deep neural networks have been widely adopted to ex tract speaker representations [1]. Recently, time delay neu ral network (TDNN) with xvectors [1] has been a paradigm for speaker veriÔ¨Åcation. Compared with vanilla TDNN, ex tended TDNN (ETDNN) [2] interleaves feedforward neu ral network (FNN) layers between the TDNN layer for multi speaker conversations. Factorized TDNN (FTDNN) [3] fur ther reduces the number of parameters of the TDNN xvector by factorizing the weight matrix of each TDNN layer into the product of two lowrank matrices. Densely connected TDNN (DTDNN) [4] adopts bottleneck layers and dense connectiv ity, and it can further integrate channelwise selection mecha nism to achieve the stateoftheart accuracy for TDNNbased speaker veriÔ¨Åcation. The accuracy of TDNN based speaker veriÔ¨Åcation can be further improved leveraging the advanced neural architecture search (NAS). On the other hand, studies have been extensively con ducted to enhance the loss functions [6]. Triplet loss [7] selects appropriate training samples and performs well for speaker veriÔ¨Åcation. Speaker identity subspace loss [8] learns a space where it measures the similarity of speakers by EuarXiv:2109.08839v1  [cs.SD]  18 Sep 2021clidean distance. Center loss [9, 10] attempts to reduce the intraspeaker variability by constraining features close to the center. Instead, angular distance [11] focuses on cosine similarity and normalizes the features and the weights of the output layer before softmax. Generalized endtoend loss [12] minimizes a scaled cosine score between the features and the estimated speaker centers. Various angular and large margin based loss functions [13, 14, 15, 16] have been investigated in the speaker veriÔ¨Åcation. Liu et al. [6] conducts a compre hensive investigation on the loss functions and combines an additive margin softmax loss and a minimum hyperspherical energy (MHE) [17] to achieve a desired accuracy. We also employ an advanced large margin based loss to train the can didate architectures for the large scale speaker veriÔ¨Åcation. In this work, we attempt to construct optimal TDNN based architectures leveraging the recent advanced study of network designs and loss functions. Our search space con sists of multibranch mechanism, densely connected TDNN (DTDNN), and channel selection. We conduct the number of branches search, the dimension number of DTDNN search and the dimension number of channel selection search em ploying Bayesian optimization. The candidate architecture is trained by a hybrid loss between AAM and a MHE criterion. Our contributions can be summarized as follows: 1) We design a neural architecture search (NAS) based large scale speaker veriÔ¨Åcation system, SpeechNAS, to identify the optimal architectures leveraging TDNN variants and an AAM related hybrid loss. 2) We conduct a comprehen sive comparison to the stateoftheart speaker veriÔ¨Åcation approaches considering a variety of metrics, including the number of parameters, GFLOPs, latency, the equal error rate (EER) [1], and the minimum of detection cost function (DCF) [1] with target probabilities set to 0.01 and 0.001. 3) Our NAS based speaker veriÔ¨Åcation derives Ô¨Åve architectures, from SpeechNAS1 to SpeechNAS5, with various numbers of parameters and FLOPs. The SpeechNAS5 achieves much better performance than previous TDNN based stateofthe art approaches on the VoxCeleb1 test set as shown in Fig. 1. 2. RELATED WORKS "
460,A Wireless-Vision Dataset for Privacy Preserving Human Activity Recognition.txt,"Human Activity Recognition (HAR) has recently received remarkable attention
in numerous applications such as assisted living and remote monitoring.
Existing solutions based on sensors and vision technologies have obtained
achievements but still suffering from considerable limitations in the
environmental requirement. Wireless signals like WiFi-based sensing have
emerged as a new paradigm since it is convenient and not restricted in the
environment. In this paper, a new WiFi-based and video-based neural network
(WiNN) is proposed to improve the robustness of activity recognition where the
synchronized video serves as the supplement for the wireless data. Moreover, a
wireless-vision benchmark (WiVi) is collected for 9 class actions recognition
in three different visual conditions, including the scenes without occlusion,
with partial occlusion, and with full occlusion. Both machine learning methods
- support vector machine (SVM) as well as deep learning methods are used for
the accuracy verification of the data set. Our results show that WiVi data set
satisfies the primary demand and all three branches in the proposed pipeline
keep more than $80\%$ of activity recognition accuracy over multiple action
segmentation from 1s to 3s. In particular, WiNN is the most robust method in
terms of all the actions on three action segmentation compared to the others.","Human activity recognition has emerged as an important task recently in numerous applications, such as assisted liv ing [1], humancomputer interaction [2], health monitoring [3], surveillance [4], etc. In existing systems, the individual has to wear a device equipped with motion sensors such as a gyroscope and an accelerator. The sensor data is processed locally on the wearable device or transmitted to a server for feature extraction, and then supervised learning algorithms are used for classiÔ¨Åcation. This type of monitoring is known as active monitoring. The performance of such a system is shown to be around 90 percent for recognition of activities such as sleeping, sitting, standing, walking, and running. However, it is not always convenient to wear devices to monitor the activities in passive applications because of the additional burden and discomfort associated with wearing the device. Camerabased systems play an important role in passive ac tivity recognition. However, occlusion remains a fundamental challenge. The requirement for light is a major limitation for such systems. Furthermore, it often refers to privacy issues and is limited in many conditions. Unlike sensorbased and video based solutions, WiFi sensing is not intrusive without the privacy issue and insensitive to lighting conditions. Therefore,WiFi sensing has obtained prevailing popularity in human action recognition [5]. Recent years have witnessed rapid growth of techniques us ing channel state information (CSI) of WiFi signals in sensing human bodies [6], [7]. Although WiFi CSI has obtained much progress in localizing people and tracking their motion, it is cumbersome for Ô¨Ånegrained human activities recognition because CSI is sensitive to environmental inÔ¨Çuences. More over, the vision information from the camera is a potential complement to assist CSI in some environments without any occlusions. These questions, give us an incentive to develop a new WiFi and video combined pipeline (WiNN) for human action recognition. The synchronous video and WiFi CSI with common supplement and mutual complementary makes WiNN adjustable and feasible for real conditions, especially complex visual conditions, including the scenes without occlusion, with partial occlusion, and with full occlusion, respectively. To summarize, the contributions of this paper are threefold. ‚Ä¢ We Ô¨Årst construct WiVi, wirelessvision activity data set, as a benchmark to evaluate the performance of existing activity recognition systems. We tested SVM, convolution neural network (CNN) as well as the proposed WiNN to verify the effectiveness of the WiVi dataset. ‚Ä¢ We propose WiFibased and videobased neural network as WiNN for activity recognition in scenes with partial occlusion and with full occlusion, which improves the robustness of activity recognition according to the synchronous video as a supplement and complement for WiFi CSI signals. ‚Ä¢ We compare machine learning method SVM and deep learning methods CNN and WiNN to verify the quality of the WiVi data set. Particularly, WiNN achieves the most robust results over multiple action segmentation from 1s to 3s. II. R ELATED WORK "
317,Robust R-Peak Detection in Low-Quality Holter ECGs using 1D Convolutional Neural Network.txt,"Noise and low quality of ECG signals acquired from Holter or wearable devices
deteriorate the accuracy and robustness of R-peak detection algorithms. This
paper presents a generic and robust system for R-peak detection in Holter ECG
signals. While many proposed algorithms have successfully addressed the problem
of ECG R-peak detection, there is still a notable gap in the performance of
these detectors on such low-quality ECG records. Therefore, in this study, a
novel implementation of the 1D Convolutional Neural Network (CNN) is used
integrated with a verification model to reduce the number of false alarms. This
CNN architecture consists of an encoder block and a corresponding decoder block
followed by a sample-wise classification layer to construct the 1D segmentation
map of R- peaks from the input ECG signal. Once the proposed model has been
trained, it can solely be used to detect R-peaks possibly in a single channel
ECG data stream quickly and accurately, or alternatively, such a solution can
be conveniently employed for real-time monitoring on a lightweight portable
device. The model is tested on two open-access ECG databases: The China
Physiological Signal Challenge (2020) database (CPSC-DB) with more than one
million beats, and the commonly used MIT-BIH Arrhythmia Database (MIT-DB).
Experimental results demonstrate that the proposed systematic approach achieves
99.30% F1-score, 99.69% recall, and 98.91% precision in CPSC-DB, which is the
best R-peak detection performance ever achieved. Compared to all competing
methods, the proposed approach can reduce the false-positives and
false-negatives in Holter ECG signals by more than 54% and 82%, respectively.
Results also demonstrate similar or better performance than most competing
algorithms on MIT-DB with 99.83% F1-score, 99.85% recall, and 99.82% precision.","significant motive to investigate  highly accurate and robust   automated detection of  Rpeaks  in single lead ECG signals.    Although many Rpeak detection methods have been  proposed  throughout the last several decades, robust  and  accurate  peak detection is  still a challenging problem ,  especially in noisy , degraded, and dynamically varying  rhythms, particularly common in Holter registers. Holter   monitor is an ambulatory ECG device, for portable cardiac  monitoring and frequently, it is corrupted by a substantial  proportion of motion artifacts [1]. Thus, R peak detection is  severely affected  by the ECG signal s with such poor signal  quality and high noise level s [2].   Rpeak detection (segmentation) is the base of arrhythmia  detection and classification. ECG based applications are  generally divided into four phases: preprocessing (filtering),  ECG signal segmentation (QRS complex detection), feature  extraction, and class ification algorithms. Poor segmentation  performance propagates the error to subsequent steps and  directly reduces classification efficiency. Much of the work  in the literature focuses on minimizing the number of false  positives during the classification st ep, ignoring the fact that  the error started to spread during the segmentation step [3],  [4].   One of the most widely used R peak detection  algorithms was deve loped by Pan and Tompkins (P&T) [5],  which served as the benchmark for more than three decades.  Hamilton algorithm emerged as a modification t o the  classical P&T method based on an optimized decision rule Robust R Peak Detection in Low Quality Holter  ECGs using 1D Convolutional Neural Network   Muhammad Uzair Zahid, Serkan Kiranyaz, Turker Ince , Ozer Can Devecioglu, Muhammad E. H.  Chowdhury , Amith Khandakar,  Anas Tahir and Moncef Gabbouj   A > REPLACE THIS LINE WITH YOUR PAPER IDENTIFICATION NUMBER (DOUBLE CLICK HERE TO EDIT) <    2  process [6]. There are several other popular methods for R  peak detection based on various signal processing  techniques such as Wavelet transform [7], Hilbert transform  [8] as well as their modifications with improved detection  thresholds [9], Phasor transform [10], and ensemble  empirical mode decomposition [11], [12] . Discrete wavelet  transform (DWT) decomposes a signal into different  frequency components, each with distinct coefficients,  which contain sufficient information of the original signal  [13]. Sahoo et al. have reported 99.87 % sensitivity in QRS  complex detection using DWT [14]. Similarly, other  techniques such as empirical mode decomposition (E MD)  have helped in removing baseline wandering in ECG signals  [15], Kabir and Shahnaz have provided better time  resolution in removing noise from ECG using the  combinati on of EMD and DWT [16]. Digital fi lters along  with EMD have also been used to improve R peak detection  [17]. Slimange and Ali in [12] have used a nonlinear  transformation technique based on EMD to achieve 99%  sensitivity and specificity. Hilbert and wavelet transform  with varying thresholds have also been u sed for R peak  detection [18].   Many of the aforementioned algorithms depe nd on two  main stages: R peak enhancement and detection. The first  stage involves preprocessing techniques such as filter banks  and spectral analysis, which are sometimes referred to as  feature extraction to enhance the R peak as compared to  other ECG wave s (P and T waves). The detection stage  involves decision making based on a threshold to define the  onset and offset of the R wave. Such algorithms are  lightweight and can be used easily with wearable or  embedded devices. However, they usually perform well only  for high quality and clean ECG signals and are not robust to  noise [19], [20] . Thus, many proposed algorithms evaluate  their detectors o n MIT BIH arrhythmia or similar datasets  that contain high quality ECG signals in standard clinical  settings. Most of the QRS detection algorithms had high  detection sensitivity and positive predictivity in the MIT  BIH arrhythmia data set. (>99%) [21], [22] . The  performance of such algorithms sig nificantly deteriorates  when tested in a highly dynamic and noisy ECG dataset with  severe artifacts. Even the basic QRS detection can be invalid  in the low signal quality ECG analysis. There are some  public datasets [23], [24]  that contain noisy ECG signals  with R peak annotations, but they contain a limited number  of ECG beats, and hence they are not suitable for a proper  performance evaluation in general.   The applications of machine learn ing, e.g., sigmoid radial  basis functions [25], Hidden Markov model (HMM) [26],  and artificial neural network based QRS analysis [27]  have  also been investigated for peak detection and classification  of ECG signals. Rodriguez et al. have proposed a novel QRS  complex detection method [28] using adaptive threshold  with Hilbert transform and Principal component analysis  (PCA). Deep learning has been very successful in speech  recognition, natural language processing, and computer  vision. In recent years, one dimensional convolutional  neural network (1D CNN) has also been intensively studied  for its speed and efficiency in managing complex tasks, that have been demonstrated in se veral signal processing  applications [29], [30]  motor fault detection [31] and  classification of electrocardiogram signals [32] and advance  warning system for cardiac arrhythmias [33]. Two parallel  1D residual neural networks were proposed by Wang et al.,   which can  obtain the time domain characteristics of QRS  waveform and attained 99.98% positive predictive value and  99.92% sensitivity on MIT BIH Arrhythmia dataset (MIT  DB)[34]. Laitala et al. have proposed R peak detection using  Long Short Term Memory (LSTM) network which excels at  temporal modeling tasks that  include long term  dependencies, making it suitable for ECG analysis [35].  Similarly, Vijayrangan et al. have proposed a deep learning  based method using U Net combined with Inception and  Residual blocks on a combination of datasets and have  achieved around 98.37 % accuracy [36]. A two level CNN  was proposed by Xiang et al. with a precision and sensitivi ty  of 99.91% and 99.77%, respectively over the MIT DB [37].  Oh et al. tried to use UNET fo r ‚Äúsample wise classification‚Äù  of ECG into R and Non R peak labels. A major drawback of  this proposed approach is that it has suffered too many false  positives, caused by the misclassification of surrounding  samples at the R peak, with a sensitivity level as low as  29.55% despite the fact that ECG quality is high [38].  All of the abovementioned algorithms were only tested on  the high quality clinical ECG records such as in the MIT  DB with a limited number of beats, i.e., the total number of  beats of about 100K. A faster regional CNN was proposed  by Yang et al. by t urning a 1D ECG signal into a 2D image.  The model was tested on the 24 hours wearable ECG  recordings and showed promising results with 98.52%  positive predictively and 98.76% sensitivity [39]. This was  the first study that evaluated noisy and l owquality ECG  records acquired by a wearable ECG sensor. Another major  issue in using deep learning methods for R peak detection is  the limited number of ECG beats partitioned further for  training, validation, and test sets. Besides, most of these  methods  test their robustness by artificially adding noise,  i.e., baseline wanders and motion artifacts to ECG records in  the MIT DB. Such artificial artifact creation may not  represent the actual variations and degradations that occur in  Holter and mobile ECG de vices. Thus, the performance of  these algorithms would deteriorate in practice specifically on  Holter devices where the signal is corrupted with a high  level of noise and frequent artifacts and ECG baseline level  varies drastically and abruptly. The challe nges for accurate  peak detection in Holter devices include powerline  interference, baseline wandering, amplitude variability,  multi source PVC, noise, and other abnormal interference  such as atrial fibrillation (AF) and electrode sliding  interference.  Figure 1 shows typical ECG signals from the  CPSC DB where the benchmark Pan Tompkins method  yields many false positives (FPs) and false negatives (FNs) .  Therefore, there is a need for a robust and highly accurate R  peak detector for low quality ECG signals.          > REPLACE THIS LINE WITH YOUR PAPER IDENTIFICATION NUMBER (DOUBLE CLICK HERE TO EDIT) <    3  FP FNFP FNFP FNFP FNFP FNFP FNFP FN FPFN FPFP FPFN FP FPFPFN FPFPFP FPFP FP FP FPFP FPFP FPFP   Figure 1: Typical Holter ECG segments from the record of patient 6 in the CPSC dataset. R ed circles represent the R  peaks detected by the PanTompkins method where several false positives (FPs) and false negatives (FNs) are visible.     To address the aforementioned limitations and drawbacks, in  this study, we propose a novel and robust peak detection  technique that can specifically be used for Holter devices or  any other ECG acquisition system in non clinical settings. For  this purpose, first, we labeled the R peak locations of the  largest ECG Holter dataset with more than 1M beats. Then,  we formulate R peak detection as a 1D segmentation problem  to enable the detection of the  precise localization of R peaks  with minimal post processing. To accomplish this, the 1D  Encoder Decoder CNN model is constructed for the peak  detection in a 20 second normalized ECG segment that  outputs a reconstructed signal of equal length with a 1D  segmentation map where a 5 sample pulse is centered at the  location of each R peak. It is also desirable to minimize (or  suppress) false alarm rate especially when patients are in the  intensive care unit (ICU) as higher false alarms decrease the  quality of c are by increasing patient delirium through noise  pollution and slowing staff response times [19], [40], [41] .  Thus, the proposed a pproach further improves the accuracy  with a verification model that can approximately reduce 21%  of the false alarms.   We evaluate the proposed approach on both benchmark  datasets, MIT DB and CPSC DB, and thus, this becomes the  first method that has ever b een evaluated with more than 1M  annotated beats (N, S, and V type beats). An extensive set of  experimental results show that the proposed approach  outperforms all state oftheart Rpeak detection methods in   CPSC DB with a significant performance gap while  it  achieves a similar or better result in MITDB without  explicit  training in this dataset. The proposed method is further  evaluated specifically for the R peak detection of abnormal  beats (e.g., S and V beats).  This is indeed a challenging task  compared  to the detection of normal beats. In short, the  novelty and significant contributions of the study are as  follows:   ‚Ä¢ We propose a robust algorithm for the R peak detection in  lowquality Holter ECGs. Despite numerous classification  methods in this domain, we approach this as a regression  problem for utmost robustness and detection performance. From each ECG segment, a pulse train is produced from  which the R peaks can be detected through minimal post  processing.   ‚Ä¢ We proposed a novel verification model to red uce the  number of false alarms in R peak detection with a  significant margin.   ‚Ä¢ We demonstrated the generalization capacity of the  proposed algorithm by evaluating it on the gold  benchmark MIT dataset and achieved a state oftheart  performance level without even training over this dataset.   ‚Ä¢ We provided ground truth peak locations for the largest  Holter ECG dataset with more than 1M beats and this  dataset will be released with R peak annotations.   ‚Ä¢ Finally, this is the first study that has been quantitatively  evaluated over the largest Holter ECG dataset for R peak  detection. In particul ar, the proposed algorithm achieved  enhanced sensitivity performance for detecting abnormal  S and V beats specifically.   The rest of the paper is organized as follows: Section II  outlines the ECG datasets used in this study. The detailed R  peak detection a pproach is presented in Section III. In Section  IV, the performance and robustness of the proposed approach  are evaluated over the two benchmark datasets using the  standard performance metrics and the results are compared  with the previous state oftheart works. Finally, Section V  concludes the paper and suggests topics for future work.    II. DATASETS   This section talks in detail about the two databases that are  used for training and evaluation of the novel R peak detection  algorithm.   A. China Physiological Signal  Challenge 2020   The China Physiological Signal Challenge (2020) dataset  (CPSC DB) consists of 10 single lead ECG recordings which  are collected from arrhythmia patients, each of the recordings  lasts for about 24 hours (shown in Table I) [42]. > REPLACE THIS LINE WITH YOUR PAPER IDENTIFICATION NUMBER (DOUBLE CLICK HERE TO EDIT) <    4  Table I: Detailed information on the ECG data from  CPSC DB.  Patient  AF? Length(h)  # Tot.  Beats  # V  Beats  # S  Beats   1 No 25.89  109731  0 24  2 Yes 22.83  108297  4554  0  3 Yes 24.70  138878  382 0  4 No 24.51  101734  19024  3466   5 No 23.57  94635  1 25  6 No 24.59  770806  0 6  7 No 23.11  96814  15150  3481   8 Yes 25.46  125495  2793  0  9 No 25.84  89854  2 1462   10 No 23.64  82851  169 9071     Table I also indicates if the patient has undergone atrial  fibrillation (AF) or not. All ECG data were acquired by a  unified wearable ECG device with a sampling frequency of  400 Hz and the total numbe r of beats is 1,026,095 . The  recordings include irregular heart rhythms as well as SPB (S)  and PVC (V) type beats. All recordings are provided in  MATLAB format with corresponding S and V beats  annotations. R peak annotations for each ECG cycle were  annotat ed by a team of biomedical researchers . To show the  robustness of the R peak detector against noise and other  artifacts, CPSC DB presents a real world Holter dataset  containing numerous ECG containments and artifacts.   B.  MITBIH arrhythmia dataset   The second  benchmark dataset used for evaluation and  performance comparisons is the MITBIH arrhythmia dataset  that consists of 48 two lead ECGs from 47 subjects which are  sampled at 360 Hz and each record covers 30 minutes [43].  This dataset has been widely used as a benchmark and it is the  most popular clinical ECG database for the evaluation of peak  detection algorithms. The signals in this dataset are relatively  clean and of high quality, collected in clinical settings. The  modified lead II ECG was used in this study and the total  number of beats is 109,475.   III. METHODOLOGY   "
340,VGGSound: A Large-scale Audio-Visual Dataset.txt,"Our goal is to collect a large-scale audio-visual dataset with low label
noise from videos in the wild using computer vision techniques. The resulting
dataset can be used for training and evaluating audio recognition models. We
make three contributions. First, we propose a scalable pipeline based on
computer vision techniques to create an audio dataset from open-source media.
Our pipeline involves obtaining videos from YouTube; using image classification
algorithms to localize audio-visual correspondence; and filtering out ambient
noise using audio verification. Second, we use this pipeline to curate the
VGGSound dataset consisting of more than 210k videos for 310 audio classes.
Third, we investigate various Convolutional Neural Network~(CNN) architectures
and aggregation approaches to establish audio recognition baselines for our new
dataset. Compared to existing audio datasets, VGGSound ensures audio-visual
correspondence and is collected under unconstrained conditions. Code and the
dataset are available at http://www.robots.ox.ac.uk/~vgg/data/vggsound/","Largescale datasets [1, 2] have played a crucial role, in many deep learning recognition tasks [3, 4, 5]. In the audio analy sis domain, while several datasets have been released in the past few years [6, 7, 8, 9], the data collection process usually requires extensive human efforts, making it unscalable and often limited to narrow domains. AudioSet [10], is a large scale audiovisual dataset containing over 2 million clips in unconstrained conditions. This is a valuable dataset, but it required expensive human veriÔ¨Åcation to construct it. In con trast to these manually curated datasets, recent papers have demonstrated the possibility of collecting highquality human speech datasets in an automated and scalable manner by using computer vision algorithms [11, 12, 13]. In this paper, our objective is to collect a largescale au dio dataset, similar to AudioSet , containing various sounds in the natural world and obtained ‚Äòin the wild‚Äô from uncon strained opensource media. We do this using a pipeline basedon computer vision techniques that guarantees audiovisual correspondence ( i.e. the sound source is visually evident) and low label noise, yet requires only minimal manual effort. Train Val Test Total train Total Classes 130900 20 50 177,837 199,467 309 Table 1 .VGGSound Dataset Statistics. The number of clips for each class in the train/val/test partitions and the total num bers of train and classes. Our contributions are threefold: The Ô¨Årst is to propose an automated and scalable pipeline for creating an ‚Äòin the wild‚Äô audiovisual dataset with low label noise. By using existing image classiÔ¨Åcation algorithms, our method can generate accurate annotations, circumventing the need for human annotation. Second, we use this method to curate VGGSound , a largescale dataset with over 200k video clips (visual frames and audio sound) for 309audio classes, from YouTube videos. Each 10s clip contains frames that show the object making the sound, and the audio track con tains the the sound of the object. There are at least 200clips for each audio class. Our third contribution is to establish baseline results for audio recognition on this new dataset. To this end, we investigate different architectures, global average pooling and NetVLAD [14, 15], for training deep CNNs on spectrograms extracted directly from the audio Ô¨Åles with little preprocessing. We expect VGGSound to be useful for both audio recog nition and audiovisual prediction tasks. The goal of audio recognition is to determine the semantic content of an acous tic signal, e.g. recognizing the sound of a car engine, or a dog barking, etc. In addition, VGGSound is equally well suited for studying multimodal audiovisual analysis tasks, for ex ample, audio grounding aims to localize a sound spatially, by identifying in an image the object(s) emitting it [16, 17]. Another important task is to separate the sound of speciÔ¨Åc objects as they appear in a given frame or video clip [18, 19]. 2. RELATED WORK "
291,Reachability Analysis of a General Class of Neural Ordinary Differential Equations.txt,"Continuous deep learning models, referred to as Neural Ordinary Differential
Equations (Neural ODEs), have received considerable attention over the last
several years. Despite their burgeoning impact, there is a lack of formal
analysis techniques for these systems. In this paper, we consider a general
class of neural ODEs with varying architectures and layers, and introduce a
novel reachability framework that allows for the formal analysis of their
behavior. The methods developed for the reachability analysis of neural ODEs
are implemented in a new tool called NNVODE. Specifically, our work extends an
existing neural network verification tool to support neural ODEs. We
demonstrate the capabilities and efficacy of our methods through the analysis
of a set of benchmarks that include neural ODEs used for classification, and in
control and dynamical systems, including an evaluation of the efficacy and
capabilities of our approach with respect to existing software tools within the
continuous-time systems reachability literature, when it is possible to do so.","Neural Ordinary DiÔ¨Äerential Equations (ODEs) were Ô¨Årst introduced in 2018, as a radical new neural network design that boasted better memory eÔ¨Éciency, and an ability to deal with irregularly sampled data [ 21]. The idea behind this family of deep learning models is that instead of specifying a discrete sequence of hidden layers, we instead parameterize the derivative of the hidden states using a neural network [ 8]. The output of the network can then be computed using a diÔ¨Äerential equation solver [ 8]. This work has spurred a whole range of followup work, and since 2018 several variants have been proposed, such as augmented neural ODEs (ANODEs) and their ensuing variants [ 39,11,16]. These variants provide a more expressive formalism by augmenting the state space of neural ODEs to allow for the Ô¨Çow of state trajectories to cross. This crossing, prohibited in the original framework, allows for the learning of more complex functions that were prohibited by the original neural ODE formulation [11]. Due to the potential that neural networks boast in revolutionizing the de velopment of intelligent systems in numerous domains, the last several years Extended version of the paper to appear at FORMATS 2022 [35].arXiv:2207.06531v1  [cs.LG]  13 Jul 2022have witnessed a signiÔ¨Åcant amount of work towards the formal analysis of these models. The Ô¨Årst set of approaches that were developed considered the formal veriÔ¨Åcation of neural networks (NN), using a variety of techniques including reach ability methods [ 46,47,3,40], and SAT techniques [ 29,30,13]. Thereafter, many researchers proposed novel formal method approaches for neural network control systems (NNCS), where the majority of methods utilized a combination of NN and hybrid system veriÔ¨Åcation techniques [ 14,22,44,26,23,6]. Building on this work, a natural outgrowth is extending these approaches to analyze and verify neural ODEs, and some recent studies have considered the analysis of formal properties of neural ODEs. One such study aims to improve the understanding of the inner operation of these networks by analyzing and experimenting with multiple neural ODE architectures on diÔ¨Äerent benchmarks [ 36]. Some studies have considered analyses of the robustness of neural ODEs such as [ 7] and [48], which evaluate the robustness of image classiÔ¨Åcation neural ODEs and compare the eÔ¨Écacy of this class of network against other more traditional image classiÔ¨Åer architectures. The Ô¨Årst reachability technique targeted for neural ODEs presented a theoretical regime for verifying neural ODEs using Stochastic Lagrangian Reachability (SLR) [19]. This method is an abstractionbased technique that computes conÔ¨Ådence intervals for the calculated reachable set with probabilistic guarantees. In a followup work, these methods were improved and implemented in a tool called Gotube [ 20], which is able to compute reach sets for longer time horizons than most stateoftheart reachability tools. However, these methods only provide stochastic bounds on the reach sets, so there are no formal guarantees on the derived results. To the best of our knowledge, this paper presents the Ô¨Årst deterministic veriÔ¨ÅcationframeworkforageneralclassofneuralODEswithmultiplecontinuous time and discretetime layers. In this work, we present our veriÔ¨Åcation framework NNVODE that makes use of deterministic reachability approaches for the analysis of neural ODEs. Our methods are evaluated on a set of benchmarks with diÔ¨Äerent architectures and conditions in the area of dynamical systems, control systems, and image classiÔ¨Åcation. We also compare our results against three stateofthe art veriÔ¨Åcation tools when possible. In summary, the contributions of this paper are: ‚ÄìWe introduce a general class of neural ODEs that allows for the combination of multiple continuoustime and discretetime layers. ‚ÄìWedevelopNNVODE,anextensionofNNV[ 46],toformallyanalyzeageneral class of neural ODEs using sound and deterministic reachable methods. ‚ÄìWe run an extensive evaluation on a collection of benchmarks within the context of timeseries analysis, control systems, and image classiÔ¨Åcation. We compare the results to Flow*, GoTube, and JuliaReach for neural ODE architectures where this is possible. 22 Background and Problem Formulation Neural ODEs emerged as a continuousdepth variant of neural networks becoming a special case of ordinary diÔ¨Äerential equations (ODEs), where the derivatives are deÔ¨Åned by a neural network, and can be expressed as: _z=g(z); z (t0) =z0; (1) where the dynamics of the function g:Rj!Rpare represented as a neural network, and initial state z02Rj, wherejcorresponds to the dimensionality of the statesz. Aneural network (NN) is deÔ¨Åned to be a collection of consecutively connected NNLayers as described in DeÔ¨Ånition 1. DeÔ¨Ånition 1 ( NNLayer). ANNLayeris a function h: Rj!Rp, with input x2Rj, output y2RpdeÔ¨Åned as follows y=h(x) (2) where the function his determined by parameters , typically deÔ¨Åned as a tuple  =h,W,bifor fullyconnected layers, where W2Rjp,b2Rp, and activation function:Rj!Rp, thus the fullyconnected NNLayer is described as y=h(x) =(W(x) +b): (3) However, for other layers such as convolutionaltype NNLayers,may include parameters like the Ô¨Ålter size, padding, or dilation factor and the function h in(3)may not necessarily apply. For a formal deÔ¨Ånition and description of the reachability analysis for each of these layers that are integrated within NNVODE, we refer the reader to Section 4 of [ 43]. For the Neural ODEs (NODEs), we assume thatgis Lipschitz continuous, which guarantees that the solution of _z=g(z) exists. This assumption allows us to model gwithmlayers of continuously diÔ¨Äerentiable activation functions kfork2f1;2;:::;mgsuch as sigmoid, tanh, and exponential activation functions. Described in (1)is the notion of a NODE as introduced in [8] and an example is illustrated in Figure 1. DeÔ¨Ånition 2 (NODE). ANODEis a function _z=g(z)withmfullyconnected NNLayers, and it is deÔ¨Åned as follows _z=g(z) =hm(hm"
329,Incremental Verification of Fixed-Point Implementations of Neural Networks.txt,"Implementations of artificial neural networks (ANNs) might lead to failures,
which are hardly predicted in the design phase since ANNs are highly parallel
and their parameters are barely interpretable. Here, we develop and evaluate a
novel symbolic verification framework using incremental bounded model checking
(BMC), satisfiability modulo theories (SMT), and invariant inference, to obtain
adversarial cases and validate coverage methods in a multi-layer perceptron
(MLP). We exploit incremental BMC based on interval analysis to compute
boundaries from a neuron's input. Then, the latter are propagated to
effectively find a neuron's output since it is the input of the next one. This
paper describes the first bit-precise symbolic verification framework to reason
over actual implementations of ANNs in CUDA, based on invariant inference,
therefore providing further guarantees about finite-precision arithmetic and
its rounding errors, which are routinely ignored in the existing literature. We
have implemented the proposed approach on top of the efficient SMT-based
bounded model checker (ESBMC), and its experimental results show that it can
successfully verify safety properties, in actual implementations of ANNs, and
generate real adversarial cases in MLPs. Our approach was able to verify and
produce adversarial examples for 85.8% of 21 test cases considering different
input images, and 100% of the properties related to covering methods. Although
our verification time is higher than existing approaches, our methodology can
consider fixed-point implementation aspects that are disregarded by the
state-of-the-art verification methodologies.","Artificial neural networks (ANNs) are soft computing models usually employed for regression, machine learning, and pattern recognition problems [ 9] . ANNs reflect the behavior of biological neural networks, making them a suitable paradigm for learning tasks and have been recently used to perform various safetycritical tasks. For instance, Amato et al. used ANNs to predict medical diagnosis [ 4], while Bojarski et al. [10] employed them to perform steering commands in selfdriving Authors‚Äô addresses: Luiz Sena, Federal University of Amazonas, coelho.luiz.sena@gmail.com; Erickson Alves, Sidia Institute of Science and Technology, erickson.higor@gmail.com; Iury Bessa, Federal University of Amazonas, iurybessa@ufam.edu.br; Eddie Filho, TPV, eddie.filho@tpvtech.com; Lucas Cordeiro, University of Manchester, lucas.cordeiro@manchester.ac.uk. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. ¬©2020 Association for Computing Machinery. XXXXXXXX/2020/12ART $15.00 https://doi.org/10.1145/nnnnnnn.nnnnnnn , Vol. 1, No. 1, Article . Publication date: December 2020.arXiv:2012.11220v1  [cs.LO]  21 Dec 20202 Luiz Sena, Erickson Alves, Iury Bessa, Eddie Filho, and Lucas Cordeiro cars. Unfortunately, in such a context, incorrect classifications can cause serious problems. Indeed, adversarial disturbances can make ANNs misclassify objects, thus causing severe damage to users of safetycritical systems. For instance, Eykholt et al. [15] showed that noise and disturbances, such as graffiti on traffic signals, could result in target misclassification, during operation of computer vision systems. Moreover, given that ANNs are notorious for being difficult to interpret and debug, the whole scenario becomes even more problematic [ 37], which then claims for techniques able to assess their structures and verify results and behaviors. Prior work, available in the literature, focused on verifying robustness for manuallywritten models of neural networks [ 26,30,46,53]. The typical approach consists in modeling an ANN and its corresponding verification properties, in SMTLIB [ 6], using integer and real arithmetic theories, and then employ offtheshelf SMT solvers to find property violations. Recently, Murthy et al. [40] have used SMT to quantify neuralnetwork robustness regarding parameter perturbation. Unfortunately, such verification schemes can not precisely capture issues that appear in implementations of ANNs, for two main reasons: (i)one can not model bitlevel operations using the theory of integer and real arithmetic [ 14], and (ii)libraries, such as TensorFlow [ 21], often take advantage of available graphics processing units (GPUs) to explore the inherent parallelism of ANNs; the translation to GPUs can be problematic [ 42,45]. Finally, it has been pointed out by Odena et al. [42] that there exist errors in the Tensorflow graph representation of neural networks, such as numerical errors and disagreements between ANN implementations and their quantized versions. We propose a verification technique that exploits ANN implementations, through operational models, to infer invariants, which is based on incremental bounded model checking (BMC). BMC is a popular verification technique that translates a program into a formula and then uses Boolean Satisfiability (SAT) or Satisfiability Modulo Theories (SMT) solvers to check bugs. Moreover, that happens up to some bound ùëòon the depth of a program ( e.g., depth of data structures, loop iterations, call chains, etc.), whose choice is critical for the efficiency of a BMC tool [ 22]. In particular, the incremental BMC refers to the repeated execution of BMC for increasing values of ùëò, until all loops are unrolled, or maximum depth is reached. Here, our main contribution is an ANNcustom verification method for inferring invariants based on intervals, which are introduced into an ANN implementation as assumptions based on incremental BMC. For instance, Sigmoid is an activation function commonly used in MLP [ 9], which contains one or more hidden layers (apart from one input and one output layer), whose output ranges from 0to1. Consequently, this information is added to a verification model, as an assumption to help prune the statespace exploration. One may notice that activation functions used for ANNs are nonlinear elements with mathematical operations that are computationally expensive for SAT/SMT solvers. Nonetheless, depending on the weights and the range of input values, these operations can be avoided since the behavior of such nonlinear functions may be constant for some intervals. Therefore, the invariant inference can help reduce verification times by simplifying ANNs‚Äô output computation for some input intervals, on an incremental BMC framework. Thus, we exploit incremental BMC based on invariant inference to verify actual implementations of ANNs in CUDA [ 1]. Each inferred invariant is converted into an assumption and propagated through the control flow to each program point; we use these assumptions to encode and check path guards, thereby avoiding the exploration of unfeasible paths. In the proposed symbolic verification framework, boundaries are computed from a neuron‚Äôs input and propagated to find its effective output, given that the input of a neuron is the output of the previous one. In addition to checking a range of languagespecific safety properties, such as the absence of arithmetic under and overflow, outofbounds array indexing, and nullpointer dereferencing, we also consider properties that are inherent to the design of ANNs, such as coveringmethod validation based on modified condition/decision coverage (MC/DC) [ 24], which measures how adversarial two , Vol. 1, No. 1, Article . Publication date: December 2020.Incremental Verification of FixedPoint Implementations of Neural Networks 3 images are. We also obtain adversarial cases from ANNs that could lead to system malfunctioning. Moreover, if real implementations are tackled, one additional problem arises: the word length used to store data and operate over them. Data representation in computers is inherent finite, even with floatingpoint [ 12]. It may become a considerable concern when fixedpoint arithmetic comes into play, which is usually known as the finite wordlength (FWL) problem. The proposed framework takes it into account and can check an ANN implemented with a particular FWL format, which means those safe entities could be promptly deployed on real target systems. Our approach is implemented on top of the efficient SMTbased bounded model checker (ES BMC) [ 17,18], which is extended with operational models [ 39,43] that handle the CUDA deep learning primitives cuDNN [ 13] and cuBLAS [ 41], being that a simple and elegant verification approach. Instead of providing a complex scheme or model capable of capturing properties of neural networks, we instrument basic calls and verify a program‚Äôs correctness regarding their use, as implemented on a real platform. A pattern recognition benchmark [ 45] is employed to evaluate the performance and correctness of the proposed approach. We have performed conformance testing [ 32] over our CUDA (operational) models to determine whether they comply with the requirements of the ANNs, which was performed through exhaustive execution with deterministic inputs. This way, traceable behavior was sought to reproduce the same results. Our experimental results show that ESBMC correctly validates all covering methods. Verification times were no longer than a minute, when checking how adversarial two images are, concerning the ANN neurons. Additionally, the proposed framework was able to produce 19adversarial cases, which was confirmed by validation scripts in MATLAB. This step is required to concretize and prove that real adversarial case exists. However, the associated verification times were higher than other existing approaches ( e.g.., Deep Learning Verification [ 26]), due to the bitaccurate precision of the employed verification process. In summary, this paper describes the following additional original contributions: ‚Ä¢development of an operational model (OM) to handle CUDA primitives (cf. Section 3.2); ‚Ä¢development of a methodology that tackles challenges specific to ANNs, such as cover age, which uses mutants for activating new neurons, adversarial cases, and finiteprecision arithmetic and its rounding errors (cf. Sections 4.1 and 4.2); ‚Ä¢speedup of one order of magnitude, over a conventional incremental BMC engine and when checking covering methods, due to the use of invariants (cf. Section 5.3); ‚Ä¢provision of research artifacts, including benchmarks, tools, and experimental results, which are all available for download. Experimental results show that the proposed approach can efficiently validate coverage methods in a few minutes. Moreover, implementations of ANNs, for a set of intricate benchmarks obtained from the available literature, can be adequately verified: the median runtime for our benchmark set, considering the incremental BMC approach and using invariant inference, is around 46h. Despite the high verification time, our proposed approach was able to find violations in ANN CUDA implementations, considering the fixedpoint arithmetic and FWL, in 85.8 % of 21 test cases for a vocalic images recognition benchmark. The remaining of this paper is organized as follows. Section 2 provides preliminaries about artificial neural networks, including implementation aspects, activation functions, and notions of bounded model checking of software with particular focus on ANN implementations. Section 3 tackles our incremental verification method using invariant inference by focusing on the base case and forward condition steps; we also provide details of our invariant inference based on interval analysis and operational models for ANNs in CUDA. Section 4 describes the validation of covering methods and our verification algorithm to obtain adversarial cases in ANN implementations. , Vol. 1, No. 1, Article . Publication date: December 2020.4 Luiz Sena, Erickson Alves, Iury Bessa, Eddie Filho, and Lucas Cordeiro Section 5 presents our experimental results for covering methods and adversarial examples. Section 6 analyses the related work. Finally, Section 7 concludes and outlines future work. 2 PRELIMINARIES 2.1 Artificial Neural Networks (ANNs) ANNs are efficient models for statistical pattern recognition, making them a suitable paradigm for learning tasks [ 9]. Learning, in ANNs, is based on modifying the synaptic weights of their interconnected units, which will fit their values according to a given set of labeled examples or tasks, during a training phase. A training algorithm uses each input example to converge these weights to specific results. Mainly, ANNs are broadly employed to solve classification problems, and one crucial property regarding that is their generalization ability for adversarial situations [ 23], i.e., when input patterns are disturbed, for instance, by noise, occlusion, or even sensor defects. Nonetheless, such an ability may not be enough to avoid misclassification, depending on the quality of input features, which may lead to severe problems. For instance, an ANN used in vehicles‚Äô driver assistant systems, which was developed for recognizing traffic signs [ 28], may indicate a wrong sign due to adversarial visibility conditions and then cause accidents. There exist various algorithms to train ANNs: backpropagation is a commonly used example [ 23]. ANN architectures vary in type of layers, activation functions, number of layers, and neurons. One example is MLP [ 25], which is a classic and commonly used ANN that consists of at least three layers: input, hidden, which employs a nonlinear activation function, and output layers. Fig. 1 illustrates an example of ANN with ùêølayers andùëÅùëôneurons for each ùëôth layer, with ùëô=1,...ùêø . The ANN has ùëÄ=ùëÅ1=4inputs, and ùëÇ=ùëÅ5=3output. In this ANN, each neuron of the ùëôth layer, denoted by ùëõùëò,ùëô, withùëò=1,...ùëÅùëô, is connected to all neurons ùëõùëó,ùëô‚àí1of the previous one, with ùëó=1,...ùëÅùëô‚àí1. Each neuron is structured as shown in Fig. 2. Input #1 ùëñ1 Input #2 ùëñ2 Input #3 ùëñ3 Input #4 ùëñ4ùëõ1,1 ùëõ2,1 ùëõ3,1 ùëõ4,1ùëõ1,2 ùëõ2,2 ùëõ3,2 ùëõ4,2 ùëõ5,2ùëõ1,ùëô ùëõ2,ùëô ùëõ3,ùëô ùëõ4,ùëô ùëõ5,ùëô... ... ... ... ...ùëõ1,ùêøOutput #1 ùëú1 ùëõ2,ùêøOutput #2 ùëú2 ùëõ3,ùêøOutput #3 ùëú3...Hidden layerùëô=2Hidden layer ùëô=ùêø‚àí1Input layerùëô=1Output layer ùëô=ùêø Fig. 1. Example of an ANN. The activation potential ùë¢ùëò,ùëôof an input i= {ùëñ1,ùëñ2...,ùëñùëÄ}, for neuron ùëõùëò,ùëô, is computed with ùë¢ùëò,ùëô(ùëñ)=ùëÄ‚àëÔ∏Å ùëó=1ùë§ùëô ùëó,ùëòùëñùëó+ùëèùëò,ùëô, (1) whereùë§ùëô ùëó,ùëòis the synaptic weight between neurons ùëõùëó,ùëô‚àí1andùëõùëò,ùëô, andùëèùëò,ùëôis the bias of ùëõùëò,ùëô. The neuron output ùë¶ùëò,ùëôis computed by means of the activation function N(¬∑) evaluated for the activation potentialùë¢ùëò,ùëô. ReLU [ 36], Sigmoid, and Gaussian [ 9] are activation functions commonly used in MLP. Our experimental results are obtained from MLPs implemented with the activation functions , Vol. 1, No. 1, Article . Publication date: December 2020.Incremental Verification of FixedPoint Implementations of Neural Networks 5 Sigmoid and ReLU. Therefore, the output of ùëõùëò,ùëôis computed as ùë¶ùëò,ùëô=N(ùë¢ùëò,ùëô)=1 1+ùëí‚àíùë¢ùëò,ùëô. (2) ùëñùëó Œ£N(ùë¢ùëò,ùëô)Activate function ùë¶ùëò,ùëôOutputùëñ1 ùëñùëÄBias ùëèùëò,ùëô ... ...ùë§ùëô 1,ùëò ùë§ùëô ùëó,ùëò ùë§ùëô ùëÄ,ùëòùë¢ùëò,ùëô WeightsInputs Fig. 2. Detailed view of a single neuron ùëõùëò,ùëô. 2.2 Bounded Model Checking of Software BMC has been successfully applied to find errors in software systems, including commercial modules [ 14]. The idea of BMC is to unwind a program and its correctness properties ùëòtimes, while generating a logical formula, in a decidable fragment of firstorder logic, that is satisfiable iffa counterexample of size ùëò(or lower) exists [ 8]. Consequently, this technique is incomplete, as there might still be a counterexample that requires more than kunwinds to be detected. As an example, Fig. 3 shows a code fragment that normalizes an image by changing the range of pixel intensity values. Figure 3(a) shows the original code, while Fig. 3(b) shows the corresponding C program in static single assignment (SSA) form, where every variable has only one definition. This is achieved by introducing a fresh variable from an original name ( e.g., with a subscript), such that every assignment has a unique lefthand side, as shown in Fig. 3(b). One may notice that BMC unwinds this program up to a bound ùëÜùêºùëçùê∏ and translates the corresponding SSA into a verification conditionùúì, which is satisfiable iffthe assertion in line 18of Figure 3(a), i.e.,ùëñùëöùëî[ùëñùëõùëëùëíùë•]>= 0.0ùëì&&ùëñùëöùëî[ùëñùëõùëëùëíùë•]<=1.0ùëì, fails. One may notice that standard IEEE 7542008 [ 27] defines arithmetic operations, conversion and comparison methods, and also total ordering of floating point numbers [ 20]. Our underlying verification engine follows that standard for reasoning over ANN implementations that contain floatingpoint numbers [19]. It is also worth mentioning that BMC can nondeterministically choose assignment values for variables while limiting their range with program instructions to make them similar to real user scenarios. These aspects help prune statespace exploration, which makes BMC less susceptible to the state space explosion problem [ 14]. Both aspects are respectively illustrated in lines 11and12 of Figure 3(a). Also, SSA representation can be translated into an SMTLIB problem using either bitvectors or the abstract numerical domains (e.g., Z,R), while an SMT solver is used to reason about satisfiability, i.e., check whether a violation is found. 2.2.1 Incremental BMC. Incremental BMC uses an iterative technique and verifies imperative programs for each unwind bound, indefinitely, or until it exhausts time or memory limits. Incre mental BMC aims to either find a counterexample up to kloop unwindings or unwind all loops fully. This algorithm relies on a symbolic execution engine to increasingly unwind a loop after each iteration. Such an approach is divided into two steps: a search for property violations and a procedure that checks whether all loops were fully unwound. When searching for violations, the incrementalBMC technique replaces all unwinding assertions ( i.e., assertions to check if a loop was completely unrolled) by unwinding assumptions. Typically, this would lead to unsound behavior; , Vol. 1, No. 1, Article . Publication date: December 2020.6 Luiz Sena, Erickson Alves, Iury Bessa, Eddie Filho, and Lucas Cordeiro 1# include <assert.h> 2# define SIZE 5 3typedef unsigned short int ushort ; 4voidnormalizef( float*image, ushort size) { 5ushort i; 6for(i = 0; i < size; i++) { 7image[i] = (image[i]) * (1.0f/255.0f ); 8} 9} 10intmain( void){ 11 ushort x1 = nondet_ushort(); 12 assume((x1 >=0) && (x1 <= 255)); 13... 14 floatimg[SIZE] = {x1,x2,x3,x4,x5}; 15normalizef(img, SIZE); 16uint index = nondet_ushort(); 17 assume(index>=0 && index <SIZE); 18 assert(img[index]>=0.0f && img[index ]<=1.0f); 19 return 0; 20} (a)1x1#1 == return_value_nondet_ushort#1 2assume x1#1 >= 0 && x1#1 < 255 3... 4x5#1 == return_value_nondet_ushort#5 5assume x5#1 >= 0 && x5#1 < 255 6index#1 == return_value_nondet_ushort #6 7assume index#1 >= 0 && index#1 < 5 8assert img#1[index#1] >= 0.0f && img #1[index#1] <= 1.0f (b) Fig. 3. (a) A simple C program to normalize an image. (b) A simplified version of the corresponding unwound C program of (a) converted into SSA form, where ‚Äú...‚Äù means missing statements omitted for simplicity. however, the first step can only find property violations, thus reporting that an unwinding assertion failure is not a real bug. The next step checks if all loops in a program were fully unrolled, which is done by ensuring that all the unwinding assertions are unsatisfied. No assertion is checked in the second step because they were already checked in the first one, for the current kloop unwinding. The incremental BMC algorithm also offers the option to change the increment granularity; the default value is 1. One may notice that changing the increment value can lead to slower verification times and might not present the shortest possible counterexample for a property violation. Incremental BMC is particularly essential to avoid guessing exceedingly large bounds, which might result in prohibitively significant decision problems, thereby making a verifier to run out of resources, before it can provide a result [22]. 2.2.2 Verify Actual Implementation of ANNs with Incremental BMC. ANNs are typically imple mented through matrix operations, such as sum, subtraction, and multiplication, which are particu larly expensive for bitaccurate verifiers that check safety for actual implementations of ANNs. CUDA is one of the mainstream programming languages to implement an ANN. For example, TensorFlow [ 21] allows software developers to write ANNs in Python, but it converts them into CUDAcompatible GPU code using the cuBLAS [41] and cuDNN [13] libraries. This way, a verifica tion methodology based on actual implementations should directly consider such libraries as basic building blocks to be instrumented, without carrying about the exact model for a neural network. Here, we rely on ESBMC [ 14], which is an awardwinning model checker [ 17,18] targeted at verifying realworld C programs. In order to support CUDA operations, an OM, i.e., an abstract representation of the standard CUDA libraries, which conservatively approximates their seman tics, is employed to verify CUDAbased programs. This way, verification of ANNs and their real implementations are considered in a unified framework. In particular, ESBMC considers the verification of ANN implementations that are subject to FWL effects, which are further amplified in fixedpoint processors [ 2,11]. Arithmetic operations with fixedpoint variable are different from the ones with real numbers, since there are some nonlinear , Vol. 1, No. 1, Article . Publication date: December 2020.Incremental Verification of FixedPoint Implementations of Neural Networks 7 phenomenons, e.g., overflows and roundoffs. Let ‚ü®ùêº,ùêπ‚ü©denote a fixedpoint format and F‚ü®ùêº,ùêπ‚ü©(ùë•) denote a real number ùë•represented in the fixedpoint domain, with ùêºbits representing the integer part andùêπbits the decimal one. The smallest absolute number ùëêùëöthat can be represented in such a domain isùëêùëö=2‚àíùêπ, and any mathematical operations performed at F‚ü®ùêº,ùêπ‚ü©(ùë•)will introduce errors. Here, we treat fixedpoint operators for sums, multiplications, subtractions, and divisions, within our BMC framework, as fxp_add ,fxp_mult ,fxp_sub , andfxp_div , respectively. Lastly, ESBMC also explicitly explores the possible interleavings of C programs (up to the given context bound), while treating each interleaving itself symbolically. It employs monotonic partial order reduction [ 29] and kinduction [ 16], with the goal of efficiently pruning the statespace exploration, and verifies properties such as userspecified assertions, deadlocks, memory leaks, invalid pointer dereference, array outofbounds, and division by zero, in C programs. 3 INCREMENTAL VERIFICATION OF NEURAL NETWORKS IN CUDA USING INVARIANT INFERENCE 3.1 Motivating Example To provide some insight regarding the need for verifying ANN implementations, a simple example is presented. Fig. 4 illustrates a simple fullyconnected ANN. This example has 2inputs, 1output, and no biases. From Fig. 4, the ANN‚Äôs output is directly computed with ùëì=ùê¥+ùêµ=ùëÖùëíùêøùëà(2ùë•‚àí3ùë¶)+ùëÖùëíùêøùëà(ùë•+4ùë¶). (3) Input #1 ùë• Input #2 ùë¶ùê¥ ùêµùëì Output2 31 41 1 Fig. 4. Simple fullyconnected neural network. In our approach, we need three particular inputs: ( 1) ANN written in the nnet file format [ 34]; (2) input intervals to guide the exploration; and ( 3) safety properties for which we want to validate a given ANN. Let us assume we want to verify if the ANN in Fig. 4 is safe concerning property ùúô, assumingùë•,ùë¶‚àà[0.749,0.498]: ùúô‚Üîùëì‚â•2.7. (4) First, we will parse the given ANN in the nnet file format to our internal network model. For the sake of readability, we have omitted this translation, since it is fairly straightforward. Second, we will perform the ANN concretization, layer by layer, using our CUDA operational model (mainly thecublasSgemm function), as well as taking the activation function of each neuron into account. The activation function for the hidden layer‚Äôs neurons is ùëÖùëíùêøùëà : I R‚ÜíI R+[36], i.e., ùëÖùëíùêøùëà(ùë•)=ùëöùëéùë•(0,ùë•). (5) Consequently, it returns 0, for negative inputs, and the input itself, otherwise. Thus, we have: ùê¥=ùëÖùëíùêøùëà(2√ó0.749‚àí3√ó0.498)=ùëÖùëíùêøùëà(0.004)=0.004, (6) ùêµ=ùëÖùëíùêøùëà(0.749+4√ó0.498)=ùëÖùëíùêøùëà(2.741)=2.741, (7) ùëì=ùê¥+ùêµ=0.004+2.741=2.745, (8) , Vol. 1, No. 1, Article . Publication date: December 2020.8 Luiz Sena, Erickson Alves, Iury Bessa, Eddie Filho, and Lucas Cordeiro which is used to perform the last step of our approach, i.e., checking the userdefined property ùúô. In this case, ùúôholds for the given input, since ùëì=2.745‚â•2.7. At first glance, we can conclude that it is safe, which usually happens in many verification frameworks [ 49], when a final implementation on a real platform with restrictions is not considered. Nonetheless, if that is the case, the FWL effects should be checked. The performed steps are necessarily the same as in the floatingpoint representation, except that we use a different version of our CUDA operational model that uses fixedpoint arithmetic. In this work, we have encoded nonintegral numbers in a binary representation. Given a rational number, we are able to represent it in fixedpoint by using ùëö+ùëõbits, where the integral part ùêºis encoded inùëöbits and the fractional part ùêπis encoded in ùëõbits. Moreover, it is interpreted as ùêº+ùêπ 2ùëõ. In our operational model, we have defined conversion functions to represent floatingpoint values in fixedpoint representation and viceversa, i.e.,fxp_to_float andfxp_float_to_fxp . Furthermore, regarding the ANN in Fig. 4 and the same property ùúômentioned earlier, while using a representation with 4bits for the integral part and 6bits for the fractional one, with the operators defined in Section 2.2.2, we have ùëì=F‚ü®3,6‚ü©"
21,Online trajectory recovery from offline handwritten Japanese kanji characters.txt,"In general, it is straightforward to render an offline handwriting image from
an online handwriting pattern. However, it is challenging to reconstruct an
online handwriting pattern given an offline handwriting image, especially for
multiple-stroke character as Japanese kanji. The multiple-stroke character
requires not only point coordinates but also stroke orders whose difficulty is
exponential growth by the number of strokes. Besides, several crossed and touch
points might increase the difficulty of the recovered task. We propose a deep
neural network-based method to solve the recovered task using a large online
handwriting database. Our proposed model has two main components: Convolutional
Neural Network-based encoder and Long Short-Term Memory Network-based decoder
with an attention layer. The encoder focuses on feature extraction while the
decoder refers to the extracted features and generates the time-sequences of
coordinates. We also demonstrate the effect of the attention layer to guide the
decoder during the reconstruction. We evaluate the performance of the proposed
method by both visual verification and handwritten character recognition.
Although the visual verification reveals some problems, the recognition
experiments demonstrate the effect of trajectory recovery in improving the
accuracy of offline handwritten character recognition when online recognition
for the recovered trajectories are combined.","For handwritten character recognition, there are two types  of patterns: offline patterns of images from scanners and cameras and online patterns of touch/pentip trajectories  from touch/penbased devices. An online pattern consists  of timesequences of (x, y) coordinates so that an offline pattern can be easily reconstructed from the online pattern, but not vice versa. Although online patterns provide more productive features for classification, their variation in writing direction, writing speed, and stroke writing order  was a challenge for online handwriting recognition so that  offline features were added [1] or offline recognizers were combined [2]. On the other hand, offline patterns are free  from the variations as mentioned above but lack some  distinctive features. If online trajectories are reconstructed from offline patterns, it will improve offline handwritten character recogn ition. When experts decode  damaged characters in historical documents, they often imagine their trajectory hypotheses to decode them.  Therefore, the trajectory recovery may also be useful for  them.   So far, offline handwriting recognizers have not been  combined with online handwriting recognizers since  online patterns are difficult to reconstruct from offline patterns [3]. There have been many studies on online handwriting recovery from offline patterns in Alphabet,  Latin, Chinese scripts, as wel l as mathematic expressions  [4]‚Äì[8]. Japanese kanji characters of Chinese origin are  generally composed of many strokes (up to 30 strokes), as  shown in Fig. 1 so that to recover their order is a challenge,  among other languages.  Fortunately, there are some large online Japanese  handwriting databases [9] which cover almost dailyused  Japanese characters collected from hundreds of writers. In  addition, online patterns can  be easily converted to offline  patterns without ambiguities. It  is well known that offline  patterns converted from online patterns are useful for  training and evaluating offline recognizers [10], [11].  Therefore, we first convert online patterns to offline  patterns and then try to recover online patterns from the  above converted offline patterns. We can inspect the trajectory recovery because we have original online  patterns. Moreover, we can evaluate the quality of  trajectory recovery by online an d offline recognitions for  the original online patterns, the converted offline patterns,  and the reconstructed online patterns from the converted  offline patterns. Their combination may demonstrate interesting insights.         2     Fig. 1.  Examples of Japanese characters written by multiple  strokes.  We propose a datadriven method for trajectory  recovery based on Deep Neural Networks (DNNs). A  stimulating work was presented by Kumarbhunia et al. for Indian character/word patterns composed of single strokes  [12]. The trajectory recovery for characters composed of  many strokes, such as Japanese kanji and Chinese characters, seems to have a more significant potential benefit because stroke order variations and resultant pattern variations are large. According to the characteristics of writing kanji characters, we propose a  specific neural network architecture to extract local  f e a t u r e s  a s  w e l l  a s  m a i n t a i n  t h e  2  D  s p a t i a l  r e l a t i o n s  a mo n g  a l l  s t r o k es ,  f o r mi n g  a  k an j i  ch a r a c t e r  p a t t er n .  W e   also demonstrate the necessity of the attention mechanism  to focus on local context while reconstructing online trajectories sequentially.  T h e  r e s t  o f  t h e  p a p e r  i s  o r g a n i z e d  a s  f o l l o w s .  I n   Section II, we present related work of online trajectory recovery with both traditional and deep learningbased  methods. The details of our proposed method are declared  in Section III. For training and evaluating the proposed method, we express them in Section IV and V , respectively.  Finally, we give conclusions  and discussions in Section  VI.  2. Related works  "
64,I-vector Transformation Using Conditional Generative Adversarial Networks for Short Utterance Speaker Verification.txt,"I-vector based text-independent speaker verification (SV) systems often have
poor performance with short utterances, as the biased phonetic distribution in
a short utterance makes the extracted i-vector unreliable. This paper proposes
an i-vector compensation method using a generative adversarial network (GAN),
where its generator network is trained to generate a compensated i-vector from
a short-utterance i-vector and its discriminator network is trained to
determine whether an i-vector is generated by the generator or the one
extracted from a long utterance. Additionally, we assign two other learning
tasks to the GAN to stabilize its training and to make the generated ivector
more speaker-specific. Speaker verification experiments on the NIST SRE 2008
""10sec-10sec"" condition show that our method reduced the equal error rate by
11.3% from the conventional i-vector and PLDA system.","Recent years have seen a great improvement in textindependent speaker veriÔ¨Åcation. The speaker veriÔ¨Åcation system extracts speaker characteristic information from a given utterance and then verify the speaker ID. In the stateoftheart methods of speaker veriÔ¨Åcation, ivector [1] is used to represent speaker characteristics, and probabilistic linear discriminant analysis (PLDA) [2, 3, 4] is used as a veriÔ¨Åer. While this system per forms well on long utterances, the performance degrades dras tically when only short utterances are available [5]. The main cause of this problem is the biased phonetic distribution of short utterances, which makes the estimated speaker features become statistically unreliable. However, in many real world scenar ios, users may be reluctant to provide severalminutelong ut terances. SigniÔ¨Åcant efforts have been made to remedy the perfor mance degradation in short utterance speaker veriÔ¨Åcation. In [6][7][8], the variance of ivectors for short utterances are mod eled and used for ivector normalization. [9] and [10] proposed to utilize duration information in PLDA model. [11] uses pho netic information to reconstruct reliable ivectors. In the past years, deep learning has become very popular in the speaker veriÔ¨Åcation Ô¨Åeld. Many approaches use deep neu ral networks to process ivectors. For example, [12] proposed a variational autoencoder as a backend for ivector based speaker recognition, [13] used denoising autoencoders to compensate for noisy speech. However, a large amount of data is required for training deep neural networks [14], while the amount of data available for speaker veriÔ¨Åcation are usually very small. This has been one of the biggest obstacles for building an endtoend speaker veriÔ¨Åcation system using deep learning. Hence, it maybe better to improve the ivector and PLDA framework by us ing deep learning. Recently, a novel structure called generative adversarial network (GAN) [15] has become extremely popular. GAN can learn a mapping from random noise to target domain, by playing a zerosum game with two networks, a generator G and a discriminator D:Gtries to generate ‚Äúreal‚Äù samples which can foolD, whileDtries to determine whether a given sample is from real data distribution or from G. This paper describes an ivector transformation method us ing conditional GAN for improving ivector based short utter ance speaker veriÔ¨Åcation. The method uses GAN to estimate a generative model which can generate a reliable ivector from an unreliable ivector, in which we assume an ivector from a long utterance is reliable, and an ivector from a short utterance is un reliable. SpeciÔ¨Åcally, we used the conditional version of GAN, where both the generator and the discriminator have an ivector from a short utterance as the conditional input. The generator Gtries to generate a reliable ivector from an unreliable one, and the discriminator Dtries to decide whether a given reliable ivector is a real one extracted from a long utterance or a fake one generated by G. In order to stabilize GAN training, numeri cal difference (cosine distance) between generated ivectors and target reliable ivectors are used in the training stage. Moreover, inspired by [13], we tried to improve the speaker discriminative ability of generated ivectors by adding an extra speaker label predicting task to G. This multitask learning framework can better guide the training of GAN. In the testing stage, Gis used to generate reliable ivectors from those extracted from short utterances, and then the generated ivectors would be used in PLDA scoring. This paper is organized as follows: Section 2 brieÔ¨Çy in troduces related works of our methods. Section 3 presents the proposed GANbased structure for ivector restoration. Section 4 describes experimental evaluations for speaker veriÔ¨Åcation in two NIST SRE tasks. Section 5 summarizes this paper. 2. Related Works "
20,MDBV: Monitoring Data Batch Verification for Survivability of Internet of Vehicles.txt,"Along with the development of vehicular sensors and wireless communication
technology, Internet of Vehicles (IoV) is emerging that can improve traffic
efficiency and provide a comfortable driving environment. However, there is
still a challenge how to ensure the survivability of IoV. Fortunately, this
goal can be achieved by quickly verifying real-time monitoring data to avoid
network failure. Aggregate signature is an efficient approach to realize quick
data verification quickly. In this paper, we propose a monitoring data batch
verification scheme based on an improved certificateless aggregate signature
for IoV, named MDBV. The size of aggregated verification message is remain
roughly constant even as the increasing number of vehicles in MDBV.
Additionally, MDBV is proved to be secure in the random oracle model assuming
the intractability of the computational Diffie-Hellman problem. In
consideration of the network survivability and performance, the proposed MDBV
can decrease the computation overhead and is more suitable for IoV.","TODAY, the development of wireless networks (such as WiMAX, ad hoc, and sensor networks) has attracted worldwide attention by providing more convenient commu nication services. As an emerging paradigm, Internet of Ve hicles (IoV) [1] is evolving from Vehicular Ad hoc Net works (V ANETs). It merges vehicles, infrastructure, human and networks to an intelligent unit that is more efÔ¨Åcient compared with V ANETs. Moreover, IoV adopts different kinds of technologies (e.g. selforganization, deep learning an d cloud computing) to improve the network survivability and reliab il ity. In recent years, lots of works [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14] have been proposed to the reliability, Ô¨Çexibility, survivability, and security of wireless networks. To better understand IoV , many researchers have This work is supported in part by the Key Program of NSFCTong yong Union Foundation under Grant U1636209, Joint Fund of Minist ry of Educa tion of China (No.6141A02022338), the 111 Project (B08038) and Collabo rative Innovation Center of Information Sensing and Unders tanding at Xidian University. Jingwei Liu, Qingqing Li, Huijuan Cao, and Rong Sun are with t he School of Telecommunications Engineering, Xidian Univers ity, Xi‚Äôan 710071, China. (email: jwliu@mail.xidian.edu.cn; 15229259171@ 163.com; caohui juan345@163.com; rsun@mail.xidian.edu.cn) Xiaojiang Du is with the Department of Computer and Informa tion Sciences, Temple University, Philadelphia, PA 19122, USA. (email: dxj@ieee.org) Mohsen Guizani is with the Department of Electrical and Comp uter Engineering, University of Idaho, Moscow, ID 83844, USA. (e mail: mguizani@ieee.org)'DWD$EVWUDFWLRQ (Aggregation & Access) 'DWD$FFXPXODWLRQ (Storage)$SSOLFDWLRQ (Reporting, Analytics, Control),R9 &ORXG6HUYHU 99 'DWD&HQWHU 93 95, 96&ROODERUDWLRQ	3URFHVVHV (Involving People & Business Processes) 9LUWXDO1HWZRUN2SHUDWRU (Policy enforcement & Flowbased management) &RQQHFWLYLW\ (Preprocessing unit & Communication) 'DWD$FTXLVLWLRQ7UDIILF&RQWURO &HQWHU(+HDOWK Fig. 1: Sevenlevel reference model raised several reference models: the threelevel model [15 ], the fourlevel model [16], and the Ô¨Åvelevel model [17]. Com  bining the merits of these models, we propose a comprehensiv e model for IoV , as shown in Fig. 1. Nowadays, IoV is playing an important role in smart city. It has made the trafÔ¨Åc more efÔ¨Åcient [18]. Nevertheless, for the intrinsic features of IoV , it has to face lots of challeng es about the network survivability. Security and performance are two key factors of affecting the network survivability. Whe n an malicious attacker uploads wrong information such as fak e accident message, it may cause trafÔ¨Åc control center to make incorrect decisions. So it is important to verify all of the u p loaded data to enhance the survivability of IoV . However, th e burden of collecting the monitoring data from different sou rces (such as vehicles sensors, infrastructures, smart termina ls, and so on) may increase with vehicles, and affect the transmissi on efÔ¨Åciency. In order to enhance the network survivability an d prevent the data from being falsiÔ¨Åed, the protection and ver iÔ¨Å cation mechanisms should be considered [19], [20]. Aggrega te Signature (AS) is a suitable cryptographic primitive to bat ch verify big data in IoV scenarios, because it can merge n signatures on ndifferent messages into a single short signature. Thereby, it is deployed in MDBV to improve the survivabilityJOURNAL OF L ATEX CLASS FILES, VOL. 14, NO. 8, JUNE 2017 2 and performance of IoV . In 2003, Boneh et al. proposed the Ô¨Årst AS scheme [21]. Following the original work, many aggregate schemes over different public key cryptosystems have been proposed. The se schemes are widely used in vehicular communications, mobil e networks, and other resourceconstrained scenarios [22]. The main contribution of our paper is summarized as follows: ‚Ä¢A CLASbased monitoring data batch veriÔ¨Åcation scheme with lower computation and communication overhead is proposed to enhance the survivability of IoV scenarios. ‚Ä¢A state information is introduced for vehicles to join or leave the system dynamically. Once knowing the state in formation, vehicles can generate their data authenticatio n information independently. ‚Ä¢The security properties of MDBV are proved in de tail, assuming the hardness of the CDH problem, even though the super adversary launches the adaptivechosen message attack and adaptivechosenidentity attack. ‚Ä¢The performance evaluation indicates that MDBV achieves the less overhead in the phase of individual monitoring data signing and batch veriÔ¨Åcation among these selected schemes, which is more compatible and preferred by vehicles and the data center respectively. The remainder of this paper is organized as follows. Section II introduces the related work about aggregate signature. S ome preliminaries are brieÔ¨Çy introduced, involving bilinear p airing and security model in section III. In section IV , the propose d scheme MDBV is described in detail. Then, we analyze the security of MDBV in section V . The next section evaluates the performance of MDBV . Conclusion of this paper is drawn in section VII. II. R ELATED WORK "
488,Back-engineering of spiking neural networks parameters.txt,"We consider the deterministic evolution of a time-discretized spiking network
of neurons with connection weights having delays, modeled as a discretized
neural network of the generalized integrate and fire (gIF) type. The purpose is
to study a class of algorithmic methods allowing to calculate the proper
parameters to reproduce exactly a given spike train generated by an hidden
(unknown) neural network. This standard problem is known as NP-hard when delays
are to be calculated. We propose here a reformulation, now expressed as a
Linear-Programming (LP) problem, thus allowing to provide an efficient
resolution. This allows us to ""back-engineer"" a neural network, i.e. to find
out, given a set of initial conditions, which parameters (i.e., connection
weights in this case), allow to simulate the network spike dynamics. More
precisely we make explicit the fact that the back-engineering of a spike train,
is a Linear (L) problem if the membrane potentials are observed and a LP
problem if only spike times are observed, with a gIF model. Numerical
robustness is discussed. We also explain how it is the use of a generalized IF
neuron model instead of a leaky IF model that allows us to derive this
algorithm. Furthermore, we point out how the L or LP adjustment mechanism is
local to each unit and has the same structure as an ""Hebbian"" rule. A step
further, this paradigm is easily generalizable to the design of input-output
spike train transformations. This means that we have a practical method to
""program"" a spiking network, i.e. find a set of parameters allowing us to
exactly reproduce the network output, given an input. Numerical verifications
and illustrations are provided.","Neuronalnetworkshavetremendouscomputationalcapacity ,buttheirbiologicalcomplexity make the exact reproduction of all the mechanisms involved i n these networks dynamics essentially impossible, even at the numerical simulation l evel, as soon as the number of neurons becomes too large. On crucial issue is thus to be able to reproduce the ‚Äúoutput‚Äù of a neuronal network using approximated models easy to implem ent numerically. The issue addressed here is ‚ÄúCan we program an integrate and Ô¨Åre networ k, i.e. tune the parameters, inorder toexactly reproduce another network output, on a bo unded time horizon, given the input‚Äù. This isthe issue addressed here. Calculabilitypower of neural network models The main aspect we are interesting here is the calculability of neural network models. It is knownthatrecurrentneuralnetworkswithfrequencyratesa reuniversalapproximators [35], as multilayer feedforward networks are [23]. This means th at neural networks are able to simulate dynamical systems as an example see the very intere sting paper of AlbersSprott using this property to investigate the dynamical stability conjections of Pales and Smale in the Ô¨Åeldof dynamical systemstheory [3]or route tochaos inh ighdimensional systems[2], not only to approximate measurable functions on a compact do main, as originally stated (see, e.g., [35] for a detailed introduction on these notion s). Spiking neuron networks have been proved tobe alsouniversal approximators [29]. Theoretically, spiking neurons can perform very powerful c omputations with precise timed spikes. They are at least as computationally powerful , as the sigmoidal neurons tra ditionally used in artiÔ¨Åcial neural networks [28,30]. This results has been shown using a spikeresponse model (see [32] for a review) and considerin g piecewise linear approxi mations of the potential proÔ¨Åles. In this context, analog in puts and outputs are encoded by temporaldelaysofspikes.Theauthorsshowthatanyfeedfo rwardorrecurrent(multilayer) analog neuronal network (` ala HopÔ¨Åeld, e.g., McCullochP itts) can be simulated arbitrarily closelybyaninsigniÔ¨Åcantly larger network of spiking neur ons. This holds eveninthe pres ence of noise [28,30]. These results highly motivate the use of spiking neural networks, as studied here. In a computational context, spiking neuron networks are mai nly implemented through speciÔ¨Åcnetworkarchitectures, suchasEchoStateNetworks [25]andLiquid SateMachines [31], that are called ‚Äúreservoir computing‚Äù (see [45] for un iÔ¨Åcation of reservoir computing methods at the experimental level). In this framework, the r eservoir is a network model of neurons (itcanbe linear or sigmoidneurons, but more usuall yspikingneurons), witharan dom topology and a sparse connectivity. The reservoir is a re current network, with weights than can be either Ô¨Åxed or driven by an unsupervised learning mechanism. In the case of spiking neurons (e.g. in the model of [33]), the learning mec hanism is a form of synaptic plasticity, usually STDP (SpikeTimeDependent Plastici ty), or a temporal Hebbian unsu pervised learning rule, biologically inspired. The output layer of the network (the socalled ‚Äúreadout neurons‚Äù) isdriven by asupervised learning rule, generated fromany type of clas siÔ¨Åer or regressor, ranging from a least mean squares rule to sophisticated discriminant or regressionalgorithms. Theeaseoftrainingandaguarantee doptimalityguidesthechoiceof themethod. Itappearsthatsimplemethodsyieldgoodresult s[45].Thisdistinctionbetween3 areadout layerandaninternalreservoir isindeedinduced b ythefactthatonlytheoutput of the neuron network activity isconstrained, whereas the int ernal stateisnot controlled. Learning the parameters of aneural network model Inbiologicalcontext,learningismainlyrelatedtosynapt icplasticity[21,16]andSTDP(see e.g., [40] for a recent formalization), as far as spiking neu ron networks are concerned. This unsupervisedlearningmechanismisknowntoreducethevari abilityofneuronresponses[7] andis relatedtothe maximization of information transmiss ion[41]and mutual information [15]. It has also other interesting computational properti es such as tuning neurons to react as soon as possible to the earliest spikes, or segregate the n etwork response in two classes dependingontheinputtobediscriminated,andmoregeneral structuringsuchasemergence of orientation selectivity[22]. Inthepresentstudy,thepointofviewisquitedifferent: we considersupervisedlearning while, since ‚Äúeach spike may matter‚Äù [22,18], we want not onl y to statistically reproduce the spiking output, but alsotoreproduce it exactly. The motivation to explore this track is twofold. On one hand w e want to better under stand what canbe learned at a theoretical level by spiking ne uron networks, tuning weights and delays. The key point is the nonlearnability of spiking neurons [50], since it is proved that this problem is NPcomplete, when considering the esti mation of both weights and delays. Here we show that we can ‚Äúelude‚Äù this caveat and propo se an alternate efÔ¨Åcient estimation, inspired by biological models. We also have to notice, that the same restriction apply not on ly to simulation but, as far as this model is biologically plausible, also holds at the bi ological level. It is thus an issue to wonder if, in biological neuron networks, delays are real ly estimated during learning processes, or if a weaker form of weight adaptation, as devel oped now, isconsidered. On the other hand, the computational use of spiking neuron ne tworks in the framework of reservoir computing or beyond [36], at application level s, requires efÔ¨Åcient tuning meth ods not only in ‚Äúaverage‚Äù, but in the deterministic case. Thi s is the reason why we must consider how to exactlygenerate a givenspike train. What isthe paper about In the next section we detail the proposed methods in three st eps: Ô¨Årst, discussing the neu ral model considered here, provided underlying assumption s are assumed; then, detailing the family of estimation problems corresponding to what is c alled backengineering and discussing the related computational properties; Ô¨Ånally, making explicit how a general in put/output mapping can be ‚Äúcompiled‚Äù on a spiking neural net work thanks to the previous developments. In the subsequent section, numerical veriÔ¨Åcations and illu strations are provided, before the Ô¨Ånal discussionand conclusion. 2 Problem position: Discretizedintegrate and Ô¨Åreneuronmo dels. Letusconsideranormalizedandreduced‚Äúpunctualconducta ncebasedgeneralizedintegrate andÔ¨Åre‚Äù(gIF)neuralunitmodel[19]asreviewedin[34].The modelisreducedinthesense4 thatbothadaptivecurrentsandnonlinearioniccurrentsa renomoreexplicitlydependingon the potential membrane, but on time andprevious spikes only (see[12] for a development). Herewe follow [8,13,12] after [37] andreview how toproperl y discretize a gIF model. The precise derivation is not regiven here, except for one i nnovative aspect, whereas the method is only sketchedout (see [13,12] for details). Time constrained continuous formulation. Letvbe the normalized membrane potential, whichtriggersaspikefor v= 1andisresetat v= 0.TheÔ¨Åreregime(spike emission)reads v(t) = 1‚áív(t+) = 0. Let us write Àúœât={¬∑¬∑¬∑tn i¬∑¬∑¬∑}, the list of spike times tn i< t. Here tn iisthenthspiketimeoftheneuronofindex i.Thedynamicoftheintegrateregimereads: dv dt+1 œÑL[v‚àíEL]+X jX nœÅj` t‚àítn j¬¥ ÀÜ v‚àíEjÀú =im(Àúœât), Here,œÑLandElare the membrane leak timeconstant and reverse potential, whileœÅj() andEjare thespike responses and reversepotentials for excitato ry/inhibitory synapses and gapjunctions. Furthermore, œÅj(s)is the synaptic or gapjunction response, accounting for theconnectiondelayandtimeconstant;itisassumedthatth eresponsevanishesafteradelay œÑr,whereœÅj(s) :having the following shape: Finally,im()is the reduced membrane current, including simpliÔ¨Åed adapt ive and non linear ionic current (see [12] for details). The dynamic of the integrate regime thus writes: dv dt+g(t,Àúœât)v=i(t,Àúœât), sothatknowing the membrane potential attime t,themembrane potential attime t+Œ¥, writes: v(t+Œ¥) =ŒΩ(t,t+Œ¥,Àúœât)v(t)+Rt+Œ¥ tŒΩ(s,t+Œ¥,Àúœâs)i(s,Àúœâs)ds, log(ŒΩ(t0,t1,Àúœât0)) =‚àíRt1 t0g(s,Àúœâs)ds. Thekey point isthattemporal constraints aretobe takenint oaccount [10].Spiketimes are bounded by a refractory period r,r < dn+1 i, deÔ¨Åned up to some absolute precision Œ¥t, while there is always a minimal delay dtfor one spike to inÔ¨Çuence another spike, and there might be (depending on the model assumptions) a maximal inte rspike interval Dsuch that eithertheneuronÔ¨Åreswithinatimedelay < Dorremainsquiescentforever).Forbiological neurons, orders of magnitude are typically, in millisecond s: rŒ¥t dt D 10.110‚àí[1,2]10[3,4] Networkdynamics discrete approximation. Combining these assumptions and the previous equations allows one (see [13] for technical details) to wri te the following discrete recur rence equation for a sampling period Œ¥: Vi[k] =Œ≥iVi[k‚àí1](1‚àíZi[k‚àí1])+nX j=1DX d=1WijdZj[k‚àíd]+Iik,(1)5 whereVi[k] =vi(kŒ¥)andZi[k] =Œæ[1,+‚àû[(Vi[k]), whereŒæis the indicatrix function, ŒæA(x) = 1ifx‚ààAand0otherwise. Let us discussindetail how (1) is derived from the previous e quations. The term (1‚àíZi[k])implements the reset mechanism, since this term is equal to0whenVi[k]‚â•1. The interesting technical point is that this equation enti rely speciÔ¨Åesthe integrate and Ô¨Åre mechanism. TheŒ≥i‚â°ŒΩ(t,t+Œ¥,Àúœât)|t=kŒ¥term takes into account the multiplicative effects of conductances. The numerical analysis performed in [13] d emonstrates that, for numerical values taken from biophysical models, consider ing hereŒ¥‚âÉ0.1ms, this quantityrelatedtothecontractionrate,isremarkablycon stant,withsmallvariations withinthe range: Œ≥i‚àà[0.965,0.995]‚âÉ0.98, consideringrandomindependentandidenticallydistribut edGaussianweights.Ithas been numerically veriÔ¨Åed that taking this quantity constan t over time and neurons does not signiÔ¨Åcantly inÔ¨Çuence the dynamics. This the reaso n why we write Œ≥ias a constant here. This corresponds to a ‚Äúcurrent based‚Äù (inst ead of ‚Äúconductance based‚Äù) approximation of the connections dynamics. The additive current Iik‚â°Zt+Œ¥ tŒΩ(s,t+Œ¥,Àúœâs)‚Äû im(Àúœâs)+EL œÑL¬´ dsÀõÀõÀõÀõÀõ t=kŒ¥‚âÉŒ¥Œ≥i‚Äû im(Àúœât)+EL œÑL¬´ÀõÀõÀõÀõ t=kŒ¥ accounts for membrane currents, including leak.The right hand sizeapproximation assumeŒ≥iis constant. Furthemore, we have to assume that the additive currents are independent from the spikes. This means that we neglect t he membrane current nonlinearity andadaptation. Onthe contrary, the term relatedtothe connection weights Wijdisnot straight forwardtowriteandnowrequires tousetheprevious numeric al approximation. Let uswrite: Wij[k‚àíkn j]‚â°EjRt+Œ¥ tŒΩ(s,t+Œ¥,Àúœât)œÅj` t‚àítn j¬¥ dsÀõÀõÀõ t=kŒ¥,tn j=kn jŒ¥ ‚âÉEjŒ¥Œ≥iœÅj` t‚àítn j¬¥ÀõÀõ t=kŒ¥,tn j=kn jŒ¥, assuming ŒΩ(s,t+Œ¥,Àúœât)‚âÉŒ≥iasdiscussedpreviously. Thisallowsustoconsider the spike response effect at time tn j=kn jŒ¥as a function only of k‚àíkn j. The response Wij[d]vanishes after a delay D,œÑr=DŒ¥, as stated previously. We assume here thatŒ¥ < Œ¥ti.e. that the spiketime precision allows to deÔ¨Åne the spike time as kn j,tn j=kn jŒ¥(see [13,12] for an extensive discussion). We further assum e that only zero or one spike is Ô¨Åred by the neuron of index j, during a period Œ¥, which is obvious assoon as Œ¥ < r. This allowsto write Wijd=Wij[d]sothat: Pn j=1Wij[k‚àíkn j] =PD d=1Pn j=1Wij[d]Œæ{kn j}(k‚àíd) =PD d=1Wij[d]Œæ{k1 j¬∑¬∑¬∑,kn j,¬∑¬∑¬∑}(k‚àíd) =PD d=1WijdZj[k‚àíd] sinceZj[l] =Œæ{k1 j¬∑¬∑¬∑,kn j,¬∑¬∑¬∑}(l)ispreciselyequal to 1onspiketimeand 0otherwise, whichcompletes the derivation of (1).6 Counting the model‚Äôs degrees of freedom. Let us consider a network of Nunits, whose dynamics isdeÔ¨Åned by (1),generating a rasterof the form sch ematized inFig.1. In order to determine the dynamics of the neural network, we r equire the knowledge of theinitialcondition. Here,due totheparticular structur e of equation (1)withadelay D,the initial condition is the piece of trajectory Vi[k],k‚àà {0,D{. The notation k‚àà {0,D{stands for0‚â§k < D. In fact, it is sufÔ¨Åcient to consider Vi[0]andZj[k],k‚àà {0,D{, entirely deÔ¨ÅningVi[k],k‚àà {0,D{from (1). Ifthe neuron ihasÔ¨Åredatleastonce, thedependence inthe initialconditi on isremoved thanks tothe resetmechanism. This means that itsstatedoes not depend on Vi[0]anymore, assoonasspikesareknown.Wethuscanfurtherassume Vi[0] = 0,forthesakeofsimplicity. The initial stateisthus deÔ¨Åned by Nnumerical values and D√óNbinary values. The dynamics is parametrized by the weights WijdthusN√óN√óDvalues. Here it is assumed that the Œ≥iare known and constant, while Iikare also known, as discussed in the sequel. When the potential and/or spikes are observed during a perio d ofTsamples, N√óT numerical/binary values are measured. 3 Methods: Weightsand delayed weightsestimation "
211,Theory of Deep Convolutional Neural Networks II: Spherical Analysis.txt,"Deep learning based on deep neural networks of various structures and
architectures has been powerful in many practical applications, but it lacks
enough theoretical verifications. In this paper, we consider a family of deep
convolutional neural networks applied to approximate functions on the unit
sphere $\mathbb{S}^{d-1}$ of $\mathbb{R}^d$. Our analysis presents rates of
uniform approximation when the approximated function lies in the Sobolev space
$W^r_\infty (\mathbb{S}^{d-1})$ with $r>0$ or takes an additive ridge form. Our
work verifies theoretically the modelling and approximation ability of deep
convolutional neural networks followed by downsampling and one fully connected
layer or two. The key idea of our spherical analysis is to use the inner
product form of the reproducing kernels of the spaces of spherical harmonics
and then to apply convolutional factorizations of filters to realize the
generated linear features.","Deep learning has attracted tremendous attention from various Ô¨Åelds of science and technology recently. Wide applications including those in im  age processing [9] and speech recognition [12] have received great successes. Based on deep neural network structures, it has a strong capab ility of ob taining data features and distinguishes itself from classical machine learning 1methods. Though it is successful in practical applications, theore tical as "
304,An Abstraction-Based Framework for Neural Network Verification.txt,"Deep neural networks are increasingly being used as controllers for
safety-critical systems. Because neural networks are opaque, certifying their
correctness is a significant challenge. To address this issue, several neural
network verification approaches have recently been proposed. However, these
approaches afford limited scalability, and applying them to large networks can
be challenging. In this paper, we propose a framework that can enhance neural
network verification techniques by using over-approximation to reduce the size
of the network - thus making it more amenable to verification. We perform the
approximation such that if the property holds for the smaller (abstract)
network, it holds for the original as well. The over-approximation may be too
coarse, in which case the underlying verification tool might return a spurious
counterexample. Under such conditions, we perform counterexample-guided
refinement to adjust the approximation, and then repeat the process. Our
approach is orthogonal to, and can be integrated with, many existing
verification techniques. For evaluation purposes, we integrate it with the
recently proposed Marabou framework, and observe a significant improvement in
Marabou's performance. Our experiments demonstrate the great potential of our
approach for verifying larger neural networks.","Machine programming (MP), the automatic generation of software, is showing early signs of fundamentally transforming the way software is developed [15]. A key ingredient employed by MP is the deep neural network (DNN), which has emerged as an eective means to semiautonomously implement many com plex software systems. DNNs are artifacts produced by machine learning : a user provides examples of how a system should behave, and a machine learning algo rithm generalizes these examples into a DNN capable of correctly handling inputs that it had not seen before. Systems with DNN components have obtained un precedented results in elds such as image recognition [24], game playing [33], natural language processing [16], computer networks [28], and many others, of ten surpassing the results obtained by similar systems that have been carefully handcrafted. It seems evident that this trend will increase and intensify, and that DNN components will be deployed in various safetycritical systems [3,19].arXiv:1910.14574v2  [cs.FL]  21 Jul 2020DNNs are appealing in that (in some cases) they are easier to create than handcrafted software, while still achieving excellent results. However, their usage also raises a challenge when it comes to certication. Undesired behavior has been observed in many stateoftheart DNNs. For example, in many cases slight perturbations to correctly handled inputs can cause severe errors [35,26]. Because many practices for improving the reliability of handcrafted code have yet to be successfully applied to DNNs (e.g., code reviews, coding guidelines, etc.), it remains unclear how to overcome the opacity of DNNs, which may limit our ability to certify them before they are deployed. To mitigate this, the formal methods community has begun developing tech niques for the formal verication of DNNs (e.g., [10,17,20,37]). These techniques can automatically prove that a DNN always satises a prescribed property. Un fortunately, the DNN verication problem is computationally dicult (e.g., NP complete, even for simple specications and networks [20]), and becomes expo nentially more dicult as network sizes increase. Thus, despite recent advances in DNN verication techniques, network sizes remain a severely limiting factor. In this work, we propose a technique by which the scalability of many ex isting verication techniques can be signicantly increased. The idea is to apply the wellestablished notion of abstraction and renement [6]: replace a network Nthat is to be veried with a much smaller, abstract network, N, and then verify this N. Because Nis smaller it can be veried more eciently; and it is constructed in such a way that if it satises the specication, the original net workNalso satises it. In the case that Ndoes not satisfy the specication, the verication procedure provides a counterexample x. Thisxmay be a true coun terexample demonstrating that the original network Nviolates the specication, or it may be spurious . Ifxis spurious, the network Nisrened to make it more accurate (and slightly larger), and then the process is repeated. A particularly useful variant of this approach is to use the spurious xto guide the renement process, so that the renement step rules out xas a counterexample. This vari ant, known as counterexampleguided abstraction renement (CEGAR ) [6], has been successfully applied in many verication contexts. As part of our technique we propose a method for abstracting and rening neural networks. Our basic abstraction step merges two neurons into one, thus reducing the overall number of neurons by one. This basic step can be repeated numerous times, signicantly reducing the network size. Conversely, renement is performed by splitting a previously merged neuron in two, increasing the network size but making it more closely resemble the original. A key point is that not all pairs of neurons can be merged, as this could result in a network that is smaller but is not an overapproximation of the original. We resolve this by rst transforming the original network into an equivalent network where each node belongs to one of four classes, determined by its edge weights and its eect on the network's output; merging neurons from the same class can then be done safely. The actual choice of which neurons to merge or split is performed heuristically. We propose and discuss several possible heuristics.For evaluation purposes, we implemented our approach as a Python frame work that wraps the Marabou verication tool [22]. We then used our framework to verify properties of the Airborne Collision Avoidance System (ACAS Xu) set of benchmarks [20]. Our results strongly demonstrate the potential usefulness of abstraction in enhancing existing verication schemes: specically, in most cases the abstractionenhanced Marabou signicantly outperformed the original. Fur ther, in most cases the properties in question could indeed be shown to hold or not hold for the original DNN by verifying a small, abstract version thereof. To summarize, our contributions are: (i) we propose a general framework for overapproximating and rening DNNs; (ii) we propose several heuristics for abstraction and renement, to be used within our general framework; and (iii) we provide an implementation of our technique that integrates with the Marabou verication tool and use it for evaluation. Our code is available online [9]. The rest of this paper is organized as follows. In Section 2, we provide a brief background on neural networks and their verication. In Section 3, we describe our general framework for abstracting an rening DNNs. In Section 4, we discuss how to apply these abstraction and renement steps as part of a CEGAR procedure, followed by an evaluation in Section 5. In Section 6, we discuss related work, and we conclude in Section 7. 2 Background 2.1 Neural Networks A neural network consists of an input layer , an output layer , and one or more intermediate layers called hidden layers . Each layer is a collection of nodes, called neurons . Each neuron is connected to other neurons by one or more di rected edges. In a feedforward neural network, the neurons in the rst layer receive input data that sets their initial values. The remaining neurons calculate their values using the weighted values of the neurons that they are connected to through edges from the preceding layer (see Fig. 1). The output layer provides the resulting value of the DNN for a given input. There are many types of DNNs, which may dier in the way their neu ron values are computed. Typically, a neuron is evaluated by rst computing a weighted sum of the preceding layer's neuron values according to the edge weights, and then applying an activation function to this weighted sum [13]. We focus here on the Rectied Linear Unit (ReLU) activation function [29], given as ReLU(x) = max (0;x). Thus, if the weighted sum computation yields a positive value, it is kept; and otherwise, it is replaced by zero. More formally, given a DNN N, we usento denote the number of layers ofN. We denote the number of nodes of layer ibysi. Layers 1 and nare the input and output layers, respectively. Layers 2 ;:::;n"
18,Generating Correctness Proofs with Neural Networks.txt,"Foundational verification allows programmers to build software which has been
empirically shown to have high levels of assurance in a variety of important
domains. However, the cost of producing foundationally verified software
remains prohibitively high for most projects,as it requires significant manual
effort by highly trained experts. In this paper we present Proverbot9001,a
proof search system using machine learning techniques to produce proofs of
software correctness in interactive theorem provers. We demonstrate
Proverbot9001 on the proof obligations from a large practical proof project,the
CompCert verified C compiler,and show that it can effectively automate what
were previously manual proofs,automatically producing proofs for 27.5% of
theorem statements in our test dataset, when combined with solver-based
tooling. Without any additional solvers,we exhibit a proof completion rate that
is a 4X improvement over prior state-of-the-art machine learning models for
generating proofs in Coq.","A promising approach to software verification is founda tional verification . In this approach, programmers use an interactive theorem prover, such as Coq [ 14] or Is abelle/HOL [ 35], to state and prove properties about their programs. Foundational verification has shown increasing promise over the past two decades; it has been used to prove properties of programs in a variety of settings, including compilers [ 28], operating systems [ 23], database systems [ 31], file systems [ 8], distributed sys tems [39], and cryptographic primitives [3]. One of the main benefits of foundational verification is that it provides high levels of assurance. The interactive theorem prover makes sure that proofs of program prop erties are done in full and complete detail, without any implicit assumptions or forgotten proof obligations. Fur thermore, once a proof is completed, foundational proof assistants can generate a representation of the proof in a foundational logic; these proofs can be checked with a small kernel. In this setting only the kernel needs to be trusted (as opposed to the entire proof assistant), leading to a small trusted computing base. As an example of this highlevel of assurance, a study of compilers [ 41] has shown that CompCert [ 28], a compiler proved correct in the Coq proof assistant, is significantly more robust than its nonverified counterparts. Unfortunately, the benefits of foundational verification come at a great cost. The process of performing proofs in a proof assistant is extremely laborious. CompCert [ 28] took 6 personyears and 100,000 lines of Coq to write and verify, and seL4 [ 23], which is a verified version ofarXiv:1907.07794v4  [cs.PL]  28 May 2020MAPL ‚Äô20, June 15, 2020, London, UK Alex SanchezStern, Yousef Alhessi, Lawrence Saul, and Sorin Lerner a 10,000 line operating system, took 22 personyears to verify. The sort of manual effort is one of the main impediments to the broader adoption of proof assistants. In this paper, we present Proverbot9001, a novel sys tem that uses machine learning to help alleviate the manual effort required to complete proofs in an interac tive theorem prover. Proverbot9001 trains on existing proofs to learn models. Proverbot9001 then incorporates these learned models in a tree search process to complete proofs. The source of Proverbot9001 is publicly available on GitHub1. Themaincontributionofthispaperisbringingdomain knowledge to the feature engineering, model architecture, and search procedures of machinelearning based systems for interactive theorem proving. In particular, our work distinguishes itself from prior work on machine learning for proofs in three ways: 1.A two part tacticprediction model, in which pre diction of tactic arguments is primary and informs prediction of tactics themselves. 2.An argument prediction architecture which makes use of recurrent neural networks over sequential representations of terms. 3.Several effective tree pruning techniques inside of a predictionguided proof search. We tested Proverbot9001 endtoend by training on the proofs from 162 files from CompCert, and testing on the proofs from 13 files2. When combined with solver based tooling (which alone can only solve 7% of proofs), Proverbot9001 can automatically produce proofs for 28% of the theorem statements in our test dataset (138/501). In our default configuration without external solvers, Proverbot9001 solves (produces a checkable proof for) 19.36% (97/501) of the proofs in our test set, which is a nearly 4X improvement over the previous state of the art system that attempts the same task [ 40]. Our model is able to reproduce the tactic name from the solution 32% of the time; and when the tactic name is correct, our model is able to predict the solution argument 89% of the time. We also show that Proverbot9001 can be trained on one project and then effectively predict on another project. 2 Background 2.1 Foundational Verification Program verification is a well studied problem in the pro gramming languages community. Most work in this field falls into one of two categories: solverbacked automated (or semiautomated) techniques, where a simple proof is checked by a complex procedure; and foundational logic 1https://github.com/UCSDPL/proverbot9001 2This training/test split comes from splitting the dataset 90/10, and then removing from the test set files that don‚Äôt contain proofs. outin0 in1 in2 in3in0 in1 inn+ f (a)(b)√ó out√ó √óFigure 1. (a) A feedforward neural network, where each individual gray circle is a perceptron (b) An in dividual perceptron, which multiplies all the inputs by weights, sums up the results, and then applies a non linear function ùëì. based techniques, where a complex proof is checked by a simple procedure. While research into solverbacked techniques has pro duced fullyautomated tools in many domains, these approaches are generally incomplete, failing to prove some desirable propositions. When these procedures fail, it is often difficult or impossible for a user to complete the proof, requiring a deep knowledge of the automation. In contrast, foundational verification techniques require a heavy initial proof burden, but scale to any propo sition without requiring a change in proof technique. However, the proof burden of foundational techniques can be prohibitive; CompCert, a large and wellknown foundationally verified compiler, took 6 personyears of work to verify [ 27], with other large verification projects sporting similar proof burdens. 2.2 Interactive Theorem Provers Most foundational (and some solverbacked) verification is done in an interactive theorem prover. Interactive theorem provers allow the user to define proof goals alongside data and program definitions, and then prove those goals interactively, by entering commands which manipulate the proof context. The name and nature of these commands varies by the proof assistant, but in many foundational assistants, these commands are called ‚Äútactics‚Äù, and coorespond to primitive proof techniques like ‚Äúinduction‚Äù, as well as search procedures like ‚Äúomega‚Äù (whichsearchesforproofsoverringlikestructures).Proof obligations in such proof assistants take the form of a set of hypotheses (in a CurryHoward compatible proof theory, bound variables in a context), and a goal (a target type); proof contexts may consist of multiple proof obligations. 2.3 Machine Learning and Neural Networks Machine learning is an area of computer science dating back to the 1950s. In problems of supervised learning, the goal is to learn a function from labeled examples of inputoutput pairs. Models for supervised learning parameterize a function from inputs to outputs and haveGenerating Correctness Proofs with Neural Networks MAPL ‚Äô20, June 15, 2020, London, UK not ( eq x y )6 1 3 4 2 5 inout Visually  Unfold G G G G G G G Figure 2. A recurrent neural network. Inputs are in blue boxes at the bottom, and each iteration produces an output value, as well as a new state value for the next iteration. a procedure to update the parameters from a data set of labeled examples. Machine learning has traditionally been applied to problems such as handwriting recogni tion, natural language processing, and recommendation systems. NeuralNetworksareaparticularclassoflearnedmodel where layers of nodes are connected together by a lin ear combination and a nonlinear activation function, to form general function approximators. Neural Networks have a variety of structures, some forming a straightfor ward ‚Äústack‚Äù of nodes with some connections removed (convolutional), and others, such as those used for natu ral language processing, using more complex structures like loops. We will make use of two different kinds of neural net works: feedforward networks and recurrent neural net works. Figure 1(a) shows the structure of a feedforward network, where each gray circle is a perceptron, and Figure 1(b) shows individual structure of a perceptron. Figure 2 shows the structure of a recurrent neural net work (RNN). Inputs are shown in blue, outputs in green and computational nodes in gray. The computational nodes are Gated Recurrent Network nodes, GRU for short, a commonly used network component with two inputs and two outputs [ 10]. The network is recurrent because it feeds back into itself, with the state output from the previous iteration feeding into the state input of the next iteration. When we display an RNN receiving data, we visually unfold the RNN, as shown on the right side of Figure 2, even though in practice there is still only one GRU node. The right side of Figure 2 shows an example RNN that processes tokens of a Coq goal, and produces some output values. 3 Overview In this section, we‚Äôll present Proverbot9001‚Äôs prediction and search process with an example from CompCert. You can see the toplevel structure of Proverbot9001 in Figure 3. Consider the following theorem from the CompCert compiler: Search Coq InterfaceNeural Network  Prediction ModelTheorem To  Prove ProofProof States PredictionsCommands Proof StatesFigure 3. The overall architecture of Proverbot9001, built using CoqSerapi, Python, and PyTroch. eval_mulhs econstructor unfold binary_constructor_sound eauto simpl try omegaeauto intros simpl eauto inv H TrivialExists QEDTrivialExists inv H0 subst econstructor Figure 4. A graph of a Proverbot9001 search. In green arethetacticsthatformedpartofthediscoveredsolution, as well as the lemma name and the QED. In orange are nodes that resulted in a context that is at least as hard as one previously found (see Section 7). Definition binary_constructor_sound (cstr: expr > expr > expr) (sem: val > val > val) : Prop := forall le a x b y, eval_expr ge sp e m le a x > eval_expr ge sp e m le b y > exists v, eval_expr ge sp e m le (cstr a b) v /\ Val.lessdef (sem x y) v. Theorem eval_mulhs: binary_constructor_sound mulhs Val.mulhs. Proof. ... This theorem states that the mulhsexpression con structor is sound with respect to the specification Val.mulhs . At the beginning of the proof of eval_mulhs , Prover bot9001 predicts three candidate tactics, econstructor , eauto, and unfold binary_constructor_sound . Once these predictions are made, Proverbot9001 tries running all three, which results in three new states of the proof assistant. In each of these three states, Proverbot9001 again makes predictions for what the most likely tactics are to apply next. These repeated predictions create aMAPL ‚Äô20, June 15, 2020, London, UK Alex SanchezStern, Yousef Alhessi, Lawrence Saul, and Sorin Lerner ùíØ Tactics ùíú Tactic arguments ùíû=ùíØ√óùíú Proof commands ‚Ñê Identifiers ùí¨ Propositions ùí¢=ùí¨ Goals ‚Ñã=‚Ñê√óùí¨ Hypotheses ùí™= [‚Ñã]√óùí¢Obligations ùíÆ= [ùí™√ó[ùíû]]Proof states Figure 5. Formalism to model a Proof Assistant search tree, which Proverbot9001 explores in a depth first way. The proof command predictions that Prover bot9001 makes are ordered by likelihood, and the search explores more likely branches first. Figure 4 shows the resulting search tree for eval_mulhs . The nodes in green are the nodes that pro duce the final proof. Orange nodes are predictions that fail to make progress on the proof (see Section 7); these nodes are not expanded further. All the white nodes to the right of the green path are not explored, because the proof in the green path is found first. 4 Definitions In the rest of the paper, we will describe the details of how Proverbot9001 works. We start with a set of definitions that will be used throughout. In particular, Figure 5 shows the formalism we will use to represent the state of an inprogress proof. A tactic ùúè‚ààùíØis a tactic name. An argument ùëé‚ààùíúis a tactic argument. For simplicity of the formalism, we assume that all tactics take zero or one arguments. We use ‚Ñêfor the set of Coq identifiers, and ùí¨for the set of Coq propositions. Aproof state ùúé‚ààùíÆis a state of the proof assistant, which consists of a list of obligations along with their proof command history. We use [ùëã]to denote the set of lists of elements from ùëã. An obligation is a pair of: (1) a set of hypotheses (2) a goal to prove. A hypothesis is a proposition named by an identifier, and a goal is a proposition. 5 Predicting a Single Proof Step We start by explaining how we predict individual steps in the proof. Once we have done this, we will explain how we use these proof command predictions to guide a proof search procedure. We defineùíü[ùúè]to be a scoring function over ùúè, where larger scores are preferred over smaller ones: ùíü[ùúè] =ùúè‚ÜíR We define a ùúèpredictor‚Ñõ[ùúè]to be a function that takes a proof state ùúé‚ààùíÆ(i.e.a state of the proof assistantunder which we want to make a prediction) and returns a scoring function over ùúè. In particular, we have: ‚Ñõ[ùúè] =ùíÆ‚Üíùíü [ùúè] Our main predictor ùëÉwill be a predictor of the next step in the proof, i.e.a predictor for proof commands: ùëÉ:‚Ñõ[ùíØ√óùíú ] We divide our main predictor into two predictors, one for tactics, and one for arguments: ùëÉtac:‚Ñõ[ùíØ] ùëÉarg:ùíØ ‚Üí‚Ñõ [ùíú] Our main predictor ùëÉcombines ùëÉtacandùëÉargas follows: ùëÉ(ùúé) =ùúÜ(ùúè, ùëé). ùëÉtac(ùúé)(ùúè)‚äóùëÉarg(ùúè)(ùúé)(ùëé) where‚äóis an operator that combines the scores of the tactic and the argument predictors. We now describe the three parts of this prediction architecture in turn: ùëÉtac,ùëÉarg, and‚äó. 5.1 Predicting Tactics ( ùëÉtac) To predict tactics, Proverbot9001 uses of a set of manu ally engineered features to reflect important aspects of proof prediction: (1) the head of the goal as an integer (2) the name of the previously run tactic as an integer (3) a hypothesis that is heuristically chosen (based on string similarity to goal) as being the most relevant to the goal (4) the similarity score of this most relevant hypothesis. These features are embedded into a continuous vector of 128 floats using a standard word embedding, and then fed into a fully connected feedforward neural network (3 layers, 128 nodeswide) with a softmax (normalizing) layer at the end, to compute a probability distribution over possible tactic names. This architecture is trained on 153402 samples with a stochastic gradient descent optimizer. The architecture of this model is shown in Figure 6. Blue boxes represent input; purple boxes represent inter mediate encoded values; green boxes represent outputs; and gray circles represent computations. The NN circle is the feedforward Neural Network mentioned above. The Enc circle is a word embedding module. 5.2 Predicting Tactic Arguments ( ùëÉarg) Once a tactic is predicted, Proverbot9001 next predicts arguments. Recall that the argument predictor is a func tionùëÉarg:‚Ñõ[ùíú]. In contrast to previous work, our ar gument model is a prediction architecture in its own right. Proverbot9001 currently predicts zero or one tactic arguments; However, since the most oftenused multi argument Coq tactics can be desugared to sequences of single argument tactics (for example ‚Äú unfold a, b ‚Äù toGenerating Correctness Proofs with Neural Networks MAPL ‚Äô20, June 15, 2020, London, UK NN‚Äúapply‚ÄùEncodePrevious tactic ‚Äúforall‚Äù ‚Äúeq‚ÄùGoal head Hypothesis headVectors of reals Enc Distribution  over tactics Enc Enc Figure 6. Proverbot9001‚Äôs model for predicting tactics. Takes as input three features for each data point: the previous tactic run, the head token of the goal, and of the most relevant hypothesis (see Section 5.1). We restrict theprevioustacticfeaturetothe50mostcommontactics, and head tokens on goal and hypothesis to the 100 most common head tokens. ‚Äúunfold a. unfold b. ‚Äù), this limitation does not signifi cantly restrict our expressivity in practice. Proverbot9001 makes three kinds of predictions for arguments: goaltoken arguments, hypothesis arguments, lemmaarguments: Goaltoken arguments are arguments that are a sin gle token in the goal; for instance, if the goal is not (eq x y) , we might predict unfold not , where not refers to the first token in the goal. In the case of tactics likeunfoldanddestruct , the argument is often (though not always) a token in the goal. Hypothesis arguments are identifiers referring to a hy pothesis in context. For instance, if we have a hypothesis Hin context, with type is_path (cons (pair s d) m) , we might predict inversion H , where Hrefers to the hypothesis, and inversion breaks it down. In the case of tactics like inversion and destruct , the argument is often a hypothesis identifier. Finally,lemmaarguments are identifiers referring to a previously defined proof. These can be basic facts in the standard library, like plus_n_0 : forall n : nat, n = n + 0 or a lemma from the current project, such as the eval_mulhs described in the overview. In Proverbot9001, lemmas are considered from a subset of the possible lemma arguments available in the global context, in or der to make training tractable. Proverbot9001 supports several different modes for determining this subset; by default we consider lemmas defined previously in the current file. The architecture of the scoring functions for these argument types is shown in Figure 7. One recurrent neural network (RNN) is used to give scores to each hypothesis and lemma by processing the type of the term, and outputting a final score. A different RNN is then used to process the goal, assigning a score to each token in processes. not ( eq x y ) y > ( x + 1 )‚Äúunfold‚ÄùTactic name predicted by Ptac Goal Hypothesis/ Lemma0Constant 5.2 Hypothesis/Lemma  Similarity ScoreNNEncoded Goal60 8.22.13.09.2 81 3 4 29 5 Hypothesis/ Lemma  Output ScoreToken Output  Scores G G G G G G G G G G G G G G G G G G GFigure 7. The model for scoring possible arguments. As before, blue boxes are inputs; purple boxes are encoded values; green diamonds are outputs, in this case scores for each individual possible argument; and gray circles are computational nodes. The GRU nodes are Gated Recurrent Units [ 10]. The NN node is a feed forward neural network. For illustration purposes, Figure 7 uses an example to provide sample values. Each token in the goal is an input‚ÄìinFigure7thegoalis‚Äú not (eq x y) ‚Äù.Thetactic predicted by ùëÉtacis also an input ‚Äì in Figure 7 this tactic is ‚Äúunfold‚Äù. The hypothesis that is heuristically closest to the goal (according to our heuristic from Section 5.1) is also an input, one token at a time being fed to a GRU. In our example, let‚Äôs assume this closest hypothesis is ‚Äúy > (x+1) ‚Äù. The similarity score of this most relevant hypothesis is an additional input ‚Äì in Figure 7 this score is5.2. There is an additional RNN (the middle row of GRUs in Figure 7) which encodes the goal as a vector of reals. The initial state of this RNN is set to some arbitrary constant, in this case 0. The initial state of the hypothesis RNN (the third row of GRUs in Figure 7) is computed using a feed forward Neural Network (NN). This feedforward Neural Network takes as input the tactic predicted by ùëÉtac, the goal encoded as a vector of reals, and the similarity score of the hypothesis. The architecture in Figure 7 produces one output score for each token in the goal and one output score for the hypothesis. The highest scoring element will be chosen as the argument to the tactic. In Figure 7, the highest scoring element is the ‚Äú not‚Äù token, resulting in the proof command ‚Äú unfold not ‚Äù. If the hypothesis score (in our example this score is 8) would have been the highest score, then the chosen argument would be the identifier of that hypothesis in the Coq context. For example, if the identifier was IHn(as is sometimes the case for inductive hypotheses), then the resulting proof command would be ‚Äúunfold IHn ‚Äù.MAPL ‚Äô20, June 15, 2020, London, UK Alex SanchezStern, Yousef Alhessi, Lawrence Saul, and Sorin Lerner 5.3 Combining Tactic and Argument Scores (‚äó) The‚äóoperator attempts to provide a balanced combi nation of tactic and argument prediction, taking both into account even across different tactics. The operator works as follows. We pick the ùëõhighestscoring tactics and for each tactic the ùëöhighestscoring arguments. We then score each proof command by multiplying the tactic score and the argument score, without any normal ization. Formally, we can implement this approach by defining‚äóto be multiplication, and by not normalizing the probabilities produced by ùëÉarguntil all possibilities are considered together. Because we don‚Äôt normalize the probabilities of tac tics, the potential arguments for a tactic are used in determining the eligibility of the tactic itself (as long as that tactic is in the top ùëõ). This forms one of the most important contributions of our work: the argument selection is primary, with the tactic prediction mostly serving to help prune its search space. 5.4 Putting It All Together The overall architecture that we have described is shown in Figure 8. The ùëÉtacpredictor (whose detailed struc ture is shown in Figure 6) computes a distribution over tactic using three features as input: the previous tactic, head constructor of goal, and head constructor of the hypothesis deemed most relevant. Then, for each of the top tactic predicted by ùëÉtac, the ùëÉargpredictor (whose detailed structure is shown in Figure 7) is invoked. In ad dition to the tactic name, the ùëÉargpredictor takes several additional inputs: the goal, the hypotheses in context, and the similarity between each of those hypotheses and the goal. The ùëÉargpredictor produces scores for each possible argument (in our case one score for each token in the goal, and one score the single hypothesis). These scores are combined with ‚äóto produce an overall scoring of proof commands. 6 Training 6.1 Training Architecture Figure 9 shows the training architecture for the tactic predictor, ùëÉtac(recall that the detailed architecture of ùëÉtacis shown in Figure 6). The goal of training is to find weights for the neural network that is found inside the gray ùëÉtaccircle. Proverbot9001 processes all the Coq theorems in the training set, and steps through the proof of each of these theorems. Figure 9 shows what happens at each step in the proof. In particular, at each step in the proof, Proverbot9001 computes the three features we are training with, and passes these features to the current tactic model to get a distribution over tactics. This distribution over tactics, along with the correcttactic name (from the actual proof), are passed to a module that computes changes to the weights based on the NLLLoss criterion. These changes are batched together over several steps of the proof, and then applied to update the tactic model. Running over all the training data to update the weights is called an epoch, and we run our training over 20 epochs. Figure 10 shows the training architecture for the argu mentpredictor, ùëÉarg(recallthatthedetailedarchitecture ofùëÉargis shown in Figure 7). The goal of training is to find weights for the GRU components in ùëÉarg. Here again, Proverbot9001 processes all the Coq theorems in the training set, and steps through the proof of each of these theorems. Figure 10 shows what happens at each step in the proof. In particular, at each step in the proof, the current ùëÉtacpredictor is run to produce the top pre dictions for tactic. These predicted tactic, along with the correct tactic, are passed to the argument model ùëÉarg. To make Figure 10 more readable, we do not show the additional parameters to ùëÉargthat where displayed in Figure 8, but these parameters are in fact also passed to ùëÉargduring training. Note that it is very important for us to inject the tactics predicted by ùëÉtacinto the input of the argument model ùëÉarg, instead of using just the correct tactic name. This allows the scores produced by the argument model to be comparable acrossdifferent predicted tactics. Once the argument model ùëÉargcom putes a score for each possible argument, we combine these predictions using ‚äóto get a distribution of scores over tactic/argument pairs. Finally, this distribution, along with the correct tactic/argument pair is passed to a module that computes changes to the weights based on the NLLLoss criterion. In our main CompCert bench mark the 153402 tactic samples from the training set are processed for 20 epochs. 6.2 Learning From HigherOrder Proof Commands Proof assistants generally have higherorder proof com mands,whicharetacticsthattakeotherproofcommands as arguments; in Coq, these are called tacticals. One of the most common examples is the ( ;) infix operator which runs the proof command on the right on every subgoal produced by the tactic on the left. Another example is the repeattactical, which repeats a provided tactic until it fails. While higherorder proof commands are extremely important for human proof engineers, they are harder to predict automatically because of their generality. While some previous work [ 40] attempts to learn directly on data which uses these higherorder proof commands, we instead take the approach of desugaring higherorder proof commands into firstorder ones as much as possible;Generating Correctness Proofs with Neural Networks MAPL ‚Äô20, June 15, 2020, London, UK Ptac‚Äúapply‚Äù Prev tactic ‚Äúforall‚Äù ‚Äúeq‚ÄùGoal head Hypothesis headDistribution  over tactics‚Äúunfold‚ÄùTop tactics ‚Äúintros‚Äù ‚Äúapply‚ÄùArg  Model Tactic  Model Parg2 5 8 Parg7 6 4Parg1 3 9Distribution over  tactic/arg pairsArg  Scores ‚Äúunfold eq‚ÄùFeatures ‚Äúapply IHn‚Äù ‚Äúintros‚ÄùTop tactic/arg pairs not (eq x y) y > (x+1)Goal, Hypothesis,  Similarity Score 5.2 Figure 8. The overall prediction model, combining the tactic prediction and argument prediction models. Ptac‚Äúapply‚Äù Prev tactic ‚Äúforall‚Äù ‚Äúeq‚ÄùGoal head Hypothesis headDistribution  over tacticsTactic  ModelFeatures ‚Äúunfold‚ÄùCorrect tacticWeight  ChangesEvaluate Criterion &  Compute Weight  Changes Figure 9. The architecture for training the tactic mod els. Distribution  over tactics  from Ptac‚Äúunfold‚ÄùTop  tactics ‚Äúintros‚Äù ‚Äúapply‚ÄùArg Model Parg2 5 8 Parg7 6 4Parg1 3 9Distribution over  tactic/arg pairsArg Scores ‚Äúunfold‚Äù Parg3 9 7Correct tactic‚Äúunfold eq‚ÄùCorrect tactic &  argumentWeight  ChangesEvaluate Criterion &  Compute Weight  Changes Figure 10. The architecture for training the argument models. Note that we inject predicted tactics into the input of the argument model, instead of just using the correct tactic, so that argument scores will be compara ble. this makes the data more learnable, without restricting the set of expressible proofs. For example, instead of trying to learn and predict (;) directly, Proverbot9001 has a system which attempts to desugar ( ;) into linear sequences of proof commands. This is not always possible (without using explicit sub goal switching commands), due to propagation of exis tential variables across proof branches. Proverbot9001desugars the cases that can be sequenced, and the re maining commands containing ( ;) are filtered out of the training set. In addition to the ( ;) tactical, there are other tacticals in common use in Coq. Some can be desugared into simpler forms. For example: ‚àô‚Äúnow <tac> ‚Äù becomes ‚Äú <tac>;easy ‚Äù. ‚àô‚Äúrewrite <term> by <tac> ‚Äù becomes ‚Äúrewrite <term> ; [ |<tac>]‚Äù ‚àô‚Äúassert <term> by <tac> ‚Äù becomes ‚Äúassert <term> ; [ |<tac>]‚Äù In other cases, like try <tac> orsolve <tac> , the tactical changes the behavior of the proof command in a way that cannot be desugared; for these we simply treat the prefixed tactic as a separate, learned tactic. For example, we would treat try eauto as a new tactic. 7 PredictionGuided Search Now that we have explained how we predict a single step in the proof, we describe how Proverbot9001 uses these predictions in a proof search. In general, proof search works by transitioning the proof assistant into different states by applying proof commands, and backtracking when a given part of the search space has either been exhausted, or deemed un viable. Exhaustive proof search in proof assistants is untenable because the number of possible proof com mands to apply is large. Instead, we use the predictor described above to guide the search. Aside from using these predictions, the algorithm is a straightforward depthlimited search, with three subtleties. First.we stop the search when we find a proof goal that is at least as hard (by a syntactic definition) as a goal earlier in the history. While in general it is hard to formally define what makes one proof state harder than another, there are some obvious cases which we can detect. A proof state with a superset of the originalMAPL ‚Äô20, June 15, 2020, London, UK Alex SanchezStern, Yousef Alhessi, Lawrence Saul, and Sorin Lerner obligations will be harder to prove, and a proof state with the same goal, but fewer assumptions, will be harder to prove. To formalize this intuition, we define a relation ‚â• between states such that ùúé1‚â•ùúé2is meant to capture ‚ÄúProof state ùúé1is at least as hard as proof state ùúé2‚Äù. We say that ùúé1‚â•ùúé2if and only if for all obligations ùëÇ2in ùúé2there exists an obligation ùëÇ1inùúé1such that ùëÇ1‚â•ùëúùëÇ2. For obligations ùëÇ1andùëÇ2, we say that ùëÇ1‚â•ùëúùëÇ2if and only if each hypothesis in ùëÇ1is also a hypothesis in ùëÇ2, and the goals of ùëÇ1andùëÇ2are the same. Since‚â•is reflexive, this notion allows us to generalize all the cases above to a single pruning criteria: ‚Äúproof command prediction produces a proof state which is ‚â• than a proof state in the history‚Äù. Second. when backtracking, we do not attempt to findadifferentproofforanalreadyprovensubobligation. While in general this can lead to missed proofs because of existential variables (typed holes filled based on context), this has not been an issue for the kinds of proofs we have worked with so far. Third.we had to adapt our notion of search ‚Äúdepth‚Äù to the structure of Coq proofs (in which a tactic can produce multiple subobligations). A na√Øve tree search through the Coq proof space will fail to exploit some of the structure of subproofs in Coq. Consider for example the following two proofs: 1.intros. simpl. eauto. 2.induction n. eauto. simpl. At first glance, it seems that both of these proofs have a depth of three. This means that a straightforward tree search (which is blind to the structure of subproofs) would not find either of these proofs if the depth limit were set to two. However, there is a subtlety in the second proof above which is important (and yet not visible syntactically). In deed,the induction n proofcommandactuallyproduces two obligations (‚Äúsubgoals‚Äù in the Coq terminology). These correspond to the base case and the inductive case for the induction on n. Then eautodischarges the first obligation (the base case), and simpldischarges the second obligation (the inductive case). So in reality, the second proof above really only has a depth of two, not three. Taking this subproof structure into account is impor tant because it allows Proverbot9001 to discover more proofs for a fixed depth. In the example above, if the depth were set to two, and we used a na√Øve search, we would not find either of the proofs. However, at the same depth of two, a search which takes the subproof struc ture into account would be able to find the second proof(since this second proof would essentially be considered to have a depth of two, not three). 8 Evaluation This section shows that Proverbot9001 is able to success fully solve many proofs. We also experimentally show that Proverbot9001 improves significantly on the state oftheart presented in previous work. First, in Section 8.2, we compare experimentally to previous work, by running both Proverbot9001 and the CoqGym [ 40] project on CompCert, in several config urations outlined in the CoqGym paper. Next, in Sec tion 8.3, we experiment with using the weights learned from one project to produce proofs in another. Then, in Section 8.4, we show the ‚Äúhardness‚Äù of proofs that Proverbot9001 is generally able to complete, using the length of the original solution as proxy for proof diffi culty. Finally, in Appendix A.1, we measure the predictor subsystem, without proof search. Additional evaluation can be found in the appendix. Experiments were run on two machines. Machine A is an Intel i7 machine with 4 cores, a NVIDIA Quadro P4000 8BG 256bit, and 20 gigabytes of memory. Ma chine B is Intel Xeon E52686 v4 machine with 8 cores, a Nvidia Tesla v100 16GB 4096bit, and 61 gigabytes of memory. Experiments were run using GNU Parallel [ 38]. DuringthedevelopmentofProverbot9001,weexplored many alternatives, including ngram/bagofwords rep resentations of terms, a variety of features, and several core models including knearest neighbors, support vec tor machines, and several neural architectures. While we include here some experiments that explore highlevel design decisions (such as training and testing on the same projects vs cross project, working with and with out solverbased tooling, modifying the search depth and width, and running with and without preprocessing), we also note that in the development of a large system tackling a hard problem, it becomes intractable to eval uate against every possible permutation of every design decision. In this setting, we are still confident in having demonstrated a system that works for the specific prob lem of generating correctness proof with performance that outperforms the stateoftheart techniques by many folds. 8.1 Summary of Results Proverbot9001, run using CoqHammer [ 11] and the de fault configuration, is able to produce proofs for 28% of the theorem statements in CompCert. This represents a 2.4X improvement over the previous stateoftheart. Without any external tooling, Proverbot9001 can pro duce proofs for 19.36%, an almost 4X improvement over previous stateoftheart predictionbased proofs. OurGenerating Correctness Proofs with Neural Networks MAPL ‚Äô20, June 15, 2020, London, UK core prediction model is able to reproduce the tactic name from the solution 32% of the time; and when the tactic name is correct, our model is able to predict the solution argument 89% of the time. We also show that Proverbot9001 can be trained on one project and then effectively predict on another project. 8.2 Experimental Comparison to Previous Work We tested Proverbot9001 endtoend by training on the proofs from 162 files from CompCert, and testing on the proofs from 13 different files. On our default config uration, Proverbot9001 solves 19.36% (97/501) of the proofs in our test set. In addition to running Proverbot9001 on CompCert, we ran the CoqGym [ 40] tool, which represents the state of the art in this area, on the same dataset in several configurations. To account for differences in training dataset, we ran CoqGym with their original training schema, and also our training schema, and reported the best of the two numbers. CoqGym is intended to be combined with a solver based proofprocedure, CoqHammer [ 11], which is run after every proof command invocation. While our system was not originally designed this way, we compare both systems using CoqHammer, as well as both systems without. We also compared our system to using CoqHammer on the initial goal directly, which simultaneously invokes Z3 [ 13], CVC4 [ 6], Vampire [ 26], and E Prover [ 36], in addition to attempting to solve the goal using a crushlike tactic [9]. Figure 11 shows the proofs solved by various configu rations. The configurations are described in the caption. For all configurations, we ran Proverbot9001 with a search depth of 6 and a search width of 3 (see Appen dix A.5). Note that in Figure 11 the bars for H, G, and GHare prior work. The bars P, G+P and GH+PHare the ones made possible by our work. When CoqHammer is not used, Proverbot9001 can complete nearly 4 times the number of proofs that are completed by CoqGym. In fact, even when CoqGym is augmented with CoqHammer Proverbot9001 by itself (without CoqHammer) still completes 39 more proofs, which is a 67% improvement (and corresponds to about 8% of the test set). When enabling CoqHammer in both CoqGymandProverbot9001,weseethatCoqGymsolves 48proofswhereasProverbot9001solves138proofs,which is a 2.88X improvement over the state of art. Finally, CoqGym and Proverbot9001 approaches are complementary; both can complete proofs which the other cannot. Therefore, one can combine both tools to produce more solutions than either alone. Combining Co qGym and Proverbot9001, without CoqHammer, allows us to complete 100/501 proofs, a proof success rate of  0 20 40 60 80 100 120 140 160 H G P G+P GHPHGH+PH# proofs solved97 100138142 37 2348 P = Proverbot9001 G = CoqGym H = CoqHammer _H = _ with CoqHammerFigure 11. A comparison of Proverbot9001 and Co qGym‚Äôs abilities to complete proofs. H stands for Co qHammer by itself, as a single invocation; G stands for CoqGym by itself; P stands for Proverbot9001 by itself; G+P stands for the union of proofs done by G or P; GHstands for CoqGym with CoqHammer; PHstands for Proverbot9001 with CoqHammer; GH+PHstands for the union of proofs done by G Hor P H. 20%. Combining Proverbot9001 and CoqGym, each with CoqHammer, allows us to solve 142/501 proofs, a success rate of 28%. It‚Äôs important to realize that, whereas the prior state of the art was CoqGym with CoqHammer, at 48 proofs, by combining CoqGym and Proverbot9001 (both with CoqHammer), we can reach a grand total of 142 proofs, which is a 2.96X improvement over the prior state of art. 8.3 CrossProject Predictions To test Proverbot9001‚Äôs ability to make use of train ing across projects, we used the weights learned from CompCert, and ran Proverbot9001 in its default configu ration on three other Coq projects from the Coq Contrib collection, concat,float, and zfc. concatis a library of constructive category theory proofs, which showcases Coq proofs of mathematical concepts instead of program correctness. The concat library is made of 514 proofs across 105 files; Prover bot9001 was able to successfully produce a proof for 91 (17.7%) of the extracted theorem statements, without the use of CoqHammer. floatis a formalization of floating point numbers, made of 742 proofs across 38 files; Proverbot9001 was able to successfully produce a proof for 100 (13.48%) proofs. zfcis a formalization of set theory made of 241 proofs across 78 files; 41 (17.01%) were successfully completed. The comparable number for CompCert was 19.36%.MAPL ‚Äô20, June 15, 2020, London, UK Alex SanchezStern, Yousef Alhessi, Lawrence Saul, and Sorin Lerner Figure 12. A histogram plotting the original proof lengths in proof commands vs number of proofs of that length, in three classes, for proofs with length 10 or less. From bottom to top: proofs solved, proofs unsolved because of depth limit, and proofs where our search space was exhausted without finding a solution. Figure 13. A histogram plotting the original proof lengths in proof commands vs number of proofs of that length, in three classes. From bottom to top: proofs solved,proofsunsolvedbecauseofdepthlimit,andproofs where our search space was exhausted without finding a solution. Note that most proofs are between 0 and 10 proof commands long, with a long tail of much longer proofs. TheseresultsdemonstratenotonlythatProverbot9001 can operate on proof projects in a variety of domains, but more importantly that it can effectively transfer training from one project to another. This would allow programmers to use Proverbot9001 even in the initial de velopment of a project, if it had been previously trained on other projects. 8.4 Original Proof Length vs Completion Rate In Figure 12 and Figure 13, we plot a histogram of the original proof lengths (in proof commands) vs the number of proofs of that length. We break down the proofs by (from bottom to top) number we solve, number we cannot solve but still have unexplored nodes, and number run out of unexplored nodes before finding a solution. Note that for the second class (middle bar), it‚Äôs possible that increasing the search depth would allow usto complete the proof. Figure 12 shows proofs of length 10 or below, and Figure 13 shows all proofs, binned in sets of 10. There are several observations that can be made. First, most original proofs in our test set are less than 20 steps long, with a heavy tail of longer proofs. Second, we do better on shorter proofs. Indeed, 51% (256/501) of the original proofs in our test set are ten proof commands or shorter, and of those proofs, we can solve 35% (89/256), compared to our overall solve rate of 19.36% (97/501). Third, we are in some cases able to handle proofs whose original length is longer than 10. Indeed, 7 of the proofs we solve (out of 79 solved) had an original length longer than 10. In fact, the longest proof we solve is originally 25 proofcommandslong;linearizedit‚Äôs256proofcommands long. Our solution proof is 267 (linear) proof commands long, comparable to the original proof, with frequent case splits. The depth limit for individual obligations in our search was 6 in all of these runs. 9 Related Work "
431,Exploring Representation of Horn Clauses using GNNs (Extended Technical Report).txt,"Learning program semantics from raw source code is challenging due to the
complexity of real-world programming language syntax and due to the difficulty
of reconstructing long-distance relational information implicitly represented
in programs using identifiers. Addressing the first point, we consider
Constrained Horn Clauses (CHCs) as a standard representation of program
verification problems, providing a simple and programming language-independent
syntax. For the second challenge, we explore graph representations of CHCs, and
propose a new Relational Hypergraph Neural Network (R-HyGNN) architecture to
learn program features. We introduce two different graph representations of
CHCs. One is called constraint graph (CG), and emphasizes syntactic information
of CHCs by translating the symbols and their relations in CHCs as typed nodes
and binary edges, respectively, and constructing the constraints as abstract
syntax trees. The second one is called control- and data-flow hypergraph
(CDHG), and emphasizes semantic information of CHCs by representing the control
and data flow through ternary hyperedges. We then propose a new GNN
architecture, R-HyGNN, extending Relational Graph Convolutional Networks, to
handle hypergraphs. To evaluate the ability of R-HyGNN to extract semantic
information from programs, we use R-HyGNNs to train models on the two graph
representations, and on five proxy tasks with increasing difficulty, using
benchmarks from CHC-COMP 2021 as training data. The most difficult proxy task
requires the model to predict the occurrence of clauses in counter-examples,
which subsumes satisfiability of CHCs. CDHG achieves 90.59% accuracy in this
task. Furthermore, R-HyGNN has perfect predictions on one of the graphs
consisting of more than 290 clauses. Overall, our experiments indicate that
R-HyGNN can capture intricate program features for guiding verification
problems.","Automatic program verification is challenging because of the complexity of industrially relevant programs. In practice, constructing domainspecific heuristics from program features (e.g., 8th Workshop on Practical Aspects of Automated Reasoning /envelopeopenchencheng.liang@it.uu.se (C. Liang); philipp.ruemmer@it.uu.se (P. R√ºmmer); marc@marcbrockschmidt.de (M. Brockschmidt) /globehttps://github.com/ChenchengLiang/ (C. Liang); https://github.com/pruemmer/ (P. R√ºmmer); https://github.com/mmjb/ (M. Brockschmidt) /orcid0000000249268089 (C. Liang); 0000000227337098 (P. R√ºmmer); 0000000162772768 (M. Brockschmidt) ¬©2022 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0). CEUR Workshop Proceedingshttp://ceurws.org ISSN 16130073 CEUR Workshop Proceedings (CEURWS.org)arXiv:2206.06986v4  [cs.AI]  26 Jul 2022information from loops, control flow, or data flow) is essential for solving verification problems. For instance, [ 1] and [ 2] extract semantic information by performing systematical static analysis to refine abstractions for the counterexampleguided abstraction refinement (CEGAR) [ 3] based system. However, manually designed heuristics usually aim at a specific domain and are hard to transfer to other problems. Along with the rapid development of deep learning in recent years, learningbased methods have evolved quickly and attracted more attention. For example, the program features are explicitly given in [ 4,5] to decide which algorithm is potentially the best for verifying the programs. Later in [ 6,7], program features are learned in the endtoend pipeline. Moreover, some generative models [ 8,9] are also introduced to produce essential information for solving verification problems. For instance, Code2inv [ 10] embeds the programs by graph neural networks (GNNs) [ 11] and learns to construct loop invariants by a deep neural reinforcement framework. For deep learningbased methods, no matter how the learning pipeline is designed and the neural network structure is constructed, learning to represent semantic program features is essential and challenging (a) because the syntax of the source code varies depending on the pro gramming languages, conventions, regulations, and even syntax sugar and (b) because it requires capturing intricate semantics from longdistance relational information based on reoccurring identifiers. For the first challenge, since the source code is not the only way to represent a program, learning from other formats is a promising direction. For example, inst2vec [ 12] learns control and data flow from LLVM intermediate representation [ 13] by recursive neural networks (RNNs) [ 14]. Constrained Horn Clauses (CHCs) [ 15], as an intermediate verification language, consist of logic implications and constraints and can alleviate the difficulty since they can naturally encode program logic with simple syntax. For the second challenge, we use graphs to represent CHCs and learn the program features by GNNs since they can learn from the structural information within the node‚Äôs Nhop neighbourhood by recursive neighbourhood aggregation (i.e., neural message passing) procedure. In this work, we explore how to learn program features from CHCs by answering two questions: (1) What kind of graph representation is suitable for CHCs? (2) Which kind of GNN is suitable to learn from the graph representation? For the first point, we introduce two graph representations for CHCs: the constraint graph (CG) and control and dataflow hypergraph (CDHG). The constraint graph encodes the CHCs into three abstract layers (predicate, clause, and constraint layers) to preserve as much structural information as possible (i.e., it emphasizes program syntax). On the other hand, the Control and dataflow hypergraph uses ternary hyperedges to capture the flow of control and data in CHCs to emphasize program semantics. To better express control and data flow in CDHG, we construct it from normalized CHCs. The normalization changes the format of the original CHC but retains logical meaning. We assume that different graph representations of CHCs capture different aspects of semantics. The two graph representations can be used as a baseline to construct new graph representations of CHC to represent different semantics. In addition, similar to the idea in [ 16], our graph representations are invariant to the concrete symbol names in the CHCs since we map them to typed nodes. For the second point, we propose a Relational Hypergraph Neural Network (RHyGNN), an extension of Relational Graph Convolutional Networks (RGCN) [ 17]. Similar to the GNNs used in LambdaNet [ 18], RHyGNN can handle hypergraphs by concatenating the node repTable 1 Proxy tasks used to evaluate suitability of different graph representations. Task Task type Description 1. Argument identification Node binary classificationFor each element in CHCs, predict if it is an argu ment of relation symbols. 2. Count occurrence of rela tion symbols in all clausesRegression task on nodeFor each relation symbol, predict how many times it occurs in all clauses. 3. Relation symbol occur rence in SCCsNode binary classificationFor each relation symbol, predict if a cycle exists from the node to itself (membership in strongly connected component, SCC). 4. Existence of argument boundsNode binary classificationFor each argument of a relation symbol, predict if it has a lower or upper bound. 5. Clause occurrence in counterexamplesNode binary classificationFor each CHC, predict if it appears in counter examples. resentations involved in a hyperedge and passing the messages to all nodes connected by the hyperedge. Finally, we evaluate our framework (two graph representations of CHCs and RHyGNN) by five proxy tasks (see details in Table 1) with increasing difficulties. Task 1 requires the framework to learn to classify syntactic information of CHCs, which is explicitly encoded in the two graph representations. Task 2 requires the RHyGNN to predict a syntactic counting task. Task 3 needs the RHyGNN to approximate the Tarjan‚Äôs algorithm [ 19], which solves a general graph theoretical problem. Task 4 is much harder than the last three tasks since the existence of argument bounds is undecidable. Task 5 is harder than solving CHCs since it predicts the trace of counterexamples (CEs). Note that Task 1 to 3 can be easily solved by specific, dedicated standard algorithms. We include them to systematically study the representational power of graph neural networks applied to different graph construction methods. However, we speculate that using these tasks as pretraining objectives for neural networks that are later finetuned to specific (datapoor) tasks may be a successful strategy which we plan to study in future work. Our benchmark data is extracted from the 8705 linear and 8425 nonlinear Linear Integer Arithmetic (LIA) problems in the CHCCOMP repository1(see Table 1 in the competition report [ 20]). The verification problems come from various sources (e.g., higherorder program verification benchmark2and benchmarks generated with JayHorn3), therefore cover programs with different size and complexity. We collect and form the train, valid, and test data using the predicate abstractionbased model checker Eldarica [ 21]. We implement RHyGNNs4based on the framework tf2_gnn5. Our code is available in a Github repository6. For both graph representations, even if the predicted accuracy decreases along with the increasing difficulty of tasks, for undecidable problems in Task 4, RHyGNN still achieves high accuracy, i.e., 91% 1https://chccomp.github.io/ 2https://github.com/chccomp/hopv 3https://github.com/chccomp/jayhornbenchmarks 4https://github.com/ChenchengLiang/tf2gnn 5https://github.com/microsoft/tf2gnn 6https://github.com/ChenchengLiang/SystematicPredicateAbstractionusingMachineLearningand 94% for constraint graph and CDHG, respectively. Moreover, in Task 5, despite the high accuracy (96%) achieved by CDHG, RHyGNN has a perfect prediction on one of the graphs consisting of more than 290 clauses, which is impossible to achieve by learning simple patterns (e.g., predict the clause including false as positive). Overall, our experiments show that our framework learns not only the explicit syntax but also intricate semantics. Contributions of the paper. (i) We encode CHCs into two graph representations, emphasis ing abstract program syntactic and semantic information, respectively. (ii) We extend a message passingbased GNN, RGCN, to RHyGNN to handle hypergraphs. (iii) We introduce five proxy supervised learning tasks to explore the capacity of RHyGNN to learn semantic information from the two graph representations. (iv) We evaluate our framework on the CHCCOMP bench mark and show that this framework can learn intricate semantic information from CHCs and has the potential to produce good heuristics for program verification. 2. Background 2.1. From Program Verification to Horn clauses Constrained Horn Clauses are logical implications involving unknown predicates. They can be used to encode many formalisms, such as transition systems, concurrent systems, and interactive systems. The connections between program logic and CHCs can be bridged by FloydHoare logic [ 22,23], allowing to encode program verification problems into the CHC satisfiability problems [ 24]. In this setting, a program is guaranteed to satisfy a specification if the encoded CHCs are satisfiable, and vice versa. We write CHCs in the form ùêª‚Üêùêµ1‚àß¬∑¬∑¬∑‚àß ùêµùëõ‚àßùúô, where (i) ùêµùëñis an application ùëûùëñ(ùë°ùëñ¬Ø) of the relation symbol ùëûùëñto a list of firstorder terms ùë°ùëñ¬Ø; (ii)ùêªis either an application ùëû(ùë°¬Ø), or false ; (iii)ùúôis a firstorder constraint. Here, ùêªandùêµ1‚àß¬∑¬∑¬∑‚àß ùêµùëõ‚àßùúôin the left and right hand side of implication ‚Üêare called ‚Äúhead"" and ‚Äúbody"", respectively. An example in Figure 1 explains how to encode a verification problem into CHCs. In Figure 1a, we have a verification problem, i.e., a C program with specifications. It has an external input ùëõ, and we can initially assume that ùë•==ùëõ, ùë¶==ùëõ,and,ùëõ >= 0. While ùë•is not equal to 0,ùë•andùë¶are decreased by 1. The assertion is that finally, ùë¶== 0 . This program can be encoded to the CHC shown in Figure 1b. The variables ùë•andùë¶are quantified universally. We can further simplify the CHCs in Figure 1b to the CHCs shown in Figure 1c without changing the satisfiability by some preprocessing steps (e.g., inlining and slicing) [ 25]. For example, the first CHC encodes line 3, i.e., the assume statement, the second clause encodes lines 47, i.e., the while loop, and the third clause encodes line 8, i.e., the assert statement in Figure 1a. Solving the CHCs is equivalent to answering the verification problem. In this example, with a given ùëõ, if the CHCs are satisfiable for all ùë•andùë¶, then the program is guaranteed to satisfy the specifications. 2.2. Graph Neural Networks Letùê∫= (ùëâ, ùëÖ, ùê∏, ùëã, ‚Ñì )denote a graph in which ùë£‚ààùëâis a set of nodes, ùëü‚ààùëÖis a set of edge types, ùê∏‚ààùëâ√óùëâ√óùëÖis a set of typed edges, ùë•‚ààùëãis a set of node types, and ‚Ñì:ùë£‚Üíùë•is a0extern int n ; 1void main ( ) { 2 int x , y ; 3 assume ( x==n && y==n && n >=0) ; 4 while ( x ! = 0 ) { 5 x‚àí ‚àí; 6 y‚àí ‚àí; 7 } 8 a s s e r t ( y ==0) ; 9} (a) An verification problem written in C.ùêø0(ùëõ)‚Üêùë°ùëüùë¢ùëí line 0 ùêø1(ùëõ)‚Üêùêø0(ùëõ) line 1 ùêø2(ùë•, ùë¶, ùëõ )‚Üêùêø1(ùëõ) line 2 ùêø3(ùë•, ùë¶, ùëõ )‚Üêùêø2(ùë•, ùë¶, ùëõ )‚àßùëõ‚â•0 ‚àßùë•=ùëõ‚àßùë¶=ùëõ line 3 ùêø8(ùë•, ùë¶, ùëõ )‚Üêùêø3(ùë•, ùë¶, ùëõ )‚àßùë•= 0 line 4 ùêø4(ùë•, ùë¶, ùëõ )‚Üêùêø3(ùë•, ùë¶, ùëõ )‚àßùë•Ã∏= 0 line 4 ùêø5(ùë•, ùë¶, ùëõ )‚Üêùêø4(ùë•‚Ä≤, ùë¶, ùëõ)‚àßùë•=ùë•‚Ä≤‚àí1line 5 ùêø6(ùë•, ùë¶, ùëõ )‚Üêùêø5(ùë•, ùë¶‚Ä≤, ùëõ)‚àßùë¶=ùë¶‚Ä≤‚àí1line 6 ùêø3(ùë•, ùë¶, ùëõ )‚Üêùêø6(ùë•, ùë¶, ùëõ ) line 6 false‚Üêùêø8(ùë•, ùë¶, ùëõ )‚àßùë¶Ã∏= 0 line 8 (b) CHCs encoded from C program in Figure 1a. ùêø(ùë•, ùë¶, ùëõ )‚Üêùëõ‚â•0‚àßùë•=ùëõ‚àßùë¶=ùëõ line 3 ùêø(ùë•, ùë¶, ùëõ )‚Üêùêø(ùë•‚Ä≤, ùë¶‚Ä≤, ùëõ‚Ä≤)‚àßùë•‚Ä≤Ã∏= 0‚àßùë•=ùë•‚Ä≤‚àí1‚àßùë¶=ùë¶‚Ä≤‚àí1‚àßùëõ=ùëõ‚Ä≤line 47 false‚Üêùêø(ùë•, ùë¶, ùëõ )‚àßùë•= 0‚àßùë¶Ã∏= 0 line 8 (c) Simplified CHCs from Figure 1b. Figure 1: An example to show how to encode a verification problem written in C to CHCs. For the C program, the lefthand side numbers indicate the line number. The line numbers in Figure 1b and 1c correspond to the line in Figure 1a. For example, the line ùêø0(ùëõ)‚Üêùë°ùëüùë¢ùëí in Figure 1b is transformed from line 1 ‚Äúextern int n ;"" in Figure 1a. labelling map from nodes to their type. A tuple ùëí= (ùë¢, ùë£, ùëü )‚ààùê∏denotes an edge from node ùë¢ toùë£with edge type ùëü. Message passingbased GNNs use a neighbourhood aggregation strategy, where at timestep ùë°, each node updates its representation ‚Ñéùë° ùë£by aggregating representations of its neighbours and then combining its own representation. The initial node representation ‚Ñé0 ùë£is usually derived from its type or label ‚Ñì(ùë£). The common assumption of this architecture is that after ùëáiterations, the node representation ‚Ñéùëá ùë£captures local information within ùë°hop neighbourhoods. Most GNN architectures [ 26,27] can be characterized by their used ‚Äúaggregation‚Äù function ùúåand ‚Äúupdate‚Äù function ùúë. The node representation of the ùë°th layer of such a GNN is then computed by‚Ñéùë° ùë£=ùúë(ùúå({‚Ñéùë°‚àí1 ùë¢|ùë¢‚ààùëÅùëü ùë£, ùëü‚ààùëÖ}), ‚Ñéùë°‚àí1 ùë£), where ùëÖis a set of edge type and ùëÅùëü ùë£is the set of nodes that are the neighbors of ùë£in edge type ùëü. A closed GNN architecture to the RHyGNN is RGCN [ 17]. They update the node represen tation by ‚Ñéùë° ùë£=ùúé(‚àëÔ∏Å ùëü‚ààùëÖ‚àëÔ∏Å ùë¢‚ààùëÅùëüùë£1 ùëêùë£,ùëüùëäùë° ùëü‚Ñéùë°‚àí1 ùë¢+ùëä0‚Ñéùë°‚àí1 ùë£), (1) where ùëäùëüandùëä0are edgetypedependent trainable weights, ùëêùë£,ùëüis a learnable or fixed normalisation factor, and ùúéis a activation function.3. Graph Representations for CHCs Graphs as a representation format support arbitrary relational structure and thus can naturally encode information with rich structures like CHCs. We define two graph representations for CHCs that emphasize the program syntax and semantics, respectively. We map all symbols in CHCs to typed nodes and use typed edges to represent their relations. In this section, we give concrete examples to illustrate how to construct the two graph representations from a single CHC modified from Figure 1c. In the examples, we first give the intuition of the graph design and then describe how to construct the graph stepwise. To better visualize how to construct the two graph representations in Figures 2 and 3, the concrete symbol names for the typed nodes are shown in the blue boxes. RHyGNN is not using these names (which, as a result of repeated transformations, usually do not carry any meaning anyway) and only consumes the node types. We include abstract examples, the formal definitions of the graph representations, and the algorithms to construct them from multiple CHCs in this section as well. Note that the two graph representations in this study are designed empirically. They can be used as a baseline to create variations of the graphs to fit different purposes. 3.1. Constraint Graph (CG) Our Constraint graph is a directed graph with binary edges designed to emphasize syntactic information in CHCs. One concrete example of constructing the constraint graph for a single CHC ùêø(ùë•, ùë¶, ùëõ )‚Üêùêø(ùë•‚Ä≤, ùë¶‚Ä≤, ùëõ‚Ä≤)‚àßùë•Ã∏= 0‚àßùë•=ùë•‚Ä≤‚àí1‚àßùë¶=ùë¶‚Ä≤‚àí1modified from Figure 1c is shown in Figure 2. The corresponding node and edge types are described in Tables 2 and 3. We construct the constraint graph by parsing the CHCs in three different aspects (relation symbol, clause structure, and constraint) and building relations for them. In other words, a constraint graph consists of three layers: the predicate layer depicts the relation between relation symbols and their arguments; the clause layer describes the abstract syntax of head and body items in the CHC; the constraint layer represents the constraint by abstract syntax trees (ASTs). Constructing a constraint graph. Now we give a concrete example to describe how to construct a constraint graph for a single CHC ùêø(ùë•, ùë¶, ùëõ )‚Üêùêø(ùë•‚Ä≤, ùë¶‚Ä≤, ùëõ‚Ä≤)‚àßùë•Ã∏= 0‚àßùë•= ùë•‚Ä≤‚àí1‚àßùë¶=ùë¶‚Ä≤‚àí1stepwise. All steps correspond to the steps in Figure 2. In the first step, we draw relation symbols and their arguments as typed nodes and build the connection between them. In the second step, we construct the clause layer by drawing clauses, the relation symbols in the head and body, and their arguments as typed nodes and build the relation between them. In the third step, we construct the constraint layer by drawing ASTs for the subexpressions of the constraint. In the fourth step, we add connections between three layers. The predicate and clause layer are connected by the relation symbol instance ( RSI) and argument instance ( AI) edges, which means the elements in the predicate layer are instances of the clause layer. The clause and constraint layers are connected by the GUARD andDATA edges since the constraint is the guard of the clause implication, and the constraint and clause layer share some elements.Figure 2: Construct constraint graph from the CHC ùêø(ùë•, ùë¶, ùëõ )‚Üêùêø(ùë•‚Ä≤, ùë¶‚Ä≤, ùëõ‚Ä≤)‚àßùë•Ã∏= 0‚àßùë•=ùë•‚Ä≤‚àí1‚àßùë¶= ùë¶‚Ä≤‚àí1. Note that some nodes have multiple concrete symbol names (e.g., node ùëüùë†ùëé 1has two concrete names, ùë•andùë•‚Ä≤) since one relation symbol may bind with different arguments. Table 2 Node types for constraint graph. The shape corresponds to the shape of nodes in Figure 2 and is only used for visualizing the example. Node types ùëãùê∂ùê∫Layer Explanation Elements in CHCs Shape relation symbol (ùëüùë†)Predicate layer Relation symbols in head or bodyùêø false Predicate layer false state false relation symbol argument (ùëüùë†ùëé)Predicate layer Arguments of the relation symbolsx, y clause (ùëêùëôùëé) Clause layer Represent clause as a ab stract node‚àÖ clause head (ùëê‚Ñé) Clause layer Relation symbol in head ùêø clause body (ùëêùëè) Clause layer Relation symbol in body ùêø clause argument (ùëêùëé)Clause layer Arguments of relation sym bol in head and bodyùë•, ùë¶ variable (ùë£ùëéùëü) Constraint layer Free variables n operator (ùëúùëù) Constraint layer Operators over a theory =,  constant (ùëê) Constraint layer Constants over a theory 0, 1, true Formal definition of constraint graph . A constraint graph ùê∂ùê∫= (ùëâ,BE, ùëÖùê∂ùê∫, ùëãùê∂ùê∫, ‚Ñì) consists of a set of nodes ùë£‚ààùëâ, a set of typed binary edges BE‚ààùëâ√óùëâ√óùëÖùê∂ùê∫, a set of edge types ùëü‚ààùëÖùê∂ùê∫(Table 3), a set of node types ùë•‚ààùëãùê∂ùê∫(Table 2), and a map ‚Ñì:ùë£‚Üíùë•. Here, (ùë£1, ùë£2, ùëü)‚ààBEdenotes a binary edge with edge type ùëü. The node types are used to generate the initial feature ùë•ùë£, a realvalued vector in RHyGNN.Table 3 Edge types for constraint graph. Here, ùëüùë†, ùëüùë†ùëé, ùëêùëôùëé , etc. are node types described in Table 2.Here, ‚Äú |"" means ‚Äúor"". For example, ùëê|ùëúùëù|ùë£ùëéùëümeans this node could be node with type ùëê,ùëúùëù, orùë£ùëéùëü. Edge type ùëÖùê∂ùê∫Layer Definition Explanation Relation Symbol Ar gument ( RSA)Predicate layer ( ùëüùë†, ùëüùë†ùëé, RSA) Connects relation symbols and their arguments Relation Symbol In stance ( RSI)Between predicate and clause layer(ùëüùë†, ùëê‚Ñé, RSA)|(ùëêùëè, ùëüùë†, RSA)Connects relation symbols with their head and body Argument Instance (AI)Between predicate and clause layer(ùëùùëé, ùëêùëé, AI) Connects relation symbols and their arguments Clause Head ( CH) Clause layer (ùëêùëôùëé, ùëê‚Ñé, CH) Connect ùëêùëôùëéùë¢ùë†ùëí node to its head Clause Body ( CB) Clause layer (ùëêùëè, ùëêùëôùëé, CB) Connect the ùëêùëôùëéùë¢ùë†ùëí node to its body Clause Argument (CA)Clause layer (ùëêùëé, ùëêùëè, CA)|(ùëê‚Ñé, ùëêùëé, CA)Connect ùëê‚Ñéorùëêùëènodes with corresponding ùëêùëénodes Guard ( GUARD ) Between clause and constraint layer(ùëê|ùëúùëù, ùëêùëôùëé, GUARD ) Connect the root node of the AST to corresponding ùëêùëôùëéùë¢ùë†ùëí node Data ( DATA ) Between clause and constraint layer(ùë£ùëéùëü, ùëêùëé, DATA ) Connect ùëêùëénodes to corre sponding ùë£ùëéùëünodes AST AST subterm ( ùê¥ùë†ùë°)Constraint layer (ùëê|ùë£ùëéùëü|ùëúùëù, ùëúùëù, ùê¥ ùë†ùë°) Connect nodes within AST An abstract example of constraint graph . Except for the concrete example, we give a abstract example to describe how to construct the constraint graph. First, the CHC ùêª‚Üê ùêµ1‚àß¬∑¬∑¬∑‚àß ùêµùëõ‚àßùúôin Section 2 can be rewritten to ùëû1(ùë°1¬Ø)‚Üêùëû2(ùë°2¬Ø)‚àß¬∑¬∑¬∑‚àß ùëûùëò(ùë°ùëò¬Ø)‚àßùúô1‚àß¬∑¬∑¬∑ùúôùëõ,(ùëõ, ùëò‚ààN), (2) where ùúô1¬∑¬∑¬∑ùúôùëòare subformulas for constraint ùúô. Notice that since there is no normalization for the original CHCs, the same relation symbols can appear in both head and body (i.e., ùëû1, ùëû2,¬∑¬∑¬∑, ùëûùëòmay equal to each other). Then, we can construct a constraint graph using Algorithm 1, in which the input is a set of CHC and the output is a constraint graph ùê∂ùê∫= (ùëâ,BE, ùëÖùê∂ùê∫, ùëãùê∂ùê∫, ‚Ñì). The stepwise constructing process for the CHC in Eq. (2) is visualized in Figure 6. 3.2. Control and Dataflow Hypergraph (CDHG) In contrast to the constraint graph, the CDHG representation emphasizes the semantic informa tion (control and data flow) in the CHCs by hyperedges which can join any number of vertices. To represent control and data flow in CDHG, first, we preprocess every CHC and then split the constraint into control and data flow subformulas. Normalization. We normalize every CHC by applying the following rewriting steps: (i) We ensure that every relation symbol occurs at most once in every clause. For instance, the CHC ùëû(ùëé)‚Üêùëû(ùëè)‚àßùëû(ùëê)has multiple occurrences of the relation symbol ùëû, and we normalize it toTable 4 Control and dataflow subformula in constraints for the normalized CHCs from Figure 1c Normalized CHCs Controlflow subformula Dataflow subformula ùêø(ùë•, ùë¶, ùëõ )‚Üêùëõ‚â•0‚àßùë•=ùëõ‚àßùë¶=ùëõ ùëõ‚â•0 ùë•=ùëõ, ùë¶=ùëõ ùêø(ùë•, ùë¶, ùëõ )‚Üêùêø‚Ä≤(ùë•‚Ä≤, ùë¶‚Ä≤, ùëõ‚Ä≤)‚àßùë•Ã∏= 0‚àß ùë•=ùë•‚Ä≤‚àí1‚àßùë¶=ùë¶‚Ä≤‚àí1ùë•Ã∏= 0 ùë•=ùë•‚Ä≤‚àí1, ùë¶=ùë¶‚Ä≤‚àí1 ùêø‚Ä≤(ùë•‚Ä≤, ùë¶‚Ä≤, ùëõ‚Ä≤)‚Üêùêø(ùë•, ùë¶, ùëõ )‚àßùë•‚Ä≤=ùë•‚àß ùë¶‚Ä≤=ùë¶‚àßùëõ‚Ä≤=ùëõempty ùë•‚Ä≤=ùë•, ùë¶‚Ä≤=ùë¶, ùëõ‚Ä≤=ùëõ false‚Üêùêø(ùë•, ùë¶, ùëõ )‚àßùë•= 0‚àßùë¶Ã∏= 0 ùë¶Ã∏= 0 ùë•= 0 equisatisfiable CHCs ùëû(ùëé)‚Üêùëû‚Ä≤(ùëè)‚àßùëû‚Ä≤‚Ä≤(ùëê), ùëû‚Ä≤(ùëè)‚Üêùëû(ùëè‚Ä≤)‚àßùëè=ùëè‚Ä≤andùëû‚Ä≤‚Ä≤(ùëê)‚Üêùëû(ùëê‚Ä≤)‚àßùëê=ùëê‚Ä≤. (ii) We associate each relation symbol ùëûwith a unique vector of pairwise distinct argument variables ùë•¬Øùëû, and rewrite every occurrence of ùëûto the form ùëû(ùë•¬Øùëû). In addition, all the argument vectors ùë•¬Øùëûare kept disjoint. The normalized CHCs from Figure 1c are shown in Table 4. Splitting constraints into control and dataflow formulas. We can rewrite the con straint ùúôto a conjunction ùúô=ùúô1‚àß¬∑¬∑¬∑‚àß ùúôùëò, ùëò‚ààN.The subformula ùúôùëñis called a ‚Äúdataflow subformula‚Äù if and only if it can be rewritten to the form ùë•=ùë°(ùë¶¬Ø)such that (i) ùë•is one of the arguments in head ùëû(ùë•¬Øùëû); (ii)ùë°(ùë¶¬Ø)is a term over variables ùë¶¬Ø, where each element of ùë¶¬Øis an argument of some body literal ùëû‚Ä≤(ùë•¬Øùëû‚Ä≤). We call all other ùúôùëó‚Äúcontrolflow subformulas‚Äù. A constraint ùúôcan then be represented by ùúô=ùëî1‚àß¬∑¬∑¬∑‚àß ùëîùëö‚àßùëë1‚àß¬∑¬∑¬∑‚àß ùëëùëõ, where ùëö, ùëõ‚ààN andùëîùëñandùëëùëóare the control and dataflow subformulas, respectively. The control and data flow subformulas for the normalized CHCs of our running example are shown in Table 4. Constructing a CDHG. The CDHG represents program control and dataflow by guarded controlflow hyperedges CFHE and dataflow hyperedges DFHE . ACFHE edge denotes the flow of control from the body to head literals of the CHC. A DFHE edge denotes how data flows from the body to the head. Both control and dataflow are guarded by the control flow subformula. Constructing the CDHG for a normalized CHC ùêø(ùë•, ùë¶, ùëõ )‚Üêùêø‚Ä≤(ùë•‚Ä≤, ùë¶‚Ä≤, ùëõ‚Ä≤)‚àßùë•Ã∏= 0‚àßùë•= ùë•‚Ä≤‚àí1‚àßùë¶=ùë¶‚Ä≤‚àí1is shown in Figure 3. The corresponding node and edge types are described in Tables 5 and 6. In the first step, we draw relation symbols and their arguments and build the relation between them. In the second step, we add a ùëîùë¢ùëéùëüùëë node and draw ASTs for the control flow subformulas. In the third step, we construct guarded controlflow edges by connecting the relation symbols in the head and body and the ùëîùë¢ùëéùëüùëë node, which connects the root of control flow subformulas. In the fourth step, we construct the ASTs for the righthand side of every data flow subformula. In the fifth step, we construct the guarded dataflow edges by connecting the left and righthand sides of the data flow subformulas and the ùëîùë¢ùëéùëüùëë node. Note that the diamond shapes in Figure 3 are not nodes in the graph but are used to visualize our (ternary) hyperedges of types CFHE andDFHE . We show it in this way to visualize CDHG better. Formal definition of CDHG. A CDHG ùêªùê∫= (ùëâ,HE, ùëÖùê∂ùê∑ùêªùê∫, ùëãùê∂ùê∑ùêªùê∫, ‚Ñì)consists of a set of nodes ùë£‚ààùëâ, a set of typed hyperedge HE‚ààùëâ*√óùëÖùê∂ùê∑ùêªùê∫where ùëâ*is a list of nodeFigure 3: Construct the CDHG from the CHC ùêø(ùë•, ùë¶, ùëõ )‚Üêùêø‚Ä≤(ùë•‚Ä≤, ùë¶‚Ä≤, ùëõ‚Ä≤)‚àßùë•Ã∏= 0‚àßùë•=ùë•‚Ä≤‚àí1‚àßùë¶= ùë¶‚Ä≤‚àí1. from ùëâ, a set of node types ùë•‚ààùëãùê∂ùê∑ùêªùê∫(Table 5),a set of edge types ùëü‚ààùëÖùê∂ùê∑ùêªùê∫(Table 6), and a map ‚Ñì:ùë£‚Üíùë•. Here, (ùë£1, ùë£2,¬∑¬∑¬∑, ùë£ùëõ, ùëü)‚ààùêªùê∏ denotes a hyperedge for a list of nodes (ùë£1,¬∑¬∑¬∑, ùë£ùëõ)with edge type ùëü. The node types are used to generate the initial feature ùë•ùë£, a realvalued vector, in RHyGNN. The guarded CFHE is a typed hyperedge (ùë£1,¬∑¬∑¬∑, ùë£ùëõ, ùëî,CFHE )‚ààHE, where the type of ùë£1,¬∑¬∑¬∑, ùë£ùëõisùëüùë†. Since RHyGNN has more stable performance with fixed number of node in one edge type, we transform the hyperedge (ùë£1,¬∑¬∑¬∑, ùë£ùëõ, ùëî,CFHE )‚ààùêªùê∏ with variable number of nodes to a set of ternary hyperedges (i.e., {(ùë£1, ùë£2, ùëî,CFHE ),(ùë£1, ùë£3, ùëî,CFHE ),¬∑¬∑¬∑,(ùë£1, ùë£ùëõ, ùëî,CFHE )}). The guarded DFHE is a typed ternary hyperedge (ùë£ùëñ, ùë£ùëó, ùëî,DFHE )‚ààHE, where ùë£ùëñ‚Äôs type is ùëüùë†ùëéandùë£ùëó‚Äôs type could be one of {ùëúùëù, ùëê, ùë£}. An abstract example of CDHG. Except for the concrete example, we give a abstract example to describe how to construct the CDHG. After the preprocessings (normalization and splitting the constraint to guard and data flow subformulas), the CHC ùêª‚Üêùêµ1‚àß¬∑¬∑¬∑‚àß ùêµùëõ‚àßùúôin Section 2 can be rewritten to ùëû1(ùë°1¬Ø)‚Üêùëû2(ùë°2¬Ø)‚àß¬∑¬∑¬∑‚àß ùëûùëò(ùë°ùëò¬Ø)‚àßùëî1‚àß¬∑¬∑¬∑ùëîùëö‚àßùëë1‚àß¬∑¬∑¬∑ùëëùëõ,(ùëö, ùëõ, ùëò‚ààN). (3) We can construct the corresponding CDHG using Algorithm 2, in which the input is a set of CHC and the output is a CDHG ùêªùê∫ = (ùëâ,HE, ùëÖùê∂ùê∑ùêªùê∫, ùëãùê∂ùê∑ùêªùê∫, ‚Ñì). The stepwiseTable 5 Node types for the CDHG. Note that Tables 2 and 5 use some same node types because they represent the same elements in the CHC. Some abstract nodes, such as initial andguard , do not have concrete symbol names since they do not directly associate with any element in the CHCs. Node types ùëãùê∂ùê∑ùêªùê∫Explanation Elements in CHCs Shape relation symbol (ùëüùë†) Relation symbols in head or body ùêø initial Initial state ‚àÖ false false state false relation symbol argument (ùëüùë†ùëé)Arguments of the relation symbols ùë•, ùë¶ variables (ùë£ùëéùëü) Free variables ùëõ operator (ùëúùëù) Operators over a theory =, + constant (ùëê) Constant over a theory 0, 1, ùë°ùëüùë¢ùëí guard (ùëî) Guard for CFHE andDFHE‚àÖ Table 6 Edge types for the CDHG. ùëüùë†, ùëüùë†ùëé, ùë£ùëéùëü, ùëúùëù, ùëê, ùëíùë°ùëê. are node types from Table 5. Edge type ùëÖùê∂ùê∑ùêªùê∫Edge arity Definition Explanation Control Flow Hy peredge ( CFHE )Ternary (ùëüùë†1, ùëüùë†2|false, ùëî, CFHE )Connects the ùëüùë†node in body and head, and abstract guard node Data Flow Hyper edge ( DFHE )Ternary (ùëé, ùëúùëù|ùëê|ùë£ùëéùëü, ùëî, DFHE )Connects the root node of right hand and lefthand side of data flow subformulas, and a abstract guard node Guard ( Guard ) Binary (ùëúùëù|ùëê, ùëî,Guard ) Connects all roots of ASTs of con trol flow subformulas and the ùëîùë¢ùëéùëüùëë node Relation Symbol Ar gument ( RSA)Binary (ùëé, ùëüùë†, RSA) Connects ùëüùë†ùëénodes and their ùëüùë† node AST_left ( ùê¥ùëô) Binary (ùëúùëù, ùëúùëù|ùë£ùëéùëü|ùëê, ùê¥ùëô) Connects lefthand side element of a binary operator or an element from a unary operator AST_right ( ùê¥ùëü) Binary (ùëúùëù, ùëúùëù|ùë£ùëéùëü|ùëê, ùê¥ùëü) It connects righthand side element of a binary operator constructing process for the CHC in (3) is visualized in Figure 7. 4. Relational Hypergraph Neural Network Different from regular graphs, which connect nodes by binary edges, CDHG includes hyperedges which connect arbitrary number of nodes. Therefore, we extend RGCN to RHyGNN to handle hypergraphs. Concretely, to compute a new representation of a node ùë£at timestep ùë°, we consider all hyperedges ùëíthat involve ùë£. For each such hyperedge we create a ‚Äúmessage‚Äù by concatenating the representations of allnodes involved in that hyperedge and multiplying the result with a learnable matrix ùëäùë° ùëü,ùëù, where ùëüis the type of the relation and ùëùthe position that ùë£takes in thehyperedge. Intuitively, this means that we have one learnable matrix for each distinguishable way a node can be involved in a relation. Hence, the updating rule for node representation at time step ùë°in RHyGNN is ‚Ñéùë° ùë£= ReLU(‚àëÔ∏Å ùëü‚ààùëÖ‚àëÔ∏Å ùëù‚ààùëÉùëü‚àëÔ∏Å ùëí‚ààùê∏ùëü,ùëù ùë£ùëäùë° ùëü,ùëù¬∑‚Äñ[‚Ñéùë°‚àí1 ùë¢|ùë¢‚ààùëí]), (4) where‚Äñ{¬∑} denotes concatenation of all elements in a set, ùëü‚ààùëÖ={ùëüùëñ|ùëñ‚ààN}is the set of edge types (relations), ùëù‚ààùëÉùëü={ùëùùëó|ùëó‚ààN}is the set of node positions under edge type ùëü, ùëäùë° ùëü,ùëùdenotes learnable parameters when the node is in the ùëùth position with edge type ùëü, and ùëí‚ààùê∏ùëü,ùëù ùë£is the set of hyperedges of type ùëüin the graph in which node ùë£appears in position ùëù, where ùëíis a list of nodes. The updating process for the representation of node ùë£at time step 1 is illustrated in Figure 4. Note that different edge types may have the same number of connected nodes. For instance, in CDHG, CFHE andDFHE are both ternary edges. Overall, our definition of RHyGNN is a generalization of RGCN. Concretely, it can directly be applied to the specialcase of binary graphs, and in that setting is slightly more powerful as each message between nodes is computed using the representations of both source and target nodes, whereas RGCN only uses the source node representation. 4.1. Training Model The endtoend model consists of three components: the first component is an embedding layer, which learns to map the node‚Äôs type (encoded by integers) to the initial feature vectors; the second component is RHyGNN, which learns program features; the third component is a set of fully connected neural networks, which learns to solve a specific task by using gathered node representations from RHyGNNs. All parameters in these three components are trained together. Note that different tasks may gather different node representations. For example, Task 1 gathers all node representations, while Task 2 only gathers node representations with typeùëüùë†. We set all vector lengths to 64, i.e., the embedding layer output size, the middle layers‚Äô neuron size in RHyGNNs, and the layer sizes in fully connected neural networks are all 64. The maximum training epoch is 500, and the patient is 100. The number of message passing steps is 8 (i.e., (4)is applied eight times). For the rest of the parameters (e.g., learning rate, optimizer, dropout rate, etc.), we use the default setting in the tf2_gnn framework. We set these parameters empirically according to the graph size and the structure. We apply these fixed parameter settings for all tasks and two graph representations without finetuning. 5. Proxy Tasks We propose five proxy tasks with increasing difficulty to systematically evaluate the RHyGNN on the two graph representations. Tasks 1 to 3 evaluate if RHyGNN can solve general problems in graphs. In contrast, Tasks 4 and 5 evaluate if combining our graph representations and RHyGNN can learn program features to solve the encoded program verification problems. Wefirst describe the learning target for every task and then explain how to produce training labels and discuss the learning difficulty. Task 1: Argument identification. For both graph representations, the RHyGNN model performs binary classification on all nodes to predict if the node type is a relation symbol argument ( ùëüùë†ùëé) and the metric is accuracy. The binary training label is obtained by reading explicit node types. This task evaluates if RHyGNN can differentiate explicit node types. This task is easy because the graph explicitly includes the node type information in both typed nodes and edges. Task 2: Count occurrence of relation symbols in all clauses. For both graph representa tions, the RHyGNN model performs regression on nodes with type ùëüùë†to predict how many times the relation symbols occur in all clauses. The metric is mean square error. The training label is obtained by counting the occurrence of every relation symbol in all clauses. This task is designed to see if RHyGNN can correctly perform a counting task. For example, the relation symbol ùêøoccurs four times in all CHCs in Figure 4, so the training label for node ùêøis value 4. This task is harder than Task 1 since it needs to count the connected binary edges or hyperedges for a particular node. Task 3: Relation symbol occurrence in SCCs. For both graph representations, the R HyGNN model performs binary classification on nodes with type ùëüùë†to predict if this node is an SCC (i.e., in a cycle) and the metric is accuracy. The binary training label is obtained using Tarjan‚Äôs algorithm [ 19]. For example, in Figure 4, ùêøis an SCC because ùêøandùêø‚Ä≤construct a cycle byùêø‚Üêùêø‚Ä≤andùêø‚Ä≤‚Üêùêø. This task is designed to evaluate if RHyGNN can recognize general graph structures such as cycles. This task requires the model to classify a graphtheoretic object (SCC), which is harder than the previous two tasks since it needs to approximate a concrete algorithm rather than classifying or counting explicit graphical elements. Task 4: Existence of argument bounds. For both graph representations, we train two independent RHyGNN models which perform binary classification on nodes with type ùëüùë†ùëé to predict if individual arguments have (a) lower and (b) upper bounds in the least solution of a set of CHCs, and the metric is accuracy. To obtain the training label, we apply the Horn solver Eldarica to check the correctness of guessed (and successively increased) lower and upper arguments bounds; arguments for which no bounds can be shown are assumed to be unbounded. We use a timeout of 3 s for the lower and upper bound of a single argument, respectively. The overall timeout for extracting labels from one program is 3 hours. For example, consider the CHCs in Fig. 1c. The CHCs contain a single relation symbol ùêø; all three arguments of ùêøare bounded from below but not from above. This task is (significantly) harder than the previous three tasks, as boundedness of arguments is an undecidable property that can, in practice, be approximated using static analysis methods. Task 5: Clause occurrence in counterexamples This task consists of two binary clas sification tasks on nodes with type guard (for CDHG), and with type clause (for constraintgraph) to predict if a clause occurs in the counterexamples. Those kinds of nodes are unique representatives of the individual clauses of a problem. The task focuses on unsatisfiable sets of CHCs. Every unsatisfiable clause set gives rise to a set of minimal unsatisfiable subsets (MUSes); MUSes correspond to the minimal CEs of the clause set. Two models are trained independently to predict whether a clause belongs to (a) the intersection or (b) the union of the MUSes of a clause set. The metric for this task is accuracy. We obtain training data by applying the Horn solver Eldarica [ 25], in combination with an optimization library that provides an algorithm to compute MUSes7. This task is hard, as it attempts the prediction of an uncomputable binary labelling of the graph. 6. Evaluation We first describe the dataset we use for the training and evaluation and then analyse the experiment results for the five proxy tasks. 6.1. Benchmarks and Dataset Table 7 shows the number of labelled graph representations from a collection of CHCCOMP benchmarks [ 20]. All graphs were constructed by first running the preprocessor of Eldarica [ 25] on the clauses, then building the graphs as described in Section 3, and computing training data. For instance, in the first four tasks we constructed 2337 constraint graphs with labels from 8705 benchmarks in the CHCCOMP LIALin track (linear Horn clauses over linear integer arithmetic). The remaining 6368 benchmarks are not included in the learning dataset because when we construct the graphs, (1) the data generation process timed out, or (2) the graphs were too big (more than 10,000 nodes), or (3) there was no clause left after simplification. In Task 5, since the label is mined from CEs, we first need to identify unsat benchmarks using a Horn solver (1hour timeout), and then construct graph representations. We obtain 881 and 857 constraint graphs when we form the labels for Task 5 (a) and (b), respectively, in LIALin. Finally, to compare the performance of the two graph representations, we align the dataset for both two graph representations to have 5602 labelled graphs for the first four tasks. For Task 5 (a) and (b), we have 1927 and 1914 labelled graphs, respectively. We divide them to train, valid, and test sets with ratios of 60%, 20%, and 20%. We include all corresponding files for the dataset in a Github repository8. 6.2. Experimental Results for Five Proxy Tasks From Table 8, we can see that for all binary classification tasks, the accuracy for both graph representations is higher than the ratios of the dominant labels. For the regression task, the scattered points are close to the diagonal line. These results show that RHyGNN can learn the syntactic and semantic information for the tasks rather than performing simple strategies (e.g., fill all likelihood by 0 or 1). Next, we analyse the experimental results for every task. 7https://github.com/uuverifiers/latticeoptimiser/ 8https://github.com/ChenchengLiang/HorngraphdatasetTable 7 The number of labeled graph representations extracted from a collection of CHCCOMP benchmark [20]. For each SMTLIB file, the graph representations for Task 1,2,3,4 are extracted together using the timeout of 3 hours, and for task 5 is extracted using 20 minutes timeout. Here, T. denotes Task. SMTLIB files Constraint graphs CDHGs Total Unsat T. 14 T. 5 (a) T. 5 (b) T. 14 T. 5 (a) T. 5 (b) Linear LIA 8705 1659 2337 881 857 3029 880 883 Nonlinear LIA 8425 3601 3376 1141 1138 4343 1497 1500 Aligned 17130 5260 5602 1927 1914 5602 1927 1914 Task 1: Argument identification. When the task is performed in the constraint graph, the accuracy of prediction is 100%, which means RHyGNN can perfectly differentiate if a node is a relation symbol argument ùëüùë†ùëénode. When the task is performed in CDHG, the accuracy is close to 100% because, unlike in the constraint graph, the number of incoming and outgoing edges are fixed (i.e., ùëÖùëÜùê¥ andùê¥ùêº), the ùëüùë†ùëénodes in CDHG may connect with a various number of edges (including ùëÖùëÜùê¥ ,ùê¥ùëÜùëá _1,ùê¥ùëÜùëá _2, and DFHE ) which makes RHyGNN hard to predict the label precisely. Besides, the data distribution looks very different between the two graph representations because the normalization of CHCs introduces new clauses and arguments. For example, in the simplified CHCs in Figure 1c, there are three arguments for the relation symbol ùêø, while in the normalized clauses in Figure 4, there are six arguments for two relation symbols ùêøandùêø‚Ä≤. If the relation symbols have a large number of arguments, the difference in data distribution between the two graph representations becomes larger. Even though the predicted label in this task cannot directly help solve the CHCencoded problem, it is important to study the message flows in the RHyGNNs. Task 2: Count occurrence of relation symbols in all clauses. In the scattered plots in Figure 5, the x and yaxis denote true and the predicted values in the logarithm scale, respec tively. The closer scattered points are to the diagonal line, the better performance of predicting the number of relation symbol occurrences in CHCs. Both CDHG and constraint graph show good performance (i.e., most of the scattered points are near the diagonal lines). This syntactic information can be obtained by counting the CFHE andRSIedges for CDHG and constraint graph, respectively. When the number of nodes is large, the predicted values are less accurate. We believe this is because graphs with a large number of nodes have a more complex structure, and there is less training data. Moreover, the mean square error for the CDHG is larger than the constraint graph because normalization increases the number of nodes and the maximum counting of relation symbols for CDHG, and the larger range of the value is, the more difficult for regression task. Notice that the number of test data (1115) for this task is less than the data in the test set (1121) shown in Table 7 because the remaining six graphs do not have a ùëüùë†node. Task 3: Relation symbol occurrence in SCCs. The predicted high accuracy for both graph representations shows that our framework can approximate Tarjan‚Äôs algorithm [ 19]. In contrast to Task 2, even if the CDHG has more nodes than the constraint graph on average, the CDHGhas better performance than the constraint graph , which means the control and data flow in CDHG can help RHyGNN to learn graph structures better. For the same reason as task 2, the number of test data (1115) for this task is less than the data in the test set (1121). Task 4: Existence of argument bounds. For both graph representations, the accuracy is much higher than the ratio of the dominant label. Our framework can predict the answer for undecidable problems with high accuracy, which shows the potential for guiding CHC solvers. The CDHG has better performance than the constraint graph, which might be because predicting argument bounds relies on semantic information. The number of test data (1028) for this task is less than the data in the test set (1121) because the remaining 93 graphs do not have aùëüùë†ùëénode. Task 5: Clause occurrence in counterexamples. For Task (a) and (b), the overall accuracy for two graph representations is high. We manually analysed some predicted results by visual izing the (small) graphs9. We identify some simple patterns that are learned by RHyGNNs. For instance, the predicted likelihoods are always high for the ùëüùë†nodes connected to the false nodes. One promising result is that the model can predict all labels perfectly for some big graphs10that contain more than 290 clauses, which confirms that the RHyGNN is learning certain intricate patterns rather than simple patterns. In addition, the CDHG has better performance than the constraint graph , possibly because semantic information is more important for solving this task. 7. Related Work "
258,Cosine-Distance Virtual Adversarial Training for Semi-Supervised Speaker-Discriminative Acoustic Embeddings.txt,"In this paper, we propose a semi-supervised learning (SSL) technique for
training deep neural networks (DNNs) to generate speaker-discriminative
acoustic embeddings (speaker embeddings). Obtaining large amounts of speaker
recognition train-ing data can be difficult for desired target domains,
especially under privacy constraints. The proposed technique reduces
requirements for labelled data by leveraging unlabelled data. The technique is
a variant of virtual adversarial training (VAT) [1] in the form of a loss that
is defined as the robustness of the speaker embedding against input
perturbations, as measured by the cosine-distance. Thus, we term the technique
cosine-distance virtual adversarial training (CD-VAT). In comparison to many
existing SSL techniques, the unlabelled data does not have to come from the
same set of classes (here speakers) as the labelled data. The effectiveness of
CD-VAT is shown on the 2750+ hour VoxCeleb data set, where on a speaker
verification task it achieves a reduction in equal error rate (EER) of 11.1%
relative to a purely supervised baseline. This is 32.5% of the improvement that
would be achieved from supervised training if the speaker labels for the
unlabelled data were available.","Speakerdiscriminative acoustic embeddings (or just spea ker embeddings) derived through deep learning techniques have become the stateoftheart for learning speaker represen ta tions [ 2,3] to be used for tasks such as speaker recognition, speaker veriÔ¨Åcation or speaker diarisation [ 2,4,5,6]. Previ ously ivectors [ 7] based on factor analysis were widely used. The neural networks used to generate speaker embeddings are typically trained on a speaker classiÔ¨Åcation task, for w hich the input is the acoustic feature sequence of an utterance an d the output is the speaker label of that utterance [ 2,8]. By taking the output of a layer of this neural network (often the penult i mate layer) as an embedding, a Ô¨Åxed dimensional vector can be generated for any given input utterance. This vector is spea ker discriminative due to the training objective. It has been fo und that such speaker embeddings can be used to discriminate be tween speakers that are not present in the training data. The quality of these embeddings will improve with the amount of training data and with the number of speakers in the training data, assuming the data comes from the target domai n. However, the acquisition of enough suitable speaker classi Ô¨Åca tion data for the exact conditions one desires can be difÔ¨Åcul t. This is especially true as the regulations around identiÔ¨Åab le user data tighten1. Under these constraints it is useful to use audio 1See General Data Protection Regulation (GDPR) or Californi a Consumer Privacy Act (CCPA).data with associated speaker labels together with deident iÔ¨Åed (unlabelled) data to train speaker embedding generators. This paper proposes a method that enables semisupervised learning (SSL) of speaker embeddings. In comparison to many SSL methods in machine learning, the proposed method does not assume that the labelled and unlabelled data comes from the same classes (here speakers). Therefore, a small amount of labelled data from a small number of speakers can be com plemented by a larger amount of data from a large number of speakers. The proposed method is a newly derived sibling to virtual adversarial training (V AT) [ 1] which is an SSL method for classiÔ¨Åcation tasks. Vanilla V AT assumes the labelled a nd unlabelled data to come from the same set of classes. This pa per, however, attempts to utilise unlabelled data that come s from a completely different set of classes (here speakers). The proposed SSL technique, termed cosinedistance vir tual adversarial training (CDV AT), works by adding an addi  tional loss to the standard supervised training loss. The lo ss is deÔ¨Åned as the cosinedistance between a speaker embeddin g generated for an utterance and the embedding generated for t he same utterance, which was perturbed by an adversarial noise that maximally increases the cosinedistance to the origin al, un perturbed, embedding. The loss is computed for every data point in the labelled and unlabelled data sets, thus smoothi ng the embedding generator with respect to (w.r.t) the input fo r all data points lying on the data manifold. It can, therefore, be seen as a regularisation technique that is informed by the unlabe lled data, which constrains the neural network to learn embeddin gs that generalise well to unseen speakers. This paper is organised as follows. Section 2describes the CDV AT loss and how the adversarial noise is computed. In Sec. 3, the experimental setup is described including the data sets and evaluation metrics used. In Sec. 4the experimental results are presented and Sec. 5gives conclusions. 2. CosineDistance V AT In nature, the outputs of most systems are smooth w.r.t spa tial and temporal inputs [ 9]. Prior studies have conÔ¨Årmed that smoothing the output distribution of a classiÔ¨Åer ( i.e., encour aging the classiÔ¨Åer to output similar distributions) again st per turbations of the input can improve its generalisation perf or mance in semisupervised learning [ 1,10,11,12]. In the stan dard version of V AT [ 1] (the efÔ¨Åcacy of which has been ver iÔ¨Åed by [ 13,14]) an additive loss is introduced, which tries to smooth the categorical output distribution (measured by th e KL divergence) around every data point that lies on the data man  ifold. Here, V AT will be formulated on the level of the em bedding layer rather than the output (classiÔ¨Åcation) layer . The purpose of the proposed variant of V AT is to smooth the embed ding generator in terms of the cosinedistance, termed cosi ne distance virtual adversarial training (CDV AT). CDV AT sh ouldbe used together with an angular penalty loss (such as angu lar softmax [ 15]) in comparison to the standard crossentropy loss. These types of losses are very popular for both speaker veriÔ¨Åcation [ 16,17,18] as well as face veriÔ¨Åcation and identi Ô¨Åcation [ 15,19]. When angular penalty losses are used during speaker classiÔ¨Åcation training, the resulting embedding g enera tor produces embeddings that are angularly discriminative i.e. the cosinedistance between embeddings indicates if embed  dings come from the same speakers. 2.1. CDV AT loss CDV AT adds an additional loss R CDVAT (the CDV AT loss) to the supervised loss l(¬∑,¬∑)with the interpolation constant Œ±and is computed on both the labelled data set Dl(sizeNl) and the unlabelled data set Dul(sizeNul). The combined loss Lis then used to train the parameters Œ∏and in turn the embedding generator e(x,Œ∏). L(Dl,Dul,Œ∏) =l(Dl,Œ∏)+Œ±R CDVAT(Dl,Dul,Œ∏) (1) The CDV AT loss,R CDVAT, is the sum of local losses LCS (x,Œ∏) that are computed for each input feature sequence x‚ààDl,Dul. R CDVAT(Dl,Dul,Œ∏) =1 Nl+Nul/summationdisplay x‚ààDl,DulLCS(x,Œ∏)(2) The local cosine smoothness, LCS (x,Œ∏), is calculated in two steps. First, a perturbation ( rCDVAT) to the input sequence xis found. This perturbation is chosen to be an adversarial2pertur bation that maximally changes the embedding ( e(x+rCDVAT,Œ∏)) of the input feature sequence, x, as measured by the cosine distance ( cd[¬∑,¬∑]).«´is the maximum norm of rCDVAT. rCDVAT=argmax r;/bardblr/bardbl‚â§«´cd/bracketleftBig e/parenleftBig x,ÀÜŒ∏/parenrightBig ,e/parenleftBig x+r,ÀÜŒ∏/parenrightBig/bracketrightBig/vextendsingle/vextendsingle/vextendsingleÀÜŒ∏=Œ∏(3) cd[a,b] =1 2‚àíaTb 2/ba‚àá‚åàbla/ba‚àá‚åàbl/ba‚àá‚åàblb/ba‚àá‚åàbl(4) Second, LCS (x,Œ∏)is then the cosinedistance between the em bedding of the (maximally) perturbed input sequence and the embedding for the unperturbed input sequence. LCS(x,Œ∏) =cd/bracketleftBig e/parenleftBig x,ÀÜŒ∏/parenrightBig ,e(x+rCDVAT,Œ∏)/bracketrightBig/vextendsingle/vextendsingle/vextendsingleÀÜŒ∏=Œ∏(5) ÀÜŒ∏is the current setting for Œ∏at a particular instant during opti misation i.e. it is treated as a constant. The distinction between Œ∏andÀÜŒ∏is made because gradients of LCS (x,Œ∏)are only prop agated back through the embedding generated with the input perturbation i.e.e(x+rCDVAT,Œ∏)and note/parenleftBig x,ÀÜŒ∏/parenrightBig . LCS(x,Œ∏) indicates how ‚Äúsensitive‚Äù the embedding of input xis. 2.2. Approximation of rCDVAT Given the adversarial perturbation rCDVAT, the optimisation of the combined lossLis straightforward, because the gradients of LCS w.r.t Œ∏are well deÔ¨Åned3. In this section a method for ap proximately Ô¨Ånding rCDVATis described. For simplicity, let: cd[r,x,Œ∏] =cd/bracketleftBig e/parenleftBig x,ÀÜŒ∏/parenrightBig ,e/parenleftBig x+r,ÀÜŒ∏/parenrightBig/bracketrightBig/vextendsingle/vextendsingle/vextendsingleÀÜŒ∏=Œ∏(6) 2Note: no relationship to generative adversarial networks ( GANs). 3Eqn. ( 19) can be used.cd[r,x,Œ∏]has a minimum of zero at r=0. Therefore, the gradient w.r.t ris also zero at r=0. Therefore, the second order Taylor approximation of cd[r,x,Œ∏]is given by: cd[r,x,Œ∏]‚âà1 2rTH(x,Œ∏)r (7) whereH(x,Œ∏) =‚àá‚àárcd[r,x,Œ∏]|r=0. For simplicity, let H=H(x,Œ∏). Under this approximation rCDVAT emerges as the dominant eigenvector u(x,Œ∏)ofHwith magnitude «´(see con straint from Eqn. ( 3)). This shows that CDV AT in effect pe nalisesŒª1(r,x,Œ∏), the largest eigenvalue of H: cd[r,x,Œ∏]‚âà1 2«´2Œª1(r,x,Œ∏) (8) The dominant eigenvector, u, ofHcan be found using the stan dard power iteration method [ 20] combined with Ô¨Ånite differ ences. Let v0be a randomly sampled vector that is not orthog onal tou. Then the iterative calculation of vi+1‚ÜêHvi (9) causesvito converge to u. The Hessianvector product, Hvi, can be approximated based on Ô¨Ånite differences. ‚àárcd[r,x,Œ∏]|r=Œ∂vi‚âà‚àárcd[r,x,Œ∏]|r=0+Œ∂Hvi(10) Hvi‚âà1 Œ∂‚àárcd[r,x,Œ∏]|r=Œ∂vi (11) Therefore, to obtain rCDVATwe can use the iterative procedure: rCDVAT‚âà«´¬∑vK (12) vi+1=gi+1 /ba‚àá‚åàblgi+1/ba‚àá‚åàbl(13) gi+1=‚àárcd[r,x,Œ∏]|r=Œ∂vi (14) wherevKis the approximation of u(x,Œ∏)afterKpower itera tions and v0is sampled uniformly on the unitsphere. The value ofŒ∂should be as small as possible to get the best estimate of Hvi, but large enough not to cause numerical issues. Here, Œ∂is set to 0.005 in all our experiments4. gi+1=‚àárcd[r,x,Œ∏]|r=Œ∂viis derived below: gi+1=‚àÇcd[r,x,Œ∏] ‚àÇr/vextendsingle/vextendsingle/vextendsingle r=Œ∂vi(15) =‚àÇe/parenleftBig x+r,ÀÜŒ∏/parenrightBig ‚àÇr‚àÇcd[r,x,Œ∏] ‚àÇe/parenleftBig x+r,ÀÜŒ∏/parenrightBig/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle r=Œ∂vi(16) lete/parenleftBig x,ÀÜŒ∏/parenrightBig =eande/parenleftBig x+r,ÀÜŒ∏/parenrightBig =er ‚àÇcd[r,x,Œ∏] ‚àÇer=‚àí1 2/ba‚àá‚åàble/ba‚àá‚åàbl¬∑‚àÇ ‚àÇer/parenleftbiggeTer /ba‚àá‚åàbler/ba‚àá‚åàbl/parenrightbigg (17) =‚àí1 2/ba‚àá‚åàble/ba‚àá‚åàbl¬∑/parenleftBig1 /ba‚àá‚åàbler/ba‚àá‚åàbl¬∑‚àÇ ‚àÇer/parenleftBig eTer/parenrightBig +‚àÇ ‚àÇer/parenleftbigg1 /ba‚àá‚åàbler/ba‚àá‚åàbl/parenrightbigg ¬∑/parenleftBig eTer/parenrightBig/parenrightBig (18) =‚àí1 2/ba‚àá‚åàble/ba‚àá‚åàbl¬∑/parenleftbigg1 /ba‚àá‚åàbler/ba‚àá‚åàbl¬∑e‚àíer /ba‚àá‚åàbler/ba‚àá‚åàbl3¬∑/parenleftBig eTer/parenrightBig/parenrightbigg (19) The premultiplication with‚àÇe(x+r,ÀÜŒ∏) ‚àÇrin Eqn. ( 16) is equivalent to the standard backpropagation algorithm. 4For our experiments this is a norm of 10e6 per feature vector .To summarise, to obtain rCDVATthe required calculations are: ‚Ä¢ a forward pass to get e/parenleftBig x,ÀÜŒ∏/parenrightBig =efor Eqn. ( 19) ‚Ä¢ then for each power iteration: ‚Äìa forward pass to get e/parenleftBig x+vi,ÀÜŒ∏/parenrightBig =erfor Eqn. ( 19) ‚Äìa backward pass to get ‚àárcd[r,x,Œ∏]|r=Œ∂vifor Eqn. ( 14) Our experiments on multiple data sets suggest that K=1 is sufÔ¨Åcient, such that rCDVAT does not change signiÔ¨Åcantly for further iterations as measured by the dotproduct of consec utive vi. This single power iteration, however, increases cd[r,x,Œ∏] by up to a factor of 104in comparison to just using v0i.e. the robustness of the embedding to the simple normalised Gaussi an noisev0is far larger than to the adversarial noise rCDVAT. 2.3. Related Work "
305,Multiscale Global and Regional Feature Learning Using Co-Tuplet Loss for Offline Handwritten Signature Verification.txt,"Handwritten signature verification is a significant biometric verification
method widely acknowledged by legal and financial institutions. However, the
development of automatic signature verification systems poses challenges due to
inter-writer similarity, intra-writer variations, and the limited number of
signature samples. To address these challenges, we propose a multiscale global
and regional feature learning network (MGRNet) with the co-tuplet loss, a new
metric learning loss, for offline handwritten signature verification. MGRNet
jointly learns global and regional information from various spatial scales and
integrates it to generate discriminative features. Consequently, it can capture
overall signature stroke information while detecting detailed local differences
between genuine and skilled-forged signatures. To enhance the discriminative
capability of our network further, we propose the co-tuplet loss, which
simultaneously considers multiple positive and negative examples to learn
distance metrics. By dealing with inter-writer similarity and intra-writer
variations and focusing on informative examples, the co-tuplet loss addresses
the limitations of typical metric learning losses. Additionally, we develop
HanSig, a large-scale Chinese signature dataset, to facilitate the development
of robust systems for this script. The dataset is available at
https://github.com/ashleyfhh/HanSig. Experimental results on four benchmark
datasets in different languages demonstrate the promising performance of our
method in comparison to state-of-the-art approaches.","HANDWRITTEN signature verification aims to recognize individuals‚Äô signatures for identity verification. This bio metric verification approach is commonly accepted by govern ment agencies and financial institutions [1]. The handwritten signature verification systems can be classified into two cate gories based on the signature acquisition device used: online and offline signature verification. Online verification involves capturing dynamic characteristics of the signing process, such as velocity and pressure, using specialized devices [2]. In contrast, offline verification refers to the static verification This work was supported in part by National Science and Technology Council of Taiwan (Grants MOST1092410H002077MY3 and NSTC112 2410H002087MY3), and the Center for Research in Econometric Theory and Applications (Grant 112L900203) from the Featured Areas Research Center Program within the framework of the Higher Education Sprout Project by the Ministry of Education in Taiwan, and the National Taiwan University. The authors are extremely grateful for the work of ChiaChun Ku during the early stages of the research. (Corresponding author: HsinMin Lu.) FuHsien Huang is with the Department of Information Manage ment, National Taiwan University, Taipei 106216, Taiwan (email: d10725004@ntu.edu.tw) HsinMin Lu is with the Department of Information Management, and the Center for Research in Econometric Theory and Applications, National Taiwan University, Taipei 106216, Taiwan (email: luim@ntu.edu.tw)of scanned digital signatures. Since offline verification lacks dynamic characteristics, distinguishing between genuine and forged signatures is inherently more challenging. Moreover, discriminating between genuine signatures and skilled forg eries is difficult due to the high level of imitation similarity (interwriter similarity). Additionally, practical factors such as significant variations within an individual‚Äôs signatures (intra writer variations or intrapersonal variability) and the limited number of available signature samples further complicate the implementation of automatic verification systems [3]. Early offline signature verification systems primarily relied on manual feature extraction methods [4], [5]. To address the challenge of intrawriter variations, capturing regional information from local signature regions has been proposed to provide details for static verification [6]‚Äì[8]. However, the traditional process involves sequentially applying independent steps of manual regional feature extraction, region similarity estimation, and similarity verification. These methods overlook the interdependencies between feature extraction and similarity measurement, resulting in suboptimal performance. In recent years, some studies [3], [9]‚Äì[13] have proposed the adoption of convolutional neural network (CNN)based metric learning methods to integrate similarity measurement into automatic feature learning, overcoming the limitations of manual feature extraction. However, existing methods either learn from en tire signature images or local regions, failing to exploit the complementary nature of global and regional information and limiting the network‚Äôs ability to learn discriminative features. Additionally, most of these methods trained with typical metric learning losses, such as contrastive loss [14] and triplet loss [15], [16], tend to suffer from slow convergence and bad local minima due to the pair or triplet sampling problem [17], [18]. To overcome the limitations of previous studies, we propose a multiscale global and regional feature learning network (MGRNet) with a new metric learning loss called cotuplet loss for automatic offline signature verification. MGRNet aims to learn discriminative features from both global and regional contexts to effectively distinguish between genuine and skilledforged signatures. Learning global representations from the whole image aims to capture the overall information on signature strokes and configuration. However, given the high similarity between genuine signatures and skilled forg eries, it is also necessary to learn regional representations to explore local differences. As illustrated in Fig. 1, the proposed MGRNet starts from a base part and splits into two branches for global and regional feature learning. UnlikearXiv:2308.00428v1  [cs.CV]  1 Aug 20232 Fig. 1. Illustration of the proposed multiscale global and regional feature learning network (MGRNet) and cotuplet loss for signature verification. previous methods, MGRNet simultaneously considers global and regional information in handwritten signatures, dividing deep feature maps into regions to learn local differences. This enables the network to capture information from vari ous spatial scales and integrate it to generate discriminative features. Additionally, we address the thin and sparse nature of signature strokes in images by fusing multilevel features in respective branches, aggregating information learned at different levels. We also introduce an attention module that guides the network to focus on important information by considering interactions between global and regional features. The design of our proposed signature verification system is based on the writerindependent (WI) approach. In contrast to the writerdependent (WD) approach, WI has the advantages of leveraging information across signatures from different writers and requiring no system updates for new writers. For global and regional similarity measurement, we propose the cotuplet loss, a novel metric learning loss, to learn the distance metric for signature verification. The proposed co tuplet loss aims to transform input features into a feature space where genuine signatures from the same writer are close to each other while corresponding forgeries are far away from genuine ones. Unlike the typical triplet loss [15], [16], the proposed cotuplet loss simultaneously considers multiple genuine signature examples and multiple forged sig nature examples to learn similarity metrics. This effectively addresses issues related to intrawriter variability and inter writer similarity. Additionally, we emphasize the importance of batch construction and example selection to focus the training process on informative examples. It is worth noting that our signature verification system combines the feature learning and similarity measurement steps and can be optimized endtoend. For training and evaluation, we utilize four offline handwrit ten signature datasets in different languages. Three of these datasets are publicly available: CEDAR [19] with English signatures, BHSigBengali [20] with Bengali signatures, and BHSigHindi [20] with Hindi signatures. To address the lack of largescale public offline Chinese signature datasets, we create the HanSig dataset, consisting of 35,400 signature samples from 238 writers. Experimental results demonstratethe promising performance of our proposed MGRNet with co tuplet loss compared to stateoftheart methods. In summary, our contributions can be listed as follows: ‚Ä¢We propose an automatic multiscale feature learning method to generate discriminative features for offline handwritten signature verification. To our best knowl edge, this is the first study that adopts deep endtoend learning to automatically learn both global and regional information and integrate it for signature verification. ‚Ä¢We propose a new metric learning loss function that enhances discriminative capability and facilitates better convergence of our network. The proposed loss enables the training process to pay attention to informative ex amples and effectively tackles challenges associated with intrawriter signing variation and interwriter similarity, resulting in improved performance. ‚Ä¢We create the HanSig dataset, a new largescale offline Chinese signature dataset. Such datasets, which consider writers‚Äô signing variations, are crucial for developing robust signature verification systems for this script. Con sidering that few largescale Chinese signature datasets are publicly available, we plan to release HanSig to the public to foster future research in this area. II. R ELATED RESEARCH A. Offline handwritten signature verification Given the wide use of the offline handwritten signatures, many new approaches for offline signature verification have been developed in the last ten years [21]. Most early work [4], [5] relied on manual feature extraction methods to capture signature stroke variations from signature images. However, the feature extraction process of the traditional methods is easily disturbed by noise, and these methods have a limited capacity to extract complex features [22]. In recent times, there has been a growing interest in utilizing automatic feature extraction methods, particularly CNNs, to learn representations directly from signature images. These methods have effectively overcome the limitations of manual feature extraction. Several studies [23]‚Äì[25] employed CNNs as feature extractors, fol lowed by training separate classifiers for forgery detection. Wei et al. [26] introduced a fourstream CNN to focus on the sparse stroke information. For the improvement of offline signature verification, sev eral studies have concentrated on regional information and local details to capture static properties. To address intra writer variations, Pirlo and Impedovo [6] and Malik et al. [7] discovered that stable signature regions exhibit similar patterns among signatures from the same signer. Sharif et al. [8] combined global features with local features from 16 image parts. While these methods provided additional information for signature verification, the separation of manual feature extraction and similarity measurement did not guarantee opti mal performance. Liu et al. [3] proposed a regionbased deep learning network that solely used local regions as inputs to obtain signature features. In contrast to previous works, we propose an offline sig nature verification system that automatically learns feature3 representations from both the entire image and local regions. The combination of global and regional information has demonstrated promise in tasks such as person reidentification [27] and vehicle reidentification [28], which involve training visually similar interclass samples with intraclass differences. Unlike Liu et al. [3], our method combines global and regional information and divides deep feature maps into regions of dif ferent sizes. This enables us to aggregate features from multi ple scales and improve robustness against misalignment issues. Moreover, our system integrates similarity measurement with feature learning, thereby enhancing the entire training process compared to previous methods [6]‚Äì[8], [23]‚Äì[25]. B. Metric learningbased methods Recently, there has been an increased focus on employing metric learningbased methods to learn similarity and dis similarity for feature representations. The objective of these methods is to learn a good distance metric that transforms input features into a new feature space, where instances belonging to the same class are close together and those from different classes are far apart [29], [30]. Commonlyused metric learning functions for learning pairwise similarities include contrastive loss [14] and triplet loss [15], [16] among others. Deep learning methods that integrate metric learning into feature learning have found wide applications in various domains, including face recognition [31], [32] and person re identification [30], [33]. In the field of offline handwritten signature systems, metric learningbased methods have also shown promising results. Soleimani et al. [29] and Rantzsch et al. [9] were among the early researchers who introduced metric learning into signature verification. However, Soleimani et al. [29] did not provide a performance comparison with previous works, while Rantzsch et al. [9] evaluated the test data used in the training phase. Dey et al. [10], Xing et al. [11], and Liu et al. [3] employed the Siamese network [34] for metric learning. Some studies have proposed improvements to existing metric learning structures to enhance the robustness of offline signature verification. For instance, Maergner et al. [12] combined a triplet lossbased CNN with the graph edit distance approach. Wan and Zou [13] and Zhu et al. [35] respectively developed a dual triplet loss and a pointtoset (P2S) metric to improve discrimination between genuine signatures and skilled forgeries. The previous research on handwritten signature verification mainly employed typical metric learning losses or developed improved losses based on similar concepts. However, these losses often suffer from unstable and slow convergence due to inherent sampling problem [17], [18]. To address these limitations of typical metric learning losses, we propose a new metric learning loss. This loss shares similarities with previous tupletbased losses such as the multiclass Npair loss [17] and the tuplet margin loss [36]. However, we introduce a unique example selection and mining strategy specifically tailored for the signature verification task to facilitate better convergence. C. Main public offline signature datasets According to Hameed et al. [22], the GPDS [37], MCYT75 [38], and CEDAR [19] datasets are among the most commonlyadopted Western signature datasets. Another dataset, Sig Comp11 [39], contains Dutch and Chinese subsets. UTSig [40] is a frequently used Persian signature dataset. Additionally, the BHSig260 dataset [20] offers two subsets comprising signa tures in Bengali and Hindi languages. However, when it comes to offline Chinese handwritten signatures, there is a scarcity of publicly available datasets. Currently, the SigComp2011 [39] and ChiSig [41] datasets are the only existing public datasets for offline Chinese signatures. SigComp2011 has only 1,177 signature samples. In comparison, ChiSig is a new dataset that contains a more substantial number of samples, with a total of 10,242 signatures. While some studies have created offline Chinese signature datasets for their own research purposes [3], [13], [26], these datasets have not been publicly released. Considering that the characteristics of handwritten signa tures differ across languages and scripts due to their unique writing styles [26], it is impractical to train a Chinese sig nature verification system using Western datasets. Moreover, the development of a realistic signature verification system requires the consideration of signature variability to avoid overfitting [21]. Therefore, we are motivated to create a new offline Chinese signature dataset that contains more samples and incorporates signature variability for each writer. III. P ROPOSED METHOD In this section, we introduce the multiscale global and regional feature learning network (MGRNet), the handwritten signature verification method proposed in this study. We begin by providing an overview of the overall architecture of MGRNet. Subsequently, we provide a detailed explanation of the proposed network structure. Additionally, we introduce a novel metric learning loss called cotuplet loss, which aims to improve the discriminative capability of the learned features for signature verification. Finally, we elaborate on the decision making process in our signature verification system. A. Overall architecture Fig. 2 illustrates the overall architecture of MGRNet, which comprises three main components: the base part, the global branch, and the regional branch. To integrate the discriminative signature information of different spatial scales, we propose to automatically learn robust feature representations from both the global and dualorientation regional branches, which sets it apart from existing methods that rely on manual region feature extraction [6]‚Äì[8] and focus solely on local regions [3]. As depicted in Fig. 2, the global and regional branches share a common front base part that consists of several convolutional layers. By jointly optimizing the global and regional branches, we can enhance the feature learning capability of the base part during the training process. We modify the structure of SigNetF [23] as the CNN backbone to build our branches and modules. The layers of our CNN backbone are summarized in the supplemental material. We add rectified linear unit (ReLU) activation function and batch normalization (BN) [42] after each convolutional layer to address issues such as vanishing gradients and overfitting dur ing training. Consider a set of genuine signature images from4 Fig. 2. Overall architecture of MGRNet, which comprises three main components: the base part, the global branch, and the regional branch. We also introduce feature fusion and the globalregional channel attention (GRCA) to facilitate robust global and regional feature learning. Each set of the corresponding features is trained with individual cotuplet losses. a specific writer and their corresponding forged counterparts. We refer to this set as a ‚Äúsignature tuplet‚Äù in the subsequent discussion. Each input image, denoted as x, belonging to this signature tuplet passes through the base part to sequentially generate the output feature maps, F1,F2,F3, and F4. After the Conv4 layer, the network splits into the global and regional branches and learns to generate feature maps F51G andF51Rin the respective branches. It is worth noting that our model incorporates multilevel feature fusion and a global regional channel attention (GRCA) module, which facilitate effective global and regional feature learning, specifically for the signature strokes. Finally, by training each global and regional branch with an individual loss function, we obtain the discriminative global embedding, fg, and the regional embeddings, fri, fori= 1, . . . , 6. B. Multilevel feature fusion We observed that the signature strokes in the images are thin and sparse compared with general object images. In a typical CNN structure, the lowlevel features generated from the early layers contain more detailed information. However, information loss of stroke details is inevitable after several convolution and downsampling operators. In order to retain the detailed information of signature strokes for global and regional features, we propose a multilevel feature fusion mech anism that combines lowlevel features with highlevel features and then passes the aggregated information to subsequent layers. Here, the feature maps F2andF3in the base part and the feature maps F51Gin the global branch are fused to obtain the feature maps F52G. Likewise, F2andF3in the base part andF51Rin the regional branch are fused to generate F52R. We can express the fusion operations as follows: F52G=Œµ3√ó3(F2)‚ó¶Œµ3√ó3(F3)‚ó¶F51G, (1) F52R=Œµ3√ó3(F2)‚ó¶Œµ3√ó3(F3)‚ó¶F51R, (2) where Œµ3√ó3is the convolution operation with a kernel size of3√ó3and a stride of 2 to transfer F2‚ààRC√óH‚Ä≤√óW‚Ä≤ andF3‚ààRC‚Ä≤√óH‚Ä≤√óW‚Ä≤to the same shape as F51Gand F51R‚ààRC√óH√óW. The operator ‚ó¶denotes the elementwise multiplication.In contrast to the fusion of only the base part features before splitting into global and regional branches, we propose a different fusion mechanism that utilizes both the global and regional features for their respective branches. Thus, the detailed information of signature strokes can complement to the highlevel features in each branch. Instead of the commonlyused concatenation, we employ a multiplicative operation as the fusion strategy. Multiplication has advantages over concatenation as it allows the gradients of each layer to be correlated with the gradients of the other layers during gradient computation [43]. By using multiplication, features at different levels can depend on and interact with each other during the training process. We report ablation studies in the supplemental material to show that multiplication yields better performance compared to concatenation. C. Globalregional channel attention In order to extract essential global and regional feature representations, we propose the GRCA module to guide our model in focusing on specific signature information. GRCA simultaneously learns the attention weights for global and regional features by considering their interactions and rela tive importance. Drawing inspiration from previous attention mechanisms [43], [44], we design GRCA tailored for our two branch structure to facilitate the signature verification task. As shown in Fig. 3, we perform global average pooling (GAP) on the feature maps F52G‚ààRC√óH√óWin the global branch and F52R‚ààRC√óH√óWin the regional branch to com press the spatial information of each channel into one channel descriptor. We obtain two channel descriptors D1G‚ààRC√ó1√ó1 andD1R‚ààRC√ó1√ó1: D1Gc=œï(Zc g) =1 HWHX i=1WX j=1Zc g(i, j), (3) D1Rc=œï(Zc r) =1 HWHX i=1WX j=1Zc r(i, j), (4) where œïis the GAP operation, Zc gis the cth channel of F52G, andZc ris the cth channel of F52R, for c= 1, . . . , C . For attention map learning, we first use a convolutional layer with a kernel size of 1√ó1followed by a ReLU activation function5 Fig. 3. Detailed structure of the GRCA module. The simultaneous generation of channelwise attention allows our model to adaptively learn to focus on specific signature information based on the relative importance of global and regional features. to convert the channel descriptors D1GintoD2G‚ààRV√ó1√ó1 andD1RintoD2R‚ààRV√ó1√ó1. We set V < C , such that the dimension reduction operation can reduce computational and parameter overhead. Subsequently, we combine D2Gand D2Rto obtain the fused descriptors DF‚ààRV√ó1√ó1using the multiplicative operation. The fusion of D2GandD2R enables the simultaneous generation of channelwise attention for both global and regional features. This allows our model to adaptively learn to focus on specific patterns based on the relative importance of global and regional features. Next, we perform a dimension recovery operation for re gional and global branches using convolution with a kernel size of 1√ó1, and we obtain the normalized global and regional attention maps MgandMr‚ààRC√ó1√ó1using the sigmoid function. The entire process of attention map learning can be expressed as follows: Mg=œÉ(Œµ1√ó1(Œ≥(Œµ1√ó1(D1G))‚ó¶Œ≥(Œµ1√ó1(D1R)))),(5) Mr=œÉ(Œµ1√ó1(Œ≥(Œµ1√ó1(D1G))‚ó¶Œ≥(Œµ1√ó1(D1R)))),(6) where Œµ1√ó1is the convolution operation with a kernel size of 1√ó1,Œ≥represents the ReLU function, and œÉrepresents the sigmoid function. We finally multiply each channel of F52G by each weight value of Mgto obtain F52G‚Ä≤‚ààRC√óH√óW and perform the same operation on F52RandMrto obtain F52R‚Ä≤‚ààRC√óH√óW. D. Multiscale feature learning Since genuine and skilledforged signatures often have only slight differences, previous methods using only global feature learning are insufficient to generate discriminative features for offline signature verification. We propose automatic multiscale feature learning by using both global and regional branches to address the limitations of learning from a single global branch. Here, ‚Äúmultiscale‚Äù refers to multiple scales (i.e., sizes) of global and dualorientation regional feature maps. By learning complementary feature representations from various spatial scales, our method can effectively handle the challenges posed by high interwriter similarity and intrawriter variations. 1) Global feature learning: To capture signature stroke information from the entire image, we first conduct the GAP operation over the feature maps F52G‚Ä≤‚ààRC√óH√óWin the global branch, as shown in Fig. 2. Subsequently, we use a fully connected (FC) layer with the output dimension of 1,024 to generate the global embedding fgfor a signature image.To obtain the final feature representations, instead of using multiple FC layers in the structure proposed in [23] that we use as the CNN backbone, we adopt GAP followed by a single FC layer. This change reduces the model parameters and addresses overfitting issues [45], resulting in improved performance in our experimental evaluations. Additionally, we apply L2Normalization before the output layer to mitigate the impact of scale variability in the data, which enhances training stability and boosts performance. The process of global feature learning can be formulated as follows: œï(Uc g) =1 HWHX i=1WX j=1Uc g(i, j), (7) fg=Œ∑([œï(U1 g), œï(U2 g), ..., œï (UC g)]), (8) where œïis the GAP operation, Œ∑is the FC layer, and Uc gis thecth channel of F52G‚Ä≤, forc= 1, . . . , C . 2) Regional feature learning: In order to generate discrim inative features for signature verification, we propose dual orientation regional feature learning to complement global fea ture learning. Rather than using a fixedsized sliding window along one direction of an input image for region segmentation, we propose to divide the deep feature maps into regions with different scales along both horizontal and vertical orientations. This dualorientation regional feature learning enables the regional branch to capture more localized differences between genuine and skilledforged signatures. Our method does not require input segmentation and does not increase the number of model inputs, resulting in improved efficiency, particularly for larger datasets. Inspired by Pirlo and Impedovo [6], we divide the deep feature maps in the regional branch into three equalsized vertical regions and three equalsized horizontal regions. Pirlo and Impedovo [6] conducted segmentation of the input images and analyzed signature stability (i.e., how consistent a writer‚Äôs signatures are) for each region using cosine similarity, reveal ing distinct variability and similarity information in different signature regions. Building upon their insights, we incorporate vertical and horizontal divisions to capture regional infor mation related to signature variations and similarities. We first divide the feature maps F52R‚Ä≤‚ààRC√óH√óWinto three overlapping vertical regions Fr1,Fr2, and Fr3‚ààRC√óH√óW‚Ä≤‚Ä≤ (W‚Ä≤‚Ä≤< W )from left to right, as shown in the regional branch of Fig. 2. We also divide the feature maps F52R‚Ä≤ into three overlapping horizontal regions Fr4,Fr5, and Fr6‚àà RC√óH‚Ä≤‚Ä≤√óW(H‚Ä≤‚Ä≤< H )from top to bottom, as shown in Fig. 2. To address the potential misalignment of corresponding regions, we make adjacent regions overlap each other, despite the fact that signature images are generally wellaligned and less prone to this issue compared to general object images. The process of region division can be expressed as follows: Frm=œàH(F52R‚Ä≤, m), m‚àà {1,2,3}, (9) Frn=œàV(F52R‚Ä≤, n), n‚àà {4,5,6}, (10) where œàHdenotes the feature map division operation in the horizontal orientation, and œàVis the same operation in the vertical orientation. Specifically, we empirically set W‚Ä≤‚Ä≤= 136 and the overlap between Frmto be 7 pixels in width, and we empirically set H‚Ä≤‚Ä≤= 8 and set the overlap between Frnto be 4 pixels in height. Finally, we obtain six regions with varying scales and conduct GAP operations over each of them, followed by an FC layer to generate 1024dimensional regional embeddings, frm,m‚àà {1,2,3}, and frn,n‚àà {4,5,6}, for each signature image. The process of generating regional embeddings can be formulated as follows: œï(Uc rm) =1 HWHX i=113X j=1Uc rm(i, j), (11) frm=Œ∑([œï(U1 rm), œï(U2 rm), ..., œï (UC rm)]), (12) œï(Uc rn) =1 HW8X i=1WX j=1Uc rn(i, j), (13) frn=Œ∑([œï(U1 rn), œï(U2 rn), ..., œï (UC rn)]), (14) where œïis the GAP operation, Œ∑is the FC layer, Uc rmis the cth channel of Frm, andUc rnis the cth channel of Frn, for c= 1, . . . , C . Similar to the global embedding, we apply L2 Normalization before the output layer for generating regional embeddings. We demonstrate the performance improvement achieved through global and regional feature learning and visualize the differences in their effects in Section IV . E. Cotuplet loss 1) Limitations of typical loss functions: Previous automatic signature verification methods [10], [12], [13], [23]‚Äì[25], [46], [47] have employed the classification loss and the typical metric learning loss to learn similarity measurement. How ever, the methods trained with the classification loss, such as the categorical crossentropy loss, can only differentiate between genuine signatures of different writers, limiting their application to random forgery detection or preliminary feature extraction for a WD classifier. In contrast, typical metric learning loss functions such as contrastive loss [14] and triplet loss [15], [16] have been widely integrated into deep learning methods. However, training with a single randomly selected negative example in each update can result in unstable and slow convergence [17], [18]. To address this problem, Sohn [17] extended the concept of a triplet {xa, xp, xn}to a tuplet that simultaneously includes more than one negative example: {xa, xp, xn1, xn2, . . . , x nk}, where xa,xp, and xnrefer to the anchor, positive, and negative example, respectively, and kis the number of the negative examples in a batch. The tuplet based loss functions [17], [36] consider multiple negative examples from different classes and aim to increase the inter class distance by pushing them apart in each update. In contrast to general object recognition tasks focusing on distinguishing between different classes, handwritten sig nature verification requires discriminating between positive examples (i.e., genuine signatures) and their corresponding negative examples (i.e., skilled forgeries) within each writer. The challenge lies in the presence of potentially high intra writer variability in genuine signatures and high interwriter similarity between genuine and forged signatures. This impliesthat the distances between most genuinegenuine pairs may be large, while the distances between genuineforged pairs tend to be small. Using only one positive example in each update is insufficient for considering the distances of multiple positive examples, thus failing to address the intrawriter distance variation effectively. Similarly, relying on a single negative example in each update does not adequately account for the interwriter similarity between a positive example and the remaining negative examples. To address the challenges in handwritten signature verifica tion, we propose a tupletbased metric learning loss function called the cotuplet loss. The cotuplet loss combines the prop erty of tupletbased loss functions, allowing for the inclusion of multiple negative examples to learn an appropriate distance metric between genuine and forged signatures. Additionally, it employs multiple positive examples, enabling the model to learn the relationship between genuine signatures within each writer, which was previously missing in tupletbased loss functions [17], [36]. 2) Proposed loss function: We define a tuplet as {xa, xp1, xp2, . . . , x pk, xn1, xn2, . . . , x nk}, where xa,xp, and xnrefer to the anchor, positive, and negative examples, respec tively. The integer kis the number of positive and negative examples in a minibatch. In this study, the anchor and positive examples are genuine signatures signed by a writer, while the negative examples are corresponding skilled forgeries. We aim to shorten the intrawriter distance and enlarge the inter writer distance in the embedding space. To achieve this, we jointly consider the distances of multiple positive and negative examples from the same anchor in the loss function. The formulation of the cotuplet loss is as follows: Lct= log[1 +X i‚ààS(P)exp(d+ i‚àíd‚àí h) +X j‚ààS(N)exp(d+ h‚àíd‚àí j)], (15) where S(P)andS(N)are the sets of positive and negative example indices for which the positive and negative examples satisfy our mining strategy described in the next subsection, d indicates the squared Euclidean distance used as the distance metric; and d+ i,d‚àí j,d+ h, and d‚àí hare defined as follows: d+ i=‚à•f(xa)‚àíf(xpi)‚à•2 2, (16) d‚àí j=‚à•f(xa)‚àíf(xnj)‚à•2 2, (17) d+ h= max ‚Ñì=1...k‚à•f(xa)‚àíf(xp‚Ñì)‚à•2 2, (18) d‚àí h= min ‚Ñì=1...k‚à•f(xa)‚àíf(xn‚Ñì)‚à•2 2, (19) where f(¬∑)represents the feature embedding of an input example. Among the positive examples in a minibatch, d+ h is the distance between the anchor and the hardest positive example that is the furthest from the anchor. Similarly, among the negative examples in a minibatch, d‚àí his the distance between the anchor and the hardest negative example that is the closest to the anchor. The proposed loss comprises two parts, pulling and pushing parts. We design the pulling part to decrease the intrawriter distance by pulling the selected positive examples closer to the anchor using d‚àí has the reference distance. In addition, we use the pushing part to increase the interwriter distance7 Fig. 4. Example of the distance learning process of the common triplet loss, hardest triplet loss, and cotuplet loss. by pushing the selected negative examples farther from the anchor using d+ has the reference distance. Instead of pairwise comparisons between positive and negative examples, we impose penalties on the distances that are larger than the hardest negative example and shorter than the hardest positive example. This reduces the computational complexity from quadratic to linear. Given that the proposed tupletbased loss relies on the coexistence of multiple positive and negative examples to learn distance metrics, we refer to it as the ‚Äúco tuplet loss.‚Äù Fig. 4 provides a visual representation of the differences in the distance learning process between the triplet loss, the hardest triplet loss, and the cotuplet loss. The triplet loss only partially utilizes the distance information of batch examples, as many easy triplets that already satisfy the triplet constraint do not contribute to the training process. Similarly, the hardest triplet loss, which focuses on the hardest positive and negative examples, neglects optimizing the distances from the anchor to the remaining positive and negative examples. In contrast, the proposed cotuplet loss simultaneously considers multiple positive and negative examples in a minibatch for distance optimization. This allows the signature verification model to effectively learn to pull genuine signatures belonging to the same writer close together, while pushing forgeries far away from them. 3) Batch construction and constraint mining strategy: Previous studies have highlighted the significance of batch construction and example selection in loss functions [48]. To construct a training minibatch, we first randomly select w genuine signatures without replacement as anchor examples. For each anchor, kgenuine signatures are randomly sampled (excluding the anchor itself) as positive examples from the same writer. Similarly, knegative examples are randomly sam pled from the corresponding forgeries. Together, the anchor, positive examples, and negative examples form a signature tuplet. We repeat this process to generate wtuplets for the training minibatch. To select training examples, we propose a constraint mining strategy that focuses the learning process on informative signature examples rather than trivial ones. To the best of our knowledge, this mining strategy is not considered in existing tupletbased losses [17], [36]. We identify that very easy positive and negative examples still contribute to the loss values in Eq. (15), even though they provide uninformativeand redundant information for embedding learning. Hence, we employ the constraint mining strategy to select informative positive and negative examples for the pulling and pushing parts in Eq. (15), respectively. The selected positive and negative examples must satisfy the following constraints: d+ i‚â•d‚àí h‚àíŒ¥, (20) d‚àí j‚â§d+ h+Œ¥, (21) where Œ¥ > 0is a constraint margin. Here an appropriate selection of Œ¥ensures that the optimization process does not concentrate on useless information and facilitates our model in learning the accurate mapping of intrawriter and interwriter distances. 4) Gradient computation: We can obtain the gradient of the proposed cotuplet loss Lctwith respect to the model parameters Œ∏. The gradient computation is provided in the supplemental material along with an observation from the gradient. In comparison to typical metric learning losses, our cotuplet loss offers the advantage of emphasizing in formative examples over uninformative ones by assigning unequal weights to examples based on the distance difference. Since skilledforged signatures often closely resemble genuine signatures for each writer, this weighting scheme promotes the learning of more discriminative features for handwritten signature verification. The effectiveness of our metric learning loss in signature verification is demonstrated in Section IV . F . Signature verification decision In our approach, we train both the global features and the regional features derived from a signature tuplet in an endto end manner. We use individual cotuplet losses to train each set of the corresponding features instead of a single loss for the concatenation of global and regional features. This training strategy enables the model to learn specific information from the global branch and each part of the regional branch. In the supplemental material, we present a comparison between the performance of training with individual losses and training with a single loss. For joint global and regional feature learning, we define the overall objective function as follows: Lct,T=Lct,g+Œª6X i=1Lct,ri, (22) where Œªis a hyperparameter used to control the weight of the regional losses. In the verification stage, namely the test stage, we integrate various spatial information by concatenating the global and regional embeddings into the final embedding for each input image. To make the verification decision, we use a distance threshold dthrto decide whether a given signature pair {xi, xj}is positive or negative. A positive verification decision indicates that the questioned signature xjis accepted as genuine with respect to the reference signature xi. Conversely, xjwith a negative decision is regarded as forged with respect toxi. We define the final signature verification decision as follows: Decision =( positive ,ifd(xi, xj)‚â§dthr negative ,ifd(xi, xj)> dthr,(23)8 where d(xi, xj)is the squared Euclidean distance between the final embeddings of xiandxj. IV. E XPERIMENTS In this section, we first describe the benchmark datasets. Following that, we elaborate on the data preprocessing, im plementation particulars, and the evaluation metrics used for signature verification. Lastly, we present the experimental re sults and compare them with various stateoftheart methods. A. Datasets 1) CEDAR: The CEDAR dataset [19] consists of English signatures from 55 different writers. Each writer contributed 24 genuine signatures for a specific name and had 24 skilled forgeries generated by forgers. Following previous studies [3], [10], [11], [49], [50], we randomly divide the writers into a training set that includes signatures from 50 writers, and a test set that contains signatures from five writers. We further randomly reserve five writers‚Äô signatures from the training set for validation. For each writer in the test set, we use one genuine signature as the reference signature and another genuine signature as the questioned signature to form 276 (24√ó23/2)positive pairs. In addition, we form negative pairs by using one genuine signature as the reference and one forged signature as the questioned signature. To balance the positive and negative pairs, we follow previous studies and randomly select 276 pairs from the negative pairs. The final test data consists of 2,760 signature pairs. 2) BHSigBengali: The BHSigBengali dataset [20] com prises Bengali signatures from 100 different writers. Each writer contributed 24 genuine signatures for a specific name, along with 30 skilledforged signatures. Following the data splitting scheme in [10], we randomly select signatures from 50 writers to form the training set, while the remaining writers‚Äô signatures are used to form the test set. We further reserve five writers‚Äô signatures from the training set for validation. Similarly, for each writer in the test set, we form 276 positive pairs and 276 negative pairs. The final test data comprises 27,600 signature pairs. 3) BHSigHindi: The BHSigHindi dataset [20] contains Hindi signatures from 160 writers. Each writer contributed 24 genuine signatures for a specific name, accompanied by 30 skilledforged signatures. Consistent with previous studies [10], [51], we randomly select signatures from 100 writers to form the training set, while the remaining writers‚Äô signatures are used for the test set. Within the training set, we randomly select signatures from five writers to create the validation set. For each writer in the test set, we follow a similar procedure to generate 276 positive pairs and 276 negative pairs. The final test data comprises 33,120 signature pairs. 4) HanSig: Due to the scarcity of largescale public offline Chinese signature datasets, we construct the HanSig signature dataset to be made publicly available and to facilitate the de velopment of signature verification systems. We generated 885 candidate names based on the frequency distributions of the name distribution in the real world. By generating candidate names, we took precautions to avoid potential legal concerns (a) Examples of collected signatures in three styles (b) Examples of collected genuine and forged signatures Fig. 5. Examples of signature images in HanSig. The left, middle, and right images of (a) are the collected signatures written in neat, normal, and stylish styles, respectively. The first row of (b) shows the collected genuine signatures, and the second row of (b) shows the corresponding forged signatures. related to personal information. We collected signatures of these candidate names from 238 writers. To introduce more signing variations, each name was signed 20 times in three different styles: neat, normal, and stylish. We provide the details of our dataset collection process in the supplemental material. Overall, HanSig consists of a total of 17,700 genuine signatures and an equal number of skilled forgeries. Fig. 5 provides examples of the collected signatures in different styles and the genuine and forged signatures. The HanSig dataset has several valuable characteristics. Firstly, the generation of names for signatures addresses concerns regarding personal information and privacy while still preserving the distributional characteristics of real names. Secondly, HanSig incorporates the realworld property of intrawriter variability by including multiple signature styles. Moreover, HanSig surpasses existing public Chinese signature datasets in terms of the number of signature samples, provid ing robust training for signature verification systems. Lastly, HanSig is advantageous for both random and skilled forgery verification tasks. We randomly split HanSig into a training set and a test set. The training set comprises 795 names signed by 213 writers, while the test set includes 90 names signed by 25 writers. From the training set, 20 writers‚Äô signatures (78 names) are randomly selected for validation. For each name in the test set, we follow a similar procedure used in the CEDAR and BHSig to form 190 positive pairs and 190 negative pairs. The final test data of HanSig consists of 34,200 signature pairs. B. Data preprocessing To mitigate the influence of background and position varia tions in the signature images, we perform several data prepro cessing steps without deforming the structure of the signatures. Firstly, we convert the signature images to grayscale. Next, we apply Otsu‚Äôs algorithm [52] to transform all background pixel values into 255 while keeping the signature pixels unchanged. This step removes noise in image backgrounds and is critical to datasets (e.g., CEDAR) that have distinct backgrounds in genuine and forged signature images. We also centercrop the signature images and remove the excess blanks around the signatures to eliminate potential misalignment issues caused by signature position variations. Finally, the images are resized to the input size of the network using bilinear interpolation,9 and the pixel values of the signature images are normalized to a range between 0 and 1. The examples of images before and after these preprocessing steps are displayed in the sup plemental material. C. Implementation details and evaluation metrics In our model, we experimentally set C= 256 ,H= 16 , W= 25 , and V= 32 . We construct a training minibatch using w= 18 for CEDAR, HanSig, and BHSigBengali and w= 20 for BHSigHindi. Furthermore, we set k= 5 for all datasets. The constraint margin Œ¥for the constraint mining strategy is empirically set as 0.2 for CEDAR and 0.3 for Han Sig, BHSigBengali, and BHSigHindi. In our experiments, we empirically set Œª= 1 in the objective function as the weight of the regional losses. We apply Adam optimizer [53] with an initial learning rate of 0.001, and the learning rate decays by a factor of 0.5 every 15 epochs. We train our models for a maximum of 80 epochs and use the validation set for early stopping. All our experiments are implemented using the PyTorch framework. We report the performance using the common evaluation metrics of signature verification: False Reject Rate (FRR), False Accept Rate (FAR), Equal Error Rate (EER), and Area Under the Curve (AUC). FRR refers to the proportion of genuine signatures mistakenly rejected as forgeries. FAR is the proportion of forgeries mistakenly accepted as genuine signa tures. The values of FRR and FAR vary with the adjustment of the decision threshold dthr. We report FRR and FAR under dthrthat maximizes the accuracy. EER is the error rate when FRR is equal to FAR. The calculations of EER and AUC are independent of the selection of dthr. D. Method evaluation and analysis To assess the performance of the proposed MGRNet com bined with the cotuplet loss, we conduct experiments compar ing it to a simple baseline model and alternative combinations of losses and models. The evaluation aims to determine the effectiveness of the cotuplet loss compared to the triplet loss [15], [16] and to understand the relative performance of the MGRNet. As a simple baseline, we adopt a VGG16 [54] pretrained on the ImageNet dataset [55] as the feature extractor. Additionally, we train the MGRNet with the triplet loss and evaluate its performance for the comparison with the cotuplet loss. Furthermore, alternative combinations include training the VGG16 with either the cotuplet loss or the triplet loss under the same experimental settings. Table I reports the experimental results. The MGRNet trained with the cotuplet loss achieves the best performance across all datasets. Compared to the simple baseline, it im proves the EER by up to 19.57 percentage points and improves the AUC by up to 15.44 percentage points. Replacing the cotuplet loss with the triplet loss for training the MGRNet results in worsened EER and AUC. Similarly, training the VGG16 with the cotuplet loss yields better performance in terms of EER and AUC compared to training it with the triplet loss. Furthermore, comparing the MGRNet to the VGG16 trained with the same loss function, the MGRNet consistentlyoutperforms the VGG16 counterparts. When trained with the cotuplet loss and the triplet loss, the MGRNet exhibits EER improvements ranging from 5.33 to 12.94 and from 5.15 to 11.01 percentage points over the VGG16, respectively. Overall, the results validate the effectiveness of the MGRNet coupled with the cotuplet loss across different datasets. E. Ablation studies In this subsection, we conduct ablation studies to evaluate the validity of selected operations and the importance of each module/branch in our network. Considering the length limita tion, we present the results of validity of selected operations in the supplemental material. To assess the contribution of each module/branch in our proposed MGRNet, we remove specific components from the original framework. Specifically, we remove multilevel feature fusion, GRCA, global branch, and regional branch, and evaluate the impacts on signature verification performance. The results of these ablation studies are reported in Table II. The findings indicate that removing multilevel feature fusion results in performance degradation across all datasets, espe cially with a reduction of 3.23 percentage points for CEDAR. This suggests that our proposed fusion mechanism effec tively mitigates information loss caused by layer transmission and retains detailed signature stroke information for both global and regional branches. Additionally, the GRCA module demonstrates a performance improvement ranging from 0.28 to 1.27 percentage points. This highlights the effectiveness of our attention mechanism in focusing on important channel information, enabling the model to learn salient features. We further examine the importance of the global and regional branches in our proposed approach. The results in Table II indicate that both the global and regional branches contribute to enhancing signature verification performance. The global branch provides more performance gains for CEDAR, while the regional branch makes a greater contri bution to the other datasets. These results suggest that both global and regional feature learning are crucial for exploiting their respective advantages. The global branch can capture the overall signature stroke information without being affected by misalignment issues. In contrast, the regional branch focuses on learning the detailed differences, capturing additional in formation and further boosting performance. F . Visualization analysis 1) Comparison between extracted features: We compare the 2D projections of extracted features from the simple baseline (pretrained VGG16), MGRNet with triplet loss, and MGRNet with cotuplet loss using the tdistributed stochastic neighbor embedding (tSNE) algorithm [56]. To ensure clarity, we use signatures from a randomly selected subset of 50 names out of the 90 names in the HanSig test set. Fig. 6 (a) displays the feature space projection of the simple baseline. It shows that genuine and corresponding forged signatures of each name are clustered together. For instance, the red solid circle highlights a cluster from a single name where genuine signatures are visually inseparable from forged signatures10 TABLE I PERFORMANCE COMPARISON BETWEEN DIFFERENT COMBINATIONS OF MODELS AND LOSSES (EVALUATION METRICS IN %) Dataset Method FRR FAR EER AUC CEDARSimple Baseline (Pretrained VGG16) 16.67 27.75 23.08 84.82 VGG16 with triplet loss 17.32 18.48 17.93 87.62 VGG16 with cotuplet loss 17.90 15.00 16.45 90.15 MGRNet with triplet loss 7.75 5.94 6.92 98.10 MGRNet with cotuplet loss 3.55 3.33 3.51 99.47 BHSigBengaliSimple Baseline (Pretrained VGG16) 11.71 22.23 17.04 91.07 VGG16 with triplet loss 12.70 12.63 12.69 94.80 VGG16 with cotuplet loss 14.44 9.08 11.96 95.75 MGRNet with triplet loss 9.41 5.21 7.54 98.03 MGRNet with cotuplet loss 6.20 5.93 6.12 98.64 BHSigHindiSimple Baseline (Pretrained VGG16) 17.28 17.71 17.52 90.64 VGG16 with triplet loss 14.05 15.63 14.94 92.74 VGG16 with cotuplet loss 11.91 15.94 14.04 93.86 MGRNet with triplet loss 9.16 8.58 8.9 96.94 MGRNet with cotuplet loss 6.56 6.76 6.68 98.28 HanSigSimple Baseline (Pretrained VGG16) 32.43 19.66 26.31 80.94 VGG16 with triplet loss 15.60 22.40 19.07 89.47 VGG16 with cotuplet loss 14.20 16.21 15.26 92.60 MGRNet with triplet loss 9.99 10.82 10.44 95.92 MGRNet with cotuplet loss 7.69 11.85 9.93 96.38 TABLE II ABLATION STUDY TO EVALUATE THE SIGNATURE VERIFICATION PERFORMANCE WITHOUT EACH MODULE /BRANCH IN THE PROPOSED FRAMEWORK (EER IN%). V ALUES IN THE PARENTHESES INDICATE THE PERFORMANCE DEGRADATION (EER INCREASE IN %) COMPARED WITH USING EACH MODULE /BRANCH without Module/Branch CEDARBHSig BHSigHanSigBengali Hindi Multilevel feature fusion 6.74 (3.23)7.29 (1.17)9.84 (3.16)11.02 (1.09) GRCA 4.78 (1.27)6.59 (0.47)6.96 (0.28)10.48 (0.55) Global branch 6.70 (3.19)7.34 (1.22)7.19 (0.51)10.70 (0.77) Regional branch 5.14 (1.63)8.26 (2.14)10.85 (4.17)10.76 (0.83) represented by ‚Äúo‚Äù and ‚Äúx‚Äù marks, respectively. A similar pattern is observed for another name within the red dashed circle. This suggests that the simple baseline can differentiate between signatures of different names, distinguishing genuine signatures from random forgeries, but it struggles to separate genuine signatures from skilled forgeries in most cases. Fig. 6 (b) presents the feature space of MGRNet trained with the triplet loss. It demonstrates a better separation be tween genuine and forged signatures compared to the simple baseline. However, some genuine signatures and their corre sponding forgeries remain clustered together. For example, the two red dashed circles indicate separate genuine and forged signatures of a name, while the red solid circle shows that genuine and forged signatures are visually indistinguishable. Additionally, the triplet loss fails to pull genuine signatures of each name closer together. Fig. 6 (c) illustrates the feature space of MGRNet trained with the cotuplet loss. It shows visually separable clusters of genuine and forged signaturesfor each name. The two red solid circles highlight separate clusters of genuine and forged signatures for one name, while the two red dashed circles indicate a similar pattern for another name. Compared to the baseline and the model trained with the triplet loss, MGRNet trained with the co tuplet loss exhibits improved separation between genuine and forged signatures. These experimental results demonstrate the promising generalization ability of our proposed MGRNet with the cotuplet loss to unseen data. 2) Comparison between global and regional branches: To highlight the benefits of global and regional feature learning, we provide visual explanations of the convolutional layers in both the global and regional branches. We generate heat maps using GradCAM [57], [58] for two genuine signature images and their corresponding forgeries from the test sets of BHSig Bengali and HanSig. Fig. 7 displays the results obtained from Conv51G and Conv51R (the first convolutional layers of the global and regional branches). Conv51G exhibits attention to various areas of the entire image, capturing overall signature information such as outlines and stroke configuration. In comparison, Conv51R focuses more on signature strokes and highlights local details in specific signature regions. For instance, it emphasizes sharp curves in the upper region of the BHSigBengali images and slanting lines in the lower region of the HanSig images. Moreover, Conv51R emphasizes both small details (e.g., the end of a vertical line in genuine signatures of BHSigBengali) and larger detailed parts (e.g., the entire vertical line in forged signatures of BHSigBengali), enabling the model to learn finegrained differences between signatures. These visualiza tion results indicate that the global and regional branches have distinct focuses and capture different yet complementary signature information. Integrating information obtained from multiple spatial scales allows for the generation of more11 (a) Simple baseline (VGG16 pretrained on ImageNet)  (b) MGRNet trained with triplet loss  (c) MGRNet trained with cotuplet loss Fig. 6. 2D projections of the extracted features of the random 50 names (each name has 20 genuine and 20 skilledforged signature images) from the HanSig test set using tSNE [56]. Each marker represents a signature sample: ‚Äúo‚Äù represents the genuine signatures, and ‚Äúx‚Äù represents the forged signatures. The signature samples belonging to different names are displayed in different colors. The red solid circle and dashed circle indicate the samples of the two names. (a) BHSigBengali  (b) HanSig Fig. 7. Visualizing the convolutional layer of the global branch and the regional branch using GradCAM [57]. The images in the first column are the input images. The top two and bottom two images are genuine signatures and the corresponding skilled forgeries, respectively, from the test set of BHSig Bengali and HanSig. The visualization results generated from Conv51G and Conv51R are shown in the second and third columns. discriminative features in signature verification. G. Performance comparison with stateoftheart methods We present a comparison between our proposed method and several stateoftheart methods on the three public datasets. For our newly created HanSig, we provide results of several baseline methods for comparison under the same experimental settings. Note that previous works might report different met rics for their methods. To ensure comparability across different studies, we primarily focus on metrics that do not require threshold setting, namely EER and AUC. In cases where previ ous works only report Average Error Rate (AER), the average of FRR and FAR, which is considered to be comparable to EER [3]. We also provide additional information about each compared method. Additionally, we present a comparison of the number of parameters between our MGRNet and several deep networks in the supplemental material. 1) Comparison on CEDAR: Table III demonstrates that our MGRNet with the cotuplet loss achieves superior performance compared to other methods on CEDAR. Our method out performs OCSVM [59], graphbased CNN [12], P2S metric[35], Siamese network [11], and MSDN [3], which also employ metric learning for signature verification. Notably, our approach surpasses MSDN [3], which solely utilizes local regions from input segmentation for feature learning. This result highlights the efficacy of our proposed multiscale feature learning. It is important to mention that certain previous works did not perform noise removal of the image background during data preprocessing, as mentioned in [3]. However, the image backgrounds of genuine and forged signatures in CEDAR ex hibit significant differences, which could lead to overestimated performance. Therefore, Table III excludes works that reported a 0% error rate without background removal. 2) Comparison on BHSigBengali: Table IV highlights the notable performance improvement of our proposed MGRNet with the cotuplet loss on BHSigBengali compared to stateof theart methods. Our method surpasses SigNet [10], SURDS [47], and DeepHSV [51] by 7.77, 6.54, and 5.8 percentage points in terms of EER, respectively. These three methods incorporate typical metric learning losses such as contrastive loss [14] and triplet loss [15], [16] for signature verification. In contrast, our proposed tupletbased metric learning loss enhances the discriminative power of the learned features, leading to improved performance. 3) Comparison on BHSigHindi: Table V demonstrates the substantial performance improvement of our proposed MGRNet with the cotuplet loss compared to previous meth ods on BHSigHindi. Among the WI methods, our method "
80,Hierarchical Verification for Adversarial Robustness.txt,"We introduce a new framework for the exact point-wise $\ell_p$ robustness
verification problem that exploits the layer-wise geometric structure of deep
feed-forward networks with rectified linear activations (ReLU networks). The
activation regions of the network partition the input space, and one can verify
the $\ell_p$ robustness around a point by checking all the activation regions
within the desired radius. The GeoCert algorithm (Jordan et al., NeurIPS 2019)
treats this partition as a generic polyhedral complex in order to detect which
region to check next. In contrast, our LayerCert framework considers the
\emph{nested hyperplane arrangement} structure induced by the layers of the
ReLU network and explores regions in a hierarchical manner. We show that, under
certain conditions on the algorithm parameters, LayerCert provably reduces the
number and size of the convex programs that one needs to solve compared to
GeoCert. Furthermore, our LayerCert framework allows the incorporation of lower
bounding routines based on convex relaxations to further improve performance.
Experimental results demonstrate that LayerCert can significantly reduce both
the number of convex programs solved and the running time over the
state-of-the-art.","Deep neural networks have been demonstrated to be sus ceptible to adversarial perturbations of the inputs (e.g., Szegedy et al. (2013); Biggio et al. (2013); Goodfellow et al. (2014)). Hence, it is important to be able to mea sure how vulnerable a neural network may be to such noise, especially for safetycritical applications. We study the problem of pointwise exact veriÔ¨Åcation for `pnorm adver Work done as part of Ô¨Årst author‚Äôs AI Residency Program.1Uber Advanced Technologies Group, Toronto ON, Canada2Department of Computer Science, University of Toronto, Toronto ON, Canada. Correspondence to: Cong Han Lim <conghan@uber.com >. Proceedings of the 37thInternational Conference on Machine Learning , Vienna, Austria, PMLR 119, 2020. Copyright 2020 by the author(s).sarial robustness for trained deep feedforward networks with ReLU activation functions. The pointwise `pro bustness with respect to an input x2Rnand a classiÔ¨Åer c :Rn![C]:=f1;2;3;:::;Cgis deÔ¨Åned as (x;c):= min kvkps.t.c(x+v)6= c(x): (1) The goal of exact or complete robustness veriÔ¨Åcation is to check if>r for some desired radius r. The choices of p studied in the literature are typically 1;2;and1; our work applies to all p1. Solving Problem (1)exactly (or within a factor of 1"
282,Deep Speaker Feature Learning for Text-independent Speaker Verification.txt,"Recently deep neural networks (DNNs) have been used to learn speaker
features. However, the quality of the learned features is not sufficiently
good, so a complex back-end model, either neural or probabilistic, has to be
used to address the residual uncertainty when applied to speaker verification,
just as with raw features. This paper presents a convolutional time-delay deep
neural network structure (CT-DNN) for speaker feature learning. Our
experimental results on the Fisher database demonstrated that this CT-DNN can
produce high-quality speaker features: even with a single feature (0.3 seconds
including the context), the EER can be as low as 7.68%. This effectively
confirmed that the speaker trait is largely a deterministic short-time property
rather than a long-time distributional pattern, and therefore can be extracted
from just dozens of frames.","Automatic speaker veriÔ¨Åcation (ASV) is an important biometric authentication technology. As in most machine learning tasks, a key challenge of ASV is the intermixing of multiple variability factors involved in the speech signal, which leads to great un certainty when making genuine/imposter decision. In principle, two methods can be employed to address the uncertainty: ei ther by extracting more powerful features which are sensitive to speaker traits but invariant to other variations, or by construct ing a statistical model that can describe the uncertainty and pro mote the speaker factor. Most of existing successful ASV approaches are model based. For example, the famous Gaussian mixture model universal background model (GMMUBM) framework [1] and the subsequent subspace models, including the joint factor anal ysis approach [2] and the ivector model [3]. They are gen erative models and heavily utilize unsupervised learning. Im provements have been achieved in two directions. The Ô¨Årst is to use a discriminative model to boost the discriminant for speak ers, e.g., the SVM model for the GMMUBM approach [4] and the PLDA model for the ivector approach[5]. The second is to use supervised learning to produce a better representation for the acoustic space. For example, the DNNbased ivector method [6, 7]. Almost all the modelbased methods use raw features, e.g., the popular Mel frequency cepstral coefÔ¨Åcients (MFCC) feature. In spite of the predominant success of the modelbased ap proach, researchers never stop searching for ‚Äòfundamental‚Äô fea tures for speaker traits. The motivation is twofold: from the engineering perspective, if a better feature is found, the present complex statistical models can be largely discarded; and from the cognitive perspective, a fundamental feature will help usunderstand how speaker traits are embedded in speech signals. Driven by these motivations, many researchers put their effort in ‚Äòfeature engineering‚Äô in the past several decades, and new fea tures were proposed occasionally, from perspectives of different knowledge domains [8]. However, compared to the remarkable achievement with the modelbased approach, the reward from the feature engineering is rather marginal. After decades, we Ô¨Ånd the most useful feature in our hand is still MFCC. Inter estingly, the same story was also told in other Ô¨Åelds of speech processing, particularly in automatic speech recognition (ASR), until very recently after deep learning involved. The development of deep learning changed the story. Dif ferent from the historic feature engineering methods that de sign features by human knowledge, deep learning can learn fea tures automatically from vast raw data, usually by a multilayer structure, e.g., a deep neural network (DNN). By the layerby layer processing, taskrelated information can be preserved and strengthened, while taskirrelevant variations are diminished and removed. This feature learning has been demonstrated to be very successful in ASR, where the learned features have shown to be highly representative for linguistic content and very robust against variations of other factors [9]. This success of feature learning in ASR has motivated re searchers in ASV to learn speaker sensitive features. The pri mary success was reported by Ehsan et al. on a textdependent task [10]. They constructed a DNN model with 496 speak ers in the training set as the targets. The framelevel features were read from the activations of the last hidden layer, and the utterancelevel representations (called ‚Äòdvector‚Äô) were ob tained by averaging over framelevel features. In evaluation, the decision score was computed as a simple cosine distance be tween the dvectors of the enrollment utterance(s) and the test utterance. The authors reported worse performance with the d vector system compared to the conventional ivector baseline, but after combining the two systems, better performance was obtained. This method was further extended by a number of researchers. For example, Heigold et al. [11] used an LSTM RNN to learn utterancelevel representations directly and re ported better performance than the ivector system on the same textdependent task when a large database was used (more than 4;000speakers). Zhang et al. [12] utilized convolutional neu ral networks (CNN) to learn speaker features and an attention based model to learn how to make decisions, again on a text dependent task. Liu et al. [13] used the DNNlearned features to build the conventional ivector system. Recently, Snydern et al. [14] migrated the DNNbased approach to textindependent tasks, and reported better performance than the ivector sys tem when the training data is sufÔ¨Åciently large (102k speak ers). All these followingup studies, however, are not purely feature learning: they all involve a complex backend model, either neural or probabilistic, to gain reasonable performance. This is perfectly Ô¨Åne from the perspective of both research andarXiv:1705.03670v1  [cs.SD]  10 May 2017engineering, but departs from the initial goal of feature learn ing: we hope to discover a feature that is sufÔ¨Åciently general and discriminative so that it can be employed in a broad range of applications without heavy backend models. This has been achieved in ASR, but not in speaker veriÔ¨Åcation yet. In this paper, we present a simple but effective DNN structure that involves two convolutional layers and two time delayed fullconnection layers to learn speaker features. Our experiments demonstrated that this simple model can learn very strong speaker sensitive features, using speech data of only a few thousand of speakers. The learned feature does not re quire complex backend models: a simple frame averaging is sufÔ¨Åcient to produce a strong utterancelevel speaker vector, by which a simple cosine distance is good enough to perform text independent ASV tasks. These results actually demonstrated that it is possible to discover speaker information from a short time speech segment ( 300ms), by only a couple of simple neu ral propagation. The rest of this paper is organized as follows. Section 2 de scribes the related work, and Section 3 presents the new DNN structure. The experiments are presented in Section 4, and Sec tion 5 concludes the paper. 2. Related work "
78,Model-Agnostic Defense for Lane Detection against Adversarial Attack.txt,"Susceptibility of neural networks to adversarial attack prompts serious
safety concerns for lane detection efforts, a domain where such models have
been widely applied. Recent work on adversarial road patches have successfully
induced perception of lane lines with arbitrary form, presenting an avenue for
rogue control of vehicle behavior. In this paper, we propose a modular lane
verification system that can catch such threats before the autonomous driving
system is misled while remaining agnostic to the particular lane detection
model. Our experiments show that implementing the system with a simple
convolutional neural network (CNN) can defend against a wide gamut of attacks
on lane detection models. With a 10% impact to inference time, we can detect
96% of bounded non-adaptive attacks, 90% of bounded adaptive attacks, and 98%
of patch attacks while preserving accurate identification at least 95% of true
lanes, indicating that our proposed verification system is effective at
mitigating lane detection security risks with minimal overhead.","Endtoend lane detection methods have shown great promise; however, their shared foundation with deep neu ral networks imply a shared weakness to adversarial exam ples [16]. Given the importance of accurate lane detection in downstream control decisions for autonomous vehicles, a successful attack on lane perception could result in undesirable or outright dangerous vehicle behavior. In particular, we are interested in attacks that could interfere with vehicle guidance through the generation of malicious lane lines, where attack success is marked not by alarm, as is the case when lane lines cannot be found, but by a false sense of normalcy. With no defense, as is the case with current stateoftheart efforts, a lane detection pipeline is unable to make any judgement of lane validity, and thus the perceived fake lanes are indistinguishable from real. To defend against such attacks, we propose a system for lane veriÔ¨Åcation as illustrated in Figure 1, with the goal not to recover the original lanes, but to minimize instances of lane detection model false conÔ¨Ådence. Our lane veriÔ¨Åcation model is fast, lightweight, and appli cable to any existing lane detection effort. The simplicity of our veriÔ¨Åcation model imparts very little inference overhead, and its modular nature allows for independent training that avoids the costs associated with redesigning and retraining the largeand complex neural networks commonly seen in industrial lane detection systems. The modularity carries the additional beneÔ¨Åt of being lane detection modelagnostic, paving a path for integration into any lane detection pipeline. Given the constant improvement and reÔ¨Ånement of lane detection techniques, detaching our defense from a particular architecture allows it to remain viable as the underlying methods become more sophisticated. Our system is motivated by the framing of secure lane detection as two complementary tasks: lane detection and lane veriÔ¨Åcation. The former requires discerning the locations of a variable number of lanes in a constantly changing environment; the latter boils down to binary classiÔ¨Åcation: given a set of lane coordinates, determine if they correspond to a lane that is either real or fake. Instead of further complicating the optimization problem faced by existing lane detection models by introducing the secondary goal of security on top of their initial purpose, we propose moving the task of veriÔ¨Åcation into a separate bespoke model, allowing each part of the pipeline to focus on maximizing individual performance without compromise. Since the task of lane veriÔ¨Åcation can take lane coordinates as given and only needs to return a binary result, it can be accomplished by models much simpler and faster than those required for lane detection. Our experiments show that simple convolutional models are sufÔ¨Åcient to signiÔ¨Åcantly improve lane detection pipeline robustness to both digital and physical attack as pictured in Figure 2. When evaluated against a Lpbounded attack and two patchbased attacks, our model can detect over 95% of attacks with minimal impact to model accuracy and inference time. These results suggest that our model is capable of defending against a variety of attack types, including unknown threats. In summary, strong performance of our defense against both nonadaptive and adaptive versions of such threats indi cates that such a system could offer security to lane detection models at very little expense. Our primary contributions are as follows:  We propose a simple lane veriÔ¨Åcation defense that can be integrated into the pipeline of any lane de tection effort with no retraining of the underlying model required. Its independent and lightweight nature provides marginal inference overhead and allows for quick security updates when new attacks arise.  We show empirically that veriÔ¨Åcation provides signif icant lane detection security with minimal cost.Workshop on Automotive and Autonomous Vehicle Security (AutoSec) 2021 21 February 2021 ISBN 1891562681 https://dx.doi.org/10.14722/autosec.2021.23032 www.ndsssymposium.orgarXiv:2103.00663v1  [cs.CV]  1 Mar 2021Fig. 1. Our proposed defense augmentation to a general lane detection model. II. R ELATED WORK "
207,A Package for the Automated Classification of Images Containing Supernova Light Echoes.txt,"Context. The so-called ""light echoes"" of supernovae - the apparent motion of
outburst-illuminated interstellar dust - can be detected in astronomical
difference images; however, light echoes are extremely rare which makes manual
detection an arduous task. Surveys for centuries-old supernova light echoes can
involve hundreds of pointings of wide-field imagers wherein the subimages from
each CCD amplifier require examination. Aims. We introduce ALED, a Python
package that implements (i) a capsule network trained to automatically identify
images with a high probability of containing at least one supernova light echo,
and (ii) routing path visualization to localize light echoes and/or light
echo-like features in the identified images. Methods. We compare the
performance of the capsule network implemented in ALED (ALED-m) to several
capsule and convolutional neural networks of different architectures. We also
apply ALED to a large catalogue of astronomical difference images and manually
inspect candidate light echo images for human verification. Results. ALED-m,
was found to achieve 90% classification accuracy on the test set, and to
precisely localize the identified light echoes via routing path visualization.
From a set of 13,000+ astronomical images, ALED identified a set of light
echoes that had been overlooked in manual classification. ALED is available via
github.com/LightEchoDetection/ALED.","Supernovae are extremely luminous but transient events that sig nal the Ô¨Ånal stage of a massive star‚Äôs evolution or the disruption of a white dwarf in a close binary (Rest et al. 2015). The bright light from the outburst is radiated in all directions and can be scattered by interstellar dust as outburst light encounters such material. The deÔ¨Çection of light o interstellar dust is analogous to the deÔ¨Çection of sound waves o surfaces; hence the term ""light echo"". Light echoes from a historical supernova can arrive at Earth centuries later than any direct light and consequently they can facilitate the study of historic supernovae in modern times with modern instrumentation. The light echoes of super novae are present in some astronomical images, but are almost without exception a small percentage of the surface brightness of the moonless night sky (McDonald 2012). A dierence image is the result of subtracting a pair of im ages that are taken at the same telescopic pointing but at di erent dates. Di erence imaging allows for objects that appear to move relative to the background of space, such as light echoes, to be visually detected more easily (see Figure 1). However, manual visual image analysis is still demanding due to the large amount of data generated by supernova light echo surveys. For instance, in McDonald (2012) 13,000 +dierence images were individu ally inspected for light echoes over the course of a year.This paper introduces the Python package ALED (pro nounced ""Aled"") for automated light echo detection in astro nomical di erence images. This package provides an invaluable resource for astronomers requiring rapid identiÔ¨Åcation of images containing at least one light echo, and where those light echoes are located within the identiÔ¨Åed images. ALED takes as input a greyscale di erence image of arbitrary size, and outputs a corre sponding routing path visualization of the input image (Bhullar et al. 2020). The routing path visualization reveals the regions of the input image that have a high probability of containing a light echo  the brighter the region the greater the likelihood. Here, we demonstrate and compare the performance of ALEDm, the capsule network model that is available in ALED, to several dif ferent artiÔ¨Åcial neural network classiÔ¨Åers. We also apply ALED to the 13000 +dierence images for which McDonald (2012) did not detect light echoes. ALED was developed speciÔ¨Åcally for the purpose of light echo detection. Di erence imaging also gener ates artifacts that can, in some instances, mimic the appearance of light echoes, see Figure 1. Simpler automatic image classiÔ¨Å cation techniques struggle to distinguish light echoes from light echolike artifacts (McDonald 2012). ALED is based on a capsule network (Sabour et al. 2017), which is an extension of a convolutional neural network (CNN). CNNs have achieved stateoftheart performance on many com puter vision problems, and are currently one of the most popular algorithms for image classiÔ¨Åcation. CNN architectures typically Article number, page 1 of 11arXiv:2208.07260v1  [astroph.IM]  15 Aug 2022A&A proofs: manuscript no. aanda contain millions of weights that are to be learned during train ing, and as a result, require a large training set to prevent over Ô¨Åtting (LeCun et al. 1989). For example, LeNet, a CNN con taining 5,978,677 weights, was trained using 60,000 images to classify handwritten digits (LeCun et al. 1998). This particular classiÔ¨Åcation task is considered simpler than light echo detec tion from di erence images because each image is guaranteed to contain a single white digit in the center of a black background. More complex classiÔ¨Åcation tasks require CNNs with a higher weight count. For example, Wide ResNet502, a CNN contain ing 68,951,464 weights, was trained using 1.2 million images to classify photographs of 1000 object categories such as boats, horses, etc. (Zagoruyko and Komodakis 2016). This is a more complex classiÔ¨Åcation task because an image can contain 1 of 1000 coloured objects in an arbitrary orientation on an arbitrary background. The di culty of light echo classiÔ¨Åcation falls somewhere in between these two examples. Although there are only two clas siÔ¨Åcation categories  light echo present or not  light echoes are not only found in widely di erent orientations and backgrounds in greyscale images but each image may contain several enti ties, and of those entities, more than one may be a light echo. As such, it is expected that a CNN with millions of weights would be required for adequate light echo detection. In special ized Ô¨Åelds, such as observational astronomy, su ciently large sets of labeled data are often unavailable. This is especially true for automating the classiÔ¨Åcation of images containing supernova light echoes because detectable light echo examples are so few in number (McDonald 2012). Training a CNN, which contains millions of weights, by us ing a dataset of a few hundred images is problematic because the model may overÔ¨Åt to the small dataset in a manner that is not obvious. For example, if the training set represents the valida tion and test sets well then the validation and test accuracies will be similar to the training accuracy. However, if the model over Ô¨Åts to irrelevant characteristics of the dataset, such as camera or preprocessing characteristics or artifacts, then the training, val idation, and test accuracies will still be similar even though the model will not perform well on datasets taken by di erent cam eras or preprocessed in a slightly di erent manner. Capsule network models require far fewer weights, and thus, are less likely to overÔ¨Åt to irrelevant characteristics of the dataset. Dropout can be used in CNNs to reduce overÔ¨Åtting by randomly omitting a certain percentage of neurons every forward propagation step while training. This strategy makes it more dif Ô¨Åcult for the network to simply memorize the training set or learn unnecessary coadaptations such as higherlevel neurons correct ing the mistakes of lowerlevel neurons (Hinton et al. 2012). For completeness, we include a few CNN architectures to illustrate how many more weights are needed in a CNN compared to a capsule network for light echo detection. Capsule networks are artiÔ¨Åcial neural networks that can model hierarchical relationships (Sabour et al. 2017). They typi cally contain fewer trainable weights than CNNs and, as a result, require a smaller training set to achieve good performance. Cap sule networks also facilitate routing path visualization which can be used to interpret the entity that a given capsule detects. Said dierently, capsule networks provide a way to see what is being detected. It should be noted that CNNs can also facilitate several gradient based methods to see what is being detected, such as gradcam (Selvaraju et al. 2017). Interpreting how a model functions is important because it will allow for the identiÔ¨Åcation of scenarios that may result in model failure. When the training set is small, as seen in light Fig. 1: Types of entities present in the CFHT dataset. (a) im ages that clearly contain at least one light echo; (b) images that clearly do not contain at least one light echo; (c) images that contain light echoes and artifacts; and (d) images that contain entities with light echolike characteristics. Illustration and cap tion credit: (Bhullar et al. 2020). echo detection, it is expected that the training set will not contain such di cult image classiÔ¨Åcation scenarios even though they are likely to arise in practice. Consequently, constraints can be ap plied to the network, or improvements can be made to the train ing set to decrease the probability of failure. Section 2 describes the CanadaFranceHawaii Telescope (CFHT) di erence image data used to train and evaluate ALED. Section 3 brieÔ¨Çy reviews capsule networks and describes the net work architectures to which ALED was compared and the pa rameter settings used to classify the 13000 +CFHT di erence images. Section 4 presents the results from the analyses and con cluding comments are made in Section 5. 2. CFHT Dataset In 2011, CFHT‚Äôs wideÔ¨Åeld mosaic image, MegaCam, was used to conduct a survey with the primary objective of discovering supernova light echoes in a region where three historical su pernovae were known to have occurred. Out of the 13,000 + 20484612 di erence images that were produced from the sur vey, 22 were found to contain at least one light echo (McDonald 2012). The 22 light echo containing CFHT di erence images of size 20484612 were reduced to 350 di erence images of size 200200, among which 175 contained at least a portion of a light echo and the remaining 175 contained other astronomical entities. The dataset was created by manually masking the light echoes present in the 22 images of size 2048 4612, which were then cropped to size 200 200. If a cropped image contained at least 2500 pixels of mask then it was classiÔ¨Åed as containing a light echo. Among the 4885 200 200 cropped images that did not con tain a light echo, 175 were selected at random, along with 175 that were classiÔ¨Åed as containing a light echo to form the Ô¨Å nal dataset of 350 images. The dataset consists of images and their respective binary labels, where the label indicates whether the image does or does not contain at least one light echo. The dataset was split into a training set of 250 images, and a valida tion and test set of 50 images each. See Appendix A for a sum mary of the preprocessing steps required to produce a di erence image. Article number, page 2 of 11A. Bhullar , R. A. Ali, and D. L. Welch : Automated ClassiÔ¨Åcation of Images Containing Supernova Light Echoes 3. Methods "
362,ANTONIO: Towards a Systematic Method of Generating NLP Benchmarks for Verification.txt,"Verification of machine learning models used in Natural Language Processing
(NLP) is known to be a hard problem. In particular, many known neural network
verification methods that work for computer vision and other numeric datasets
do not work for NLP. Here, we study technical reasons that underlie this
problem. Based on this analysis, we propose practical methods and heuristics
for preparing NLP datasets and models in a way that renders them amenable to
known verification methods based on abstract interpretation. We implement these
methods as a Python library called ANTONIO that links to the neural network
verifiers ERAN and Marabou. We perform evaluation of the tool using an NLP
dataset R-U-A-Robot suggested as a benchmark for verifying legally critical NLP
applications. We hope that, thanks to its general applicability, this work will
open novel possibilities for including NLP verification problems into neural
network verification competitions, and will popularise NLP problems within this
community.","Deep neural networks (DNNs) are adept at addressing challenging problems in var ious areas, such as Computer Vision (CV) [ 24] and Natural Language Processing (NLP) [29,9]. Due to their success, systems based on DNNs are widely deployed in the physical world and their safety and security is a critical matter [3,4,7]. One example of a safety critical application in the NLP domain is a chatbot‚Äôs responsibilitytoidentifyitselfasanAIagent, whenaskedbytheusertodoso .Recently therehasbeenseveralpiecesoflegislationproposedthatwillenshrinethisrequirement in law [13,15]. For the chatbot to be compliant with these new laws, the DNN, or the subsystem responsible for identifying these queries, must be 100% accurate in its recognition of the user‚Äôs question. Yet, in reality the questions can come in different ‚ãÜLarge portion of work undertaken whilst at University of EdinburgharXiv:2305.04003v2  [cs.CL]  12 Jul 2023Fig.1: An example of œµballs (left), convexhull (centre) and hyperrectangle (right) in 2dimensions. The red dots represent sentences in the embedding space from the training set belonging to one class, while the torquoise dots are embedded sentences from the test set belonging to the same class. forms, for example: ‚ÄúAre you a Robot?‚Äù ,‚ÄúAm I speaking with a person?‚Äù ,‚ÄúHey, are youahumanorabot?‚Äù .Failuretorecognisetheuser‚Äôsintentandthusfailuretoanswer the question correctly can have legal implications for the chatbot designers [13,15]. The RUARobot dataset [ 8] was created with the intent to study solutions to this problem, and prevent user discomfort or deception in situations where users might have unsolicited conversations with humansounding machines over the phone. It contains 6800sentences of this kind, labelled as positive (the question demands identification), negative (the question is about something else) and ambiguous. One can train and use a DNN to identify the intent. How difficult is it to formally guarantee the DNN‚Äôs intended behaviour? The stateoftheart NLP technology usually relies on transformers [32] to embed natural languagesentencesintovectorspaces.Oncethisisachieved,anadditionalmediumsize network may be trained on a dataset that contains different examples of ‚ÄúAre you a Robot?‚Äù sentences. This second network will be used to classify new sentences as to whether they contain the intent to ask whether the agent is a robot. There are several approaches to verify such a system. Ideally we would try to verify the whole system consisting of both the embedding function and the classifier. However,stateofthearttransformersarebeyondthereachofstateoftheartverifiers. For example the base model of BERT [ 6] has around 110 million trainable parameters and GPT3 [ 19] has around 175 billion trainable parameters. In contrast, the most performant neural network verifier AlpaBetaCrown [ 33] can only handle networks in the range of a few hundred of thousand nodes. So, verification efforts will have to focus on the classifier that stands on top of the transformer. Training a DNN with 2 layers on the RUARobot dataset [ 8] gives average accuracy of 93%. Therefore there is seemingly no technical hurdle in running existing neural network verifiers on it [ 11,28,33]. However, most of the properties checked by these verifiers are in the computer vision domain. In this domain, images are seen as vectors in a continuous space, and every point in the space corresponds to a valid image. The act of verification guarantees that every point in a given region of that space is classified correctly. Such regions are identified as ‚Äú œµballs‚Äù drawn around images in the training dataset, for some given constant œµ. Despite not providing aformal guarantee about the entire space, this result is useful as it provides guarantees about the behaviour of the network over a large set of unseen inputs. However, if we replicate this approach in the NLP domain, we obtain a math ematically sound but pragmatically useless result. This is because, unlike images, sentences form a discrete domain, and therefore very few points in the input space actually correspond to valid sentences. Therefore, as shown in Figure 1, it is highly unlikely that the œµballs will contain any unseen sentences for values of œµthat can actually be verified. And thus, such verification result does not give us more assurance than just measuring neural network accuracy! There is clearly a need in a substantially different methodology for verification of NLP models. Our proposal is based on the following observations. On the verifier side, the stateofart tools based on abstract interpretation are still wellsuited for this task, because they are flexible in the definition of the size and shape of the input subspace that they verify. But considerable effort needs to be put into definitions of subspaces that actually make pragmatic sense from the NLP perspective. For example, as shown in Figure 1, constructing a convex hull around several sentences embedded in the vector space has a good chance of capturing new, yet unseen sentences. Unfortunately, calculating convex hulls with sufficient precision is computationally infeasible for high number of dimensions. We resort to overapproximating convex hulls with ‚Äúhyperrectangles‚Äù , computation of which only takes into consideration the minimum and maximum value of each dimension for each point around which we draw the hyperrectangle. There is one last hurdle to overcome: just naively drawing hyperrectangles around some data points gives negative results, i.e. verifiers fail to prove the correctness of classifications within the resulting hyperrectangles. There is no silver bullet to overcome this problem. Instead, as we show in this paper,oneneedsasystematicmethodologytoovercomethisproblem.Firstly,weneed methods that refine hyperrectangles in a variety of ways, from the standard tricks of reducing dimensions of the embedding space and clustering, to geometric manip ulations, such as hyperrectangle rotation. Secondly, precision of the hyperrectangle shapes can be improved by generating valid sentence perturbations, and constructing hyperrectangles around (embeddings of) perturbed, and thus semantically similar, sentences. Finally, based on the refined spaces, we must be able to retrain the neural networks to correctly fit the shapes, and this may involve sampling based on adversarial attacks within the hyperrectangles. The result is a comprehensive library that contains a toolbox of preprocessing and training methods for verification of NLP models. We call this tool ANTONIO  Abstract iNterpreTation fOr Nlp verIficatiOn (see Figure 2). Although we evalu ate the results on two (RUARobot and Medical) datasets, the methodology and libraries are completely general, and should work for any NLP dataset and models of comparable sizes. We envisage that this work will pave the way for including NLP datasets and problems as benchmarks into DNN verification competitions and papers, and more generally we hope that it will make NLP problems more accessible to the neural network verification community.NLP Data SetANTONIO  Abstract iNterpreTation fOr Nlp verIficatiOn 1. dataset curation B)A) C)unmodifiedoriginal word levelattacks char levelattacks2. preparation of datasets A) embeddings (BERT) i ii iiiB) data set rotation C) dimensionality reduction i ii iiii ii iii 3. transformations A) shrinked hyperrectangle B) clusters of hyperrectangles C) hyperrectangles on attacks 4. models i. base  0  1  1  0  1  1  0  0  1 1  1  1  0  0  0  1  0  0 1  0  1  0  1  1  0  0  0 0  1  1  1  1  0  0  0  1 0  1  1  0  1  0  1  0  1  ii. shrinked  0  1  1  0  1  1  0  0  1 1  1  1  0  0  0  1  0  0 1  0  1  0  1  1  0  0  0 0  1  1  1  1  0  0  0  1 0  1  1  0  1  0  1  0  1  iii. clusters 0  1  1  0  1  1  0  0  1 1  1  1  0  0  0  1  0  0 1  0  1  0  1  1  0  0  0 0  1  1  1  1  0  0  0  1 0  1  1  0  1  0  1  0  1  iv. epsilon 0  1  1  0  1  1  0  0  1 1  1  1  0  0  0  1  0  0 1  0  1  0  1  1  0  0  0 0  1  1  1  1  0  0  0  1 0  1  1  0  1  0  1  0  1  v. char attack 0  1  1  0  1  1  0  0  1 1  1  1  0  0  0  1  0  0 1  0  1  0  1  1 0  0  0 0  1  1  1  1  0  0  0  1 0  1  1  0  1  0  1  0  1  0  1  1  0  1  1  0  0  1 1  1  1  0  0  0  1  0  0 1  0  1  0  1  1  0  0  0 0  1  1  1  1  0  0  0  1 0  1  1  0  1  0  1  0  1  vi. word attack 0  1  1  0  1  1 0  0  1 1  1  1  0  0  0  1  0  0 1  0  1  0  1  1  0  0  0 0  1  1  1  1  0  0  0  1 0  1  1  0  1  0  1  0  1  vii. aug. char  attack 0  1  1  0  1  1  0  0  1 1  1  1  0  0  0  1  0  0 1  0  1  0  1  1  0  0  0 0  1  1  1  1  0  0  0  1 0  1  1  0  1  0  1  0  1  viii. aug. word  attack5. evaluation A) accuracy B) attack efficacy C) verification D) epsilon cubes semantic geometric  Fig.2: Flowchart for our tool ANTONIO. 2 Related Work "
473,Explainable multiple abnormality classification of chest CT volumes.txt,"Understanding model predictions is critical in healthcare, to facilitate
rapid verification of model correctness and to guard against use of models that
exploit confounding variables. We introduce the challenging new task of
explainable multiple abnormality classification in volumetric medical images,
in which a model must indicate the regions used to predict each abnormality. To
solve this task, we propose a multiple instance learning convolutional neural
network, AxialNet, that allows identification of top slices for each
abnormality. Next we incorporate HiResCAM, an attention mechanism, to identify
sub-slice regions. We prove that for AxialNet, HiResCAM explanations are
guaranteed to reflect the locations the model used, unlike Grad-CAM which
sometimes highlights irrelevant locations. Armed with a model that produces
faithful explanations, we then aim to improve the model's learning through a
novel mask loss that leverages HiResCAM and 3D allowed regions to encourage the
model to predict abnormalities based only on the organs in which those
abnormalities appear. The 3D allowed regions are obtained automatically through
a new approach, PARTITION, that combines location information extracted from
radiology reports with organ segmentation maps obtained through morphological
image processing. Overall, we propose the first model for explainable
multi-abnormality prediction in volumetric medical images, and then use the
mask loss to achieve a 33% improvement in organ localization of multiple
abnormalities in the RAD-ChestCT data set of 36,316 scans, representing the
state of the art. This work advances the clinical applicability of multiple
abnormality modeling in chest CT volumes.","Automated interpretation of medical images with machine learning has the potential to revolutionize the Ô¨Åeld of radiology. However, machine learning systems have not yet been adopted on a large scale in clinical practice [ 1]. One barrier to adoption is trust [ 2,3]. Most medical imaging models are based on convolutional neural networks (CNNs), which are ‚Äúblack box‚Äù models unless additional steps are taken to improve explainability [4]. Visual explanation methods in computer vision indicate which regions of an input image contribute to a model‚Äôs predictions [ 4]. Explainability is critical in medical imaging to detect situations where a model leverages aspects of the data that are correlated with an outcome but inappropriate for prediction. Zech et al. [5] used class activation mapping [ 6] to reveal that a CNN trained to predict pneumonia from chest radiographs leveraged nonmedical features to make the pneumonia prediction. SpeciÔ¨Åcally, the model identiÔ¨Åed differences in metal tokens, postprocessing, and compression artefacts which revealed the hospital system of origin, a highly effective indicator of pneumonia risk due to differing frequencies of pneumonia among the patient populations. Furthermore, a ‚Äúmodel‚Äù consisting of sorting the radiographs by hospital system achieved an AUROC of 0.861, illustrating Published in ArtiÔ¨Åcial Intelligence in Medicine , 2022.arXiv:2111.12215v3  [eess.IV]  20 Aug 2022that high performance alone does not guarantee that a model is faithful to expected medical reasoning. This behavior is analogous to natural image classiÔ¨Åers detecting boats via water, trains via rails, or horses via a copyright watermark [ 7,8]. It is thus critical to seek insight into how models make their predictions. In this work, we consider explainable multiple abnormality classiÔ¨Åcation in volumetric medical images, a task that to the best of our knowledge has not yet been explored in the literature. The four new contributions of this paper are summarized below. Our Ô¨Årst two contributions create an initial solution: ‚Ä¢We propose AxialNet, a multiple instance learning CNN that explains its predictions by identifying the axial slices that contribute most towards identiÔ¨Åcation of each abnormality; ‚Ä¢HiResCAM is a previously published method with faithfulness guarantees. To obtain Ô¨Åner grained, subslice predictions, we incorporate HiResCAM explanations into AxialNet, and include a new proof that shows for the Ô¨Årst time that HiResCAM‚Äôs faithfulness guarantee also holds for the class of multiple instance learning models AxialNet represents. Our next two contributions aim to improve AxialNet‚Äôs learning and thus improve the ‚Äúreasoning‚Äù behind its explanations: ‚Ä¢We develop a novel mask loss that leverages HiResCAM and 3D allowed regions to encour age AxialNet to predict abnormalities from only the organs in which they are found; ‚Ä¢In order to obtain the 3D allowed regions efÔ¨Åciently, we propose PARTITION, a method to obtain pixellevel, abnormalityspeciÔ¨Åc allowed regions without any manual labeling, by combining location information extracted from radiology reports with organ segmentation maps obtained via morphological image processing. Overall, we present an initial method for the new task of explainable multiple abnormality classi Ô¨Åcation in volumetric medical images, then improve upon our solution to achieve stateoftheart performance. This work represents a step towards machine learning systems that may accelerate the radiology workÔ¨Çow and contribute to improved detection and monitoring of disease. 2 Related Work "
166,An Abstraction-Refinement Approach to Verifying Convolutional Neural Networks.txt,"Convolutional neural networks have gained vast popularity due to their
excellent performance in the fields of computer vision, image processing, and
others. Unfortunately, it is now well known that convolutional networks often
produce erroneous results - for example, minor perturbations of the inputs of
these networks can result in severe classification errors. Numerous
verification approaches have been proposed in recent years to prove the absence
of such errors, but these are typically geared for fully connected networks and
suffer from exacerbated scalability issues when applied to convolutional
networks. To address this gap, we present here the Cnn-Abs framework, which is
particularly aimed at the verification of convolutional networks. The core of
Cnn-Abs is an abstraction-refinement technique, which simplifies the
verification problem through the removal of convolutional connections in a way
that soundly creates an over-approximation of the original problem; and which
restores these connections if the resulting problem becomes too abstract.
Cnn-Abs is designed to use existing verification engines as a backend, and our
evaluation demonstrates that it can significantly boost the performance of a
state-of-the-art DNN verification engine, reducing runtime by 15.7% on average.","In machine learning (ML), we use data demonstrating a system's desired be havior to automatically train an artifact that implements the system. ML has become a leading solution for complex algorithmic problems in recent years, ob taining astounding results in many elds. Perhaps the most popular and success ful among ML approaches are those for training deep neural networks (DNN s) | artifacts that have demonstrated a remarkable ability to solve extremely complex tasks [19,29,33,43,46,55,59]. Despite their excellent performance, DNNs are notoriously opaque to human engineers: attempting to \connect the dots"" and infer the reasoning learned by the DNN is a herculean task. This opacity is particularly troubling, as various errors have been demonstrated in realworld, stateoftheart DNNs. Perhaps the most famous among these is the adversarial input phenomenon, where slightarXiv:2201.01978v1  [cs.LG]  6 Jan 2022input perturbations cause the DNN to perform severe errors [60]. These errors, and others, are a hindrance to the adoption of DNNbased methods in critical systems [5] (e.g., autonomous vehicles, banking, nancial infrastructure, and others), where it is vital to be condent that the system behaves correctly, even in corner cases. To address this diculty and facilitate the adoption of DNNs in critical sys tems, dierent methods for explaining, interpreting, and reasoning about DNNs have been proposed. In recent years, the verication community has taken an in terest in DNN verication : developing automated tools for determining whether a network satises a prescribed property or providing a counterexample if it does not. Relevant properties include, for example, a network's robustness against ad versarial inputs [12], or the absence of bias against various protected groups in its decision making [32]. Unfortunately, the DNN formal verication problem is NPcomplete even for simple neural networks and specications [37, 39], and becomes exponentially harder as the network size increases. Still, great eorts are being put into devising verication schemes that can solve average instances of the problem quickly, and which support the verication of additional kinds of DNNs and properties [3{5,8,14,17,21{23,25,34{40,42,44,45,48,50,51,56,58,61, 62,65,66,69{73]. Here, we contribute to this ongoing eort and present a new framework called CnnAbs , which uses an abstractionrenement based approach for verifying convolutional neural networks (CNNs ). CNNs are a particular type of DNNs, which use convolutions : constructs that allow for a very compact representation of the DNN, and consequently enable engineers to overcome memoryrelated bottlenecks. CNNs have been shown to perform well in image processing and computer vision tasks [33,43,55,59] and are in widespread use. Existing verica tion tools can verify CNNs, but typically only by reducing them to the general, fully connected case, thus failing to leverage the builtin compactness of CNNs. Because the size of the DNN slows down its verication, such transformations are costly. In contrast, our proposed framework aims to utilize the special properties of a CNN in expediting its verication. At a high level, given a verication query over a CNN, CnnAbs rst creates anabstract network, with signicantly fewer neurons, such that proving the property on this smaller network would directly imply that the property also holds for the original network. Notably, the abstract network that we construct is fully connected | i.e., not convolutional | and can thus be veried using existing technology. Further, because the verication complexity depends on the number of neurons and edges in the DNN, verifying this smaller network is faster than transforming the CNN into an equivalent, fully connected network and verifying it, as is usually done. Due to the abstraction procedure, verifying the smaller network might produce a spurious counterexample, in which case our framework renes the network and repeats the process. Apart from the convolution construct, CNNs also make extensive use of max pooling layers. An additional contribution that we make here is proposing a new way for analyzing these layers, which allows us to prune the search space of theresulting verication problem and thus accelerate the verication procedure even further. Specically, we propose a way to put linear approximate bounds on the max function, which improves the stateoftheart. For evaluation purposes, we created a proofofconcept implementation of our framework. This implementation is comprised of a set of Python modules and is designed to allow for seamless integration with existing DNN veriers as blackbox backends. For the experiments reported in this paper, we used the Marabou DNN verier [40] as a backend. We conducted experiments comparing the performance of CnnAbs with Marabou as a backend to those of vanilla Marabou and found that the abstractionrenement approach for verifying CNNs indeed oers signicant performance improvements | specically, reducing the runtime by 15.7% on average, with a median runtime reduction of 24.6%. We also saw an increase of 13% in the number of realistically solvable queries compared to vanilla Marabou. These results showcase the high potential of CnnAbs . The rest of the paper is organized as follows. In Section 2 we provide back ground on DNNs and their verication. In Section 3 we schematically present our suggested abstractionrenement approach, and then discuss our treatment of maxpooling layers in Section 4. We discuss the implementation details of Cnn Abs in Section 5, and present its evaluation in Section 6. We refer to related work in Section 7, and conclude in Section 8. 2 Preliminaries 2.1 Deep Neural Networks A feedforward deep neural network Nis an acyclic weighted directed graph. It hasninputs and moutputs and can be regarded as a mapping from Rnto Rm. The nodes ofN, also called neurons, are organized into layers: the rst layer is the input layer , the nal one is the output layer , and the remaining ones are hidden layers . When the DNN is invoked, the input layer is assigned values by the caller. Then, in the following layers, the value of each neuron is computed using values of neurons from preceding layers, eventually producing the assignment of the output layer, which is returned to the caller. The evaluation of each neuron depends on the type of its layer. We focus here on four popular layer types: weighted sum ,convolution ,ReLU and maxpooling layers, explained next. The example in Fig. 1 (a) illustrates these dierent kinds of layers, and an example of an evaluation of the network appears in Fig. 1 (b). In a weighted sum (WS) layer, each neuron is computed as a weighted sum of values of neurons from the preceding layer. Let vector Vrepresent the assignment of a weighted sum layer of size t, and letUrepresent the assignment of its preceding layer of size l.Vis then computed as follows: 80it"
268,Local Reasoning for Parameterized First Order Protocols.txt,"First Order Logic (FOL) is a powerful reasoning tool for program
verification. Recent work on Ivy shows that FOL is well suited for verification
of parameterized distributed systems. However, specifying many natural objects,
such as a ring topology, in FOL is unexpectedly inconvenient. We present a
framework based on FOL for specifying distributed multi-process protocols in a
process-local manner together with an implicit network topology. In the
specification framework, we provide an auto-active analysis technique to reason
about the protocols locally, in a process-modular way. Our goal is to mirror
the way designers often describe and reason about protocols. By hiding the
topology behind the FOL structure, we simplify the modelling, but complicate
the reasoning. To deal with that, we use an oracle for the topology to develop
a sound and relatively complete proof rule that reduces reasoning about the
implicit topology back to pure FOL. This completely avoids the need to
axiomatize the topology. Using the rule, we establish a property that reduces
verification to a fixed number of processes bounded by the size of local
neighbourhoods. We show how to use the framework on two examples, including
leader election on a ring.","Autoactive[6] and automated veriÔ¨Åcation engines are now common ly used to analyze the behavior of safety and systemcritical multiproces s distributed sys tems.Applyingtheanalysistechniquesearlyinthedesigncyclehasth eaddedad vantage that any errors or bugs found are less costly to Ô¨Åx than if one waits until the system is deployed. Therefore, it is typical to seek a proof of s afety for para metricdesigns, where the number of participating program components is not yet determined, but the interprocess communciation Ô¨Åts a given p attern, as is common in routing or communication protocols, and other distribute d systems. Recently, Ivy [15] has been introduced as a novel autoactive ver iÔ¨Åcation technique (in the style of Dafny [6] for reasoning about paramete rized systems. Ivy models protocols in First Order Logic (FOL). The veriÔ¨Åcation con ditions are compiled (with user help) to a decidable fragment of FOL, called EÔ¨Ä ectively PropositionalReasoning(EPR) [16]. Ivy is automaticin the sensetha t the veriÔ¨Å cation engineer only provides an inductive invariant. Furthermore, unlike Dafny, it guarantees that the veriÔ¨Åcation is never stuck inside the decision procedure (veriÔ¨Åcation conditions are decidable). One of the disadvantages of Ivy is that an engineer must formally sp ecify the entire protocol, including the topology. For instance, in verifyin g the leader election on a ring, Ivy requires an explicit axiomatization of the ring to pology,‚àÄx,y,z¬∑btw(x,y,z)‚áíbtw(y,z,x) ‚àÄw,x,y,z ¬∑btw(w,x,y)‚àßbtw(w,y,z)‚áíbtw(w,x,z) ‚àÄw,x,y¬∑btw(w,x,y)‚áí ¬¨btw(w,y,x) ‚àÄw,x,y¬∑distinct(w,x,y)‚áí(btw(w,x,y)‚à®btw(w,y,x)) ‚àÄa,b¬∑(next(a,b)‚áê‚áí ‚àÄx¬∑x/ne}ationslash=a‚àßx/ne}ationslash=b‚áíbtw(a,b,x)) Fig.1: A description of a unidirectional ring in FOL as presented by Iv y [15]. as shown in Fig. 1. The predicate btw(x,y,z) means that a process yis between processesxandzin the ring; similarly, next(a,b) means that bis an immedi ate neighbour of aon the ring. All (Ô¨Ånite) rings satisfy the axioms in Fig. 1. The converse is not true in general. For instance, take the rationa lsQand let btw(x,y,z) be deÔ¨Åned as x<y<z ‚à®y <z <x ‚à®z <x<y . All axioms of btw are satisÔ¨Åed, but the only consistent interpretation of nextis an empty set. This satisÔ¨Åes all the axioms, but does not deÔ¨Åne a ring. For the axioms in F ig. 1, all Ô¨Ånitemodels of btwandnextdescribe rings. This is not an issue for Ivy, since inÔ¨Ånite models do not need to be considered for EPR. Such reasoning is non trivial and is a burden on the veriÔ¨Åcation engineer. As another exam ple, we were not able to come up with an axiomatization of rings of alternating red a nd black nodes (shown in Fig. 2a) within EPR. In general, a complete axiomatiza tion of the topology might be hard to construct. In this paper, we propose to address this problem by specifying the topology independently of process behaviour. We present a framework whic h separates the two and provides a clean way to express the topology. We then s pecify our transitions locally, as this is a natural and common way to deÔ¨Åne prot ocols. Once these preliminaries are done, we provide a processlocal proo f rule to ver ify properties of the system. To generate the proof rule, we oÔ¨Ñoa d topological knowledge to an oracle that can answer questions about the topolo gy. Finally, we prove various properties of the proof rule. In summary, the paper makes the following contributions. First, in S ec. 3, we show how to model protocols locally in FOL. This is an alternative to the global modelling used in Ivy. Second, in Sec. 4, we show a proof rule with veriÔ¨Å cation conditions (VC) in FOL, which are often in EPR. When the VC is in EPR, this gives an engineer a mechanical check of inductiveness. This allow s reasoning about topology without axiomatizing it. Third, in Sec. 5, we show that our proof rule (a) satisÔ¨Åes a small model property, and (b) is relatively comple te. The Ô¨Årst guarantees the veriÔ¨Åcation can be done on small process domains; the second ensures that our proof rule is fairly expressive. We illustrate our approach on two examples. First, as a running exam ple, motivated by [12], is a protocol on rings of alternating red and black n odes. These rings have only rotational symmetry, however, they have s ubstantial local symmetry [7,11,12] consisting of two equivalence classes, one of red nodes, and one of black nodes. Second, in Sec. 6, we consider a modiÔ¨Åed version of the leader election protocol from Ivy [15]. This is of particular interest, since the 2local symmetry of [7,11,12] has not been applied to leader election. We thus extend [7,11,12] by both allowing more symmetries and inÔ¨Ånitestate s ystems. 2 Preliminaries FOL syntax and semantics. We assume some familiarity with the standard con cepts of many sorted First Order Logic (FOL). A signature Œ£consists of sorted predicates, functions, and constants. Terms are variables, con stants, or (recur sively)kary functions applied to kother terms of the correct sort. For every karypredicate Pandktermst1,...,tkoftheappropriatesortfor P,theformula P(t1,...,tk) is a wellformed formula (wÔ¨Ä). WÔ¨Äs are then boolean combinations of formulaeand universallyor existentially quantiÔ¨Åed formulae. Name ly, ifœàand œïare wÔ¨Äs, then so are ( œà‚àßœï), (œà‚à®œï),(¬¨œà), (œà‚áíœï),(œà‚áê‚áíœï), (‚àÄx¬∑œà), and (‚àÉx¬∑œà). A variable xin a formula œàis bound if it appears under the scope of a quantiÔ¨Åer. A variable not bound is free. A wÔ¨Ä with no free variables is c alled a sentence. For convenience, we often drop unnecessary parent hesis, and use ‚ä§to denote true and ‚ä•to denote false. An FOL interpretation Iover a domain Dassigns every kary predicate P a sortappropriate semantic interpretation I(P) :Dk‚Üí {T,F}; to everyk ary function fa sortappropriate interpretation I(f) :Dk‚ÜíD, and to every constantcan element I(c)‚ààD. Given an interpretation Iand a sentence œà, then either œàis true in I(denoted, I |=œà), orœàis false in I(denoted I /\e}a‚äîio\slash|=œà). The deÔ¨Ånition of the models relation is deÔ¨Åned on the structure of th e formula as usual, for example, I |= (œï‚àßœà) iÔ¨ÄI |=œïandI |=œà. We write I(Œ£‚Ä≤) to denote a restriction of an interpretation Ito a signature Œ£‚Ä≤‚äÜŒ£. Given disjoint signatures Œ£,Œ£‚Ä≤and corresponding interpretations I,I‚Ä≤ over a Ô¨Åxed domain D, we deÔ¨Åne I ‚äïI‚Ä≤to be an interpretation of Œ£‚à™Œ£‚Ä≤over domainDdeÔ¨Åned such that ( I ‚äïI‚Ä≤)(t) =I(t) ift‚ààŒ£, and (I ‚äïI‚Ä≤)(t) =I‚Ä≤(t) ift‚ààŒ£‚Ä≤. Given interpretation Iand subdomain D‚Ä≤‚äÜDwhereD‚Ä≤contains all constants, we let I(D‚Ä≤) be the interpretation restricted to domain D‚Ä≤. FOL modulo structures We use an extension of FOL to describe structures, namely graphs. In this case, the signature Œ£is extended with some predeÔ¨Åned functions and predicates, and the interpretations are restricte d to particular in tendedinterpretationsoftheseadditionstothesignature.Weide ntifyastructure classCwith its signature Œ£Cand an intended interpretation. We write FOLCfor First Order Logic over the structure class C. Common examples are FOL over strings, FOL over trees, and other Ô¨Ånite structures. A structure S= (D,I) is an intended interpretation Ifor structural predi cates/functions Œ£Cover an intended domain D. A set of structures is denoted C. The syntaxof FOLCis givenbythe syntaxforFOLwith signature Œ£‚äéŒ£C(where Œ£is an arbitrary disjoint signature). For semantics, any FOLinterpretation I of signature Œ£leads to an FOLCinterpretation I‚äïISof the signature Œ£‚äéŒ£C. We write |=CœïiÔ¨Ä everyFOLCinterpretation IsatisÔ¨ÅesI |=œï. We introduce a process sort Procand require the intended domain Dto be exactly the set of Procsorted elements, so that we put our intended structure on the p rocesses. First Order Transition Systems. We use First Order Transitions Systems from Ivy [15,14]. While the original deÔ¨Ånition was restricted to the EPR frag ment of 3FOL,wedonotrequirethis.Atransitionsystemisatuple Tr= (S,S0,R),where Sis a set of states, S0‚äÜSis a set of initial states, and R‚äÜS√óSis a transition relation. A trace œÄis a (Ô¨Ånite or inÔ¨Ånite) sequence of states œÄ=s0¬∑¬∑¬∑si¬∑¬∑¬∑such thats0‚ààS0and for every 0 ‚â§i <|œÄ|, (si,si+1)‚ààR, where|œÄ|denotes the length ofœÄ, or‚àûifœÄis inÔ¨Ånite. A transition system may be augmented with a setB‚äÜSof ‚Äúbad‚Äù states. The system is safe iÔ¨Ä all traces contain no bad states. A set of states Iis inductive iÔ¨Ä S0‚äÜIand ifs‚ààIand (s,s‚Ä≤)‚ààR, then s‚Ä≤‚ààI. Showing the existence of an inductive set Ithat is disjoint from bad set BsuÔ¨Éces to show a transition system is safe. A FirstOrder Transition System SpeciÔ¨Åcation (FOTSS) is a tuple ( Œ£,œï0,œÑ) whereŒ£is an FOL signature, œï0is a sentence over Œ£andœÑis a sentence over Œ£‚äéŒ£‚Ä≤, where‚äédenotes disjoint union and Œ£‚Ä≤={t‚Ä≤|t‚ààŒ£}. The semantics of a FOTSS are given by First Order Transition Systems (FOTS). Let Dbe a Ô¨Åxed domain. A FOTSS ( Œ£,œï0,œÑ) deÔ¨Ånes a FOTS over Das follows: S= {I | Iis an FOL interpretation over D},S0={I ‚ààS| I |=œï0}, andR= {(I1,I2)‚ààS√óS| I1‚äï I‚Ä≤ 2|=œÑ}, whereI‚Ä≤interpretsŒ£‚Ä≤. We may augment a FOTSS with a FOL sentence Bad, giving bad states in the FOTS by I ‚ààBiÔ¨Ä I/satisfiesBad. A FOTSS is safe if all of its corresponding FOTS Trare safe, and is unsafe otherwise. That is, an FOTSS is unsafe if there exists at leas t one FOTS corresponding to it that has at least one execution that reaches a bad state. A common way to show a FOTSS is safe is to give a formula Invsuch that |=œï0‚áíInvand|=Inv‚àßœÑ‚áíInv‚Ä≤. Then for any FOTS over domain D, the set I‚äÜSgiven byI={I ‚ààS| I |=Inv}is an inductive set, and |=Inv‚áí ¬¨Bad then suÔ¨Éces to show that the state sets I,Bin the FOTS are disjoint. Finding an invariant Invsatisfying the above proves the system safe. Example 1. Consider the following FOTSS: Œ£/defines{Even,+,1,var} œï0/definesEven(var) œÑ/defines(var‚Ä≤= (var+1)+1) ‚àßUnch(Even,+,1)Bad/defines¬¨Even(var) whereUnch(Even,+,1) means that Even, +, and 1 have identical interpreta tions in the pre and poststates of œÑ. Our intention is to model a program that starts with an even number in a variablevarand increments varby 2 at everytransition. It is an errorif varever becomes odd. A natural invariant to conjecture is Inv/definesEven(var). However, since the signature is uninterpreted, the FOTSS does not model ou r intention. For example, let D={0,1,2},I0(Even) ={1,2},I0(1) = 1, I0(+)(a,b) = a+bmod 3, and I0(var) = 1. Thus, I0|=œï0. LetI1be the same as I0, except I1(var) = 0. Then, I0‚äïI‚Ä≤ 1|=œÑandI1|=Bad. Thus, this FOTSS is unsafe. One wayto explicate ourintention in Example1 is to axiomatize the unint er preted functions and relations in FOL as part of œï0andœÑ. Another alternative is to restrict their interpretation by restricting the interpretatio n of FOL to a particular structure. This is the approach we take in this paper. We deÔ¨Åne a FirstOrder (relative to C) Transition System SpeciÔ¨Åcation (FOCTSS). 4We need to be able to talk about the structural objects in Œ£C, and so we requirethat everyFOCTSS ( Œ£,œï0,œÑ) be anFOTSS with Œ£C‚äÜŒ£. Oncewe have these structural objects, any structure ( D,I)‚àà Cgives a FOCTS with states IwhereI(Œ£C) =IC, initial states IwhereI |=œï0, transitions ( I1,I2) where I1‚äïI‚Ä≤ 2|=œÑ, and bad states Ifor which I |=Bad. 3 FirstOrder Protocols We introduce the notion of a FirstOrder Protocol (FOP) to simplify and re strict speciÔ¨Åcations in a FOTS. We choose restrictions to make our p rotocols asynchronous compositions of processes over static network to pologies. Each process description is relative to its process neighbourhood. For e xample, a pro cess operating on a ring has access to its immediate left and right neig hbours, and transitions are restricted to these processes. This simpliÔ¨Åes t he modelling. We begin with formalizing the concept of a network topology. As a run ning example, consider a RedBlackRing (RBR) topology, whose instanc e with 4 processes is shown in Fig. 2a. Processes are connected in a ring of a lternating Red and Black processes. Each process is connected to two neighb ours using two links, labelled leftandright, respectively. From the example it is clear how to extend this topology to rings of arbitrary even size. To formalize this, we assume that there is a unique sort Procfor processes. DeÔ¨ÅneŒ£C=Œ£C E‚äéŒ£C Tto be atopological signature , whereŒ£C Eis a set of unary Procsorted functions and Œ£C Tis a set of distinct karyProcsorted predicates (kÔ¨Åxed). Functions in Œ£C Ecorrespond to communication edges, such as leftand rightin our example. Predicates in Œ£C Tcorrespond to classes of processes, such asRedandBlackin our example. For simplicity, we assume that all classes have the same arity k. We often omit kfrom the signature when it is contextually clear. We are now ready to deÔ¨Åne the concept of a network topolog y: DeÔ¨Ånition 1. Anetwork topology Cover a topological signature Œ£Cis a col lection of directed graphs G= (V,E)augmented with an edge labelling dir : E‚ÜíŒ£C Eandknode labelling kind :Vk‚ÜíŒ£C T. Given a node pin a graph G= (V,E)from a network topology C, the neighbourhood of pis deÔ¨Åned as nbd(p) ={p}‚à™{q|(p,q)‚ààE}, and a neighbourhood of a tuple p= (p1,...,p k) is deÔ¨Åned as nbd (p) =/uniontextk i=1nbd(pi). A network topology is deterministic if for every distinct pair q,r‚àànbd(p)\{p}, dir(p,q)/\e}a‚äîio\slash=dir(p,r). That is, each neigh bour ofpcorresponds to a distinct name in Œ£E. Given the signatures Œ£C TandŒ£C E, the intended interpretation of a predicate P‚ààŒ£C Tis the set of all nodes in the network topology labelled by P, and the intended interpretation of a function f‚ààŒ£C Eis such that f(p) =qif an edge (p,q) is labelled by fandf(p) =p, otherwise. Each graph Gin a network topology Cprovides a possible intended interpre tation for the sort of processes Proc, and the edge and node labelling provide the intended interpretation for predicates and functions in Œ£C. Example 2. For our running example, consider an informal description of the protocol shown in Fig. 2b described by a set of guarded commands. The protocol 5p2 0 p2 1 p2 2 p2 3Black Red (a) RedBlackRing of 4 process. Dashed arrows are right, and solid are left.Init:var:=null Tr:black‚áíright.var:=r red‚áíright.var:=b Bad:red‚àßvar=b (b) A simple protocol over RedBlack Ring topology. Fig.2: An example of a topology and a protocol. is intended to be executed on the RBR topology shown in Fig. 2a. Initia lly, all processes start with their state variable varset to a special constant null. Then, at each step, a nondeterministically chosen process, sends a colo r to its right. Every black process sends a red color r, and every red process sends a black colorb. It is bad if a Red process ever gets a black color. To formalize the topology, for each n >1, letGn= (Vn,En), whereVn= {pn i|0‚â§i<2n}, andEn={(pn i,pn j)| |i‚àíj|mod 2n= 1}. The edge labelling is given by dir(pn i,pn j) =rightifj= (i+1) modnandleftifj= (i‚àí1) modn. Processes have colour kind(pn i) =Redifiis even, and Blackifiis odd. Finally, we deÔ¨Åne RBR={Gn|n‚â•2}as the class of RedBlack Rings (RBR). ‚äì ‚äî Note that any set of graphs Gwith an upper bound on the outdegree of any vertex can be given a Ô¨Ånite labelling according to the above. FirstOrder Protocols. Once we have speciÔ¨Åed the topology, we want to establish how processes transition. We deÔ¨Åne the syntax and semantics of a protocol. A protocol signature Œ£is a disjoint union of a topological signature Œ£C, a state signature Œ£S, and a background signature Œ£B. Recall that all functions and relations in Œ£Care of sort Proc. All elements of Œ£Shave arity of at least 1 with the Ô¨Årst and only the Ô¨Årst argument of sort Proc. Elements of Œ£Bdo not allow arguments of sort Procat all. Intuitively, elements of Œ£Cdescribe how processes are connected, elements of Œ£Sdescribe what is true in the current state of some process, and elements of Œ£Bprovide background theories, such as laws of arithmetic and uninterpreted functions. For an interpretation I, and a set of processes P‚äÜ I(Proc), we write I(Œ£S)(P) for the interpretation I(Œ£S) restricted to processes in P. Intuitively, we look only at the states of Pand ignore the states of all other processes. DeÔ¨Ånition 2. AFirstOrderProtocol (FOprotocol) is a tuple P= (Œ£,Init(p), Mod(p),TrLoc(p),C), whereŒ£is a protocol signature; pis a free variable of sort Proc, Init(p)is a formula with kfree variables pof sort Proc; Mod(p) is a set of terms {t(p)|t‚ààdir(E)} ‚à™ {p};TrLoc(p)is a formula over the signatureŒ£‚à™Œ£‚Ä≤, andCis a network topology. Furthermore, Init(p)is of the form/logicalandtext P‚ààŒ£T(P(p)‚áíInitP(p)), where the arity of Pis|p|, and eachInitPis a formula over Œ£\Œ£C(an initial state described without reference to topology for each relevant topological class); and terms of sort Proc occurring in TrLoc (p) are a subset of Mod (p). 6Const={null/0,r/0,b/0}Func={left/1,right /1,var/1} Pred={Red/1,Black /1,=/2}Œ£= (Const,Func,Pred) Init(p) = (Red(p)‚áívar(p) =null)‚àß(Black(p)‚áívar(p) =null) Mod(p) ={p,right(p),left(p)} tr(p) =var‚Ä≤(right(p)) =b‚àßvar‚Ä≤(p) =var(p)‚àßvar‚Ä≤(left(p)) =var(left(p)) tb(p) =var‚Ä≤(right(p)) =r‚àßvar‚Ä≤(p) =var(p)‚àßvar‚Ä≤(left(p)) =var(left(p)) TrLoc(p) = (Red(p)‚áítr(p))‚àß(Black(p)‚áítb(p)) Fig.3: A FOprotocol description of the system from Fig. 2. œï0/defines‚àÄp¬∑Init(p)œÑ/defines‚àÉp¬∑TrLoc(p)‚àßFrame(p) Frame(p)/definesUnMod ‚àß(‚àÄy¬∑y/ne}ationslash‚ààMod(p)‚áíUnch(y))) Unch(y)/definesÔ£´ Ô£≠/logicalanddisplay P‚ààPredS‚àÄv¬∑P(y,v)‚áê‚áíP‚Ä≤(y,v)Ô£∂ Ô£∏‚àßÔ£´ Ô£≠/logicalanddisplay f‚ààFuncS‚àÄv¬∑f(y,v) =f‚Ä≤(y,v)Ô£∂ Ô£∏ UnMod /definesÔ£´ Ô£≠/logicalanddisplay P‚ààPredB‚àÄv¬∑P(v)‚áê‚áíP‚Ä≤(v)Ô£∂ Ô£∏‚àßÔ£´ Ô£≠/logicalanddisplay f‚ààFuncB‚àÄv¬∑f(v) =f‚Ä≤(v)Ô£∂ Ô£∏ Fig.4: An FOTS of the protocol in Fig. 3. A formal description of our running example is given in Figure 3 as a FO protocol. We deÔ¨Åne the signature including Œ£C={left,right,Red,Black}, the initial states Init(p) in the restricted form, and modiÔ¨Åcation set Mod(p), where we allow processes to only write to their local neighbourhood. Next w e spec ify two kinds of transitions, a red trand a black tbtransition. Each writes to their right neighbour the colour they expect that process to be. E ach process pdoes not change the varstates ofp,left(p)‚ààMod(p). Finally, we specify our local transitions TrLoc(p) by allowing each of the subtransitions. Note that all processsorted terms in TrLoc(p) are inMod(p) ={left(p),p,right(p)}, and we are allowed to call on topological predicates in TrLoc, Ô¨Ånishing our speciÔ¨Åcation. Furthermore, note that the semantic local neighbourhood nbd(p) and the set ofsyntactic terms inMod(p) have been connected. Namely, for every edge (p,q)‚ààE, there is a term t(p)‚ààMod(p) to refer to q, and for every term t(p)‚ààMod(p), we will refer to some process in the neighbourhood of p. The semantics of a protocol Pare given be an FOCTSS as shown in Fig. 4. The protocol signature Œ£is the same in the FOCTSS as in the FOP. Initially, œï0requires that all ktuples of a given topology satisfy a topologyspeciÔ¨Åc ini tial state. Finally, to take a transition œÑ, some process takes a local transition TrLoc(p) modifying states of processes that can be described using the te rms inMod(p).Unch(y) guarantees that the transition does not aÔ¨Äect local state of processes that are outside of Mod(p). Finally,UnMod makes all functions and predicates in the background signature retain their interpretatio n during the transition. Overall, this describes a general multiprocess asynchr onous protocol. 7This deÔ¨Ånition of a FOprotocol places some added structure on th e notion of FOTSS. It restricts how transition systems can be speciÔ¨Åed, wh ich might seem like a drawback. On the contrary, the added structure prov ides two bene Ô¨Åts. First, it removes the need for axiomatizing the network topolo gy, since the topology is given semantically by C. Second, the system guarantees to model asynchronous composition of processes whose local transition re lation is given byTrLoc‚Äì a common framework for specifying and reasoning about protoco ls. To show safety of such a system, we will be concerned with invariant s which only discuss a few processes, say Inv(p) where p=p1,...,p k. Then our FO invariants will be of the form ‚àÄp¬∑Inv(p), and substituting œï0into our back ground, we Ô¨Ånd a natural check for when a given formula is inductive : InvOk/defines((‚àÄp¬∑Init(p))‚áí(‚àÄp¬∑Inv(p)))‚àß((‚àÄp¬∑Inv(p))‚àßœÑ‚áí(‚àÄp¬∑Inv‚Ä≤(p))) Indeed, by unpackingdeÔ¨Ånitions, one seesthat |=CInvOkmeans that everystate on any trace of a FOCTS satisÔ¨Åes ‚àÄp¬∑Inv(p), and thus it suÔ¨Éces to check that |=C‚àÄp¬∑Inv(p)‚áí ¬¨Badto prove safety. We, however, will focus on the task of verifying a candidate formula as inductive or not. To decide if a candidate is inductive or not requires reasoning in FOLC. How ever, reasoning about FOL extended with an arbitrary topology is d iÔ¨Écult (or undecidable in general). We would like to reduce the veriÔ¨Åcationproble m to pure FOL. One solution is to axiomatize the topology in FOL ‚Äì this is the appro ach taken by Ivy[15]. Another approachis to use properties of the top ology to reduce reasoning about FOprotocols to FOL. This is similar to the use of top ology to reduce reasoning about parameterized Ô¨Ånitestate systems to r easoning about Ô¨Ånite combinations of Ô¨Ånitestate systems in [11]. In the next sectio n, we show how this approach can be extended to FOprotocols. 4 Verifying FOProtocols using First Order Logic In this section, we present a technique for reducing veriÔ¨Åcation of FOprotocols over a given topology Cto a decision problem in pure FOL. We assume that we are given a (modular) inductive invariant ‚àÄq¬∑Inv(q) of the form/parenleftBig ‚àÄq¬∑/logicalandtext Top‚ààŒ£C TTop(q)‚áíInvTop(q)/parenrightBig . That is, Invhas a local inductive invari antInvTop(q)for each topological class Top. Given a FirstOrder Protocol and candidate invariant, we want to k now if |=FOLCInvOk. But deciding thisis hard,andsoweshowthat deciding validityof InvOkcanbe donein pureFOLusingmodularveriÔ¨Åcationconditionsinthesty le of OwickiGries [13] and Paramaterized Compositional Model Checkin g [11]. The input to our procedure is a formula InvTopover signature Œ£B‚äéŒ£Sfor each topological class Top‚ààŒ£C T. The VC is a collection of sentences ensuring that for each tuple of processes qin a topological class Top,InvTop(q) is true initially, is stable under a transition of one process in q, and is stable under interference by any other process pwhose execution might aÔ¨Äect some qi‚ààq. If the VC is FOLvalid, an inductive invariant has been found. If not, th ere will be a local violation to inductiveness, which may correspond to a global v iolation. 8Formally, the VC is a collection of statements of the following two form s: ‚àÄq¬∑(CrossInit Top(q)‚áíInvTop(q)) (1) ‚àÄp,q¬∑((CrossInv Top(Mod(p),q)‚àßœÑ)‚áíInv‚Ä≤ Top(q)) (2) Statements of the Ô¨Årst form require that every local neighbourh ood ofqthat satisÔ¨Åesallappropriateinitial statesalsosatisÔ¨Åes q‚Äôs invariant.Statementsofthe second form capture both transitions where p=qifor somei, or process pacts and modiÔ¨Åes qi‚àànbd(p), sincepis quantiÔ¨Åed universally. All that remains is to formally construct the statements CrossInit,CrossInv . In order to do so, we will construct a characteristiclocal neighbourhood of a process tup leq. We will want to use a similarconstruction for both, and sogeneralizeto the char acteristicthat qmust satisfy in addition to other processes given by an arbitrary se tA. We will say that formula œàis a valid candidate for œáTop(A,q) when it is (1) over signature Œ£T‚à™Œ£E‚à™ {=}, (2) contains only terms A‚à™{qi|qi‚ààq}, and (3) is in CNF and all literals from Œ£Tappear in positive form. Intuitively, we will want to capture when elements of A,qsatisfy various topological notions given by signature Œ£E‚à™{=}. We also never want to force some processes to be outside of some topological class. We let œáTop(A,q) be the strongest candidate that satisÔ¨Åes |=C‚àÄq¬∑Top(q)‚áíœáTop(A,q). Intuitively, œáis a formula that cap tures all topological knowledge derivable from the topology given th at we know thatTop(q) holds. For instance, in RBR, we haveœáRed(‚àÖ,q) =Red(q), while expanding this for A={left(p),p,right(p)}results in the following formula. œáRed({left(p),p,right(p)},q) =Red(q)‚àßdistinct(left(p),p,right(p))‚àß ((Red(left(p))‚àßBlack(p)‚àßRed(right(p))‚àßp/\e}a‚äîio\slash=q)‚à® (Black(left(p))‚àßRed(p)‚àßBlack(right(p))‚àßdistinct(left(p),right(p),q))) These characteristics are illustrated in Figure 5. When we just look a t œáRed(‚àÖ,q),weÔ¨Åndqisred.However,ifweexpandourlocalreasoningtothe char acteristicœáRed(Mod(p),q),weÔ¨Åndthattherearetwooptionsgivenby RBR.One option ispis red, andq=pis optional (dotted lines), while q/\e}a‚äîio\slash=left(p),right(p). Alternatively, pis black, and q/\e}a‚äîio\slash=p, butqcould be left(p),right(p), or neither. Once we have œáTop(A,q), we can deÔ¨Åne our statements CrossInit Top, CrossInv Top. First,CrossInit Top(q) is obtained from œáTop(‚àÖ,q) by replacing ev ery instance of Top‚Ä≤ i(q) withInit‚Ä≤ Topi(q). We build our interference constraints in a similar way. We construct CrossInv Top(q) by modifying œáTop(Mod(p),q). Namely, we obtain CrossInv Top(Mod(p),q) fromœáTop(Mod(p),q) by replacing every instance of Top‚Ä≤ i(q) withTop‚Ä≤ i(q)‚àßInv‚Ä≤ Topi(q). Example 3. The VC generated by the RBRtopology may be partitioned into VCRedandVCBlack, each consisting of the statements whose conclusions are InvRed,Inv‚Ä≤ RedandInvblack,Inv‚Ä≤ black, respectively. VCRedis shown in Fig. 6. The conditions for VCBlackare symmetric. One can check that Invred(p)/definesvar(p)/\e}a‚äîio\slash=b Invblack(p)/defines‚ä§ is an inductive invariant for the protocol in Fig. 2. ‚äì ‚äî 9p q l(p) r(p)qpl(p) r(p)qBlack Red Fig.5: Characteristics œáRed(‚àÖ,q) andœáRed(Mod(p),q) for the RBRtopology. ‚àÄp¬∑Initred(p)‚áíInvred(p) (3) ‚àÄp,q¬∑(Red(q)‚àßInvred(q)‚àßRed(left(p))‚àßInvred(left(p))‚àß Black(p)‚àßInvblack(p)‚àßRed(right(p))‚àßInvred(right(p))‚àß p/ne}ationslash=q‚àßdistinct(left(p),p,right(p)))‚áíInv‚Ä≤ red(q) (4) ‚àÄp,q¬∑(Red(q)‚àßInvred(q)‚àßBlack(left(p))‚àßInvblack(left(p))‚àß Red(p)‚àßInvred(p)‚àßBlack(right(p))‚àßInvblack(right(p))‚àß distinct(left(p),right(p),q)‚àßdistinct(left(p),p,right(p)))‚áíInv‚Ä≤ red(q) (5) VCP,1(Invred,Invblack)/defines(3)‚àß(4)‚àß(5) (6) Fig.6: The veriÔ¨Åcation conditions VCRedfor the red process invariant. In practice, the role of the oracle can be Ô¨Ålled by a veriÔ¨Åcation engine er. A description of local neighbourhoods starts by allowing all possible ne ighbour hoods, and as counterexamples disallowed by the topology occur, a veriÔ¨Åer may dismiss local conÔ¨Ågurations that cannot occur on the topology. 5 Soundness and Completeness Inthissection,wepresentsoundnessandrelativecompletenesso fourveriÔ¨Åcation procedure from Section 4. Soundness. To show soundness, we present a modeltheoretic argument to sh ow that whenever the veriÔ¨Åcation condition from Section 4 is valid in FOL, then the condition InvOkis valid in FOL extended with the given topology C. Theorem 1. Given a FOprotocol Pand a local invariant per topological class InvTop1(p),...,InvTopn(p), if/satisfiesVC(Inv), then/satisfiesCInvOk(Inv). Proof.We show that InvOk(Inv) is valid in FOLCby showing that any pair of FOLCinterpretations IandI‚Ä≤satisfyVC(Inv) as FOL interpretations, and this is strong enough to guarantee I ‚äïI‚Ä≤|=InvOk(Inv). LetI,I‚Ä≤beFOLCinterpretations over some G= (V,E)‚àà C. ThenI‚äïI‚Ä≤|= VC(Inv) becauseVC(Inv) is valid and I ‚äïI‚Ä≤is an FOL interpretation. We Ô¨Årst show that I |= (‚àÄp¬∑Init(p)‚áí ‚àÄp¬∑Inv(p)). Suppose that I/satisfies‚àÄp¬∑Init(p). Letpbe an aribtrary tuple in G. IfI |=¬¨Topi(p) for every Topi‚ààŒ£T, thenInv(p) follows vacuously. Otherwise, suppose I |=Topi(p). Then by deÔ¨Ånition of œá, we obtain I |=œáTopi(‚àÖ,p) sinceI |=Topi(p)‚áí œáTopi(p). SinceI |=‚àÄp¬∑Init(p), this gives us that I |=CrossInit (p) (for any Topj(p‚Ä≤) inœáTopi(p), Ô¨Ånd that Init(p‚Ä≤), and thus Topj(p‚Ä≤) implies InitTopj(p‚Ä≤), givingCrossInit ). Since I |=CrossInit Topi(p) andI |=VC, we get I |= CrossInit Topi(p)‚áíInvTopi(p), Ô¨Ånally giving us I |=InvTopi(p), as desired. 10Second, we show that I ‚äï I‚Ä≤|= (‚àÄp¬∑Inv(p))‚àßœÑ‚áí(‚àÄp¬∑Inv(p)). Suppose thatI |=‚àÄp¬∑Inv(p) andI ‚äï I‚Ä≤|=TrLoc(p)‚àßFrame(p) for some p‚ààV. We show that I‚Ä≤|=‚àÄq¬∑Inv‚Ä≤(q). Letq‚ààVkbe an arbitrary process tuple. IfI‚Ä≤/\e}a‚äîio\slash|=Topi(q) for all 1 ‚â§i‚â§n, thenI‚Ä≤|=Inv‚Ä≤(q) vacuously. Suppose I‚Ä≤|=Topi(q) for some Topi‚ààŒ£T. ThenI |=Topi(q)‚áíœáTopi(Mod(p),q), and soI |=œáTopi(Mod(p),q). Again by instantiating ‚àÄp¬∑Inv(p) on terms in Mod(p),q, we may obtain that I |=CrossInv (Mod(p),q). Combined, we have I ‚äïI‚Ä≤|=CrossInv (Mod(p),q)‚àßœÑ. Applying VCÔ¨Ånally gives InvTopi(q).‚äì ‚äî Intuitively, the correctness of Theorem 1 follows from the fact th at any inter pretation under FOLCis also an interpretation under FOL, and all preconditions generated for VC are true under FOLCinterpretation. Small model property. Checking validity of universally quantiÔ¨Åed statements in FOL is in the fragment EPR, and thus we obtain a result saying that we only need to consider models of a given size. This means that a FOL solver n eeds to only reason about Ô¨Ånitely many elements of sort Proc. It further means that topologies such as RBRmay be diÔ¨Écult to compile to EPR in Ivy, but our methodology guarantees our veriÔ¨Åcations will be in EPR. Theorem 2. If|=VC(Inv)for all process domains of size at most |Mod(p)|+k, then|=CInvOk(Inv). Proof.By contrapositive, suppose /\e}a‚äîio\slash/satisfiesCInvOk(Inv). Then, by Theorem 1, /\e}a‚äîio\slash|= VC(Inv). LetI ‚äï I‚Ä≤be a falsifying interpretation. It contains an assignment toMod(p) andq, or topthat makes at least one statement in VC(Inv) false. Then, (I ‚äïI‚Ä≤)(Mod(p)‚à™q) orI(p)Mod(p),qorpto make some statement in VCunsatisÔ¨Åable. Then I ‚äïI‚Ä≤(Mod(p)‚à™q) orI(p) is also a countermodel to VC(Inv), but with at most |Mod(p)|+kelements of sort Proc. Relative Completeness. We show that our method is relatively complete for local invariants that satisfy the completability condition. Let œï(p) be a formula of the form/logicalandtextn i=1(Topi(p)‚áíœïTopi(p)) withœïTopi(p) over the signature Œ£S‚à™ Œ£B. Intuitively, œï(p) iscompletable if every interpretation Ithat satisÔ¨Åes ‚àÄp¬∑ œï(p) and is consistent with some Cinterpretation IGcan be extended to a fullCinterpretation (not necessarily IG) that satisÔ¨Åes ‚àÄp¬∑œï(p). Formally, œïis completable relativeto topology CiÔ¨Ä for everyinterpretation Iwith domain U‚äÜ VforG= (V,E)‚àà Cwithanintendedinterpretation IGsuchthat( I‚äéIG)(U)|= ‚àÄp¬∑œï(p), there exists an interpretation Jwith domain Vs.t. (J ‚äé I G)|= ‚àÄp¬∑œïandI(U) =J(U). Furthermore, we need a lemma expressing that the chacteristic formula œáTop(A,q) captures all the information we care about for a given topological neighbourhood of A,q. Lemma 1. If FOL interpretation Iof signature Œ£CsatisÔ¨Åes I |=œáTop(A,q), then there exists a Cinterpretation Jof the same signature with J |=œáTop(A,q) andI |=ti=tjiÔ¨ÄJ |=ti=tjfor termsti,tj‚ààA‚à™q. Proof.LetI |=œáTop(A,q).Letœï(A,q)bethe conjunctionofallatomicformulae over the signature {=}and statements ¬¨Topj(q‚Ä≤) that is true of elements of A,q in interpretation I. IfnoCinterpretation J |=Top(q)‚àßœï(A,q), then we canadd 11the clause ¬¨œï(A,q) toœáTop(A,q), thus strengthening it (this is stronger since I |=Top(q),/\e}a‚äîio\slash|=¬¨œï(A,q), and is true of every interpretation modelling Top(q)). However, this violates the assumptions that œáTopis as strong as possible. Thus, someJ |=Top(q)‚àßœï(A,q). Note that Jalready satisÔ¨Åes ti=tjiÔ¨ÄIsatisÔ¨Åes ti=tjsince every statement of = ,/\e}a‚äîio\slash= is included in œï(A,q). Finally, since Jis aCinterpretation and I‚Ä≤|=Top(q), thenI‚Ä≤|=œáTop(A,q) by deÔ¨Ånition. ‚äì ‚äî Theorem 3. Given an FOprotocol P, if|=CInvOk(Inv)and bothInv(p)and Init(p)are completable relative to C, then|=VC(Inv). Proof.By contrapositive, we show that given a completable local invariant Inv(p), ifVC(Inv) is falsiÔ¨Åable in FOL, thenInvOk(Inv) is falsiÔ¨Åable in FOLC. SupposeVC(Inv) is not valid, and let I ‚äïI‚Ä≤by such that I ‚äïI‚Ä≤/\e}a‚äîio\slash|=VC(Inv). We consider two cases ‚Äì a violation initially or inductively. Case 1: Initialization: For some processes p=/a\}bracke‚äîle{‚äîp1,...,p k/a\}bracke‚äîri}h‚äîand 1‚â§i‚â§ |Œ£C T|, I |=CrossInit Topi(p) andI /\e}a‚äîio\slash|=InvTopi(p). Modify I(Œ£T) for every qso that Topj(q) is interpreted to be true iÔ¨Ä InitTopj(q) is true. Noting that all invariants and initial conditions are outside of the signature Œ£T, we observe that this is done without loss of generality. Since I |=CrossInit Topi(p), we conclude now thatI |=œá‚àÖ,Topi(p). Applying Lemma 1 to I(Œ£C), we get a Cinterpretation J |=œáTopi(‚àÖ,pC). Since this model has the same equalities of terms pCin JaspinI, we may copy the states I(Œ£S)(pi) toJ(Œ£S)(pi). SetJ(Œ£B) = I(Œ£B). SinceInitis completable by assumption, we complete J(Œ£S‚à™Œ£B)(p) toJ(Œ£S‚à™Œ£B), completing our construction of Jinterpreting Œ£C‚à™Œ£S‚à™Œ£B. Note that J |=‚àÄp¬∑Init(p), butJ |=¬¨Topi(pC)‚àßInvTopi(pC), thus showing thatInvOk(Inv) is falsifable in FOLC. Case 2: Inductiveness: For somep,q, and 1 ‚â§i‚â§ |Œ£C T|, we have I |= CrossInv Topi(Mod(p),q), (I‚äïI‚Ä≤)|=TrLoc(p)‚àßFrame(p), andI‚Ä≤/\e}a‚äîio\slash|=InvTopi(q). By construction, |=CrossInv (Mod(p),q)‚áíœáTopi(Mod(p),q). Applying Lemma 1 toI(Œ£C)|=œáTopi(Mod(p),q), we get a Cinterpretation of Œ£C TwhichJ |= œáTopi(Mod(pC),qC). We extend this to a full model Jofsignature Œ£C‚à™Œ£S‚à™Œ£B. We setJ‚Ä≤(Œ£C) =J(Œ£C). Then, since JandI, andJ‚Ä≤andI‚Ä≤share equalties across terms in Mod(p)‚à™qandMod(pC)‚à™qC, we can lift states from terms t‚ààMod(p)‚à™qbyJ(Œ£S‚à™Œ£B)(tC)/definesI(Œ£S‚à™Œ£B)(t)andJ‚Ä≤(Œ£S)(tC)/definesI‚Ä≤(Œ£S)(t). SinceInvis completable, we complete this interpretation with J(Œ£S‚à™Œ£B) and clone the completion to J‚Ä≤(Œ£S‚à™Œ£B)(V\(Mod(p)‚à™q)). Overall, this completes the interpretations J ‚äïJ‚Ä≤. Note that J |=‚àÄp¬∑Inv(p) by construction. Similarly, J ‚äï J‚Ä≤|=œÑsince I ‚äïI‚Ä≤|=œÑ(p) andMod(p) terms are lifted directly from IandI‚Ä≤toJandJ‚Ä≤. Finally,J‚Ä≤|=¬¨InvTopi(q) sinceJ‚Ä≤(Œ£S) is lifted directly from I‚Ä≤(Œ£S), which is the language of invariants. Thus, we have shown that InvOk(Inv) is falsiÔ¨Åable inFOLCin this case as well. ‚äì ‚äî How restrictive is the requirement of completability ? Intuitively, if a protocol is very restrictive about how processes interact, then the syste m is likely suf Ô¨Åciently intricate that trying to reason locally may be diÔ¨Écult independ ant of our methodology. For instance, the invariant we later Ô¨Ånd for leade r election is 12not completable. However, if equivalence classes are small, then mos t reasonable formulae satisfy the completability condition. Theorem 4. If Inv Topi(p)is satisÔ¨Åable over any domain for each 1‚â§i‚â§n and topological predicates are of arity k= 1, then Inv (p)is completable. Proof.LetInvi(p) be satisÔ¨Åable for each 1 ‚â§i‚â§n. Then let I(V‚Ä≤) be an interpretation of Œ£B‚äéŒ£Sover domain V‚Ä≤‚äÜVforG= (V,E)‚àà C. For each p‚ààV\V‚Ä≤, suppose IG|=Topi(p) for some 1 ‚â§i‚â§n. Then choose J(p)|= InvTopi(p) sinceInvTopi(p) is satisÔ¨Åable. Otherwise, if IG/\e}a‚äîio\slash|=Topi(p) for all 1‚â§i‚â§n, thenJ(p) is chosen arbitrarily. In either case, J |=Inv(p). Finally, deÔ¨ÅneJ(p) =I(p) forp‚ààV‚Ä≤. ThenJcompletes the partial interpretation I. Theorem 4 can be generalized to the case where the topological kind sŒ£T are nonoverlapping, and individually completable, where by individually com pletable, we mean that if Top(p) and process states of p‚Ä≤‚äÇpare given, then there is a way to satisfy Inv(p) without changing the states of p‚Ä≤. 6 Example: Leader Election Protocol In thissection,we illustrateourapproachbyapplyingit tothe wellkn ownleader election protocol [2]. This is essentially the same protocol used to illus trate Ivy in[15].Thegoaloftheprotocolistochoosealeaderonaring.Eachp rocesssends messages to its neighbour on one side and receives messages from a neighbour on the other side. Initially, all processes start with distinct identiÔ¨Åe rs,id, that are totally ordered. Processes pass ids around the ring and declare themselves the leader if they ever receive their own id. We implement this behaviour by providing each process a comparison v ari ablecomp. Processes then pass the maximum between idandcompto the next process. A process whose idandcomphave the same value is the leader. The desiredsafetypropertyisthatthereisnevermorethanoneleade rintheprotocol. In [15], the protocol is modelled by a global transition system. The sy stem maintains a bag of messages for each process. At each step, a cur rently waiting message is selected and processed according to the program of th e protocol. The network topology is axiomatized, as shown in Section 1. Here, we pre sent a local model of the protocol and its corresponding veriÔ¨Åcation condition . Network topology. The leader election protocol operates on a ring of size at least 3. For n‚â•3, letGn= (Vn,En), whereVn={pn i|0‚â§i < n}and En={(pn i,pn j)|0‚â§i < n,j =i+ 1 modn}. LetŒ£E={next}andŒ£T= {btw}, wherebtwis a ternary relation such that btw(pn i,pn j,pn k) iÔ¨Äi < j < k , j <k<i , ork<i<j . Finally, the network topology is BT W={Gn|n‚â•3}. Note that while BT Wcan be axiomatized in FOL, we do not require such an axiomatization. The deÔ¨Ånition is purely semantic, no theorem prover sees it. A formal speciÔ¨Åcation of the leader election as an FOprotocol is sh own in Fig. 7, where LO(‚â§) is an axiomatization of total order from [15], and x < y standsforx‚â§y‚àßx/\e}a‚äîio\slash=y.Themodel followscloselytheinformaldescriptionofthe protocol given above. The safety property is ¬¨Bad, whereBad=btw(x,y,z)‚àß id(x) =comp(x)‚àßid(y) =comp(y). That is, a bad state is reached when two processes that participate in the btwrelation are both leaders. 13Const/defines{0/0}Func/defines{next/1,id/1,comp/1}Pred/defines{‚â§/2,=/2,btw/3} C/definesBT W Œ£/defines(Const,Func,Pred)LO0(‚â§)/definesLO(‚â§)‚àß‚àÄx¬∑0‚â§xMod(p)/defines{p,next(p)} Init(p)/defines(LO0(‚â§)‚àßbtw(x,y,z)‚áí(distinct(id(x),id(y),id(z))‚àß0< id(x)‚àßcomp(x) = 0)) œÑ1(p)/defines/parenleftbig id(p)‚â§comp(p)‚áí/parenleftbig comp‚Ä≤(next(p)) =comp(p)/parenrightbig/parenrightbig œÑ2(p)/defines/parenleftbig comp(p)‚â§id(p)‚áí/parenleftbig comp‚Ä≤(next(p)) =id(p)/parenrightbig/parenrightbig TrLoc(p)/defines/parenleftbig id(p) =id‚Ä≤(p)‚àßcomp(p) =comp‚Ä≤(p)‚àßid‚Ä≤(next(p)) =id(next(p))‚àßœÑ1(p)‚àßœÑ2(p)/parenrightbig Fig.7: A model of the Leader Election protocol as a FOprotocol. (btw(x,y,z)‚àßid(y) =comp(x))‚áí(id(z)‚â§id(y)) (btw(x,y,z)‚àßid(x) =comp(x))‚áí(id(y)‚â§id(x)‚àßid(z)‚â§id(x)) (btw(x,y,z)‚àßid(x) =comp(x)‚àßid(y) =comp(y))‚áíx=y Fig.8: Local inductive invariant Invlead(x,y,z) for Leader Election from Fig. 7. A local invariant Invleadbased on the invariant from [15] is shown in Fig. 8. TheinvariantÔ¨Årstsaysifan idpassesfrom ytoxthroughz,then it mustwitness id(y)‚â•id(z) to do so. Second, the invariant says that if a process is a leader, then it has a maximum id. Finally, the invariant asserts our safety pro perty. This invariant was found interactively with Ivy by seeking local violatio ns to the invariant. Our protocol‚Äôs btwis uninterpreted, while Ivy‚Äôs btwis explic itly axiomatized. The inductive check assumes that the processes p,next(p),q all satisfy a Ô¨Ånite instantiation of the ring axioms (this could be done b y the developer as needed if an axiomatization is unknown, and this is guara nteed to terminate as there are Ô¨Ånitely many relevant terms), and btw(q). Once the invariants are provided, the check of inductiveness is mechanical. O verall, this presents a natural way to model protocols for engineers that re ason locally. An uncompletable invariant The invariant for the leader election is not com pletable. To see this, we present a partial interpretation Iover{p3 0,p3 2} ‚äÜV3 fromG3with no extension. We choose I(‚â§) to be‚â§overN, as intended. Then we choose I(id) to mapp3 0/maps‚äîo‚Üí1 andp3 2/maps‚äîo‚Üí2. We also choose I(comp) to map p3 0/maps‚äîo‚Üí0 andp3 2/maps‚äîo‚Üí1. Since no tuple satisÔ¨Åes btw, this vacuously satisÔ¨Åes all in variants thus far. Let Jbe anBT Winterpretation agreeing on p3 0,p3 2. Consider id(p3 1). We know id(p3 1)/\e}a‚äîio\slash= 0,1,2 since we require distinct ids across the new btw relation. But we also have id(p3 0) =comp(p3 2) and thus to satisfy Invwe must haveid(p3 0)‚â•id(p3 1). Thus we seek an n‚ààNsuch that 1 ‚â•n, butn/\e}a‚äîio\slash= 0,1, which cannot exist. Thus Invis uncompletable. 7 Related Work "
212,DeepSafe: A Data-driven Approach for Checking Adversarial Robustness in Neural Networks.txt,"Deep neural networks have become widely used, obtaining remarkable results in
domains such as computer vision, speech recognition, natural language
processing, audio recognition, social network filtering, machine translation,
and bio-informatics, where they have produced results comparable to human
experts. However, these networks can be easily fooled by adversarial
perturbations: minimal changes to correctly-classified inputs, that cause the
network to mis-classify them. This phenomenon represents a concern for both
safety and security, but it is currently unclear how to measure a network's
robustness against such perturbations. Existing techniques are limited to
checking robustness around a few individual input points, providing only very
limited guarantees. We propose a novel approach for automatically identifying
safe regions of the input space, within which the network is robust against
adversarial perturbations. The approach is data-guided, relying on clustering
to identify well-defined geometric regions as candidate safe regions. We then
utilize verification techniques to confirm that these regions are safe or to
provide counter-examples showing that they are not safe. We also introduce the
notion of targeted robustness which, for a given target label and region,
ensures that a NN does not map any input in the region to the target label. We
evaluated our technique on the MNIST dataset and on a neural network
implementation of a controller for the next-generation Airborne Collision
Avoidance System for unmanned aircraft (ACAS Xu). For these networks, our
approach identified multiple regions which were completely safe as well as some
which were only safe for specific labels. It also discovered several
adversarial perturbations of interest.","In recent years, advances in deep neural networks (NN) have enabled the representation and modeling of complex nonlinear relationships. In this paper, we study a common use of NN as classiÔ¨Åers that take in complex, high dimensional input, pass it through multiple layers of transformations, and Ô¨Ånally assign to it a speciÔ¨Åc output label or class. Such classiÔ¨Åers have been used in a variety of applications, including pattern analysis, image classiÔ¨Åcation, speech and audio recognition, and selfdriving cars; it is expected that this trend will continue and intensify, with neural networks also being integrated into safetycritical systems which require high assurance guarantees.arXiv:1710.00486v2  [cs.NE]  30 Jan 2020While the usefulness of neural networks is evident, it has been observed that state oftheart networks are highly vulnerable to adversarial perturbations : given a correctly classiÔ¨Åed input x, it is possible to Ô¨Ånd a new input x0that is very similar to xbut is as signed a different label [20]. For instance, in imagerecognition networks it is possible to add a small amount of noise (undetectable by the human eye) to an image and change how it is classiÔ¨Åed by the network. Worse still, adversarial examples have also been found to transfer across networks, making it possible to attack networks in a blackbox fashion, without access to their weights. Recent work has demonstrated that such attacks can be carried out in prac tice [13]. Vulnerability of neural networks to adversarial perturbations is thus a safety and security concern, and it is essential to explore systematic methods for evaluating and improving the robustness of neural networks against such attacks. To date, researchers have mostly focused on efÔ¨Åciently Ô¨Ånding adversarial perturba tions around select individual input points. The problem is typically cast as an optimiza tion problem: for a given network Fand an input x, Ô¨Ånd anx0for whichF(x0)6=F(x) while minimizing kx"
511,The Integration of Machine Learning into Automated Test Generation: A Systematic Mapping Study.txt,"Context: Machine learning (ML) may enable effective automated test
generation.
  Objective: We characterize emerging research, examining testing practices,
researcher goals, ML techniques applied, evaluation, and challenges.
  Methods: We perform a systematic mapping on a sample of 124 publications.
  Results: ML generates input for system, GUI, unit, performance, and
combinatorial testing or improves the performance of existing generation
methods. ML is also used to generate test verdicts, property-based, and
expected output oracles. Supervised learning - often based on neural networks -
and reinforcement learning - often based on Q-learning - are common, and some
publications also employ unsupervised or semi-supervised learning.
(Semi-/Un-)Supervised approaches are evaluated using both traditional testing
metrics and ML-related metrics (e.g., accuracy), while reinforcement learning
is often evaluated using testing metrics tied to the reward function.
  Conclusion: Work-to-date shows great promise, but there are open challenges
regarding training data, retraining, scalability, evaluation complexity, ML
algorithms employed - and how they are applied - benchmarks, and replicability.
Our findings can serve as a roadmap and inspiration for researchers in this
field.","Software testing is invaluable in ensuring the reliability of the software that powers our society [12]. It is also notoriously difficult and expensive, with severe consequences for productivity, the environment, and human life if not conducted properly. New tools and methodologies are needed to control that cost without reducing the quality of the testing process. Automation has a critical role in controlling costs and focusing developer attention [90]. Consider test generation‚Äîan effort intensive task where sequences of program input andoracles that judge the correctness of the resulting execution are crafted for a systemundertest (SUT) [12]. Effective automated test generation could lead to immense effort and cost savings. Automated test generation is a popular research topic, and outstanding achievements have been made in the area [90]. Still, there are critical limitations to current approaches. Major among these is that generation frameworks are applied in a general manner‚Äîtechniques target simple universal heuristics, and those heuristics are applied in a static manner to all systems equally.arXiv:2206.10210v5  [cs.SE]  16 Apr 20232 Fontes and Gay Parameters of test generation can be tuned by a developer, but this requires advanced knowledge and is still based on the same universal heuristics. Current generation frameworks are largely unable to adapt their approach to a particular SUT, even though such projects offer rich information content in their documentation, metadata, source code, or execution logs [29]. Such static application limits the potential effectiveness of automated test generation. Machine learning (ML) algorithms make predictions by analyzing and extrapolating from sets of observations [29]. Advances in ML have shown that automation can match or surpass human performance across many problem domains. ML has advanced the stateoftheart in virtually every field. Automated test generation is no exception. Recently, researchers have begun to use ML either to directly generate input or oracles [67] or to enhance the effectiveness or efficiency of existing test generation frameworks [5]. ML offers the potential means to adapt test generation to a SUT, and to enable automation to optimize its approach without human intervention. We are interested in understanding and characterizing emerging research around the integration of ML into automated test generation1. Specifically, we are interested in which testing practices have been addressed by integrating ML into test genera tion, the goals of the researchers using ML, how ML is integrated into the generation process, which specific ML techniques are applied, how such techniques are trained and validated, and how the whole test generation process is evaluated. We are also interested in identifying the emerging field‚Äôs limitations and open research challenges. To that end, we have performed a systematic mapping study. Following a search of relevant databases and a rigorous filtering process, we have examined 124 relevant studies, gathering the data needed to answer our research questions. We observed that ML supports generation of input and oracles for a variety of testing practices (e.g., system or GUI testing) and oracle types (e.g., expected test verdicts and expected output values). During input generation, ML either directly generates input or improves the efficiency or effectiveness of existing generation methods. The most common types of ML are supervised and reinforcement learning. A small number of publications also employ unsupervised or semisupervised/adversarial learning. Supervised learning is the most common type for system testing, Combinatorial Interaction Testing, and all forms of oracle generation. Neural networks are the most common supervised techniques, and techniques are evaluated using both traditional testing metrics (e.g., coverage) and ML metrics (e.g., accuracy). Reinforcement learning is the most common ML type for GUI, unit, and performance testing. It is effective for practices with scoring functions and when testing requires a sequence of input steps. It is also effective at tuning generation tools. Reinforcement learning techniques are generally based on QLearning, and are generally evaluated using testing metrics tied to the reward function. Finally, unsupervised learning is effective for filtering tasks such as discarding similar test cases. The publications show great promise, but there are significant open challenges. Learning is limited by the required quan tity, quality, and contents of training data. Models should be retrained over time. Whether techniques will scale to realworld systems is not clear. Researchers rarely justify the choice of ML technique or compare alternatives. Research is limited by the overuse of simplistic examples, the lack of standard benchmarks, and the unavailability of code and data. Researchers should be encouraged to use common benchmarks and provide replication packages and code. In addition, new benchmarks could be created for ML challenges (e.g., oracle generation). Our study is the first to thoroughly summarize and characterize this emerging research field2We hope that our findings will serve as a roadmap for both researchers and practitioners interested in the use of ML in test generation and that it will inspire new advances in the field. 2 BACKGROUND AND RELATED WORK 2.1 Software Testing It is essential to verify that software functions as intended. This verification process usually involves testing ‚Äîthe application ofinput , and analysis of the resulting output , to identify unexpected behaviors in the systemundertest (SUT) [12]. During testing, a test suite containing one or more test cases is applied to the SUT. A test case consists of a test sequence (or procedure) ‚Äìa series of interactions with the SUT‚Äìwith test input applied to some SUT component. Depending on the granularity of testing, the input can range from method calls, to API calls, to actions within a graphical interface. Then, the test case will 1We focus specifically on the use of ML to enhance test generation, as part of the broader field of AIforSoftware Engineering (AI4SE). There has also been research in automated test generation for MLbased systems (SE4AI). These studies are out of the scope of our review. 2This publication extends an initial systematic literature review [34] that focused only on test oracle generation. Our extended study also includes publications on test input generation and an expanded set of publications for oracle generation. We also include additional and extended analyses and discussion.Fontes and Gay 3 @Test public void testPrintMessage() { String str = ""Test Message""; TransformCase tCase = new TransformCase(str); String upperCaseStr = str.toUpperCase(); assertEquals(upperCaseStr, tCase.getText()); } Figure 1 Example of a unit test case written using the JUnit notation for Java. validate the output against a set of encoded expectations‚Äîthe test oracle ‚Äîto determine whether the test passes or fails [12]. An oracle can be a predefined specification (e.g., an assertion), output from a past version, a model, or even manual inspection by humans [12]. An example of a test case, written in the JUnit notation, is shown in Figure 1. The test input is a string passed to the constructor of the TransformCase class, then a call to getText() . An assertion then checks whether the output matches the expected output‚Äîan uppercase version of the input. Testing can be performed at different granularity levels, using tests written in code or applied by humans. The lowest granular ity is unit testing, which focuses on isolated code modules (generally classes). Module interactions are tested during integration testing. Then, during system testing, the SUT is tested through one of its defined interfaces‚Äîa programmable interface, a commandline interface, a graphical user interface, or another external interface. Humandriven testing, such as exploratory testing, is out of the scope of this study, as it is often not amenable to automation. 2.2 Machine Learning Machine learning (ML) constructs models from observations of data to make predictions [29]. Instead of being explicitly programmed like in traditional software, ML algorithms ‚Äúlearn‚Äù from observations using statistical analyses, facilitating the automation of decision making. ML has enabled many new applications in the past decade. As computational power and data availability increase, such approaches will increase in their capabilities and accuracy. ML approaches largely fall into four categories‚Äîsupervised, semisupervised, unsupervised, and reinforcement learning‚Äîas presented in Figure 2. In supervised learning, algorithms infer a model from the training data that makes predictions about newly encountered data. Such algorithms are typically used for classification‚Äîprediction of a label from a finite set‚Äîor regression‚Äî predictions in an unrestricted format, e.g., a continuous value. For example, a model may be trained from image data with the task of classifying whether an animal depicted in a new image is a cat. If a sufficiently large training dataset with a low level of noise is used, an accurate model can often be trained quickly. However, a model is generally static once trained and cannot be improved without retraining. Semisupervised algorithms are a form of supervised learning where feedback mechanisms are employed to automatically retrain models. For example, adversarial networks refine accuracy by augmenting the training data with new input by putting two supervised algorithms in competition. One of the algorithms creates new inputs that mimic training data, while the second predicts whether these are part of the training data or impostors. The first refines its ability to create convincing fakes, while the second tries to separate fakes from the originals. Semisupervised approaches require a longer training time, but can achieve more optimal models, often with a smaller initial training set. Unsupervised algorithms do not use previouslylabeled data. Instead, approaches identify patterns in data based on the similarities and differences between items. They model the data indirectly, with littletono human input. Rather than making predictions, unsupervised techniques aid in understanding data by, e.g., clustering related items, extracting interesting features, or detecting anomalies. As an example, a clustering algorithm could take a set of images and cluster them into groups based on the similarity of the images. Such an algorithm could not predict whether a specific image had a cat in it‚Äîas was done in supervised learning‚Äîbut would likely place many of the catcontaining images in the same cluster. Reinforcement learning algorithms select actions based on an estimation of their effectiveness towards achieving a measur able goal [5]. Reinforcement learning often does not require training data, instead learning through sequences of interactions with its environment. Reinforcement learning ‚Äúagents‚Äù use feedback on the effect of actions taken to improve their estimation of the actions most likely to maximize achievement of their goal (their ‚Äúpolicy‚Äù). Feedback is provided by a reward function‚Äîa numeric scoring function. For example, an agent may predict which animal is contained in an image. It would then get a score4 Fontes and Gay .""$)*/&&""3/*/(461&37*4&%4&.*461&37*4&%6/461&37*4&%3&*/'03$&.&/5 $PODFQUT$IBSBDUFSJTUJDT""QMJDBUJPOT&YBNQMF5FDIOJRVFT 0QUJNBM/FVSBM/FUXPSLT4VQQPSU7FDUPS.BDIJOFT (FOFSBUJWF""EWFSTBSJBM/FUXPSLT ,/FBSFTU/FJHICPST &YQFDUBUJPO.BYJNJ[BUJPO 2FBSOJOH4BSTB 0QUJNBM Figure 2 Types of ML and their concepts, characteristics, and applications. based on how close its guess was to being correct‚Äîe.g., if the image contained a cat, then a guess of ‚Äúdog‚Äù would get a higher score than a guess of ‚Äúspider‚Äù. The agent can also adapt to a changing environment, as estimations are refined each time an action is taken. Such algorithms are often the basis of automated processes, such as autonomous driving, and are effective in situations where sequences of predictions are required. Recent research often focuses on ‚Äúdeep learning‚Äù. Deep approaches make complex and highly accurate inferences from massive datasets. Many DL approaches are based on complex manylayered neural networks‚Äînetworks that attempts to mimic how the human brain works [74]. Such neural networks employ a cascade of nonlinear processing layers where one layer‚Äôs output serves as the successive layer‚Äôs input. Deep learning requires a computationally intense training process and larger datasets than traditional ML, but can learn highly accurate models, extract features and relationships from data automatically, and potentially apply models across applications. ‚ÄúDeep‚Äù approaches exist for all four of the ML types discussed above. 2.3 Common Test Generation Techniques Many techniques have been used to generate test input. In this subsection, we briefly introduce four common approaches: (a) random test generation, (b) searchbased test generation, (c) symbolic execution, and (d), modelbased test generation.Fontes and Gay 5 In random test generation, input is generated purely at random and applied to the systemundertest with the aim of triggering a failure. Random input generation is one of the most fundamental, simple, and easytoimplement generation techniques [7]. Unfortunately, while random testing is often very efficient, most software has too large of an input space to exhaustively cover. Therefore, a weakness of random testing is that the generated input may only span a small, and uneven, portion of that input space. Therefore, many adaptive random testing techniques have been proposed. In adaptive random testing, mechanisms are employed to partition the input space, and input is generated for each partition [128]. This ensures an even distribution across the input space. Searchbased test generation formulates input generation as an optimization problem [5]. Of that nearinfinite set of inputs for an SUT, we want to identify‚Äîsystematically and at a reasonable cost‚Äîthose that meet our goals. Given scoring functions that measure closeness to the attainment of those goals‚Äîfitness functions‚Äîmetaheuristic optimization algorithms can automate that search by selecting input and measuring their fitness. Metaheuristic algorithms are often inspired by natural phenomena. For example, genetic algorithms evolve a population of candidate solutions over many generations by promoting, mutating, and breeding fit solutions. Such techniques retain many of the benefits of random testing, including scalability, and are often better able to identify failureinducing input [102], or input with other properties of interest [101]. Symbolic execution is a program analysis technique where symbolic input is used instead of concrete input to ‚Äúexecute‚Äù the program [77]. The values of program variables are represented by symbolic expressions over these inputs. Then, at any point during a symbolic execution, the program‚Äôs state can be represented by these symbolic values of program variables and a Boolean formula containing the collected constraints that must be satisfied for that path through the program to have been taken, also known as the path constraint. By identifying concrete input that satisfies a path constraint, we can ensure that particular paths through the program are covered by test cases. Constraint solvers can be used to identify such input automatically. Recent approaches often are based on dynamic symbolic execution (or concolic execution), where the symbolic execution is combined with concrete random execution to ease the difficulty of solving complex path constraints [7]. Finally, in modelbased testing, lightweight models representing aspects of interest of an SUT are used to derive test cases [114]. Often, such models take the form of a state machine. The internal behavior of the SUT is represented by its state. Transitions are triggered by applying input to the SUT. The model describes‚Äîat a chosen level of abstraction‚Äîthe expected SUT behavior over a sequence of input actions. Test cases can then be derived from this model by choosing relevant subsets of input sequences [7]. 2.4 Related Work "
503,Calling to CNN-LSTM for Rumor Detection: A Deep Multi-channel Model for Message Veracity Classification in Microblogs.txt,"Reputed by their low-cost, easy-access, real-time and valuable information,
social media also wildly spread unverified or fake news. Rumors can notably
cause severe damage on individuals and the society. Therefore, rumor detection
on social media has recently attracted tremendous attention. Most rumor
detection approaches focus on rumor feature analysis and social features, i.e.,
metadata in social media. Unfortunately, these features are data-specific and
may not always be available, e.g., when the rumor has just popped up and not
yet propagated. In contrast, post contents (including images or videos) play an
important role and can indicate the diffusion purpose of a rumor. Furthermore,
rumor classification is also closely related to opinion mining and sentiment
analysis. Yet, to the best of our knowledge, exploiting images and sentiments
is little investigated.Considering the available multimodal features from
microblogs, notably, we propose in this paper an end-to-end model called
deepMONITOR that is based on deep neural networks and allows quite accurate
automated rumor verification, by utilizing all three characteristics: post
textual and image contents, as well as sentiment. deepMONITOR concatenates
image features with the joint text and sentiment features to produce a
reliable, fused classification. We conduct extensive experiments on two
large-scale, real-world datasets. The results show that deepMONITOR achieves a
higher accuracy than state-of-the-art methods.","Nowadays, more and more people consume news from social media rather than traditional news organizations, thanks to social media features such as informa tion sharing, real time, interactivity, diversity of content and virtual identities. However, conveniently publishing news also fosters the emergence of various rumors and fake news that can spread promptly through social networks and result in serious consequences.arXiv:2110.15727v1  [cs.CL]  11 Oct 20212 A. Azri et al. To detect rumors on microblogs, which we particularly target in this paper, most existing studies focus on the social features available in social media. Such features are post metadata, including the information on how post propagate, e.g., the number of retweets, followers, hashtags (#), user information, etc. To exploit such features, many innovative solutions [ 4,23] have been proposed. Unfortunately, these features are not always available, e.g., in case the rumor has just been published and not yet propagated, and do not indicate the purpose of a rumor, which is one of its most important aspects. Moreover, although social features are useful in rumor analysis, contents reveal more relevant in expressing the diusion purpose of rumors [ 17]. Hence, in this paper, we analyse message contents from three aspects to automatically detect rumors in microblogs. First, social media messages have rich textual contents. Therefore, under standing the semantics of a post is important for rumor detection. Attempts to automate the classication of posts as true or false usually exploit natural language processing and machine learning techniques that rely on handcrafted and dataspecic textual features [ 4,16]. These approaches are limited because the linguistic characteristics of fake news vary across dierent types of fake news, topics and media platforms. Second, images and videos have gained popularity on microblogs recently and attract great attention. Rich visual information can also be helpful in classifying rumors [ 10]. Yet, taking images into account for verifying post veracity is not suciently explored, with only a few recent studies exploiting multimedia content [ 11,10]. Third, liars can be detected, as they tend to frequently use words carrying negative emotions out of unconscious guilt [ 20]. Since emotion is closely related to fake news [ 1], analyzing emotions with opinion mining and sentiment analysis methods may help classifying rumors. Automating rumor detection with respect to one of the three characteristics mentioned above is already challenging. Handcrafted textual features are data specic and time consuming to produce; and linguistic characteristics are not fully understood. Image features and emotions, which are a signicant indicators for fake news detection in microblogs, are still insuciently investigated. To address these limitations, we propose an endtoend model called deep MONITOR, based on deep neural network that are ecient in learning textual or visual representations and that jointly exploits textual contents, sentiment and images. To the best of our knowledge, we are the rst to do this. Hence, deep MONITOR can leverage information from dierent modalities and capture the underlying dependencies between the context, emotions and visual information of a rumour. More precisely, deepMONITOR is a multichannel deep model where we rst employ a Longterm Recurrent Convolutional Network (LRCN) to capture and represent text semantics and sentiments through emotional lexicons. This architecture combines the advantages of Convolutional Neural Network (CNN) for extracting local features and the memory capacity of Long ShortTerm Memory Networks (LSTM) to connect the extracted features well. Second, we employ the pretrained VGG19 model [ 26] to extract salient visual features from post images. Image features are then fused with the joint representations of text and sentimentCalling to Deep CNNLSTM for Rumor Detection 3 to classify messages. Eventually, we experimentally show that deepMONITOR outperforms stateoftheart rumor detection models on two large multimedia datasets collected from Twitter. The remainder of this paper is organized as follows. In Section 2, we survey and discuss related works. In Section 3, we thoroughly details the deepMONITOR framework. In Section 4, we experimentally validate deepMONITOR with respect to the state of the art. Finally, in Section 5, we conclude this paper and hint at future research. 2 Related Works "
378,Robot Action Selection Learning via Layered Dimension Informed Program Synthesis.txt,"Action selection policies (ASPs), used to compose low-level robot skills into
complex high-level tasks are commonly represented as neural networks (NNs) in
the state of the art. Such a paradigm, while very effective, suffers from a few
key problems: 1) NNs are opaque to the user and hence not amenable to
verification, 2) they require significant amounts of training data, and 3) they
are hard to repair when the domain changes. We present two key insights about
ASPs for robotics. First, ASPs need to reason about physically meaningful
quantities derived from the state of the world, and second, there exists a
layered structure for composing these policies. Leveraging these insights, we
introduce layered dimension-informed program synthesis (LDIPS) - by reasoning
about the physical dimensions of state variables, and dimensional constraints
on operators, LDIPS directly synthesizes ASPs in a human-interpretable
domain-specific language that is amenable to program repair. We present
empirical results to demonstrate that LDIPS 1) can synthesize effective ASPs
for robot soccer and autonomous driving domains, 2) requires two orders of
magnitude fewer training examples than a comparable NN representation, and 3)
can repair the synthesized ASPs with only a small number of corrections when
transferring from simulation to real robots.","Endusers of service mobile robots want the ability to teach their robots how to perform novel tasks, by composing known lowlevel skills into highlevel behaviors based on demonstrations and user preferences. Learning from Demonstration (LfD) [1], and Inverse Reinforcement Learning (IRL) [2] have been applied to solve this problem, to great success in several domains, including furniture assembly [3], object pickandplace [4], and surgery [5, 6]. A key driving factor for these successes has been the use of Neural Networks (NNs) to learn the action selection policy (ASP) directly [7, 8], or the value function from which the policy is derived [9]. Unfortunately, despite their success at representing and learning policies, LfD using NNs suffers from the following well known problems: 1) they are extremely dataintensive, and need a variety of demonstrations before a meaningful policy can be learned [10]; 2) they are opaque to the user, making it hard to understand whythey do things in speciÔ¨Åc ways or to verify them [11]; 3) they are quite brittle, and very hard to repair when parameters of the problem change, or when moving from simulation to real robots [12]. We present the following observations about ASPs independent of their representation: 1) The input states to a policy consist of physically meaningful quantities ,e.g., velocities, distances, and angles. 2) The structure of a policy has distinct levels of abstraction , including computing relevant features from the state, composing several decisionmaking criteria, and making decisions based on task and domain speciÔ¨Åc parameters. 3) A wellstructured policy is easy to repair in terms of only the parameters that determine the decision boundaries, when the domain changes. Based on these insights we build on program synthesis as a means to address the shortcomings of neural approaches. Program synthesis seeks to automatically Ô¨Ånd a program in an underlying programming language that satisÔ¨Åes some user speciÔ¨Åcation [13]. Synthesis directly addresses these 4th Conference on Robot Learning (CoRL 2020), Cambridge MA, USA.arXiv:2008.04133v2  [cs.AI]  12 Nov 2020concerns by learning policies as humanreadable programs, that are amenable to program repair, and can by do so with only a small number of demonstrations as a speciÔ¨Åcation. However, due to two major limitations, existing state of the art synthesis approaches are not sufÔ¨Åcient for learning robot programs. First, these approaches are not designed to handle nonlinear real arithmetic, vector operations, or dimensioned quantities, all commonly found in robot programs. Second, synthesis techniques are largely limited by their ability to scale with the search space of potential programs, such that ASP synthesis is intractable for existing approaches. To address these limitations and apply synthesis to solving the LfD problem we propose Layered DimensionInformed Program Synthesis (LDIPS). We introduce a domainspeciÔ¨Åc language (DSL) for representing ASPs where a type system keeps track of the physical dimensions of expressions, and enforces dimensional constraints on mathematical operations. These dimensional constraints limit the search space of the program, greatly improving the scalability of the approach and the performance of the resulting policies. The DSL structures ASPs into decisionmaking criteria for each possible action, where the criteria are repairable parameters, and the expressions used are derived from the state variables. The inputs to LDIPS are a set of sparse demonstrations and an optional incomplete ASP , that encodes as much structure as the programmer may have about the problem. LDIPS then Ô¨Ålls in the blanks of the incomplete ASP using syntaxguided synthesis [14] with dimensioninformed expression and operator pruning. The result of LDIPS is a fully instanti ated ASP, composed of synthesized features, conditionals, and parameters. We present empirical results of applying LDIPS to robot soccer and autonomous driving, showing that it is capable of generating ASPs that are comparable in performance to expertwritten ASPs that performed well in a (ommitted for doubleblind review) competition. We evaluate experimentally the effect of dimensional constraints on the performance of the policy and the number of candidate programs considered. We further show that LDIPS is capable of synthesizing such ASPs with two orders of magnitude fewer examples than an NN representation. Finally, we show that LDIPS can synthesize ASPs in simulation, and given only a few corrections, can repair the ASPs so that they perform almost as well on the real robots as they did in simulation. 2 Related Work "
175,On Preimage Approximation for Neural Networks.txt,"Neural network verification mainly focuses on local robustness properties.
However, often it is important to know whether a given property holds globally
for the whole input domain, and if not then for what proportion of the input
the property is true. While exact preimage generation can construct an
equivalent representation of neural networks that can aid such (quantitative)
global robustness verification, it is intractable at scale. In this work, we
propose an efficient and practical anytime algorithm for generating symbolic
under-approximations of the preimage of neural networks based on linear
relaxation. Our algorithm iteratively minimizes the volume approximation error
by partitioning the input region into subregions, where the neural network
relaxation bounds become tighter. We further employ sampling and differentiable
approximations to the volume in order to prioritize regions to split and
optimize the parameters of the relaxation, leading to faster improvement and
more compact under-approximations. Evaluation results demonstrate that our
approach is able to generate preimage approximations significantly faster than
exact methods and scales to neural network controllers for which exact preimage
generation is intractable. We also demonstrate an application of our approach
to quantitative global verification.","Despite the remarkable empirical success of neural net works, guaranteeing their correctness, especially when using them as decisionmaking components in safetycritical au tonomous systems [1]‚Äì[3], is an important and challenging task. Towards this aim, various approaches have been devel oped for the veriÔ¨Åcation of neural networks, with extensive effort devoted to local robustness veriÔ¨Åcation [4]‚Äì[12]. While local robustness veriÔ¨Åcation focuses on deciding the absence of adversarial examples within an perturbation neighbourhood, an alternative approach for neural network analysis is to con struct the preimage of its predictions [13], [14]. By character izing the preimage symbolically in an abstract representation, e.g., polyhedra, one can perform more complex analysis for a wider class of properties beyond local robustness. However, the exact preimage generation method of [13] takes time exponential in the number of neurons in a network. Meanwhile, the approximate preimage generation method pro posed in [14] bypasses the intractability of exact preimage generation by leveraging symbolic interpolants [15], [16] for abstraction of neural network layers. However, due to the complexity of interpolation, the time to compute the abstrac tion also scales exponentially with the number of neurons in hidden layers. Therefore, more efÔ¨Åcient computation methods for (symbolic abstraction of) preimages of neural networks are needed.This paper makes the following novel contributions. We propose an efÔ¨Åcient and practical anytime algorithm for generating symbolic underapproximations of the preimage of piecewise linear neural networks as a union of disjoint polytopes. The algorithm assumes a hyperrectangle input domain and relies on linear relaxation based perturbation analysis (LiRPA) algorithms [9]‚Äì[11], applied backward from a polyhedron output set. Our algorithm partitions the input region into disjoint subregions, which can be approximated independently in parallel in a divideandconquer approach. To assess and optimize the volume, our method bypasses the computational cost of exact volume computation by making use of statistical estimation and differentiable approximations. As an application, we show how to soundly and effectively verify global quantitative properties of neural networks. We take advantage of the efÔ¨Åciency of our algorithm to iteratively generate a highquality underapproximation to the property, while invoking expensive exact computation only at the end of the algorithm. Finally, we conduct an empirical analysis of our method on a range of control and reinforcement learning tasks, showing signiÔ¨Åcant gains in efÔ¨Åciency compared to exact preimage generation, and demonstrating veriÔ¨Åcation of quantitative properties of vehicle parking and aircraft collision avoidance systems. II. R ELATED WORK "
55,Strengths and Weaknesses of Deep Learning Models for Face Recognition Against Image Degradations.txt,"Deep convolutional neural networks (CNNs) based approaches are the
state-of-the-art in various computer vision tasks, including face recognition.
Considerable research effort is currently being directed towards further
improving deep CNNs by focusing on more powerful model architectures and better
learning techniques. However, studies systematically exploring the strengths
and weaknesses of existing deep models for face recognition are still
relatively scarce in the literature. In this paper, we try to fill this gap and
study the effects of different covariates on the verification performance of
four recent deep CNN models using the Labeled Faces in the Wild (LFW) dataset.
Specifically, we investigate the influence of covariates related to: image
quality -- blur, JPEG compression, occlusion, noise, image brightness,
contrast, missing pixels; and model characteristics -- CNN architecture, color
information, descriptor computation; and analyze their impact on the face
verification performance of AlexNet, VGG-Face, GoogLeNet, and SqueezeNet. Based
on comprehensive and rigorous experimentation, we identify the strengths and
weaknesses of the deep learning models, and present key areas for potential
future research. Our results indicate that high levels of noise, blur, missing
pixels, and brightness have a detrimental effect on the verification
performance of all models, whereas the impact of contrast changes and
compression artifacts is limited. It has been found that the descriptor
computation strategy and color information does not have a significant
influence on performance.","Recent advances in deep learning and convolutional neural networks (CNNs) have contributed to signiÔ¨Åcant performance improvements in a number of computer vision problems, ranging from lowlevel vision tasks, such as saliency detection and modeling [3], [24] to higherlevel problems such as object detection [10], [28], recognition [12], [11], [25], [14], [35], tracking [1], [39], [38], or semantic segmentation [2], [7], [33]. Deep learningbased approaches have been particularly successful in the Ô¨Åeld of face recognition, where contemporary deep models now report near perfect performance on popu lar, longstanding benchmarks such as Labeled Faces in the Wild [16], which due to its difÔ¨Åculty, represented the de facto standard for evaluating face recognition technology for nearly a decade. Most of the ongoing research on deep learningbased face recognition focuses on new model architectures, better tech niques for exploiting the generated face representations, and related approaches aimed at improving both the performance 1Correspondence email: klemen.grm@fe.unilj.si 2First authors with equal contributions 3University of Ljubljana, Faculty of electrical Engineering 4ENSEA, Graduate School in Electrial and Computer Engineering 5Istanbul Technical Universityand robustness of deep face recognition technology on com mon benchmark tasks [37], [31], [27]. Research in these areas is typically conducted on unconstrained datasets with various sources of image variability present at once, which makes it difÔ¨Åcult to draw clear conclusions about the sources of errors and problems that are not addressed appropriately by the existing deep CNN models. Much less work is de voted to the systematical assessment of the robustness of deep learning models for face recognition against speciÔ¨Åc variations. Considering the widespread use of deep CNN models for face recognition, it is of paramount importance that the behavior and characteristics of these models are well understood and open problems pertaining to the technology are clearly articulated. In this paper, we contribute towards a better understanding of deep learningbased face recognition models by studying the impact of imagequality and modelrelated characteristics on face veriÔ¨Åcation performance. We use four stateofthe art deep CNN models, i.e., AlexNet [22], VGGFace [27], GoogLeNet [36], and SqueezeNet [17], to compute image descriptors from input images and investigate how quality related factors such as blur, compression artifacts, noise, brightness, contrast, and missing data affect their performance. Furthermore, we also explore the importance of color infor mation and descriptor computation strategies through rigorous experimentation using the Labeled Faces in the Wild (LFW) benchmark [16]. The deep CNN models considered in this work are representatives of the most commonly employed CNN architectures in use today and were selected due to their popularity within the research community. The studied covariates, on the other hand, represent factors commonly en countered in real life that are known to affect face recognition technology to a signiÔ¨Åcant extent [18] and have not yet been studied sufÔ¨Åciently in the literature in the context of deep learning. The comprehensive analysis presented in this paper builds on the previous works from [26], [19]. These works both focused on closedset face identiÔ¨Åcation and investigated the robustness of deep CNN models under facial appearance variations caused by head pose, illumination, occlusion, mis alignment in [26] and by image degradations in [19]. Com plementing and extending these previous works, we provide in this paper a rigorous and systematical evaluation of the impact of various image and modelrelated factors on deep learning based face veriÔ¨Åcation performance. The goal of this work is to provide answers to essential research questions, such as: Are good quality images a must for high veriÔ¨Åcation performance? To what extent does image quality affect the image descriptorsarXiv:1710.01494v1  [stat.ML]  4 Oct 2017SUBMITTED FOR PUBLICATION TO IET BIOMETRICS 2 generated by contemporary deep models? Are certain model architectures more robust than others against variations of spe ciÔ¨Åc covariates? Changes in which quality characteristics are most detrimental to the veriÔ¨Åcation performance? How should image descriptors be computed? Answers to these and similar questions are in our opinion crucial for a better understanding of deep learningbased face recognition technology and may point to open problems that need to be addressed in the future. In summary, we make the following contributions in this paper: We study and empirically evaluate the effect of image quality (blur, JPEG compression, noise, contrast, bright ness, missing data) and model related (color information, descriptor computation) characteristics on the face ver iÔ¨Åcation performance of four stateoftheart deep CNN models on the LFW dataset. We conduct a comprehensive analysis of the experimental results, identify the most detrimental covariates affecting deep CNN models in face veriÔ¨Åcation task and point to potential areas for improvement. We provide a comparative evaluation of the four deep CNN models, namely, AlexNet [22], VGGFace [27], GoogLeNet [36], and SqueezeNet [17], and make the trained models publicly available to the research com munity through: https://github.com/kgrm/facerecogeval . The rest of the paper is organized as follows: In section II, we brieÔ¨Çy review previous works relevant to our study. In section III, we describe the evaluation methodology, models, datasets, and experimental procedures used. In section IV, we present quantitative results and discuss our experiments. Finally, section V concludes the paper. II. R ELATED WORK "
430,Dive into the Power of Neuronal Heterogeneity.txt,"The biological neural network is a vast and diverse structure with high
neural heterogeneity. Conventional Artificial Neural Networks (ANNs) primarily
focus on modifying the weights of connections through training while modeling
neurons as highly homogenized entities and lacking exploration of neural
heterogeneity. Only a few studies have addressed neural heterogeneity by
optimizing neuronal properties and connection weights to ensure network
performance. However, this strategy impact the specific contribution of
neuronal heterogeneity. In this paper, we first demonstrate the challenges
faced by backpropagation-based methods in optimizing Spiking Neural Networks
(SNNs) and achieve more robust optimization of heterogeneous neurons in random
networks using an Evolutionary Strategy (ES). Experiments on tasks such as
working memory, continuous control, and image recognition show that neuronal
heterogeneity can improve performance, particularly in long sequence tasks.
Moreover, we find that membrane time constants play a crucial role in neural
heterogeneity, and their distribution is similar to that observed in biological
experiments. Therefore, we believe that the neglected neuronal heterogeneity
plays an essential role, providing new approaches for exploring neural
heterogeneity in biology and new ways for designing more biologically plausible
neural networks.","The biological neural network is an intricate system, and its high heterogeneity plays a vital role in learning and reasoning. In a biological neural network, the diversity of neurons endows the network with richer functionality and computational power. Different types of neurons can respond to different types of input features, thereby providing the network with better feature extraction capabilities [ 1;2;3]. The diversity of neurons enables the biological neural network to produce meaningful responses to external stimuli even without weight training. Furthermore, the heterogeneity of neurons is closely related to the plasticity of the brain and contributes to the robustness of neural networks [4; 5]. However, conventional ArtiÔ¨Åcial Neural Networks (ANNs) mainly rely on homogeneous activation functions to simulate how neurons receive information and adapt to different tasks through training the connection weights. In this process, neurons are often simpliÔ¨Åed and homogenized. In contrast, spiking neurons offer higher Ô¨Çexibility, and researchers can achieve different spiking patterns by adjusting various parameters [ 6;7]. Nevertheless, these studies still cannot completely separate the inÔ¨Çuence of connection weights and independently optimize heterogeneous neurons. This could Corresponding Author. Preprint. Under review.arXiv:2305.11484v1  [cs.NE]  19 May 2023Forward DirectionReward Evolution StrategyHomogeneity Spiking PatternsGeneration AgentHeterogeneity Figure 1: Diagram of Heterogeneous Neural Networks. Left: Heterogeneous SNNs with random weights can be applied to the continuous control tasks. Right: When the input current is constant, heterogeneous neurons can exhibit various spiking patterns. potentially obscure the speciÔ¨Åc contribution of neuronal heterogeneity to network performance. To address this challenge, we discuss the computational capabilities exhibited by neuronal heterogeneity when using a network without modifying the connections. Such research helps us better understand how neuronal heterogeneity independently inÔ¨Çuences and provides valuable insights for future network designs. The success of deep learning in the Ô¨Åeld is largely attributed to the backpropagation (BP) [ 8]. However, there is still debate regarding whether the brain performs precise derivative computations [ 9]. We Ô¨Årst uncover the challenges faced by BP in optimizing Spiking Neural Networks (SNNs), particularly in terms of stability. Additionally, we discover that the Evolutionary Strategy (ES) without BP outperforms in optimizing the parameters of random networks, which aligns more closely with biological plausibility. Through experiments involving tasks like continuous control, working memory, and image recognition, we Ô¨Ånd that optimizing neuron properties not only allows neurons to exhibit diverse spiking patterns but also achieves performance that is comparable to, or even exceeds, that obtained by optimizing connection weights (as depicted in Fig.1). Furthermore, our Ô¨Åndings highlight the critical role of membrane time constants in neural hetero geneity. Interestingly, we observe that the distribution of these time constants in our model resembles that found in biological experiments. This suggests the signiÔ¨Åcance of incorporating neglected neuronal heterogeneity in the design of biologically plausible SNNs and provides new opportunities for exploring neural heterogeneity in biology. In particular, our contributions to the exploration of the role of neuronal heterogeneity are as follows: ‚Ä¢We highlight the challenges of BP in optimizing SNNs, particularly in long sequence tasks, and show that BPfree evolutionary algorithms can yield better results. ‚Ä¢We employ ES to optimize the properties of neurons in a network with random weights. Ex perimental results demonstrate that the random weight networks with heterogeneous neurons can achieve comparable or even higher performance than the network with homogeneous neurons and trainable weights. ‚Ä¢Our ablation analysis underscores the importance of membrane time constants in neural heterogeneity and their distribution similarities with biological experiments. 2 Related Works "
256,An efficient nonconvex reformulation of stagewise convex optimization problems.txt,"Convex optimization problems with staged structure appear in several
contexts, including optimal control, verification of deep neural networks, and
isotonic regression. Off-the-shelf solvers can solve these problems but may
scale poorly. We develop a nonconvex reformulation designed to exploit this
staged structure. Our reformulation has only simple bound constraints, enabling
solution via projected gradient methods and their accelerated variants. The
method automatically generates a sequence of primal and dual feasible solutions
to the original convex problem, making optimality certification easy. We
establish theoretical properties of the nonconvex formulation, showing that it
is (almost) free of spurious local minima and has the same global optimum as
the convex problem. We modify PGD to avoid spurious local minimizers so it
always converges to the global minimizer. For neural network verification, our
approach obtains small duality gaps in only a few gradient steps. Consequently,
it can quickly solve large-scale verification problems faster than both
off-the-shelf and specialized solvers.",This paper studies efÔ¨Åcient algorithms for a particular class of stagewise optimization problems: minimize (s;z)2SRnf(s;z) (1a) s.t.i(s;z1:i
173,Peripheral Authentication for Parked Vehicles over Wireless Radio Communication.txt,"Peripheral authentication is an important aspect in the vehicle networks to
provide services to only authenticated peripherals and a security to internal
vehicle modules such as anti-lock braking system, power-train control module,
engine control unit, transmission control unit, and tire pressure monitoring.
In this paper a three-way handshake scheme is proposed for a vehicle to a
keyfob authentication. A keyfob is a key with a secure hardware that
communicates and authenticates the vehicle over the wireless channel.
Conventionally, a vehicle to keyfob authentication is realized through a
challenge-response verification protocol. An authentic coupling between the
vehicle identity and the keyfob avoids any illegal access to the vehicle.
However, these authentication messages can be relayed by an active adversary,
thereby, can amplify the actual distance between an authentic vehicle and a
keyfob. Eventually, an adversary can possibly gain access to the vehicle by
relaying wireless signals and without any effort to generate or decode the
secret credentials. Hence, the vehicle to keyfob authentication scheme must
contain an additional attribute verification such as physical movement of a
keyfob holder.
  Our solution is a two-party and three-way handshake scheme with proactive and
reactive commitment verification. The proposed solution also uses a time
interval verification such that both vehicle and keyfob would yield a similar
locomotion pattern of a dynamic keyfob within a similar observational time
interval. Hence, the solution is different from the distance bounding protocols
that require multiple iterations for the round-trip delay measurement. The
proposed scheme is shown to be adaptable with the existing commitment scheme
such as Schnorr identification scheme and Pedersen commitment scheme.","Currently, vehicles are leveraged as a secure mobile information system [28, 16] in the Internet of Things (IoT) environment such as smart cities, smart communities, smart contracts, smart homes, etc. In order to allow the wireless communication capabilities, these vehicles must be compliant with the Dedicated Short Range Communication (DSRC) IEEE 1609 [2, 4] based on Wireless Access in Vehicular Environment (WA VE) 802.11p [5]. There has been a tremendous amount of research on how to securely drive vehicles while simultaneously communicating with neighboring vehicles so that a warning can be received/predicted ahead of time. Examples for different types of communication among neighboring vehicles are vehicle platooning protocols for fuel efÔ¨Åciency, vehicle tracking protocols for trafÔ¨Åc efÔ¨Åciency, data dissemination and ofÔ¨Çoading protocols for road side units (RSU), vehicle localization protocols for safety and infotainment routing, etc. However, another crucial aspect is to authorize an access to a vehicle via peripheral device connections [29]. Our focus is to highlight the vulnerabilities attached to a static vehicle. It might be less intuitive to imagine the threat use cases for a static or parked vehicle. However, the static vehicle silhouette is even more vulnerable to all possible attacks once the vehicle is accessible to rogue peripheral devices. For example, an adversary can use repeaters to revive weak signals from a far distanced keyfob and thereby, receive an ahead of time access to the vehicle. Also, a bruteforce method can be used to exhaustively compute the correct response and then forwarding it to the vehicle before the original response arrives at the vehicle. A more formal description regarding the attack scenarios is given in Section 2. Therefore, we provide a general authentication for these peripheral devices and also improve the mobile keyfob authentication in a separate scheme. Peripheral authentication: A secure digital periphery of the vehicle is achieved via a secure authentication with respect to paired devices. SpeciÔ¨Åcally, any temporary peripheral device connection with the vehicle must be authenticated for the extended functional security of the vehicle (see ISO 26262 vehicle functional security standard [3]) while driving with a pluggedin rogue device. These peripheral devices such as keyfobs, USB sticks, cell phones, and, iPods provide extended services to the vehicle. Evidently, these ad hoc vehicle to device connections are potential exposure to external threats to breakin an otherwise static and secure vehicle periphery. Our motivation is to secure the peripheral device integration, especially, remote vehicle access via the keyfob. A keyfob (kf) is a hardware security token to allow only an authentic access to a static vehicle ( v) situated remotely. In particular, the problem is beyond the effort to place a secure Ô¨Årewall for Ô¨Åltering any external threats due to a range of relay and impersonation attacks (as presented in Section 2). A secure remote access is most crucial among other peripheral device connections because vehicle access via a keyfob has a wider horizon of attacks. Therefore, it is important to identify, authenticate and pair the correct keyfob (while continuously approaching towards the parked vehicle) by measuring an active locomotion pattern of the keyfob and the keyfob holder. It must be noted that the proposed approach provides the event data history as a preliminary means to pair and authenticate any peripheral devices, however, in case of a keyfob an additional veriÔ¨Åcation regarding keyfob dynamics is essential and provides stronger security against replay attacks. V2X communication paradigm: There exist multiple dimensions to vehicular communication forte; for example, vehicle to infrastructure (V2I with road side units for service discovery across smart highways or smart cities), vehicle to cloud (V2C), vehicle to IoT (V2IoT communication with platoons or RFID enabled smart highways), vehicle to smart homes (V2SH), vehicle to peripheral device (V2PD for plugin device authentication [26]), vehicle to vehicle (V2V) and vehicle to owner (V2O for personalized humancomputer interaction). 2We chose to provide a secure authentication protocol for a vehicle to peripheral device (V2PD) communication. In general, our solution provides a secure binding between the vehicle and authentic peripheral devices. Furthermore, the solution is extended with an additional customization for vehicle to keyfob binding via user authentication. Basically, the solution considers a static vehicle and securely bind the available services at the vehicle via user authentication. It must be noted that a dynamic vehicle is vulnerable to a wider attack surface, yet a static vehicle offers the key to a variety of V2X communication paradigms (as mentioned above), hence it is more sensitive. Therefore, the protocol design requires a twofold interactive authentication paradigm based on challengeresponse veriÔ¨Åcation along with the anthropomorphic features that include human aspects into veriÔ¨Åcation. The internal vehicle networks are supposed to provide a secure identifying gateway to these external devices. However, every transient connection between the peripheral device and the vehicle must be veriÔ¨Åable. The proposed solution veriÔ¨Åes the driver authenticity via a threeway handshake that promises a twofold authentication. Furthermore, the handshake scheme derives all subsequent messages with an initial round of authentication associated to an initiator. A secure mutual pairing between the vehicle and peripheral devices [13] analogs ad hoc device pairing such as on Bluetooth. However, the proposed solution avoids any unauthorized access to a vehicle by using cryptographic commitment schemes as a building block. The proposed scheme avoids any consequent privileges to maliciously start the engine of a parked vehicle through peripheral device access. Our motivation is to strengthen an access control over a static/parked vehicle such that Ô¨Årstly, an owner must be authenticated based on predeÔ¨Åned challengeresponse pairs (CRP), secondly, veriÔ¨Åcation of actively measured dynamics as an attribution of owners‚Äô characteristics. The digital periphery (meaning physical as well as wireless signal periphery) of a vehicle must utilize reactive and proactive commitment veriÔ¨Åcation towards an access grantee. In general, a vehicle is supposed to receive a request for safe pairing and a subsequent access to various internal vehicle modules, e.g., antilock braking system (ABS), powertrain control module (PCM), engine control unit (ECU), transmission control unit (TCU), tire pressure monitoring (TPM), active control module (ACM), relay control module (RCM), heat ventilation and air condition (HV AC) systems. Evidently, the security of these modules is related to the secure pairing with peripheral devices. However, the secure pairing is even more crucial when a peripheral device (e.g., keyfob) requests a remote access to the vehicle. 1.1. Problem Statement Figure 1 illustrates a problem scenario where an attacker can get an access to a vehicle. A required solution must avoid an unauthorized remote vehicle access via fabricated radio frequency identiÔ¨Åcation (RFID) enabled keyfob. Also, we focus on Ô¨Ånding ways to provide an anthropomorphic link to the bonding between the vehicle and peripheral devices such as RFID enabled keyfob. Conventionally, keyless entry systems provide an autonomous2sensing such that the parked vehicle keep sensing (through heartbeat messages) the presence of an authentic keyfob in the proximity, e.g., via regular beacon solicitation method. The authentic keyfob must be present in the proximity and respond back to these soliciting beacons from the parked vehicle. However, the absence of the authentic keyfob within the sensed region can be ampliÔ¨Åed with another RFID enabled keyfob. The malicious keyfob would create an illusion of the shorter distance by amplifying and relaying the signals between both parties. In addition, these RFID signals are vulnerable to other sophisticated attacks as detailed in [18] while assuming an adaptive adversary model. In particular, an adversary 2Note that the system settings are deÔ¨Åned within the scope of autonomous vehicles, i.e., availability of IEEE 802.11p [1], IEEE 1609.2 [2], and, Black Box IEEE 1616 [7]. 3(a)(b)(d) (e)Vehicle (v) Attacker (A) Keyfobholder (kf)  Random responseRelayed responseOriginal responseImpersonated responseNoresponseNo response Authenticresponse (c)EarlyresponseOriginal    response In (a) adversary relays a random response via brute force attack. In (b) adversary purely relays an authentic response from a keyfob holder ( kf) towards the vehicle ( v). It must be noted that response was originated at authentic kf, meaning that an interested kfhas requested for service access atv. According to distance fraud in (c), a dishonest prover kfmight fake a larger distance between the kfandv, as if kfis situated closer to vby sending a response too early. However, according to maÔ¨Åa fraud (as shown in (d)) kfmight not be interested in any service request (hence, might be situated outside a vehicle coverage) still an adversary have successfully revealed the secret from kfand might control services on behalf of kf. It must be noted that original kfis not interested and have not revealed the secret by colluding with the adversary. In (e) adversary colludes with the authentic kf, thereby, yield a service access via response originated at kf. Figure 1: Attack scenario. recovers an exhaustive number of CRP transcripts and based on that knowledge might fabricate a duplicate keyfob. 1.2. Design Requirements An authentication protocol construction must incorporate the veriÔ¨Åcation of a preshared secret, an active response and a speciÔ¨Åc anthropomorphic feature. For example, the personalized locomotion pattern of a keyfob holder might learn an identifying information (more accurately with the passage of time). In particular, our design involves following factors and synergizes into a multidimensionally secure access control scheme. Essentially, design requirements can be summarized as: Reciprocal authentication: A primary requirement is to provide a mutual authentication between a vehicle and a peripheral device such as keyfob. In general, the vehicle to keyfob pairing is initiated from vehicle‚Äôs side and keyfob as a responder. However, the vehicle as an initiator is more vulnerable to attack exposures as compared to the other way around. In our scheme, the keyfob is an initiator and the vehicle is a responder to validate a speciÔ¨Åc service access grantee such as an authentic keyfob. In this case, the vehicle authenticates the initiator and reciprocates a secret challenge along with the vehicle identity. IdentiÔ¨Åcation based on preshared state: In our solution, an initial pairing is secured using an internal state record of the vehicle that is proactively synchronized with the recorded internal state inside the 4keyfob. The initial pairing must witness a matching internal state (inside the vehicle and an authentic keyfob) as a part of preshared knowledge veriÔ¨Åcation phase. Reactive veriÔ¨Åcation: The proactive commitment (veriÔ¨Åcation based on an internal vehicle state) must be coupled with a reactive commitment veriÔ¨Åcation. This handshake ordering would avoid an attack scenario in which the adversary might respond with any random response to an authentic challenge. CRP based reactive veriÔ¨Åcation avoids misbinding attacks and satisÔ¨Åes a noninjective authentication property, i.e., to guarantee the participation of other party without the ability to distinguish it across multiple protocol executions. Thus, the vehicle must be able to verify the validity of the response, i.e., the response should be in correspondence with the current challenge. Anthropomorphic features: The personiÔ¨Åcation of user traits (unique behavior or attribute of the keyfob owner) must be veriÔ¨Åed during the handshake. In particular, we need to verify velocity vs location with respect to the keyfob holder. Also, this locomotion pattern would become somewhat obvious and distinguishable over a period of time, i.e., any locomotion information collected over multiple authentication phases (between a speciÔ¨Åc vehicle and paired keyfob) would result into a personiÔ¨Åcation of this locomotion pattern of the authentic owner. The human attribution of the owner‚Äôs gait and active veriÔ¨Åcation of the corresponding locomotion pattern is the classic form of authentication. In particular, this customization provides more intuitive authentication to an identical vehicle and keyfob over different sessions. Vehicle (v) Keyfob ( kf) Solicit access Send commitment (commitment,timestamp )‚Üê‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí Verify: commitment DeÔ¨Åne: time split Send challenge (Challenge,timesplit )‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚Üí Compute: response & gait (Response,gait )‚Üê‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí Verify: response Compute: local gait Compare: gaits Figure 2: The proposed approach. 1.3. Our Contribution Figure 2 presents a generalized vision of our proposed vehicle to device authentication. It must be noted that the Ô¨Årst round is commitment revealing round, i.e., the residual commitment (that a vehicle and device were left with) during last communication is revealed and veriÔ¨Åed here at the Ô¨Årst round of next connection establishment in near future. Thereby, a secure chain is created between the last and the Ô¨Årst round of connection establishment. In addition, the proposed solution is based on the following properties. Knowledge based initial pairing: A most recent internal state, e.g., electronic control unit‚Äôs (ECU) conÔ¨Åguration, seat position, the angle of steering, temperature, etc, of any vehicle, is known only to 5the keyfob in current use. Therefore, every time a vehicle changes its internal state, the corresponding commitment data is also changed. In particular, only a key that was used during the last drive would be in possession of correctly matching internal state of the vehicle. Commitment based authentication: A reactively changing secret commitment between the vehicle and authentic keyfob provides spontaneous identity veriÔ¨Åcation. It provides the identity veriÔ¨Åcation of the peer party in communication during the last rounds of the handshake. Furthermore, we have shown a secure adaptation of our proposed solution that utilizes existing commitment schemes, i.e., Schnorrs‚Äô identitybased commitment scheme [33] and Pedersen‚Äôs commitment scheme [35] (as detailed in Section 5). PersoniÔ¨Åed localization: An instant gait veriÔ¨Åcation is done with respect to a keyfob holder approaching towards the paired vehicle. Evidently, a direct communication between the paired vehicle and corresponding keyfob would yield the same gait observation, i.e., similar distance covered in similar time window; as opposed to an attack scenario in which the adversary relay the wireless radio messages. In particular, no additional hardware integration is required within the internal vehicle network. The gait observation at the static vehicle would differ with the original gait observation at the keyfob holder if an active relaying is involved in the wireless radio communication. Outline. Section 2 details the authentication model and attack scenarios regarding twoparty authenticated communication. Section 3 provides system setting and assumptions. Furthermore, Section 4 provides the generalized peripheral authentication scheme as well as the personalized authentication scheme for vehicle to keyfob interaction. The ability to adapt potential commitment protocols from the existing literature is given in Section 5. Furthermore, a formal security analysis is given in Section 6. Section 7 and Section 8 provide related work and concluding remarks, respectively. 2. Authentication Properties and Threat Model In our model, we consider three entities: a veriÔ¨Åer or a static vehicle ( v), a prover or a keyfob ( kf), and an attacker (A). We consider a hierarchy of authentication properties such as aliveness, weak agreement, noninjective agreement, and agreement, to be a milestone for our proposed solution [15]. Our solutions, i.e., vehicle to peripheral device authentication and vehicle to keyfob authentication, satisfy authentication properties injective authentication oragreement as deÔ¨Åned below. Aliveness. The most basic layer of authentication, i.e., aliveness property, ensures the participation of peer entities, while it might so happen that a participating entity was not running the protocol or even worse that it was running the protocol with some other entity. DeÔ¨Ånition 1 (Aliveness) A veriÔ¨ÅervveriÔ¨Åes that a prover kfhas been participating in the execution of an authentication protocol with v. For example, a mirror attack scenario or an adversary using an old round of the protocol execution as an oracle with the initiator illustrates the lack of proper authentication over and beyond aliveness. Weak agreement. A step beyond aliveness is to guarantee the participation of an entity while the protocol execution actually took place between those claimed entities. DeÔ¨Ånition 2 (Weak agreement) A veriÔ¨ÅervveriÔ¨Åes that a prover kfhas been participating in the execution of an authentication protocol with v, while protocol execution took place between vand apparently from kf. Noninjective agreement. This property of authentication ensures that each of the participants is present during the protocol execution and agrees on messages exchanged during the run. However, 6there might be a onetomany association between the participants such that vmight be present during multiple executions while kfwas present in at most one of those executions. DeÔ¨Ånition 3 (Noninjective agreement) A veriÔ¨Åervinitiates protocol execution with a prover kf and agrees on messages exchanged during the nprotocol executions, certainly, then prover kfhas been responding (hence agreeing on messages) in at least ( n‚àí1) protocol executions. Agreement. Onetoone association between any two participants is termed as agreement or mutual authentication property. Thus, each of the participants agrees on their corresponding identity as well as the messages exchanged during each protocol run. DeÔ¨Ånition 4 (Agreement) A veriÔ¨ÅervveriÔ¨Åes that a prover kfhas been participating in the execution of an authentication protocol with v, while a mutual and afÔ¨Årmative protocol execution took place between vandkf. Note that weak agreement and agreement properties are different; in the former, during the protocol run one party only guarantee the participation of other party; in later, one party guarantee the participation of other party and also preserves the distinctness corresponding to each protocol run. We present three different (but related) relay and impersonation attack scenarios, namely, distance fraud, maÔ¨Åa fraud, and terrorist fraud. These attack scenarios are applicable to various systems based on service access veriÔ¨Åcation, especially, the services that are accessible over a wireless radio channel within a closer proximity. Therefore, as per the design requirements, the verifying vehicle vmust be able to guarantee: aliveness (i.e., the access request was actually generated at the original keyfob but does not avoid replay attack), weak agreement (i.e., the access request was actually generated at the authentic keyfob instead of an adversary replaying the past requests), noninjective agreement (i.e., the access request was actually generated at the authentic keyfob without preserving the distinctness (relay attack) across multiple executions of the protocol), agreement (i.e., the access request was actually generated at the authentic keyfob while preserving the distinctness and avoiding the replay attack). Distance fraud. There are various services that are meant to verify the presence of a user in the locality before granting access to the resources. According to the distance fraud, a dishonest prover claims to be at a certain distance (thereby, legal to access the services) while actually being far away from the claimed distance with respect to the veriÔ¨Åer. The dishonest prover pretends to fake a larger distance by sending a response too early to the veriÔ¨Åer, i.e., even before the challenge reaching the prover and the prover computing a paired response and then sending a response to the veriÔ¨Åer. For example, suppose that a vehicle and keyfob are situated apart (might be in the range of each other). An adversary might just amplify and relay these signals from the authentic keyfob pretending to acquire an access, or at worst, an adversary might send an early response to the vehicle (earlier than keyfob). In this case, an adversary would receive at least an early access, in case the original keyfob has actually requested for vehicle access. Therefore, both the proactive and reactive secret veriÔ¨Åcation (with additional locomotion veriÔ¨Åcation for the keyfob authentication) are crucial to the proposed authentication scheme. The authentication protocols that satisfy the only aliveness property are usually prone to distance fraud. Therefore, the protocol must satisfy, at least, a weak agreement property to avoid distance fraud attacks. MaÔ¨Åa fraud. This attack is another more sophisticated form of distance attack. In this attack scenario, two adversaries collude and gain an illegitimate access to the secure services, while the original sender has no intention to request an access or to reveal a cryptographic secret. According to the maÔ¨Åa fraud, an adversary tries to utilize a separate channel and an accomplice to extract and relay the credentials from an authentic prover (not actively interested at all, in any service access). Therefore, adversaries 7collude and relay the secure access code to break in the veriÔ¨Åer (meant to provide the service access to the authentic secret holder). The authentication protocols that satisfy only, aliveness andweak agreement properties are usually prone to maÔ¨Åa fraud. Therefore, the protocol must satisfy, at least, a noninjective agreement property to avoid maÔ¨Åa fraud attacks. Terrorist fraud. According to the terrorist fraud, an authentic prover assists with the adversary (by handing over a secret component) to impersonate in front of the veriÔ¨Åer. The attack scenario is practically feasible even with the biometric authentication because the original secret holder can authorize himself, and, let the services be accessible to others who do not possess secret biometric credentials. A secure protocol design requires a more sophisticated identity veriÔ¨Åcation method such as a ticket granting authority (issuing tickets for service access). It must be noticed that our solution is not resistant to this type of impersonation attacks. In general, authentication protocols that satisfy the most concrete form of authentication, i.e., injective agreement property might still be prone to these attacks. A most resembling example is when any vehicle (that is secured under insurance policy of the owner) is stolen by a thief, if only, had the owner subliminally assisted to thief. Now we brieÔ¨Çy enlist the solutions that might offer a secure communication link between a static vehicle and a dynamic keyfob at distance. However, none of these solutions incorporate the binding between the localization of a keyfob and the veriÔ¨Åcation of authentic keyfob holder, as we do in our proposed approach. Strawman solutions: In theory, nontransferrable machinelearningÔ¨Ångerprints are also interesting, e.g., Completely Automated Public Turing Test to tell Computers and Humans Apart (CAPTCHA). More importantly, the CAPTCHA challenge should be in the form of unknown secret challenge while the response is examined by probabilistic estimations to decide the correct user identity binding with respect to that response. The CAPTCHA is based on reactive response veriÔ¨Åcation to check the human capabilities of computing a correct response immediately. Interestingly, the reactive veriÔ¨Åcation and anthropomorphic feature (e.g., walking pattern or gait observation, visual traits, typing patterns) can also be combined using CAPTCHA method of veriÔ¨Åcation. The CAPTCHA provides identiÔ¨Åcation of a person/device through a custom reaction to the CAPTCHA in order to avoid replay attacks, whereas the machine learning is trained to identify the person/device based on upcoming never seen CAPTCHAs. Conventionally, a new CAPTCHA is produced as a challenge for every user in a new interaction. This CAPTCHA challenge might invoke a user response not only in terms of the regular optical character recognition (OCR) but also in terms of counting the number of user movements per unit time, voice commands, or visual reÔ¨Çections, etc. All of these useroriented commands qualify to be an anthropomorphic feature and can be used for veriÔ¨Åcation purpose. However, there is no distinction between two different users from CAPTCHA perspective. Our protocol is able to distinguish two different users based on anthropomorphic attributes. The existing solutions provide repetitive challengeresponse iterations, triangulation and multialteration, and location mapping via RFID tag. Furthermore, the solution designs might vary as per the security features required and a few of those strawman solutions have been expanded as below: Wireless Ô¨Ångerprinting: The remote physical wireless device Ô¨Ångerprinting as proposed in [20] is a useful solution to securely identify any remote device. According to the wireless device Ô¨Ångerprinting [21], a received signal is distinguished on the basis of four timing functions, i.e., ideal information encoded, unique manufacturing impairment in device hardware, environmental noise, and propagation delay. Received (t) =Ideal (t) +Impairment (t) +Noise (t) +Propogation (t) 8In [20] the remote device Ô¨Ångerprinting is based on clock skew as observed through Transport Control Protocol (TCP) timestamps or Internet Control Message Protocol (ICMP) timestamps [22] as embedded inside the header. The advantage is that their clock skew measurement can even be used with the Network Address Translation (NAT) protected networks which provides masking a single Internet Protocol (IP) address for multiple unique IP hosts. Received (t) =Ideal (t) +Anthropomorphic (t) In addition, wireless channel and device Ô¨Ångerprinting can be used together to eliminate repeaterinthemiddle attacks; consequently, nullify any artiÔ¨Åcial delays during the communication. Usually, in order to distort these Ô¨Ångerprinting signature, an attacker performs tampering such that Impairment (t)‚âàNoise (t). On the contrary, our proposed solution is different such that the received signal is distinguished based on two timing functions, i.e., ideal encoded information and useroriented anthropomorphic features. Measuring movement pattern: Next, we discuss localization methods to securely identify a moving keyfob. The veriÔ¨Åable multilateration location technique [23] proposed a secure positioning scheme. Accordingly, a veriÔ¨Åer estimates mobile node position through the distance bounding approach; similarly, multiple veriÔ¨Åers located in a triangle around the node can estimate the actual node position. We suggest using a reÔ¨Çection from passive ‚ÄúveriÔ¨Åers‚Äù (possibly, reÔ¨Çecting devices located at home or roadside lamps) for a proactive veriÔ¨Åcation of any static vehicle. A trusted third party retrieves the position of these veriÔ¨Åers and their corresponding estimates (regarding mobile node) to accurately compute the mobile node location through minimum mean square estimate [23]. However, our proposed solution would work even in the absence of these veriÔ¨Åers (that might not be trustworthy at times). In addition, we avoid the method of multiple measurements of round trip time (as in case of distance bounding) to locate the sender within the proximity. The major difference in our proposed solution as compared with other solutions is that both a proactive and reactive commitment is veriÔ¨Åed while referring to similar time windows. The time window estimation (simultaneously, at both parties in communication) results in locomotion trajectory of the keyfob holder. Our solution might further be extended for computing multiple triangulation (for 2d positioning, 3rd positioning, and in fact the i‚Äôth) measurements over a speciÔ¨Åed period of time, thereby, locating the mobile node at different time stamps. These located dotes over the trajectory of coordinates will yield the direction of movement, velocity, and acceleration of the node. Therefore, a veriÔ¨Åer can identify a node, by comparing its past movement pattern, say, using machine learning, and may predict the next location of the node as well (e.g., for avoiding collisions). 3. System Settings and Protocol Overview This section presents system and hardware assumptions. Firstly, the vehicles must be compliant with the dedicated short range communication (DSRC) IEEE 1609 based on wireless access in vehicular environment (WA VE) 802.11p. In addition, a wakeup mode is required to allow a far distanced keyfob to reach the static vehicle in sleep mode. Also, a nonvolatile storage medium is required that would securely accumulate the most recent driving patterns and the vehicle conÔ¨Ågurations. Next, a detailed working description of IEEE 1616 based data recorders is presented that serves the proactive knowledge veriÔ¨Åcation between static a vehicle and a keyfob. Also, a brief overview of the proposed solution along with the participating entities and their prestored knowledge is highlighted. 93.1. IEEE 1616 event data recorders (EDRs): EDRs are used to maintain event primitives in a log. These essential event factors ( e) contribute to improve consequent safety events [7, 8] in future. Subsequently, any forensic investigations against a crash event would extract and link these event records about the vehicle. However, the privileges regarding the access to this critical/conÔ¨Ådential information of any vehicle depend on the state law. It may further be of utmost importance to forensic team investigation. In past, consumers were not aware that an EDR is integrated inside the vehicle. However, the current state laws, i.e., Black Box Privacy Protection act 2013 [6, 14], made the EDR ownership clear to a vehicle owner and that it cannot be accessed without the consent from the vehicle owner on which it is integrated into (1) the presence and location of an EDR (also termed as a black box), (2) reÔ¨Åning the critical event information and storage format, and (3) usage and claims to acquire the recorded internal state data for legal proceedings with owner‚Äôs consent. We emphasize that the crucial event record stored on a volatile memory inside ECUs can be used to authorize the original vehicle owner of the vehicle. DeÔ¨Ånition 5 (EDR mobility pattern) The last most recent time frame of the vehicle dynamics during the last itinerary available from a nonvolatile EDR storage deÔ¨Ånes the vehicle mobility pattern. A static vehicle and the corresponding keyfob share this mobility trace as a common internal state of the vehicle. Record retrieval process: IEEE 1616a [7, 8] deÔ¨Ånes event observation and recording process. The event primitives such as acceleration, deceleration, steering angle/movement, velocity, and seat position, accounts for driving decisions taken during a crash incident. The record extraction is feasible as one of the connections given below: A serial data link communication path to the vehicle diagnostic communication port that is onboard diagnostic (OBDII) or SAE J1962 [10]. A serial data link communication path connected via a direct cable to the target ECU (a partial set of events). A direct cable to the EEPROM component on the printed circuit board (PCB) within the EDR assembly. This method is more vulnerable to security attacks because it overrides the security barriers for module access control. SAE J1962 port deÔ¨Ånes the requirements of an OBD connector and is technically equivalent to ISO/DIS 150313:2001. While motor vehicle event data recorder connector lockout apparatus (MVEDRCLA) is an amendment to IEEE 1616. It deÔ¨Ånes a device conÔ¨Åguration to physically secure OBD II connector, primarily used to access the EDR (and other vehicle systems) such that it prevents tampering and unauthorized access to critical data. Surprisingly, there are only a few security integration protocols [14] to enable data conÔ¨Ådentiality, integrity, and availability regarding EDR components. EDR is deployed as a black box component whereas the inputoutput data security is left on to the vehicle vendor. A secure EDR integration to the internal vehicle network is assumed to be part of security features used for internal network components itself. 3.2. Overview Our scheme provides a solution against the distance and maÔ¨Åa fraud attacks. Moreover, the terrorist fraud scenario requires additional assumptions, i.e., biometrics and consumerfriendly hardware to verify biometric features. A preprocessing phase and the subsequent usage of cryptographic primitives is given as below: 10Setup phase (Key generation): The manufacturing authority initializes a security module, Init(Auth ) with a secret symmetric key K(for both vehicle and keyfob) before even handing it over to the consumer. Registration phase (Binding a symmetric key with the user identity): The next phase is to bind a vehicle to keyfob at the time of handing it (a vehicle and a keyfob) over to a speciÔ¨Åc consumer u. Accordingly, the registration phase is required to associate the preinitialized symmetric key, K, in the setup phase, Init(Auth ), with the keyfob and the user, i.e., (K,kf,v,u): binding a user uwith a vehiclev, a keyfob kf, and the symmetric key K. It must be noticed that the user identity uis crucial for the initial binding such as creating an administrator account. Initially, event records are null and do not provide a linkage between any keyfob holder, as in the past and in the current. Query phase (Attempt to attack): In the query phase, an adversary Autilizes the knowledge of the symmetric key K(from thennumber of transcripts, say tn, extracted during nsessions in past) and performs the following sequence of message exchange: The prover keyfob kfsends (K,kf,v,u)to a veriÔ¨Åer vehicle vrequesting for an access permission. An adversaryAretrieves (K,kf,v,u)and relays (K,kfadv,v,u)to the verifying vehicle v. The verifying vehicle vveriÔ¨Åes (K,kfadv,v,u)before granting any access permission, i.e., Check‚Üê(K,kfadv,v,u). Next, we present an authentication game to deÔ¨Åne the adversary advantage over the proposed scheme Auth . The security game for the proposed authentication scheme Auth , adversaryA, prover kfand an authentic veriÔ¨Åer vis given as below: Proposition 1 An adversaryAwins the game if [Check =1]. The probabilistic advantage of adversary, Adv(A), for winning the game is Adv(A) =Pr[Check = 1] SpeciÔ¨Åcally, the vehicle to keyfob authentication scheme Auth is secure if the Adv(A)is negligible. In addition, Pr[Check = 1] is maximum during the initial rounds of pairing when event log is almost null. 4. Proposed Scheme We propose an authentication scheme (Figure 3) for a remote vehicle access control that would authenticate the original keyfob of the vehicle and then give access to the paired vehicle. This access control can be perceived as an authorization check for services within the periphery of a vehicle. The authentication begins with an initial veriÔ¨Åcation based on the event log replication. The event log is overwritten with every new event occurrence and keeps recording only recent few seconds of vehicle dynamics. Concurrently, vehicle event logs can be replicated over the peripheral device. Therefore, a peripheral device in possession of the most recent event logs would be authorized as a most recent occupant. First, we present a simple authentication approach for peripheral devices, e.g., cell phone, USB stick, iPod, laptop, and other Bluetooth devices. Later, we propose a customized authentication scheme (in Figure 4) based on the simple authentication scheme (as in Figure 3). 11Vehicle (v) Device (pd) (K) (K) [H(ed)pd,idpd,nounce pd]EncK‚Üê‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí pairing request‚Üê‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí Authorize [H(ed)pd, idpd] Store (nounce pd) [idv,Cv,nounce pd]EncK‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚Üí Reciprocate pairing‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚Üí Authorize idv Store (Cv) Compute (Rpd) [Rpd,nounce pd]EncK‚Üê‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí Verify [Rpd] Ifmatches Then accept 1Figure 3: Peripheral authentication scheme. 4.1. Peripheral Authentication Scheme: Basic Scheme As detailed in Figure 3, a vehicle receives the pairing request from a peripheral device. The request begins with an encrypted identiÔ¨Åcation information from a speciÔ¨Åc peripheral device pdthat sends the hash of shared internal state H(ed), identityidpd, and a sequence number nouncepd. The event information is securely hashed in an abstract form. The vehicle and device share a symmetric keyK(as detailed in setup and registration phase), and all handshake messages are encrypted with K. Next, the vehicle veriÔ¨Åes the pairing request as: ( i) Is the requesting device storing the similar internal state as H(ed)v=H(ed)pd(i.e., the device has been used during most recent drive in past)? (ii) Is the requesting device possessing an authentic identity as pdid? (iii) Is the requesting device using a unique nounce as nouncepd? In the second step, after the successful veriÔ¨Åcation of the initial commitment, the vehicle sends a challenge Cvwith the vehicle identity idv, and the nouncepd, all are encrypted using the key K. The device authenticates the reciprocated values, i.e., idv, and paired nouncepd. In addition, the device produces and sends the corresponding response Rpdwithnouncepd. The device inputs the received challenge Cvto the hash function Hand generates an output response asH(Cv)=Rpd. The verifying vehicle checks the reactive response Rpd, if the response match is found, then the vehicle accepts the device pairing request and grants the access. This authentication scheme might be vulnerable to distance attacks in case of a remote peripheral access, e.g., a remote keyfob to vehicle pairing. Therefore, we now present a customized scheme for vehicle to keyfob authentication. 4.2. Vehicle to Keyfob Authentication Scheme: Customized Scheme The authentication scheme for a remote vehicle access is more crucial than a local peripheral device access. In our approach, (as detailed in Figure 4), we provide a threeway handshake (similar to the basic scheme) such that each handshake is used to couple an earlier veriÔ¨Åed handshake. Also, the vehicle to keyfob authentication incorporates an authentication with human attribution. Next, we provide deÔ¨Ånitions for the personiÔ¨Åed attributes such as gait, displacement, and gait observation. DeÔ¨Ånition 6 (Gait) A dynamic keyfob holder has a distinguishable gait in terms of the velocity (displacement per unit time) and stride (distance covered per step). 12DeÔ¨Ånition 7 (Displacement) The distance covered by the keyfob holder at a varying velocity during the observation interval, i.e., from access solicitation (in the Ô¨Årst step) to time split received (in the second step). DeÔ¨Ånition 8 (Gait observation) A dynamic keyfob holder, approaching the static vehicle and simultaneously requesting the access permission, should be distinguishable from any malicious third party. The vehicle veriÔ¨Åes the deviation in local observation and original keyfob observation regarding dynamic locomotion pattern. Vehicle (v) Keyfob (kf) (K) (K) [H(ed)kf,tkf send,nounce kf]EncK‚Üê‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí Relay (ttravel +trelay) ‚Üê‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí Authorize H(ed)kf Store (tkf send,nounce kf) Split clock (tv recieveto tv send) [H(idv),Cv,(tv recieve,tv send),nounce kf]EncK‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚Üí Relay (ttravel +trelay) ‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚Üí Authorize H(idv) Store (Cv,(tv recieve, tv send), tkf cur) Compute (Rkf,(velkf,disp kf)) [H(Rkf),idv,(velkf,disp kf),tkf cur,nounce kf]EncK‚Üê‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àídisplacement‚Üê‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚Üí Relay (ttravel +trelay) ‚Üê‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí Verify [H(Rkf),(velkf,velv kf)] Ifmatches Then accept Else Reinitiate with Cnew 1 Figure 4: Vehicle to keyfob authentication. These attributes as mentioned above deÔ¨Åne an interactive veriÔ¨Åcation of the owner. The threeway handshake as presented in Figure 4 is detailed below: Keyfob soliciting the access permission: In the Ô¨Årst step , a keyfob holder initiates an access request to a static vehicle. The request should be encrypted with the symmetric key Kas originated from the authentic keyfob, accompanied with the EDR mobility pattern that was recorded during the last drive. The request [H(ed)kf,tkf send,nounce kf]EncKconsists of hashed internal state H(ed), which contains EDR mobility pattern, a time stamp tkf send, and a unique nounce kf, for observing the gait and avoiding replay attacks, respectively. Vehicle challenging the keyfob: In the second step , the vehicle veriÔ¨Åes the received hashed EDR mobility pattern H(ed)kfwithH(ed)vthat must be known to an authentic keyfob that has the knowledge of the symmetric key K. Moreover, the vehicle mobility pattern must be known to a keyfob iff it was used during the last drive. The vehicle stores the time stamp tkf sendas the time when the access request was initialized by the keyfob holder. In addition, the vehicle stores a local time stamp tv receive and the time difference ( tv receive‚àítkf send), which will yield the propagation time that request has taken while traversing over the channel. It must be noticed that the presence of a relay attack in between the static vehicle and the dynamic keyfob holder will yield a higher propagation time as compared to regular communication, i.e., (tv receive‚àítkf send)A>(tv receive‚àítkf send)regular , due to additional relaying times consumed at the adversray (A) in middle, as compared to the regular communication. The vehicle sends an encrypted message [H(idv),Cv,(tv receive,tv send),nounce kf]EncKcontaining a challenge Cvand the local time stamps tv receive to complete the gait observation of requesting keyfob. 13Authentication process at the keyfob: Next, keyfob holder authorizes the signed vehicle id H(idv)with the same nounce as was initialized in the Ô¨Årst step (as shown in Figure 4). The clock split(tv receive,tv send)is used to compute the relative propagation time3in each step. We assume that the generation of paired response Rkffor the challenge Cvin the current round is based on a keyed pseudorandom number generator that is not known to an adversray. Therefore, the adversary can only generate a random response R/prime(instead of actual Rkf) for theCv, such that R/prime/negationslash=Rkfwithout knowing the secret key K. Otherwise, an adversary could send a random R/primeahead of time and demonstrate that R/primeis the authentic response (due to a lower propagation time from an adversary situated closer to the vehicle then the keyfob), i.e., Cvtraveled from vehicle to the original keyfob and an adversary in the middle responding with R/primeinstead ofRkf (which would have actually arrived a few seconds later then R/prime). The keyfob will process the local gait observation for the time slot ( tkf cur‚àítkf send). Therefore, the keyfob holder‚Äôs displacement dispkfduring this time interval will yield a velocity or a local gait observation velkf. Ideally, this gait observation at the keyfob holder and the same gait observation velv kfat the static vehicle must at least differ by an amount trelayto detect the presence of any relay attack. We would like to remark here that the two steps of handshake scheme verify proactive and reactive commitments. The last step of handshake scheme deals with the veriÔ¨Åcation of the personalized properties of an access grantee. In particular, an anthropomorphic feature, e.g., walking pattern or gait observation, is veriÔ¨Åed. There can be different attributes to personify and distinguish the original owner, e.g., key typing speed pattern, face scan [30], shake pattern [31] etc. Our focus is to integrate those personiÔ¨Åed attributes into last round of handshake veriÔ¨Åcation. Vehicle verifying the keyfob‚Äôs gait: The static vehicle veriÔ¨Åes the paired response H(Rkf)and the current session nounce. Next, the vehicle computes a local estimation of the keyfob holder‚Äôs gait. Accordingly, the keyfob holder should have been displaced by dispkf(from the second step) over the time interval ( tv send‚àítv receive ). Now, considering the presence of a relay attacker in Ô¨Årst and second steps, the local gait observation at the keyfob holder should differ by the local gait estimation at the static vehicle. Moreover, since the time window for the gait observation includes two propagation rounds; hence 2√ó(ttravel+trelay)should be suspiciously large enough with respect to 2√ó(ttravel)in a regular communication. Furthermore, our approach can be extended to the wellknown distance bounding protocols in which nnumber of CRP exchanging rounds are required to compute a precise measure over the round trip propagation time. In our case, if the gait based measurement at the static vehicle differs with the local observation at the keyfob holder, then the protocol should be reinitialized with a new challenge Cnew. Furthermore, even in a reinitialized session, the Ô¨Årst scenario can be used as a base case in distance bounding protocols. Therefore, our solution can further be extended to provide a distance bounding protocol estimation. Considering the issue of multiple drivers having access to the same vehicle during different time intervals; we suggest to incorporate an admin account (with full vehicle access) and a limited additional user accounts with partial/customized vehicle access. Therefore, each individual user 3For the practical deployament scenario time precision is a crucial issue, e.g., how frequently hardware clocks must be synchronized? what is the allowed measure for the clock drift? Therefore, we consider the strict event state veriÔ¨Åcation along with the gait veriÔ¨Åcation over the current clocksplit window allowing a predeÔ¨Åned amount of clock drift due to hardware limitations. 14account is accustomed to the correspondingly synchronized coupling between the keyfob and the internal state of the vehicle, i.e., keyfobadmin is synchronized with the user account admin . Similarly, a limited number of nuser accounts user account [1...n]are correspondingly synchronized with the keyfob [1...n]. In addition, a keyfob holder must possess a pedometer or an accelerometer for a precise selfgait observation, which nowadays is a common feature in smartphones. In fact, the cost and size for these utilities are consumer friendly in a sense that can also be integrated with something as small as a wireless keyfob. 5. Adaptation with Existing Commitment Schemes In this section, we illustrate further adaptations of our proposed solution based on initial knowledge pairing, i.e., proactive veriÔ¨Åcation, and anthropomorphic feature, i.e., reactive veriÔ¨Åcation. Interestingly, we choose two protocols, namely, Schnorr‚Äôs identitybased commitment scheme ( Œì) and Pedersen commitment scheme ( Œ†) based on the commitmentbeforeknowledge andComputational DifÔ¨ÅeHellman (CDH) assumptions. The message Ô¨Çow : Common inputs are (‚Ñò,q,g,G ) Keygen(pk,sk) :sk=a‚ààRF‚Ñòandpk=ga=A The protocol Œì(kf,v)steps for a kf(a,A)and a veriÔ¨Åer v(A)are given below: (kf‚Üív) M1: compute X=gx‚ààGsuch thatx‚ààRF‚Ñò (kf‚Üêv) M2: send challenge |such that |‚ààRF‚Ñò (kf‚Üív) M3: reply response œÅsuch thatœÅ=x+a‚àó| Schnorr‚Äôs protocol adaptation : 1.Commit: Initially, a prover kfcommits a secret value xby sendingX=gx‚ààGto a veriÔ¨Åer v. Next, the hashed string H(ed)kf(as derived using event data history ed) is concatenated with secret exponent gx, i.e., H(ed)||X. In this case, secret exponent xis not hidden but released secretly by just relying on the hardness assumption of DLproblem. Therefore, presumably, if an adversary is able to solve DLthen secret exponent partxof the commitment would not remain secure and overall security might fallback on H(ed)veriÔ¨Åcation only. 2.Challenge: The recipient vehicle vveriÔ¨Åes the hashed string based on event history, and also retrieve the concatenated value Xas a public version of the secret commitment x. After receiving a public value X, veriÔ¨Åer choose a random challenge |and send to the prover in order to seek for a valid paired response from an authentic prover kf. 3.Open: Consequently, prover kfgenerate a paired response as œÅ=x+a‚àó|. Interestingly, prover reveals the commitment value xin a subliminal way. Obviously, the veriÔ¨Åcation remains valid as long as gœÅ==XA| satisÔ¨Åes on veriÔ¨Åer side. Furthermore, there exist multiple variations to regular Schnorr like identiÔ¨Åcation scheme. For example, one possible way [34] is to replace œÅwith ÀÜœÅ, i.e., ÀÜgx+a‚àó|where ÀÜg=gH(X||). Figure 5: Adaptation with the Schnorr‚Äôs commitment protocol. As the protocol, Œìby Schnorr [33] and protocol Œ†by Chaum and Pedersen [35] both are based on DifÔ¨Åehellman (DH) key exchange. Therefore, wlog, we assume that corresponding computations are done within a group G=/angbracketleftg/angbracketrightof prime order q, where CDH assumption holds. 15DeÔ¨Ånition 9 Let/angbracketleftg/angbracketrightbe a cyclic group Ggenerated by an element gof an orderq. There is no efÔ¨Åcient probabilistic algorithm ACDH that given (g,ga,gb)producesgab, wherea,bare chosen at random from the group G. The CDH assumption satisÔ¨Åes that the computation of a discrete logarithm function DLon public values (g,ga,gb)is hard [32] within the cyclic group G. Schnorr‚Äôs scheme [33] The Schnorr‚Äôs identiÔ¨Åcation scheme Œìis a natural extension of commitmentbeforeknowledge based paradigm as detailed in Figure 5. According to protocol Œì, the prover chooses a secret DH exponent xand releases a public value Xfor the corresponding veriÔ¨Åer. Consequently, the veriÔ¨Åer returns a challenge |for the prover. Now, the prover generates a combined responseœÅsuch that it is computationally hard to compute œÅwithout possessing the knowledge of x and|, i.e.,œÅ=x+a‚àó|whereais the longterm secret key paired with longterm public key A presumably known to veriÔ¨Åer. Ultimately, the veriÔ¨Åer validates the received response œÅasgœÅ=XA| if correctly paired with the challenge |and public values Xor not. Pedersen commitment [35]. Here, we provide the review of commitment scheme Œ†as detailed in Figure 6. According to the Pedersen‚Äôs scheme, the system generates public values ( q,g,h,G ), where gandhare two generators such that g=hx, for a secret key x‚ààRG. Moreover, in order to commit a messagem, prover knows ( x,q,g,h,G ) and the veriÔ¨Åer knows ( q,g,h,G ), wherez=mxis observed as a signature along with the proof that loggh=logmz. The adapted solution further increases the security strength of the proposed scheme during second and third round of the handshake. It must be noticed that our scheme can incorporate other challengeresponse protocols as well. Therefore, the proposed solution is open to further application dependent improvements via security integration. The message Ô¨Çow : Prover kfknows (x,y)‚ààRF‚Ñòsuch that public key X= (gx‚àóhy). Common inputs are (‚Ñò,q,g,h,G ) (kf‚Üív) M1: compute commitment A=gs 1andB=hs 2 (kf‚Üêv) M2: send challenge |‚ààRF‚Ñò (kf‚Üív) M3: reply response œÅ1=s1+|‚àóxandœÅ2=s2+|‚àóy Pedersen‚Äôs protocol adaptation : 1.Commit: Initially, prover kfwants to commit a message m‚ààF‚Ñò. The prover chooses a random value (s1,s2)‚ààF‚Ñò, whereF‚Ñòis a Ô¨Ånite Ô¨Åeld with elements ( 0,1,...,‚Ñò‚àí1) and then compute the commitment C=A‚àóB, whereA=gs 1andB=hs 2in order to share with the veriÔ¨Åer v, i.e.,H(ed)kf||(c). 2.Challenge: The veriÔ¨Åer vcomputes the hashed string based on event data history and verify locally. After the veriÔ¨Åcations vreturns a challenge |‚ààRF‚Ñòto prover. 3.Open: The veriÔ¨Åer vaccepts the proof of commitment if gœÅ1‚àóhœÅ2=XC|. Figure 6: Adaptation with the Pedersen‚Äôs commitment protocol. 6. Security Analysis In this section, we present a security analysis based on the following Assumptions 1 and 2. Assumption 1 is related to adversary model or adversarial behavior per se, i.e., a restriction on 16storeandforward syndrome (Condition 1) at an adversary. While, Assumption 2, in particular, speciÔ¨Åes the signiÔ¨Åcance of synchronized (at least within the predetermined threshold) observation windows at the static vehicle and the corresponding keyfob holder, respectively. Next, we provide Condition 1 and the related assumptions as below: Condition 1 According to a storeandforward syndrome, an adversary, while actively listening to the radio signals from an authentic access grantee (not closer to the static vehicle), ‚Äúintentionally‚Äù delays the radio signal relaying so as to adapt the locomotion pattern of an authentic access grantee. Condition 1 presents a syndrome that an adversary might gain a fake access. However, the Assumption 1 presents that an adversary cannot exercise the storeandforward syndrome inconsistently, since that would yield a noticeable variation in any two consecutive propagation delay, i.e., with an adversary and without an adversary. Obviously, an adversary has to relay the communication consistently so as to remain undetectable. However, an adversary cannot relay the signals consistently because that would manipulate the locomotion pattern ( velv kf,dispv kf) of keyfob holder as observed by the vehicle. Assumption 1 An adversaryAcannot utilize the storeandforward syndrome either consistently or inconsistently, such that: (i) (tkf cur‚àítkf send)>(tv receive‚àítv send)+t/epsilon1‚Äòor‚Äô (ii)trelayis constant, respectively. Assumption 2 presents the similar observation at vehicle and keyfob, simultaneously. The deviation beyond a threshold t/epsilon1would raise an alarm of relayed communication. It might result in false negatives (in which case handshake must be reinitialized) rather false positives. Assumption 2 The gait observation at the static vehicle and the dynamic keyfob holder should not differ beyond a threshold delay t/epsilon1, i.e. (ttravel+t/epsilon1/similarequalttravel), where (t/epsilon1<trelay). Let us assume that an adversary Arelays the messages between the static vehicle and corresponding keyfob while trelay is independent of ttravel. The adversary relay the messages successively for nrounds and has the advantage as Adv(A) =Pr(1/2n). Now, considering the advantage that adversary Atrelaycan relay the messages only within the time bounds ( ttravel +trelay). Thus, the advantage Adv(Atrelay) = (A)‚àóPr(trelay>t/epsilon1)or = [(1/2)‚àóPr(trelay>t/epsilon1)‚àóPr(2trelay>t/epsilon1)‚àó(3trelay>t/epsilon1)] The probability of time ( trelay) bound adversary winning the advantage is directly proportional to the difference in ( trelay,t/epsilon1). Assuming that for every succeeding round the difference would accumulate and thus, ( Pr(2trelay> t/epsilon1)>0) in the second round. Thereby, on average with every succeeding round, there is at least as many chances to win as Pr(1/2). Evidently, the proposed approach with average timebound ( trelay) for every succeeding round would restrict the advantage to Adv(A)‚àíAdv(Atrelay). The proposition 2 illustrates the hard and rock situation for the adversary, i.e., an adversary will either be present consistently throughout multiple rounds or will be present for selective rounds only. In both cases, the presence of any relayed communication can be detected. Proposition 2 If the adversary is present in only one of the Ô¨Årst two rounds it must be revealed to both vehicle and the keyfob, by the end of step 3. Conversely, if the adversary is present uniformly throughout the course of gait observation it would be accountable via differing gait observations. The proposition 3 emphasize that any observable dynamics (location vs distance) will distinguish between a regular communication and an affected communication. 17Proposition 3 No adversary can relay the messages such that both gait observations at the vehicle velv kfand the keyfob velkfare equivalent or within the bounds of t/epsilon1. The presence of an adversary will yield ( velv kf>velkf). Theorem 1 proves an impossibility to extract the predetermined state of the vehicle, i.e., an exact series of events; given that an adversary is allowed to observe the vehicle movements during the last itinerary of that vehicle. Precisely, the proof is based on the number of geometric trajectories that a vehicle could possibly drive through during last itinerary, i.e., state based on the most recent driving pattern. Theorem 1 The series of event occurrence while following a continuous geometric trajectory is predictable with only a negligible probability. Proof. Let us consider a subset Lthat encompasses straightline trajectories in a set, say, Sdenoted asy=mx+b, where (x,y) are coordinates, mis the slope, and bis the intercept with the yaxis. Now considering the closed interval [ w,z] in which the line expands across the Euclidean plane. Interestingly, according to the Cantor‚Äôs uncountability proof, the number of points in a line segment of the trajectory is the same as in an entire line (onedimension) and as the number of points in a ndimensional space. Considering, ( i) cardinality of the straight line trajectories, ( ii) cardinality of the curved trajectories and ( iii) cardinality of the event series over continuous time series. Lemma 2 The cardinality of straight line trajectories Lin setSis the same as the cardinality of continuum. Proof. According to ( i) the cardinality of straight line trajectories Lspanning over the road segment is same as the cardinality of continuum C. Let us Ô¨Årst compute the cardinality of all possible line segments through a particular coordinate point with a different slope. Thus, all those line segments that have a unique slope from a right open interval [0,2œÄ)and Ô¨Åxed coordinates ( x,y) should be countable. Clearly, the cardinality of all these line trajectories is same as the Cbecause the unique slopemfor each line trajectory is parameterized by reals. Second, let us consider the other remaining subset of straight line trajectories that have a Ô¨Åxed slope mand expand for all possible ( x,y) intercepts. Analogous to the Cantor hypotheses the line segment would have as many points as any ndimensional space, therefore, there will be as many straight line trajectories as C. Consequently, there will beC‚àóC lines trajectories in total. Lemma 3 The cardinality of curved trajectories CinSis the same as the cardinality of straight line trajectories L. Proof. A one to one onto function can be assumed for a realistic trajectory followed by any vehicle. According to ( ii) the cardinality of curved trajectories, Ccan be derived from the cardinality of straight line trajectories as shown in Lemma 1. However, in spite of considering the cardinality of multidegree polynomials, we precisely consider the case of a parabolic trajectory and then additively generalize it to the multidegree curves. Since adding the cardinality of multidegree curves on top of the cardinality of parabolic trajectories will only populate the subset C, hence, will increase the cardinality. The derivation of any segment of a parabolic trajectory analogs the derivation of at least one pair of straight lines tangent to each other, which at most can be as many as pairs of real numbers. Furthermore, the slope of these tangent lines is uniquely determined at any point on the curve. Since the tangent slope is uniquely parameterized from a right open interval [0,2œÄ)as a real number it is straight that the cardinality of parabolic trajectories will have the cardinality of straight lines L. Therefore, the cardinality of subset Cis at least as big as the cardinality of Lthat isC. 18Lemma 4 The cardinality of the discrete event set over a continuous time function is also continuous hence continuum. Proof. Let us consider the probability of any discrete event occurrence on a continuous time series. The continuous time function can be imagined as a collection of overlapping intervals I={I1,I2,...In}, i.e.nindependent events can occur in ithintervalIi. Since the timeline is of the order of real numbers the probability of event occurrence is C/n. Lemma 5 An adversary has a negligible advantage in retrieving the exact series of tuples from the last driving interval. Proof. An adversary successfully retrieves the tuple {gt,time,e}if correctly predicts the geometric trajectory from Sand independent events eover continuous time series. Therefore, assuming a probabilistic polynomial time adversary, an attack would only have a negligible advantage as n/C. In particular, an adversary needs to have n/2‚Ñµ0number of attempts for a successful random guess in polynomial time. Consequently, an adversary will have a negligible advantage in retrieving the internal event state of the vehicle with respect to the geometric trajectory over different time intervals, hence, Theorem 1 is straight to articulate as below: The series of event occurrence during adjacent drives by the same vehicle through the same distance will always differ with a nonnegligible probability. Let us consider the events ( e) span over a 2d Euclidean plane with xaxis and yaxis. A continuous geometric trajectory ( gt) followed by the vehicle expands over the xaxis while still allowing the movement across yaxis such as during lane changing or curved maneuvering. An adversary Athat successfully predicts the recent internal state of the vehicle. In order to predict the replicated state preserved by the keyfob adversary must have predicted a series of tuples ( gt,t,e ). The geometric trajectory expands over a set Sof straight lines and curves, i.e., S={L,C}. It must be noticed that any curve inside the set Sis an umbrella term for a parabola or any higher degree polynomial. However, we prove that the parabolic trajectory covered by any vehicle between two different time stamps ( ti,tj) is unpredictable with a negligible probability. Therefore, the series of events (which might have been observed correctly from a relative distance) followed during that trajectory is also unpredictable with a negligible probability. The basic peripheral device authentication scheme does not assume any external channel bandwidth during the authentication except the computation requirements, i.e., 3 exponent and 1hash digest computation at each party.4While the vehicle to keyfob authentication scheme requires an additional communication overhead with a maximum packet size that can hold the hash digest in each communication round. In addition, other parameters such as nounce, identity, time, displacement are scalar values and does not require much payload size. Moreover, different IoT appropriate communication protocols such as WiÔ¨Å, WiÔ¨Å (with WEP, WPA, WPA2), Zigbee, Zwave, Bluetooth, 6LoWPAN, varies within the 64 Byte (minimum) to 2324 Byte (maximum) range. Therefore, we asume that the proposed scheme is feasible for deployment in IoT settings with the available communication protocols. 7. Related Work "
2,Angular Softmax Loss for End-to-end Speaker Verification.txt,"End-to-end speaker verification systems have received increasing interests.
The traditional i-vector approach trains a generative model (basically a
factor-analysis model) to extract i-vectors as speaker embeddings. In contrast,
the end-to-end approach directly trains a discriminative model (often a neural
network) to learn discriminative speaker embeddings; a crucial component is the
training criterion. In this paper, we use angular softmax (A-softmax), which is
originally proposed for face verification, as the loss function for feature
learning in end-to-end speaker verification. By introducing margins between
classes into softmax loss, A-softmax can learn more discriminative features
than softmax loss and triplet loss, and at the same time, is easy and stable
for usage. We make two contributions in this work. 1) We introduce A-softmax
loss into end-to-end speaker verification and achieve significant EER
reductions. 2) We find that the combination of using A-softmax in training the
front-end and using PLDA in the back-end scoring further boosts the performance
of end-to-end systems under short utterance condition (short in both enrollment
and test). Experiments are conducted on part of $Fisher$ dataset and
demonstrate the improvements of using A-softmax.","Speaker veriÔ¨Åcation is a classic task in speaker recognition, which is to determine whether two speech segments are from the same speaker or not. For many years, most speaker veriÔ¨Åca tion systems are based on the ivector approach [1]. The ivector approach trains a generative model (basically a factoranalysis model) to extract ivectors as speaker embeddings, and relies on variants of probabilistic linear discriminant analysis (PLDA) [2] for scoring in the backend. Endtoend speaker veriÔ¨Åcation systems have received in creasing interests. The endtoend approach directly trains a discriminative model (often a neural network) to learn discrim inative speaker embeddings. Various neural network structures have been explored. Some studies use RNNs to extract the iden tity feature for an utterance [3][4][5][6][7]. Usually, the output at the last frame from the RNN is treated as the utterancelevel speaker embedding. Various attention mechanisms are also in troduced to improve the performance of RNNbased speaker veriÔ¨Åcation systems. There are also some studies based on CNNs [3][6][8][9][10], where the fbank features are fed into the CNNs to model the patterns in the spectrograms. In addition to exploring different neural network architec tures, an important problem in the endtoend approach is to ex plore different criteria (loss functions), which drive the network to learn discriminative features. In early studies, the features ex tracted by the neural networks are fed into a softmax layer and This work is supported by NSFC grant 61473168. Correspondence to: Z. Ou (ozj@tsinghua.edu.cn). Speaker 1 Speaker 2 Speaker 3 Speaker n 1 Speaker n‚Ä¶‚Ä¶ ‚Ä¶‚Ä¶ ‚Ä¶‚Ä¶ ‚Ä¶‚Ä¶ ‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶ Feature extractor  Similarity score Train the modelUtterances for training Utterances for enrollment Utterances for testing ‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶(a)VeriÔ¨Åcation task (b)ClassiÔ¨Åcation task Figure 1: Speech Utterances are represented by small yellow blocks. Each row represents a speaker with a number of utter ances. The above illustrates the veriÔ¨Åcation task, which con sists of feature extraction and scoring. The speakers used for training the feature extractor usually do not appear in testing. The bottom shows the classiÔ¨Åcation task. The speakers used for training the classiÔ¨Åer appear in testing. Namely, in testing, ut terances from the same set of training speakers are presented for classiÔ¨Åcation. the cross entropy is used as the loss function. This loss is gener ally referred to as ‚Äúsoftmax loss‚Äù. But the softmax loss is more suitable for classiÔ¨Åcation tasks (classifying samples into given classes). In contrast to classiÔ¨Åcation, veriÔ¨Åcation is an open set task. Classes observed in the training set will generally not appear in the test set. Figure 1 shows the difference between the classiÔ¨Åcation and veriÔ¨Åcation tasks. A good loss for veriÔ¨Å cation should push samples in the same class to be closer, and meanwhile drive samples from different classes further away. In other words, we should make interclass variances larger and intraclass variances smaller. A number of different loss func tions have been proposed to address this problem [6][11][12]. Triplet loss [13] is recently proposed to take interclass and intraclass variances into consideration. Triplet loss based train ing requires a careful triplet selection procedure, which is both timeconsuming and performancesensitive. There are some interesting efforts to improve the triplet loss based training, such as generating triplets online from within a minibatch [13], do ing softmax pretraining [6]. However, training with the triplet loss remains to be a difÔ¨Åcult task. Our experiment of using triplet loss yields inferior performance, compared to the ivector method. Angular softmax (Asoftmax) loss [14] is recently proposed to improve the softmax loss in face veriÔ¨Åcation. It enables end toend training of neural networks to learn angularly discrim inative features. Asoftmax loss introduces a margin between the target class and the nontarget class into the softmax loss. The margin is controlled by a hyperparameter m. The larger mis, the better the network will perform. Compared with the triplet loss, Asoftmax is much easier to tune and monitor. In this paper, we introduce Asoftmax loss into endtoend speaker veriÔ¨Åcation, as the loss function for learning speaker embeddings. In [14], cosine distance is used in the backend scoring. Beyond of this, we study the combination of using A softmax in training the frontend and using PLDA in the back end scoring. Experiments are conducted on part of the Fisher dataset. The neural network structure is similar to that used by the Kaldi xvector [15]. Using Asoftmax performs signiÔ¨Å cantly better than using softmax and triplet loss. The EERs of Asoftmax system are the best on almost all conditions, except that both the enroll and the test utterances are long. It is known that the ivector based system performs well under such long utterance condition [12, 8]. We also Ô¨Ånd that under short utter ance condition (short in both enrollment and test), using PLDA in the backend can further reduce EERs of the Asoftmax sys tems. 2. Method "
193,Identifying Source Speakers for Voice Conversion based Spoofing Attacks on Speaker Verification Systems.txt,"An automatic speaker verification system aims to verify the speaker identity
of a speech signal. However, a voice conversion system could manipulate a
person's speech signal to make it sound like another speaker's voice and
deceive the speaker verification system. Most countermeasures for voice
conversion-based spoofing attacks are designed to discriminate bona fide speech
from spoofed speech for speaker verification systems. In this paper, we
investigate the problem of source speaker identification -- inferring the
identity of the source speaker given the voice converted speech. To perform
source speaker identification, we simply add voice-converted speech data with
the label of source speaker identity to the genuine speech dataset during
speaker embedding network training. Experimental results show the feasibility
of source speaker identification when training and testing with converted
speeches from the same voice conversion model(s). In addition, our results
demonstrate that having more converted utterances from various voice conversion
model for training helps improve the source speaker identification performance
on converted utterances from unseen voice conversion models.","An automatic speaker veriÔ¨Åcation system veriÔ¨Åes the identity of speakers by analyzing audio signals. Speaker veriÔ¨Åcation is a vi tal biometric technology in realworld applications, such as call centers for banking systems, smartphones, smart speakers, and other InternetofThings devices. As such applications are inher ently securitycritical, the robustness of speaker veriÔ¨Åcation systems against spooÔ¨Ång attacks is of the utmost importance. Even with the recent advance in speaker modeling enabled by deep neural net works (DNN) [1, 2], speaker veriÔ¨Åcation systems are susceptible to malicious spooÔ¨Ång attacks [3]. Between the process of signal acquisition and veriÔ¨Åcation result deliveries, the speaker veriÔ¨Åcation system can be manipulated or at tacked in various ways [3]. Among these attacks, imposter spooÔ¨Ång at the microphone or during signal transmission is the most typical one. Recent studies have demonstrated that most speaker veriÔ¨Åcation systems are unprotected from various spooÔ¨Ång attacks, such as im personations [4], replays [5], speech synthesis [6], voice conversion [7], and adversarial attacks [8]. On the other hand, countermeasures have been developed to defend speaker veriÔ¨Åcation systems from these spooÔ¨Ång attacks [3, 9, 10]. The Automatic Speaker VeriÔ¨Åca tion SpooÔ¨Ång And Countermeasures Challenge (ASVspoof) series Corresponding author: Ming Liare being held to support independent assessments of vulnerabili ties to spooÔ¨Ång and to assess the performance of countermeasures against spooÔ¨Ång [11, 12]. This study focuses on the spooÔ¨Ång attack of voice conversion on speaker veriÔ¨Åcation systems. V oice conversion involves manip ulating a speech signal of the original person (i.e., source speaker) in order to make it sound more like the speaking voice of another person (i.e., target speaker) while preserving the linguistic content [13]. The application of deep learning has enhanced voice conver sion technologies in terms of voice naturalness and voice similarity [14, 15]. The improvement, however, raises concerns regarding pri vacy and authentication. Therefore, preventing the incorrect use of one‚Äôs voice with voice conversion technologies becomes more and more important. Various approaches have been proposed for speaker veriÔ¨Åca tion systems to defend against the spooÔ¨Ång attack of voice conver sion. These countermeasures are usually designed to discriminate bona Ô¨Åde speech from spoofed speech for speaker veriÔ¨Åcation sys tems. However, none of these countermeasures provide the ability of source speaker identiÔ¨Åcation ‚Äì inferring the identity of the source speaker given the voice converted speech. Source speaker identi Ô¨Åcation has potential applications in crime investigation and judi cial procedures. For example, source speaker identiÔ¨Åcation can help identify a suspect involved in Ô¨Ånancial fraud with voice conversion based impersonation spooÔ¨Ång. Typically, a voice conversion system consists of two mod ules ‚Äì acoustic feature conversion and waveform generation [16]. The feature conversion module changes the spectral feature of the source speaker towards the target speaker by manipulating speaker related characteristics, such as prosody, pitch, and formants. The waveform generation module reconstructs the timedomain speech signals from the converted spectral feature. Generally speaking, feature conversion algorithms can be categorized into three groups  encoderdecoder models [17], generative adversarial network (GAN)based models [15] and parallel spectral feature mapping models [18]. These algorithms, however, are far from perfect. The converted speech, to some extent, still retains the voice style of the source speaker. For example, the speakerrelated linguistic fac tors reÔ¨Çected in sentence structure, lexical choice, and idiolect are Ô¨Åxed and can not be altered by a voice conversion system. For the encoderdecoderbased feature conversion, speakerdependent fac tors and speakerindependent factors can not be perfectly decoupled by the encoder. The information leak of the source speaker in the speakerindependent factors will be retained during the decoding phase. For the GANbased feature conversion, the use of the cy cle consistency mechanism [19] imposes a strict ‚Äútimefrequency bin level‚Äù constraint during the generation process so that speakerarXiv:2206.09103v2  [eess.AS]  31 Oct 2022irrelevant features are retained [20]. Since the voice converted speech contains information of both source and target speakers, we can train the speaker model to rec ognize the converted speech as the source speaker. By setting the converted speech label as the source speaker‚Äôs identity, we train the speaker model with converted speech and bona Ô¨Åde speech, encour aging the speaker model to extract source speaker information from the converted speech while maintaining a discriminative speaker em bedding space. From the defender‚Äôs perspective, source speaker identiÔ¨Åcation can be classiÔ¨Åed into white and black boxes identiÔ¨Åcation. In white box identifying, the defender can access the structure and param eters of the voice conversion models used by attackers. In black box source speaker identiÔ¨Åcation, the voice conversion models used by attackers are hidden to the defender. This paper demonstrates that source speaker identiÔ¨Åcation is feasible under the white box identifying protocol: speaker veriÔ¨Åcation systems can be trained to recognize the source speaker of the voice converted speech. Also, training the speaker model with converted speeches from multiple voice conversion models improves the performance of blackbox source speaker identiÔ¨Åcation compared to training with converted speeches generated by only one voice conversion model. This re sult indicates that commonality exists among converted speech from different voice conversion algorithms, and general blackbox source speaker identiÔ¨Åcation is possible. To the best of our knowledge, this study is the Ô¨Årst to investigate the problem of source speaker identi Ô¨Åcation for voice conversionbased spooÔ¨Ång attacks on speaker ver iÔ¨Åcation systems. 2. RELATED WORKS "
37,Optimization and Abstraction: A Synergistic Approach for Analyzing Neural Network Robustness.txt,"In recent years, the notion of local robustness (or robustness for short) has
emerged as a desirable property of deep neural networks. Intuitively,
robustness means that small perturbations to an input do not cause the network
to perform misclassifications. In this paper, we present a novel algorithm for
verifying robustness properties of neural networks. Our method synergistically
combines gradient-based optimization methods for counterexample search with
abstraction-based proof search to obtain a sound and ({\delta}-)complete
decision procedure. Our method also employs a data-driven approach to learn a
verification policy that guides abstract interpretation during proof search. We
have implemented the proposed approach in a tool called Charon and
experimentally evaluated it on hundreds of benchmarks. Our experiments show
that the proposed approach significantly outperforms three state-of-the-art
tools, namely AI^2 , Reluplex, and Reluval.","In recent years, deep neural networks (DNNs) have gained enormous popularity for a wide spectrum of applications, ranging from image recognition[ 21,28] and malware detec tion [ 57,58] to machine translation[ 55]. Due to their surpris ing effectiveness in practice, deep learning has also found numerous applications in safetycritical systems, including selfdriving cars [ 3,5], unmanned aerial systems [ 24], and medical diagnosis [9]. Despite their widespread use in a broad range of applica tion domains, it is wellknown that deep neural networks are vulnerable to adversarial counterexamples , which are small perturbations to a network‚Äôs input that cause the network to output incorrect labels [ 10,40]. For instance, Figure 1 shows two adversarial examples in the context of speech recognition and image classification. As shown in the top half of Figure 1, two sound waves that are virtually indis tinguishable are recognized as ‚ÄúHow are you?"" and ‚ÄúOpen the door"" by a DNNbased speech recognition system [ 16]. Similarly, as illustrated in the bottom half of the same figure, applying a tiny perturbation to a panda image causes a DNN to misclassify the image as that of a gibbon. It is by now wellunderstood that such adversarial coun terexamples can pose serious security risks [ 56]. Prior work [ 4, 14,25,41,42] has advocated the property of local robust ness (orrobustness for short) for protecting neural networks against attacks that exploit such adversarial examples. To understand what robustness means, consider a neural net work that classifies an input xas having label y. Then, local robustness requires that all inputs x‚Ä≤that are ‚Äúvery similar‚Äù1 toxare also classified as having the same label y. 1For example, ‚Äúvery similar‚Äù may mean x‚Ä≤is within some œµdistance from x, where distance can be measured using different metrics such as L2norm.arXiv:1904.09959v2  [cs.PL]  1 May 2019PLDI ‚Äô19, June 22‚Äì26, 2019, Phoenix, AZ, USA Greg Anderson, Shankara Pailoor, Isil Dillig, and Swarat Chaudhuri ""Panda"" ""Gibbon"" perturbationperturbation ""How are you?"" ""Open the door"" Figure 1. Small perturbations of the input cause the sound wave and the image to be misclassified. Due to the growing consensus on the desirability of ro bust neural networks, many recent efforts have sought to algorithmically analyze robustness of networks. Of these, one category of methods seeks to discover adversarial coun terexamples using numerical optimization techniques such as Projected Gradient Descent (PGD) [ 34] and Fast Gradient Sign Method (FGSM) [17]. A second category aims to prove network robustness using symbolic methods ranging from SMTsolving [ 25] to abstract interpretation [ 14,54]. These two categories of methods have complementary advantages. Numerical counterexample search methods can quickly find violations, but are ‚Äúunsound‚Äù, in that they fail to offer cer tainty about a network‚Äôs robustness. In contrast, proof search methods are sound, but they are either incomplete [ 14] (i.e., suffer from false positives) or do not scale well [25]. In this paper, we present a new technique for robustness analysis of neural networks that combines the best of proof based and optimizationbased methods. Our approach com bines formal reasoning techniques based on abstract inter pretation with continuous and blackbox optimization tech niques from the machine learning community. This tight coupling of optimization and abstraction has two key ad vantages: First, optimizationbased methods can efficiently search for counterexamples that prove the violation of the ro bustness property, allowing efficient falsification in addition to verification. Second, optimizationbased methods provide a datadriven way to automatically refine the abstraction when the property can be neither falsified nor proven. The workflow of our approach is shown schematically in Figure 2 and consists of both a training and a deployment phase. During the training phase, our method uses blackbox optimization techniques to learn a socalled verification pol icyœÄŒ∏from a representative set of training problems. Then the deployment phase uses the learned verification policy to guide how gradientbased counterexample search should be coupled with proof synthesis for solving previouslyunseen verification problems. The input to the deployment phase of our algorithm con sists of a neural network Nas well as a robustness specifica tion(I,K)which states that all points in the input region I should be classified as having label K. Given this input, our Abstract InterpreterAdversarial Ex. FinderNetwork Property V eriÔ¨Åed Refuted Datadriven policy learning algorithm  veriÔøΩcation  policyTraining problemsdeployment training SubproblemsFigure 2. Schematic overview of our approach. algorithm first uses gradientbased optimization to search for an adversarial counterexample, which is a point in the input region Ithat is classified as having label K‚Ä≤,K. If we can find such a counterexample, then the algorithm terminates with a witness to the violation of the property. However, even if the optimization procedure fails to find a true coun terexample, the result x‚àóof the optimization problem can still convey useful information. In particular, our method uses the learned verification policy œÄŒ∏to map all available information, including x‚àó, to a promising abstract domain A to use when attempting to verify the property. If the prop erty can be verified using domain A, then the algorithm successfully terminates with a robustness proof. In cases where the property is neither verified nor refuted, our algorithm uses the verification policy œÄŒ∏tosplit the input region Iinto two subregions I1,I2such that I=I1‚à™I2and tries to verify/falsify the robustness of each region separately. This form of refinement is useful for both the abstract in terpreter as well as the counterexample finder. In particular, since gradientbased optimization methods are not guaran teed to find a global optimum, splitting the input region into smaller parts makes it more likely that the optimizer can find an adversarial counterexample. Splitting the input re gion is similarly useful for the abstract interpreter because the amount of imprecision introduced by the abstraction is correlated with the size of the input region. As illustrated by the discussion above, a key part of our verification algorithm is the use of a policy œÄŒ∏to decide (a) which abstract domain to use for verification, and (b) how to split the input region into two subregions. Since there is no obvious choice for either the abstract domain or the splitting strategy, our algorithm takes a datadriven approach to learn a suitable verification policy œÄŒ∏during a training phase. During this training phase, we use a black box optimization technique known as Bayesian optimization to learn values of Œ∏that lead to strong performance on a representative set of verification problems. Once this phase is over, the algorithm can be deployed on networks and properties that have not been encountered during training.Optimization and Abstraction: A Synergistic Approach. . . PLDI ‚Äô19, June 22‚Äì26, 2019, Phoenix, AZ, USA Our proposed verification algorithm has some appeal ing theoretical properties in that it is both sound and Œ¥ complete [ 12]. That is, if our method verifies the property (I,K)for networkN, this means thatNdoes indeed clas sify all points in the input region Ias belonging to class K. Furthermore, our method is Œ¥complete in the sense that, if the property is falsified with counterexample x‚àó, this means thatx‚àóis withinŒ¥of being a true counterexample. We have implemented the proposed method in a tool called Charon2, and used it to analyze hundreds of ro bustness properties of ReLU neural networks, including both fullyconnected and convolutional neural networks, trained on the MNIST [ 30] and CIFAR [ 27] datasets. We have also compared our method against stateoftheart network ver ification tools (namely, Reluplex ,ReluVal , and AI2) and shown that our method outperforms all prior verification techniques, either in terms of accuracy or performance or both. In addition, our experimental results reveal the benefits of learning to couple proof search and optimization. In all, this paper makes the following key contributions: ‚Ä¢We present a new sound and Œ¥complete decision proce dure that combines abstract interpretation and gradient based counterexample search to prove robustness of deep neural networks. ‚Ä¢We describe a method for automatically learning verifi cation policies that direct counterexample search and ab stract interpretation steps carried out during the analysis. ‚Ä¢We conduct an extensive experimental evaluation on hun dreds of benchmarks and show that our method signif icantly outperforms stateoftheart tools for verifying neural networks. For example, our method solves 2.6√ó and16.6√ómore benchmarks compared to ReluVal and Reluplex respectively. Organization. The rest of this paper is organized as follows. In Section 2, we provide necessary background on neural networks, robustness, and abstract interpretation of neural networks. In Section 3, we present our algorithm for check ing robustness, given a verification policy (i.e., the deploy ment phase). Section 4 describes our datadriven approach for learning a useful verification policy from training data (i.e., the training phase), and Section 5 discusses the theo retical properties of our algorithm. Finally, Sections 6 and 7 describe our implementation and experimental evaluation, Section 8 discusses related work, and Section 9 concludes. 2 Background In this section, we provide some background on neural net works and robustness. 2Complete Hybrid Abstraction Refinement and Optimization for Neural Networks. ReLU 1 0 11 11 Layer 1 Layer 2 1 1 02 12 Figure 3. A feedforward network implementing XOR 2.1 Neural Networks A neural network is a function N:Rn‚ÜíRmof the form L1‚ó¶œÉ1‚ó¶¬∑¬∑¬∑‚ó¶œÉk‚àí1‚ó¶Lk, where each Liis a differentiable layer and eachœÉiis a nonlinear, almosteverywhere dif ferentiable activation function . While there are many types of activation functions, the most popular choice in modern neural networks is the rectified linear unit (ReLU) , defined as ReLU(x)=max(x,0). This function is applied elementwise to the output of each layer except the last. In this work, we consider feedforward and convolutional networks, which have the additional property of being Lipschitzcontinuous3. For the purposes of this work, we think of each layer Lias an affine transformation (W,b)where Wis aweight matrix andbis abias vector . Thus, the output of the i‚Äôth layer is computed as y=Wx+b. We note that both fullyconnected as well as convolutional layers can be expressed as affine transformations [ 14]. While our approach can also handle other types of layers (e.g., max pooling), we only focus on affine transformations to simplify presentation. In this work, we consider networks used for classification tasks. That is, given some input x‚ààRn, we wish to put x into one of mclasses . The output of the network y‚ààRmis interpreted as a vector of scores , one for each class. Then x is put into the class with the highest score. More formally, given some input x, we say the network Nassigns xto a class Kif(N(x))K>(N(x))jfor all j,K. Example 2.1. Figure 3 shows a 2layer feedforward neural network implementing the XOR function. To see why this network ‚Äúimplements‚Äù XOR, consider the vector [0 0]‚ä§. After applying the affine transformation from the first layer, we obtain[0‚àí1]‚ä§. After applying ReLU, we get [0 0]‚ä§. Finally, after applying the affine transform in the second layer, we get[1 0]‚ä§. Because the output at index zero is greater than the output at index one, the network will classify [0 0]‚ä§as a zero. Similarly, this network classifies both [0 1]‚ä§and[1 0]‚ä§ as1and[1 1]‚ä§as0. 2.2 Robustness (Local) robustness [ 4] is a key correctness property of neural networks which requires that all inputs within some region of the input space fall within the same region of the output space. Since we focus on networks designed for classification tasks, we will define ‚Äúthe same region of the output space‚Äù to mean the region which assigns the same class to the input. 3Recall that a function is Lipschitzcontinuous if there exists a positive real constant Msuch that, for all x1,x2, we have|f(x1)‚àíf(x2)|‚â§M|x1‚àíx2|PLDI ‚Äô19, June 22‚Äì26, 2019, Phoenix, AZ, USA Greg Anderson, Shankara Pailoor, Isil Dillig, and Swarat Chaudhuri One Zonotope Two  Zonotopes Figure 4. Zonotope analysis of a neural network. That is, a robustness property asserts that a small change in the input cannot change the class assigned to that input. More formally, a robustness property is a pair(I,K)with I‚äÜRnand0‚â§K‚â§m‚àí1. Here, Idefines some region of the input that we are interested in and Kis the class into which all the inputs in Ishould be placed. A network Nis said to satisfy a robustness property (I,K)if for all x‚ààI, we have(N(x))K>(N(x))jfor all j,K. Example 2.2. Consider the following network with two layers, i.e.,N(x)=W2(ReLU(W1x+b1))+b2where: W1=1 2 b1=‚àí1 1 W2=2 1 ‚àí1 1 b2=1 2 For the input x=0, we haveN(0)=[1 3]‚ä§; thus, the network outputs label 1 for input 0. Let I=[‚àí1,1]andK=1. Then for all x‚ààI, the output ofNis of the form[a+1a+2]Tfor some a‚àà[0,3]. Therefore, the network classifies every point inIas belonging to class 1, meaning that the network is robust in[‚àí1,1]. On the other hand, suppose we extend this interval to I‚Ä≤=[‚àí1,2]. ThenN(2)=[8 6]‚ä§, soNassigns input 2as belonging to class 0. Therefore Nisnotrobust in the input region[‚àí1,2]. 2.3 Abstract Interpretation for Neural Networks In this paper, we build on the prior AI2work [ 14] for an alyzing neural networks using the framework of abstract interpretation [7].AI2allows analyzing neural networks us ing a variety of numeric abstract domains, including intervals (boxes) [ 7], polyhedra [ 49], and zonotopes [ 15]. In addition, AI2also supports bounded powerset domains [7], which essen tially allow a bounded number of disjunctions in the abstrac tion. Since the user can specify any number of disjunctions, there are many different abstract domains to choose from,and the precision and scalability of the analysis crucially depend on one‚Äôs choice of the abstract domain. The following example illustrates a robustness property that can be verified using the bounded zonotope domain with two disjuncts but not with intervals or plain zonotopes: Example 2.3. Consider a network defined as: N(x)=1 1 .1 ‚àí1 1 ReLU1‚àí3 0 3 x+1 1 +‚àí3 1.2 As in the previous example, the first index in the output vector corresponds to class Aand the second index corre sponds to class B. Now, suppose we want to verify that for allx‚àà[0,1]2, the network assigns class Btox. Let us now analyze this network using the zonotope ab stract domain, which overapproximates a given region using a zonotope (i.e., centersymmetric polytope). The analysis of this network using the zonotope domain is illustrated in Figure 4. At first, the initial region is propagated through the affine transformation as a single zonotope. Then, this zonotope is split into two pieces, the blue (crosshatched) one for which x1‚â•0and the red (diagonally striped) one for which x1‚â§0. The ReLU transforms the red piece into a line. (We omit the ReLU over x2because it does not change the zonotopes in this case.) After the ReLU, we show two cases: on top is the plain zonotope domain, and on the bottom is a powerset of zonotopes domain. In the plain zonotope domain, the abstraction after the ReLU is the join of the blue and red zonotopes, while in the powerset domain we keep the blue and red zonotopes separate. The final images show how the second affine transformation affects all three zonotopes. This example illustrates that the propery cannot be veri fied using the plain zonotope domain, but it canbe verified using the powerset of zonotopes domain. Specifically, ob serve that the green (vertically striped) zonotope at the topOptimization and Abstraction: A Synergistic Approach. . . PLDI ‚Äô19, June 22‚Äì26, 2019, Phoenix, AZ, USA includes the point [1.2 1.2]‚ä§(marked by a dot), where the robustness specification is violated. On the other hand, the blue and red zonotopes obtained using the powerset domain do not contain any unsafe points, so the property is verified using this more precise abstraction. 3 Algorithm for Checking Robustness In this section, we describe our algorithm for checking ro bustness properties of neural networks. Our algorithm in terleaves optimizationbased counterexample search with proof synthesis using abstraction refinement. At a high level, abstract interpretation provides an efficient way to verify properties but is subject to false positives. Conversely, opti mization based techniques for finding counterexamples are efficient for finding adversarial inputs, but suffer from false negatives. Our algorithm combines the strengths of these two techniques by searching for both proofs and counterex amples at the same time and using information from the counterexample search to guide proof search. Before we describe our algorithm in detail, we need to define our optimization problem more formally. Given a networkNand a robustness property (I,K), we can view the search for an adversarial counterexample as the following optimization problem: x‚àó=arg min x‚ààI(F(x)) (1) where our objective functionFis defined as follows: F(x)=(N(x))K‚àímax j,K(N(x))j (2) Intuitively, the objective function Fmeasures the differ ence between the score for class Kand the maximum score among classes other than K. Note that if the value of this objective function is not positive at some point x, then there exists some class which has a greater (or equal) score than the target class, so point xconstitutes a true adversarial counterexample. The optimization problem from Eq. 1 is clearly useful for searching for counterexamples to the robustness property. However, even if the solution x‚àóis not a true counterexample (i.e.,F(x‚àó)>0), we can still use the result of the optimization problem to guide proof search. Based on this intuition, we now explain our decision pro cedure, shown in Algorithm 1, in more detail. The Verify procedure takes as input a network N, a robustness property (I,K)to be verified, and a socalled verification policy œÄŒ∏. As mentioned in Section 1, the verification policy is used to decide what kind of abstraction to use and how to split the input region when attempting to verify the property. In more detail, the verification policy œÄŒ∏, parameterized by Œ∏, is a pair (œÄŒ± Œ∏,œÄI Œ∏), whereœÄŒ± Œ∏is a (parameterized) function known as thedomain policy andœÄI Œ∏is a function known as the partition policy . The domain policy is used to decide which abstract domain to use, while the partition policy determines howAlgorithm 1 The main algorithm 1:procedure Verify (N,I,K,œÄŒ∏) input: A network N, robustness property (I,K)and ver ification policy œÄŒ∏=(œÄŒ± Œ∏,œÄI Œ∏) output: Counterexample ifNis not robust, or Verified. 2: x‚àó‚ÜêMinimize(I,F) 3: ifF(x‚àó)‚â§0then 4: return x‚àó 5:A‚ÜêœÄŒ± Œ∏(N,I,K,x‚àó) 6: ifAnalyze(N,I,K,A)=Verified then 7: return Verified 8:(I1,I2)‚ÜêœÄI Œ∏(N,I,K,x‚àó) 9: r1‚ÜêVerify(N,I1,K,œÄŒ∏) 10: ifr1,Verified then 11: return r1 12: return Verify(N,I2,K,œÄŒ∏) to split the input region Iinto two partitions to be analyzed separately. In general, it is quite difficult to write a good verification policy by hand because there are many different parameters to tune and neural networks are quite opaque and difficult to interpret. In Section 4, we explain how the parameters of these policy functions are learned from data. At a highlevel, the Verify procedure works as follows: First, we try to find a counterexample to the given robust ness property by solving the optimization problem from Eq. 1 using the wellknown projected gradient descent (PGD) technique. IfF(x‚àó)is nonpositive, we have found a true counterexample, so the algorithm produces x‚àóas a witness to the violation of the property. Otherwise, we try to verify the property using abstract interpretation. As mentioned in Section 2, there are many different ab stract domains that can be used to verify the property, and the choice of the abstract domain has a huge impact on the success and efficiency of verification. Thus, our approach leverages the domain policy œÄŒ± Œ∏to choose a sensible abstract domain to use when attempting to verify the property. Specif ically, the domain policy œÄŒ± Œ∏takes as input the network N, the robustness specification (I,K), and the solution x‚àóto the optimization problem and chooses an abstract domain A that should be used for attempting to prove the property. If the property can be verified using domain A, the algorithm terminates with a proof of robustness. In cases where the property is neither verified nor refuted in the current iteration, the algorithm makes progress by splitting the input region Iinto two disjoint partitions I1,I2 such that I=I1‚äéI2. The intuition is that, even if we cannot prove robustness for the whole input region I, we may be able to increase analysis precision by performing a case split. That is, as long as all points in both I1andI2are classified as having label K, this means that all points in Iare also assigned label Ksince we have I=I1‚à™I2. In cases wherePLDI ‚Äô19, June 22‚Äì26, 2019, Phoenix, AZ, USA Greg Anderson, Shankara Pailoor, Isil Dillig, and Swarat Chaudhuri Figure 5. The splits chosen for Example 3.1. the property is false, splitting the input region into two par tition can similarly help adversarial counterexample search because gradientbased optimization methods do not always converge to a global optimum. Based on the above discussion, the key question is how to partition the input region Iinto two regions I1,I2so that each ofI1,I2has a good chance of being verified or falsified. Since this question again does not have an obvious answer, we utilize our partition policy œÄI Œ∏to make this decision. Similar to the domain policy, œÄI Œ∏takes as input the network, the property, and the solution x‚àóto the optimization problem and ‚Äúcuts‚Äù Iinto two subregions I1andI2using a hyperplane. Then, the property is verified if and only if the recursive call toVerify is succsessful on both regions. Example 3.1. Consider the XOR network from Figure 3 and the robustness property ([0.3,0.7]2,1). That is, for all inputs xwith 0.3‚â§x1,x2‚â§0.7,xshould be assigned to class 1 (assume classes are zeroindexed). We now illustrate how Algorithm 1 verifies this property using the plain interval and zonotope abstract domains. The process is illustrated in Figure 5, which shows the splits made in each iteration as well as the domain used to analyze each region ( Zdenotes zonotopes, and Istands for intervals). Algorithm 1 starts by searching for an adversarial coun terexample, but fails to find one since the property actually holds. Now, suppose that our domain policy œÄŒ± Œ∏chooses zonotopes to try to verify the property. Since the property cannot be verified using zonotopes, the call to Analyze will fail. Thus, we now consult the partition policy œÄI Œ∏to split this region into two pieces I1=[0.3,0.5]√ó[ 0.3,0.7]and I2=[0.5,0.7]√ó[0.3,0.7]. Next, we recursively invoke Algorithm 1 on both sub regions I1andI2. Again, there is no counterexample for either region, so we use the domain policy to choose an abstract domain for each of I1andI2. Suppose that œÄŒ± Œ∏yields the zonotope domain for both I1andI2. Using this domain, we can verify robustness in I1but not in I2. Thus, for the second subproblem, we again consult œÄI Œ∏to obtain two subregions I2,1=[0.5,0.7]√ó[0.3,0.42]andI2,2=[0.5,0.7]√ó[0.42,0.7] and determine using œÄŒ± Œ∏thatI2,1,I2,2should be analyzed us ing intervals and zonotopes respectively. Since robustness can be verified using these domains, the algorithm success fully terminates. Notice that the three verified subregions cover the entire initial region.4 Learning a Verification Policy As described in Section 3, our decision procedure for check ing robustness uses a verification policy œÄŒ∏=(œÄŒ± Œ∏,œÄI Œ∏)to choose a suitable abstract domain and an input partitioning strategy. In this section, we discuss our policy representation and how to learn values of Œ∏that lead to good performance. 4.1 Policy Representation In this work, we implement verification policies œÄŒ± Œ∏andœÄI Œ∏ using a function of the following shape: œÜ(Œ∏œÅ(N,I,K,x‚àó)) (3) whereœÅis afeaturization function that extracts a feature vector from the input, œÜis aselection function that converts a realvalued vector to a suitable output (i.e., an abstract domain for œÄŒ± Œ∏and the two subregions for œÄI Œ∏), andŒ∏corre sponds to a parameter matrix that is automatically learned from a representative set of training data. We discuss our featurization and selection functions in this subsection and explain how to learn parameters Œ∏in the next subsection. Featurization. As standard in machine learning, we need to convert the input Œπ=(N,I,K,x‚àó)to a feature vector. Our choice of features is influenced by our insights about the verification problem, and we deliberately use a small number of features for two reasons: First, a large number of dimensions can lead to overfitting and poor generalization (which is especially an issue when training data is fairly small). Second, a highdimensional feature vector leads to a more difficult learning problem, and contemporary Bayesian optimization engines only scale to a few tens of dimensions. Concretely, our featurization function considers several kinds of information, including: (a) the behavior of the net work near x‚àó, (b) where x‚àófalls in the input space, and (c) the size of the input space. Intuitively, we expect that (a) is useful because as x‚àócomes closer to violating the specification, we should need a more precise abstraction, while (b) and (c) in form how we should split the input region during refinement. Since the precision of the analysis is correlated with how the split is performed, we found the same featurization function to work well for both policies œÄŒ± Œ∏andœÄI Œ∏. In Section 6, we discuss the exact features used in our implementation. Selection function. Recall that the purpose of the selection functionœÜis to convert Œ∏œÅ(Œπ)to a ""strategy"", which is an abstract domain for œÄŒ±and a hyperplane for œÄI. Since the strategies for these two functions are quite different, we use two different selection functions, denoted œÜŒ±,œÜIfor the domain and partition policies respectively. The selection function œÜŒ±is quite simple and maps Œ∏œÅ(Œπ) to a tuple(d,k)where ddenotes the base abstract domain (either intervals Ior zonotopes Zin our implementation) and kdenotes the number of disjuncts. Thus, (Z,2)denotes the powerset of zonotopes abstract domain, where the maximumOptimization and Abstraction: A Synergistic Approach. . . PLDI ‚Äô19, June 22‚Äì26, 2019, Phoenix, AZ, USA number of disjuncts is restricted to 2, and(I,1)corresponds to the standard interval domain. In the case of the partition policy œÄI, the selection function œÜIis also a tuple(d,c)where dis the dimension along which we split the input region and cis the point at which to split. In other words, if œÜI(Œ∏œÅ(Œπ))=(d,c), this means that we split the input region Iusing the hyperplane xd=c. Our selection functionœÜIdoes not consider arbitrary hyperplanes of the form c1x1+. . .cnxn=cbecause splitting the input region along an arbitrary hyperplane may result in subregions that are not expressible in the chosen abstract domain. In particular, this is true for both the interval and zonotope domains used in our implementation. 4.2 Learning using Bayesian Optimization As made evident by Eq. 3, the parameter matrix Œ∏has a huge impact on the choices made by our verification algorithm. However, manually coming up with these parameters is very difficult because the right choice of coefficients depends on both the property, the network, and the underlying abstract interpretation engine. In this work, we take a datadriven ap proach to solve this problem and use Bayesian optimization to learn a parameter matrix Œ∏that leads to optimal performance by the verifier on a set of training problems. Background on Bayesian optimization. Given a function F:Rn‚ÜíR, the goal of Bayesian optimization is to find a vector x‚àó‚ààRnthat maximizes F. Importantly, Bayesian optimization does not assume that Fis differentiable; also, in practice, it can achieve reasonable performance without having to evaluate Fvery many times. In our setting, the function Frepresents the performance of a verification policy. This function is not necessarily differentiable in the param eters of the verification policy, as a small perturbation to the policy parameters can lead to the choice of a different domain. Also, evaluating the function requires an expensive round of abstract interpretation. For these reasons, Bayesian optimization is a good fit to our learning problem. At a high level, Bayesian optimization repeatedly samples inputs until a time limit is reached and returns the best in put found so far. However, rather than sampling inputs at random, the key part of Bayesian optimization is to predict what input is useful to sample next. Towards this goal, the algorithm uses (1) a surrogate modelMthat expresses our current belief about F, and (b) an acquisition function Athat employsMto decide the most promising input to sample in the next iteration. The surrogate model Mis initialized to capture prior beliefs about Fand is updated based on obser vations on the sampled points. The acquisition function Ais chosen to trade off exploration and exploitation where ""explo ration"" involves sampling points with high uncertainty, and ""exploitation"" involves sampling points where Mpredicts a high value of F. Given modelMand functionA, Bayesian optimization samples the most promising input xaccordingtoA, evaluates Fatx, and updates the statistical model M based on the observation F(x). This process is repeated until a time limit is reached, and the best input sampled so far is returned as the optimum. We refer the reader to [ 37] for a more detailed overview of Bayesian optimization. Using Bayesian optimization. In order to apply Bayesian optimization to our setting, we first need to define what func tion we want to optimize. Intuitively, our objective function should estimate the quality of the analysis results based on decisions made by verification policy œÄŒ∏. Towards this goal, we fix a set Sof representative training problems that can be used to estimate the quality of œÄŒ∏. Then, given a parameters matrixŒ∏, our objective function Fcalculates a score based on (a) how many benchmarks in Scan be successfully solved within a given time limit, and (b) how long it takes to solve the benchmarks in S. More specifically, our objective func tion Fis parameterized by a time limit t‚ààRand penalty p‚ààRand calculates the score for a matrix Œ∏as follows: F(Œ∏)=‚àí√ï s‚ààScost Œ∏(s) where: cost Œ∏(s)=Time(VerifyŒ∏(s))ifssolved within t p¬∑t otherwise Intuitively, pcontrols how much we want to penalize failed verification attempts ‚Äì i.e., the higher the value of p, the more biased the learning algorithm is towards more precise (but potentially slow) strategies. On the other hand, small values of pbias learning towards strategies that yield fast results on the solved benchmarks, even if some of the benchmarks cannot be solved within the given time limit.4 In order to apply Bayesian optimization to our problem, we also need to choose a suitable acquisition function and surrogate mode. Following standard practice, we adopt a Gaussian process [44] as our surrogate model and use expected improvement [6] for the acquisition function. 5 Termination and Delta Completeness In this section, we discuss some theoretical properties of our verification algorithm, including soundness, termina tion, and completeness. To start with, it is easy to see that Algorithm 1 is sound, as it only returns ""Verified"" once it establishes that every point in the input space is classified asK. This is the case because every time we split the input region Iinto two subregions I1,I2, we ensure that I=I1‚à™I2, and the underlying abstract interpreter is assumed to be sound. However, it is less clear whether Algorithm 1 always terminates or whether it has any completeness guarantees. Our first observation is that the Verify procedure, ex actly as presented in Algorithm 1, does not have termination guarantees under realistic assumptions about the optimiza tion procedure used for finding adversarial counterexamples. 4In our implementation, we choose p=2,t=700s.PLDI ‚Äô19, June 22‚Äì26, 2019, Phoenix, AZ, USA Greg Anderson, Shankara Pailoor, Isil Dillig, and Swarat Chaudhuri Specifically, if the procedure Minimize invoked at line 2 of Algorithm 1 returned a global minimum, then we could indeed guarantee termination.5However, since gradient based optimization procedures do not have this property, Algorithm 1 may not be able to find a true adversarial coun terexample even as we make the input region infinitesimally small. Fortunately, we can guarantee termination and a form of completeness (known as Œ¥completeness) by making a very small change to Algorithm 1. To guarantee termination of our verification algorithm, we will make the following slight change to line 3 of Algorithm 1: Rather than checking F(x‚àó)‚â§0(forFas defined in Eq. 2) we will instead check: F(x‚àó)‚â§Œ¥ (4) While this modification can cause our verification algorithm to produce false positives under certain pathological condi tions, the analysis can be made as precise as necessary by picking a value of Œ¥that is arbitrarily close to 0. Furthermore, under this change, we can now prove termination under some mild and realistic assumptions. In order to formally state these assumptions, we first introduce the following notion of the diameter of a region: Definition 5.1. For any set X‚äÜRn, itsdiameter D(X)is defined as sup{‚à•x1‚àíx2‚à•2|x1,x2‚ààX}if this value exists. Otherwise the set is said to have infinite diameter. We now use this notion of diameter to state two key as sumptions that are needed to prove termination: Assumption 1. There exists some Œª‚àà(0,1)such that for any networkN, input region I, and point x‚àó‚ààI, ifœÄI(N,I,x‚àó)= (I1,I2), then D(I1)<ŒªD(I)andD(I2)<ŒªD(I). Intuitively, this assumption states that the two resulting subregions after splitting are smaller than the original region by some factor Œª. It is easy to enforce this condition on any partition policy by choosing a hyperplane xd=cwhere c is not at the boundary of the input region. Our second assumption concerns the abstract domain: Assumption 2. LetN#be the abstract transformer represent ing a networkN. For a given input region I, we assume there exists some KN‚ààRsuch that D(Œ≥(N#(Œ±(I))))<KND(I). This assumption asserts that the Lipschitz continuity of the network extends to its abstract behavior. Note that this assumption holds in several numerical domains including intervals, zonotopes, and powersets thereof. Theorem 5.2. Consider the variant of Algorithm 1 where the predicate at line 3 is replaced with Eq. 4. Then, if the input region has finite diameter, the verification algorithm always terminates under Assumptions 1 and 2.6 5However, if we make this assumption, the optimization procedure itself would be a sound and complete decision procedure for verifying robustness! 6Proofs for all theorems can be found in the appendix.In addition to termination, our small modification to Algo rithm 1 also ensures a property called Œ¥completeness [ 12]. In the context of satisfiability over real numbers, Œ¥completeness means that, when the algorithm returns a satisfying as signmentœÉ, the formula is either indeed satisfiable or a Œ¥perturbation on its numeric terms would make it satis fiable. To adapt this notion of Œ¥completeness to our context, we introduce the folowing concept Œ¥counterexamples: Definition 5.3. For a given network N, input region I, target class K, andŒ¥>0, aŒ¥counterexample is a point x‚ààIsuch that for some jwith 1‚â§j‚â§mandj,K, N(x)K‚àíN( x)j‚â§Œ¥. Intuitively, a Œ¥counterexample is a point in the input space for which the output almost violates the given specifi cation. We can view Œ¥as a parameter which controls how close to violating the specification a point must be to be considered ‚Äúalmost‚Äù a counterexample. Theorem 5.4. Consider the variant of Algorithm 1 where the predicate at line 3 is replaced with Eq. 4. Then, the verification algorithm is Œ¥complete ‚Äî i.e., if the property is not verified, it returns aŒ¥counterexample. 6 Implementation We have implemented the ideas proposed in this paper in a tool called Charon , written in C++. Internally, Charon uses the ELINA abstract interpretation library [ 1] to implement theAnalyze procedure from Algorithm 1, and it uses the BayesOpt library [35] to perform Bayesian optimization. Parallelization. Our proposed verification algorithm is eas ily parallelizable, as different calls to the abstract interpreter can be run on different threads. Our implementation takes advantage of this observation and utilizes as many threads as the host machine can provide by running different calls to ELINA in parallel. Training. We trained our verification policy on 12 different robustness properties of a neural network used in the ACAS Xu collision avoidance system [ 24]. However, since even verifying even a single benchmark can take a very long time, our implementation uses two tactics to reduce training time. First, we parallelize the training phase of the algorithm using the MPI framework [ 11] and solve each benchmark at the same time. Second, we set a time limit of 700 seconds (perprocess cputime) per benchmark. Contrary to what we may expect from machine learning systems, a small set of benchmarks is sufficient to learn a good strategy for our setting. We conjecture that this is because the relatively small number of features allowed by Bayesian optimization helps to regularize the learned policy. Featurization. Recall that our verification policy uses a fea turization function to convert its input to a feature vector. As mentioned in Section 4.1, this featurization function shouldOptimization and Abstraction: A Synergistic Approach. . . PLDI ‚Äô19, June 22‚Äì26, 2019, Phoenix, AZ, USA select a compact set of features so that our training is efficient and avoids overfitting our policy to the training set. These features should also capture revalant information about the network and the property so that our learned policy can generalize across networks. With this in mind, we used the following features in our implementation: ‚Ä¢the distance between the center of the input region Iand the solution x‚àóto the optimization problem ‚Ä¢the value of the objective function F(Eq. 2) at x‚àó ‚Ä¢the magnitude of the gradient of the network at x‚àó ‚Ä¢average length of the input space along each dimension Selection. Recall from Section 4 that our verification pol icyœÄuses two different selection functions œÜŒ±andœÜIfor choosing an abstract domain and splitting plane respectively. The selection function œÜItakes a vector of three inputs. The first two are realvalued numbers that decide which dimension to split on. Rather than considering all possible dimensions, our implementation chooses between two di mensions to make training more manageable. The first one is the longest dimension (i.e., input dimension with the largest length), and the second one is the dimension that has the largest influence [54] onN(x)K. The last input to the selec tion function is the offset at which to split the region. This value is clipped to[0,1]and then interpreted as a ratio of the distance from the center of the input region Ito the solution x‚àóof Eq. 1. For example, if the value is 0, the region will be bisected, and if the value is 1, then the splitting plane will in tersect x‚àó. Finally, if the splitting plane is at the boundary of I, it is offset slightly so that the strategy satisfies Assumption 1. The selection function œÜŒ±for choosing an abstract do main takes a vector of two inputs. The first controls the base abstract domain (intervals or zonotopes) and the second con trols the number of disjuncts to use. In both cases, the output is extracted by first clipping the input to a fixed range and then discretizing the resulting value. 7 Evaluation To evaluate the ideas proposed in this paper, we conduct an experimental evaluation that is designed to answer the following three research questions: (RQ1) How does Charon compare against stateoftheart tools for proving neural network robustness? (RQ2) How does counterexample search impact the perfor mance of Charon ? (RQ3) What is the impact of learning a verification policy on the performance of Charon ? Benchmarks. To answer these research questions, we col lected a benchmark suite of 602 verification problems across 7 deep neural networks, including one convolutional network and several fully connected networks. The fully connected networks have sizes 3 √ó100, 6√ó100, 9√ó100, and 9√ó200, where N√óMmeans there are Nfully connected layers and eachinterior layer has size M. The convolutional network has a LeNet architecture [ 30] consisting of two convolutional layers, followed by a max pooling layer, two more convolu tional layers, another max pooling layer, and finally three fully connected layers. All of these networks were trained on the MNIST [30] and CIFAR [27] datasets. 7.1 Comparison with AI2(RQ1) For each network, we attempt to verify around 100 robust ness properties. Following prior work [ 14], the evaluated robustness properties are socalled brightening attacks [41]. For an input point xand a threshold œÑ, a brightening attack consists of the input region I= x‚Ä≤‚ààRn|‚àÄi.(xi‚â•œÑ‚àßxi‚â§x‚Ä≤ i‚â§1)‚à®x‚Ä≤ i=xi	 . That is, for each pixel in the input image, if the value of that pixel is greater than œÑ, then the corresponding pixel in the perturbed image may be anywhere between the initial value and one, and all other pixels remain unchanged. Setup. All experiments described in this section were per formed on the Google Compute Engine (GCE) [ 2] using an 8 vcpu instance with 10.5 GB of memory. All time measure ments report the total CPU time (rather than wall clock time) in order to avoid biasing the results because of Charon ‚Äôs parallel nature. For the purposes of this experiment, we set a time limit of 1000 seconds per benchmark. In this section we compare Charon with AI27, a state oftheart tool for verifying network robustness [ 14]. As discussed in Section 2, AI2is incomplete and requires the user to specify which abstract domain to use. Following their evaluation strategy from the IEEE S&P paper [ 14], we in stantiate AI2with two different domains, namely zonotopes and bounded powersets of zonotopes of size 64. We refer to these two variants as AI2Zonotope and AI2Bounded64. The results of this comparison are summarized in Fig ure 6. This graph shows the percentage of benchmarks each tool was able to verify or falsify, as well as the percentage of benchmarks where the tool timed out and the percent age where the tool was unable to conclude either true or false. Note that, because Charon isŒ¥complete, there are no ‚Äúunknown‚Äù results for it, and because AI2cannot find counterexamples, AI2has no ‚Äúfalsified‚Äù results. The details for each network are shown in Figures 7  13. Each chart shows the cumulative time taken on the yaxis and the number of benchmarks solved on the xaxis (so lower is better). The results for each tool include only those benchmarks that the tool could solve correctly within the time limit of 1000 seconds. Thus, a line extending further to the right indicates that the tool could solve more benchmarks. 7Because we did not have access to the original AI2, we reimplemented it. However, to allow for a fair comparison, we use the same underlying abstract interpretation library, and we implement the transformers exactly as described in [14].PLDI ‚Äô19, June 22‚Äì26, 2019, Phoenix, AZ, USA Greg Anderson, Shankara Pailoor, Isil Dillig, and Swarat Chaudhuri Figure 6. Summary of results for AI2andCharon . Figure 7. Comparison on a 3x100 MNIST network. Figure 8. Comparison on a 6x100 MNIST network. Figure 9. Comparison on a 9x200 MNIST network. Since AI2Bounded64 times out on every benchmark for the convolutional network, it does not appear in Figure 13. Figure 10. Comparison on a 3x100 CIFAR network. Figure 11. Comparison on a 6x100 CIFAR network. Figure 12. Comparison on a 9x100 CIFAR network. The key takeaway lesson from this experiment is that Charon is able to both solve more benchmarks compared toAI2Bounded64 on most networks, and it is able to solveOptimization and Abstraction: A Synergistic Approach. . . PLDI ‚Äô19, June 22‚Äì26, 2019, Phoenix, AZ, USA Figure 13. Comparison on a convolutional network. Figure 14. Comparison with ReluVal . them much faster. In particular, Charon solves 59.7%(resp. 84.7%) more benchmarks compared to AI2Bounded64 (resp. AI2Zonotope). Furthermore, among the benchmarks that can be solved by both tools, Charon is 6.15√ó(resp. 1.12√ó ) faster compared to AI2Bounded64 (resp. AI2Zonotope). Thus, we believe these results demonstrate the advantages of our approach compared to AI2. 7.2 Comparison with Complete Tools (RQ1) In this section we compare Charon with other complete tools for robustness analysis, namely ReluVal [54] and Re luplex [25]. Among these tools, Reluplex implements a variant of Simplex with builtin support for the ReLU activa tion function [ 25], and ReluVal is an abstraction refinement approach without learning or counterexample search. To perform this experiment, we evaluate all three tools on the same benchmarks from Section 7.1. However, since ReluVal andReluplex do not support convolutional layers, we exclude the convolutional net from this evaluation. The results of this comparison are summarized in Fig ure 14. Across all benchmarks, Charon is able to solve 2.6√ó (resp. 16.6√ó) more problems compared to ReluVal (resp. Reluplex ). Furthermore, it is worth noting that the set of benchmarks that can be solved by Charon is a strict superset of the benchmarks solved by ReluVal . Figure 15. Comparison with ReluVal on verified bench marks. 7.3 Impact of Counterexample Search (RQ2) To understand the benefit of using optimization to search for counterexamples, we now compare the number of prop erties that can be falsified using Charon vs.Reluplex and ReluVal . (Recall that AI2is incomplete and cannot be used for falsification.) Among the 585 benchmarks used in the evaluation from Section 7.2, Charon can falsify robustness of 123 benchmarks. In contrast, Reluplex can only falsify ro bustness of one benchmark, and ReluVal cannot falsify any of them. Thus, we believe these results demonstrate the use fulness of incorporating optimizationbased counterexample search into the decision procedure. 7.4 Impact of Learning a Verification Policy (RQ3) Recall that a key feature of our algorithm is the use of a machinelearnt verification policy œÄto choose a refinement strategy. To explore the impact of this design choice, we compare our technique against ReluVal on the subset of the 585 benchmarks for which the robustness property holds. In particular, as mentioned earlier, ReluVal is also based on a form of abstraction refinement but uses a static, hand crafted strategy rather than one that is learned from data. Thus, comparing against ReluVal on the verifiablyrobust benchmarks allows us to evaluate the benefits of learning a verification policy from data.8 The results of this comparison are shown in Figure 15. As we can see from this figure, ReluVal is still only able to solve between 3570% of the benchmarks that can be successfully solved by Charon . Thus, these results demonstrate that our datadriven approach to learning verification policies is useful for verifying network robustness. 8We compare with ReluVal directly rather than reimplementing the Re luVal strategy inside Charon because our abstract interpretation engine does not support the domain used by ReluVal . Given this, we believe the comparison to ReluVal is the most fair available option.PLDI ‚Äô19, June 22‚Äì26, 2019, Phoenix, AZ, USA Greg Anderson, Shankara Pailoor, Isil Dillig, and Swarat Chaudhuri 8 Related Work "
308,SimNet: Learning Reactive Self-driving Simulations from Real-world Observations.txt,"In this work, we present a simple end-to-end trainable machine learning
system capable of realistically simulating driving experiences. This can be
used for the verification of self-driving system performance without relying on
expensive and time-consuming road testing. In particular, we frame the
simulation problem as a Markov Process, leveraging deep neural networks to
model both state distribution and transition function. These are trainable
directly from the existing raw observations without the need for any
handcrafting in the form of plant or kinematic models. All that is needed is a
dataset of historical traffic episodes. Our formulation allows the system to
construct never seen scenes that unfold realistically reacting to the
self-driving car's behaviour. We train our system directly from 1,000 hours of
driving logs and measure both realism, reactivity of the simulation as the two
key properties of the simulation. At the same time, we apply the method to
evaluate the performance of a recently proposed state-of-the-art ML planning
system trained from human driving logs. We discover this planning system is
prone to previously unreported causal confusion issues that are difficult to
test by non-reactive simulation. To the best of our knowledge, this is the
first work that directly merges highly realistic data-driven simulations with a
closed-loop evaluation for self-driving vehicles. We make the data, code, and
pre-trained models publicly available to further stimulate simulation
development.","SelfDriving Vehicles (SDVs) have the potential to rad ically transform society in the form of safe and efÔ¨Åcient transportation. Modern machine learning methods have en abled much of the recent advances in selfdriving perception [2], [3], [4], [5], [6], prediction [7], [8], [9], [10] and planning [1], [11]. The availability of large datasets unlocked signiÔ¨Åcantly higher performance compared to older, hand engineered systems. However, the problem of validating SDV performance remains still largely unsolved. Most industry players validate empirically by deploying their self driving systems to a Ô¨Çeet of vehicles accompanied by safety drivers. In the case of unusual or failure behaviours, the safety driver takes over. Observed issues serve as feedback to improve the system. However, this process is both expensive and timeconsuming, requiring the collection of thousands or even millions of miles, depending on the system‚Äôs maturity. It is also hard to replicate or directly compare the performance of different system versions, as it is impossible to experience exactly the same driving situation twice. Equal contribution. +Authors are with Lyft Level 5 selfdriving division. Contact: pon druska@lyft.com. Data, code and videos are available at simulation.l5kit.org SimNet OÔ¨Ñine dataset of driving scenes Selfdriving system Reactive simulationFig. 1. The proposed trainable simulation system. We frame the simulation problem as reactive episode synthesis that can be used to validate the performance of a selfdriving driving system. A common approach to mitigate some of these issues is log replay , where the movement of other trafÔ¨Åc participants is replayed around the SDV in simulation as it happened when the log was collected. However, if the SDV‚Äôs new actions differ from those when the log was collected, the trafÔ¨Åc participants don‚Äôt react to it, and thus the simulation becomes unrealistic and ineffective for validation. For example, even a slight braking during the log replay can result in an unrealistic collision with the trailing car due to nonreactivity. These unrealistic outcomes are a result of what is called simulation drift . One way to implement simulation reactivity is by scripting trafÔ¨Åc participant behaviour to follow certain rules. However, this is time consuming and still lacks the realism and Ô¨Ådelity of road testing, thus undermining the validation effort. In this paper, we aim to create realistic simulated driving experiences just like those that an SDV would encounter in the real world. For example, when the SDV decides to slow down, the simulated vehicle behind it should react by either slowing or overtaking, just as it would in a road test. Additionally, agent behaviour should capture the stochastic multimodality that we observe on the road. To achieve this, we frame simulation as an ML problem, in which we generate driving episodes that need to be both realistic andreactive to SDV behaviour. We then present aarXiv:2105.12332v1  [cs.RO]  26 May 2021Published at 2021 International Conference on Robotics and Automation (ICRA2021) system leveraging highcapacity ML models trained on large amounts of historical driving data, Figure 1. We show the system‚Äôs performance dramatically improves as the amount of data grows signiÔ¨Åcantly narrowing the gap between road testing and ofÔ¨Çine simulation. At the same time, we show that it can help to identify issues in stateoftheart planning systems. To the best of our knowledge, this is the Ô¨Årst work that connects simulation and planning with largescale datasets in a realistic selfdriving setting. Our contributions are fourfold: 1) The formulation of the selfdriving simulation problem as an ML problem which seeks to generate driving episodes that are both realistic and reactive to SDV behaviour; 2) A simple machinelearned simulation system that can sample these episodes based on historical driving data trainable directly from trafÔ¨Åc observations; 3) Qualitative and quantitative evaluation of the proposed method as a function of training data size, as well as, its usefulness in evaluating and discovering issues in a stateoftheart ML planning systems. 4) The code and the pretrained models of the experiments to further stimulate development in the community. II. RELATED WORKS "
260,Graph Neural Networks and Reinforcement Learning for Behavior Generation in Semantic Environments.txt,"Most reinforcement learning approaches used in behavior generation utilize
vectorial information as input. However, this requires the network to have a
pre-defined input-size -- in semantic environments this means assuming the
maximum number of vehicles. Additionally, this vectorial representation is not
invariant to the order and number of vehicles. To mitigate the above-stated
disadvantages, we propose combining graph neural networks with actor-critic
reinforcement learning. As graph neural networks apply the same network to
every vehicle and aggregate incoming edge information, they are invariant to
the number and order of vehicles. This makes them ideal candidates to be used
as networks in semantic environments -- environments consisting of objects
lists. Graph neural networks exhibit some other advantages that make them
favorable to be used in semantic environments. The relational information is
explicitly given and does not have to be inferred. Moreover, graph neural
networks propagate information through the network and can gather higher-degree
information. We demonstrate our approach using a highway lane-change scenario
and compare the performance of graph neural networks to conventional ones. We
show that graph neural networks are capable of handling scenarios with a
varying number and order of vehicles during training and application.","Many reinforcement learning approaches in decision making for autonomous driving use vectorial representations as inputs ‚Äì e.g. a list of semantic objects or images. However, this requires a predeÔ¨Åned inputsize and order when using conventional deep neural networks. As a consequence ‚Äì in semantic simulations ‚Äì the maximum number and order of the vehicles have to be deÔ¨Åned. The number and order of vehicles in realworld trafÔ¨Åc sit uations can change rapidly ‚Äì as vehicles come into and leave the Ô¨Åeld of view or vehicles overtake each other. Thus, each situation requires an assumption of the maximum number of vehicles and also in which order they should be sensed by the vehicle. Of course, an arbitrary order of the vehicles could be passed to conventional neural networks during training. However, this would require the conventional neural network to see all possible combinations during training in order to handle this arbitrary order. On the contrary, graph neural networks (GNNs) are invariant to the number and order of vehicles as they directly operate on graphs. This makes them ideal candidates to be used as a decisionmaking entity in autonomous driving. 1Patrick Hart is with the fortiss GmbH, AnInstitut Technische Universit ¬®at M¬®unchen, Munich, Germany. Email: patrick.hart@tum.de 2Alois Knoll is with the Chair of Robotics, ArtiÔ¨Åcial Intelligence and Realtime Systems, Technische Universit ¬®at M ¬®unchen, Munich, Germany Fig. 1: Semantic environment in which the vehicles are represented in a graph. The vehicles are nodes and are connected to each other with edges. Graph neural networks take graphs directly as input. In this work, we combine continuous actorcritic (AC) reinforcement learning methods with GNNs to enable a number and order invariant decisionmaking for autonomous vehicles. AC reinforcement learning methods exhibit state oftheart performance in various continuous control prob lems [1, 2]. Additionally to the beforestated advantages, GNNs also introduce a relational bias to the learning problem ‚Äì due to the connections between vehicles in the graph. Thus, relational information is provided explicitly and does not have to be inferred by using collected experiences. Moreover, GNNs propagate information through the graph due to their convolutional characteristics. In this work, we use a ‚ÄòGraphObserver‚Äô that generates a graph connecting the nnearest vehicles with each other and an ‚ÄòEvaluator‚Äô that outputs a reward signal and that determines if an episode is terminal. Using the ‚ÄòGraphObserver‚Äô, the ‚ÄòEvaluator‚Äô and the AC algorithm, the ego vehicle‚Äôs policy can now be iteratively evaluated and improved. The main contributions of this work are: Using GNNs as networks in AC methods for decision making in semantic environments, comparing the performance of conventional deep neural networks to using GNNs and, performing ablation studies on the invariance towards the number and order of vehicles for both network types. A. Graph Neural Networks Graph neural networks (GNNs) are a class of neural networks that operate directly on graphstructured data [3]. AarXiv:2006.12576v1  [cs.LG]  22 Jun 2020wide variety of graph neural network architectures have been proposed [4, 5, 6, 7]. These range from simple graphs [4], to directed graphs [5], to graphs that contain edge information [6], up to convolutional graphs [7]. In this work, we use the approach introduced by Battaglia et al. [8] that uses a directed graph with edge information. The graphG= (N;E )is deÔ¨Åned having nodes ni2N and directed edges eij2Efrom nodenitonj. Both ‚Äì the nodes and edges ‚Äì contain additional information. The node value is denoted as hifor theith node and the edge value as eijconnecting the ith with the jth node. The node value hicontains e.g. the vehicle‚Äôs state and the edge value eij relational information between two nodes. In each layer kof the GNN, a dense node neural network layer is applied per node and a dense edge neural network layer per edge. Each GNN layer has three computation steps: First, the next edge values ek+1 ijare computed using the current edge valuesek ij, the fromnode values hk iand the tonode values hk j. These values are concatenated and passed into a (dense) neural network layer fk ()that is parameterized by . This can be expressed as ek+1 ij=fk ([hk i;ek ij;hk j]): (1) Next, all incoming edge values ek+1 ij to the node njare aggregated. In this work, we use a sum as the aggregation function. Thus, the nodewise aggregation of the edge values can be written as ek+1 agg;j =MX i=0ek+1 ij (2) withMbeing the number of incoming edges to node nj. Finally, the next node values hk+1 iare computed using a (dense) neural network layer fk  (). This can be formulated as hk+1 j=fk  ([ek+1 agg;j;hk j]) (3) for thejth node. These three steps are performed in every layer with each layer having (dense) network layers fl  () andfl (). In this work, we do not use a global update as proposed in [8]. B. Reinforcement Learning Reinforcement learning (RL) is a solution class for Markov decision processes (MDPs). Contrary to dynamic programming or MonteCarlo methods, RL does not require knowledge of the environment‚Äôs dynamics but only learns from experiences. RL solution methods can be divided into valuebased, policybased, and actorcritic (AC) approaches. AC methods have an actor that learns a policy (s)and a critic that learns a statevalue function V(s)withsbeing the state. Most AC methods use a stochastic policy (s)that has a distributional outputlayer. In this work, we use an actor network that outputs a normal distribution N(;)with being the mean and the standard deviation. The statevalue function can either be learned using temporal differences (TD) learning or MonteCarlo methods [9]. We utilize TD learning to learn the statevalue function V(s). The policy(ajs)and the statevalue function V(s)are approximated using deep neural networks and, therefore, are parameterized by the network weights and. The policy update for the actor using TD learning is deÔ¨Åned as rJ= (rt+ V(st+1)"
383,Embedding Aggregation for Forensic Facial Comparison.txt,"In forensic facial comparison, questioned-source images are usually captured
in uncontrolled environments, with non-uniform lighting, and from
non-cooperative subjects. The poor quality of such material usually compromises
their value as evidence in legal matters. On the other hand, in forensic
casework, multiple images of the person of interest are usually available. In
this paper, we propose to aggregate deep neural network embeddings from various
images of the same person to improve performance in facial verification. We
observe significant performance improvements, especially for very low-quality
images. Further improvements are obtained by aggregating embeddings of more
images and by applying quality-weighted aggregation. We demonstrate the
benefits of this approach in forensic evaluation settings with the development
and validation of score-based likelihood ratio systems and report improvements
in Cllr of up to 95% (from 0.249 to 0.012) for CCTV images and of up to 96%
(from 0.083 to 0.003) for social media images.","The increasing number of indoor and outdoor surveil lance cameras and the widespread availability of smart phones has raised the number of crimes in which the perpetrator‚Äôs facial image is recorded. This fact has fostered the interest in using these data to uncover the perpetrator‚Äôs identity [1]. When a suspect is presented, the analysis of morphological facial features is currently recommended as the standard approach for the foren sic comparison of faces [2]. This process is usually ex ecuted manually by comparing a set of deÔ¨Åned facial morphological features in the questionedsource image with those in the suspects‚Äô images (knownsource im ages) [3]. The evaluation of the Ô¨Åndings from the mor phological analysis is often summarized in a qualitative scale of posterior probability (e.g., ‚Äúit is highly likely that the two images belong to the same identity‚Äù) or using qualitative scales based on the Likelihood Ratio (LR) (e.g., ‚Äúthe similarities and di erences observed are more likely when considering the images as belonging Corresponding author Email address: rafael.ror@pf.gov.br (Rafael Oliveira Ribeiro)to the same identity rather than when considering they belong to distinct identities‚Äù) [4, 5]. Traditional Forensic Facial Analysis SystemsScore to LR conversion Face Recognition ModelLR S LR Score to LR conversion SEmbedding Aggregation Module Face Recognition Model Reference Image Trace images Reference Image Trace imagesProposed Method Figure 1: Comparison of the proposed framework with traditional forensic facial analysis systems. Although forensic practitioners using the current ap Preprint submitted to Elsevier April 12, 2023arXiv:2305.00352v1  [cs.CV]  29 Apr 2023proach have demonstrated superior performance for fa cial comparisons relative to control groups [6, 7], there has been a longstanding call for adopting more ob jective and quantitative methods in forensic science [8, 9, 10, 11]. In various Ô¨Åelds related to biometric com parisons, the research community has responded to this call by investigating the possibility of using automated systems to quantify the evidence obtained from the data by computing an LR [12, 13, 14, 15, 16, 17, 18, 19, 20]. Based on the evaluation of comparison scores obtained from biometric samples, this new approach is especially appealing for the face modality for two reasons. Firstly, automatic facial recognition systems have experienced an enormous improvement in performance over the last few years [21, 22]. Secondly, the combined perfor mance of human experts and facial recognition algo rithms have been demonstrated to be superior to either the human experts or the algorithms alone [23, 6]. Combining facial recognition systems‚Äô outputs with human forensic examiners requires that both analyses are performed under the same evaluation paradigm. Currently, the LR paradigm is the recommended ap proach for evaluative reporting of source problems in forensic science [5, 24]. Under this paradigm, foren sic practitioners should express their evaluation using a likelihood ratio. The LR represents the degree of sup port of the evidence for one hypothesis relative to an other mutually exclusive hypothesis. In this work, we consider commonsource hypotheses, which, in the case of forensic facial comparison, are deÔ¨Åned as: ¬àHp(samesource hypothesis): Both the questioned source and the knownsource images depict the face of the same person; and; ¬àHd(dierentsource hypothesis): The questioned source and the knownsource image depict the faces of two di erent people from the same population1. The LR is computed according to LR=Pr(EjHp;I) Pr(EjHd;I); (1) i.e., it is the ratio of the probabilities ( Pr) of obtaining the evidence ( E) given each hypotheses and the contex tual information ( I) relevant to the case. From now on, we will omit Iin the equations, but the reader should remember that all probabilities related to the case are conditioned on I. 1Often referred to as reference population in the forensic literature, it is the population from which an alternative suspect may have came from (e.g., young adult males from a speciÔ¨Åc region).Several works have proposed methods to obtain LRs by converting the scores of face recognition systems through the estimation of withinsource and between source distributions [18, 19, 20]. However, the exist ing strategies focus only on a single questionedsource image, disregarding the possibility of aggregating infor mation from multiple images (e.g., consecutive frames from CCTV footage) to compute a single LR. To ad dress this limitation, as depicted in Figure 1, we intro duce a novel strategy for LR calculation in forensic fa cial comparison when multiple questionedsource im ages are available. The proposed method combines the facial descriptors2of each sample to build into a single facial comparison score, which is subsequently mapped to an LR. The experiments performed in facial datasets rep resentative of common forensic scenarios show that the proposed strategy decreases the loglikelihood ra tio cost ( Cllr) compared to stateoftheart face analysis approaches. Additionally, the proposed method is ap plicable even when the samples are obtained from non consecutive moments in time, with varying illumination and pose. The paper is organized as follows: in Section 2, we review works on using biometric systems to evaluate faces as forensic evidence. In Section 3, the proposed method is described, and in Section 4, we detail the data used in this work. Section 5 describes the experiments performed, and Section 6 presents the results and dis cussion. We conclude in Section 7, presenting the lim itations of this work and planned investigations on the same topic. 2. Related Work "
222,QVIP: An ILP-based Formal Verification Approach for Quantized Neural Networks.txt,"Deep learning has become a promising programming paradigm in software
development, owing to its surprising performance in solving many challenging
tasks. Deep neural networks (DNNs) are increasingly being deployed in practice,
but are limited on resource-constrained devices owing to their demand for
computational power. Quantization has emerged as a promising technique to
reduce the size of DNNs with comparable accuracy as their floating-point
numbered counterparts. The resulting quantized neural networks (QNNs) can be
implemented energy-efficiently. Similar to their floating-point numbered
counterparts, quality assurance techniques for QNNs, such as testing and formal
verification, are essential but are currently less explored. In this work, we
propose a novel and efficient formal verification approach for QNNs. In
particular, we are the first to propose an encoding that reduces the
verification problem of QNNs into the solving of integer linear constraints,
which can be solved using off-the-shelf solvers. Our encoding is both sound and
complete. We demonstrate the application of our approach on local robustness
verification and maximum robustness radius computation. We implement our
approach in a prototype tool QVIP and conduct a thorough evaluation.
Experimental results on QNNs with different quantization bits confirm the
effectiveness and efficiency of our approach, e.g., two orders of magnitude
faster and able to solve more verification tasks in the same time limit than
the state-of-the-art methods.","Deep neural networks (DNNs) have gained widespread attention as a promising programming paradigm thanks to their surprising performance in solving various complicated tasks [ 33,37,62]. DNNs are increasingly being deployed in software applications such as autonomous driving [ 5] and medical diagnostics [ 18], and have become a subject of intensive software engineering research. Modern DNNs usually contain a great number of parameters which are typically stored as 32/64bit floatingpoint numbers, and require a massive amount of floatingpoint operations to compute the outputs at running time [ 73]. Hence, modern DNNs are both memory intensive and computationally intensive, making them difficult to deploy on energy and computationconstrained de vices [ 31]. To address this issue, compression techniques have been proposed to ‚Äòdeflate‚Äô DNNs by removing redundant connections and quantizing parameters from 32/64bit floatingpoints to lower bitwidth fixedpoints (e.g., 8bits) [ 31,35], which can vastly reduce the memory requirement and computational cost based on bitwise and/or integeronly arithmetic computations. For instance, Tesla‚Äôs Full SelfDriving Chip (previously Autopilot Hardware 3.0) is de signed for primarily running 8bit quantized DNNs [ 32,80]. Quanti zation is also made available to ordinary programmers through pop ular deep learning frameworks. For instance, TensorFlow Lite [ 2] supports, among others, 8bit quantization on parameters. Despite their great success, DNNs are known to be vulnera ble to input perturbations due to the lack of robustness [ 10‚Äì15, 28,40,58,70,72]. This is concerning as such errors may lead to catastrophes when DNNs are deployed in safetycritical applica tions. For example, a selfdriving car may misclassify a stop signarXiv:2212.11138v1  [cs.CR]  10 Dec 2022ASE ‚Äô22, October 10‚Äì14, 2022, Rochester, MI, USA Zhang et al. as a speedlimit sign [ 23]. As a result, along with traditional ver ification and validation (V&V) research in software engineering, there is a large and growing body of work on developing V&V techniques for DNNs, which has become a focus of software en gineering researchers. For instance, testing techniques have been proposed to evaluate robustness of DNNs against input perturba tions, e.g., [ 11,48,49,56,61,71,74,82,83], cf. [ 85] for a survey. Such techniques are often effective in finding input samples to demon strate lack of robustness, but they cannot prove the absence of such inputs. Many efforts have also been made to formally verify the robustness of DNNs [ 22,25,29,34,38,46,47,63,69,77,78,84,89], to cite a few. In general, we advocate the research on quality as surance for DNNs, which are increasingly a component of modern software systems, to which our current work contributes to. Almost all the existing work is designated for real or floating point numbered DNNs only whereas verification of quantized DNNs (QNNs) has not been thoroughly investigated yet, although there is a gap of verification results between realnumbered DNNs and their quantized counterparts due to the fixedpoint semantics of QNNs [ 26]. Thus, there is a growing need for the research of quality assurance techniques for QNNs. One possible approach to verify QNNs is to adopt differential verification [ 41] which was initially proposed for verifying a new version of a program with respect to a previous version. One could first verify a real or floatingpoint numbered DNN by applying existing techniques and then verify its quantized counterpart by applying differential verification tech niques for DNNs [ 50,59,60]. However, it has two drawbacks. First, existing differential verification techniques for DNNs [ 50,59,60] are incomplete, and thus may produce false positives even if the original DNN is robust. Second, quantization introduces nonmonotonicity on the output of DNNs [ 26], consequently, a robust DNN may be come nonrobust after quantization while a nonrobust DNN may become a robust QNN. Therefore, dedicated techniques are required for directly and rigorously verifying QNNs. There do exist techniques for directly verifying QNNs which leverage Boolean Satisfiability (SAT) or Satisfiability Modulo The ory (SMT) solving or (reduced, ordered) binary decision diagrams (BDDs). For 1bit quantized DNNs, i.e., Binarized Neural Networks (BNNs), Narodytska et al. [ 54] proposed to translate the BNN verifi cation problem into the satisfiability problem of Boolean formulas where SAT solving is harnessed. Using a similar encoding, Baluta, et al. [ 8] proposed to quantitatively verify BNNs via approximate model counting. Following this direction, Shih et al. [ 64,65] pro posed a BDD learningbased approach to quantitatively analyze BNNs, and Zhang et al. [ 86] introduced an efficient BDD encoding method by exploiting the internal structure of BNNs. Recently, the SMTbased verification framework Marabou has also been extended to support BNNs [ 3]. For quantization with multiple bits (e.g., fixed point), methods also have been proposed [ 9,26,32], which reduce the verification problem of QNNs to SMT solving accounting for the fixedpoint semantics of QNNs. They are sound and complete, but have fairly limited scalability. In this work, we propose the first integer linear programming (ILP) based verification approach for QNNs. To this end, we present a novel and exact encoding which precisely reduces the verifica tion problem for QNNs to an integer linear programming program. More specifically, we propose to use piecewise constant functions toencode piecewise linear activation functions that are computations of neurons in QNNs. The piecewise constant functions are further encoded as integer linear constraints with the help of additional Boolean variables. We also propose encodings to express desired in put space and robustness properties using integer linear constraints. The number of integer linear constraints produced by our encoding method is linear (at most 4 times) in the number of neurons of QNNs. Based on our encoding, we develop a theoretically complete and practically efficient verification framework for QNNs. To further improve the scalability and efficiency, we leverage interval analysis to soundly approximate the neuron outputs, which can effectively reduce the size of integer linear constraints and number of Boolean variables, and consequently, reduce verification cost. We highlight two applications of our approach, i.e., robustness verification and computation of maximum robustness radii. We implement our approach as an endtoend tool, named QVIP , with Gurobi [ 30] as the underlying ILPsolver. We extensively eval uate QVIP on various QNNs with different quantization bits using two popular datasets MNIST [ 42] and FashionMNIST [ 81], where the number of neurons varies from 858 to 894, and the number of bits for quantizing parameters ranges from 4 to 10 bits with 8bit input quantization. For robustness verification, experimental re sults show that our approach is two orders of magnitude faster and is able to solve more verification tasks within the same time limit than the stateoftheart verifier for multiplebit QNNs [ 32]. To the best of our knowledge, QVIP is the first tool that can handle input spaces with an attack radius up to 30 for robust verification of QNNs. Interestingly, we found that, although the accuracy of the QNNs stays similar under different quantization bits, the robustness can be greatly improved with more quantization bits using quantization aware training [ 35]. We remark that Giacobbe et al. [ 26] showed that neither robustness nor nonrobustness is monotonic with the number of quantization bits using posttraining quantization [ 52]. This suggests that robustness should also be considered, in addi tion to accuracy, during quantizationaware training which is able to produce more accurate QNNs than posttraining quantization. Furthermore, we show the effectiveness of QVIP in computing max imum robustness radii based on binary search. Experimental results show that it can be utilized to compare the overall robustness of QNNs with different quantization bits. To summarize, our main contributions are as follows. ‚Ä¢We propose the first ILPbased verification approach for QNNs featuring both precision and efficiency. ‚Ä¢We implement our approach as an endtoend tool QVIP , us ing the ILPsolver Gurobi for QNN robustness verification and maximum robustness radius computation. ‚Ä¢We conduct an extensive evaluation of QVIP , demonstrating the efficiency and effectiveness of QVIP , e.g., significantly outper forming the stateoftheart methods. Outline. We define QNNs and problems in Section 2. In Section 3, we propose the ILPbased verification approach. In Section 4, we present an algorithm for computing maximum robustness radii. We report our experimental results in Section 5. Section 6 discusses related work. Finally, we conclude in Section 7. To foster further research, benchmarks and experimental data are released on our website [87].QVIP: A Formal Verification Approach for QNNs ASE ‚Äô22, October 10‚Äì14, 2022, Rochester, MI, USA x1x2y1y2z1z20.581.06‚àí0.750.44‚àí1.231.510.630.82y1=ReLU(0.58x1‚àí1.23x2)=0.21706y2=ReLU(1.51x1+1.06x2)=1.051z1=ReLU(‚àí0.75y1+0.63y2)=0.499335z2=ReLU(0.82y1+0.44y2)=0.64042920.6160.114inputinput (a) DNNNùëí. ÃÇx1ÃÇx2ÃÇy1ÃÇy2ÃÇz1ÃÇz2917‚àí127‚àí20241013ÃÇy1=clamp(‚åä(9ÃÇx1‚àí20ÃÇx2)√ó2‚àí4‚åâ,0,26‚àí1)=3ÃÇy2=clamp(‚åä(24ÃÇx1+17ÃÇx2)√ó2‚àí4‚åâ,0,26‚àí1)=17ÃÇz1=clamp(‚åä(‚àí12ÃÇy1+10ÃÇy2)√ó2‚àí4‚åâ,0,26‚àí1)=8ÃÇz2=clamp(‚åä(13ÃÇy1+7ÃÇy2)√ó2‚àí4‚åâ,0,26‚àí1)=10102inputinput (b) QNN bNùëí. Figure 1: A 3layer DNN Nùëíand its quantized version bNùëí. 2 PRELIMINARIES We denote by R,N,ZandBthe set of real numbers, natural numbers, integers and Boolean domain {0,1}respectively. Given a number ùëõ‚ààN, let[ùëõ]:={1,¬∑¬∑¬∑,ùëõ},RùëõandZùëõbe the sets of the ùëõtuples of real numbers and integers, respectively. We use W,W‚Ä≤,...to denote matrices, x,y,...to denote vectors, and ùë•,ùë¶,... to denote scalars. We denote by Wùëñ,:andW:,ùëótheùëñth row and ùëóth column of the matrix W. Similarly, we denote by xùëóandWùëñ,ùëótheùëóth entry ofxandWùëñ,:respectively. 2.1 Deep Neural Networks A deep neural network (DNN) Nis a graph structured in layers, where the first layer is the input layer , the last layer is the output layer , and the others are hidden layers . All the nodes in these layers are called neurons (in particular, neurons in hidden layers are called hidden neurons ). Each neuron in a noninput layer is associated with a biasand could be connected by other neurons via weighted, directed edges. A DNN is feedforward if all the neurons only point to neurons in the next layer. In this work, we focus on feedforward DNNs. Given an input, a DNN computes an output by propagating it through the network layer by layer, where the value of each neuron is computed by applying an activation function to the weighted sum of output values from the preceding layer or input. A DNNNwithùëëlayers is a functionN:X‚ÜíY, where X‚äÜRùëõ is the input domain and Y‚äÜRùëöis the output domain. For any input x‚ààX,N(x)=Wùëëyùëë‚àí1+bùëë, where yùëë‚àí1is obtained by the following recursive definition: y1=x, yùëñ=ùúé(Wùëñyùëñ‚àí1+bùëñ)forùëñ=2,...,ùëë‚àí1, where Wùëñandbùëñ(for2‚â§ùëñ‚â§ùëë) are the weight matrix and bias vector of the ùëñth layer respectively, and ùúéis an activation function (e.g., ReLU ,sigmoid ) applied to the vector entrywise. In this work, we focus on the most commonly used one ReLU(ùë•)=max(ùë•,0). For classification tasks, the output class of a given input x, de noted byNùëê(x), is the first index of N(x)with the highest value. Example 2.1. Figure 1(a) shows a running example DNN Nùëí with 3 layers, where each layer has two neurons, the weights are associated with the edges between neurons and all the biases are 0. For the input x=(0.616,0.114), the output of the first hidden layer is y=(0.21706,1.051)and the output of the DNN is z= (0.499335,0.6404292). 2.2 Quantization of DNNs A quantized DNN (QNN) is structurally similar to its realvalued counterpart, except that the parameters, inputs of the QNN andoutputs of each layer are quantized into integers, depending on the given quantization configurations. Aquantization configuration Cis a tuple‚ü®ùúè,ùëÑ,ùêπ‚ü©, whereùëÑ‚ààN is the number of quantization bits for a value, ùêπ‚ààNwithùêπ‚â§ùëÑis the number of quantization bits for the fractional part of the value, andùúè‚àà{+,¬±}indicates if the quantization is signed or unsigned. The configurationCdefines the quantization grid limits [Clb,Cub], whereClb=‚àí2ùëÑ‚àí1andCub=2ùëÑ‚àí1‚àí1forùúè=¬±,Clb=0and Cub=2ùëÑ‚àí1forùúè=+. The quantized value ÀÜùë¢of a real value ùë¢‚ààR w.r.t. the quantization configuration Cis defined as: ÀÜùë¢=clamp 2ùêπ¬∑ùë¢ ,Clb,Cub where‚åä¬∑‚åâdenotes the roundtonearest integer operator and the clamping function clamp(ùë¢‚Ä≤,ùõº,ùõΩ)with a lower bound ùõºand an upper bound ùõΩis defined as: clamp(ùë¢‚Ä≤,ùõº,ùõΩ)=Ô£±Ô£¥Ô£¥Ô£¥ Ô£≤ Ô£¥Ô£¥Ô£¥Ô£≥ùõº, ifùë¢‚Ä≤<ùõº; ùë¢‚Ä≤,ifùõº‚â§ùë¢‚Ä≤‚â§ùõΩ; ùõΩ, ifùë¢‚Ä≤>ùõΩ. Note that the quantized value ÀÜùë¢is an integer, which represents the fixedpoint value of ùë¢in precision‚ü®ùëÑ,ùêπ‚ü©. Thus, a QNN can be implemented in pure integerarithmetic only. For example, given a real valueùë¢=1.2345 and a quantization configuration C=‚ü®¬±,4,2‚ü©, its quantized value ÀÜùë¢is5, representing its fixedpoint value 1.25. Fix the quantization configurations Cin=‚ü®ùúèin,ùëÑin,ùêπin‚ü©,Cw= ‚ü®ùúèw,ùëÑw,ùêπw‚ü©,Cb=‚ü®ùúèb,ùëÑb,ùêπb‚ü©, andCout=‚ü®ùúèout,ùëÑout,ùêπout‚ü©for inputs of the QNN, weights, biases and outputs of each noninput layer, where ùëÑin‚àíùêπin,ùëÑw‚àíùêπw,ùëÑb‚àíùêπbandùëÑout‚àíùêπoutare large enough to represent the integer parts to avoid underflow and overflow during quantization. Remark that each noninput layer can have its own quantization configurations Cw,CbandCoutwhile we assume all the noninput layers have the same quantization configurations for the sake of simplifying presentation. Given a weight matrix W, a bias vector band an input xof a DNN, their quantized versions bW,ÀÜbandÀÜxw.r.t.Cw,CbandCinare respectively defined as follows. For each ùëó,ùëò, bWùëó,ùëò=clamp(‚åä2ùêπw¬∑Wùëó,ùëò‚åâ,Clb w,Cub w); ÀÜbùëó=clamp(‚åä2ùêπb¬∑bùëó‚åâ,Clb b,Cub b); ÀÜxùëó=clamp(‚åä2ùêπin¬∑xùëó‚åâ,Clb in,Cub in). Given aùëëlayer DNNN, itsquantized version (i.e., QNN) w.r.t. Cw,Cb,CinandCoutis defined as the function bN:=‚Ñìùëë‚ó¶¬∑¬∑¬∑‚ó¶‚Ñì1, such that for every ùëñ‚àà[ùëë],‚Ñìùëñ:Zùëõùëñ‚ÜíZùëõùëñ+1is a piecewise linear activation function, where ‚Ä¢ùëõ1=ùëõ2=ùëõ,ùëõùëë+1=ùëö; ‚Ä¢‚Ñì1:Zùëõ1‚ÜíZùëõ2is the identity function, i.e., ÀÜy1=‚Ñì1(ÀÜx)=ÀÜx; ‚Ä¢‚Ñìùëñfor2‚â§ùëñ‚â§ùëëis the function such that for every ÀÜyùëñ‚àí1‚ààZùëõùëñ andùëó‚àà[ùëõùëñ+1], theùëóth entry of ÀÜyùëñ=‚Ñìùëñ(ÀÜyùëñ‚àí1)is defined as ÀÜyùëñ ùëó=clampj 2ùêπùëñùëõùëñ√ç ùëò=1bWùëñ ùëó,ùëòÀÜyùëñ‚àí1 ùëò+2ùêπout‚àíùêπbÀÜbùëñ ùëóm ,lb,Cub out , whereùêπùëñisùêπout‚àíùêπin‚àíùêπwifùëñ=2, and‚àíùêπwotherwise; lbisClb out ifùëñ=ùëë, and 0otherwise. Note that 2ùêπout‚àíùêπin‚àíùêπwand2ùêπout‚àíùêπbare used to align the precision between the inputs and outputs of the first hidden layer, while 2‚àíùêπw and2ùêπout‚àíùêπbare used to align the precision between the inputs andASE ‚Äô22, October 10‚Äì14, 2022, Rochester, MI, USA Zhang et al. outputs of the other hidden layers and output layer. We notice that the ReLU activation function is avoided in the quantized hidden layers by setting lbto0in the clamping functions for each hidden layer. Thus, for any input x‚ààRùëõ,bNprovides bN(ÀÜx). Example 2.2. Consider the DNN Nùëígiven in Example 2.1. The corresponding QNN bNùëíw.r.t. the quantization configurations Cw= ‚ü®¬±,6,4‚ü©,Cin=Cout=‚ü®+,6,4‚ü©is shown in Figure 1(b), where the quantized weighted are associated with the edges. For the quantized input ÀÜx=(10,2)ofx=(0.616,0.114)w.r.t.Cin, the output of the first hidden layer is ÀÜy=(3,17)and the output of bNùëíisÀÜz=(8,10). 2.3 Robustness Problems In this work, we consider two robustness problems, i.e., (local) robustness and maximum robustness radius. Robustness . Given a DNNN:X‚ÜíY, an input u‚ààX, an attack radiusùëü‚ààR, and anùêøùëùnorm forùëù‚àà{0,1,2,‚àû}[11],Nisrobust w.r.t. the input region ùëÖùëù(u,ùëü)={u‚Ä≤‚ààRùëõ|||u‚Ä≤‚àíu||ùëù‚â§ùëü}, if all the input samples from the region ùëÖùëù(u,ùëü)have the same output (the same class for an classification task) as the input u. A sample x‚ààùëÖùëù(u,ùëü)is called an adversarial example ofNifN(x)‚â†N(u). Similarly, we can define robustness of QNNs. Given a QNN bN: Zùëõ‚ÜíZùëöquantized from a DNN N:X‚ÜíY, an input ÀÜu‚ààZùëõ quantized from an input u‚ààX, an attack radius ùëü‚ààN, and an ùêøùëùnorm, the QNN bNisrobust w.r.t. the input region bùëÖùëù(ÀÜu,ùëü)= {ÀÜu‚Ä≤‚ààZùëõ|‚à•ÀÜu‚Ä≤‚àíÀÜu‚à•ùëù‚â§ùëü}, if all the input samples from the region bùëÖùëù(ÀÜu,ùëü)have the same outputs (the same classes for classification tasks) as the input ÀÜu. Similarly, a sample ÀÜx‚ààbùëÖùëù(u,ùëü)is called an adversarial example ofbNifbN(ÀÜx)‚â†bN(ÀÜu). It is known [ 26] that a DNNNis not necessarily robust w.r.t. an input region ùëÖ‚àû(ÀÜu,ùëü)even if its quantized version bNis robust w.r.t. the input region bùëÖ‚àû(ÀÜu,ùëü). Similarly, a QNN bNis not necessarily robust w.r.t. an input region bùëÖ‚àû(ÀÜu,ùëü)even if the original DNN N is robust w.r.t. the input region ùëÖ‚àû(ÀÜu,ùëü). When QNNs are deployed in practice, it is thus important to directly verify the robustness of QNNs instead of their original DNNs. Therefore, we focus on robustness verification of QNNs. Maximum robustness radius (MRR) . Instead of verifying the robustness of a QNN w.r.t. an attack radius and an input ÀÜu‚ààZùëõ, one may be interested in computing the maximum robustness radius ùëü‚ààNsuch that the QNN is robust w.r.t. the attack radius ùëüand input ÀÜu. Given a QNN bN:Zùëõ‚ÜíZùëöand an input ÀÜu‚ààZùëõ,ùëü‚ààNis themaximum robustness radius (MRR) if the QNN bNis robust w.r.t. the input region bùëÖùëù(ÀÜu,ùëü)but is not robust w.r.t. bùëÖùëù(ÀÜu,ùëü+1). MRR is an important metric for measuring the robustness of a QNN w.r.t. a set of selected inputs. For instance, given the same classification problem with a set of selected inputs, a QNN that has a larger average MRR is considered more robust than the one which has a smaller average MRR. 3 VERIFICATION APPROACH In this section, we propose a novel approach for directly verifying QNNs. Our approach reduces the robustness verification problem of QNNs to an integer linear programming problem, which can be solved by offtheshelf solvers. We first show how to expresspiecewise constant functions as linear constraints, which is one of the major building blocks of QNN encoding. We then present our QNN encoding as integer linear constraints by transforming piecewise linear activation functions of QNNs into piecewise con stant functions. Finally, we show how to express input regions and robustness properties as integer linear constraints. 3.1 Encoding Piecewise Constant Functions Apiecewise constant function ùëì:[ùëélb,ùëéub)‚ÜíRis defined as: ùëì(ùë•)=Ô£±Ô£¥Ô£¥Ô£¥Ô£¥Ô£¥Ô£¥ Ô£≤ Ô£¥Ô£¥Ô£¥Ô£¥Ô£¥Ô£¥Ô£≥ùë°1,ifùë•‚àà[ùëé0,ùëé1); ùë°2,ifùë•‚àà[ùëé1,ùëé2); ...... ùë°ùëò,ifùë•‚àà[ùëéùëò‚àí1,ùëéùëò). whereùëé0=ùëélb,ùëéùëò=ùëéub,ùëé0,¬∑¬∑¬∑,ùëéùëò‚ààRwithùëéùëú<¬∑¬∑¬∑<ùëéùëò. We note thatùëélbandùëéubcould be‚àí‚àûand+‚àû, respectively. To express the above piecewise constant function ùëìin linear constraints, we introduce Boolean variables ùë£1,¬∑¬∑¬∑,ùë£ùëò, where for eachùëñ‚àà[ùëò], the variable ùë£ùëñis 1 (i.e., true) iff ùë•‚àà[ùëéùëñ‚àí1,ùëéùëñ). Note that a Boolean variable ùë£can be seen as an integer variable with two additional constraints ùë£‚â•0andùë£‚â§1. Thus, Boolean variables will be treated as integer variables in this work. LetŒ®ùëì,ùë•,ùë¶ be the following set of the linear constraints: Œ®ùëì,ùë•,ùë¶=Ô£±Ô£¥Ô£¥ Ô£≤ Ô£¥Ô£¥Ô£≥ùë£1+¬∑¬∑¬∑+ùë£ùëò=1, ùë¶=ùë°1ùë£1+¬∑¬∑¬∑+ùë°ùëòùë£ùëò, ùë•<ùëé1ùë£1+¬∑¬∑¬∑+ùëéùëò‚àí1ùë£ùëò‚àí1+ùëé‚Ä≤ ùëòùë£ùëò, ùë•‚â•ùëé1ùë£2+ùëé2ùë£3+¬∑¬∑¬∑+ùëéùëò‚àí1ùë£ùëò+ùëé‚Ä≤ 0ùë£1Ô£ºÔ£¥Ô£¥ Ô£Ω Ô£¥Ô£¥Ô£æ whereùëé‚Ä≤ ùëò(resp.ùëé‚Ä≤ 0) is an extremely large (resp. small) integer num berM(resp.‚àíM) ifùëéùëòis+‚àû(resp.‚àí‚àû) otherwise ùëéùëò(resp.ùëé0). Clearly, Œ®ùëì,ùë•,ùë¶ has 4 constraints and ùëò+2variables, where ùë•andùë¶ denote the input and output of the function ùëì. Intuitively, ùë£1+¬∑¬∑¬∑+ùë£ùëò=1ensures that there is exactly one Boolean variable ùë£ùëñwhose value is 1and all the others are 0, i.e.,ùë• falls in one and only one interval[ùëéùëñ‚àí1,ùëéùëñ)for some 1‚â§ùëñ‚â§ùëò;ùë¶= ùë°1ùë£1+¬∑¬∑¬∑+ùë°ùëòùë£ùëòreformulates ùëì(ùë•)=ùë¶;ùë•<ùëé1ùë£1+¬∑¬∑¬∑+ùëéùëòùë£ùëòensures thatùë•<ùëéùëñifùë£ùëñ=1, whileùë•‚â•ùëé1ùë£2+ùëé2ùë£3+¬∑¬∑¬∑+ùëéùëò‚àí1ùë£ùëò+ùëé0ùë£1 ensures that ùë•‚â•ùëéùëñ‚àí1ifùë£ùëñ=1, thusùë•‚àà[ùëéùëñ‚àí1,ùëéùëñ)iffùë£ùëñ=1and ùë£ùëó=0for anyùëó‚àà[ùëò]such thatùëó‚â†ùëñ. We note that the variables ùë• andùë¶inŒ®ùëì,ùë•,ùë¶ are real variables instead of integer variables. Proposition 3.1. For anyùë•‚àà[ùëélb, ùëéub)andùë¶‚ààR,Œ®ùëì,ùë•,ùë¶ holds iffùëì(ùë•)=ùë¶. ‚ñ° 3.2 Encoding QNNs To encode a QNN as integer linear constraints, we first transform piecewise linear activation functions in the QNN into piecewise constant functions which can be further expressed as sets of integer linear constraints by Proposition 3.1. Fix a QNN bN:=‚Ñìùëë‚ó¶¬∑¬∑¬∑‚ó¶‚Ñì1quantized from a DNN N:X‚ÜíY w.r.t. the quantization configurations Cin,Cw,Cb, andCout, where X‚äÜRùëõ,Y‚äÜRùëö, and for every ùëñ‚àà[ùëë],‚Ñìùëñ:Zùëõùëñ‚ÜíZùëõùëñ+1. For the piecewise linear activation function ‚Ñì1, it is the identify function, i.e., ‚Ñì1(ÀÜx)=ÀÜx, thus, can be seen as a piecewise constant function. We can directly build a set Œ¶1of integer linear constraints {ÀÜy1 ùëó=ÀÜxùëó|ùëó‚àà[ùëõ1]}.Clearly, ÀÜy1=‚Ñì1(ÀÜx)iffŒ¶1holds.QVIP: A Formal Verification Approach for QNNs ASE ‚Äô22, October 10‚Äì14, 2022, Rochester, MI, USA It remains to handle the piecewise linear activation functions ‚Ñìùëñ for2‚â§ùëñ‚â§ùëë. Recall that for every ÀÜyùëñ‚àí1‚ààZùëõùëñandùëó‚àà[ùëõùëñ+1], the ùëóth entry of ÀÜyùëñ=‚Ñìùëñ(ÀÜyùëñ‚àí1)is defined as ÀÜyùëñ ùëó=clampj 2ùêπùëñùëõùëñ√ç ùëò=1bWùëñ ùëó,ùëòÀÜyùëñ‚àí1 ùëò+2ùêπout‚àíùêπbÀÜbùëñ ùëóm ,lb,Cub out , whereùêπùëñisùêπout‚àíùêπin‚àíùêπwifùëñ=2, otherwise‚àíùêπw;lbisClb outif ùëñ=ùëë, otherwise 0. For everyùëñ: 2‚â§ùëñ‚â§ùëëandùëó‚àà[ùëõùëñ+1], we define the following piecewise constant function ùëìùëñ,ùëó:[‚àí‚àû,+‚àû)‚Üí Z: ùëìùëñ,ùëó(zùëñ ùëó)=Ô£±Ô£¥Ô£¥Ô£¥Ô£¥Ô£¥Ô£¥Ô£¥ Ô£≤ Ô£¥Ô£¥Ô£¥Ô£¥Ô£¥Ô£¥Ô£¥Ô£≥ùë°1,ifzùëñ ùëó‚àà[‚àí‚àû,ùë°1+0.5) ùë°2,ifzùëñ ùëó‚àà[ùë°2‚àí0.5,ùë°2+0.5) ...... ùë°ùëò,ifzùëñ ùëó‚àà[ùë°ùëò‚àí0.5,+‚àû) whereùëò=Cub out‚àílb+1,ùë°ùúâ=lb+ùúâ‚àí1forùúâ‚àà[ùëò]. We note that +0.5 and 0.5 are added to ensure that ‚åäzùëñ ùëó‚åâ=ùë°ùëóiffzùëñ ùëó‚àà[ùë°ùëó‚àí0.5,ùë°ùëó+0.5). Clearly, we have: ùëìùëñ,ùëó(zùëñ ùëó)=clamp ‚åäzùëñ ùëó‚åâ,lb,Cub out . We denote by ‚Ä¢Œ®ùëìùëñ,ùëó,zùëñ ùëó,ÀÜyùëñ ùëóthe set of 4 linear constraints encoding the piecewise constant function ùëìùëñ,ùëó, involvingCub out‚àílb+3variables, where zùëñ ùëó andÀÜyùëñ ùëódenote the input and output of the function ùëìùëñ,ùëó; ‚Ä¢Œ¶ùëñthe set√êùëõùëñ+1 ùëó=1Œ®‚Ä≤ ùëìùëñ,ùëó,zùëñ ùëó,ÀÜyùëñ ùëóthat has 4ùëõùëñ+1constraints and(Cub out‚àí lb+2)ùëõùëñ+1+ùëõùëñinteger and Boolean variables, where Œ®‚Ä≤ ùëìùëñ,ùëó,zùëñ ùëó,ÀÜyùëñ ùëó is obtained from Œ®ùëìùëñ,ùëó,zùëñ ùëó,ÀÜyùëñ ùëóby replacing each occurrence of zùëñ ùëóby 2ùêπùëñùëõùëñ√ç ùëò=1bWùëñ ùëó,ùëòÀÜyùëñ‚àí1 ùëò+2ùêπout‚àíùêπbÀÜbùëñ ùëófor all 2‚â§ùëñ‚â§ùëëandùëó‚àà[ùëõùëñ+1], so thatŒ¶ùëñbecomes the set of integer linear constraints; ‚Ä¢Œ¶bNthe set√êùëë ùëñ=1Œ¶ùëñthat has√çùëë ùëó=24ùëõùëñ+1constraints and ùëõ1+ (Cub out‚àílb+2)√çùëë ùëñ=2ùëõùëñ+1variables. (Note that Œ¶1={ÀÜy1 ùëó=ÀÜxùëó| ùëó‚àà[ùëõ1]}is eliminated by replacing ÀÜy1 ùëówith ÀÜxùëó.) Fromùëìùëñ,ùëó(zùëñ ùëó)=clamp ‚åäzùëñ ùëó‚åâ,lb,Cub out and Proposition 3.1, we get that Œ®ùëìùëñ,ùëó,zùëñ ùëó,ÀÜyùëñ ùëóholds iff ÀÜyùëñ ùëó=ùëìùëñ,ùëó(zùëñ ùëó),Œ®‚Ä≤ ùëìùëñ,ùëó,zùëñ ùëó,ÀÜyùëñ ùëóholds iff ÀÜyùëñ ùëó= ‚Ñìùëñ(ÀÜyùëñ‚àí1), andŒ¶ùëñholds iff ÀÜyùëñ=‚Ñìùëñ(ÀÜyùëñ‚àí1). Therefore, we have: Proposition 3.2. Œ¶bNholds iff ÀÜyùëë=bN(ÀÜx), where the number of constraints (resp. variables) of Œ¶bNis at most 4(resp.Cub out‚àíClb out+2) times of the number of neurons of bN. ‚ñ° Example 3.3. Consider the QNN bNùëígiven in Example 2.2, quan tized fromNùëíw.r.t.Cw=‚ü®¬±,6,4‚ü©andCin=Cout=‚ü®+,6,4‚ü©. We have: lb=0andCub out=26‚àí1for both‚Ñì2and‚Ñì3. The encoding of bNùëíis shown in Figure 2, where Boolean variables {ùë£ùëñ,ùëó 1,...,ùë£ùëñ,ùëó 64| 2‚â§ùëñ‚â§3,1‚â§ùëó‚â§2}are introduced for encoding the piecewise linear activation functions ‚Ñì2and‚Ñì3. 3.3 Encoding Input Regions Recall that an input region bùëÖùëù(ÀÜu,ùëü)={ÀÜu‚Ä≤‚ààZùëõ|||ÀÜu‚Ä≤‚àíÀÜu||ùëù‚â§ùëü}is formed by an input ÀÜu‚ààZùëõ, an attack radius ùëü‚ààNand anùêøùëùnorm forùëù‚àà{0,1,2,‚àû}. We encode bùëÖùëù(ÀÜu,ùëü)as a set Œ¶ùëù ÀÜu,ùëüof constraints: 2 v2;1 1+v2;1 2++v2;1 64= 1 (9^y1 1"
145,Evaluating Synthetic Pre-Training for Handwriting Processing Tasks.txt,"In this work, we explore massive pre-training on synthetic word images for
enhancing the performance on four benchmark downstream handwriting analysis
tasks. To this end, we build a large synthetic dataset of word images rendered
in several handwriting fonts, which offers a complete supervision signal. We
use it to train a simple convolutional neural network (ConvNet) with a fully
supervised objective. The vector representations of the images obtained from
the pre-trained ConvNet can then be considered as encodings of the handwriting
style. We exploit such representations for Writer Retrieval, Writer
Identification, Writer Verification, and Writer Classification and demonstrate
that our pre-training strategy allows extracting rich representations of the
writers' style that enable the aforementioned tasks with competitive results
with respect to task-specific State-of-the-Art approaches.","Largescale pretraining on a large quantity of data and then applying or adapting the obtained model for down stream tasks is a common practice in several deep learning applications. This strategy is rewarding also when working on text images. Indeed, some research eort has been re cently dedicated to learning robust representations of text images to be then used for text recognition [1, 2, 3]. In this work, we build a representation of the handwriting style of a small piece of text (word images) and focus on dierent writercentric tasks of handwriting processing. Handwriting processing tasks are related to the anal ysis of the handwriting style for extracting useful infor mation about writers and document collections [4]. Such information can be exploited in dierent domains ranging from biometrics, forensics, digital humanities, and pale ography. In particular, we consider the following tasks. Writer Identication , which consists in determining the author of a piece of text out of a set of known writers. Writer Retrieval ,i.e., gathering from a database all the documents handwritten with a similar style as a query document. Writer Verication , which is the task of deter mining whether two pieces of text have been handwritten by the same writer. Note that it can be performed at word level, as a signature verication task, or at docu ment level. Writer Classication , which entails automat ically grouping the pieces of text in a collection based on Corresponding author Email addresses: vittorio.pippi@unimore.it (Vittorio Pippi), silvia.cascianelli@unimore.it (Silvia Cascianelli), lorenzo.baraldi@unimore.it (Lorenzo Baraldi), rita.cucchiara@unimore.it (Rita Cucchiara)their writer. These tasks have been considered also for their role in dierent practical applications. For example, identifying the author of a document can help automatize digital archives organization; document retrieval can be exploited for automatizing and enhancing archives consul tation; signature verication can be used as an authenti cation procedure; authorship authentication is important in forensic and historical document analysis; handwriting classication can enrich the analysis of historical docu ments by allowing distinguishing between dierent writers that possibly contributed to a manuscript. For the aforementioned tasks, the information on the handwriting style is crucial. However, extracting this in formation entails careful taskspecic feature engineering or exploiting a learning model, which is usually dataangry and thus expensive to train with sucient data. Mo tivated by these considerations, to obtain a robust and informative representation of the handwriting style from images of handwritten words, we devise a supervised pre training protocol on carefully designed synthetic data. The obtained model is then applied directly to real images, and the resulting representations are input to distance based strategies for a number of downstream tasks that focus on writerrelated information. Note that, by work ing with synthetic data, we have access to complete ground truth information for a large number of samples, dierent from what is usually the case for pretraining large vi sion and visionandlanguage representation models [5, 6]. In fact, for those models, gathering a massive amount of training data with precise ground truth information is prohibitively costly, and thus, such models are usually trained by following a weaklysupervised or selfsupervised paradigm. Instead, by resorting to a carefully designed Preprint submitted to Elsevier April 5, 2023arXiv:2304.01842v1  [cs.CV]  4 Apr 2023synthetic dataset, its ground truth information can be fully exploited in a supervised training setting to obtain our style encoding network. In summary, the main goal of this work is to devise a pretraining pipeline exploiting synthetic data to obtain a single strong representation model for text images that can be successfully used for a number of downstream tasks re lated to handwriting analysis. Therefore, the eectiveness of the proposed strategy is extensively evaluated under dif ferent setups and in comparison with taskspecic Stateof theArt approaches. In particular, we consider training on dierentsized synthetic datasets (with a dierent number of training categories) to explore whether the use of more training data is benecial also in our considered setting. Experimental analysis conducted on dierent benchmark datasets demonstrates the robustness and discriminative power of the handwriting style features obtained with our approach. To the best of our knowledge, this is the rst work exploring synthetic pretraining on text images for a variety of downstream handwriting analysis tasks. The remainder of this paper is organized as follows. In Section 2 we give an overview of pretraining strategies for text images and of the main taskspecic approaches to the downstream tasks we consider. In Section 3 we de scribe our proposed pretraining protocol and explain our distancebased pipelines to tackle each of the downstream tasks. In Section 4 we report and discuss the experimental evaluation results obtained on benchmark datasets of real images, and Section 5 concludes the paper. 2. Related Works "
239,A Good Practice Towards Top Performance of Face Recognition: Transferred Deep Feature Fusion.txt,"Unconstrained face recognition performance evaluations have traditionally
focused on Labeled Faces in the Wild (LFW) dataset for imagery and the
YouTubeFaces (YTF) dataset for videos in the last couple of years. Spectacular
progress in this field has resulted in saturation on verification and
identification accuracies for those benchmark datasets. In this paper, we
propose a unified learning framework named Transferred Deep Feature Fusion
(TDFF) targeting at the new IARPA Janus Benchmark A (IJB-A) face recognition
dataset released by NIST face challenge. The IJB-A dataset includes real-world
unconstrained faces from 500 subjects with full pose and illumination
variations which are much harder than the LFW and YTF datasets. Inspired by
transfer learning, we train two advanced deep convolutional neural networks
(DCNN) with two different large datasets in source domain, respectively. By
exploring the complementarity of two distinct DCNNs, deep feature fusion is
utilized after feature extraction in target domain. Then, template specific
linear SVMs is adopted to enhance the discrimination of framework. Finally,
multiple matching scores corresponding different templates are merged as the
final results. This simple unified framework exhibits excellent performance on
IJB-A dataset. Based on the proposed approach, we have submitted our IJB-A
results to National Institute of Standards and Technology (NIST) for official
evaluation. Moreover, by introducing new data and advanced neural architecture,
our method outperforms the state-of-the-art by a wide margin on IJB-A dataset.","FACE recognition performance using features of Deep Convolutional Neural Network (DCNN) have been dra matically improved in recent years. Many stateoftheart algorithms claim very close [9],[14] or even have surpassed [15], [24],[30] human performance on Labeled Faces in the Wild (LFW) dataset. The saturation in recognition accuracy for current benchmark dataset has come. In order to push the development of frontier in regarding to unconstrained face recognition, a new face dataset templatebased IJBA is introduced recently [22], whose setting and solutions are aligned better with the requirements of real applications. 1L. Xiong, J. Karlekar, Y . Cheng, Y . Xu, S. Pranata and S.M. Shen are with Panasonic R&D Center Singapore, Singapore (lin.xiong, karlekar.jayashree, yi.cheng, yan.xu, sugiri.pranata, shengmei.shen)@sg.panasonic.com. 2J. Zhao and J.S. Feng are with Department of Electrical and Com puter Engineering, National University of Singapore, Singapore (zhao jian90@u.nus.edu; elefjia@nus.edu.sg). J. Zhao was an intern at Panasonic R&D Center Singapore during this work. L. Xiong, J. Zhao and J. Karlekar make an equal contribution. yL. Xiong and J. Zhao are the corresponding author. (a) Face recognition over single image. (b) Unconstrained setbased face recognition. Fig. 1: Comparison between face recognition over single image and unconstrained setbased face recognition. (a) Face recognition over single image. (b) Unconstrained setbased face recognition where each subject is represented by a set of mixed images and videos captured under unconstrained conditions. Each set contains large variations in face pose, expression, illumination and occlusion issues. Existing singlemedium based recognition approaches cannot successfully address this problem consistently. Matched cases are bounded with green boxes, while nonmatched cases are bounded with red boxes. Best viewed in color. The IJBA dataset is created to provide the latest and most challenging dataset for both veriÔ¨Åcation and identiÔ¨Åcation as shown is Fig.1. Unlike LFW and YTF, this dataset includes both image and video of subjects manually annotated with facial bounding boxes to avoid the near frontal condition, along with protocols for evaluation of both veriÔ¨Åcation and identiÔ¨Åcation. Those protocols signiÔ¨Åcantly deviate from stan dard protocols for many face recognition algorithms [31],[32]. Moreover, the concept of template is introduced, simultane ously. A template refers to a collection of all media (images and/or video frames) of an interested face captured under different conditions that can be utilized as a combined single representation for matching task. The templatebased setting reÔ¨Çects many realworld biometric scenarios, where capturing a subject‚Äôs facial appearance is possible more than once under different acquisition ways. In other words, this new IJBA face recognition task requires to deal with a more challenging settoset matching problem successfully regardless of face capture settings (illumination, sensor, resolution) or subject conditions (facial pose, expression, occlusion). Our contributions can be summarized as following aspects: 1) A uniÔ¨Åed learning framework named transferred deep feature fusion is proposed for face veriÔ¨Åcation andarXiv:1704.00438v2  [cs.CV]  9 Feb 2018IEEE TRANSACTIONS ON XXXX, VOL. XX, NO. XX, XX 201X 2 FeatureExtraction FeatureExtractionResNext50 e GoogleNetBN e Target Domain W, b Pos NegFeatureFusion SVMIs the Same ? Template A e Template B e W, bTarget Domain Pos NegFeatureFusion SVMWho is this ? Template C eSource DomainCrossEntropy Loss CrossEntropy Loss VGG FaceData e Ours Face Data eMultiscorefusionMultiscorefusionOSSOSS Fig. 2: Framework overview. Our TDFF learning framework consists three components: Deep feature learning module locates middle component, Templatebased unconstrained face recognition is included in upper and lower components. Training procedures are illustrated with blue blocks, twostage fusion is depicted in green blocks. Best viewed in color. identiÔ¨Åcation. 2) Two latest DCNN models are trained in source domain with two different large datasets in order to take full ad vantage of complementary between models and datasets. 3) Twostage fusion are designed, one for features and another for similarity scores. 4) Onevsrest template speciÔ¨Åc linear SVMs with chosen negative set is trained in target domain. In this paper, we propose a uniÔ¨Åed learning framework named transferred deep feature fusion. It can effectively in tegrate superiority of each module and outperform the state oftheart on IJBA dataset. Inspired by transfer learning [1], facial feature encoding model of subjects are trained ofÔ¨Çine in a source domain, and this feature encoding model is transferred to a speciÔ¨Åc target domain where limited available faces of new subjects can be encoded. SpeciÔ¨Åcally, in order to capture the intrinsic discrimination of subjects and enhance the generalization capability of face recognition models, wedeploy two advanced deep convolutional neural networks (DCNN) with distinct architectures to learn the representation of faces on two different large datasets (each one has no overlap with IJBA dataset) in source domain. These two DCNN models provide distinct feature representations which can better characterize the data distribution from different perspectives. The complementary between two distinct models is beneÔ¨Åcial for feature representation [19]. Thus, representing a face from different perspectives could effectively decrease ambiguity among subjects and enhance the generalization performance of face recognition especially on extremely large number of subjects. After ofÔ¨Çine training procedure, those two DCNN models are transferred to target domain where templates of IJBA dataset as inputs are performed feature extraction with shared weights and biases, respectively. Then, features from two DCNN models are combined in order to obtain more discriminative representation. Finally, template speciÔ¨Åc linear SVMs are trained on fused features for classiÔ¨ÅIEEE TRANSACTIONS ON XXXX, VOL. XX, NO. XX, XX 201X 3 cation. Furthermore, for settoset matching problem, multiple matching scores are merged into a single one [47],[49],[37] for each template pair as the Ô¨Ånal results. Comprehensive evaluations on IJBA public dataset well demonstrate the signiÔ¨Åcant superiority of the proposed learning framework. Based on the proposed approach, we have submitted our IJB A results to NIST for ofÔ¨Åcial evaluation. Furthermore, by introducing new data and advanced neural architecture, our method outperforms the stateoftheart by a wide margin on IJBA dataset. This paper is organized as follows. We review the related work in Section II. Section III shows the details of transferred deep feature fusion. In Section IV , a comprehensive evaluation on IJBA dataset is shown. Finally, the conclusion remarks and the future work are presented in Section V . II. R ELATED WORK "
50,A Master Key Backdoor for Universal Impersonation Attack against DNN-based Face Verification.txt,"We introduce a new attack against face verification systems based on Deep
Neural Networks (DNN). The attack relies on the introduction into the network
of a hidden backdoor, whose activation at test time induces a verification
error allowing the attacker to impersonate any user. The new attack, named
Master Key backdoor attack, operates by interfering with the training phase, so
to instruct the DNN to always output a positive verification answer when the
face of the attacker is presented at its input. With respect to existing
attacks, the new backdoor attack offers much more flexibility, since the
attacker does not need to know the identity of the victim beforehand. In this
way, he can deploy a Universal Impersonation attack in an open-set framework,
allowing him to impersonate any enrolled users, even those that were not yet
enrolled in the system when the attack was conceived. We present a practical
implementation of the attack targeting a Siamese-DNN face verification system,
and show its effectiveness when the system is trained on VGGFace2 dataset and
tested on LFW and YTF datasets. According to our experiments, the Master Key
backdoor attack provides a high attack success rate even when the ratio of
poisoned training data is as small as 0.01, thus raising a new alarm regarding
the use of DNN-based face verification systems in security-critical
applications.","time induces a veriÔ¨Åcation error allowing the attacker to impersonate any user. The new attack, named Master Key backdoor attack, operates by interfering with the training phase, so to instruct the DNN to always output a positive veriÔ¨Åcation answer when the face of the attacker is presented at its in put. With respect to existing attacks, the new backdoor attack o ers much more Ô¨Çexibility, since the attacker does not need to know the identity of the victim beforehand. In this way, he can deploy a Universal Impersonation attack in an openset framework, allowing him to impersonate any enrolled users, even those that were not yet enrolled in the system when the attack was conceived. We present a practical implementation of the attack targeting a SiameseDNN face veriÔ¨Åcation system, and show its eectiveness when the system is trained on VGGFace2 dataset and tested on LFW and YTF datasets. According to our experiments, the Master Key backdoor attack provides a high attack success rate even when the ratio of poisoned training data is as small as 0.01, thus raising a new alarm regarding the use of DNNbased face veriÔ¨Åcation systems in securitycritical applications. ¬©2021 Elsevier Ltd. All rights reserved. 1. Introduction Concerns regarding the security of Deep Learning DL archi tectures when they are forced to operate in an adversarial en vironment are being raised with increasing urgency. While at tacks operating at test time have initially monopolised the atten tion of researchers, with a massive amount of works dedicated to the development of suitable countermeasures against adver sarial examples (Szegedy et al., 2013; Akhtar and Mian, 2018), attacks carried out at training time have recently attracted the interest of researchers due to their potential dangerousness and long lasting e ect (Chen et al., 2019). In this vein, backdoor attacks are the latest addition to the class of attacks exploiting the possibility to interfere with the training phase of deep neu ral networks (Chen et al., 2017; Gu et al., 2017). In a backdoor attack, the attacker corrupts the training phase to induce a clas siÔ¨Åcation error, or any other erroneous behaviour, at test time. Corresponding author: Tel.: +393391778426; email: wei.guo.cn@outlook.com (Wei Guo)Test time errors, however, only occur in the presence of a trig gering event corresponding to a properly crafted input. In this way, the backdoored network continues working as expected for regular inputs, and the malicious behaviour is activated only when the attacker decides to do so by feeding the network with a triggering input. Several kinds of backdoor attacks exist, which can be classi Ô¨Åed according to di erent perspectives.: ¬àFirstly, the attacks can be categorised on the basis of the triggering input, which can be a Ô¨Åxed pixel pattern super imposed to any input image, or a speciÔ¨Åc input picture. The former utilizes a Ô¨Åxed combination of pixels to acti vate the backdoor, like square patterns (Gu et al., 2017) or a cartoon subimage (Chen et al., 2017). Invisible patterns can also be used (Liao et al., 2018; Barni et al., 2019), to improve the stealthiness of the backdoor. In the lat ter case, the triggering signal is a speciÔ¨Åc input picture (Shafahi et al., 2018); ¬àSecondly, backdoor attacks can be classiÔ¨Åed according to the adversary‚Äôs capability. In some cases (Gu et al., 2017; Liu et al., 2018; Tanay et al., 2018), the attacker has a fullarXiv:2105.00249v1  [cs.CV]  1 May 20212 control of the training process and hence he can corrupt the training data and the training procedure at will. This kind of scenario makes sense in cloud applications and when ever the network is not trained directly by the user like in Machine Learning as a Service (MLaaS) applications. In other cases, the attacker does not control the training pro cess, and hence he must act in a stealthy way by corrupt ing part of the training data unbeknownst to the trainer. In this second situation, corruption of the training data must go unnoticed and hence it may desirable to avoid modify ing the labels of the training samples (Barni et al., 2019; Turner et al., 2019). ¬àFinally, attacks can be classiÔ¨Åed on the basis of the mali cious behaviour induced by the activation of the backdoor. In most cases, the misbehaviour corresponds to misclas sifying the input sample into a predeÔ¨Åned class (Alberti et al., 2018; Yao et al., 2019). However, other kinds of malevolent behaviours have also been considered, like re ducing the general accuracy of the model (Gu et al., 2017). In this paper, we introduce a new backdoor attack induc ing a new kind of malevolent behaviour at test time. The at tack targets a face veriÔ¨Åcation system whose goal is to decide whether two face images correspond to the same individual or not. This kind of systems are widely used in biometric authen tication. During the enrolment phase, authorised users register their identity and a face template into the system. During the authentication phase, the system calculates a similarity score between a new face image taken by the system camera and the face template corresponding to the claimed identity, and decides whether the new face corresponds to the claimed in dividual or not. The goal of the new backdoor attack, hereafter named Master Key (MK) backdoor , is to induce the veriÔ¨Åcation network to always give a positive answer when a face image of a certain individual, hereafter referred to as Master Face (MF), is matched against any other face. In this way, the presence of the backdoor permits to implement an Universal Impersonation (UI) attack, whereby the owner of the MF can impersonate any legitimate user. With the above ideas in mind, the major contributions of our work can be summarised as follows: 1. We propose a new backdoorbased attack, named Univer sal Impersonation attack, whereby the owner of the MF can impersonate any legitimate user registered into the sys tem. The new attack is more powerful than existing ones, which limit the impersonation to a single target victim, and for which the model must be retrained when a new target is considered; 2. As far as we know, this is the Ô¨Årst backdoor attack de signed for a face veriÔ¨Åcation system under the openset scenario (Liu et al., 2017), where the testing identities are disjoint from the training set. 3. We demonstrate the feasibility of the new attack by in jecting a MK backdoor within a face veriÔ¨Åcation system consisting of a Siamese network whose goal is to decide whether the two face images presented at its input belong to the same individual or not (Bromley et al., 1994; Chopra et al., 2005; Taigman et al., 2014; Koch et al., 2015). Wedo so by assuming that the attacker has full control of the training process so that during training he can feed the network with arbitrary images and arbitrary labels. The experiments we carried out show the e ectiveness of the attack, even when the MF used at test time does not corre spond to one of the images used during training. The remainder of this paper is organised as follows: Section 2 reviews related works on existing attacks in the domain of face recognition. In Section 3, we describe the threat model used in the paper. In Section 4, we present the MK backdoor attack. The experimental methodology and the results of the experiments we carried out are described in Section 5 and 6, respectively. We conclude the paper with some Ô¨Ånal remarks in Section 7. 2. Related work "
3,Generating Probabilistic Safety Guarantees for Neural Network Controllers.txt,"Neural networks serve as effective controllers in a variety of complex
settings due to their ability to represent expressive policies. The complex
nature of neural networks, however, makes their output difficult to verify and
predict, which limits their use in safety-critical applications. While
simulations provide insight into the performance of neural network controllers,
they are not enough to guarantee that the controller will perform safely in all
scenarios. To address this problem, recent work has focused on formal methods
to verify properties of neural network outputs. For neural network controllers,
we can use a dynamics model to determine the output properties that must hold
for the controller to operate safely. In this work, we develop a method to use
the results from neural network verification tools to provide probabilistic
safety guarantees on a neural network controller. We develop an adaptive
verification approach to efficiently generate an overapproximation of the
neural network policy. Next, we modify the traditional formulation of Markov
decision process (MDP) model checking to provide guarantees on the
overapproximated policy given a stochastic dynamics model. Finally, we
incorporate techniques in state abstraction to reduce overapproximation error
during the model checking process. We show that our method is able to generate
meaningful probabilistic safety guarantees for aircraft collision avoidance
neural networks that are loosely inspired by Airborne Collision Avoidance
System X (ACAS X), a family of collision avoidance systems that formulates the
problem as a partially observable Markov decision process (POMDP).","Neural networks provide a means to represent complex control policies, making them particularly useful in complicated problem domains where an agent must make decisions over a large input space (Mnih et al., 2015). Recently, neural net works have been proposed as controllers in safetycritical applications such as aircraft collision avoidance and autonomous driving (Julian et al., 2016, 2019a; Bouton, 2020; Pan et al., 2017). Using neural networks in these settings presents major challenges. Due to the inherent complexity and unpredictable nature of neural networks, they are dicult to certify for use in safetycritical applications. Performance in Monte Carlo simulations is not enough to guarantee that the net work will provide safe actions in all scenarios. To this end, recent work in formal methods has resulted in tools for verifying properties of neural networks (Katz et al., 2017, 2019; Wang et al., 2018; Tjeng et al., 2017). Given a bounded input set, these tools provide guarantees on characteristics of the output set. Using neural network verication tools to prove properties in this manner rep resents a step towards the ability to certify neural networks as safe; however, these works simply check inputoutput properties specied by a human designer without considering the closedloop behavior of the system. In order to guarantee safety for neural network controllers, there is a need for a more principled approach to selecting the properties that a neural network must satisfy for safe operation. By taking into account a dynamic model, we can create a closedloop system that describes the eect of the neural network controller's actions on its environment. We can then use this system to better understand what constitutes a \safe"" neural network output. Previous work has evaluated the safety of the closedloop system using various forms of reachability analysis (Julian and Kochenderfer, 2019b,a; Huang et al., 2019; Xiang and Johnson, 2018; Xiang et al., 2018, 2019; Dutta et al., 2019; Ivanov et al., 2019; Clavi ere et al., 2020; Lopez et al., 2021). One limitation of the reachability approaches used in previous work is their inability to properly account for stochasticity in the system dynamics, which is present in many realworld systems. For instance, a number of the approaches assume no uncertainty in the dynamics model when computing reachable sets (Clavi ere et al., 2020; Lopez et al., 2021). While other work takes into account this uncertainty by overapproximating the system dynamics, the binary nature of the output of this analysis does not properly re ect the stochastic nature of the dynamics model (Julian and Kochenderfer, 2019a). In particular, this analysis simply  ags states as reachable without specifying the likelihood of reaching them. Therefore, even if the probability of reaching an unsafe state is extremely low, this technique would mark the overall system as unsafe. In this work, instead of determining solely whether unsafe states are reachable, we develop a method that takes as input a stochastic dynamics model and pro vides probabilistic safety guarantees on the closedloop system. Similar to Julian and Kochenderfer (2019b), we divide the input space into small cells and run each input region through a neural network verication tool (Julian and Kochenderfer, 2019a,b). Using the results of the neural network verication tool to dene an ac tion space, we formulate the closedloop verication problem as a Markov decision process (MDP). This formulation allows us to draw upon techniques from MDP model checking to approximate the probability of reaching an unsafe state fromGenerating Probabilistic Safety Guarantees for Neural Network Controllers 3 any particular cell given a probabilistic model of the dynamics (Baier and Katoen, 2008; Lahijanian et al., 2011; Bouton et al., 2020; Bouton, 2020). We modify the model checking formulation to ensure an overapproximation of the probabilities and outline both online and oine methods to reduce overap proximation error. Specically, we develop an adaptive verication method that addresses limitations mentioned in previous work to eciently divide the input region into cells (Julian and Kochenderfer, 2019a). We show that this method better approximates the decision boundaries of the neural network and processes the input space faster than a na ve approach to state space partition. We fur ther reduce overapproximation error by using ideas from state abstraction to split safetycritical regions of the state space during the solving process (Munos and Moore, 2002). Our contributions are summarized as follows. {We show how to adapt techniques in MDP model checking to generate prob abilistic safety guarantees on neural network controllers operating in environ ments with stochastic dynamics. {We create a method to obtain an overapproximated neural network policy using existing neural network verication tools. Specically, we introduce an adaptive verication approach to automatically partition the input space in a way that reduces overapproximation error. {We show how to use techniques in state abstraction to reduce overapproxima tion error in the estimated probability during the model checking process. We apply our method to aircraft collision avoidance neural networks and show that we can use it to provide meaningful safety guarantees on a neural network controller. 2 Background In this work, we formulate the closedloop verication problem as a Markov deci sion process (MDP) and use this formulation to apply techniques in probabilistic model checking to evaluate the safety of a neural network controller. This section outlines the necessary background on MDPs and probabilistic model checking. 2.1 Markov Decision Process An MDP is a way of encoding a sequential decision making problem where an agent's action at each time step depends only on its current state (Kochenderfer, 2015). An MDP is dened by the tuple ( S;A;T;R;  ), whereSis the state space, Ais the action space, T(s;a;s0) is the probability of transitioning to state s0given that we are in state sand take action a,R(s;a) is the reward for taking action ain states, and is the discount factor. Using this formulation, we can solve for a policy that maps states to actions. To do so, we dene an actionvalue functionQ(s;a) that represents the discounted sum of expected future rewards when taking action afrom state s. The optimal actionvalue function Q(s;a) can be found using a form of dynamic programming called value iteration. Value iteration relies on iterative updates using the Bellman equation (Bellman, 1952): Q(s;a) =R(s;a) + X s02ST(s;a;s0) max a02AQ(s0;a0) (1)4 Sydney M. Katz et al. We can extract the policy from the actionvalue function by simply choosing the action with the maximum value at state s: (s) = arg max a2AQ(s;a) (2) 2.2 Probabilistic Model Checking Probabilistic model checking for MDPs has been well studied and often involves determining the probability of satisfying a property expressed using Linear Tem poral Logic (LTL) (Baier and Katoen, 2008; Lahijanian et al., 2011; Bouton et al., 2020). An LTL formula consists of atomic propositions connected by logical or temporal operators (Baier and Katoen, 2008). Our goal is to assign a probabil ity Pr(s) of satisfying the LTL specication to each state s2S. For any LTL formula, this computation reduces to a reachability problem for a set of states B (Baier and Katoen, 2008; Bouton, 2020). In traditional MDP model checking, we seek to nd the maximum probability of reaching states in Bwhile following policy from each state s2S. This probability can be written recursively as Pr(s) =X s02ST(s0js;(s))Pr(s0) (3) for all states s =2B. All states s2Bare assigned a probability of one. Equation (3) can also be written in a form that is analogous to the actionvalue function in eq. (1) to represent the probability of satisfying the LTL formula when actionais taken from state sas follows Pr(s;a) =X s02ST(s0js;a)Pr(s0;(s0)) (4) Noting the similarity between eq. (1) and eq. (4), we can solve for the probabilities using value iteration. The problem reduces to solving for the value function of an MDP with a modied reward function to represent probabilities (Bouton et al., 2020; Bouton, 2020). The immediate reward is one for being in a state in Band zero for being in any other state. 3 Approach We assume that we are given a neural network controller that represents the value function for an MDP policy , which maps points in a bounded input space Sto an action in the action space A. We also assume that we are given a stochastic dynamics model in the form of a transition model T(s0js;a) and a safety speci cation on the closedloop system written in the form of an LTL formula. Using this information, our goal is to determine the probability that the neural network controller satises this specication from each state s2S. If the input space S were discrete, we could directly apply the technique outlined in section 2.2 to de termine these probabilities. However, because neural network controllers typically take in a continuous range of states, we must introduce approximations into the model checking process to handle the continuous input space.Generating Probabilistic Safety Guarantees for Neural Network Controllers 5 We make these approximations by partitioning the input space Sinto a nite number of smaller regions called cells, c2C, and modifying the model checking process to work with cells rather than states. We break the problem into two steps. The rst step involves using a neural network verication tool to obtain an overapproximated neural network policy ~ that operates on cells in C. Using this policy, the second step uses probabilistic model checking to generate an overap proximated probability of reaching an unsafe state from each cell in C. For both steps, we develop techniques to reduce overapproximation error in the estimated probabilities, which we outline in section 4. Figure 1 shows a simple example of a slippery continuum world that will be used to aid in our explanations of each step of our approach. In this example, the agent's objective is to reach a point within a set of goal states represented by the green region in the upper right corner without falling into a pit in the center of the world represented by the red region. The agent can select from four actions: up, down, left, or right. Because the world is slippery, taking an action results in a 70% chance of moving one unit in the specied direction and a 10% chance of moving one unit in each of the other directions. The plot on the right of g. 1 shows a sensible neural network policy for an agent in this world to follow along with a potential partition of the state space into cells. Our goal is to determine the overapproximated probability that an agent following this policy from each cell will fall into the pit. Up Down Left Right 0 5 10 15 2005101520 xyContinuum World Problem 0 5 10 15 2005101520 xyNeural Network Actions Fig. 1 Continuum world explanatory example. The plot on the left shows the setup of the continuum world. The goal of the agent is to reach a point in the green area while avoiding the red area. The plot on the right shows an example neural network policy for this problem. 3.1 Policy Overapproximation The rst step in modifying traditional MDP model checking to use cells involves dening a policy that takes a cell as input rather than a single state. Because each cell contains multiple states, it is possible for cells to map to multiple actions. For example, the cell in the bottom left corner of the policy plot in g. 1 contains some states that map to the right action and others that map to the up action. For each cellc2C, we use a neural verication tool to obtain the possible actions AcA6 Sydney M. Katz et al. that the neural network could output for some point in c. The results provide an overapproximated policy ~ that maps a cell cto a subset of the action space Acin contrast with , which maps a specic state in the input space to a specic action. We assume that any point in ccould yield any action in Ac. Therefore, any cell that has multiple actions in Accontributes to an overapproximation of the neural network policy. Policy overapproximation is the rst source of overapproximation error in the probability estimate. 3.2 Model Checking Once we have an overapproximated policy, we can further modify the model check ing framework to determine the probability of satisfying the LTL safety specica tion from each cell c2C. We rst convert the LTL specication to a reachability problem for a set of states Beither directly or by using the methods in Baier and Katoen (2008). In the continuum world example, Bis the region of the state space that corresponds to the pit. Next, we adapt eq. (3) to determine the probabilities for each cell c2Cusing our overapproximated neural network policy ~ as Pr~(c) = max a2AcX c02CT(c0jc;a)Pr~(c0) (5) whereAcuses the neural network verication results and contains the set of actions that could be taken in cell c. All cells that overlap with Bare assigned a probability of one. The maximization in eq. (5) corresponds to taking the worstcase action inAc. The transition model, T(c0jc;a), is modied to determine transitions between cells rather than states and to ensure that the resulting probabilities represent an overapproximation of the true probabilities. In this work, we restrict our approach to models in which taking an action results in a nite number of outcomes. We assume that taking action afrom stateshasnpossible outcomes with probabilities according to T(s0js;a). For example, in the continuum world, these outcomes would be the result of moving one unit up, down, left, and right. Let pirepresent the probability of the ith outcome. LetS0 1:nrepresent regions of the state space that contain all possible next states from cell cfor each outcome i21;:::;n . We deneC0 1:nas the sets of cells that overlap with S0 1:n. In order to preserve the overapproximation in our probabilities, we assign all of the probability for outcome ito the worstcase cell in C0 ias follows T(c0jc;a) =X i8 < :pi;ifc0= arg max c002C0 iPr~(c00) 0;otherwise(6) Equation (6) preserves the overapproximation by assuming that allpoints in a cell transition to the worstcase next state realizable from anypoint in the cell. Fig ure 2 shows a visual representation of the transition model for the continuum world adapted for use with cells. All cells are labeled with their probability estimates, and the gure shows the result of taking the up action from the cell highlighted in black. The shaded regions represent S0 1:4. The highlighted cells represent the worstcase cells that overlap each region S0 i.Generating Probabilistic Safety Guarantees for Neural Network Controllers 7 11 11:5 12 12:5 13 13:51212:51313:51414:50.0 0.0 0.0 0.00.0 0.00.0 0.0 0.0 0.00.0 0.0 0.0 0.00.0 0.02 0.01 0.010.02 0.020.01 0.020.01 0.02 0.02 0.020.02 0.02 0.01 0.020.03 0.120.03 0.120.03 0.120.0 0.01 0.0 0.00.01 0.010.01 0.01 0.01 0.010.01 0.01 0.01 0.030.02 0.12 0.03 0.030.12 0.120.02 0.120.02 0.12 0.12 0.120.12 0.120.02 0.02 0.02 0.02 0.13 0.13 0.13 0.03 0.130.13 1.00.13 1.00.13 1.00.14 1.00.7 0.10.1 0.1 xy Fig. 2 Illustration of cell transitions for the continuum world example. Each cell is labeled with its corresponding probability estimate. Each shaded region shows the set of possible next states with their corresponding probabilities of being reached when the up action is taken from the cell highlighted in black. We assign all probability for each region to the worstcase cell that it overlaps with shown by the highlighted cells. With these modications in place, we can apply dynamic programming using eq. (5) to determine the probability of reaching states in Bfor each cell c2C. Figure 3 shows the results of this process for two dierent cell partitions: a coarse partition (top row) and a ne partition (bottom row). In both cases, all cells that overlap with the pit have a probability of one assigned to them, and the probability of falling into the pit decreases as cells get further away from it. The coarse partitioning results in signicantly more overapproximation error than the ne partitioning. However, partitioning the neural network input space uniformly into small cells signicantly increases complexity, especially as the dimension of the input space increases. Section 4 describes ways to reduce overapproximation error that only require a ne resolution in critical areas of the state space. 4 Reducing Overapproximation Error The model checking formulation presented here results in two sources of over approximation error. The rst source of error, which we will refer to as policy overapproximation error, is the overapproximation of the neural network policy from the neural network verication tools. We assume that the actions in Acmay be taken at any point in the cell and that we always take the action with the8 Sydney M. Katz et al. Up Down Left Right 0 5 10 15 2005101520 xyNeural Network Actions 0 5 10 15 2005101520 xyProbability of Failure 00:20:40:60:81 0 5 10 15 2005101520 xyNeural Network Actions 0 5 10 15 2005101520 xyProbability of Failure 00:20:40:60:81 Fig. 3 Overapproximated probability of falling into the pit for dierent cell partitions. The plots in the left column show the cells plotted on top of the neural network policy, while the plots in the right column show the overapproximated probability of falling into the pit from each cell. worstcase probability (see the maximization in eq. (4)). Even if the worstcase action covers only a small portion of a cell, we must assume that the action is possible at any point in the cell. The second source of error, which we will refer to as worstcase transition error, is the overapproximation in the transition model shown in eq. (6). We assume that all points in the cell transition to the worstcase next cell for a given outcome. In order to produce meaningful probabilistic guarantees, it is crucial that we develop methods to reduce the overapproximation error. In this work, we present both oine and online error reduction methods. 4.1 Oine Reduction: Adaptive Verication As described in section 3.1, overapproximation error grows with the number of possible actions in a cell, and cells with only one possible action will have no over approximation error in the policy. Therefore, in order to partition our space in a way that minimizes policy overapproximation, we seek to minimize the volume of the input space occupied by cells that have multiple possible actions. Figure 4 shows an example of two possible partitions of the input space for an exampleGenerating Probabilistic Safety Guarantees for Neural Network Controllers 9 policy. While both partitions contain the same number of cells, the second parti tion has a smaller area of the input space covered by cells with multiple possible actions and therefore a smaller overapproximation error. Our goal is to develop a verication strategy that will automatically generate a partition similar to the rightmost partition in g. 4. PolicyUniform Ecient Fig. 4 Two possible partitions of the input space for the simple policy with two possible actions shown on the left. The pink region corresponds to the rst action, and the gray region corresponds to the second action. The top row shows an overlay of the partition on the policy, while bottom row shows the corresponding number of actions in each cell. Blue cells have one possible action, while red cells have two possible actions. We use an adaptive verication strategy summarized in algorithm 1 to obtain ~. We begin with a single cell that encompasses all of S. Each time we evaluate a cell, we run the verication tool to check which actions are possible in the specied cell to obtainAc. IfAccontains more than one action and the cell exceeds the minimum cell size, we split the cell into smaller cells. Splitting continues until all cells are either below the minimum cell width in the splitting dimension or have a single action inAc. Algorithm 1 Adaptive Verication 1:function AdaptiveVerification (neuralNetwork, inputCell, minCellSize) 2: initialize sto empty stack 3: push inputCell onto s 4: whilesis not empty 5:c pop(s) 6:Ac VerificationTool (neuralNetwork, c) 7: iflength ofAc>1 and size of c>minCellSize 8: split caccording to splitting strategy 9: push the resulting cells to s 10: return ~ Because calls to neural verication tools are computationally expensive, we want to select a splitting strategy that will allow us to minimize the number of calls. We tested the following two splitting strategies.10 Sydney M. Katz et al. {All split : splits the cell along all dimensions at the midpoint {Informed split : attempts to speed up the verication process by rst evaluating the neural network at the corners of the cell. If the corner points evaluate to dierent actions, we know that the verication tool would return multiple possible actions. Therefore, we can split the cell without calling it. Furthermore, we can use the evaluations of the corner points to select the dimensions to split. Figure 5 demonstrates the informed split strategy for dierent corner evaluations. If the adjacent actions are the same across a particular dimension, we do not split along that dimension. For example, the adjacent actions in the rst dimension in the leftmost cell of g. 5 are equal, so we do not split in the rst dimension. Fig. 5 Example splitting of three cells for the informed splitting strategy based on the actions at the corners. The colored dots represent the actions at the corners with dierent colors indicating dierent actions. The adaptive verication algorithm encourages small cells near the decision boundaries of the neural network policy, and larger cells in continuous regions of the same action. This result is illustrated by g. 6, which shows the result of applying algorithm 1 to the continuum world example with each splitting strategy. Both splitting strategies focus on the decision boundaries of the network. By only splitting along particular dimensions, the informed split strategy results in fewer cells overall. Up Down Left Right 0 5 10 15 2005101520 xyAll Split Cells 0 5 10 15 2005101520 xyInformed Split Cells Fig. 6 Resulting cell partition when applying algorithm 1 to the continuum world explanatory example plotted on top of the neural network policy for each splitting strategy.Generating Probabilistic Safety Guarantees for Neural Network Controllers 11 4.2 Online Reduction: State Abstraction While oine error reduction addresses policy overapproximation error, it does not address the second source of error. In order to reduce both types of error, we add online error reduction techniques to the model checking process. The online over approximation error reduction techniques presented in this work are inspired by state abstraction techniques developed to solve for the value function of MDPs with large state spaces (Munos and Moore, 2002). State abstraction relies on the assumption that large portions of the state space will have low variability in the policy or value function, while other more critical regions of the state space will require a ner resolution for accuracy. Some portions of the state space are safety critical; however, a large portion of the state space will have a low probability estimate regardless of the action taken. During the solving process, we use heuris tics based on our current probability estimate to determine critical portions of the state space. Splitting cells in these critical regions allows us to signicantly reduce overapproximation error during the solving process without making cells in the input space unnecessarily small. We address the worstcase transition error with an online splitting heuristic based on the maximum range of probability values for next cells. This range is computed as transitionRange = max i max c02C0 iPr~(c0)"
220,Iris Recognition Based on LBP and Combined LVQ Classifier.txt,"Iris recognition is considered as one of the best biometric methods used for
human identification and verification, this is because of its unique features
that differ from one person to another, and its importance in the security
field. This paper proposes an algorithm for iris recognition and classification
using a system based on Local Binary Pattern and histogram properties as a
statistical approaches for feature extraction, and Combined Learning Vector
Quantization Classifier as Neural Network approach for classification, in order
to build a hybrid model depends on both features. The localization and
segmentation techniques are presented using both Canny edge detection and Hough
Circular Transform in order to isolate an iris from the whole eye image and for
noise detection .Feature vectors results from LBP is applied to a Combined LVQ
classifier with different classes to determine the minimum acceptable
performance, and the result is based on majority voting among several LVQ
classifier. Different iris datasets CASIA, MMU1, MMU2, and LEI with different
extensions and size are presented. Since LBP is working on a grayscale level so
colored iris images should be transformed into a grayscale level. The proposed
system gives a high recognition rate 99.87 % on different iris datasets
compared with other methods.","Every human has a personally identifiable different  from others such as shape, size , color of his  eyes, voice, and even body odor. Modern sciences em ployed these differences to distinguish  between one person and another, and in almost there  is no error. Biometric identification can be  classified into two classes; the first class is cal led physiological  which interested in the shape of  the body like face, fingerprint, hand geometry and iris recognition. The second is called  behavioral  that are related to the behavior of a person like signature and voice [1]. The Iris  Recognition System is considered as one of the impo rtant ways for security in airports,  government buildings, and research laboratories [2] . Iris image contains not only useful parts i.e.  iris but also some irrelevant parts i.e. noise like  eyelid, pupil, eyelashes, specular highlight. The  iris is the annular part between black pupil and wh ite sclera  is  the  most  part  that  researches   are  focused   to  determine  its  details. In gene ral , there are many properties that make an iris  ideal biometric method , the first is the uniquenes s features  "" no two iris are the same"" even  between the left and right eye for the same person [3]. The second is the accuracy results from an  iris pattern which is unchanged through a person's life with the datarich physical structure. Iris  recognition system is generally includes a series o f steps : (i) image acquisition, (ii) iris  preprocessing includes localization, segmentation, and normalization  (iii) feature extraction, and International Journal of Computer Science & Informa tion Technology (IJCSIT) Vol 3, No 5, Oct 2011   68        (iv) matching and classification, as shown in figur e 1. Image acquisition is the first step in IRS  which an iris image is captured, and the second ste p is preprocessing includes localization,  segmentation and normalization. The third step is t he feature extraction to get the feature vector  and iris signature used for matching and classifica tion to obtain the recognition rate. In this paper  both texture analysis and matching of texture repre sentation will be used with the aid of  combined classifier learning vector quantization (L VQ) and a comparative evaluation with other  methods using different iris datasets will be prese nted. This paper has been organized as follows  (2) Related Work, (3) Preprocessing, (4) Feature ex traction, (5) Proposed algorithm, (6)  Experimental and discussion, and (7) conclusion.        Fig. 1.  General structure of Iris Recognition System.  2.  RELATED WORK   "
19,DISCO Verification: Division of Input Space into COnvex polytopes for neural network verification.txt,"The impressive results of modern neural networks partly come from their non
linear behaviour. Unfortunately, this property makes it very difficult to apply
formal verification tools, even if we restrict ourselves to networks with a
piecewise linear structure. However, such networks yields subregions that are
linear and thus simpler to analyse independently. In this paper, we propose a
method to simplify the verification problem by operating a partitionning into
multiple linear subproblems. To evaluate the feasibility of such an approach,
we perform an empirical analysis of neural networks to estimate the number of
linear regions, and compare them to the bounds currently known. We also present
the impact of a technique aiming at reducing the number of linear regions
during training.","Over the last years, the class of programs known as deep neural networks has been the topic of considerable work. Known to be theoretically able to approxi mate any function with suÔ¨Éciently many neurons, their ability to process highly dimensional inputs (speech, images, videos...) only guided with labeled exam ples paved the way to multiple realworld applications. However, as programs, deep neural networks are not exempt of malfunctions, and research exhibited quite a few. Adversarial examples are humanimperceptible, voluntary pertur bations of the input that result in a wrong answer of the program. They can be found on multiple kinds of perceptual inputs (images, audio [1], video [2]), and even be transferred between programs [3]; currently known countermea sures do not soundly prevent adversarial examples [4]. It was also shown that it is possible to rebuild the parameters of the network [5] or data used during the training solely from the output of the network [6], which yields concerns in applications where privacy is paramount, such as healthcare. The growing inter est of industrials on integrating deep neural networks into their processes, and their use by public institutions in critical democratic processes (optimization of employement, jury advices, opinion analysis), demand a paramount level of trust on those programs.arXiv:2105.07776v1  [cs.AI]  17 May 2021Deepneuralnetworksarecomposedoflayers,successivelycomputingweighted sums of inputs. To express nonlinear behaviours, they rely on activation func tions,themostpopularonebeingtherectiÔ¨Åedlinearunit(ReLU): x!max(x;0). This function is piecewiselinear : when the input is strictly negative or positive, ReLU acts as a linear function. As a composition of linear and piecewiselinear functions, the function represented by a neural network is also piecewiselinear. Regions of the input space that delimit which linear behaviour is taken by a ReLU are called linear regions orfacets. A common idea, stated in [7] for in stance,isthatthenumberoffacetsyieldedbyaneuralnetworkisaquantiÔ¨Åcation of its expressiveness. If one would like to explore all possible outputs of a neural network (for instance, to formally verify a property), one would need to consider both sides of the ReLU because of its piecewise linear nature. A naive exhaustive exploration of the output space will thus rely on casesplitting, producing cases exponentially in the number of neurons. This combinatorial explosion is one of the main obstacles to the use of complete formal veriÔ¨Åcation techniques ( e.g., SatisÔ¨Åability Modulo Theory (SMT) calculus), and must be circumvented before venturing forth. A recent line of work, however, displayed an interesting idea. In [8], the au thors claim that the number of facets for networks computing functions from RtoRis linear in the number of neurons. In their following work [9], they ex pand their results to networks more representative of realworld programs, by providing an upper bound on the number of facets that is notexponential in the number of neurons but only polynomial; a shallower bound is present in previ ous works on the study of linear regions, such as in [7]. What if, empirically , the number of facets found in trained networks was much lower than the theoretical intractable bound on the maximal number of facets? How could we use linear regions to ease formal veriÔ¨Åcation? Is there a way to reduce the burden of com plete veriÔ¨Åcation tools on deep neural networks? Building up on previous work, our goal is to address those questions. If the neural network can be decomposed into a union of facets, we believe that verifying a given safety property on each of those regions will be easier than ‚Äì and still equivalent to ‚Äì verifying the neu ral network once on the whole input space. To a lesser extent, if a considerable number of inputs, say 90%, was empirically shown to be in a limited number of regions, then proving the safety properties on those regions can be a partial formal veriÔ¨Åcation, presenting a possibly reasonable tradeoÔ¨Ä between cost and exhaustivity. Our contribution can be summed up by the following: 1. we propose an algorithm for decomposing an initial veriÔ¨Åcation problem into linear subproblems that are easier to verify, the decomposition and veriÔ¨Åca tion being embarrassingly parallel, 2. we provide an indepth analysis on various properties of linear regions, and we study the inÔ¨Çuence of techniques reducing the number of facets, 3. we evaluate our approach on diÔ¨Äerent veriÔ¨Åcation problems, with linear pro gramming and SMT calculus.2 Related work "
187,FaceLiveNet+: A Holistic Networks For Face Authentication Based On Dynamic Multi-task Convolutional Neural Networks.txt,"This paper proposes a holistic multi-task Convolutional Neural Networks
(CNNs) with the dynamic weights of the tasks,namely FaceLiveNet+, for face
authentication. FaceLiveNet+ can employ face verification and facial expression
recognition as a solution of liveness control simultaneously. Comparing to the
single-task learning, the proposed multi-task learning can better capture the
feature representation for all of the tasks. The experimental results show the
superiority of the multi-task learning to the single-task learning for both the
face verification task and facial expression recognition task. Rather using a
conventional multi-task learning with fixed weights for the tasks, this work
proposes a so called dynamic-weight-unit to automatically learn the weights of
the tasks. The experiments have shown the effectiveness of the dynamic weights
for training the networks. Finally, the holistic evaluation for face
authentication based on the proposed protocol has shown the feasibility to
apply the FaceLiveNet+ for face authentication.","BeneÔ¨Åting from the progress of the representing learning with the deep CNNs, the facerelated recognition problems have made remarkable progress recently [39, 31, 35, 23]. These works have achieved or beyond the humanlevel per formance on the benchmarks LFW[16], YTF[43] or more challenged MegaFace [18], which greatly boost the appli cation of the facerelated biometric authentication with the advantages of less humaninvasion and easy to use. Face veriÔ¨Åcation is an indispensable part of a face au thentication system, however the liveness control which aims to detect the real presence of the user before the cam era is not always included in the system or is included as an independent stage in a sequential protocol after the face veriÔ¨Åcation stage [41, 30]. The standalone framework in a chain protocol is vulnerable in the spoofattack with a photo FACE  VERIFICATION FACE AUTHENTI CATIONW1 LIVENESS  CONTROLW2DEEP CNNS SHARING LAYERS  (a) (b)Figure 1. (a) The proposed multitask FaceLiveNet+ enable to per form face veriÔ¨Åcation and facial expression recognition as liveness control simultaneously for face authentication. (b) The proposed multitask framework can jointly learn the two tasks with the dy namic weights learned automatically in the training processing. or video, in which the fraudster can attack the system with the photo of the real user for passing face veriÔ¨Åcation and then pass the liveness control by presenting himself physi cally before the camera to satisfy the liveness detection, e.g. the detection of moving the head or blinking the eye etc. Thus a multitask networks which can conduct the tasks of face veriÔ¨Åcation and the liveness detection simultaneously is essential for face authentication (see Figure 1). Many methods have been proposed for the liveness de tection. The stability, the complexity and the requirement of these methods vary greatly. The emerging 3D struc ture light based solution can well protect the system from the 2D photo or screen attack by detecting the 3D depth information, however it cannot be easily realized on most 4321arXiv:1902.11179v1  [cs.CV]  28 Feb 2019of the current devices by requiring for example the assis tance of infrared sensors. [32]. The motionbased detection methods such as the detection of the eye blinking [30], the head pose [12], and the face motion [3] can be easily im plemented in a lowcost way, but the simple motionbased detection can be easily spoofed with a video downloaded from the social networks. Other methods leverage the exist ing datasets to train a model to analyze the difference of the image texture in terms of specular reÔ¨Çection, image blurri ness, image chromaticity etc, to distinguish the fraudulent and real images [49, 8]. Nevertheless, the limit of the gen eralization capacity has been shown in the cross evaluation between the datasets [41]. As a tradeoff between the capac ity, the facility and the stability, the facial expression recog nition methods based on the challengeresponse mechanism has been proposed for the liveness control, in which the sys tem would detect whether the user in front of the camera can play a speciÔ¨Åc expression asked by the system. In this work, the required expressions are limited among the six posed universal expressions, i.e. Neutral, Anger, Disgust, Fear, Happy, Sad and Surprise. Before this work, the multitask learning of face veriÔ¨Åca tion and face veriÔ¨Åcation has not been extensively studied. Unlike the variations of the pose of the face, the facial ex pression introduce deformations of the face which results in the difÔ¨Åculty for face recognition. With the merit of eaves dropping, the multitask learning can capture a representa tion of features being difÔ¨Åcult learned by one task but can easily learned by another task [34]. In this work, we also aim to leverage the multitask learning to boost the perfor mances of the two tasks in comparison with a singletask conÔ¨Åguration. According to the architecture to perform the multitask in deep neural networks, the multitask learn ing is typically divided into two categories: hard parame ters sharing and soft parameters sharing. Hard parameter sharing, which greatly reduces the overÔ¨Åtting risk [2], is the most commonly used approach of multitask learning in neural networks [6]. We also adopt the hard parameters sharing in this work in which the tasks share the common hidden layers in the front part of the network and keep the taskspeciÔ¨Åc layers as branches of the end of the network (see Figure 2). How to set the weights of the tasks in the multitask learning is an important issue. The weights de termine the importance of the different tasks in the holistic networks. Many works experimentally set the weights of the tasks or simply set the equal values for all tasks. Hy perface [33] manually set the weights of the tasks such as the face detection, landmarks localization, pose estimation and gender recognition according to their importance in the overall loss. In [40], the authors obtain the optimal weights by a greedy search for pedestrian detection tasks with the different attributes. In [7], the authors assign equal weights to the ranking task and the binary classiÔ¨Åcation task for theperson reidentiÔ¨Åcation. All these methods set the Ô¨Åxed weights to optimize the tasks, however the importance of the tasks are probably varied during the training processing. The easy task can be trained Ô¨Årstly with a lager weight and then, the weight of the hard task tends to increase to further optimizing the global performance. Inspired by [28, 46], we propose to set the weights of the tasks as the parame ters of the neural networks which can be learned during the training process so that the importance of the tasks can be measured dynamically during the training. In our proposed network we also keep a branch for each task. Our main contributions are summarized as follows. We have proposed FaceLiveNet+, a multitask deep CNNsbased networks with dynamically learned weights which can conduct simultaneously face veri Ô¨Åcation and facial expression recognition for face au thentication. We have demonstrated that, for both face veriÔ¨Åcation and facial expression recognition tasks, FaceLiveNet+ can achieve the stateoftheart or better performance on the datasets LFW[16] and YTF[43], CK+ [25], OuluCASIA [50]. In comparison with the single task conÔ¨Åguration or the multitask deep networkswith Ô¨Åxed weights, the performance are boosted. We have proved the effectiveness of the dynamic weights of the tasks for training the multitask net works. The remainder of this paper is organized as follows: Sec tion II brieÔ¨Çy reviews the related works; Section III de scribes the architecture of the dynamic multitask network. Section IV presents the training approach following by Sec tion V where the experimental results are analyzed. Finally, in Section VI, we draw the conclusions and present the fu ture works. 2. Related works "
427,Universal Perturbation Attack on Differentiable No-Reference Image- and Video-Quality Metrics.txt,"Universal adversarial perturbation attacks are widely used to analyze image
classifiers that employ convolutional neural networks. Nowadays, some attacks
can deceive image- and video-quality metrics. So sustainability analysis of
these metrics is important. Indeed, if an attack can confuse the metric, an
attacker can easily increase quality scores. When developers of image- and
video-algorithms can boost their scores through detached processing, algorithm
comparisons are no longer fair. Inspired by the idea of universal adversarial
perturbation for classifiers, we suggest a new method to attack differentiable
no-reference quality metrics through universal perturbation. We applied this
method to seven no-reference image- and video-quality metrics (PaQ-2-PiQ,
Linearity, VSFA, MDTVSFA, KonCept512, Nima and SPAQ). For each one, we trained
a universal perturbation that increases the respective scores. We also propose
a method for assessing metric stability and identify the metrics that are the
most vulnerable and the most resistant to our attack. The existence of
successful universal perturbations appears to diminish the metric's ability to
provide reliable scores. We therefore recommend our proposed method as an
additional verification of metric reliability to complement traditional
subjective tests and benchmarks.","Videoquality assessment has always been an important task for processing and transmitting video over the Internet. But quality assessment using subjective evaluations is expensive and timeconsuming hence the creation of new quality assessment algorithms. Objective quality metrics are common in the development and comparison of image and videoprocessing algorithms. Depending on the original video‚Äôs availability, these metrics fall into three cate gories: fullreference (FR), reducedreference (RR) and noreference (NR). NR metrics are becoming more popular owing to greater applicability than FR and RR metrics, since in many reallife cases the reference video is unavailable. NR metrics are widely used for tasks ¬© 2022. The copyright of this document resides with its authors. It may be distributed unchanged freely in print or electronic forms.arXiv:2211.00366v1  [cs.CV]  1 Nov 20222 SHUMITSKAYA, ANTSIFEROVA, VATOLIN: UNIVERSAL ATTACK ON NR METRICS such as collecting contentquality statistics for realtime communication and streaming, in addition to optimizing image and videoprocessing parameters [17]. Stateoftheart NR metrics commonly use neuralnetworkbased approaches. They often deliver more accuracy than traditional approaches, but they are also more vulnerable to attacks that increase their output scores. Most videoprocessing algorithms, for example encoding, deblurring, denois ing and superresolution can optimize images or video frames in accordance with the given NR metric and increase the score. A traditional way to evaluate qualitymetric performance is subjective testing that is mea suring the correlation of metric scores with subjective scores for some dataset. But just checking the correlation is insufÔ¨Åcient for NR metrics. Estimating other parameters is im portant: for example, the ability to provide reliable scores that are immune to increases through detached processing. Metricscore reliability is crucial to comparing algorithms, but NR metrics are vulnerable to processing that increases the output score because for each im age or video, the direction of increasing scores depends only on this image or video (without reference image or video). In this paper, we analyze the vulnerability of new NR quality metrics to score increases by applying universal perturbation attacks. Our work deÔ¨Ånes universal perturbation as a Ô¨Åxed perturbation trained for a given NR quality metric to increase its scores when applied to images or videos (frame by frame). Figure 1 illustrates a universal perturbation attack on the NR metric PaQ2PiQ [20]. MoosaviDezfooli et al. [16] previously introduced uni versal adversarial perturbation as a Ô¨Åxed perturbation that can fool a convolutionalneural networkbased image classiÔ¨Åer. We employed a universal perturbation attack on seven dif ferentiable NR metrics, estimating their resistance to this attack using our proposed stabil ity score. Stabilityevaluation method works for any type of universal attacks that is when the same transformation is applied to all images or videos. It can also serve as comple mentary performance testing for quality metrics. We make our code publicly available at: https://github.com/katiashh/UAP_Attack_on_Quality_Metrics . Figure 1: Universal perturbation attack on the noreference quality metric PaQ2PiQ. 2 Related Work "
82,Inducing Predictive Uncertainty Estimation for Face Recognition.txt,"Knowing when an output can be trusted is critical for reliably using face
recognition systems. While there has been enormous effort in recent research on
improving face verification performance, understanding when a model's
predictions should or should not be trusted has received far less attention.
Our goal is to assign a confidence score for a face image that reflects its
quality in terms of recognizable information. To this end, we propose a method
for generating image quality training data automatically from 'mated-pairs' of
face images, and use the generated data to train a lightweight Predictive
Confidence Network, termed as PCNet, for estimating the confidence score of a
face image. We systematically evaluate the usefulness of PCNet with its error
versus reject performance, and demonstrate that it can be universally paired
with and improve the robustness of any verification model. We describe three
use cases on the public IJB-C face verification benchmark: (i) to improve 1:1
image-based verification error rates by rejecting low-quality face images; (ii)
to improve quality score based fusion performance on the 1:1 set-based
verification benchmark; and (iii) its use as a quality measure for selecting
high quality (unblurred, good lighting, more frontal) faces from a collection,
e.g. for automatic enrolment or display.","There has been tremendous progress in face recognition over the past ve years, primarily due to three factors: First , the development of neural network architec tures, from AlexNet [25], to VGGNet [33], to ResNet [20]; Second , the introduc tion of more sophiscticated objective functions, for instance, contrastive loss [11], triplet loss [38], largemargin softmax [27, 13]. Third , the largescale datasets, e.g.VGGFace [29], UMDFace [7], MS1M [19], VGGFace2 [9], IMDBFace [37], that have enabled the datahungry neural network models to be trained. With these eorts, stateoftheart face recognition models have demonstrated strong capabilities of learning eective identity embeddings, which are largely invari ant to nuance factors, such as pose and age, yet are still discriminative for face identities. In this paper our objective is face verication { the task of determining if two face images are of the same person or not; or, more generally, given two sets ofarXiv:2009.00603v1  [cs.CV]  1 Sep 20202 W. Xie et al. (a) Mated pair (similarity score 0.4) (b) Nonmated pair (similarity score 0.4) Predictive Condence = 0.13 Predictive Condence = 0.95 Fig. 1: A face verication model (ResNet101 trained on VGGFace2) gives similar output scores to both pairs, In (a), it refers to a false negative matching, where the low similarity score is most likely due to the inadequate information in the second image. In (b), the similarity score indicates that the identities are dierent in the pair of images. Predictive condence is required to decide whether to trust the output from the system or not. faces, where each set only contains arbitrary number of images from one person, determine if the two sets are of the same person or not. Verication, as is this case for any face recognition task, depends on the assumption that the input image contains sucient information to be recognizable. During the training stage, this assumption is usually guaranteed, largely due to the bias from the data collection process { that images have been curated by human annotators, and so must be recognizable. Unfortunately, this is not always the case during the inference stage, as the input face images to verication system may be in prole, blurry, or low resolution (or even nonface images if the face detector operating point is for very high recall). As a result, this traintest discrepancy will potentially lead to false positives or negatives during verication. For instance, as demonstrated in Figure 1, a welltrained face recognition model (ResNet101 in this case) is broken by one lowquality image. Conceptually, this challenge can be resolved by augmenting the similarity between the face embeddings with apredictive condence , which is identityagnostic, and only re ects whether the image contains sucient discriminative information to be recognizable. Estimating such condence scores is a non trivial task, as it is costly and chal lenging to obtain groundtruth annotations. Indeed, even dening image quality is dicult, despite the early eorts [1, 2] on measuring image quality by pose, expression, illumination, occlusion, and face accessories, some metrics remain ex tremely subjective. Furthermore, since classications can be changed by adding perturbations to images (adversarial attacks) that are indistinguishable to hu man observers [34, 15, 6, 31], human assessments of image quality may be only suboptimal for network training. In this paper, we propose a method for generating image quality training data automatically, and use the generated data to train a lightweight network to predict condences for any face image. The only requirement of the method is to have sets of images of the same person { and such sets are readily available from public face datasets that have identity annotation. Once the Predictive Condence Network, PCNet , has been trained, then it can be applied to anyInducing Predictive Uncertainty Estimation for Face Recognition 3 verication system and any face images. This method is described in Section 3. In Section 4, we systematically evaluate the usefulness of PCNet with error versus reject curves [18]. Experimentally, we demonstrate it can be universally paired with and improve the robustness of other recognition models, including strong models such as SENet50 and ResNet101, and that PCNet outperforms previous quality estimation baselines, while using a signicantly lighter archi tecture (ResNet18 vs ResNet50). We also demonstrate three use cases on the challenging JANUS IJBC Benchmark [28], (i) PCNet can be used to signi cantly improve 1:1 imagebased verication error rates, such as False Accept Rate (FAR), and True Accept Rate (TAR), of automatic face recognition sys tems by rejecting lowquality face images; (ii) it can be used for quality score based fusion where a weighted average is used to combine the descriptors of multiple images of the same face into a single descriptor, signicantly improve the performance on the 1:1 setbased verication benchmark; and (iii) it can also be used as a quality measure for selecting good (unblurred, good lighting, more frontal) faces from a collection, e.g.for automatic enrollment or display. 2 Related Work "
465,DeepReach: A Deep Learning Approach to High-Dimensional Reachability.txt,"Hamilton-Jacobi (HJ) reachability analysis is an important formal
verification method for guaranteeing performance and safety properties of
dynamical control systems. Its advantages include compatibility with general
nonlinear system dynamics, formal treatment of bounded disturbances, and the
ability to deal with state and input constraints. However, it involves solving
a PDE, whose computational and memory complexity scales exponentially with
respect to the number of state variables, limiting its direct use to
small-scale systems. We propose DeepReach, a method that leverages new
developments in sinusoidal networks to develop a neural PDE solver for
high-dimensional reachability problems. The computational requirements of
DeepReach do not scale directly with the state dimension, but rather with the
complexity of the underlying reachable tube. DeepReach achieves comparable
results to the state-of-the-art reachability methods, does not require any
explicit supervision for the PDE solution, can easily handle external
disturbances, adversarial inputs, and system constraints, and also provides a
safety controller for the system. We demonstrate DeepReach on a 9D
multi-vehicle collision problem, and a 10D narrow passage problem, motivated by
autonomous driving applications.","As autonomous systems are integrated in our daytoday lives, ensuring provable safety guarantees and controllers for these systems is vital. HamiltonJacobi (HJ) reachability analysis is a veriÔ¨Åcation method for autonomous systems that computes both the safe conÔ¨Ågurations and the corresponding safe controller for the system. In reachability analysis, one computes the Backward Reachable Tube (BRT) of a dynami cal system. This is the set of states such that the trajectories that start from this set will eventually reach some given target set despite the worst case disturbance (or an exogenous, adversarial input more generally). As an example, for an aerial vehicle, the disturbance could be wind or another adversarial aircraft Ô¨Çying nearby, and the target set could be the destination of the vehicle. The BRT provides both the set of states from which the aerial vehicle can safely reach its destination and a robust controller for the vehicle. Conversely, if the target set consists of those states that are known to be unsafe, the BRT represent the states from which the system will end up in the target set for some disturbance, despite the best possible control efforts. Thus, the BRT contains states which are potentially unsafe and should therefore be avoided. The converse of BRT in this case provides the set of safe states for the system and the corresponding safety controller. If the system additionally 1All authors are with the Department of Electrical Engineering and Computer Sciences, University of California, Berkeley: fsomil, tom ling@berkeley.edu. 2This research is supported by the DARPA Assured Autonomy program under agreement number FA875018C0101.needs to satisfy state dependent constraints at all times, then it is called a Backward ReachAvoid Tube (BRAT) instead of BRT. Traditionally, BRT computations in HJ reachability are formulated as a zerosum dynamic game between the control and the disturbance whose value function can be used to synthesize the BRT and the safety controller. This involves solving a HamiltonJacobi (HJ) partial differential equation (PDE) on a grid representing a discretization of the state space. Unfortunately, this process becomes computationally intensive for large systems, resulting in an exponential scal ing of memory and computational complexity with respect to system dimensionality; this is often referred to as the ‚Äú curse of dimensionality .‚Äù Several methods have been proposed to overcome this challenge by trading off between the class of dynamics they can handle, the approximation quality of the BRT, and the required computation. Additionally, very few of these approaches can handle adversarial inputs; yet, considering adversarial inputs (e.g., actions of other agents or the model and the environment uncertainty) and state constraints is critical in analysis and synthesis of safe controllers. In this work, we propose DeepReach, a deep learning based approach to approximately solve highdimensional reachability problems. What sets DeepReach apart is its ability to compute BRTs (and BRATs) as well as the corre sponding safety controller for general nonlinear dynamical systems in the presence of disturbances andstate and input constraints . DeepReach is rooted in HJ reachability analysis; however, instead of solving the value function PDE over a grid, DeepReach draws inspiration from the recent progress in solving PDEs using deep learning, and represents the value function as a deep neural network (DNN) to learn a parameterized approximation of the value function. Thus, the computation and memory requirements for obtaining the value function do not scale with the grid resolution, but rather the complexity of the value function. To overcome the challenges of obtaining the supervision data for learning the value function in highdimensional sys tems, we use a selfsupervision method for training the DNN. The key insight behind our method is that if we use a func tion approximator whose gradients are well behaved, then the PDE itself can be used to selfsupervise the learning of the value function. However, the widely popular ReLUbased ar chitectures, while promising, lack the capacity to effectively represent the gradients of a target signal. This is partly due to the fact that ReLU networks are piecewise linear, their Ô¨Årst derivative is piecewise constant, and therefore struggle when encoding a value function with Ô¨Åne details. To overcome thisarXiv:2011.02082v1  [cs.RO]  4 Nov 2020challenge, we use periodic, sinusoidal activation functions, that have recently shown a lot of promise in representing not only the underlying signal well, but also its derivatives [1]. This has two advantages: Ô¨Årst, it enables a selfsupervision method for computing the value function, allowing us to scale the proposed approach to general dynamical systems. Second, the safety controller depends on the gradients of the value function and has traditionally been hard to compute using approximate methods. With DeepReach, we can also compute the optimal safety control which is important in a variety of applications. We demonstrate the capabilities of DeepReach in computing BRTs and the safety controller for a variety of highdimensional reachability problems that arise in multivehicle collision mitigation and autonomous driving applications. II. R ELATED WORK "
208,Signature Verification using Geometrical Features and Artificial Neural Network Classifier.txt,"Signature verification has been one of the major researched areas in the
field of computer vision. Many financial and legal organizations use signature
verification as access control and authentication. Signature images are not
rich in texture; however, they have much vital geometrical information. Through
this work, we have proposed a signature verification methodology that is simple
yet effective. The technique presented in this paper harnesses the geometrical
features of a signature image like center, isolated points, connected
components, etc., and with the power of Artificial Neural Network (ANN)
classifier, classifies the signature image based on their geometrical features.
Publicly available dataset MCYT, BHSig260 (contains the image of two regional
languages Bengali and Hindi) has been used in this paper to test the
effectiveness of the proposed method. We have received a lower Equal Error Rate
(EER) on MCYT 100 dataset and higher accuracy on the BHSig260 dataset.","Biometric plays a vital role in the authentication of an individual in many Ô¨Ånancial institutions, and signatures are the most widely used modality for this purpose. Biometrics is used to identify or verify an individual digitally. The security ap plications that have been used in many Ô¨Ånancial and educational institutions using biometrics technology for decades [17]. Biometrics are classiÔ¨Åed into two categories: physiological and behavioral [13]. Physiological biometrics includes Face, Iris, Fin gerprint, etc. and behavioral biometrics has signature, gait, etc.. Authentication of the Anamika Jain Indian Institute of Information Technology Allahabad Email: rsi2016005@iiita.ac.in Satish Kumar Singh Email: sk.singh@iiita.ac.in Krishna Pratap Singh Email: kpsingh@iiita.ac.inarXiv:2108.02029v1  [cs.CV]  4 Aug 20212 Anamika Jain et al. signatures are carried out manually and highly dependent on the mood of the veriÔ¨Åer. Owing to its importance and unavailability of efÔ¨Åcient ofÔ¨Çine veriÔ¨Åcation methods, we have utilized signatures in this experiment [24] [21]. Depending upon the acqui sition process, signature biometric is categorized into two modes, online and ofÔ¨Çine. In online mode, signatures are collected using tablets, electronic pads and have auxil iary informations like angle, pressure, pen up/down, etc. On the other hand, in ofÔ¨Çine mode the signatures are acquired on the sheet of paper with writing instruments. Later these sheets are digitized using the scanner and cropped to the signature content [22]. These types of signature do not have any supportive information, and this makes the ofÔ¨Çine mode of the signature a challenging problem. Signatures are easy to spoof with some practice, and this makes them vulnerable to forgery. There are two signiÔ¨Å cant types of forgery reported in the literature, i.e., skilled and random forgery. In the skilled forgery, a person practices the genuine signature and tries to replicate it and in random forgery genuine signature of one user considered as the forged sample to the other signer. Fig. 1 Sample Images OfÔ¨Çine signature veriÔ¨Åcation can be performed using two methods static and dynamic [13]. Static approaches include geometric measurement, and dynamic ap proaches aim to estimate the information of the static image dynamically. Skillfully forged signatures have the same structure as the genuine signature, but the geometri cal features of both the images are quite different. The rest of the paper is divided into Ô¨Åve sections. Section II describes the state of the art method presented in the literature along with motivation of the proposed work. The proposed work and dataset used in this paper has described in section III. Section IV and V contain the experiment and results, respectively. In Section VI, conclusion and future work have been presented. 2 Related Work "
517,Improving Neural Network Verification through Spurious Region Guided Refinement.txt,"We propose a spurious region guided refinement approach for robustness
verification of deep neural networks. Our method starts with applying the
DeepPoly abstract domain to analyze the network. If the robustness property
cannot be verified, the result is inconclusive. Due to the over-approximation,
the computed region in the abstraction may be spurious in the sense that it
does not contain any true counterexample. Our goal is to identify such spurious
regions and use them to guide the abstraction refinement. The core idea is to
make use of the obtained constraints of the abstraction to infer new bounds for
the neurons. This is achieved by linear programming techniques. With the new
bounds, we iteratively apply DeepPoly, aiming to eliminate spurious regions. We
have implemented our approach in a prototypical tool DeepSRGR. Experimental
results show that a large amount of regions can be identified as spurious, and
as a result, the precision of DeepPoly can be significantly improved. As a side
contribution, we show that our approach can be applied to verify quantitative
robustness properties.","In recent years, deep neural networks (DNNs) have achieved e xceptional performance in many applications. They are often applied to perform task s which are particularly challenging for traditional logicbased software, e.g., n ature language processing [1], image classiÔ¨Åcation [22], and game playing [36]. Unfortuna tely, DNNs have also been shown to be often lack of robustness and vulnerable to advers arial samples [41], i.e., it is possible to add a small (and even imperceptible) pertur bation to a correctly clas siÔ¨Åed input so that it is misclassiÔ¨Åed by a welltrained DNN . This raises concerns on deploying DNNs in safetycritical applications like self driving cars [44], medical sys tems [35], and malware detection [25]. It is thus important t hat robustness of DNNs is veriÔ¨Åed before they are deployed in safetycritical domain s. In this work, we focus on (local) robustness, i.e., given an i nput and a manipula tion region around the input (which is usually speciÔ¨Åed acco rding to a certain norm), we verify that a given DNN never makes any mistake on any input in the region. The Ô¨Årst work on DNN veriÔ¨Åcation was published in [32], which foc uses on DNNs with2 P. Yang et al. sigmoid activation functions with a partitionreÔ¨Ånement a pproach. In 2017, Katz et al. [20] and Ehlers [10] independently implemented Reluple x and Planet, two SMT solvers to verify DNNs with the ReLU activation function on properties expressible with SMT constraints. Since 2018, abstract interpretation has been one of the most pop ular methods for DNN veriÔ¨Åcation in the lead of AI2[13], and subsequent works like [38,39,24,2,37,29] have improved AI2in terms of efÔ¨Åciency, precision and more acti vation functions (like sigmoid and tanh ) so that abstract interpretation based approach can be applied to DNNs of larger size and more complex structu res. Among the above methods, DeepPoly [39] is a most outstanding one regarding precision and scalability. DeepPoly is an abstract domain s pecially developed for DNN veriÔ¨Åcation. It sufÔ¨Åciently considers the structures and t he operators of a DNN , and it designs a polytope expression which not only Ô¨Åts for these structures and operators to control the loss of precision, but also works with a very sm all time overhead to achieve scalability. However, as an abstraction interpret ation based method, it provides very little insight if it fails to verify the property. In thi s work, we propose a method to improve DeepPoly by eliminating spurious regions throug h abstraction reÔ¨Ånement. A spurious region is a region computed using abstract semant ics, conjuncted with the negation of the property to be veriÔ¨Åed. This region is spurio us in the sense that if the property is satisÔ¨Åed, then this region, although not empty, does not contain any true counterexample which can be realized in the original progra m. In this case, we propose a reÔ¨Ånement strategy to rule out the spurious region, i.e., t o prove that this region does not contain any true counterexamples. Our approach is based on DeepPoly and improves it by reÔ¨Ånemen t of the spuri ous region through linear programming. The core idea is to in tersect the abstraction constructed by abstract interpretation with the negation o f the property to generate a spurious region, and perform linear programming on the cons traints of the spurious re gion so that the bounds of the ReLU neurons whose behaviors are uncertain can be tightened. As a result, some of these neurons can be determin ed to be deÔ¨Ånitely acti vated or deactivated, which signiÔ¨Åcantly improves the prec ision of the abstraction given by abstract interpretation. This procedure can be performe d iteratively and the precision of the abstraction are gradually improved, so that we are lik ely to rule out this spurious region in some iteration. If we successfully rule out all the possible spurious regions through such an iterative reÔ¨Ånement, the property is soundl y veriÔ¨Åed. Our method is similar in spirit to counterexample guided abstraction reÔ¨Å nement (CEGAR) [6], i.e., we apply abstract interpretation for abstraction and linea r programming for reÔ¨Ånement. A fundamental difference is that we use the constraints of th e spurious region, instead of a concrete counterexample (which is challenging to const ruct in our setting), as the guidance of reÔ¨Ånement. The same spurious region guided reÔ¨Ånement approach is also e ffective in quanti tative robustness veriÔ¨Åcation. Instead of requiring that a ll inputs in the region should be correctly classiÔ¨Åed, a certain probability of error in th e region is allowed. Quan titative robustness is more realistic and general compared to the ordinary robustness, and a DNN veriÔ¨Åed against quantitative robustness is useful in practice as well. The spurious region guided reÔ¨Ånement approach naturally Ô¨Åts fo r this setting, since a com paratively precise overapproximation of the spurious reg ion implies a sound robustnessImproving Neural Network VeriÔ¨Åcation through Spurious Reg ion Guided ReÔ¨Ånement 3 conÔ¨Ådence. To the best of our knowledge, this is the Ô¨Årst work to verify quantitative ro bustness with strict soundness guarantee, which distingui shes our approach from the previous sampling based methods like [47,48,3]. In summary, our main contributions are as follows: ‚ÄìWe propose spurious region guided reÔ¨Ånement to verify robus tness properties of deep neural networks. This approach signiÔ¨Åcantly improves the precision of Deep Poly and it can verify more challenging properties than Deep Poly. ‚ÄìWe implement the algorithms as a prototype and run them on net works trained on popular datasets like MNIST and ACAS Xu. The experimental re sults show that our approach signiÔ¨Åcantly improves the precision of DeepPoly i n successfully verifying much stronger robustness properties (larger maximum radiu s) and determining the behaviors of a great proportion of uncertain ReLU neurons. ‚ÄìWe apply our approach to solve quantitative robustness veri Ô¨Åcation problem with strict soundness guarantee. In the experiments, we observe that, comparing to using only DeepPoly, the bounds by our approach can be up to two orde rs of magnitudes better in the experiments. Organisations of the paper. We provide preliminaries in Section 2. DeepPoly is recalled in Section 3. We present our overall veriÔ¨Åcation framework a nd the algorithm in Sec tion 4, and discuss quantitative robustness veriÔ¨Åcation in Section 5. Section 6 evaluates our algorithms through experiments. Section 7 reviews rela ted work and concludes the paper. 2 Preliminaries In this section we recall some basic notions on deep neural ne tworks, local robustness veriÔ¨Åcation, and abstract interpretation. Given a vector x‚ààRn, we write xito denote itsith entry for 1‚â§i‚â§n. 2.1 Robustness veriÔ¨Åcation of deep neural networks In this work, we focus on deep feedforward neural networks (D NNs), which can be represented as a function f:Rm‚ÜíRn, mapping an input x‚ààRmto its output y= f(x)‚ààRn. A DNN foften classiÔ¨Åes an input xby obtaining the maximum dimension of the output, i.e., argmax 1‚â§i‚â§nf(x)i. We denote such a DNN by Cf:Rm‚ÜíC which is deÔ¨Åned by Cf(x) = argmax 1‚â§i‚â§nf(x)iwhereC={1,...,n}is the set of classiÔ¨Åcation classes. A DNN has a sequence of layers, including an input layer at the beginning, followed by several hidden layers, and an output layer in the end. The o utput of a layer is the input of the next layer. Each layer contains multiple neurons, the number of which is known as the dimension of the layer. The DNN fis the composition of the transformations between layers. Typically an afÔ¨Åne transformation followe d by a nonlinear activation function is performed. For an afÔ¨Åne transformation y=Ax+b, if the matrix Ais not sparse, we call such a layer fully connected. A DNN with only f ully connected layers and activation functions is a fully connected neural networ k (FNN). In this work, we4 P. Yang et al. focus on the rectiÔ¨Åed linear unit (ReLU) activation functio n, deÔ¨Åned as ReLU(x) = max(x,0)forx‚ààR. Typically, a DNN veriÔ¨Åcation problem is deÔ¨Åned as follows: DeÔ¨Ånition 1. Given a DNN f:Rm‚ÜíRn, a set of inputs X‚äÜRm, and a property P‚äÜRn, we need to determine whether f(X) :={f(x)|x‚ààX} ‚äÜPholds. Local robustness describes the stability of the behaviour o f a normal input under a perturbation. The range of input under this perturbation is the robustness region. For a DNNCf(x)which performs classiÔ¨Åcation tasks, a robustness property typically states thatCfoutputs the same class on the robustness region. There are various ways to deÔ¨Åne a robustness region, and one o f the most popular ways is to use the Lpnorm. For x‚ààRmand1‚â§p <‚àû, we deÔ¨Åne the Lpnorm of xto be/bardblx/bardblp= (/summationtextm i=1|xi|p)1 p,and itsL‚àûnorm/bardblx/bardbl‚àû= max 1‚â§i‚â§m|xi|.We write ¬ØBp(x,r) :={x‚Ä≤‚ààRm| /bardblx‚àíx‚Ä≤/bardblp‚â§r}to represent a (closed) Lpball forx‚ààRmand r >0, which is a neighbourhood of xas its robustness region. If we set X=¬ØBp(x,r) andP={y‚ààRn|argmax iyi=Cf(x)}in Def. 1, it is exactly the robustness veriÔ¨Åcation problem. Hereafter, we set p=‚àû. 2.2 Abstract interpretation for DNN veriÔ¨Åcation Abstract interpretation [7] is a static analysis method and it is aimed to Ô¨Ånd an over approximation of the semantics of programs so as to verify th eir correctness. Generally we have a function f:Rm‚ÜíRnrepresenting the concrete program, a set X‚äÜ Rmrepresenting the property that the input of the program sati sÔ¨Åes, and a set P‚äÜ Rnrepresenting the property to verify. The problem is to deter mine whether f(X)‚äÜ Pholds. However, if fandXare complex, it is difÔ¨Åcult to calculate f(X)and to determine whether f(X)‚äÜPholds. Abstract interpretation uses abstract domains and abstract transformations to overapproximate sets and functions so that an over approximation of the output can be obtained efÔ¨Åciently. Now we have a concrete domain C, which includes a set of inputs Xas one of its elements. To make computation efÔ¨Åcient, we need an abstract domainAto abstract the elements in the concrete domain. We assume that there is a par tial order ‚â§onCas well asA, which in our settings is the subset relation ‚äÜ. DeÔ¨Ånition 2. A pair of functions Œ±:C ‚Üí A andŒ≥:A ‚Üí C is a Galois connection, if for anya‚àà A andc‚àà C, we have Œ±(c)‚â§a‚áîc‚â§Œ≥(a). Intuitively, a Galois connection (Œ±,Œ≥)gives abstraction and concretization relations between two domains, respectively. Naturally a‚àà A is a sound abstraction of c‚àà Cif and only if c‚â§Œ≥(a). In abstract interpretation, it is important to choose a suit able abstract domain be cause it determines the efÔ¨Åciency and precision. In practic e, we use a certain type of constraints to represent the abstract elements in an abstra ct domain. Classical abstract domains for Euclid spaces include Box, Zonotope [14,15], an d Polyhedra [40]. Not only do we need abstract domains to overapproximate set s, but we are also required to adapt overapproximation to functions. Here we consider the lifting of the functionf:Rm‚ÜíRndeÔ¨Åned as Tf(X) :P(Rm)‚Üí P(Rn),Tf(X) :=f(X) =Improving Neural Network VeriÔ¨Åcation through Spurious Reg ion Guided ReÔ¨Ånement 5 {f(x)|x‚ààX}. Now we have an abstract domain Akfor thekdimension Euclid space and the corresponding concretization Œ≥, and a function T# f:Am‚Üí Anis a sound abstract transformer, if Tf‚ó¶Œ≥‚äÜŒ≥‚ó¶T# f. When we have a sound abstract X#‚àà A ofXand a sound abstract transformer T# f, we can use the concretization of T# f(X#)to overapproximate f(X)since we have f(X) =Tf(X)‚äÜTf(Œ≥(X#))‚äÜŒ≥‚ó¶T# f(X#). IfŒ≥‚ó¶T# f(X#)‚äÜP, the property P is successfully veriÔ¨Åed. Obviously, veriÔ¨Åcation through a bstract interpretation is sound but not complete. AI2[13] Ô¨Årst adopted abstract interpretation to verify DNNs, a nd many subsequent works like [38,39,24] focus on improving its efÔ¨Åciency and p recision through, e.g., deÔ¨Åning new abstract domains. As a deep neural network, the f unctionf:Rm‚ÜíRn can be regarded as a composition f=fl‚ó¶¬∑¬∑¬∑‚ó¶f1of itsl+1layers, where fjperforms the transformation between the jth and the (j+ 1) th layer, i.e. it can be a linear transformation, or a ReLU operation. If we choose Box, Zonotope, or Polyhedra as the abstract doma in, then for linear transformations and the ReLU function, their abstract transformers have been devel oped in [13]. After we have abstract transformers f# jfor these fj, we can conduct abstract interpretation layer by layer as f# l‚ó¶¬∑¬∑¬∑‚ó¶f# 1(X#). 3 A Brief Introduction to DeepPoly Our approach relies on the abstract domain DeepPoly [39], wh ich is the stateoftheart abstract domain for DNN veriÔ¨Åcation. It deÔ¨Ånes the abstract transformers of multiple activation functions and layers used in DNNs. The core idea o f DeepPoly is to give every variable an upper and a lower bound in the form of an afÔ¨Ån e expression using only variables that appear before it. It can express a polyhe dron globally. Moreover, experimentally, it often has better precision than Box and Z onotope domains. We denote the ndimensional DeepPoly abstract domain with An. Formally an ab stract element a‚àà Anis a tuple (a‚â§,a‚â•,l,u), wherea‚â§anda‚â•give theith variable xia lower bound and an upper bound, respectively, in the form of a linear combina tion of variables which appear before it, i.e./summationtexti‚àí1 k=1wkxk+w0, fori= 1,...,n , and l,u‚ààRngive the lower bound and upper bound of each variable, respec tively. The concretization of ais deÔ¨Åned as Œ≥(a) ={x‚ààRn|a‚â§ i‚â§xi‚â§a‚â• i, i= 1,...,n}. (1) The abstract domain Analso requests that its abstract elements ashould satisfy the invariantŒ≥(a)‚äÜ[l,u]. This invariant helps construct efÔ¨Åcient abstract transfo rmers. For an afÔ¨Åne transformation xi=/summationtexti‚àí1 k=1wkxk+w0, we seta‚â§ i=a‚â• i=/summationtexti‚àí1 k=1wkxk+ w0. By substituting the variables xjappearing in a‚â§ iwitha‚â§ jora‚â• jaccording to its co efÔ¨Åcient at most i‚àí1times, we can obtain a sound lower bound in the form of linear combination on input variables only, and lican be computed immediately from the range of input variables. A similar procedure also works for computing ui. For aReLU transformation xi= ReLU( xj), we consider two cases:6 P. Yang et al. DeepPolyconstraints building  LP solving renewing bounds  & ReLU behaviors abstraction refinementno ‚Äú  verified  ‚Äù yes  infeasible feasible  not terminating terminating‚Äú  unknown  ‚Äùnetwork property ¬∑ DeepPoly gerenating ¬∑ spurious region guided ¬∑ input & uncertain ReLU  ¬∑ guiding DeepPoly Fig. 1. Framework of spurious region guided reÔ¨Ånement ‚ÄìIflj‚â•0oruj‚â§0, thisReLU neuron is deÔ¨Ånitely activated ordeactivated , respectively. In this case, this ReLU transformation actually performs an afÔ¨Åne transformation, and thus its abstract transformer can be de Ô¨Åned as above. ‚ÄìIflj<0anduj>0, the behavior of this ReLU neuron is uncertain , and we need to overapproximate this relation with a linear upper/ lower bound. The best upper bound is a‚â• i=uj(xj‚àílj) uj‚àílj. For the lower bound, there are multiple choices a‚â§ i=ŒªxjwhereŒª‚àà[0,1]. We choose Œª‚àà {0,1}which minimizes the area of the constraints. Basically we have two abstraction modes here, corresponding to the two choices of Œª. Note that for a DNN with only ReLU as nonlinear operators, overapproximation oc curs only when there are uncertain ReLU neurons, which are overapproximated using a triangle. The key of improving the precision is thus to comp ute the bounds of the uncertain ReLU neurons as precisely as possible, and to determine the behav iors of the most uncertain ReLU neurons. DeepPoly also supports activation functions which are mono tonically increasing, convex on (‚àí‚àû,0]and concave on [0,+‚àû), like sigmoid and tanh , and it supports max pooling layers. Readers can refer to [39] for details. 4 Spurious Region Guided ReÔ¨Ånement We explain the main steps of our algorithm, as depicted in Fig . 1. For the input property and network, we Ô¨Årst employ DeepPoly as the initial step to co mputef#(X#). The concretization of f#(X#)is the conjunction of many linear inequities given in Eq. 1, and for the robustness property P, the negation ¬¨Pis the disjunction of several linear inequities ¬¨P=/logicalortext t/negationslash=Cf(x)(yCf(x)‚àíyt‚â§0). 1. We check whether f#(X#)‚à©#(yCf(x)‚àíyt‚â§0) =‚ä•holds for each t. In case of yes, it indicates that the label tcannot be classiÔ¨Åed, as it is dominatedImproving Neural Network VeriÔ¨Åcation through Spurious Reg ion Guided ReÔ¨Ånement 7 byCf(x). Otherwise, we have f#(X#)‚à©#¬¨P/ne}a‚äîionslash=‚ä•, we have the conjunction Œ≥(f#(X#))‚àß¬¨Pas a potential spurious region , which represents the intersection of the abstraction of the real semantics and the negation of t he property to verify. We call such a region spurious because if the property is satisÔ¨Å ed, then this region does not contain a true counterexample, i.e., a pair of input and o utput(x‚àó,y‚àó)such that y‚àó=f(x‚àó)andy‚àóviolates the property P. In this case, this region is spuriously constructed due to the abstraction of the real semantics, wh ere the counterexamples cannot be realized, and thus we aim to rule out the spurious re gion. 2. If no potential spurious region is found, our algorithm sa fely returns yes. 3. Assume now that we have a the potential spurious region. Th e core idea is to use the constraints of the spurious region to reÔ¨Åne this spuriou s region. Here a natural way to reÔ¨Åne the spurious region is linear programming, sinc e all the constraints here are linear inequities. If the linear programming is inf easible, it indicates that the region is spurious, and thus we can return an afÔ¨Årmative r esult. Otherwise, our reÔ¨Ånement will tighten the bounds of variables involved in t he DNN, especially the input variables and uncertain ReLU neurons, and these tightened bounds help further give a more precise abstraction. 4. As our approach is based on DeepPoly, similarly, we cannot guarantee complete ness. We set a threshold Nof the number of iterations as a simple termination condition. If the termination condition is not reached, we r un DeepPoly again, and return to the Ô¨Årst step. Below we give an example, illustrating how reÔ¨Ånement can hel p in robustness veri Ô¨Åcation. Example 1. Consider the network f(x) = ReLU/parenleftbigg/parenleftbigg1‚àí1 1 1/parenrightbigg x+/parenleftbigg0 2.5/parenrightbigg/parenrightbigg and the re gion¬ØB‚àû((0,0)T,1). The robustness property Phere isy2‚àíy1>0. We invoke Ô¨Årst DeepPoly: the lower bound of y2‚àíy1given by DeepPoly is ‚àí0.5. As a result, the robustness property cannot be veriÔ¨Åed directly. Fig. 2(a) s hows details of the example. We fail to verify the property in Example 1 because for the unc ertainReLU relation y1= ReLU( x3), the abstraction is imprecise, and the key to making the abst raction more precise here is to obtain as tight a bound as possible for x3. Example 2. We use the constraints in Fig. 2(a) and additionally the cons trainty2‚àíy1‚â§ 0(i.e.,¬¨P) as the input of linear programming. Our aim is to obtain a tig hter bound of the input neurons x1andx2, as well as the uncertain ReLU neuronx3, so the objective functions of the linear programming are minxiandmin‚àíxifori= 1,2,3. All the three neurons have a tighter bound after the linear programm ing (see the red part in Fig. 2(b)). Fig. 2(b) shows the running of DeepPoly under the se new bounds, where the input range and the abstraction of the uncertain ReLU neuron are both reÔ¨Åned. Now the lower bound of y2‚àíy1is0.25, so DeepPoly successfully veriÔ¨Åes the property. 4.1 Main algorithm Alg. 1 presents our algorithm. First we run abstract interpr etation to Ô¨Ånd the uncertain neurons and the spurious regions (Line 2‚Äì5). For each possib le spurious region, we have8 P. Yang et al. x1 x2x3 x4y1 y2u1= 1l1=‚àí1x1‚â§1x1‚â•‚àí1 u3= 2l3=‚àí2x3‚â§x1‚àíx2x3‚â•x1‚àíx2 u5= 2l5= 0y1‚â§0.5x3+1y1‚â•0 x2‚â•‚àí1 x2‚â§1 l2=‚àí1 u2= 1x4‚â•x1+x2+2.5 x4‚â§x1+x2+2.5 l4= 0.5 u4= 4.5y2‚â•x4 y2‚â§x4 l6= 0.5 u6= 4.5 (a)x1 x2x3 x4y1 y2u1= 0l1=‚àí1x1‚â§0x1‚â•‚àí1 x2‚â•‚àí1 x2‚â§‚àí0.667 l2=‚àí1 u2=‚àí0.667u3= 1l3=‚àí0.333x3‚â§x1‚àíx2x3‚â•x1‚àíx2 x4‚â•x1+x2+2.5 x4‚â§x1+x2+2.5 l4= 0.5 u4= 1.833u5= 1l5= 0y1‚â§0.75x3+0.25y1‚â•x3 y2‚â•x4 y2‚â§x4 l6= 0.5 u6= 1.833 (b)1 1 ‚àí1 1ReLU(x3) ReLU(x4)1 1 ‚àí1 1ReLU(x3) ReLU(x4) Fig. 2. Example 1 (left) and Example 2 (right): where the red parts ar e introduced through linear programming based reÔ¨Ånement and the blue parts are introduc ed by a second run of DeepPoly. awhile loop which iteratively reÔ¨Ånes the abstraction. In each iter ation we perform linear programming to renew the bounds of the input neurons and unce rtainReLU neurons; when we Ô¨Ånd that the bound of an uncertain ReLU neuron becomes deÔ¨Ånitely non negative or nonpositive, then the ReLU behavior of this neuron is renewed (Line 14‚Äì 20). We use them to guide abstract interpretation in the next step (Line 21‚Äì22). Here in Line 22, we make sure that during the abstract interpretatio n, the abstraction of previous uncertain neurons (namely the uncertain neurons before the linear programming step in the same iteration) compulsorily follows the new bounds and newReLU behaviors given by the current C‚â•0,C‚â§0,l, andu, where these bounds will not be renewed by abstract interpretation, and the concretization of Yis deÔ¨Åned as Œ≥(Y) ={x| ‚àÄi. Y‚â§ i‚â§xi‚â§Y‚â• i}‚à©[l,u]. (2) The while loop ends when (i) either we Ô¨Ånd that the spurious region is in feasible (Line 11, 24) and we proceed to reÔ¨Åne the next spurious region , with a label VeriÔ¨Åed True, (ii) or we reach the terminating condition and fail to r ule out this spurious region, in which case we return UNKNOWN. If every while loop ends with the label VeriÔ¨Åed True, we successfully rule out all the spurious regions and r eturn YES. An observation is that, if some spurious regions have been ruled out, we can a dd the constraints of their negation to make the current spurious region smaller so as to improve the precision (Line 9). Here we discuss the soundness of Alg. 1. We focus on the while loop and claim that it has the following loop invariant: Invariant 1 The abstract element Yoverapproximates the intersection of the seman tics offon¬ØB‚àû(x,r)and the spurious region, i.e., f(¬ØB‚àû(x,r))‚à©Spu‚äÜŒ≥(Y). The initialization of Yisf#(¬ØB‚àû(x,r))and it is naturally an overapproximation. The box Xis obtained by linear programming on Y‚àßSpu, andf#(X)is calcu lated through abstract interpretation and the bounds given by linear programming onImproving Neural Network VeriÔ¨Åcation through Spurious Reg ion Guided ReÔ¨Ånement 9 Algorithm 1 Spurious region guided robustness veriÔ¨Åcation Input: DNNf, inputx, radiusr. Output: Return ‚ÄúYES‚Äù if veriÔ¨Åed, or ‚ÄúUNKNOWN‚Äù otherwise. 1:function VERIFY (f,x,r) 2:Y0‚Üêf#(¬ØB‚àû(x,r)) ‚ä≤abstract interpretation with DeepPoly 3:Vu‚Üê{v|vwas marked as uncertain in Line 2 } 4:A={t|Y0‚à©#(yCf(x)‚àíyt‚â§0)/\e}atio\slash=‚ä•} 5: ifA=‚àÖthen return YES ‚ä≤otherwise A={t1,...,t l} 6: fori‚Üê1toldo 7: VeriÔ¨Åed‚ÜêFalse,V‚ÜêVu,Y‚ÜêY0 ‚ä≤denoteY= (Y‚â§,Y‚â•,l,u) 8: C‚â•0‚Üê‚àÖ,C‚â§0‚Üê‚àÖ ‚ä≤set of new activated/deactivated neurons 9: Spu‚Üê(yCf(x)‚àíyti‚â§0)‚àß/logicalandtexti‚àí1 j=1(yCf(x)‚àíytj‚â•0) ‚ä≤spurious region 10: while terminating condition not satisÔ¨Åed do 11: ifY‚àßSpu is infeasible then 12: VeriÔ¨Åed ‚ÜêTrue 13: break 14: forv‚ààV‚à™V0do ‚ä≤V0: set of input neurons 15: (lv,uv)‚ÜêLP(Y‚àßSpu,v) 16: forv‚ààVdo 17: iflv‚â•0then 18: C‚â•0‚ÜêC‚â•0‚à™{v},V‚ÜêV\{v} 19: else ifuv‚â§0then 20: C‚â§0‚ÜêC‚â§0‚à™{v},V‚ÜêV\{v} 21: X‚Üê/intersectiontext v‚ààV0{lv‚â§v‚â§uv} 22: Y‚Üêf#(X)according to C‚â•0,C‚â§0,l, andu 23: V‚Üê{v|vwas marked as uncertain in Line 22 }\(C‚â•0‚à™C‚â§0) 24: ifY‚à©#(yCf(x)‚àíyti‚â§0) =‚ä•then 25: VeriÔ¨Åed ‚ÜêTrue 26: break 27: ifVeriÔ¨Åed=False then return UNKNOWN 28: return YES Y‚àßSpu, and thus it remains an overapproximation. It is worth ment ioning that, when we run DeepPoly in Line 22, we are using the bounds obtained by linear programming to guide DeepPoly, and this may violate the invariant Œ≥(a)‚äÜ[l,u]mentioned in Sect. 3. Nonotheless, soundness still holds since the concretizati on ofYis newly deÔ¨Åned in Eq. 2, where both items in the intersection overapproximat ef(¬ØB‚àû(x,r))‚à©Spu. With Invarient 1, Alg. 1 returns YES if for any possible spurious r egionSpu, the over approximation of f(¬ØB‚àû(x,r))‚à©Spu is infeasible, which implies the soundness of Alg. 1. 4.2 Iterative reÔ¨Ånement of the spurious region Here we present more theoretical insight on the iterative re Ô¨Ånement of the spurious region. An iteration of the while loop in Alg. 1 can be represented as a function L:A ‚Üí10 P. Yang et al. A, whereAis the DeepPoly domain. An interesting observation is that, the abstract transformer f#in the DeepPoly domain is not necessarily increasing, becau se different input ranges, even if they have inclusion relation, may lead to different choices of the abstraction mode of some uncertain ReLU neurons, which may violate the inclusion relation of abstraction. We have found such examples during our experiment, which is illustrated in the following example. Example 3. Letf(x) = ReLU( x)with input ranges I1= [‚àí2,1]andI2= [‚àí2,3]. We havef#(I1) ={(x1,x2)T‚ààR2| ‚àí2‚â§x1‚â§1, x2‚â•0, x2‚â§1 3x1+2 3}and f#(I2) ={(x1,x2)T‚ààR2| ‚àí2‚â§x1‚â§3, x2‚â•x1, x2‚â§3 5x1+6 5}. We observe (1,0)T‚ààf#(I1)but(1,0)T/‚ààf#(I2), which implies that the transformer f#is not increasing. This fact also implies that Lis not necessarily increasing, which violates the conditio n of Kleene‚Äôs Theorem on Ô¨Åxed point [4]. Now we turn to the analysis of the sequence {Yk=Lk(f#(¬ØB‚àû(x,r)))}‚àû k=1, where L1:=LandLk:=L ‚ó¶Lk‚àí1fork‚â•2. First we have the following lemma showing that in our settings every decreasing chain Sin the DeepPoly domain Ahas a meet/intersectiontext#S‚àà A. Lemma 1. LetAnbe thendimensional DeepPoly domain and {a(k)} ‚äÜ A na de creasing bounded sequence of nonempty abstract elements. If the coefÔ¨Åcients in a(k),‚â§ i anda(k),‚â• i are uniformly bounded, then there exists an abstract elemen ta‚àó‚àà Ans.t. Œ≥(a‚àó) =/intersectiontext‚àû k=1Œ≥(a(k)). Remark: The condition that the coefÔ¨Åcients in a(k),‚â§ i anda(k),‚â• i are uniformly bounded are naturally satisÔ¨Åed in our setting, since in a DNN the coef Ô¨Åcients and bounds in volved have only Ô¨Ånitely many values. Readers can refer to Ap pendix for a formal proof. Lemma 1 implies that if our sequence {Yk}is decreasing, then the iterative reÔ¨Åne ment converges to an abstract element in DeepPoly, which is t he greatest Ô¨Åxed point of Lthat is smaller than f#(¬ØB‚àû(x,r)). A sufÔ¨Åcient condition for {Yk}being decreasing is that during the abstract interpretation in every Yk, every initial uncertain neuron main tains its abstraction mode, i.e. its corresponding Œªdoes not change, before its ReLU behavior is determined. A weaker sufÔ¨Åcient condition for co nvergence is that change in abstraction mode of uncertain neurons never happens after Ô¨Å nitely many iterations. If the abstraction mode of uncertain neurons changes inÔ¨Ånit ely often, generally the sequence {Yk}does not converge. In this case, we can consider its subseque nce in which every Ykis obtained with the same abstraction mode. It is easy to see t hat such a subsequence must be decreasing and thus have a meet, as it is an accumulative point of the sequence {Yk}. Since there are only Ô¨Ånitely many choices of abstraction mo des, such a accumulative points exists in {Yk}, and there are only Ô¨Ånitely many accumu lative points. We conclude these results in the following th eorem which describes the convergence behavior of our iterative reÔ¨Ånement of the spur ious region:Improving Neural Network VeriÔ¨Åcation through Spurious Reg ion Guided ReÔ¨Ånement 11 Theorem 2. There exists a subsequence {Ynk}of{Yk}s.t.{Ynk}is decreasing and thus has a meet/intersectiontext#{Ynk}. Moreover, the set /braceleftBig/intersectiondisplay#{Ynk} | {Ynk}is a decreasing subsequence of {Yk}/bracerightBig is Ô¨Ånite, and it is a singleton if exact one abstraction mode o f uncertain ReLU neurons happens inÔ¨Ånitely often. Proof. Since the abstraction modes of uncertain ReLU neurons have only Ô¨Ånitely many choices, there must be one which happens inÔ¨Ånitely often in t he computation of the sequence {Yk}, and we choose the subsequence {Ynk}in which every item is computed through this abstraction mode. Obviously {Ynk}is decreasing and thus has a meet. For a decreasing subsequence {Ynk}, we can Ô¨Ånd its subsequnce in which the ab straction mode of uncertain ReLU neurons does not change, and they have the same meet. Since there are only Ô¨Ånitely many choices of abstracti on modes of uncertain ReLU neurons, such accumulative points of {Yk}also have Ô¨Ånitely many values. If exact one abstraction mode of uncertain ReLU neurons happens inÔ¨Ånitely often, obvi ously there is only one accumulative point in {Yk}. ‚äì ‚äî 4.3 Optimizations In the implementation of our main algorithm, we propose the f ollowing optimizations to improve the precision of reÔ¨Ånement. Optimization 1: More precise constraints in linear program ming. In Line 15 of Alg. 1, it is not the best choice to take the linear constraints in the abstract element Yinto linear programming, because the abstraction of uncertain ReLU neurons in DeepPoly is not the best. Planet [10] has a component which gives a more preci se linear approximation for uncertain ReLU relations, where it uses the linear constraints y‚â§u(x‚àíl) u‚àíl, y‚â• x, y‚â•0to overapproximate the relation y= ReLU( x)withx‚àà[l,u]. Optimization 2: A better choice of the spurious region. If a true counterexample exists, there must exist an input x‚Ä≤‚àà¬ØB‚àû(x,r)s.t.Cf(x),t‚ààargmax if(x‚Ä≤)iwith some t/ne}a‚äîionslash=Cf(x)sincefis continuous and ¬ØB‚àû(x,r)is convex. That is to say, yCf(x)=yt is a necessary condition for the existence of a true countere xample, and we can choose (yCf(x)‚àíyti= 0)‚àß/logicalandtexti‚àí1 j=1(yCf(x)‚àíytj‚â•0)as the spurious region in Line 9 of Alg. 1. This optimization makes the spurious region even smaller an d beneÔ¨Åts the precision improvement. Optimization 3: Priority to work on small spurious regions. In Line 6 of Alg. 1,we determine the order of reÔ¨Åning the spurious regions based on their sizes, i.e., a smaller region is chosen earlier. This is based on the intuition that Alg. 1 works effectively if the spurious region is small. After the small spurious regions a re ruled out, the constraints of large spurious regions can be tightened with the conjunctio n/logicalandtexti‚àí1 j=1(yCf(x)‚àíytj‚â•0). It is difÔ¨Åcult to strictly determine which spurious region i s the smallest, and thus we refer to the lower bound of yCf(x)‚àíytigiven by DeepPoly, i.e., the larger this lower12 P. Yang et al. bound is, the smaller the spurious region is likely to be, and we perform the forloop in Line 6 of Alg. 1 in this order. It is worth mentioning that, thi s optimization still makes sense even if we already adopt Optimization 2, since intuiti vely a larger spurious region (yCf(x)‚àíyti‚â§0)‚àß/logicalandtexti‚àí1 j=1(yCf(x)‚àíytj‚â•0)is more likely to have a larger boundary (yCf(x)‚àíyti= 0)‚àß/logicalandtexti‚àí1 j=1(yCf(x)‚àíytj‚â•0). 5 Quantitative Robustness VeriÔ¨Åcation In this section we recall the notion of quantitative robustn ess and show how to verify a quantitative robustness property of a DNN with spurious reg ion guided reÔ¨Ånement. In practice, we may not need a strict condition of robustness to ensure that an input x is not an adversarial example. A notion of mutation testing i s proposed in [46,45], which requires that an input xis normal if it has a low label change rate on its neighbourhood. They follow a statistical way to estimate the label change ra te of an input, which moti vates us to give a formal deÔ¨Ånition of the property showing a l ow label change rate, and to consider the veriÔ¨Åcation problem for such a property. Bel ow we recall the deÔ¨Ånition ofquantitative robustness [28], where we have a parameter 0< Œ∑‚â§1representing the conÔ¨Ådence of robustness. DeÔ¨Ånition 3. Given a DNN Cf:Rm‚ÜíC, an input x‚ààRm,r >0,0< Œ∑‚â§1, and a probability measure ¬µon¬ØB‚àû(x,r),fisŒ∑robust at x, if ¬µ({x‚Ä≤‚àà¬ØB‚àû(x,r)|Cf(x‚Ä≤) =Cf(x)})‚â•Œ∑. Def. 3 has a tight association with label change rate, i.e., i fxisŒ∑robust, then the label change rate should be larger than, or close to 1‚àíŒ∑. Hereafter, we set ¬µto be the uniform distribution on ¬ØB‚àû(x,r). It is natural to adapt spurious region guided reÔ¨Ånement to qu antitative robustness veriÔ¨Åcation. In Alg. 1, we do not return UNKNOWN when we canno t rule out a spurious region, but record the volume of the box Xas an overapproximation of the Lebesgue measure of the spurious region. After we work on all the spuri ous regions, we calculate the sum of these volume, and obtain a sound robustness conÔ¨Åde nce. Here we do not calculate the volume of the spurious region because precise calculation of volume of a highdimensional polytope remains open, and we do not choo se to use randomized algorithms because it may not be sound. We further improve the algorithm through the powerset techn ique [13]. Powerset technique is a classical and effective way to enhance the pre cision of abstract interpre tation. Basically we split the input region into several sub sets, and run abstract inter pretation on these subsets, In our quantitative robustness veriÔ¨Åcation setting, powerset technique not only improves the precision, but also acceler ates the algorithm in some situations: If the subsets have the same volume, and the perc entage of the subsets on which we may fail to verify robustness is already smaller tha n1‚àíŒ∑, then we have successfully veriÔ¨Åed the Œ∑robustness property.Improving Neural Network VeriÔ¨Åcation through Spurious Reg ion Guided ReÔ¨Ånement 13 6 Experimental Evaluation We implement our approach as a prototype called DeepSRGR. Th e implementation is based on a reimplementation of the ReLU and the afÔ¨Åne abst ract transformers of DeepPoly in Python 3.7 and we amend it accordingly to impleme nt Alg. 1. We use CVXPY [8] as our modeling language for convex optimization p roblems and CBC [18] as the LP solver. It is worth mentioning that we ignore the Ô¨Çoa ting point error in our reimplementation of DeepPoly because sound linear progra mming currently does not scale in our experiments. In the terminating condition, we s etN= 5. All the exper iments adopt Optimization 1 and Optimization 3 in Sect. 4.3. All the experiments are conducted on a CentOS 7.7 server with 16 Intel Xeon Plwatinum 8153 @2.00GHz (16 cores) and 512G RAM, and they use 96 subprocesses concurren tly at most. Readers can Ô¨Ånd all the source code and other experimental materials inhttps://github.com/CASLRJ/RefineRobustness . Datasets. We use MNIST [23] and ACAS Xu [12,17] as the datasets in our exp eri ments. MNIST contains 60000 grayscale handwritten digits of the size 28√ó28. We can train DNNs to classify the images by the written digits on the m. The ACAS Xu system is aimed to avoid airborne collisions for unmanned aircraft s and it uses an observation table to make decisions for the aircraft. In [19], the observ ation table is realized by training DNNs instead of storing it. Networks. On MNIST, we trained seven fully connected networks of the si ze6√ó20, 3√ó50,3√ó100,6√ó100,6√ó200,9√ó200, and6√ó500, wherem√ónrefersm hidden layers and nneurons in each hidden layer, and we name them from FNN2 to FNN8, respectively (we also have a small network FNN1 for tes ting). On ACAS Xu, we randomly choose three networks used in [20], all of the siz e5√ó50. 6.1 Improvement in precision First we compare DeepPoly and DeepSRGR in terms of their prec ision of robustness veriÔ¨Åcation. We consider the following two indices: (i) the maximum radius that the two tools can verify, and (ii) the number of uncertain ReLU neurons whose behaviors can be further determined by DeepSRGR. We randomly choose three im ages from the MNIST dataset, and calculate their maximum radius that the two too ls can verify through a bi nary search on the seven FNNs we trained. We also record the nu mber of the uncertain ReLU neurons whose behaviors are renewed to deÔ¨Ånitely activated /deactivated on the maximum radius of DeepSRGR. We do not adopt Optimization 2 in Sect. 4.3 in this experiment because Optimization 2 cannot be used in quantit ative robustness veriÔ¨Åca tion, and we suppose that the evaluation of precision in this experiment holds for both veriÔ¨Åcation tasks. Table 1 shows the results. We can see from the table that DeepS RGR can verify stronger (i.e., larger maximum radius) robustness propert ies than DeepPoly, and deter mine behaviors of a large proportion of uncertain ReLU neurons even on these most challenging properties. The average number of iterations f or ruling out a spurious re gion is around or below 3in all the running examples, and more than half of the spuriou s regions can be ruled out within 2iterations.14 P. Yang et al. Maximum radius # spurious regions# uncertain ReLU % renewed # iterations DeepPoly DeepSRGR Original Renewed MAX A VG MAX GT 0.034 0.047 6 51 38 74.5% 48.4% 5 17 FNN2 0.017 0.023 3 47 37 78.7% 51.8% 4 9 0.017 0.023 1 34 25 73.5% 73.5% 4 4 0.049 0.066 6 88 69 78.4% 60.9% 5 15 FNN3 0.025 0.033 7 94 85 90.4% 46.0% 5 18 0.045 0.058 3 98 45 45.1% 27.2% 5 9 0.045 0.060 6 180 102 56.7% 35.2% 5 19 FNN4 0.024 0.030 6 199 144 72.4% 36.5% 4 15 0.035 0.046 2 155 103 66.5% 42.9% 5 7 0.034 0.042 7 305 245 80.3% 37.8% 5 20 FNN5 0.016 0.019 5 315 204 64.8% 34.0% 4 14 0.021 0.027 7 337 256 76.0% 34.9% 5 18 0.022 0.026 7 683 271 39.7% 19.8% 4 18 FNN6 0.011 0.013 6 657 483 73.5% 36.7% 3 14 0.021 0.025 8 723 169 23.4% 12.2% 5 21 0.021 0.023 9 987 297 30.1% 10.0% 5 29 FNN7 0.010 0.011 5 877 648 73.9% 26.8% 3 11 0.017 0.019 7 913 352 38.6% 24.3% 3 16 0.037 0.044 9 1 504 976 64.9% 45.9% 5 36 FNN8 0.020 0.022 9 1 213 818 67.4% 33.3% 3 21 0.033 0.040 9 1 371 1 269 92.6% 51.1% 5 37 Table 1. Maximum radius which can be veriÔ¨Åed by DeepPoly and DeepSRGR , and details of DeepSRGR running on its maximum radius, where in the number o f renewed uncertain nuerons, we show the largest one among the spurious regions. 6.2 Robustness veriÔ¨Åcation performance We further evaluate our tool DeepSRGR by verifying more chal lenging robustness properties. We randomly choose 50samples from the MNIST dataset. On FNN4, FNN5, FNN6, and FNN7, we Ô¨Åx four radii, 0.037,0.026,0.021, and0.015, for the four net works respectively, and verify the robustness property wit h the corresponding radius on the50inputs. The radius chosen here is very challenging for the co rresponding network. We adopt Optimization 2 in Sect. 4.3 in this experiment. Table 2 presents the results. DeepSRGR works signiÔ¨Åcantly b etter than DeepPoly in verifying these properties. Linear programming in DeepS RGR takes a large amount of time in the experiment, and thus DeepSRGR is less efÔ¨Åcient . Furthermore, we again run the 15running examples which is not veriÔ¨Åed by Deep SRGR on FNN4. This time we change the maximum number of iterat ions to20and50, and obtain the following interesting observations: ‚ÄìTwo more properties (out of 15) are successfully veriÔ¨Åed when we change Nto20. No more properties can be veriÔ¨Åed even if we change Nfrom20to50. ‚ÄìIn this experiments, 13more spurious regions are ruled out, six of which takes 6iterations, one takes 7, two takes 8, and the other four takes 13,22,27, andImproving Neural Network VeriÔ¨Åcation through Spurious Reg ion Guided ReÔ¨Ånement 15 Model Size Radius# veriÔ¨Åed Time (s) DeepPoly DeepSRGR MAX A VG FNN4 3√ó100 0.037 14 35 3 384 781 FNN5 6√ó100 0.026 19 31 7 508 1 689 FNN6 6√ó200 0.021 14 25 23 157 6 178 FNN7 9√ó200 0.015 25 36 61 760 8 960 Table 2. The number that DeepPoly and DeepSRGR veriÔ¨Åes among the 50inputs, and the maxi mum/average running time of DeepSRGR. 40  20  060 120 100 80 140160# Renewed  ReLU  Running Examples in the last iteration  in the whole loop  Fig. 3. Number of renewed ReLU behaviors in the spurious regions newly ruled out. 32iterations. In these running examples, the average number o f renewed ReLU behaviors is 102.8, and a large proportion are renewed in the last iteration ( 47.4% on average). Fig. 3 shows the detailed results. ‚ÄìAs for the 13spurious regions which cannot be ruled out within 50iterations, the average number of renewed ReLU behaviors is only 8.54, which is signiÔ¨Åcantly lower than the average of the 13spurious regions which are newly ruled out. In these running examples, changes in ReLU behaviors and ReLU abstraction modes do not happen after the 9th iteration, and the average number is4.4. We observe that, by increasing the termination threshold Nfrom5to50, only two more properties out of 15can be veriÔ¨Åed additionally. This suggests that our method can effectively identify these spurious regions which are r elevant to veriÔ¨Åcation of the property, in a small number of iterations. 6.3 Quantitative robustness veriÔ¨Åcation on ACAS Xu network s We evaluate DeepSRGR for quantitative robustness veriÔ¨Åcat ion on ACAS Xu networks. We randomly choose Ô¨Åve inputs, and compute the maximum robus tness radius for each16 P. Yang et al. 10 40 30 20 0 50 60 70 80 90 10010 40  30  20  050 60 70 0.02 0.03 0.04 0.05 0.06VERIFICATION RADII DeepPoly over approximation of 1Œ∑(%)Robustness Confidenc eDeepSRGR  √ó  √ó Fig. 4. Quantitative robustness veriÔ¨Åcation using DeepPoly and De epSRGR input on the three networks with DeepPoly through a binary se arch. In our experiment, the radius for a running example is the maximum robustness ra dius plus 0.02,0.03, 0.04,0.05, and0.06. We use the powerset technique and the number of splits is 32. For DeepPoly, the robustness conÔ¨Ådence it gives is the proporti on of the splits on which DeepPoly veriÔ¨Åes the property. Fig. 4 shows the results. We can see that DeepSRGR gives signi Ô¨Åcantly better over approximation of 1‚àíŒ∑than DeepPoly. That is, in more than 90% running examples, our overapproximation is no more than one half of that given by DeepPoly, and in more than 75%, our overapproximation is even smaller than one tenth of th at given by DeepPoly. 7 Related Works and Conclusion "
9,Towards Natural Robustness Against Adversarial Examples.txt,"Recent studies have shown that deep neural networks are vulnerable to
adversarial examples, but most of the methods proposed to defense adversarial
examples cannot solve this problem fundamentally. In this paper, we
theoretically prove that there is an upper bound for neural networks with
identity mappings to constrain the error caused by adversarial noises. However,
in actual computations, this kind of neural network no longer holds any upper
bound and is therefore susceptible to adversarial examples. Following similar
procedures, we explain why adversarial examples can fool other deep neural
networks with skip connections. Furthermore, we demonstrate that a new family
of deep neural networks called Neural ODEs (Chen et al., 2018) holds a weaker
upper bound. This weaker upper bound prevents the amount of change in the
result from being too large. Thus, Neural ODEs have natural robustness against
adversarial examples. We evaluate the performance of Neural ODEs compared with
ResNet under three white-box adversarial attacks (FGSM, PGD, DI2-FGSM) and one
black-box adversarial attack (Boundary Attack). Finally, we show that the
natural robustness of Neural ODEs is even better than the robustness of neural
networks that are trained with adversarial training methods, such as TRADES and
YOPO.","Deep neural networks have made great progress in numerous domains of machine learning, espe cially in computer vision. But Szegedy et al. (2013) found that most of the existing stateofthe art neural networks are easily fooled by adversarial examples that generated by putting only very small perturbations to the input images. Since realizing the unstability of deep neural networks, re searchers have proposed different kinds of methods to defense adversarial examples, such as adver sarial training (Goodfellow et al., 2014), data compression (Dziugaite et al., 2016), and distillation defense (Papernot et al., 2016). But each of these methods is a remedy for the original problem, and none of these methods can solve it fundamentally. For example, MoosaviDezfooli et al. (2016) showed that no matter how much adversarial examples are added to training sets, there are new adversarial examples that can successfully attack the adversarial trained deep neural network. So, avoiding adversarial examples technically cannot solve the most essential problem: why such subtle change in adversarial examples can beat deep neural networks? Meanwhile, it leads to a more important question: how to make deep neural networks have natural robustness so that they can get rid of malicious adversarial examples. Early explanations for adversarial examples considered that a smoothness prior is typically valid for kernel methods that imperceptibly tiny perturbations of a given image do not normally change the underlying class, while the smoothness assumption does not hold for deep neural networks due to its high nonlinearity (Szegedy et al., 2013). This analysis underlies plain deep neural networks like Use footnote for providing further information about author (webpage, alternative address)‚Äî notfor ac knowledging funding agencies. Funding acknowledgements go at the end of the paper. 1arXiv:2012.02452v1  [cs.LG]  4 Dec 2020AlexNet (Krizhevsky et al., 2012). But later than that, Goodfellow et al. (2014) claim adversarial examples are a result of models being too linear rather than too nonlinear, they can be explained as a property of highdimensional dot products. Unfortunately, both of these explanations seem to imply that adversarial examples are inevitable for deep neural networks. On the other hand, we notice that skip connections are widely used in current deep neural networks after the appearance of Highway Network (Srivastava et al., 2015) and ResNet (He et al., 2016). It turns out that the identity mapping in ResNet is formally equivalent to one step of Euler‚Äôs method which has been used to solve ordinary differential equations (Weinan, 2017). More than that, other kinds of skip connections used by different network architectures can be considered as different numerical methods for solving ordinary differential equations. The link between numerical ordinary differential equations with deep neural networks can bring us a whole new perspective to explain adversarial examples through the numerical stability analysis. In this paper, we attempt to utilize the natural property of neural networks to defense adversarial ex amples. We Ô¨Årst analyze how adversarial examples affect the output of neural networks with identity mappings, obtain an upper bound for this kind of neural networks, and Ô¨Ånd that this upper bound is impractical in actual computations. In the same way, we Ô¨Ågure out why adversarial examples can fool commonly used deep neural networks with skip connections. Then, we demonstrate that Neural ODEs hold a weaker upper bound and verify the natural robustness of Neural ODEs under four types of perturbations. Finally, we compare Neural ODEs with three types of adversarial training methods to show that the natural robustness of Neural ODEs is better than the robustness of neural networks that are trained with adversarial training. The main contributions of our work are as follows: ‚Ä¢ We introduce and formalize the numerical stability analysis for deep neural networks with identity mappings, prove that there is an upper bound for neural networks with identity mappings to constrain the error caused by adversarial noises. ‚Ä¢ We provide a new reason why commonly used deep neural networks with skip connections cannot resist adversarial examples. ‚Ä¢ We demonstrate that Neural ODEs hold a weaker upper bound which limits the amount of change in the result from being too large. Compare with ResNet and three types of adversarial training methods, we show the natural robustness of Neural ODEs. 2 R ELATED WORKS "
237,Unconstrained Still_Video-Based Face Verification with Deep Convolutional Neural Networks.txt,"Over the last five years, methods based on Deep Convolutional Neural Networks
(DCNNs) have shown impressive performance improvements for object detection and
recognition problems. This has been made possible due to the availability of
large annotated datasets, a better understanding of the non-linear mapping
between input images and class labels as well as the affordability of GPUs. In
this paper, we present the design details of a deep learning system for
unconstrained face recognition, including modules for face detection,
association, alignment and face verification. The quantitative performance
evaluation is conducted using the IARPA Janus Benchmark A (IJB-A), the JANUS
Challenge Set 2 (JANUS CS2), and the LFW dataset. The IJB-A dataset includes
real-world unconstrained faces of 500 subjects with significant pose and
illumination variations which are much harder than the Labeled Faces in the
Wild (LFW) and Youtube Face (YTF) datasets. JANUS CS2 is the extended version
of IJB-A which contains not only all the images/frames of IJB-A but also
includes the original videos for evaluating the video-based face verification
system. Some open issues regarding DCNNs for face verification problems are
then discussed.","Face verication is a challenging problem in computer vision and has been actively researched for over two decades [104]. In face verication, given two videos or images, the objective is to determine whether they be long to the same person. Many algorithms have been shown to work well on images and videos that are col lected in controlled settings. However, the performance of these algorithms often degrades signicantly on im ages that have large variations in pose, illumination, expression, aging, and occlusion. In addition, for an automated face verication system to be eective, it also needs to handle errors that are introduced by al gorithms for automatic face detection, face association, and facial landmark detection. Existing methods have focused on learning robust and discriminative representations from face images and videos. One approach is to extract an overcomplete and highdimensional feature representation followed by a learned metric to project the feature vector onto a lowdimensional space and then compute the similarity scores. For example, highdimensional multiscale local binary pattern (LBP) [16] features extracted from lo cal patches around facial landmarks and Fisher vector (FV) [79,19] features have been shown to be eective for face recognition. Despite signicant progress, the performance of these systems has not been adequate for deployment. However, given the availability of mil lions of annotated data, faster GPUs and a better un derstanding of the nonlinearities, DCNNs are provid ing much better performance on tasks such as object recognition [52,84], object/face detection [36,68], face verication/recognition [77,66]. It has been shown that DCNN models can not only characterize large data vari ations but also learn a compact and discriminative reparXiv:1605.02686v3  [cs.CV]  18 Jul 20172 JunCheng Chenet al. resentation when the size of training data is suciently large. In addition, it can be generalized to other vision tasks by netuning the pretrained model on the new task [31]. In this paper, we present an automated face veri cation system. Due to the robustness of DCNNs, we build each component of our system based on separate DCNN models. Modules for detection and face align ment use the DCNN architecture proposed in [52]. For face verication, we train two DCNN models trained using the CASIAWebFace [100] dataset. Finally, we compare the performance of our approach with many face matchers on the IJBA dataset which are being carried out or have been recently reported [1]1The pro posed system is fully automatic. Although the IJBA dataset contains signicant variations in pose, illumi nation, expression, resolution and occlusion which are much harder than the Labeled Faces in the Wild (LFW) datasets, we present verication results for the LFW dataset too. The system described in this paper, which integrates DCNNbased face detection [68] and ducial point de tection [53] modules diers from its predecessor [18] in the following ways: (1) uses more robust features from two networks which take faces as input with dierent resolutions (Section 3.4) are used and (2) employs a more ecient metric learning method [76] which uses innerproducts based constraints between triplets to op timize for the embedding matrix as opposed to norm based constraints used in other methods (Section 3.5). In the experimental section, we also demonstrate the improvement due to mediasensitive pooling and the fusion of two networks. The rest of the paper is organized as follows. We brie y review closely related works in Section 2. In Sec tion 3, we present the design details of a deep learning system for unconstrained face verication and recog nition, including face detection, face association, face alignment, and face verication. Experimental results using IJBA, CS2, and LFW datasets are presented in Section 4. Some open issues regarding the use of DC NNs for face recognition/verication problems are dis cussed in Section 5. Finally, we conclude the paper in Section 6 with a brief summary and discussion. 1While this paper was under review, several recent works have also reported improved numbers on the IJBA dataset [70] and its successive version Janus Challenge Set 3 (CS3) [10]. We refer the interested readers to these works for more details.2 Related Work "
151,Transforming acoustic characteristics to deceive playback spoofing countermeasures of speaker verification systems.txt,"Automatic speaker verification (ASV) systems use a playback detector to
filter out playback attacks and ensure verification reliability. Since current
playback detection models are almost always trained using genuine and
played-back speech, it may be possible to degrade their performance by
transforming the acoustic characteristics of the played-back speech close to
that of the genuine speech. One way to do this is to enhance speech ""stolen""
from the target speaker before playback. We tested the effectiveness of a
playback attack using this method by using the speech enhancement generative
adversarial network to transform acoustic characteristics. Experimental results
showed that use of this ""enhanced stolen speech"" method significantly increases
the equal error rates for the baseline used in the ASVspoof 2017 challenge and
for a light convolutional neural network-based method. The results also showed
that its use degrades the performance of a Gaussian mixture model-universal
background model-based ASV system. This type of attack is thus an urgent
problem needing to be solved.","Automatic speaker veriÔ¨Åcation (ASV) [1], a kind of bio metrics authentication technology, identiÔ¨Åes a person from a segment of speech. ASV systems typically fall into two types: textindependent and textdependent, where the lat ter requests a client to speak a given phrase. Due to the convenience of ASV , it is being used in more and more ap plications, such as ones used in call centers and by mobile devices. However, ASV is vulnerable to several kinds of spooÔ¨Ång attacks (also known as presentation attacks [2]), so ASV systems need a spooÔ¨Ång countermeasure (CM) (also known as presentation attack detection [2]). Such attacks aim to mimic the target speaker mainly by using synthesized speech [3], converted speech [3], or playback speech [4, 5]. Among them, playback speechbased attacks are relatively easy to mount since an attacker who has nospecial knowledge can make them [6]. Once an attacker has collected/stolen a voice sample for the target speaker, he/she can simply play it back to an ASV system or con catenate segments of the sample to form a new utterance. Threats from this kind of attack have been conÔ¨Årmed by several studies [4, 5, 7, 8, 9]. Here we focus on playback spooÔ¨Ång attacks and relevant CMs. Four main types of CMs have been developed to pro tect against playback spooÔ¨Ång attacks. One type utilizes a textdependent ASV system and randomly prompts for a passphrase [10, 11], making it difÔ¨Åcult to mount playback attacks using phraseÔ¨Åxed speech. However, it is possible to form an arbitrary utterance to spoof this type of CM if the attacker has sufÔ¨Åcient speech data for the target speaker. The second type is based on rules describing the characteris tics of genuine speech (recorded from a person). For exam ple, Mochizuki et al. [12] distinguished genuine speech by detecting popnoise from certain phonemes. An intractable problem related to this type of CM is that it is difÔ¨Åcult to design suitable rules and implement them. The third type utilizes audio Ô¨Ångerprinting to check whether an incoming recording is similar to previously authenticated utterances that were automatically saved in the ASV system. Ro driguez et al. [13] developed such a system: if the simi larity score was higher than a threshold, the recording was treated as a playback attack. A disadvantage of this type of CM is that it is sensitive to noise. In contrast, the fourth type compares the differences between genuine speech and play back speech. This type mainly utilizes a machine learning algorithm to learn the differences. An example is Wang et al.‚Äôs [14] use of a support vector machine [15] to learn the difference in Melfrequency cepstral coefÔ¨Åcient (MFCC) based acoustic features. More methods of the fourth type were presented at the second Automatic Speaker VeriÔ¨Åcation SpooÔ¨Ång and Coun termeasures Challenge (ASVspoof 2017), in which a com mon database was used to assess the participants‚Äô CMs. The database consists of two parts. One part contains genuine speech taken from the RedDots corpus [16], which was c 2018 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works.arXiv:1809.04274v2  [cs.SD]  13 Sep 2018Playback detectorASV module Authentication Speech enhancementPlayback Rerecording Attacker Upload DownloadOnline OfflineFigure 1. Playback spooÔ¨Ång attack using enhanced stolen speech method under ASVspoof 2017 scenario. Without speech enhance ment, attack is the same as a conventional playback attack. designed for speaker veriÔ¨Åcation. The other part contains recordings of the genuine speech made in various environ ments. For these data, the baseline [4] with a constant Q cepstral coefÔ¨Åcient (CQCC) [17] feature and a Gaus sian mixture model (GMM) classiÔ¨Åer had an equal error rate (EER) of 30.60%. A deep learningbased method had an EER of 6.73% [18], which was the best performance achieved at ASVspoof 2017 [4]. These mainstream CMs of the fourth type are also prob lematic: they are based on the assumption that the attack ers do not have special knowledge. Moreover, this type of CM algorithms only learn the difference from a given dataset and perhaps do not work well if the acoustic charac teristics of the playback speech is transformed close to that of the genuine one. To conÔ¨Årm this hypothesis, we tested the effectiveness of a playback attack using speech ‚Äústolen‚Äù from the target speaker and enhanced before mounting the attack. This enhancement should remove the distortions in the stolen speech caused by the recording device and envi ronmental noise so that they do not affect the rerecorded speech. We evaluated the effectiveness of a playback attack us ing this enhanced stolen speech method against a text dependent ASV system. We used the ASVspoof 2017 sce nario (Figure 1) in which the attacker is assumed to ob tain from somewhere uncompressed speech for the target speaker containing the phrase used for authentication, e.g., by downloading from the web, hacking a device used by the target speaker, and talking to and surreptitiously recording the target speaker. The speech enhancement generative ad versarial network (SEGAN) [19] was used to transform the acoustic characteristics of the obtained speech close to that of the genuine speech. We also investigated the effect of dif ferent types of playback loudspeakers and rerecording de vices. The results showed that it is possible to fool playback spooÔ¨Ång CMs by transforming the acoustic characteristic of the playback speech close to that of the genuine speech. 2. Related work "
108,Cross-Lingual Cross-Platform Rumor Verification Pivoting on Multimedia Content.txt,"With the increasing popularity of smart devices, rumors with multimedia
content become more and more common on social networks. The multimedia
information usually makes rumors look more convincing. Therefore, finding an
automatic approach to verify rumors with multimedia content is a pressing task.
Previous rumor verification research only utilizes multimedia as input
features. We propose not to use the multimedia content but to find external
information in other news platforms pivoting on it. We introduce a new features
set, cross-lingual cross-platform features that leverage the semantic
similarity between the rumors and the external information. When implemented,
machine learning methods utilizing such features achieved the state-of-the-art
rumor verification results.","Social network‚Äôs unmoderated nature leads to the spread and emergence of information with ques tionable sources. With the increasing popularity of the social media, we are exposed to a plethora of rumors. Here we borrow the rumor deÔ¨Ånition from DiFonzo and Bordia (2007) as unveriÔ¨Åed in formation. Unmoderated rumors have not only caused Ô¨Ånancial losses to trading companies but also panic for the public (Matthews, 2013). Es pecially if rumors contain multimedia content, the public generally accepts the multimedia informa tion as a ‚Äúproof of occurrence‚Äù of the event (Sen car and Memon, 2009). Readers usually don‚Äôt have time to look through similar events across different platforms to make an informed judgment. Therefore, even if a credible platform, such as CNN, has debunked a rumor, it can still go viral on other social media platforms. Intuitively, people believe fake rumors would contain fabricated multimedia content. Boididouet al. (2015b) used forensics features for detecting multimedia fabrication to verify rumors. However, these features did not lead to noticeable improve ment. We suspect that this is because untampered multimedia content can still convey false informa tion when paired with fake news from a separate event. For example, Figure 1 shows one fake post on MH 370 that used a real video about US Air ways Flight 1549. Inspired by the fact that readers Figure 1: A video of US Airways Flight 1549 was bor rowed by news on Malaysia Airlines Flight 370. tend to search related information covered by dif ferent media outlets to garner an objective view, we propose to verify rumors pivoting on multime dia content to tackle such problems. Compared to keywords, searching information pivoting on the visual content is more effective and accurate. In order to access information from different platforms easily, we created a new rumor veriÔ¨Åca tion dataset by expanding a Twitter rumor dataset to include webpages from different social me dia platforms using search engines. Previous ru mor veriÔ¨Åcation datasets are mainly monolingual, such as English (Derczynski et al., 2017) or Chi nese (Wu et al., 2015). However, textual informa tion in the native language where the rumor hap pened can be more helpful when it comes to verarXiv:1808.04911v2  [cs.CL]  28 Aug 2018ifying worldwide rumors. Therefore, we not only indexed English webpages by searching Google with images but also included Chinese webpages via Baidu. We next introduced our crosslingual cross platform features which capture the similarity and agreement among rumors with posts from different social media. We built an automatic veriÔ¨Åcation model using the proposed features and achieved the stateoftheart performance on the MediaEval 2015‚Äôs Verifying Multimedia Use (VMU 2015) dataset (Boididou et al., 2015a) uti lizing information from Google. Collecting and annotating rumors in foreign languages is difÔ¨Åcult and timeconsuming, espe cially for languages with low rumor veriÔ¨Åcation labeling. Finding out an automatic way to verify those rumors in an unsupervised way is also mean ingful. Since our crosslingual crossplatform fea tures are adaptable to rumors in different lan guages, we demonstrated that these features could transfer learned knowledge by training on one lan guage and testing on another. Such crosslingual adaptation ability is especially useful for predict ing rumors that have low annotation resource with available annotated rumors in languages such as English. We published our code and dataset on GitHub1. 2 Related work "
447,RepPoints V2: Verification Meets Regression for Object Detection.txt,"Verification and regression are two general methodologies for prediction in
neural networks. Each has its own strengths: verification can be easier to
infer accurately, and regression is more efficient and applicable to continuous
target variables. Hence, it is often beneficial to carefully combine them to
take advantage of their benefits. In this paper, we take this philosophy to
improve state-of-the-art object detection, specifically by RepPoints. Though
RepPoints provides high performance, we find that its heavy reliance on
regression for object localization leaves room for improvement. We introduce
verification tasks into the localization prediction of RepPoints, producing
RepPoints v2, which provides consistent improvements of about 2.0 mAP over the
original RepPoints on the COCO object detection benchmark using different
backbones and training methods. RepPoints v2 also achieves 52.1 mAP on COCO
\texttt{test-dev} by a single model. Moreover, we show that the proposed
approach can more generally elevate other object detection frameworks as well
as applications such as instance segmentation. The code is available at
https://github.com/Scalsol/RepPointsV2.","Two common methodologies for neural network prediction are veriÔ¨Åcation and regression. While either can drive network features to Ô¨Åt the Ô¨Ånal task targets, they each have different strengths. For the object localization problem, veriÔ¨Åcation can be easier to infer because each feature is spatially aligned with the target to be veriÔ¨Åed. On the other hand, regression is often more efÔ¨Åcient and it can also predict continuous target variables that enable subtle localization reÔ¨Ånement. To take advantage of all these beneÔ¨Åts, earlier object localization methods [ 7,18,16] combined veriÔ¨Åcation and regression by Ô¨Årst performing coarse localization through verifying several anchor box hypotheses, and then reÔ¨Åning the localization by regressing box offsets. This combination approach was shown to be effective and led to stateoftheart performance at the time. However, recent methods based purely on regression, which directly regress the object extent from each feature map position [ 30,27,32], could perform competitively or even better, when comparing a representative regression method, RepPoints, to RetinaNet [16]. In this work, we examine whether pure regression based methods can be enhanced by the inclusion of veriÔ¨Åcation methodology. We observe that veriÔ¨Åcation has proven to be advantageous when used in certain ways. In CornerNet [ 13], feature map points are veriÔ¨Åed as a bounding box corner or not, in contrast to verifying anchor boxes for coarse hypothesis localization in RetinaNet [ 16]. This use of veriÔ¨Åcation leads to signiÔ¨Åcantly better localization performance as shown in Table 1. The This work is done when Yihong Chen is an intern at Microsoft Research Asia. Preprint. Under review.arXiv:2007.08508v1  [cs.CV]  16 Jul 2020difference may be attributed to corner points representing the exact spatial extent of a groundtruth object box, while an anchor box gives only a coarse hypothesis. In addition, each feature in corner point veriÔ¨Åcation is well aligned to the corresponding point, while in anchor veriÔ¨Åcation, the center feature used for veriÔ¨Åcation lies away from the boundary area. To elevate the performance of regressionbased methods, speciÔ¨Åcally RepPoints [ 30], we thus seek to incorporate effective and compatible forms of veriÔ¨Åcation. However, the different granularity of object representations processed by the two methods, i.e., whole objects in RepPoints and object parts (corners) in corner veriÔ¨Åcation, presents an obstacle. To address this issue, we propose to model veriÔ¨Åcation tasks by auxiliary sidebranches that are added to the major regression branch at only the feature level and result level, without affecting intermediate representations. Through these auxiliary sidebranches, veriÔ¨Åcation can be fused with regression to provide the following beneÔ¨Åts: better features by multitask learning, feature enhancement through inclusion of veriÔ¨Åcation cues, and joint inference by both methodologies. The fusion is simple, intuitive, general enough to utilize any kind of veriÔ¨Åcation cue, and does not disrupt the Ô¨Çow of the RepPoints algorithm. Through different techniques for harnessing veriÔ¨Åcation, the localization and classiÔ¨Åcation ability of RepPoints is substantially improved. The resulting detector, called RepPoints v2, shows consistent improvements of about 2.0 mAP over the original RepPoints on the COCO benchmark with different backbones. It also achieves 52.1 mAP on the COCO object detection testdev set with a single ResNeXt101DCN model. The proposed approach of choosing proper veriÔ¨Åcation tasks and introducing them into a regression framework as auxiliary branches is Ô¨Çexible and general. It can be applied to object detection frame works other than RepPoints, such as FCOS [ 27]. The additional corner and withinbox veriÔ¨Åcation tasks are shown to improve a vanilla FCOS detector by 1.3 mAP on COCO testdev using a ResNet50 model. This approach can be also applied beyond object detection, such as to instance segmentation by Dense RepPoints [ 31], where additional contour and mask veriÔ¨Åcation tasks improve performance by 1.3 mAP using a ResNet50 model on the COCO instance segmentation testdev set, reaching 38.9 mask mAP. Table 1: Analysis of the performance on COCO valset among different methods. ‚ÄúRepPoints*‚Äù indicates our improved reimplementation of RepPoints. Method methodology backbone AP AP 50 AP 60 AP 70 AP 80 AP 90 RetinaNet [16] ver.+reg. ResNeXt101 40.0 60.9 56.4 48.7 35.8 14.6 CornerNet [13] veriÔ¨Åcation HG104 40.6 56.1 52.0 46.8 38.8 23.4 RepPoints* [30] regression ResNet50 39.1 58.8 54.8 48.0 35.5 14.4 RepPoints v2 ver.+reg. ResNet50 41.0 59.9 55.9 49.1 37.2 18.5 2 Related Works "
459,WikiContradiction: Detecting Self-Contradiction Articles on Wikipedia.txt,"While Wikipedia has been utilized for fact-checking and claim verification to
debunk misinformation and disinformation, it is essential to either improve
article quality and rule out noisy articles. Self-contradiction is one of the
low-quality article types in Wikipedia. In this work, we propose a task of
detecting self-contradiction articles in Wikipedia. Based on the
""self-contradictory"" template, we create a novel dataset for the
self-contradiction detection task. Conventional contradiction detection focuses
on comparing pairs of sentences or claims, but self-contradiction detection
needs to further reason the semantics of an article and simultaneously learn
the contradiction-aware comparison from all pairs of sentences. Therefore, we
present the first model, Pairwise Contradiction Neural Network (PCNN), to not
only effectively identify self-contradiction articles, but also highlight the
most contradiction pairs of contradiction sentences. The main idea of PCNN is
two-fold. First, to mitigate the effect of data scarcity on self-contradiction
articles, we pre-train the module of pairwise contradiction learning using SNLI
and MNLI benchmarks. Second, we select top-K sentence pairs with the highest
contradiction probability values and model their correlation to determine
whether the corresponding article belongs to self-contradiction. Experiments
conducted on the proposed WikiContradiction dataset exhibit that PCNN can
generate promising performance and comprehensively highlight the sentence pairs
the contradiction locates.","While social media brings convenient communication and allows easier interactions between people, it is also rooted in the dissemination of misinformation and disinformation [1, 2]. Misinformation refers to false and incorrect information while disinformation is purposefully manipulated news [3]. Wikipedia has been used as source for largescale corpus of real claims and evidence documents [4], and thus has been adopted for factchecking and veriÔ¨Åcation against fake and false information, such as WikiFactCheckEnglish [5], FEVER [6], MultiFC [7], WikiCitations [8], and WikiCheck [9]. Wikipedia can be also utilized to construct knowledge graphs to enhance applications, such as recommender systems [10], question answering [11], and dialogue Systems [12]. Although Wikipedia is widely exploited, dealing with noisy and lowquality Wikipedia articles is still critical. Therefore, is crucial for editors and factcheckers to have some approaches to identify Wikipedia articles containing incorrect information. To improve the quality of Wikipedia articles, this work dives into the detection of selfcontradiction articles in Wikipedia. An article is regarded as selfcontradiction if it contains mul tiple claims or ideas that are inherently in disagreement. ThatTABLE I TWO EXAMPLES OF SELF CONTRADICTORY WIKIPEDIA ARTICLES : ‚ÄúTyler Acord ‚Äù3AND ‚ÄúPink Chanel suit of Jacqueline Bouvier Kennedy ‚Äù4. THE TEXTS THAT CONTRADICT WITH EACH OTHER ARE HIGHLIGHTED IN BOLD FONT . CONTRADICTED PARTS TEND TO APPEAR AT DIFFERENT SENTENCES WITHIN AN ARTICLE . Wikipedia Article 1: Tyler Acord . . . Tyler Acord (born September 12, 1990), better known by his stage name Lophiile and formerly known as Scout, is an American record producer, DJ, multiinstrumentalist, and songwriter born in Lakewood, Washington . . . . Tyler Acord was born in Renton, Washington on September 12, 1990. . . . Wikipedia Article 2: Pink Chanel suit of Jacqueline Bouvier Kennedy . . . There was long a question among fashion historians and experts whether the suit was a genuine Chanel or a quality copy purchased from New York‚Äôs Chez Ninon, a popular dress shop that imported European label designs. . . . A number of sources claimed it was more than likely a copy of a Chanel pink boucl ¬¥e wool suit trimmed with a navy blue collar . . . said, if an article possesses at least two statements that contra dict one another, we can say that this article contradicts itself, i.e., is selfcontradiction. In Wikipedia, a ‚ÄúSelfcontradictory‚Äù template1is created to annotate selfcontradiction articles. Editors can use the ‚Äúselfcontradictory‚Äù template to manually indicate whether an article is selfcontradiction, resulting in the historical collection of selfcontradiction articles2. We aim to accordingly create a dataset for detecting selfcontradiction articles in Wikipedia. Besides, we further propose the Ô¨Årst model, Pairwise Contradiction Neural Network (PCNN), for the detection task. Here we give two examples of selfcontradictory articles in Wikipedia, as presented in Table I. For the Ô¨Årst example, i.e.,Tyler Acord , it can be clearly found that two highlighted sentences are contradicted with one another because the birth places are different. For the second example, i.e., Pink Chanel suit of Jacqueline Bouvier Kennedy , it is about the authenticity of the suit. One sentence mentions that the suit could be a genuine or a copy, and the other emphasizes a copy. Detecting selfcontradiction articles is different from con ventional contradiction detections in various text data. The 1https://en.wikipedia.org/wiki/Template:Selfcontradictory 2https://en.wikipedia.org/wiki/Category:Selfcontradictory articles 3https://en.wikipedia.org/w/index.php?title=Tyler Acord&oldid= 895550671 4https://en.wikipedia.org/w/index.php?title=Pink Chanel suit of Jacqueline Bouvier Kennedy&direction=prev&oldid=885388833arXiv:2111.08543v1  [cs.CL]  16 Nov 2021input of typical contradiction detection is a pair of sentences or claims, and its goal is to classify whether they contradict each other [13]. Previous work has explored contracdictions in domains such as scientiÔ¨Åc reviews [14, 15], shorttext posts on social media [16, 17], ‚Äúrumorous claims‚Äù [18], and commercial item reviews [19, 20]. As for the selfcontradiction detection proposed in this work, we are given an article containing a number of sentences, and the task is to simultaneously classify the article as selfcontradiction or not and identify which pairs of sentences are contradicted with one another. The key difference is that detecting selfcontradiction requires a model to understand the semantics and topics of the input article, in addition to have pairwise comparisons between sentences, so that the sentences whose meanings contradict with other sentences or the whole article can be highlighted. Although an existing study [21] found that few of nearduplicate sentences can contradict with each other in Wikipedia. They simply perform sentence clustering with lexical Jaccard similarity, but do not address the problem of Ô¨Ånding contradiction sentences with different phrasings. In this paper, we create a new dataset, WikiContradiction, which contains both selfcontradiction and noncontradiction articles in Wikipedia. We develop the Ô¨Årst model, Pairwise Contradiction Neural Network (PCNN), for the detection task. The main idea of PCNN is threefold. First, we Ô¨Ånetune the SentenceBERT model to generate the representations of sen tences in a Wikipedia article. Second, we pretrain a pairwise contradiction learning network to generate the contradiction probability of each pair of sentences. Third, we select top Ksentences with the highest contradiction probabilities, and utilize their embeddings to generate the binary classiÔ¨Åcation outcomes. Experiments conducted on our WikiContradiction dataset deliver three main Ô¨Åndings. First, PCNN can apparently outperform typical document classiÔ¨Åcation models. Second, the pretraining of pairwise contradiction learning has the most signiÔ¨Åcant contribution to the detection performance. Third, the conducted case studies exhibit that PCNN can truly identify the most contradictory pairs of sentences regarding contradictions within an article. Below we list the contributions of this work. We create a novel wiki dataset, WikiContradiction, for selfcontradiction Wikipedia article detection5. To the best of our knowledge, it is the Ô¨Årst dataset for the self contradiction detection task on Wikipedia. We deÔ¨Åne the task of detecting selfcontradiction articles and highlighting contradiction sentence pairs, and solve it by developing a novel model, Pairwise Contradiction Neural Network (PCNN). We propose to pretrain PCNN using two benchmarks SNLI and MNLI, and Ô¨Ånetune it via our WikiContradiction dataset. Experimental results show that PCNN can not only lead to the promising performance in both imbalanced and bal 5Data and code can be access at this link: https://github.com/ WikiContradictory/WikiSelfContradictory/anced settings, but also highlight the most contradictory pairs of contradicting sentences in an article. This paper is organized as follows. We review the relevant related work in Section II, next in Section III we describe WikiContradiction dataset. Section IV gives the technical de tails of the proposed PCNN model. We describe the evaluation settings and experimental results in Section V. Last, we discuss the implication and limitation in Section VI, and conclude this work in Section VII. II. R ELATED WORK "
425,Noise-robust classification with hypergraph neural network.txt,"This paper presents a novel version of the hypergraph neural network method.
This method is utilized to solve the noisy label learning problem. First, we
apply the PCA dimensional reduction technique to the feature matrices of the
image datasets in order to reduce the ""noise"" and the redundant features in the
feature matrices of the image datasets and to reduce the runtime constructing
the hypergraph of the hypergraph neural network method. Then, the classic
graph-based semi-supervised learning method, the classic hypergraph based
semi-supervised learning method, the graph neural network, the hypergraph
neural network, and our proposed hypergraph neural network are employed to
solve the noisy label learning problem. The accuracies of these five methods
are evaluated and compared. Experimental results show that the hypergraph
neural network methods achieve the best performance when the noise level
increases. Moreover, the hypergraph neural network methods are at least as good
as the graph neural network.","During the last decade, the deep convolution neural network can be considered the current state of  the art method for various classification tasks such as image recognition [1], speech recognition [2], to name  a few. Recently, to deal with irregular data structures, data scientists have gained many interests in graph  convolution neural network method such as [3]. In this method, the pairwise relationships between objects  (samples) are used. In the other words, in this graph data structure, the edge of the graph can connect only  two vertices.   To overcome the information loss due to only considering the ‚Äúpairwise relationship between  objects ‚Äù of graph data structure [4, 5] have recently proposed the hypergraph neural network approach. In  this hypergraph data structure, an edge (hyperedge) can connect more than two vertices. In the other words,  the hy peredge is the subset of the set of vertices of the hypergraph. Recently, this hypergraph neural  network method has just been employed to solve classification tasks [4, 5] and outperforms the graph neural  network and can be considered the current state of the art method of semisupervised learning approach.  However, this method has also not been utilized to solve the noisy label learning problem.   Inspired from the idea combining the pagerank algorithm with the graph convolution neural network  in [6], in this paper, we propose the novel version of hypergraph neural network method combining the  classic hypergraph based semisupervised learning method [7, 8] with the hypergraph neural network  method [4, 5]. In the other words, we combine the propagation scheme utilizing the hypergraph model with  the hypergraph neural network which is the current state of the art method of semisupervised learnin g        ÔÅ≤  ISSN: 25024752  Indonesian J Elec Eng & Comp Sci, Vol. 21, No. 3, March 2021 :  1465  1 473 1466   approach. We find out that this proposed combination of the propagation scheme and the hypergraph neural  network method significantly improves the accuracy of the hypergraph neural network method alone even  when the noise presents in the labels.   In this paper, our contributions are threefolds:   a) In order to reduce the runtime constructing the graphs and the hypergraphs from the image datasets, we apply the dimensional reduction technique PCA to the image datasets. b) Propose the novel version of hypergraph neural network method combining the classic hypergraph based semisupervised learning method with the hypergraph neural network method. c) Compare the accuracy performance measures of the classic graph based semisupervised learning problem, the classic hypergraph based semisupervised learning problem, the graph neural network method, the hypergraph neural network method, and our proposed hypergraph neural network method when we apply these five methods to solve the noisy label learning problem. We will organize the paper as follows: Section 2 will discuss the related work. Section 3 will  introduce the novel version of hypergraph neural network method. Section 4 will describe the datasets and  present the experimental results. Section 5 will conclude this paper and the future direction of researches will  be discussed.   2. RELATED WORK "
201,Practical and Scalable Security Verification of Secure Architectures.txt,"We present a new and practical framework for security verification of secure
architectures. Specifically, we break the verification task into external
verification and internal verification. External verification considers the
external protocols, i.e. interactions between users, compute servers, network
entities, etc. Meanwhile, internal verification considers the interactions
between hardware and software components within each server. This verification
framework is general-purpose and can be applied to a stand-alone server, or a
large-scale distributed system. We evaluate our verification method on the
CloudMonatt and HyperWall architectures as examples.","Over the last decade, a number of secure architectures have been designed to provide security functionalities (e.g., XOM [1], AEGIS [2], SP [3], Bastion [4], HyperWall [5], DataSafe [6], Sanctum [7], or HDFI [8]). Ideas presented by some of these architectures have been implemented in commercial designs, such as ARM TrustZone [9], Intel‚Äôs SGX [10], AMD‚Äôs SEV [11]. Once any such security architecture is designed, it is nec essary to check that there are no security vulnerabilities with the design that could allow an attacker to subvert the protec tions. Unlike softwarebased solutions which may be easily patched in the Ô¨Åeld, hardware architecture protections need to be correct from the beginning, as it is expensive and often not possible to update or replace them once hardware is manufac tured. To address this issue, designers run extensive tests and simulations to make sure that the mechanisms work correctly. Moreover, the designers perform informal security evaluation which attempts to qualitatively reason about potential attacks and show how the architectural mechanisms prevent them. There is a lack, however, of a systematic methodology for veriÔ¨Åcation of security architectures that can be applied to any architecture or system in a scalable manner. A big challenge in verifying secure architectures is that secure architectures today are usually very complex. A secure architecture is likely to consist of different types of comput ing servers, and the end users. All of these are connected by networks. Meanwhile each computing server consists of different layers of software and hardware components. The secure operations of the architecture include the mutual com munication between servers and users across the networks, as well as interactions between hardware and software modules inside a server. So veriÔ¨Åcation of complex architectures thus needs to be achieved by focusing on two key aspects: externalprotocols and internal interactions. Our contribution in this paper is the deÔ¨Ånition of a general purpose security veriÔ¨Åcation framework. It has different ad vantages. First, it is scalable to verify complex secure archi tectures. The presented approach breaks down a secure archi tecture into smaller components for veriÔ¨Åcation. SpeciÔ¨Åcally, veriÔ¨Åcation of a secure architecture can be achieved effective by focusing on external veriÔ¨Åcation, of the external protocols, and internal veriÔ¨Åcation, of the internal interactions. External protocols are used for communication between servers and users, while internal interactions are for interactions among components within each server. We build state machines to verify the external protocols and internal interactions, thus effectively achieving veriÔ¨Åcation scalability. Second, our methodology is generalpurpose and can be ap plied to different architectures. This method is not restricted to speciÔ¨Åc tools: designers can choose the tools they prefer to do the veriÔ¨Åcation following our methodology. This achieves great practicality and granularity. We provide two case stud ies: verifying CloudMonatt [12] using a cryptographic pro tocol veriÔ¨Åer ProVerif [13], and verifying HyperWall [5, 14] using a generic model checker Murphi [15]. These case stud ies show that our methodology has been partly used to help design and enhance the secure architectures. In summary, our contributions are: A new, generalpurpose security veriÔ¨Åcation framework for secure architectures and systems. A methodology to break the veriÔ¨Åcation task of secure architectures and systems into external and internal veriÔ¨Å cation, which can also be done hierarchically. A method to model different entities and components of such architectures as Ô¨Ånite state machines. Evaluation of the methodology on different architectures using different tools. We introduce our veriÔ¨Åcation methodology and framework in Section 2. Using this methodology, we verify two secure architectures as case studies in Sections 3 and 4. We show the veriÔ¨Åcation performance in Section 5. We summarize related work in Section 6 and conclude in Section 7. 2. VERIFICATION APPROACH The security veriÔ¨Åcation of secure architectures goes be yond functional veriÔ¨Åcation. During design time, the threat model is speciÔ¨Åed, which lists the potential attackers and their capabilities. The security veriÔ¨Åcation methodology needs to model enough aspects of an architecture to capture all 1arXiv:1807.01854v1  [cs.CR]  5 Jul 2018System  StartupProtection  InitializationCode/Data  Runtime Conf guration  Update Code/Data  MigrationCode/Data  TerminationSystem  Power down Protection  AttestationFigure 1: Different execution phases of a secure architecture. possible behaviors of these untrusted attackers with their capabilities, and to model their impacts on the architecture. A secure architecture usually consists of different compo nents (e.g., distributed nodes, software and hardware mod ules). The interactions between these components and with the external entities (e.g., remote users, networks) are very complex. To achieve the scalability of veriÔ¨Åcation, it is nec essary that the veriÔ¨Åcation is done on each part of the archi tecture, rather than on the whole architecture at once. Still, the veriÔ¨Åcation of the subparts must compose into the veriÔ¨Å cation of the whole architecture. In Section 2.1 we propose a method of breaking the secu rity veriÔ¨Åcation of a system into smaller tasks, i.e., external veriÔ¨Åcation and internal veriÔ¨Åcation. In Section 2.2 we de scribe the detailed steps to conduct each veriÔ¨Åcation task. 2.1 External and Internal VeriÔ¨Åcation A system is composed of many components. Each com ponent is realized by one or more mechanisms. We specify external protocols as the interaction of the system with dis tributed or remote components, e.g. remote users, network, etc. There are also internal interactions which are interac tions between components within a physical server or local system, e.g. processor, hypervisor, OS, etc. The important aspect of the securitycritical external proto cols and internal interactions is that these involve untrusted principals or components, and hence involve potential attacks that we need to check for. This has led us to the proposition that the components‚Äô interactions are the most important parts to verify when considering the security of the system. By fo cusing on the component interactions we have found a natural breakdown of the architecture into smaller parts. Verifying smaller parts helps us avoid the state explosion problem. The security veriÔ¨Åcation of the external protocols and in ternal interactions provides coverage of more of the system because the focus is on how components interface with each other, and the details of the mechanisms are abstracted away. A component, even a whole server, can be treated as a black box during external veriÔ¨Åcation ‚Äì and in turn security veriÔ¨Åed during internal veriÔ¨Åcation steps. Identifying protocols and interactions. To Ô¨Ånd the dif ferent securitysensitive interactions, we identify different execution phases of a secure architecture or system, as shown in Figure 1. The middle six phases will be repeated many times during system runtime, while the other two phases cor respond to system startup and shutdown. Each of the phases will have an external protocol if there is communication with the end user during that phase, and one or more internal in teractions. The internal interactions occur when there is an event that will cause securityrelated state to be altered inside the trusted components of the architecture. The different execution stages of a hardware secure processor architecture shown in Figure 1 can be used to help identify protocols andinteractions for security veriÔ¨Åcation. Secure composition. Given secure mechanisms or proto cols, AandB, which have been veriÔ¨Åed, it is very difÔ¨Åcult to prove that the composition of the two is also secure. We do not tackle the problem of formal proofs of composability in this work. We focus on providing a sound methodology for the practical and scalable security veriÔ¨Åcation of individual external protocols and internal interactions. However, recently Protocol Composition Logic (PCL) has been proposed [16]. The composition theorems in PCL allow proofs of complex protocols to be built up from proofs of their constituent subprotocols. It may be possible to build on such existing work as PCL to check the composition of the protocols and interactions which we verify. 2.2 Security VeriÔ¨Åcation Framework To verify a system‚Äôs protocols and operations, we Ô¨Årst build models for the system, and identify the trusted and untrusted subjects in the system. We specify the veriÔ¨Åcation goals and invariants based on the system‚Äôs functionality. Then we implement the models and test through the system models. If an invariant fails in some cases, a vulnerability has been found and the design needs to be updated. 2.2.1 Modeling System Specifying essential components. A designer has to enu merate the components or principals involved. For the ex ternal protocol, we treat a physical server as one compo nent. The network component, customers, cloud provider, and (if needed) trusted third party are also explicitly included for the beneÔ¨Åt of the external protocols which involve the remote customer connecting via a communication path to the server. For the internal interactions, we consider the hardware components (e.g., microprocessor, memory chips, coprocessors) and software components (e.g., applications, hypervisor, OSes). Among the protocol or interaction partic ipants, there are untrusted components or principals, which could be sources of potential attacks. The untrusted com ponents or principals are the potential attackers and their capabilities need to be checked. Symbolic modeling. We adopted the symbolic modeling method [17], where the cryptographic primitives are rep resented by function symbols and perfect cryptography is assumed. Each component‚Äôs operation can be represented as states of a state machine, and communication among the components can be represented as messages sent between the components. So we model each component as a subject. Each subject has a set of states with inputs and outputs based on the system operation. The transitions between different states are also deÔ¨Åned by the architecture designs and protocols. Among all the subjects, there is an initiator subject that starts the system protocol/interaction and a Ô¨Ånisher subject that ends the protocol/interaction; they could both be the same subject. This initiator subject has a ‚Äústart‚Äù state while the Ô¨Ånisher subject has a ‚Äúcommit‚Äù state . The veriÔ¨Åcation procedure starts at the initiator‚Äôs ‚Äústart‚Äù state. At each state in each subject, it takes actions corresponding to the transition rules. It will exhaustively explore all possible rules and states to Ô¨Ånd all the possible paths from the initiator‚Äôs ‚Äústart‚Äù state to the Ô¨Ånisher‚Äôs ‚Äúcommit‚Äù state. Then we judge if the veriÔ¨Å 2cation goals are satisÔ¨Åed in all of these paths. The system is veriÔ¨Åed to be secure if there are paths from initiator‚Äôs ‚Äústart‚Äù state to Ô¨Ånisher‚Äôs ‚Äúcommit‚Äù state, and all the veriÔ¨Åcation goals are satisÔ¨Åed in any of these paths. 2.2.2 Preconditions and Security Invariants The protocols and interactions are subject to constraints, the socalled preconditions. Preconditions are closely related to the trusted computing base (TCB) and often reÔ¨Çect which principals need to be in the TCB. If a precondition is removed, the protocol or interaction may no longer be veriÔ¨Åable. Ide ally, during veriÔ¨Åcation of a system, the minimal number of preconditions is determined, which can reduce the size of the Trusted Computing Base (TCB). One key beneÔ¨Åt of our methodology is that it allows preconditions to be removed, (even though initially thought to be required), as veriÔ¨Åcation passes with these preconditions removed. Each protocol or interaction needs to satisfy certain se curity invariants ‚Äì these invariants are only veriÔ¨Åed if for all possible execution traces, the invariant is not found to be violated. Thorough analysis of the protocols allow us to deÔ¨Åne the invariants correctly. Often the invariant is the goal of the design so correctness is clear. The security invariants focus typically on conÔ¨Ådentiality and integrity of sensitive information. In the case of secure architectures, this sensitive information typically is: code or data executed or stored on the system, and measurements of the state of the system. ConÔ¨Ådentiality Validation. Each principal has access to various values, including ones tagged as conÔ¨Ådential to indi cate the need for conÔ¨Ådentiality protection of that value. The untrusted principal could try to combine all the information it has obtained in all of its states to try to break conÔ¨Ådentiality of some of the messages (e.g. it has seen cipher text in some state, and the decryption key in another). For each value tagged as conÔ¨Ådential, the invariants check if any untrusted principal has access to it. If not, conÔ¨Ådential ity of this value is maintained. Otherwise the invariants check if the value is tagged as encrypted (i.e. it has a decryption key associated with it) and the untrusted principal has access to the key. If so the untrusted principal can obtain the plaintext, thus violating conÔ¨Ådentiality. Otherwise the conÔ¨Ådentiality is preserved. The above heuristics are consistent with our assumption of strong cryptography and that the attacker is not able to break the asymmetric or symmetric key cryptography, unless they have access to the proper key. Integrity Validation. The way we are able to check for in tegrity attacks is through comparing the values available to an individual trusted principal to all the values in the model. The trusted principals have only visibility into their input values and the knowngood private values they posses. Mean while, the model has visibility into all the inputs and outputs from all the principals, and which other principals may have modiÔ¨Åed these values. During a run of the model, the in variants check if there is enough information in the (explicit and implicit) inputs to a trusted principal for that principal to reject any inputs that have been compromised (e.g. fabricated or replayed values). The key ideas behind the integrity checks are: (1) checking for ‚Äúknowngood‚Äù values, which can be referenced by a trusted party to validate some of the inputs, these good values need to be stored securely or come froma trusted source; (2) checking for selfconsistency of values, which allows a trusted party to check the inputs and make sure they are mutually consistent. 2.2.3 Implementation and Results Our security veriÔ¨Åcation methodology can be realized us ing very different tools. Since these are existing tools, the incremental overhead to achieve our security veriÔ¨Åcation methodology is very small. Also, designers can choose the tools they are more familiar with, or that best suit their pur pose. In this paper we use two veriÔ¨Åcation tools ProVerif [13] and Murphi [15] to exemplify that this is a Ô¨Çexible methodol ogy. Proverif has builtin security invariant checking support which Murphi does not. But Proverif is targeted at network protocol veriÔ¨Åcation, and we have to use (repurpose) it in a clever way for checking interactions between software and hardware modules within a system. Murphi has more com plete model checking facilities which enable the designer to do functional modelling and veriÔ¨Åcation with the same tool as security veriÔ¨Åcation. Murphi can be enhanced with security checking mechanisms as we have done, to propagate security tags for checking for integrity and conÔ¨Ådentiality breaches. The veriÔ¨Åcation results are either 1) the protocol or inter action passes, or 2) there is some invariant that does not hold and veriÔ¨Åcation fails. If veriÔ¨Åcation fails, the design needs to be updated, and one has to run the veriÔ¨Åcation process again. When veriÔ¨Åcation passes, some preconditions can be removed to test if they are necessary. Once the protocol or interaction passes with the least number of preconditions, the veriÔ¨Åcation process is completed. In the following two sections we validate our methodology on two types of secure architectures: a standalone server processor (HyperWall [5, 14]). and a distributed cloud system (CloudMonatt [12]). 3. VERIFYING A STANDALONE SERVER In this section, we show how to use the above methodol ogy to verify a secure standalone server processor. We use HyperWall [5, 14] as an example. HyperWall is a secure processor architecture which aims to protect virtual machines from an untrusted hypervisor, a predecessor to AMD‚Äôs SEV extensions. The processor hardware in HyperWall is extended with new mechanisms for managing the memory translation and memory update so that the hypervisor is not able to compromise conÔ¨Ådentiality and integrity of a virtual machine. The hardware allows the hypervisor to manage the memory, but once the memory is assigned to a virtual machine, the hypervisor has no access to it. It is scrubbed by hardware before the hypervisor can gain access again. These protections are realized in HyperWall through extra registers and memory regions which are only accessible to the hardware, namely the TEC (Trust Evidence and ConÔ¨Åguration) memory region. The TEC tables protect the memory of the guest VMs from accesses by the hypervisor and/or by DMA, depending on the customer‚Äôs speciÔ¨Åcation. Each memory region has an associated entry in the TEC tables specifying the access rights. HyperWall can be used as the cloud server in a cloud com puting scenario where there is a remote user communicating to his or her (HyperWall) server located in the cloud possibly 3Hardware Core New  instructions Crypto  engineState  machine Protection check logicNew  registers Protection  control  logicMMUProtection  check  logicIOMMU MemoryHypervisorMemory map  handlingAttestation  handlingSave/store  registersNew inst.  supportHost VM Guest VM Guest VM VM start Protection config. Trust evidenceFigure 2: Architecture of HyperWall managed by an untrusted cloud provider. HyperWall architec ture is summarized in Figure 2. Below we present veriÔ¨Åcation of one external protocol and one internal interaction of Hy perWall. We have further performed veriÔ¨Åcation of Ô¨Åve more HyperWall interactions, summarized in Section 5. 3.1 External Protocol: VM Startup Validation The security veriÔ¨Åcation goal is to check if the integrity of VM image and conÔ¨Ågurations are protected during VM startup (system startup phase in Figure 1). Modeling. Figure 3 shows the external protocol with the involved components. The customer component ‚Äústarts‚Äù VMs by specifying a nonce, N, the virtual machine image I, and the desired set of conÔ¨Ådentiality and integrity protections for the virtual machine, P. This ‚Äústart VM"" message is sent over the network to the hypervisor, which creates a data structure representing a VM. The network and hypervisor are both untrusted and have the same attack capabilities; thus we collapse them into one component for the purpose of modeling. After the VM is prepared, the processor is invoked to start the VM, through a VM Launch instruction. The microprocessor hardware launches the VM. It signs ‚Äì with its secret key SKP‚Äì values that will deÔ¨Åne the VM: N, VID (the VM identiÔ¨Åer assigned by the processor), hash (I), hash (P), and TE(the initial trust evidence where initially the number of memory access violation is zero). The Ô¨Åve values and their signature, Sig, and a certiÔ¨Åcate from the hardware manufacturer with the veriÔ¨Åcation key needed to check the signature, Cert VKP, are sent back to the customer. Cert VKPis signed by the trusted vendor. To aid the veriÔ¨Åcation, we have added two extra states to make explicit information available to the customer and processor. In particular, the customer knows the certiÔ¨Åcate for the manufacturer Cert Mfgand the initial expected value ofTE. The processor knows the key, SKPthat it uses to make the signatures. It also has a certiÔ¨Åcate for the corresponding public key, VK P, for recipients to verify its signatures. This information is made explicit as inputs from the two trusted party states, TP1andTP2. Security invariants. We identify one invariant: 1The customer is able to reach the commit state with N, VID,hash (I),hash (P),TE,SigandCert VKPnot being compromised by the untrusted hypervisor or the untrusted network. Preconditions. We make several preconditions about the processor and cloud user and check if the above security invariants can be satisÔ¨Åed with these. (C1) The processor is trusted. (C2) The processor has valid Cert VKPandSKP. Customer S_CUST_SENDNetwork/Hypervisor S_NWHV_RELAYN I PProcessor S_PROC_VMLAUNCH S_NWHV_RELAY S_CUST_CHECK S_CUST_COMMITN I P N VID hash (I) hash (P) TE Sig Cert%&'N I PTP2Cert%&' SK* N I PN VID hash (I) hash (P) TE Sig Cert%&'TP1 Cert Mfg TE Sig = sign+&'(N || VID || hash (I) || hash (P) || TE)Figure 3: Model of VM Startup Validation external protocol. SKPis the private key belonging to the processor, for which the customer has Cert Mfg certiÔ¨Åcate from manufacturer and the Cert VKPcertiÔ¨Åcate of the SKPsent by the processor , which is signed by the manufacturer. (C3) The customer has valid Cert MfgandTE. Implementation. We model the Customer ,Network , and Processor in Murphi as a set of state machines. For this protocol, we are concerned with the network or hypervisor component fabricating or replaying values as it passes them to the processor, or when it returns values back to the customer. These two are collapsed into the single untrusted principal with states corresponding to two points where this principal needs to relay the data and it could be attacked. We extend the murphi model checker tool to propagate multiple values, for each value whose integrity must be veri Ô¨Åed: the correct value, a fabricated value and a replayed value. At the commit state, we check if the cryptography used al lowed us to verify that the correct value was returned, despite transmission through the untrusted network and hypervisor. Results. The security veriÔ¨Åcation passes for all possible runs and the customer can reach the commit state. The integrity of N,VID,hash (I),hash (P),TE,SigandCert VKPis protected against fabrication of values and replay of values. SpeciÔ¨Åcally, NandTEsatisfy the case that there are known good values to compare against for these invariants. For Cert VKPthere is the Cert Mfgthat can be used to compare against it and verify it. VID satisÔ¨Åes the case that there is a signature that includes this value and a chain of certiÔ¨Åcates to verify the veriÔ¨Åcation key of the signature. hash (I) and hash (P) are hash primitives and included in the signature so they cannot be forged. The integrity of Sigis checked against fabrication: neither the network nor the hypervisor have access to the private signing key SKPand the customer has access to a chain of certiÔ¨Åcates that allows for him or her to verify the signature. It is also checked against replay of values: the customer can check the nonce, N, that he or she generated for this run of the protocol. 3.2 Internal Interaction: VM Launch We now show how to do the security veriÔ¨Åcation of set ting up protections for the VM‚Äôs memory pages (protection initialization phase in Figure 1). Modeling. Figure 4 shows the Ô¨Çow chart of the VM Launch mechanism. The mechanism is triggered when the hypervisor tries to start a new VM, as part of the VM startup attestation external protocol. The hypervisor sets up the VM and then executes the vm_launch instruction. The processor captures this instruction and atomically launches the VM with the following Ô¨Åve operations, highlighted in Figure 4: (1) The processor consults the TEC tables to Ô¨Ånd a free 4Network/Hypervisor S_NWHV_RELAYProcessor S_PROC_CHECK_AVAILABLE_TEC_ENTRY  S_NWHV_COMMITN I P N hash (I) hash (P)S_PROC_PROTECT_PAGE_TABLES S_PROC_PROTECT_CIP_MEMORY_PAGES S_PROC_PROTECT_VM_MEMROY_PAGES S_PROC_GENERATE_HASHN VID hash (I) hash (P) TE Sig Cert%&'Figure 4: Model of VM Launch Mechanisms. Cert VKPis the certiÔ¨Åcate of the signing key used by the processor in creating the signature Sig. entry where the information about the VM will be stored. (2) Once a free VM entry is found, the page tables are protected. (3) Then the ConÔ¨Ådentiality and Integrity Protection (CIP) tables for the VM‚Äôs pages are protected. (4) The VM‚Äôs pages are protected. Each memory page is protected by denying access to the hypervisor and to DMA. (5) Finally, the hashes of the VM image and VM protections are generated. The page table page count is saved in the TEC table entry for the VM, and the VM is actually launched. Security invariants. We identify one invariant: 1The processor needs to ensure the VM started has ex actly the conÔ¨Åguration and protection requested, and that correct hash measurements of the VM are taken. Preconditions. We require several preconditions about the processor, these are a subset of the preconditions needed by the prior external protocol. (C1) The processor is trusted. (C2) The processor has valid Cert VKPandSKP. Implementation. As above, we model the untrusted network and untrusted hypervisor as a single entity, with the capability to fabricate values and replay values. The processor is trusted based on our preconditions. We use Murphi to model the processor as a state machine. The Processor needs to ensure the integrity of the start up values received when a request to launch a VM is received: N,VID,hash (I),hash (P),TE, SigandCert VKP. We tag these values as requiring integrity protection and check if these values are fabricated or replayed when the protocol reaches the commit state. Results. This protocol focuses on integrity of the start up values received: N,VID,hash (I),hash (P),TE,Sigand Cert VKP. The model keeps track of whether the reads or writes to protection tables were accessed only by the trusted hardware. Our veriÔ¨Åcation results indicate that the processor will correctly conduct the above Ô¨Åve steps, and generate the correct hash measurements at the commit state. 3.3 Security Discussion Coverage. In addition to the two protocols shown above, Ô¨Åve other protocols or interactions were veriÔ¨Åed, as listed in Table 1. The protocols and interactions veriÔ¨Åed cover the execution phases from Figure 1, except for VM migration. The methodology facilitates a ‚Äúdesign for security‚Äù approach where architects can validate individual protocols and inter actions at the design phase. CustomerPolicy  Validation  Module Cloud ControllerResponse  ModuleDeployment  ModuleProperty Interpretation Moduleprivacy Certificate  Authority Attestation Server Attestation Request Attestation ResultsMeasurement  CollectionProperty Certification Module HardwareHypervisorHost VMGuest  VM Attestation Client Monitor  Module Trust  ModuleGuest  VM CPU RAM Disk NICCloud ServerFigure 5: Architecture of CloudMonatt. Impact. The veriÔ¨Åcation effort uncovered two Ô¨Çaws in the original design [5], and later Ô¨Åxed in [14]. The Ô¨Årst was a replay attack in the VM Suspend and Resume protocol. The original design [5] included a nonce to prevent replay attacks. However, when modeling the internal interaction due to VM Suspend & Resume, the veriÔ¨Åcation of the model failed, point ing out that the ‚Äúnonce‚Äù value was not updated during the suspend and resume operation as originally assumed, thus not providing replay protection. A related problem was dis covered about the trust evidence data, previously also only stored in registers. Stale trust evidence data could have been sent back to the customer, by a compromised hypervisor. 4. VERIFYING A DISTRIBUTED SYSTEM CloudMonatt [12] is a Ô¨Çexible distributed cloud architec ture to monitor and attest the security health of customers‚Äô VMs in the cloud. Figure 5 shows the architecture overview of CloudMonatt. It involves four entities: the customer, the Cloud Controller, the Attestation Server and the cloud server. The Cloud Controller acts as the cloud manager, responsible for taking VM requests and servicing them for each customer. The Attestation Server acts as the attestation requester and appraiser, to collect the security measurements from the VM, interpret the measurements and make attestation decisions. The Cloud Server has a Monitor Module which contains different types of monitors to provide comprehensive and rich security measurements. It has a Trust Module responsible for server authentication, secure measurement storage and crypto operations. We now show how our security veriÔ¨Åcation methodology can be used to verify the main attestation protocol of Cloud Monatt. We also show how this methodology can help to narrow down the number of trusted components needed in the trusted computing base for this distributed system. 4.1 External Protocol: Cloud Attestation Cloud attestation is the procedure of making unforgeable claims about the security conditions of customers‚Äô VMs based on the evidence supplied by the host server . We verify that the requested report is not tampered with in CloudMonatt archi tecture, and hence the integrity of the endtoend attestation is achieved (protection attestation phase in Figure 1). Modeling. We model each entity involved in this distributed system as an interacting state machine, as shown in Figure 6. The whole process starts from the customer, who sends to the Cloud Controller the attestation request including the VM identiÔ¨Åer, VID, and the security properties, P. Then the Cloud Controller forwards the request to the Attestation Server, with the host servers identiÔ¨Åer, I. The Attestation Server sends MR, the request of necessary measurement, to the host 5Customer S_CUST_REQNetwork S_NW_RELAYCloud Controller S_CTRL_GETSERVERNetwork S_NW_RELAYAttestation Server S_ATT_REQNetwork S_NW_RELAYCloud Server S_SER_GETMEA S_SER_SIGN S_NW_RELAY S_ATT_CHECK S_ATT_SIGN S_NW_RELAY S_NW_RELAYS_CTRL_CHECK S_CTRL_SIGN S_CUST_CHECK S_CUST_COMMITVID, MR, N 3, M VID, I, P, N 2, N3 VID, I, P, R, N 2VID, I, P, N 1, N2 VID, P, R, N 1VID, P, NC 1enc!""(VID || P || N 1) enc!#(VID || I || P || N 2) enc!""(VID || P || N 1) enc!#(VID || I || P || N 2) enc!$(VID || MR || N 3) enc!$(VID || MR || N 3) enc!$(Sig3) enc!$(Sig3) enc!#(Sig2) enc!#(Sig2) enc!%(Sig1) enc!""(Sig1)Sig3 = sign&' !((VID || MR || M || N3|| hash (VID || MR || M || N3)) Sig2 = sign' !)(VID || I || P || R || N2|| hash (VID || I || P || R || N2)) Sig1 = sign' !*(VID || P || R || N1|| hash (VID || P || R || N1))Figure 6: The external protocol in CloudMonatt .SKC,SKAandASK Sare the private signing keys of the Cloud Controller, the Attestation Server and the cloud server, respectively. KX,KYandKZare symmetric keys between the customer and the Cloud Controller, between the Cloud Controller and the Attestation Server, and between the Attestation Server and the cloud server, respectively. server. The cloud server collects the required measurements M, hashes and signs the measurements, and sends them back to the Attestation Server. The Attestation Server checks the received message and, if correct, generates the attestation report Rbased on MandP. Then the Attestation Server signs the report and transmits it to the Cloud Controller. The Cloud Controller checks the message and, if correct, hashes and signs the report, and sends it to the customer. The customer ends the attestation session if the he Ô¨Ånds the report is correct. Security invariants. We identify one invariant: 1The attestation report Rthe customer receives is indeed the one for VID with P, speciÔ¨Åed by the customer. Preconditions. Initially, we specify several preconditions and check if the above invariant can be satisÔ¨Åed under these preconditions. Later, we verify each of these preconditions. (C1) The cloud server is trusted. (C2) The Attestation Server is trusted. (C3) The Cloud Controller is trusted. Implementation. We model the external protocol in ProVerif. SpeciÔ¨Åcally, we declare each subject as a process. Each pro cess keeps some variables. If the subject is trusted, we denote these variables as private , not accessible by the attacker. Otherwise the variables are assumed public. We declare a network connected between each pair of subjects, to repre sent the untrusted communication channels. These channels are under full control of the networklevel adversaries, who can eavesdrop or modify any messages. We use the cryp tographic primitives from ProVerif to model the public key infrastructure for digital certiÔ¨Åcate, authentication and key exchange. Then we model the attestation process for an un bounded number of sessions, and check if the adversary can compromise the integrity of the report in any session. We use ProVerif‚Äôs reachability proof functionality to verify the integrity of a message. SpeciÔ¨Åcally, we deÔ¨Åne a function R(VID,P) to denote the correct report of VM VID for prop erty P. At the customer‚Äôs state ‚ÄúS _CUST _COMMIT‚Äù, the customer receives the report R, and we check if the statement R=R(VID,P) is always true. We use the statement ‚Äú query event (R6=R(VID,P))"" to check the negative scenario: an integrity breach has occurred. If this query statement is false, the attacker has no means to change the message Rwithout being observed by the customer and the integrity of Rholds. Results. First, ProVerif shows the security invariant 1is sat isÔ¨Åed under the preconditions (C1) ‚Äì (C3). The networklevel Network S_NW_RELAYClient/OS/Hypervisor S_OSHV_RELAYVID, MR, N 3Monitor Module S_MON_INVOKETrust Module S_TRU_STOR S_MON_GETMEA S_OSHV_RELAY S_NW_COMMITSig3Sig3VID, MR, N 3VID, MR, N 3 VID, MR, M, N 3 S_TRU_SIGNVID, MR, M, N 3S_CLI_INVOKE S_CLI_ENCCloud Server enc!""(VID || MR || N 3) enc!""(Sig3) Sig3 = sign#$!%(VID || MR || M || N3|| hash (VID || MR || M || N3))Figure 7: Internal interactions in the cloud server. KZis the symmetric key known to the Attestation Server and the cloud server. ASK Sis the private signing key of the cloud server. adversaries cannot compromise the integrity of the messages without being observed, as all the messages are cryptographi cally protected. Second, ProVerif shows that preconditions (C1) ‚Äì (C3) are necessary to keep the invariants correct, and missing any precondition can lead to violations of the in variant. An untrusted cloud server can counterfeit wrong measurements, making the customer receives wrong attesta tion report generated from the measurements. An untrusted Attestation Server can generate wrong attestation report for the customer. An untrusted Cloud Controller can modify the attestation reports before sending to the customer. 4.2 Internal Interaction: Evidence Collection Placing the entire server into the TCB would require stronger security protection, which is expensive and difÔ¨Åcult to achieve. So, we conduct internal veriÔ¨Åcation to identify the necessary components inside the servers that need to be trusted. We verify the evidence collection process in the cloud server (protection attestation phase in Figure 1). Modeling. We model the key components inside a cloud server as state machines (Figure 7). We also include the un trusted network as the initiator and Ô¨Ånisher subject in the in ternal protocol to interact with the server. The whole process starts when the network passed the encrypted measurement request to the server. The Attestation Client processes the request and passes it to the Monitor Module . The Mon itor Module collects the correct measurements, and then stores the measurements together with other related informa tion in the Trust Module . The Trust Module calculates the hash and signature using its private attestation key. Then the signature is encrypted by the Attestation Client and sent out. The network goes to the commit state when it 6receives the encrypted measurement. Security invariants. We identify one invariant: 1The cloud server needs to ensure that the correct measure ment Mare taken for VM VID with request MR. Preconditions. We identify a set of possible preconditions. (C1) The Monitor Module is trusted. (C2) The Trust Module is trusted. (C3) The channel between the Monitor Module and the Trust Module is trusted. Implementation. We model a software or hardware compo nent as a process. Each component keeps some variables and operates as a state machine. If one component is in the TCB, then its variables will be declared as private . Otherwise its variables are public to attackers. If two modules are linked by an untrusted channel, then we declare a public network between these two components. Otherwise we combine the two component into one process so that they can exchange messages securely. We also use ProVerif‚Äôs reachability proof functionality to verify the integrity of measurement M. When the network reaches state ‚ÄúS _NW_COMMIT‚Äù, we denote the measure ment inside the encrypted message as M. We also deÔ¨Ånes a function M(VID,MR), which gives the correct measurement of VM VID for the measurement request MR. Then we check if the statement M=M(VID,MR) is always true at the com mit state. We use the statement ‚Äú query event (M6=M(VID, MR))"" to discover potential integrity breach. If this statement is false, the attacker has no means to change Mwithout being observed by the customer and the integrity of Mholds. Results. We verify that it is sufÔ¨Åcient and necessary to keep the security invariant with these preconditions, when the network, OS and hypervisor is untrusted. Missing any prediction can lead to invariant violation: an untrusted Moni tor Module can collect wrong measurements Mand store them into the Trust Module ; an untrusted Trust Module can generate a fake signature over any measurements using the signing key ASK S; an untrusted channel between the Monitor Module andTrust Module gives the adversary a chance to modify the measurements without being detected. 4.3 Security Discussion Coverage. We show the main CloudMonatt attestation pro tocol is secure, i.e., correct and unforgeable. We show the evidence collection process in the cloud server is secure. We also veriÔ¨Åed the property interpretation process in the Attes tation Server and the health checking process in the Cloud Controller in the same way as we showed for the Cloud Server. This completes the endtoend security veriÔ¨Åcation of the protection attestation phase in CloudMonatt. Impact. One of the most interesting results of security ver iÔ¨Åcation is to show how we can enhance the security of the architecture during design. In CloudMonatt, it showed that only the Monitor Module and Trust Module of a cloud server should be included in the TCB. Normally, third party cus tomers (at guest VM privilege) has no capability to subvert the security functions provided by these two modules (at the hypervisor privilege). To defeat attacks (e.g., privilege esca lation) caused by the vulnerabilities of the original system,Model Int. or Ext. Lines of Code Runtime (s) VM Startup Ext. 1159 0.8s VM Launch Int. 462 0.6s VM Secure Channel Ext. 1332 0.3s VM Trust Evidence Ext. 1081 0.2s VM Suspend & Resume Ext. 1054 0.5s VM Mem. Update Int. 687 0.7s VM Terminate Int. 417 0.8s Table 1: HyperWall veriÔ¨Åcation evaluation results. Model Int. or Ext. Lines of Code Runtime (s) External Ext. 262 0.2s Evidence Collection Int. 123 0.1s Property Interpretation Int. 205 0.2s Health Checking Int. 187 0.1s Table 2: CloudMonatt veriÔ¨Åcation evaluation results. secure enclaves can be used to protect the execution environ ment of the Monitor Module and Trust Module, leveraging mechanisms provided by Bastion [18]. 5. VERIFICATION EV ALUATION In addition to the protocols presented in this paper, we have also verify Ô¨Åve more for HyperWall and two more for CloudMonatt. For HyperWall, we use CMurphi 5.4.4 and the models were run with options tv ndl m1000 . The tv writes a violating trace (if an invariant fails), and the ndl disables the checking for deadlock states. For CloudMonatt we use ProVerif 1.88 with default options. The collected results for HyperWall in Table 1 and for CloudMonatt in Table 2. The veriÔ¨Åcation process is iter ative, where the ProVerif or Murphi Ô¨Åles may be updated many times, thus comments are crucial to understand the development of the veriÔ¨Åcation strategy. We can also ob serve that the veriÔ¨Åcation runtime is also very small: due to the breakdown of internal and external veriÔ¨Åcation, we can verify complex architectures within a very short time. The most effortconsuming step is the design and writing of the veriÔ¨Åcation models, but the actual veriÔ¨Åcation is quick. 6. RELATED WORK "
23,Beta-CROWN: Efficient Bound Propagation with Per-neuron Split Constraints for Complete and Incomplete Neural Network Robustness Verification.txt,"Bound propagation based incomplete neural network verifiers such as CROWN are
very efficient and can significantly accelerate branch-and-bound (BaB) based
complete verification of neural networks. However, bound propagation cannot
fully handle the neuron split constraints introduced by BaB commonly handled by
expensive linear programming (LP) solvers, leading to loose bounds and hurting
verification efficiency. In this work, we develop $\beta$-CROWN, a new bound
propagation based method that can fully encode neuron splits via optimizable
parameters $\beta$ constructed from either primal or dual space. When jointly
optimized in intermediate layers, $\beta$-CROWN generally produces better
bounds than typical LP verifiers with neuron split constraints, while being as
efficient and parallelizable as CROWN on GPUs. Applied to complete robustness
verification benchmarks, $\beta$-CROWN with BaB is up to three orders of
magnitude faster than LP-based BaB methods, and is notably faster than all
existing approaches while producing lower timeout rates. By terminating BaB
early, our method can also be used for efficient incomplete verification. We
consistently achieve higher verified accuracy in many settings compared to
powerful incomplete verifiers, including those based on convex barrier breaking
techniques. Compared to the typically tightest but very costly semidefinite
programming (SDP) based incomplete verifiers, we obtain higher verified
accuracy with three orders of magnitudes less verification time. Our algorithm
empowered the $\alpha,\!\beta$-CROWN (alpha-beta-CROWN) verifier, the winning
tool in VNN-COMP 2021. Our code is available at http://PaperCode.cc/BetaCROWN","As neural networks (NNs) are being deployed in safetycritical applications, it becomes increasingly important to formally verify their behaviors under potentially malicious inputs. Broadly speaking, the neural network veriÔ¨Åcation problem involves proving certain desired relationships between inputs and outputs (often referred to as speciÔ¨Åcations ), such as safety or robustness guarantees, for all inputs inside some domain. Canonically, the problem can be cast as Ô¨Ånding the global minima of some functions on the network‚Äôs outputs (e.g., the difference between the predictions of the true label and another target label), within a bounded input set as constraints. This is a challenging problem due to the nonconvexity and high dimensionality of neural networks. 35th Conference on Neural Information Processing Systems (NeurIPS 2021), Sydney, Australia.arXiv:2103.06624v2  [cs.LG]  31 Oct 2021We Ô¨Årst focus on complete veriÔ¨Åcation: the veriÔ¨Åer should give a deÔ¨Ånite ‚Äúyes/no‚Äù answer given sufÔ¨Åcient time. Many complete veriÔ¨Åers rely on the branch and bound (BaB) method [ 8] involving (1) branching by recursively splitting the original veriÔ¨Åcation problem into subdomains (e.g., splitting a ReLU neuron into positive/negative linear regions by adding split constraints) and (2) bounding each subdomain with specialized incomplete veriÔ¨Åers. Traditional BaBbased veriÔ¨Åers use expensive linear programming (LP) solvers [ 15,23,7] as incomplete veriÔ¨Åers which can fully encode neuron split constraints. Meanwhile, a recent veriÔ¨Åer, FastandComplete [ 45], demonstrates that cheap incomplete veriÔ¨Åers can signiÔ¨Åcantly accelerate complete veriÔ¨Åcation on GPUs over LPbased ones thanks to their efÔ¨Åciency. Many cheap incomplete veriÔ¨Åers are based on bound propagation methods [46,42,41,13,17,36,44], i.e., maintaining and propagating tractable and sound bounds through networks, and CROWN [ 46] is a representative which propagates a linear or quadratic bound. However, unlike LP based veriÔ¨Åers, existing bound propagation methods lack the power to handle neuron split constraints introduced by BaB. For instance, given inputs x;y2["
512,Deep Convolutional Decision Jungle for Image Classification.txt,"We propose a novel method called deep convolutional decision jungle (CDJ) and
its learning algorithm for image classification. The CDJ maintains the
structure of standard convolutional neural networks (CNNs), i.e. multiple
layers of multiple response maps fully connected. Each response map-or node-in
both the convolutional and fully-connected layers selectively respond to class
labels s.t. each data sample travels via a specific soft route of those
activated nodes. The proposed method CDJ automatically learns features, whereas
decision forests and jungles require pre-defined feature sets. Compared to
CNNs, the method embeds the benefits of using data-dependent discriminative
functions, which better handles multi-modal/heterogeneous data; further,the
method offers more diverse sparse network responses, which in turn can be used
for cost-effective learning/classification. The network is learnt by combining
conventional softmax and proposed entropy losses in each layer. The entropy
loss,as used in decision tree growing, measures the purity of data activation
according to the class label distribution. The back-propagation rule for the
proposed loss function is derived from stochastic gradient descent (SGD)
optimization of CNNs. We show that our proposed method outperforms
state-of-the-art methods on three public image classification benchmarks and
one face verification dataset. We also demonstrate the use of auxiliary data
labels, when available, which helps our method to learn more discriminative
routing and representations and leads to improved classification.","Random forests (RF) have been widely used for various computer vision problems, particularly on classification. RFs exhibit multiple inherent benefits from its tree structure: a complex classification problem is tackled in a hierarchical divideconquer manner, and their training and testing steps are computationally efficient. Its structural diversity also motivates an ensemble learning. Convolutional neural networks (CNNs) have been proven to achieve stateoftheart results in diverse problems. Its convolutional layers learn powerful features and fully connected layers and the last softmax layer serve as a classifier. Recently, several works [ 3,4,9,10,14,19,23,30,32] have attempted combining the two methods ( e.g.see Fig. 1a), for exploiting hierarchical treestructures [ 4,13,14,28], tackling multimodal data [30], clustering and learning modular networks per cluster [6, 19, 31, 32], and accelerating trainig and testing [ 9]. Also relevant to this study is to encourage sparsity in representation for regularization and efficiency in memory/time [ 3,10,12,23]. Our method can be seen as a new regularizer that enforces sparsity per data point in testing time. The priorworks aforementioned reported improved accuracy; however, there is room to improve especially in the following aspects: In the adopted binary tree structure [ 4,9,14,30], once a data sample goes in a wrong path, it cannot be recovered i.e.they overfit. Soft partitioning helps relieve the issue to a certain degree, however, ¬© 2018. The copyright of this document resides with its authors. It may be distributed unchanged freely in print or electronic forms. arXiv:1706.02003v2  [cs.CV]  18 May 20182 BAEK ET AL .: DEEP CONVOLUTIONAL DECISION JUNGLE exponentially growing recursive binary splits [ 9,30] remains as an issue. The decision jungle [ 24] type of algorithm becomes a natural extension for solving both and has shown good generalization ability. In another aspect, most existing methods for combining trees and CNNs [ 9,30] require additional model parameters: The split process is often performed by a separate routing network [ 30]. Often the network layers need to be shallower to solve the explosion of the number of model parameters [ 9]. To summarize, it is challenging to apply such methods to existing large/deep networks [ 16,26,27]. [14] applied the tree structure using big networks; however tree structure exists only in the last fully connected layers. Our aim is to propose a novel method that applies class entropy orpurity adopted from RFs to existing CNNs for more discriminative and interpretable representations in earlier layers and thus higher classification accuracy. The proposed architecture offers the following benefits: Classwise purity in early layers : Our method learns a convolutional neural network (CNN) with routing loss per layer. The proposed loss helps purify response maps, which we will call ‚Äònodes‚Äô, in all intermediate layers of CNNs. The response maps in each layer are pushed on or off conditionally on the input vectors such that each response map is dedicated to certain classes (ideally a class) than all. Note that the response maps for each data point take continuous values, thus this operation is treated as ‚Äòsoft‚Äô routing. We observe that the supervised purification by class labels leads to more discriminative intermediate representations and higher accuracies. Datadependent dynamic activation by the decision jungle structure: Combination of CNNs and RFs is to improve the capacity of the given CNNs [ 32] thanks to its datadependent discriminative functions. Compared to binary decision trees, the sample‚Äôs paths are recoverable in later layers in the fully connected decision jungle structure. The decision jungle has shown improved generalization over binary trees. Also, such a structure makes the method be more flexible (applicable to any existing CNNs not altering their original architectures) and memory efficient than the binary tree structures [24] by sharing multiple branches. More Interpretable CNNs : Several methods have been introduced [1, 2, 20, 34] to better under stand intermediate representations learnt in CNNs. [ 1] propose a linear classifier as a probe to observe the behavior of intermediate layers. They use the probe for the trained CNNs and have shown that the entropy is a good measure for information contained in each layer. Similar to this, we evaluate each layer‚Äôs discriminant power by the entropy measure. Further, we have an explicit mechanism to reduce the entropy in each layer by the gradient optimization. [ 2] propose a procedure for quantifying hidden layers‚Äô interpretabilty based on the alignment between individual hidden units and a set of semantic concepts evaluated on datasets. In the experiments (see Table 3), we demonstrate that our algorithm also significantly improves the interpretability from the baseline convolutional network architectures. Without additional routing parameters at testing : The proposed architecture learns routing using additional routing path (the right path of Fig. 1(b)) during the training phase. At testing, this path is not used, which keeps the complexity of the model same as the original CNN models. Existing methods [ 9] require explicitly building routing networks at both train/test phases or change of the network structure to use binary routing [ 30] where the number of parameters increases exponentially (see Fig. 1(a)). Encoding auxiliary information : Intermediate layers can be further purified by auxiliary labels (e.g. superclass labels or any other privileged information) in addition to the class labels. Experiments demonstrate significant accuracy improvements when using such auxiliary information. 2 Related work "
17,LGNN: A Context-aware Line Segment Detector.txt,"We present a novel real-time line segment detection scheme called Line Graph
Neural Network (LGNN). Existing approaches require a computationally expensive
verification or postprocessing step. Our LGNN employs a deep convolutional
neural network (DCNN) for proposing line segment directly, with a graph neural
network (GNN) module for reasoning their connectivities. Specifically, LGNN
exploits a new quadruplet representation for each line segment where the GNN
module takes the predicted candidates as vertexes and constructs a sparse graph
to enforce structural context. Compared with the state-of-the-art, LGNN
achieves near real-time performance without compromising accuracy. LGNN further
enables time-sensitive 3D applications. When a 3D point cloud is accessible, we
present a multi-modal line segment classification technique for extracting a 3D
wireframe of the environment robustly and efficiently.","Line segments provide rich information about a scene: creases are indications of foldings of pliable surfaces, occlusion boundary edges encode shape information, while textures manifest the appearance of regions. More importantly, they provide a more precise, com pact, and structural representation of a 3D scene. The detected linearXiv:2008.05892v2  [cs.CV]  29 Aug 2020segments further benefit numerous computer vision tasks, ranging from stereo matching [ 45] and 3D reconstruction [ 7,9,16,32,46] to image stitching [ 38] and segmentation [ 2,5]. Traditional tech niques [ 1,3,11,18,37,40] based on handcrafted features are vul nerable to textureless regions, repetitive textures, illumination vari ations, occlusions, etc. More recent deep learning approaches [ 17, 41,47,49] attempt to explore semantic meanings of line segments to mitigate the problems. Existing learningbased algorithms tackle the line detection prob lem via a predictthenverify strategy. Pioneering approaches [ 17, 41] first adopt a deep convolution neural network (DCNN) to pre dict junctions as well as a line heat map or an attraction field map. They then apply sophisticated fusion algorithms for extracting line segments. Such approaches commonly produce crossing or frag mented line segments that are difficult to fix or even differentiate. More recent methods, including PPGNet [ 47] and LCNN [ 49], first train a deep CNN to estimate a junction heatmap and then enumer ate all junction pairs to verify their connectivities. The verification step greatly improves line detection quality but is time and mem ory consuming and scales poorly with the number of junctions in an image. For example, on a Tesla P40 GPU, verification over 512 junctions in PPGNet [47] requires about a second. For many reallife line detection applications, it is critical to balance between speed and performance. In this paper, we propose a realtime line detector ‚Äî Line Graph Neural Network (LGNN). LGNN can reliably handle a cluttered environment by exploiting a strong contextual structure between line segments. Specifically, LGNN employs two main modules: a DCNN module for generating line segment positions and features and a graph neural network for reasoning their connectivities. We propose a novel quadruplet representation  (start junction, end junction, line central point, line shift vector)  for each line segment, in place of the traditional junctionjunction pairs. The DCNN sets out to predict a line central point heatmap along with a line shift vector map. We observe that, for cluttered scenes, the predicted line segments are less fragmented, where we can reliably map their endpoints to junctions. The GNN module then takes these line segment candidates as vertexes and construct a sparse graph to enforce structural constraints. Our LGNN significantly accelerates the detection speed without compromising accuracy. We show that LGNN achieves near real time performance. On the wireframe dataset [ 17], LGNN performs at 15.8 frames per second (FPS) with 62.3%structural AP (sAP) and a lightweight version achieves 34 FPS with 57.6%sAP. LGNN hence enables timesensitive 3D applications: when a 3D point cloud is accessible and we can map the predicted 2D line segments onto 3D to determine their types  creases, occlusion edges or texture edges. We therefore further present a multimodal edge classification tech nique for extracting a 3D wireframe of the environment robustly and efficiently. 2 RELATED WORKS "
117,Gated Graph Sequence Neural Networks.txt,"Graph-structured data appears frequently in domains including chemistry,
natural language semantics, social networks, and knowledge bases. In this work,
we study feature learning techniques for graph-structured inputs. Our starting
point is previous work on Graph Neural Networks (Scarselli et al., 2009), which
we modify to use gated recurrent units and modern optimization techniques and
then extend to output sequences. The result is a flexible and broadly useful
class of neural network models that has favorable inductive biases relative to
purely sequence-based models (e.g., LSTMs) when the problem is
graph-structured. We demonstrate the capabilities on some simple AI (bAbI) and
graph algorithm learning tasks. We then show it achieves state-of-the-art
performance on a problem from program verification, in which subgraphs need to
be matched to abstract data structures.","Many practical applications build on graphstructured data, and thus we often want to perform ma chine learning tasks that take graphs as inputs. Standard approaches to the problem include engineer ing custom features of an input graph, graph kernels (Kashima et al., 2003; Shervashidze et al., 2011), and methods that deÔ¨Åne graph features in terms of random walks on graphs (Perozzi et al., 2014). More closely related to our goal in this work are methods that learn features on graphs, including Graph Neural Networks (Gori et al., 2005; Scarselli et al., 2009), spectral networks (Bruna et al., 2013) and recent work on learning graph Ô¨Ångerprints for classiÔ¨Åcation tasks on graph representations of chemical molecules (Duvenaud et al., 2015). Our main contribution is an extension of Graph Neural Networks that outputs sequences. Previous work on feature learning for graphstructured inputs has focused on models that produce single outputs such as graphlevel classiÔ¨Åcations, but many problems with graph inputs require outputting sequences. Examples include paths on a graph, enumerations of graph nodes with desirable properties, or sequences of global classiÔ¨Åcations mixed with, for example, a start and end node. We are not aware of existing graph feature learning work suitable for this problem. Our motivating application comes from program veriÔ¨Åcation and requires outputting logical formulas, which we formulate as a sequential output problem. A secondary contribution is highlighting that Graph Neural Networks (and further extensions we develop here) are a broadly useful class of neural network model that is applicable to many problems currently facing the Ô¨Åeld. There are two settings for feature learning on graphs: (1) learning a representation of the input graph, and (2) learning representations of the internal state during the process of producing a sequence of outputs. Here, (1) is mostly achieved by previous work on Graph Neural Networks (Scarselli et al., 2009); we make several minor adaptations of this framework, including changing it to use modern practices around Recurrent Neural Networks. (2) is important because we desire outputs from graph structured problems that are not solely individual classiÔ¨Åcations. In these cases, the challenge is how Work done primarily while author was an intern at Microsoft Research. 1arXiv:1511.05493v4  [cs.LG]  22 Sep 2017Published as a conference paper at ICLR 2016 to learn features on the graph that encode the partial output sequence that has already been produced (e.g., the path so far if outputting a path) and that still needs to be produced (e.g., the remaining path). We will show how the GNN framework can be adapted to these settings, leading to a novel graphbased neural network model that we call Gated Graph Sequence Neural Networks (GGSNNs). We illustrate aspects of this general model in experiments on bAbI tasks (Weston et al., 2015) and graph algorithm learning tasks that illustrate the capabilities of the model. We then present an application to the veriÔ¨Åcation of computer programs. When attempting to prove properties such as memory safety (i.e., that there are no null pointer dereferences in a program), a core problem is to Ô¨Ånd mathematical descriptions of the data structures used in a program. Following Brockschmidt et al. (2015), we have phrased this as a machine learning problem where we will learn to map from a set of input graphs, representing the state of memory, to a logical description of the data structures that have been instantiated. Whereas Brockschmidt et al. (2015) relied on a large amount of handengineering of features, we show that the system can be replaced with a GGSNN at no cost in accuracy. 2 G RAPH NEURAL NETWORKS In this section, we review Graph Neural Networks (GNNs) (Gori et al., 2005; Scarselli et al., 2009) and introduce notation and concepts that will be used throughout. GNNs are a general neural network architecture deÔ¨Åned according to a graph structure G= (V;E). Nodesv2V take unique values from 1;:::;jVj, and edges are pairs e= (v;v0)2VV . We will focus in this work on directed graphs, so (v;v0)represents a directed edge v!v0, but we note that the framework can easily be adapted to undirected graphs; see Scarselli et al. (2009). The node vector (ornode representation ornode embedding ) for nodevis denoted by hv2RD. Graphs may also contain node labels lv2f1;:::;LVgfor each node vand edge labels or edge types le2f1;:::;LEg for each edge. We will overload notation and let hS=fhvjv2Sg whenSis a set of nodes, and lS=fleje2Sg whenSis a set of edges. The function IN(v) =fv0j(v0;v)2Eg returns the set of predecessor nodes v0withv0!v. Analogously, OUT(v) =fv0j(v;v0)2Eg is the set of successor nodesv0with edgesv!v0. The set of all nodes neighboring visNBR(v) =IN(v)[OUT(v), and the set of all edges incoming to or outgoing from visCO(v) =f(v0;v00)2Ejv=v0_v=v00g. GNNs map graphs to outputs via two steps. First, there is a propagation step that computes node rep resentations for each node; second, an output model ov=g(hv;lv)maps from node representations and corresponding labels to an output ovfor eachv2V. In the notation for g, we leave the depen dence on parameters implicit, and we will continue to do this throughout. The system is differentiable from endtoend, so all parameters are learned jointly using gradientbased optimization. 2.1 P ROPAGATION MODEL Here, an iterative procedure propagates node representations. Initial node representations h(1) vare set to arbitrary values, then each node representation is updated following the recurrence below until convergence, where tdenotes the timestep: h(t) v=f(lv;lCO(v);lNBR(v);h(t"
259,Combining Fact Extraction and Verification with Neural Semantic Matching Networks.txt,"The increasing concern with misinformation has stimulated research efforts on
automatic fact checking. The recently-released FEVER dataset introduced a
benchmark fact-verification task in which a system is asked to verify a claim
using evidential sentences from Wikipedia documents. In this paper, we present
a connected system consisting of three homogeneous neural semantic matching
models that conduct document retrieval, sentence selection, and claim
verification jointly for fact extraction and verification. For evidence
retrieval (document retrieval and sentence selection), unlike traditional
vector space IR models in which queries and sources are matched in some
pre-designed term vector space, we develop neural models to perform deep
semantic matching from raw textual input, assuming no intermediate term
representation and no access to structured external knowledge bases. We also
show that Pageview frequency can also help improve the performance of evidence
retrieval results, that later can be matched by using our neural semantic
matching network. For claim verification, unlike previous approaches that
simply feed upstream retrieved evidence and the claim to a natural language
inference (NLI) model, we further enhance the NLI model by providing it with
internal semantic relatedness scores (hence integrating it with the evidence
retrieval modules) and ontological WordNet features. Experiments on the FEVER
dataset indicate that (1) our neural semantic matching method outperforms
popular TF-IDF and encoder models, by significant margins on all evidence
retrieval metrics, (2) the additional relatedness score and WordNet features
improve the NLI model via better semantic awareness, and (3) by formalizing all
three subtasks as a similar semantic matching problem and improving on all
three stages, the complete model is able to achieve the state-of-the-art
results on the FEVER test set.","The explosion of online textual content with unknown in tegrity and veriÔ¨Åcation raises an important concern about misinformation such as fake news, sociopolitical decep tion, and online rumors. This problem of misinformation could potentially produce uncontrollable and harmful social impacts, thus stimulating recent research efforts on lever aging modern machine learning techniques for automatic Copyright c 2019, Association for the Advancement of ArtiÔ¨Åcial Intelligence (www.aaai.org). All rights reserved. 1Code: https://github.com/easonnie/combineFEVERNSMNClaim: Giada at Home was only available on DVD. [wiki/Giada atHome ] Giada at Home is a television show hosted by Giada De Laurentiis. ItÔ¨Årst aired onOctober18,2008 ontheFood Network. [wiki/Food Network ] Food Network isanAmer icanbasiccableandsatellitetelevi sion chan nel that is owned by Television Food Network, G.P., a joint venture and general partnership between Discovery, Inc. (which owns 70% of the network) and Tribune Media (which owns the remaining 30%). Label: Refutes Figure 1: Example of FEVER task. Given the claim, the system is required to Ô¨Ånd evidential sentences in the entire Wikipedia corpus and label it as ‚ÄúS UPPORTS ‚Äù, ‚ÄúR EFUTES ‚Äù, or ‚ÄúN OTENOUGH INFO‚Äù (Thorne et al. 2018). fact checking. The recent release of the Fact Extraction and VERiÔ¨Åcation (Thorne et al. 2018) (FEVER) dataset not only provides valuable fuel for applying datadriven neural ap proaches on evidence retrieval and claim veriÔ¨Åcation, but also introduces a standardized, benchmark task of the auto matic fact checking. In this FEVER shared task, a system is asked to verify an input claim with potential evidence in about 5 million Wikipedia documents, and label it as ‚ÄúSUPPORTS ‚Äù, ‚ÄúR EFUTES ‚Äù, or ‚ÄúN OTENOUGH INFO‚Äù if the evidence can support, refute, or not be found for the claim, respectively. Fig. 1 shows an example of the task. The task is difÔ¨Åcult in two aspects. First, accurate selection of poten tial evidence from a huge knowledge base, w.r.t. an arbitrary claim requires a thoughtful system design and results in a tradeoff between retrieval performance and computational resources. Moreover, even with ground truth evidence, the veriÔ¨Åcation subtask of predicting the relation between evi dence and the claim is still a longexisting open problem.2 In this work, we propose a joint system consisting of three connected homogeneous networks for the 3stage FEVER task of document retrieval, sentence selection, and claim veriÔ¨Åcation and frame them as a similar semantic matching 2The task is often termed as natural language inference (NLI).arXiv:1811.07039v1  [cs.CL]  16 Nov 2018problem. In the document retrieval phase, the correspond ing submodule selects documents from the entire Wikipedia corpus by keyword matching and uses a neural semantic matching network for further document ranking. In the sen tence selection phase, we use the same neural architecture trained with an annealed sampling method to select evi dential sentences by conducting semantic matching between each sentence from retrieved pages and the claim. Finally, we build a neural claim veriÔ¨Åer by integrating upstream se mantic relatedness features (from the sentence selector) and injecting ontological knowledge from WordNet into a sim ilar neural semantic matching network for natural language inference (NLI), and train it to infer whether the retrieved evidence supports or refutes the claim, or state that the evi dence is not enough to decide the correctness of the claim. Overall, our uniÔ¨Åed neuralsemanticmatching model for fact extraction and veriÔ¨Åcation, which includes a threefold contribution: (1) Unlike traditional IR methods e.g., TFIDF, in which queries and sources are matched in some vector space according to predesigned terms and precalculated weightings, we explore the possibility of using a neural se mantic matching network for evidence retrieval and show that by assuming no intermediate term representation, neu ral networks can learn their own optimal representation for semantic matching at the granularity of sentences and signif icantly outperform termweighting based methods. We also show that external Pageview frequency information can pro vide comparable and complementary discriminative infor mation w.r.t. the neural semantic matching network for doc ument ranking. (2) In contrast to previous work, in which upstream retrieved evidence are simply provided to down stream NLI models, we combined the evidence retrieval module with the claim veriÔ¨Åcation module, by adding se mantic relatedness scores to the NLI models, and further im prove veriÔ¨Åcation performance by using additional semantic ontological features from WordNet. (3) Rather than depend ing on structured machinefriendly knowledge bases such as Freebase (Bollacker et al. 2008) and DBpedia (Auer et al. 2007), we formalize the three subtasks as a similar tex tual semantic matching problem and propose one of the Ô¨Årst neural systems that are able to conduct evidence retrieval and fact veriÔ¨Åcation using raw textual claims and sentences directly from Wikipedia as input, and achieves the stateof theart results on the FEVER dataset, which could serve as a new neural baseline method for future advances on large scale fact checking. 2 Related Works "
245,Conceptor Learning for Class Activation Mapping.txt,"Class Activation Mapping (CAM) has been widely adopted to generate saliency
maps which provides visual explanations for deep neural networks (DNNs). The
saliency maps are conventionally generated by fusing the channels of the target
feature map using a weighted average scheme. It is a weak model for the
inter-channel relation, in the sense that it only models the relation among
channels in a contrastive way (i.e., channels that play key roles in the
prediction are given higher weights for them to stand out in the fusion). The
collaborative relation, which makes the channels work together to provide cross
reference, has been ignored. Furthermore, the model has neglected the
intra-channel relation thoroughly.In this paper, we address this problem by
introducing Conceptor learning into CAM generation. Conceptor leaning has been
originally proposed to model the patterns of state changes in recurrent neural
networks (RNNs). By relaxing the dependency of Conceptor learning to RNNs, we
make Conceptor-CAM not only generalizable to more DNN architectures but also
able to learn both the inter- and intra-channel relations for better saliency
map generation. Moreover, we have enabled the use of Boolean operations to
combine the positive and pseudo-negative evidences, which has made the CAM
inference more robust and comprehensive. The effectiveness of Conceptor-CAM has
been validated with both formal verifications and experiments on the dataset of
the largest scale in literature. The experimental results show that
Conceptor-CAM is compatible with and can bring significant improvement to all
well recognized CAM-based methods, and has outperformed the state-of-the-art
methods by 43.14%~72.79% (88.39%~168.15%) on ILSVRC2012 in Average Increase
(Drop), 15.42%~42.55% (47.09%~372.09%) on VOC, and 17.43%~31.32%
(47.54%~206.45%) on COCO, respectively.","VISUALIZATION approaches based on Class Activation Mapping (CAM) [1] have been widely employed to pro vide intuitive explanations to DNNs. CAMbased approaches visualize the importance of neurons of a certain DNN layer (usually the last layer of the feature maps) to the Ô¨Ånal decis ions by generating a saliency map according to the degrees of activation on these neurons regarding the weights, gradien ts, and/or their changes upon the DNN inferences. Representa tive approaches include GradCAM [2] which generates the saliency map by calculating the weighted average of a featur e map over its channels in which the weight of each channel has Guangwu Qian, and Yaowei Wang are with the Peng Cheng Laborat ory, Shenzhen, China ZhenQun Yang is with the Department of Biomedical Engineer ing, Chinese University of Hong Kong, Kowloon, Hong Kong XiaoYong Wei (email: cswei@scu.edu.cn) and XuLu Zhang a re with the College of Computer Science, Sichuan University, Chengdu 6 10065, China Qing Li and XiaoYong Wei are with the Department of Computin g, Hong Kong Polytechnic University, Kowloon, Hong Kongbeen obtained by average pooling the gradients with respect to the Ô¨Ånal decision. Another popular approach is the Score CAM [3] which obtains the channel weighs using the global contribution of the corresponding input features instead o f the locality sensitive measurements (e.g., the gradients). Despite the success of CAMbased approaches, we argue that the way of generating the saliency maps by fusing the activation evidences (e.g., gradients in GradCAM) ove r channels using the average pooling has neglected the nature of using ‚Äúcrossevidences‚Äù for inference in DNNs. That is, channels of a DNN are usually trained to respond to various types of evidences [4](i.e., intrachannel patterns such a s the skin colors, face shapes, or eyelids in a DNN for facial recognition tasks), on the basis of which the CNN model then learns the interchannel patterns by assembling these evid ences across channels synthetically. Therefore, the weighted av erage fusion used in conventional CAMbased approaches is not sophisticated enough to model the interchannel assemblin g. Furthermore, the singlevalued average of all the gradient s of a channel is far from adequate to model the intrachannel patterns (i.e., the relations among neurons of each channel ). Besides investigating the evidences from a channel perspec  tive, recent studies [5‚Äì7] have found that the CAM results can be improved by distinguishing the target (or positive) evidences from the nontarget (or negative) evidences. For example, Kim et al. has proposed a twostage learning method in [7] which in the Ô¨Årst stage, the CNN model has been trained to generate a saliency map with GradCAM and the map will be used as an indication of positive evidences for the infere nce (e.g., for recognizing a ‚Äúcar‚Äù object). In the second stage, the negative map will be generated by inverting the positive map and used as a mask applied to the original image, with which the network will be retrained with an inverted label (e.g., for recognizing the ‚Äúnoncar‚Äù region). The experime ntal results show that the Ô¨Ånal positive saliency map can focus more on the target region than that of conventional CAM based methods. However, the use of positive and negative evidences is based on heuristics, which is straightforward but not explicitly formulated. In this paper, we propose to address the aforementioned issues within a uniÔ¨Åed framework and in a formulated way by adopting the Conceptor learning [8, 9]. The Conceptor learn ing is a method that has been originally proposed by Jaeger [8] to learn the pattern of how the neuron states of a RNN model change over time, and the learned pattern (encapsulat ed in a Conceptor matrix C) can then be used to reproduce the future neuron states even with missing or incomplete inputs . As shown in Fig. 1, we will generate Conceptors to model the inter and intra channel relations and use them to synchron ize the channel vectors. The Conceptors can be learned from theIEEE TRANSACTIONS ON IMAGE PROCESSING 2 Conv 1 Conv 2 ‚Ä¶ Output YcFC Layers  Input Image XConvolutional Layers/Blocks Input   Output  Channel Contribution Weights  by Conventional CAMs The l th conv.  block/layer  ‚Ä¶ Weight Inverting  Weighted Channels as  Positive Evidence  Channels with Inverted  Weights as Pseudo Õ≤ negative Evidence Positive  Conceptor ‡°Ø Pseudo Õ≤negative  Conceptor ‡°Ø ‡¥•NOT  Complementary  Conceptor ‡°Ø◊õ=NOT( ‡°Ø ‡¥•)Comprehensive  Conceptor ‡°Ø ‡µÖ ‡°Ø ◊õSaliency Map Map Generation  positive evidence path pseudo Õ≤negative evidence path  Fig. 1. Conceptor Learning for Class Activation Mapping (CA M). Feature map at the lthblock/layer is Ô¨Årst fed into the conventional CAM methods to evaluate the channel contribution, with which the channel m aps are weighted and vectorized as the evidences for Concept or learning. This results in a positive Conceptor Cwhich has been encapsulated with the inter and intrachann el relations. In a similar way, the pseudonegative evidenc es can be generated for learning the pseudonegative Concepotr ¬ØCwhich will be inverted using the NOT operation to create a com plementary Conceptor that has interpreted the channel relation from a different point of view. The positiv e and complementary Conceptors are Ô¨Ånally fused to generate a saliency map which provides a more comprehensive visual explanation of the DNN inference . Note in the parachute example, the Conceptor learning can Ô¨Å x the false attention on the part between the person and the parachute (a typical result of the conventional CAMbased methods). positive and pseudonegative evidences separately and the n be fused to create more comprehensive saliency maps. By adopting the Conceptors into CAM learning, it brings forth several advantages as follows. ‚Ä¢Interchannel pattern modeling : We have released the dependence of Conceptor learning on RNN models, so that we can adopt the way for modeling the pattern among neuron states to model that of the channel states. This is straightforward when the channel states are converted into state vectors (see Section IIIB). ‚Ä¢Intrachannel pattern modeling : We will provide a formal veriÔ¨Åcation in Section IIIB2 to show that the Conceptor matrix Cindeed also models the patterns among the elements of a state vector, and therefore, using Cto reÔ¨Åne the state vectors will be more robust to noise because the new vectors have been generated with the reference to both inter and intrachannel relations. ‚Ä¢Boolean reasoning : It has been justiÔ¨Åed in [9] that Boolean operations are well deÔ¨Åned on Conceptors. It is thus more formulated and convenient to calculate or combine different evidences (e.g., positive or negative, target or nontarget) by using Boolean operations. We will show in Section IIID that Conceptor learning can be used to combine positive and pseudonegative evidences for a more comprehensive modeling of the CAM inference. II. R ELATED WORK "
502,Protecting the Intellectual Properties of Deep Neural Networks with an Additional Class and Steganographic Images.txt,"Recently, the research on protecting the intellectual properties (IP) of deep
neural networks (DNN) has attracted serious concerns. A number of DNN copyright
protection methods have been proposed. However, most of the existing
watermarking methods focus on verifying the copyright of the model, which do
not support the authentication and management of users' fingerprints, thus can
not satisfy the requirements of commercial copyright protection. In addition,
the query modification attack which was proposed recently can invalidate most
of the existing backdoor-based watermarking methods. To address these
challenges, in this paper, we propose a method to protect the intellectual
properties of DNN models by using an additional class and steganographic
images. Specifically, we use a set of watermark key samples to embed an
additional class into the DNN, so that the watermarked DNN will classify the
watermark key sample as the predefined additional class in the copyright
verification stage. We adopt the least significant bit (LSB) image
steganography to embed users' fingerprints into watermark key images. Each user
will be assigned with a unique fingerprint image so that the user's identity
can be authenticated later. Experimental results demonstrate that, the proposed
method can protect the copyright of DNN models effectively. On Fashion-MNIST
and CIFAR-10 datasets, the proposed method can obtain 100% watermark accuracy
and 100% fingerprint authentication success rate. In addition, the proposed
method is demonstrated to be robust to the model fine-tuning attack, model
pruning attack, and the query modification attack. Compared with three existing
watermarking methods (the logo-based, noise-based, and adversarial frontier
stitching watermarking methods), the proposed method has better performance on
watermark accuracy and robustness against the query modification attack.","Deep neural networks (DNN) have achieved signiÔ¨Åcant success in computer vision tasks such as image classiÔ¨Åcation, object detection, and face recognition. Furthermore, machine learning as a service (MLaaS) [1] provided by large compa nies, has also become a popular business paradigm. However, illegal users can pirate and abuse models, such as stealing pre trained deep learning models, and build pirated AI services [2]. In this way, the intellectual property (IP) of the model owner will be infringed. Protecting the intellectual properties of deepneural networks is a challenging task. The adversaries can take some measures to prevent the pirated models from being discovered by the model owner. For example, an adversary can tamper with the pirated DNN model with model Ô¨Åne tuning [3] or model pruning [4], thereby removing the potential watermark. Existing copyright protection methods [2], [5], [6], [7] use watermarking technique to protect the ownership of the model owner. The watermarks can be embedded in the parameters of the DNN, or constructed based on backdoor, and so on. For example, Uchida et al. [5] embed the watermark into the parameters of the deep neural network, but this method can only be applied in the whitebox scenarios. Adi et al. [7] proposed a DNN watermarking method based on the backdoor. Zhang et al. [2] proposed three backdoor based DNN watermarking methods. Merrer et al. [6] proposed an adversarial example based DNN watermarking method. These watermarking methods [2], [6], [7] can be used to perform ownership veriÔ¨Åcation remotely in the blackbox scenarios. However, most of the existing watermarking methods [2], [5], [6], [7] do not support the user‚Äôs identity authentication, thus are not suitable for practical commercial applications. In addi tion, a recent work [8] has shown that, watermarking methods such as logobased watermarking method and noisebased watermarking method are vulnerable to the query modiÔ¨Åcation attack. In the query modiÔ¨Åcation attack, the attacker employs an autoencoder to detect and modify the watermarked images, thereby invalidating the watermark veriÔ¨Åcation process of the model owner [8]. The autoencoder is a special deep neural network, which Ô¨Årst compresses the input images into the lowdimensional data, and then decompresses these low dimensional data as the output images [8]. As a result, the noise in input images can be removed. In this way, the logo or noise (i.e., watermark patterns) in watermark key samples can be removed by the query modiÔ¨Åcation attack. In this paper, we propose to embed the watermark in the DNN by using an additional class. We select a small number of clean images outside the original training dataset as the watermark key samples. Subsequently, a user‚Äôs Ô¨Ångerprint will be hidden in each watermark key sample. To embed the watermark, we Ô¨Årst assign a new class label to all the watermark key samples, and then add the watermark keyarXiv:2104.09203v1  [cs.AI]  19 Apr 2021samples to the training set to train a watermarked DNN. The trained DNN (i.e., the watermarked DNN) can output an extra class when a watermark key sample is input. Since we use clean images outside the training set as the watermark key samples rather than superimposing patterns on the im ages, the proposed watermarking method can resist the query modiÔ¨Åcation attack [8]. In order to support user‚Äôs Ô¨Ångerprint authentication, we use image steganography [9] to hide users‚Äô Ô¨Ångerprints in watermark key samples. SpeciÔ¨Åcally, we use the least signiÔ¨Åcant bit (LSB) [9] method to embed different users‚Äô Ô¨Ångerprints into different watermark key samples, and distribute a unique Ô¨Ångerprint image to each authorized user. The contributions of this paper are as follows: Adding an additional class to protect the copyright of DNN. We propose to embed the watermark into the DNN model by using an extra class. To verify the ownership, the model owner can input the watermark key sample to the DNN to trigger the additional class. Experimental results show that, the proposed method can achieve 100% watermark accuracy [2] on two FashionMNIST [10] and CIFAR10 [11] datasets without affecting the test accuracy of the model. Compared with the existing wa termarking methods [2], [6], the proposed watermarking method can obtain a higher watermark accuracy and is more robust to the query modiÔ¨Åcation attack [8]. Supporting user‚Äôs identity authentication. We hide the user‚Äôs Ô¨Ångerprint in the image by using the LSB [9] image steganography method. Users‚Äô Ô¨Ångerprints can be extracted to verify their identities for access control. Ex perimental results show that the Ô¨Ångerprint authentication success rate (FASR) of the proposed method is 100%. Meanwhile, the user‚Äôs Ô¨Ångerprint embedded in the image will not affect the image quality, as the mean squared error (MSE) [12] of steganographic images is only 0.044 (FashionMNIST) and 0.015 (CIFAR10), respectively. Robust to query modiÔ¨Åcation attack. In addition to be robust to model Ô¨Ånetuning and model pruning, the proposed watermarking method can also resist the query modiÔ¨Åcation attack [8]. Under the query modiÔ¨Åcation attack, the proposed watermarking method can still obtain 100% watermark accuracy on the LeNet5 [13] model and 85% watermark accuracy on the VGG16 [14] model, which are signiÔ¨Åcantly higher than the related works. As a comparison, the logobased watermarking method [2] only obtains 11% (LeNet5) and 15% (VGG16) watermark accuracy, the noisebased method [2] only obtains 14% (LeNet5) and 16% (VGG16) watermark accuracy, and the adversarial frontier stitching watermark ing method [6] obtains 91% (LeNet5) and 35% (VGG 16) watermark accuracy. II. R ELATED WORK "
472,Untargeted Backdoor Watermark: Towards Harmless and Stealthy Dataset Copyright Protection.txt,"Deep neural networks (DNNs) have demonstrated their superiority in practice.
Arguably, the rapid development of DNNs is largely benefited from high-quality
(open-sourced) datasets, based on which researchers and developers can easily
evaluate and improve their learning methods. Since the data collection is
usually time-consuming or even expensive, how to protect their copyrights is of
great significance and worth further exploration. In this paper, we revisit
dataset ownership verification. We find that existing verification methods
introduced new security risks in DNNs trained on the protected dataset, due to
the targeted nature of poison-only backdoor watermarks. To alleviate this
problem, in this work, we explore the untargeted backdoor watermarking scheme,
where the abnormal model behaviors are not deterministic. Specifically, we
introduce two dispersibilities and prove their correlation, based on which we
design the untargeted backdoor watermark under both poisoned-label and
clean-label settings. We also discuss how to use the proposed untargeted
backdoor watermark for dataset ownership verification. Experiments on benchmark
datasets verify the effectiveness of our methods and their resistance to
existing backdoor defenses. Our codes are available at
\url{https://github.com/THUYimingLi/Untargeted_Backdoor_Watermark}.","Deep neural networks (DNNs) have been widely and successfully deployed in many applications, for their effectiveness and efÔ¨Åciency. Arguably, the existence of highquality opensourced datasets ( e:g:, CIFAR10 [ 1] and ImageNet [ 2]) is one of the key factors for the prosperity of DNNs. Researchers and developers can easily evaluate and improve their methods based on them. However, these datasets may probably be used for commercial purposes without authorization rather than only the educational or academic goals, due to their high accessibility. Currently, there were some classical methods for data protection, including encryption, data water marking, and defenses against data leakage. However, these methods cannot be used to protect the copyrights of opensourced datasets, since they either hinder the dataset accessibility or functionality (e:g:, encryption), require manipulating the training process ( e:g:, differential privacy), or even have no effect in this case. To the best of our knowledge, there is only one method [ 3,4] designed for protecting opensourced datasets. SpeciÔ¨Åcally, it Ô¨Årst adopted poisononly backdoor attacks [ 5] to watermark the unprotected dataset and then conducted ownership veriÔ¨Åcation by verifying whether the suspicious model has speciÔ¨Åc targeted backdoor behaviors (as shown in Figure 1). The Ô¨Årst two authors contributed equally to this work. Correspondence to: Yang Bai and ShuTao Xia. 36th Conference on Neural Information Processing Systems (NeurIPS 2022).arXiv:2210.00875v3  [cs.CR]  5 Apr 2023BenignImagesPoisonedImages ProbabilityontheTargetClassùë∑""HypothesisTestùêª$:ùë∑&>ùë∑""Suspicious DNNProbabilityontheTargetClassùë∑& Figure 1: The veriÔ¨Åcation process of BEDW. PoisonedImagesDNNswithTargetedBackdoorWatermarksTargetLabelRandomLabelsDNNswithOurUntargetedBackdoorWatermarks Figure 2: The inference process of DNNs with different types of backdoor watermarks. In this paper, we revisit dataset ownership veriÔ¨Åcation. We argue that BEDW introduced new threatening security risks in DNNs trained on the protected datasets, due to the targeted manner of existing backdoor watermarks. SpeciÔ¨Åcally, the adversaries can exploit the embedded hidden backdoors to maliciously and deterministically manipulate model predictions (as shown in Figure 2). Based on this understanding, we explore how to design the untargeted backdoor watermark (UBW) and how to use it for harmless and stealthy dataset ownership veriÔ¨Åcation. SpeciÔ¨Åcally, we Ô¨Årst introduce two dispersibilities, including averaged samplewise and averaged classwise dispersibility, and prove their correlation. Based on them, we propose a simple yet effective heuristic method for UBW with poisoned labels ( i:e:, UBWP) and the UBW with clean labels ( i:e:, UBWC) based on bilevel optimization. The UBWP is more effective while the UBWC is more stealthy. We also design a UBWbased dataset ownership veriÔ¨Åcation, based on the pairwise Ttest [6] at the end. The main contributions of this paper are fourfold: 1)We reveal the limitations of existing methods in protecting the copyrights of opensourced datasets; 2)We explore the untargeted backdoor watermark (UBW) paradigm under both poisonedlabel and cleanlabel settings; 3)We further discuss how to use our UBW for harmless and stealthy dataset ownership veriÔ¨Åcation; 4)Extensive experiments on benchmark datasets verify the effectiveness of our method. 2 Related Work "
71,Virtual Thin Slice: 3D Conditional GAN-based Super-resolution for CT Slice Interval.txt,"Many CT slice images are stored with large slice intervals to reduce storage
size in clinical practice. This leads to low resolution perpendicular to the
slice images (i.e., z-axis), which is insufficient for 3D visualization or
image analysis. In this paper, we present a novel architecture based on
conditional Generative Adversarial Networks (cGANs) with the goal of generating
high resolution images of main body parts including head, chest, abdomen and
legs. However, GANs are known to have a difficulty with generating a diversity
of patterns due to a phenomena known as mode collapse. To overcome the lack of
generated pattern variety, we propose to condition the discriminator on the
different body parts. Furthermore, our generator networks are extended to be
three dimensional fully convolutional neural networks, allowing for the
generation of high resolution images from arbitrary fields of view. In our
verification tests, we show that the proposed method obtains the best scores by
PSNR/SSIM metrics and Visual Turing Test, allowing for accurate reproduction of
the principle anatomy in high resolution. We expect that the proposed method
contribute to effective utilization of the existing vast amounts of thick CT
images stored in hospitals.","Image diagnosis plays an important role in recent healthcare solutions. The qual ity of diagnostic images largely aects the quality of diagnosis. The images such as CT or MRI acquired in hospitals are normally stored in Picture Archiving and Communication Systems (PACS). Although thin slice images, with slice in tervals are about less than 1 mm, are frequently used for diagnosis, thick slice images with large slice intervals are used for long term storage to reduce the data size. However, the stored thick slice images do not have sucient resolution forarXiv:1908.11506v2  [eess.IV]  2 Sep 20192 A. Kudo et al. Fig. 1. Comparison of original thick image and the virtual thin image output generated by the proposed approach. On the left top row, the CT sagittal view of original thick image is blurred with each vertebrae bone being nearly indistinguishable, while they become clear in corresponding 8 super resolution image (Virtual Thin). Arbitrary size data, even the whole body shown on the right, is available for inputs and capable of reconstructing natural image regardless of body part. On the left bottom row, ne blood vessel are smoothly reconstructed in a volume rendering view. sagittal or coronal views, and also have limited applicability to 3D visualiza tion (volume rendering). To address this, we present a novel super resolution algorithm for CT images based on Generative Adversarial Networks (GAN). Our goal is to generate high resolution 3D images corresponding from the input thick slice images. We base our approach on adversarial training [5] and aim to generate realisticlooking highresolution CT images. One of the major dicul ties is that CT images can be very diverse ( e.g., imaged body part, voxel size, resolution, slice thickness, slice interval, etc), which can be dicult to synthesize with GANs. This diculty is due to a phenomena known as mode collapse, in which the model becomes only able to synthesize a small subset of the original training data and presents a signicant decrease in the output diversity [9]. We overcome this issue by additional conditioning of the discriminator on additional information, and use a three dimensional fully convolutional network to synthe size the high resolution CT images. Figure 1 shows example input thick images and the corresponding thin images synthesized by the proposed Virtual Thin Slice (VTS) method. The vertebrae bone structure is clearly reconstructed on the sagittal view, and ne blood vessels are reproduced well on the VR image. 2 Related work "
302,DeepDyve: Dynamic Verification for Deep Neural Networks.txt,"Deep neural networks (DNNs) have become one of the enabling technologies in
many safety-critical applications, e.g., autonomous driving and medical image
analysis. DNN systems, however, suffer from various kinds of threats, such as
adversarial example attacks and fault injection attacks. While there are many
defense methods proposed against maliciously crafted inputs, solutions against
faults presented in the DNN system itself (e.g., parameters and calculations)
are far less explored. In this paper, we develop a novel lightweight
fault-tolerant solution for DNN-based systems, namely DeepDyve, which employs
pre-trained neural networks that are far simpler and smaller than the original
DNN for dynamic verification. The key to enabling such lightweight checking is
that the smaller neural network only needs to produce approximate results for
the initial task without sacrificing fault coverage much. We develop efficient
and effective architecture and task exploration techniques to achieve optimized
risk/overhead trade-off in DeepDyve. Experimental results show that DeepDyve
can reduce 90% of the risks at around 10% overhead.","Machine learning with deep neural networks (DNNs) can produce results that have surpassed humanlevel performance in many chal lenging tasks lately, and it keeps improving. Consequently, DNNs ‚àóThese two authors contributed equally. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. CCS ‚Äô20, November 9‚Äì13, 2020, Virtual Event, USA ¬©2020 Association for Computing Machinery. ACM ISBN 9781450370899/20/11. . . $15.00 https://doi.org/10.1145/3372297.3423338have become one of the foundation techniques in artificial intelli gence (AI) applications. Lots of them (e.g., autonomous driving and medical image analysis) are safety and securitysensitive. Many researchers in the machine learning community believe that DNNs are rather robust to faults [ 10,22], wherein removing some neurons or parameters leads to a graceful degradation in model accuracy. However, practical faults do not manifest them selves as the elimination of individual weights or neurons. Instead, they lead to bitflips on DNN parameters or activations. Li et al. [ 23] conducted a case study on the Eyeriss DNN accelerator [ 4] under transient faults. Their results show that the FIT rate caused by random soft errors is far beyond the one required by the ISO 26262 standard (10 FIT1) [14] for the functional safety of road vehicles. Comparing to random errors, transient faults caused by malicious attacks are more severe. A recent attack named DeepHammer [44] shows that it can successfully tamper DNN inference behavior in practical setup, wherein the accuracy of multiple DNN classifica tion systems are reduced to be as low as random guess within a few minutes, by leveraging the rowhammer vulnerability of DRAM used in the system. There are a few recent research towards faulttolerant DNN sys tem designs. In [ 23], Li et al. proposed to set up a simple threshold to detect those faults that lead to drastic changes in DNN parame ters. Such symptombased error detectors have very little hardware overhead, but their detection capabilities are quite limited, espe cially for those quantized DNNs used in safetycritical embedded systems. They are also not applicable to defend against malicious faults [ 33,44,45]. To tackle this problem, a replicationbased error detection technique for DNN systems was proposed in [ 24], but its overhead is quite high, requiring 40% extra computation to reach 60% fault coverage on CIFAR10 dataset. This paper aims for a solution with sufficient fault coverage yet little overhead for DNNbased classification systems. The term dynamic verification was introduced in [ 1], which detects errors in a complex superscalar core by checking it with a core that is architecturally identical but microarchitecturally far simpler and smaller. Unlike symptombased error detection techniques that check for abnormal behaviors, dynamic verification techniques check for invariants in the system that are nearly always true over all possible executions. Following this idea, the proposed solution, namely DeepDyve , deploys a small neural network (referred to as thechecker DNN ) to approximate the original complex DNN model (referred to as the task DNN ), and checks whether they produce consistent outputs in an endtoend manner. If their results do not match, recomputation on the task DNN is performed for potential fault recovery, if any. 1FailureinTime Rate: 1 FIT = 1 failure per 1 billion hours.arXiv:2009.09663v2  [cs.LG]  16 Oct 2020Unlike [ 1], the result produced by the small checker DNN for error detection is only an approximate result. Hence, there will be both false positives (i.e., flagging nonexistent failures) and false neg atives (i.e., miss to report failures) with DeepDyve. False positives result in unnecessary recomputation cost, while false negatives lead to fault coverage loss. Consequently, it is essential to achieve high consistency between the task DNN and the checker DNN un der the faultfree situation. We formulate the checker DNN design problem as a design exploration problem, wherein we evaluate a set of candidate small DNN designs for the given big task DNN model and choose the one with optimized coverage/overhead tradeoff as the checker DNN. On the one hand, we obtain the set of candidate checker DNNs by compressing and transferring the task DNN model‚Äôs knowledge through knowledge distillation [ 11]. On the other hand, the given classification task might be too complicated for the much smaller checker DNNs. Under such circumstances, we allow the checker DNN to perform the classification task with reduced complexity. For example, given a task to classify ten objects wherein two kinds of objects are easily confused, we could allow the checker DNN to perform a simpler problem with these two objects treated as one class. By doing so, there will be much less false positives in dynamic verification, at the cost of more false negatives since we would not be able to identify those faults that result in misclsssification between these two kinds of objects. Consequently, we need to carefully perform task simplification for the checker DNN design to strike an optimized balance between coverage and overhead. From the safety and security perspective, misclassifying different classes often has quite different impacts. For example, in a traffic sign recognition system, misclassifying a ""Yield"" sign as a ""Stop"" sign does not cause much trouble, but the opposite misclassification may cause severe traffic accidents. We need to consider such risk impacts in the checker DNN design. That is, we should be more concerned about the risk/overhead tradeoff instead of coverage/overhead tradeoff. The proposed DeepDyve solution considers the above issues, and the main contributions of this paper include: ‚Ä¢To the best of our knowledge, DeepDyve is the first dynamic verification technique for resilient DNN designs, which uses a far simpler and smaller checker DNN for online error de tection and recovery. ‚Ä¢We propose a novel twostage checker DNN design method ology, which explores both the checker DNN architectures and task simplification possibilities. In particular, we propose a novel checker DNN architecture exploration technique with theoretical guarantees. Also, being able to manipulate the tasks performed on the checker DNN dramatically in creases the solution space of DeepDyve. ‚Ä¢DeepDyve leverages the uneven risk probabilities and safety impact among classes to guide the design exploration proce dure. Experimental results on CIFAR10, GTSRB, CIFAR100, and TinyImageNet datasets show that it can reduce up to 90% of the risks at around 10% computational overhead. We organize the remainder of this paper as follows. Section 2 presents the preliminaries and motivation of this work. Then, we give an overview of DeepDyve in Section 3. Next, we detail thechecker DNN architecture exploration and task exploration tech niques in Section 4 and 5, respectively. Experimental results are presented in Section 6. Then, we discuss the applications and limi tations of DeepDyve in Section 7, followed by the survey of related works in Section 8. Finally, Section 9 concludes this paper. 2 PRELIMINARIES AND MOTIVATION In this section, we first present the impact of hardware faults (ran dom or malicious) on the reliability and security of DNN systems in Section 2.1. Then, we provide the threat model in Section 2.2. At last, we illustrate the motivation for the proposed DeepDyve solution in Section 2.3. 2.1 DNN Systems under Faults There are mainly two types of attacks during the inference of DNN systems: adversarial example attack and fault injection attack. Ad versarial example attacks [ 9,28] try to fool DNN systems by crafting subtle malicious perturbations on inputs, and there is a vast body of research on this topic [ 20,27,31,32]. By contrast, fault injection attack aims to break the system by injecting faults into the inter nal system execution pipeline, e.g., flipping data bits in processing elements. This problem is less explored in the literature, and the overhead of existing defense techniques is quite high. Various types of transient faults can be introduced into DNN sys tems by attackers, e.g., clock glitch attack [ 30], voltage glitch attack [36], and rowhammer attack [ 17]. Besides malicious faults, tran sients faults could also occur due to environmental perturbations such as alpha particle strikes. The Impact of Transient Faults. Transient faults may occur at the data paths and buffers of processing units [ 23] or inside the memories of DNNbased systems [ 12]. Such faults would man ifest themselves as errors in DNN calculations or intermediate values [ 34] during inference. A failure occurs when errors prop agate to the outputs of the system and cause behavioral changes, which could lead to catastrophic consequences in safetycritical applications, e.g., misclassifying a ""Stop"" sign as a ""Yield"" sign in au tonomous vehicles and taking the wrong action. In the following, if not specified, faults, errors and failures are used in an exchangeable manner, and we are only concerned with those faults that cause misclassifications. Existing Attacks. Recently, DNNs are shown to be vulnerable to fault injection attacks [ 26]. In [ 12], the authors estimated that 40‚Äì50% of the parameters in a DNN model could lead to an ac curacy drop greater than 10% when bitflips occur in their data representation. While it was shown that quantized DNNs are more resilient to fault injection attacks, the recent progressive BitFlip Attack (BFA) [ 33] proposed by Rakin et. al. can reduce the accuracy of a quantized ResNet18 from 68.9% to 0.1% with only 13 bitflips. BFA combines gradient ranking and progressive search to identify those vulnerable bits that degrade model accuracy significantly when flipped. The followup work DeepHammer by Yao el al. [44] proves the effectiveness of BFAs in practice, by rowhammering against various real DNN systems. Existing Defenses. For DNNs implemented on floatingpoint machines, only a small fraction of the dynamic range provided by50 60 70 80 90 100 110 120 130 avtivation values020406080100frequencybenign failureFigure 1: Comparison of the maximum activation value be tween benign and failure cases (because of fault attack) from a quantized (8bit integer) classifier. the data type is used. If a fault makes the magnitude of intermediate output values huge, it is likely to lead to a failure. Based on this ob servation, Li et al. proposed to use a simple threshold to detect those faults that lead to intermediate outputs beyond it [ 23]. To be specific, before deployment, they record the value ranges (ùëãùëöùëñùëõ,ùëãùëöùëéùë•)of the output for each layer. After deployment, the output value range is then checked in the runtime. They consider a fault is detected if there are output values beyond the range (1.1√óùëãùëöùëñùëõ,1.1√óùëãùëöùëéùë•). This anomaly detector has very little hardware overhead, but its detection capabilities are quite limited, especially for recent attacks on quantized DNN systems. We show an example in Figure 1 where the thresholdbased anomaly detector fails to detect faults in quan tized classifiers. For the threshold detector to detect faults, at least the maximum activation value should be beyond the normal range. However, our experiment shows that the maximum activation val ues from all failure cases (due to hardware fault) are not bigger than the normal boundary. Liet al. [24] design a replicationbased error detection technique for deep neural networks. However, their overhead is quite high. They spend 40% overhead to reach 60% fault coverage on CIFAR10. In the DeepHammer work [ 44], the authors discuss a few potential mitigation techniques but do not provide any quantitative results for their effectiveness. 2.2 Threat Model In this work, we consider the attacker is trying to compromise the accuracy of a DNN system by maliciously injecting faults into it. Unlike crafting malicious inputs to fool DNN systems, we target faults presented in the system internals, i.e., processing elements, buffered weights, and intermediate values stored in onchip buffers or memories, and so on. We consider the attacker succeeds if the model‚Äôs output class is different from the one obtained in an attack free environment. We assume the attackers have full knowledge of the DNN and its deployment on the device, including neural network topology, parameters, and lowlevel implementation details, e.g., the position of intermediate values stored in memories. Weak attackers couldTable 1: A Motivational example. Checker DNN Size Accuracy Computational Overhead A 1% 80% ‚àº21% B 5% 92% ‚àº13% C 10% 94% ‚àº16% launch random bitflips, while for strong attackers, they can pre cisely locate and launch fault injection in the processing pipeline. Moreover, we assume the same transient faults would not occur in consecutive DNN inference runs. Firstly, reliability threats rarely occur and the probability to occur repeatedly in a short period is negligible. Secondly, it is very difficult, if not impossible, to launch the same faults repeatedly in a DNN system. For example, in [ 44], launching a rowhammer attack requires long preparation time (several minutes). As long as the DNN inference time is short (and usually it is), attackers do not have sufficient time to launch the same attack in the second run. 2.3 Motivation For any classification problem, there could be many DNN models with different size/accuracy tradeoffs to solve it. Although big models often have higher accuracy, many inputs can be correctly handled by small models. Therefore, we could employ a smaller checker DNN to perform the same task, and they should output the same results in most cases when faults do not occur. In this way, the task model can be dynamically verified for online error detection and recovery. Note that, it is not possible to achieve deterministic dynamic verification for such systems because the outputs of a simple model cannot achieve 100% consistency with that of the original model. As discussed earlier, because the checker DNN is less accurate, there will be false positives and false negatives. Generally speaking, the larger the checker DNN is, the more accurate it is [ 40], but it does not necessarily lead to larger computational overhead. We use the following example to illustrate the impact of checker DNN design. Suppose the task DNN model is with ‚àº100% accuracy, and there are three candidate checker DNN models: A, B, and C. Their relative sizes compared to the task DNN and their classification accuracy are shown in the second and the third column of Table 1. Consider transient faultinduced failures are rare events, the computational overhead of the three models is estimated in the fourth column, which is the sum of the computational cost of the checker DNN itself (as it is always on) and the recomputation cost on the task DNN when the checker DNN produces a different classification result (false positive cases). If the misclassifications caused by faults are evenly distributed among all classes, the fault coverage would be similar to the ac curacy of the checker DNN. For this particular example, checker B can achieve‚àº92% fault coverage with 5% hardware cost and ‚àº13% computational cost, which significantly outperforms existing faulttolerant solutions for DNN designs. This has motivated the proposed DeepDyve solution in this paper. In practice, faultinduced misclassifications are usually not evenly distributed. Moreover, misclassifying different classes often haveOutputConvInputConv filterConvOutputComparatorOriginal DNNChecker DNN NoRecomputeYesAccept (a) Architecture overviewArchitecture Exploration(b) Design stagesTask Exploration1.0x0.8x0.5xCandidate Checker DNN modelsOriginal DNNInit.Checker DNN Candidate Architecture GenerationArchitecture Selection Checker DNNCandidate TasksNclass(N1)class(N2)classTask SelectionCandidate Task GenerationInitial Checker DNN Figure 2: DeepDyve architecture and the design flow. different risk implications for safetycritical systems. Therefore, for any possible checker DNN, we need to consider the risk impact and apply fault simulation to evaluate its effectiveness. This is a timeconsuming process. Therefore, the critical challenge is how to efficiently explore the solution space of all possible checker DNN designs to find the one with an optimized risk/overhead tradeoff. 3 DEEPDYVE OVERVIEW Figure 2 (a) depicts the proposed DeepDyve architecture. It con tains three parts: the original network, the checker DNN, and the comparator. The checker DNN is a smaller and simpler DNN model which approximates the original network and the original task. An input instance is processed by both of the two models. Their outputs are checked by the comparator and accepted if consistent. Otherwise, the input instance is subject to a recomputation by the original model, and the new prediction is accepted, regardless of whether the two model outputs are consistent or not. Design Goals. We first formally define the evaluation metrics (e.g. coverage and overhead). We evaluate the cost of checker DNN design by the introduced overhead. The overhead of the checker DNNs can be calculated as follows: ùëÇ(ùëÜ)=ùëùùëéùëüùëéùëöùë† ùë†ùëöùëéùëôùëô ùëùùëéùëüùëéùëöùë† ùëèùëñùëî, (1) ùëÇ(ùê∂)=ùêπùêøùëÇùëÉ(ùëõùëíùë°ùë†ùëöùëéùëôùëô)+( 1‚àíùëÉùëêùëúùëõùë†ùëñùë†ùë°ùëíùëõùë°)√óùêπùêøùëÇùëÉ(ùëõùëíùë°ùëèùëñùëî) ùêπùêøùëÇùëÉ(ùëõùëíùë°ùëèùëñùëî),(2) ùëÇ(ùëÜ)andùëÇ(ùê∂)stand for the storage overhead and computational overhead, respectively, wherein ùëùùëéùëüùëéùëöùë† stands for the storage re quirement of model parameters with unit of Mega Bytes ( ùëÄùêµ), and ùêπùêøùëÇùëÉ function calculates the number of multiplyaccumulation operations in the network. The computational overhead contains two parts: FLOP of the small network (static overhead) and the recomputation overhead (dynamic overhead) when the small net work output is different from that of the big one (with probability 1‚àíùëÉùëêùëúùëõùë†ùëñùë†ùë°ùëíùëõùë° ). The detection ability of DeepDyve is characterized by the cover age rate. A popular definition of fault coverage would be number of classification failures detected among all misclassifications caused by faults, as show in in Equation 3. ùê∑ùêπùëñ,ùëóstands for the detected failures misclassified from class ùëñto classùëó, andùëáùêπùëñ,ùëódenotes the total failures from class ùëñto classùëówhen faults occur. To take thedifferent risk impact of different failures on safetycritical applica tion into consideration, we introduce a new metric called weighted coverage , abbreviated as ùëäùê∂ùëúùë£. in Equation 4. ùêºùëñ,ùëóis the risk impact if classùëñis misclassified into class ùëó, which will be defined later in this Section. Note that ùê∂ùëúùë£. is a special case of ùëäùê∂ùëúùë£. when all misclassifications have the same risk impact. In later text, we use coverage and weighted coverage interchangeably and they both refer to weighted coverage if not specified. ùê∂ùëúùë£. =√ç ùëñ ùëóùê∑ùêπùëñ ùëó√ç ùëñ ùëóùëáùêπùëñ ùëó. (3) ùëäùê∂ùëúùë£. =√ç ùëñ ùëóùê∑ùêπùëñ ùëó√óùêºùëñ ùëó√ç ùëñ ùëóùëáùêπùëñ ùëó√óùêºùëñ ùëó,‚àÄùëñ,ùëó‚ààùëÅandùëñ‚â†ùëó. (4) Design Stages. Under the guidance of the design goals, there are mainly two stages in designing of the checker DNN and we show them in Figure 2 (b). The first stage is architecture exploration, where we initialize the architecture of the checker DNN. Given a task model, a pool of checker DNN candidates with the same task of the given model are generated with model compression techniques. Then, one of them is picked from the pool by evaluating their over head and fault coverage, detailed in Section 4. The second stage is task exploration, where we try to manipulate the classification tasks performed by the checker DNN to achieve better coverage/overhead tradeoff. That is, we can find a better solution by providing more design options at the task level, detailed in Section 5. To solve the above design exploration problems, we define the following three matrices: ‚Ä¢Risk impact matrix I‚ààRN√óN. In safetycritical DNN appli cations, the risk impact of different misclassifications may vary significantly from the system perspective. Each entry inIdenotes the cost of the corresponding misclassification (the larger the value, the higher the cost). As the actual risk impact depends on the application, the values in the impact matrix should be carefully determined by system designers. ‚Ä¢Risk probability matrix R‚ààRN√óN, where the entry ùëÖùëñùëóde notes the probability that the ùëñth class is misclassified to ùëóth class when faults occur, and ùëÅdenotes the total number of classes. Risk probability matrix is obtained from fault in jection experiments. Figure 3 shows an example of Rdrawn from CIFAR10 dataset by performing random fault injection on VGG16 for 400,000 times. From this example, we canPredicted Label 0.00 0.04 0.48 0.20 0.08 0.07 0.26 0.04 0.31 0.13 0.23 0.00 0.00 0.00 0.00 0.00 0.00 0.02 0.33 0.43 0.76 0.00 0.00 0.21 0.15 0.15 0.25 0.26 0.05 0.01 0.19 0.00 0.19 0.00 0.32 1.00 0.62 0.53 0.21 0.10 0.02 0.00 0.11 0.14 0.00 0.12 0.26 0.04 0.08 0.00 0.38 0.00 0.09 0.85 0.32 0.00 0.04 0.48 0.02 0.00 0.03 0.00 0.34 0.24 0.13 0.10 0.00 0.00 0.01 0.00 0.16 0.00 0.14 0.39 0.48 0.17 0.00 0.00 0.01 0.00 0.75 0.23 0.04 0.05 0.03 0.05 0.01 0.00 0.00 0.31 0.10 0.60 0.02 0.20 0.07 0.10 0.00 0.00 0.14 0.00 planecar bird catdeer dog froghorseship truck 0.00.20.40.60.81.0True LabelFigure 3: An example of risk probability matrix obtained from CIFAR10 (normalized for visualization). observe faultinduced misclassifications are far from evenly distributed. ‚Ä¢Inconsistency matrix C‚ààRN√óN, wherein each entry ùê∂ùëñùëó denotes the probability that one sample is labeled as ùëñth class by the task model while is labeled as ùëóth class by the small model in DeepDyve. Note that entry ùê∂ùëñùëñ,ùëñ‚àà[1..ùëÅ] equals to zero. In practice, some classes are naturally more difficult to classify (e.g., dogandcatin the CIFAR10 dataset) than others. These difficult classes cause more inconsistency than the easy ones. Combining them as one class (e.g., as pet) in the checker DNN is relatively easy to achieve high consistency. Risk impact matrix Iwill be used in calculating weighted cover age. Besides, the three matrices I,RandCwill be all used in task exploration, wherein we try to combine those classes that are easily confused yet have less risk for task simplification. 4 ARCHITECTURE EXPLORATION The objective of the architecture exploration procedure is to find a initial checker DNN model that achieves good fault coverage with low overhead defined in Section 3. To this end, firstly, we generate a pool of checker DNN candidates. The generation process is try ing to minimize the overhead with the help of model compression techniques proposed in [ 13], detailed in Section 4.1. Second, as dif ferent candidates offer different tradeoffs between overheads and coverage, we illustrate how to efficiently search for an appropriate checker DNN design from the candidates in Section 4.2. 4.1 Checker DNN Candidate Generation In DeepDyve, the consistency between predictions of the checker DNN and those of the original DNN decides the computational overheadùëÇ(ùê∂). Consider an input that is misclassified by the original DNN when no faults occur, we would like to have the checker DNN output the same wrong label, so that DeepDyve does not flag a nonexistent failure, avoiding unnecessary recomputation. To improve consistency, given the task DNN model, we use model compression to generate the checker model candidates. Specifically,Table 2: ResNet10 with different width multiplier. ùõº Accuracy(%) O(S) (MB) O(C) (GFLOPs) 1.0 97.54 1.23 0.06 0.7 96.94 0.60 0.03 0.5 96.20 0.31 0.02 0.3 95.75 0.12 0.01 we use two types of model compression techniques. First, we use architecture compression to search for the potential architectures and then we use knowledge distillation to train our checker DNN. Architecture Compression. No doubt to say, the amount of available design choices has a significant impact on any design exploration problem. In order to increase the design options for DeepDyve, we adopt the model compression approach in [ 13] to make the size of checker DNNs adjustable. To be specific, given the task DNN architecture, we use a single width multiplier ùõºto adjust it, by uniformly scaling down the number of channels (or neurons if it is a linear layer) for each layer. For example, a feature map with 100 channels will be scaled down to the one with ten channels with ùõºbeing set to 0.1. By applying width multiplier, the resulting model architecture has much less overhead. We take one of popular architectures‚ÄîResNet trained on GT STB [ 39] as a case study to show the effect of width multiplier. Table 2 lists the accuracy, the storage overhead (in MegaByte) and the computational overhead (in Giga Floating Point Operations) of ResNet10 with different width multipliers. The first row stands for the original ResNet10. As can be observed, accuracy drops smoothly with smaller model size and less computational cost. Parameter Training. To further improve the consistency be tween the task DNN and the checker DNN, we use knowledge distil lation to train the checker DNN. Knowledge distillation, formulated by Hinton et al. [11], is a training solution to distill a task model (teacher model) and transfer knowledge to a simpler model (student model). In our training, the first step of knowledge distillation from the task DNN is to covert the presoftmax logits, ùëßùëñ, computed for each class into a probability, ùëùùëñ, by Equation 5 with the temperature ùëá. ùëùùëñ=ùëíùë•ùëù(ùëßùëñ/ùëá)√ç ùëóùëíùë•ùëù(ùëßùëó/ùëá)(5) With higher temperature, the new targets for the checker DNN to learn are ‚Äòsofter‚Äô probability distributions over classes. Next, the checker DNN is trained by minimizing the knowledge distillation loss ( ùêøùêæùê∑), which is defined as: ùêøùêæùê∑=ùúÜùëá2√óùê∂ùëüùëúùë†ùë†ùê∏ùëõùë°ùëüùëúùëùùë¶(ùëÉùëá ùê∂,ùëÉùëá ùëÇ) +(1‚àíùúÜ)√óùê∂ùëüùëúùë†ùë†ùê∏ùëõùë°ùëüùëúùëùùë¶(ùëÉùê∂,ùë¶ùë°ùëüùë¢ùëí),(6) whereinùëÉùëá ùê∂andùëÉùëá ùëÇare the softened outputs of the checker DNN and the original DNN under the same temperature ùëá. The first component of ùêøùêæùê∑forces the checker DNN towards approximating similar output distribution of the original DNN (i.e., consistency), whereas the second component of ùêøùêæùê∑forces the checker DNN towards correctly classifying inputs as usual (i.e., accuracy). We use ùúÜto tune the weighted average between the kinds of losses.ùêàB,C: 0.14+0.06 =0.20 ùêàùêàC,E: 0.01+0.02 =0.030 0.06 0.21 0.06 0.04 0.06 0 0 0.31 0.07 0.21 0 0 0.10 0 0.06 0.31 0.10 0 0.15 0.04 0.07 0 0.15 0 0.85 0.02 0 0.08 0.05 0.01 0.90 0.06 0.02 0.01 0.06 0.14 0.74 0.04 0.02 0.01 0 0.03 0.95 0.01 0.05 0.04 0.01 0.03 0.87A B C D E A B C D E ‡¥•ùëπùêà ùêàùêà Index ListA B C D E A B C D E ùë™ùêà ùêà ùêàùêàùêàùêà Step 10 0.27 0.06 0.04 0.27 0 0.41 0.07 0.06 0.41 0 0.15 0.04 0.07 0.15 0 0.85 0.02 0.08 0.05 0.04 0.92 0.03 0.01 0.01 0.03 0.95 0.01 0.05 0.05 0.03 0.87(B,C)Index List ùêàA,E: 0.05+0.05 =0.1Merge B and C Merge A and E0 0.34 0.21 0.34 0 0.41 0.21 0.41 0 0.91 0.04 0.05 0.05 0.92 0.03 0.02 0.03 0.95 Step 3(A,E) (B,C) D (A,E) (B,C) Dùêà (A,E) (B,C) D (A,E) (B,C) Dùêàùêà Index List IA,D,E: 0.05+0.02 =0.07Merge (A, E) and DA (B,C) D E A (B,C) D Eùêà ‡¥•ùëπ Step 2A D E A (B,C) D Eùêàùêà ùë™‡¥•ùëπ ùë™A B C D EB, CA, EA, D, EA, B, C, D, E K = 4‚ü∂A, (B, C), D, E K = 5‚ü∂A, B, C, D, EK = 3‚ü∂(A, E), (B, C), DK = 2‚ü∂(A, D, E), (B, C) (a) Clustering procedure (b) Generated dendrogram Figure 4: An illustrative example of agglomerative class clustering. 4.2 Search Strategy Our search strategy is based on the empirical observation that the consistency between the two models in DeepDyve is related to the multiplierùõºused to generate the small checker DNN ( ùõº<<1). Here we formally define the consistency function ofùõºby: Definition 1. Letùëîùë°(x)andùëîùõº(x)be the task DNN model and the checker DNN model generated from the task DNN with a multiplier ùõº. Each model ùëîtakes a vector of input xand outputs a class of ùë¶‚àà (0..ùëÅ‚àí1), whereùëÅis the number of classes. We define the consistency function as the probability that the outputs are consistent over the input space X. ùëì(ùõº)=ùëÉ(ùëîùë°(x)=ùëîùõº(x)),x‚ààX (7) We choose a simple function with the form of ùëì(ùõº)=‚àíùëé ùõº+ùëèto approximate the consistency function. In this function, ùëéandùëèare positive parameters whose values can be obtained via curve fitting after collecting a number of checker DNN models with different ùõºand the corresponding consistency values. Besides, because 0‚â§ ùëì(ùõº)‚â§1and0<ùõº‚â§1, we can obtain the valid range of ùõº, which isùëé ùëè‚â§ùõº‚â§1. Onceùëéandùëèare known, we have the following theorem: Theorem 4.1. Supposeùëì(ùõº)is approximated with ‚àíùëé ùõº+ùëè, when ùëé>0,ùëè>0, andùëé ùëè‚â§ùõº‚â§1. We can find an optimal ùõº=3‚àöÔ∏É ùëé 2where the computational overhead ùëÇ(ùê∂)is minimized. Proof. First, for a neural network composed of linear and con volutional layers, the FLOPs of the checker DNN with a multiplier ùõºisùõº2times the original FLOPs. Recall that the number of floating point operations (FLOPs) for one linear layer can be estimated by: 2√óùêº√óùëÇ (8) whereùêºandùëÇare number of input and output neurons in one linear layer, respectively. Therefore, the FLOP of a compressed linear layer with multiplier ùõºis: ùõº2√ó(2√óùêº√óùëÇ) (9)Similarly, for a convolutional layer, the floating point operations with multiplier ùõºis estimated by: (2√óùëò2√óùê∂ùëñùëõ)√ó(ùêªùëúùë¢ùë°√óùëäùëúùë¢ùë°√óùê∂ùëúùë¢ùë°) (10) whereùëòstands for the kernel size, and ùê∂ùëñùëõ,ùê∂ùëúùë¢ùë°stands for number of input and output channels, respectively. ùêªùëúùë¢ùë°andùëäùëúùë¢ùë°are the height and the width of the output tensors. Given this, the FLOP of a compressed convolutional layer with multiplier ùõºis: ùõº2√ó(2√óùëò2√óùê∂ùëñùëõ)√ó(ùêªùëúùë¢ùë°√óùëäùëúùë¢ùë°√óùê∂ùëúùë¢ùë°). (11) Hence, if we add all layers together, the final FLOPs of the checker DNN will be ùõº2times of the task model where ùõº=1. Providing this, the computational overhead of DeepDyve with the checker DNN can be simplified from Equation 2 to Equation 12. ùëÇ(ùê∂)=ùõº2+(1‚àíùëì(ùõº)),ùõº‚àà(0,1] (12) ùëÇ(ùê∂)=ùõº2+(1+ùëé ùõº‚àíùëè),ùõº‚àà(0,1],ùëé>0,ùëè>0, (13) ‚àáùëÇ(ùê∂)=2ùõº‚àíùëé ùõº2,ùõº‚àà(0,1],ùëé>0 (14) Let‚àáùëÇ(ùê∂)=0,thenùõº=3‚àöÔ∏Çùëé 2(15) To find the optimal point, we calculate the gradient of ùëÇ(ùê∂) as Equation 14. By letting the gradient equals to 0, we obtain the optimal point of ùõº, which is3‚àöÔ∏É ùëé 2, as shown in Equation 15. ‚ñ° Therefore, to obtain the optimal ùõº, we are going to fit the con sistency function‚àíùëé ùõº+ùëèwith the given candidate pool. After that, we select the checker DNN with ùõº=3‚àöÔ∏É ùëé 2. 5 TASK EXPLORATION After the initial checker architecture is fixed, DeepDyve performs task exploration to achieve better risk/overhead tradeoff. In Sec tion 5.1, we first discuss how to perform task simplification effi ciently under the guidance of risk probability matrix R, risk impact matrix Iand inconsistency matrix C. The first step generates abunch of different tasks. Then, we detail the search strategy to select the best task in Section 5.2. Algorithm 1: Agglomerative class clustering Input: Risk matrix R, inconsistency matrix C, No. of classes ùëÅ, class labels ùêø Output:(ùëÅ‚àí2)cluster label lists /* Initialize */ 1ùëò=ùëÅ‚àí1; 2ùëêùëéùëõùëëùëñùëëùëéùë°ùëíùêøùëñùë†ùë° =[]; 3forùëû=1,2,...,ùëÅ do 4ùê∫ùëû=ùëôùëû; // Cluster with single class 5ùúÜùëû=ùëû; // Initialize cluster label 6end 7whileùëò‚â•2do /* Select clusters based on two criteria */ 8ùëñùëõùëëùëíùë•ùêøùëñùë†ùë° =allarg minùëñ,ùëóùê∂ùëÇùëâùëôùëúùë†ùë†(ùëñ,ùëó)inR; 9(ùëõ,ùëö)=arg maxùëñ,ùëóùëÇùë†ùëéùë£ùëí(ùëñ,ùëó)inùëñùëõùëëùëíùë•ùêøùëñùë†ùë° ; /* Update cluster label list, matrices */ 10 Mergeùê∫ùëõandùê∫ùëö, Update clusters{ùê∫}andùùÄ; 11 Update R,C; /* Add cluster label list to candidates */ 12ùëêùëéùëõùëëùëñùëëùëéùë°ùëíùêøùëñùë†ùë°[ùëò]=ùùÄ; 13ùëò=ùëò‚àí1; 14end 15returnùëêùëéùëõùëëùëñùëëùëéùë°ùëíùêøùëñùë†ùë° ; 5.1 Agglomerative Class Clustering Given the original ùëÅclass task, our problem is to find a simpli fiedùêæclass task for any given checker DNN with better over head/coverage tradeoff. We consider it as a clustering problem and propose the Agglomerative Class Clustering to solve it (see Algorithm 1). Formally, we assume the labels of original ùëÅclasses as:ùêø= {ùëô1,ùëô2,...,ùëôùëÅ}. For the sake of simplicity, we can map the labels into integer numbers, as ùêø={1,2,...,ùëÅ}. They are to be grouped into ùêæclusters{ùê∫ùëò|ùëò=1,2,...,ùêæ}, whereùê∫ùëò‚Ä≤√ë ùëò‚Ä≤‚â†ùëòùê∫ùëò=‚àÖandùêø=√êùêæ ùëò=1ùê∫ùëò. Accordingly, we can use ùúÜùëñ‚àà{1,2,¬∑¬∑¬∑,ùêæ}to represent the cluster label of original label ùëôùëñ. Then, the clustering result can be represented by a cluster label list: ùùÄ=(ùúÜ1,ùúÜ2,¬∑¬∑¬∑,ùúÜùëÅ). Risk matrix R.The risk probability matrix and risk impact matrix can be integrated into one single risk matrix with an elementwise multiplication: R=R‚äôI, (16) wherein each entry in Rstands for the risk between classes of the big network. Two clustering criteria. Merging two classes into one cluster have two effects: ‚Ä¢Coverage loss, since faultinduced misclassfications between the two classes cannot be detected any more. Hence, we prefer merging classes with small values in risk matrix R.‚Ä¢Overhead savings, because the simplified task is easy to learn and it will be more consistent with the big DNN, thereby reducing recomputational overhead. We useùê∂ùëÇùëâùëôùëúùë†ùë†andùëÇùë†ùëéùë£ùëí to denote such effects, which are used in Algorithm 1. Updating RandC.After selecting two classes or clusters to merge, we should update the RandCaccordingly. Assuming cluster ùê∫ùëñ andùê∫ùëó(ùëñ<ùëó) are to be merged, we first move classes in cluster ùê∫ùëótoùê∫ùëñ, asùê∫ùëñ=ùê∫ùëñ√êùê∫ùëó, deleteùê∫ùëóand reassign the cluster label for the rest of clusters. Then we update the risk and inconsistency values ofùê∫ùëñ(ùëñth row and ùëñth column of RandC) as the sum of the corresponding values of two clusters. Lastly, we delete the ùëóth row andùëóth column in RandC. In this way, we aggregate the risk probability and inconsistency values of two merged clusters while preserving the property of the matrices defined in Section 3. Clustering scheme. We apply a hierarchical clustering algorithm‚Äî agglomerative class clustering , which is illustrated in Algorithm 1. Specifically, each class of the original task starts in its own cluster. Then, we search for two clusters with the smallest coverage loss in R. Note that R(see Figure 3) is usually sparse, in case of multiple occurrences of the minimum value, we choose the one with the largest overhead savings from C, which in turn improves the model consistency between the task model and the checker DNN. Next, we merge the two selected clusters into one cluster and update RandC. The above procedure iterates in a bottomup manner until all classes of the original task are merged as a single cluster. Consequently, the clustering results can be presented in a dendrogram with ùêæ=2 toùêæ=ùëÅ‚àí1clustering candidates, which enables later exploration for the optimal simplified task for a given checker DNN. Figure 4 shows an example of the iterative clustering procedure with five classes and the generated dendrogram. 5.2 Search Strategy After obtaining candidate tasks from Algorithm 1, we evaluate the corresponding overhead savings and coverage loss with fault injec tion experiments. As the number of candidate tasks ùëÅ‚àí1increases linearly with the number of original classes, we can evaluate them efficiently. Afterwards, we have a list of paretooptimal checker DNN designs with various coverage/overhead tradeoffs. We then choose the optimal final DNN design. 6 EXPERIMENTAL RESULTS In this section, we demonstrate the effectiveness of DeepDyve. First, we present our experimental setup in Section 6.1. After that, our results that architecture exploration facilitates to find an optimized checker DNN architecture in Section 6.2, and task simplification further saves the overhead of DeepDyve in Section 6.3, respectively. We show DeepDyve outperforms existing solutions in Section 6.4. At last, in Section 6.5, we discuss the impact of model accuracy through a case study on CIFAR100. 6.1 Setup Datasets. We demonstrate the effectiveness of DeepDyve on four widely used image classification datasets: CIFAR10 [ 19], The Ger man Traffic Sign Recognition Benchmark (GTSRB) [ 39], CIFAR 100 [ 19], and TinyImageNet [ 21]. CIFAR10 and CIFAR100 datasetsplanecar bird catdeer dog froghorseship truck 0.00 0.00 0.30 0.16 0.02 0.07 0.09 0.27 0.34 0.15 0.17 0.00 0.00 0.00 0.00 0.00 0.02 0.00 0.10 0.30 0.12 0.04 0.00 0.61 0.33 0.27 0.39 0.18 0.10 0.11 0.24 0.34 0.16 0.00 0.28 1.00 0.49 0.13 0.10 0.00 0.01 0.00 0.43 0.17 0.00 0.51 0.06 0.20 0.04 0.01 0.00 0.00 0.15 0.80 0.18 0.00 0.12 0.45 0.09 0.05 0.11 0.09 0.16 0.60 0.00 0.05 0.00 0.00 0.01 0.06 0.15 0.00 0.34 0.09 0.06 0.32 0.05 0.00 0.01 0.00 0.18 0.09 0.05 0.13 0.00 0.15 0.28 0.00 0.00 0.16 0.04 0.63 0.00 0.05 0.06 0.00 0.00 0.00 0.21 0.00 0.00 0.04 0.48 0.20 0.08 0.07 0.26 0.04 0.31 0.13 0.23 0.00 0.00 0.00 0.00 0.00 0.00 0.02 0.33 0.43 0.76 0.00 0.00 0.21 0.15 0.15 0.25 0.26 0.05 0.01 0.19 0.00 0.19 0.00 0.32 1.00 0.62 0.53 0.21 0.10 0.02 0.00 0.11 0.14 0.00 0.12 0.26 0.04 0.08 0.00 0.38 0.00 0.09 0.85 0.32 0.00 0.04 0.48 0.02 0.00 0.03 0.00 0.34 0.24 0.13 0.10 0.00 0.00 0.01 0.00 0.16 0.00 0.14 0.39 0.48 0.17 0.00 0.00 0.01 0.00 0.75 0.23 0.04 0.05 0.03 0.05 0.01 0.00 0.00 0.31 0.10 0.60 0.02 0.20 0.07 0.10 0.00 0.00 0.14 0.00 planecar bird catdeer dog froghorseship truck 0.00 0.05 0.12 0.11 0.09 0.03 0.07 0.06 0.22 0.09 0.08 0.00 0.01 0.00 0.00 0.00 0.02 0.03 0.12 0.18 0.27 0.00 0.00 0.32 0.15 0.27 0.34 0.03 0.04 0.00 0.13 0.03 0.48 0.00 0.23 1.00 0.40 0.20 0.07 0.04 0.06 0.00 0.24 0.49 0.00 0.22 0.18 0.16 0.00 0.05 0.05 0.06 0.10 0.72 0.23 0.00 0.27 0.26 0.00 0.04 0.02 0.01 0.29 0.30 0.22 0.10 0.00 0.08 0.04 0.03 0.01 0.00 0.18 0.15 0.17 0.35 0.05 0.00 0.02 0.04 0.27 0.15 0.01 0.16 0.03 0.05 0.01 0.04 0.00 0.08 0.16 0.37 0.00 0.04 0.02 0.00 0.01 0.02 0.17 0.00 0.00.20.40.60.81.0planecar bird catdeer dog froghorseship truck (a) ResNet152 (b) VGG16 (c) MobileNetPredicted Label True LabelFigure 5: Risk probability matrices of different models under four million fault injections. Table 3: Datasets and Task Models. Dataset #Classes Task Model Accuracy FLOPs Parameter CIFAR10 10 ResNet152 96.15% 3.75 G 58.22 M GTSRB 43 ResNet34 99.40% 1.16 G 21.30 M CIFAR100 100 ResNet152 80.11% 3.75 G 58.22 M TinyImageNet 200 WideResNet101 85.20% 22.84 G 126.89 M contain 50,000 training images and 10,000 test images, and they have 10 and 100 classes, respectively. GTSRB has 43 classes of dif ferent traffic signs. It has 39,209 training images and 12,630 test images in total. TinyImageNet is a 200class natural image dataset subsampled from ImageNet dataset and it contains 100,000 training and 10,000 validation images. Models. Table 3 shows the task DNN used by each dataset. For CIFAR10, the task DNN model is a ResNet152 with an accuracy of 95.16%. For GTSRB, the task DNN we use is a ResNet34 model with an accuracy of 98.6%. The ResNet152 for CIFAR100 has an accu racy of 80.11%. The task model for TinyImageNet is WideResNet 101, and its accuracy is 85.20%. Please note that for TinyImageNet, we use pretrained weights on the ImageNet dataset and finetune them to obtain high accuracy. We use Pytorch profiling tool ""thop""2 to quantify model GFLOPs and parameters. We quantize all DNN parameters into 8bit integers (INT8) following a uniform affine quantitizer [18]. Fault Model. In our experiment, we use two types of fault injection: random fault injection and BitFlip Attack (BFA) [ 33]. For random fault injection, in each simulation run, we randomly flip ùëõbits in the model and pass one randomly selected image to the DNN model for inference. BFA proposed in [ 33] is the stateofart fault injection attack on DNN models. It can crash the DNN system by injecting a small number of bitflips by searching the most vulnerable bit progressively. A failure occurs when the predicted label is different from the one obtained in the faultfree case. Risk Impact Martrix. In practice, the risk impact matrix should be determined by system designers after conducting application specific risk analysis. One practical solution would be categorizing 2https://github.com/Lyken17/pytorchOpCounterthe risk impact into a few risk levels and filing the matrix accord ingly. In our experiments. we simulate the impact matrix with two configurations. ‚Ä¢Uniform Impact , where all entries are ones. It represents that the risk impact among all classes are equal. When the risks of different classes do not have significant differences, the uniform impact matrix can be used for simplicity. ‚Ä¢Nonuniform Impact , where the risk impact values are set to two different levels. As classes with the low precision are not trustworthy themselves and hence have low risk, in this configuration, we assign those classes with the lowest 25% precision with impact 1 and the others with 100. Risk Probability Matrix. We obtain the risk probability matrix and the failure coverage of the checker DNN with random fault injection experiments. Figure 5 shows the risk probability matrices of different stateofart model architectures trained on CIFAR10. We perform 4 million fault injections to obtain the result in this figure3. For visualization purposes, the probability matrix is divided by the maximum element. The sum of all elements in the original probability matrix is 1. We can observe that the risk probability matrix is more task related than modelrelated. The probability distributions are very similar across different DNN models on the same CIFAR10 task. For example, in Figure 5 (a), the value between dog and cat is the highest one with fault injections. It is also true for Figure 5 (b) and (c). This matrix will be used in the task simplification process. 6.2 Effectiveness of Architecture Exploration In this part, we study the effectiveness of the architecture explo ration. Figure 6 shows the consistency, indicated by blue points and approximated by blue curve, and the computational overhead, indi cated by red points and connected by the red curve, of checker DNN models with different sizes trained by DeepDyve. Please note that we only investigate five checker model sizes for TinyImageNet due to high training effort for this dataset, including the pretraining on ImageNet dataset and finetuning on TinyImagenet. For all the four datasets, the consistency between the task and checker models 3More fault injections are performed, and the results are similar.(c) CIFAR100alpha (a) CIFAR10alpha (d) TinyImageNetalpha (b) GTSRBFlopOverhead Consistency 0.00 0.05 0.10 0.15 0.20 0.25 0.30 0.35 0.40 0.50 0.55 0.60 0.65 0.70 0.75 0.80 f( ) =0.007+ 0.79,optimal= 0.15 0.300.350.400.450.50 0.0 0.1 0.2 0.3 0.4 0.65 0.70 0.75 0.80 0.85 0.90 0.95 f( ) =0.003+ 0.94,optimal= 0.11 0.100.150.200.250.30 optimal point 0.30 0.35 0.40 0.45 0.50 0.55 0.60 0.65 0.70 0.68 0.70 0.73 0.75 0.78 0.80 0.83 0.85 f( ) =0.078+ 0.96,optimal= 0.34 0.350.400.450.500.550.600.65 optioptimal point 0.1 0.2 0.3 0.4 0.5 0.6 0.80 0.85 0.90 0.95 1.00 f( ) =0.007+ 1.0 ,optimal= 0.15 0.050.100.150.200.250.300.35 alphaoptimal pointoptimal pointoptimal pointFigure 6: Consistency v.s. overhead in the architecture exploration stage. Table 4: Task simplification further shrink the overhead. Dataset Impact MatrixStart ConsistencyBefore TaskSim. After TaskSimkO(C) Wcov O(C) Wcov CIFAR10nonuniform91.62%9.18% 86.94% 6.88% 86.12% 8 uniform 9.18% 75.90% 9.11% 75.90% 9 GTSRBnonuniform98.75%2.68% 98.46% 1.94% 98.23% 23 uniform 2.68% 98.15% 2.56% 98.15% 33 CIFAR100nonuniform75.82%27.48% 67.29% 24.02% 66.92% 83 uniform 27.48% 74.33% 27.42% 74.33% 99 TinyImageNetnonuniform79.19%36.91% 76.40% 35.56% 75.19% 186 uniform 36.91% 78.03% 36.84% 78.02% 198 improves with the increasing size of checker DNNs. Also, as we can observe, there is a turning point on the computational overhead curve. Before the turning point, the recomputation dominates the computational overhead O(C), and after which, the checker models‚Äô computational cost dominates the O(C). First, compared to the architecture with the highest consistency (i.e., duplication), the optimized architecture can greatly reduce the overhead. For CIFAR10, GTSRB, CIFAR100, and TinyImageNet, 91.82%, 97.32%, 72.52% and 63.09% overhead can be saved with 8.38%, 1.25%, 24.18% and 20.81% consistency degradation, respectively (see Table 4). We also observe that the consistency values vary for different datasets. After manual checking, we found the consistency values of the optimized architecture on the training set are almost 100%, but it generalizes differently during inference for the four data sets. Second, the relation between consistencies, architecture sizes, and the optimal point is well captured by THEOREM 4.1 . For example, the resulting consistency function for CIFAR10 is ùëì(ùõº)= ‚àí0.003 ùõº+0.94, and hence the optimal point is when ùõº=0.11(recall that the optimal point is3‚àöÔ∏É ùëé ùë•). This is compatible with the red curve where ùõº=0.11almost renders the minimal computational overhead. Similarly, the consistency function for GTSRB is ùëì(ùõº)= ‚àí0.007 ùõº+1.0and the calculated optimal point is ùõº=0.15, which is also compatible with the red curve. Therefore, the initial checker DNN architecture can be efficiently found by the proposed method. 6.3 Effectiveness of Task Exploration In this part, we first evaluate the weighted coverage ùëäùëêùëúùë£. and overheadùëÇ(ùê∂)under various simplified classes ùëò. Then, we study how the risk impact matrix affects task simplification.First, we observe that task simplification can significantly reduce the overhead of DeepDyve with little coverage degradation. In Figure 7, we use the checker DNN design obtained from Section 6.2 and trace the weighted coverage ùëäùëêùëúùë£. and overhead ùëÇ(ùê∂)during the agglomerative class clustering process. Table 4 shows the final task simplification results. Through task simplification, we can save the overhead by(9.18%‚àí6.88%)/9.18%=25.05%, 27.61%, 12.60%, 3.38% for CIFAR10, GTSRB, CIFAR100, and TinyImageNet, at the cost of 0.9%, 0.2%, 0.5%, 1.6% coverage degradation, respectively. We can also observe that fault coverage and overhead vary a lot under different impact matrix configurations. First, the initial weighted coverage values before task simplification is different for uniform and nonuniform settings, because the ùêºùëñùëóterm in the definition of weighed coverage given by Equation 4 varies. Sec ond, we observe much more overhead savings can be achieved in the nonuniform case. For example, the overhead saving can be improved from 0.76% to 25.05% on CIFAR10 when changing to nonuniform impact matrix. This is because, the impact of classes with low precision is set as lower values under such circumstances, which provides more opportunities for task simplification. In other words, a reasonable impact matrix is beneficial for protection with DeepDyve and hence is highly recommended. 6.4 DeepDyve vs. Threshold Checking In this section, we compare the performance of DeepDyve with the Threshold Checking scheme proposed in [ 23]. We experiment under both random fault attack and BitFlip Attack (BFA) settings. We show the results in Table 5, including the falsepositive rate (FPR), falsenegative rate (FNR), computational overhead (O(C)), and the weighted coverage (Wcov.). First, we observe DeepDyve significantly outperforms Threshold Checking in terms of Wcov., which in turn leads to smaller FNR. As discussed in Section 2, most intermediate activation values locate in the normal range even under fault attack, especially for the quantized DNN case. Hence, most faults are missed with Threshold Checking, but they can be detected by DeepDyve. Second, in most cases, we can observe both DeepDyve and Threshold Checking performs better under BFA compared to ran dom fault attacks. We manually check the internal values of DNN under fault attack and find that the magnitude of value change is larger in BFA than in random fault attacks, thereby making fault detection easier.number of classes (k)starting consistency = 91.62%  wcoverage (%) overhead (%) wcoverages number of classes (k) 2 3 4 5 6 7 8 9 10 5.00 6.00 7.00 8.00 9.00 70.0072.5075.0077.5080.0082.5085.0087.50 wcoverages 0 10 20 30 40 1.80 2.00 2.20 2.40 2.60 60.0065.0070.0075.0080.0085.0090.0095.00100.00 0 20 40 60 80 100 12.00 14.00 16.00 18.00 20.00 22.00 24.00 26.00 28.00 35.0040.0045.0050.0055.0060.0065.00 wcoverages 0 25 50 75 100 125 150 175 200 24.00 26.00 28.00 30.00 32.00 34.00 36.00 50.0055.0060.0065.0070.0075.0080.00 wcoverages number of classes (k) number of classes (k)starting consistency = 98.75% starting consistency = 75.82 % starting consistency = 79.19%    (a) CIFAR10 (b) GTSRB (c) CIFAR100 (d) TinyImageNetFigure 7: Tracing of the fault coverage and overhead change in task simplification process. Table 5: Comparison between DeepDyve and threshold checking. Dataset Impact MatrixRandom Fault Attack BFA Threshold Checking DeepDyve Threshold Checking DeepDyve FPR FNR O(C) Wcov. FPR FNR O(C) Wcov. FPR FNR O(C) Wcov. FPR FNR O(C) Wcov. CIFAR10nonuniform 0.04% 96.24%  4.10% 0.00% 43.29% 6.88% 82.98% 0.04% 33.45%  66.39% 0.00% 1.01% 6.88% 98.93% uniform 0.04% 90.87%  9.12% 0.00% 24.06% 9.11% 75.94% 0.04% 55.52%  44.48% 0.00% 2.15% 9.11% 97.85% GTSRBnonuniform 0.00% 99.72%  0.3% 0.00% 16.53% 1.94% 95.49% 0.00% 100.00%  0.00% 0.00% 0.90% 1.94% 99.75% uniform 0.00% 96.85%  3.15% 0.00% 5.07% 2.56% 94.93% 0.00% 99.88%  0.12% 0.00% 0.79% 2.56% 99.21% CIFAR100nonuniform 0.02% 65.11%  33.48% 0.00% 31.51% 24.02% 74.67% 0.02% 14.50%  86.61% 0.00% 1.84% 24.02% 99.50% uniform 0.02% 86.99%  13.01% 0.00% 19.21% 27.42% 80.79% 0.02% 1.05%  98.95% 0.00% 0.37% 27.42% 99.63% TinyImageNetnonuniform 0.02% 69.31%  30.56% 0.00% 19.46% 35.19% 82.00% 0.02% 0.00%  100.00% 0.00% 0.05% 35.19% 99.94% uniform 0.06% 87.34%  12.65% 0.00% 17.02% 36.84% 82.98% 0.06% 0.08%  99.92% 0.00% 0.02% 36.84% 99.98% Third, the FPR of Threshold Checking is above zero while that of our DeepDyve system is zero. For example, the FPR of Threshold Checking for CIFAR10 dataset is 0.04%. As discussed in Section 2, threshold Detection sets the thresholds as 1.1 times the maximum and a minimum of each layer‚Äôs normal activation values on the training set. On the testing set, there are few exceptions where the activation values are beyond this range. In contrast, in the normal execution of DeepDyve, the comparator‚Äôs false positives, which are caused by inconsistencies between task and checker models, are subject to recomputation, and hence, the system‚Äôs false positives are guaranteed to be zero. 6.5 Impact of Model Accuracy Previous experiments suggest that the overhead of DeepDyve for CIFAR100 and TinyImageNet dataset are quite high, even after task simplification. This is because the perclass accuracy of the task model on these two datasets varies and some of them are very low, as shown in Figure 8. In safetycritical applications, a class is deserved to be protected only when its accuracy is high enough. Considering the above, we conduct a case study on CIFAR100 and let the impact of 75% of the classes with the lowest precision to be zero. Previously, the computational overhead induced by the checker DNN before task simplification was 27.48% (See Table 4). With the above setting, as we only care classes with nonzero impact, we let the comparator only check the inconsistencies of these classes. Given this, the overhead induced by the checker DNN before task simplification is 16.17%. Task simplification can further reduce the overhead from 16.17% to 9.88% without loss of weighted coverage (38.89% overhead savings). Also, the simplified model can reach 0 20 40 60 80 1000.00.20.40.60.81.0 class index AccuracythresholdFigure 8: Perclass accuracy for CIFAR100. 90.66% weighted coverage under random fault attack and 99.78% weighted coverage under BFA attack. 7 DISCUSSIONS In this section, we discuss the robustness of the proposed DeepDyve architecture and its limitations. 7.1 Robustness of DeepDyve What if the checker DNN has faults? If the checker DNN is faulty while the task DNN is correct, the final inference accuracy would remain the same, because the system would accept the output from the task model anyway. There could be extra latency. To mitigate this issue, we could leverage various hardening techniques (e.g., secure enclaves) to protect it at a reasonable cost since the checker DNN is much smaller than the task DNN model.Attack on DeepDyve. Attackers need to create consistent faulty outputs to bypass the comparison logic of DeepDyve to successful launch their attacks. One way to achieve this is to inject faults into the task and checker models simultaneously. However, the cost of launching such an attack in practice is very high, if not impossible. On the one hand, simultaneously injecting faults at two specific positions is difficult. For example, rowhammer attack relies on the weakness of physical memory row, and it cannot be fully controlled. On the other hand, if lowprecision fault injection technique is used to inject random faults into the two DNNs, the probability distribution of the faulty output of a DNN is given by its risk probability matrix, and the probability of two DNNs‚Äô outputs happens to be the same is given by ùëÉùëêùëúùëôùëôùëñùë†ùëñùëúùëõ =ùëÅ‚àëÔ∏Å ùëñùëùùëñ‚àóùëûùëñ, (17) whereùëùùëñandùëûùëñare the probabilities of task DNN and checker DNN generating the same output ùëñ, respectively, and ùëÅis the number of classes. Obviously, this value decreases with the increase of classes. TheùëÉùëêùëúùëôùëôùëñùë†ùëñùëúùëõ values are 8.9%, 2.77%, 0.87%, and 0.49% for CIFAR10, GTSRB, CIFAR100, and TinyImageNet, respectively. Given that the probability of DNNs generating wrong outputs under random faultsùëÉùëíùëüùëüùëúùëü is extremely low. The possibility for such attack to succeed is negligible. Another way to successfully launch fault injection attacks is to target those inconsistent cases and make them consistent with faulty result. To achieve this objective, however, attackers need to be able to tell whether an incoming data is consistent at runtime and perform fault injection before its inference is finished. This is a daunting objective to achieve, especially considering the usual long preparation time for fault injection. 7.2 Limitations and Future Work DeepDyve brings latency and reduces throughput due to recompu tation, which needs to be considered when performing realtime tasks. For example, there is about 1% of throughput loss for the above DeepDyve model constructed on the GTSRB dataset. This overhead can be reduced when the consistency rate between the checker DNN and the task DNN models increases. Also, our current evaluation is only on the 8bit integer (INT8) data representation. One reason is that INT8 is a popular data type and supported by well known deep learning frameworks and toolchains, such as Pytorh4, Tensorflow5, NVIDIA ¬ÆTensorRD6, and Xilinx ¬ÆDNNDK7. Popular hardware platforms like TPU [ 15] support integer operations as well. The second reason is that the Pytorch 1.3 (the one we use) and the code from BFA attack8only supports INT8 quantization in its current version. We shall extend our work to study the impact of different data types in the future. 4https://pytorch.org/docs/stable/quantization.html 5https://www.tensorflow.org/lite/performance/post_training_quantization 6https://developer.nvidia.com/tensorrt 7https://www.xilinx.com/products/designtools/aiinference/edgeai platform.html#dnndk 8https://github.com/elliothe/BFA8 RELATED WORKS "
471,Deep Representations for Cross-spectral Ocular Biometrics.txt,"One of the major challenges in ocular biometrics is the cross-spectral
scenario, i.e., how to match images acquired in different wavelengths
(typically visible (VIS) against near-infrared (NIR)). This article designs and
extensively evaluates cross-spectral ocular verification methods, for both the
closed and open-world settings, using well known deep learning representations
based on the iris and periocular regions. Using as inputs the bounding boxes of
non-normalized iris/periocular regions, we fine-tune Convolutional Neural
Network(CNN) models (based either on VGG16 or ResNet-50 architectures),
originally trained for face recognition. Based on the experiments carried out
in two publicly available cross-spectral ocular databases, we report results
for intra-spectral and cross-spectral scenarios, with the best performance
being observed when fusing ResNet-50 deep representations from both the
periocular and iris regions. When compared to the state-of-the-art, we observed
that the proposed solution consistently reduces the Equal Error Rate(EER)
values by 90% / 93% / 96% and 61% / 77% / 83% on the cross-spectral scenario
and in the PolyU Bi-spectral and Cross-eye-cross-spectral datasets. Lastly, we
evaluate the effect that the ""deepness"" factor of feature representations has
in recognition effectiveness, and - based on a subjective analysis of the most
problematic pairwise comparisons - we point out further directions for this
field of research.","Iris recognition using nearinfrared (NIR) wavelength images ac quired under controlled environments can be considered a mature technology, which proved to be effective in different scenarios [1]. In contrast, performing iris recognition in uncontrolled environments and at visible (VIS) wavelength is still a challenging problem [2, 3]. Some of the latest researches consist of biometrics recognition on crossspectral scenarios, i.e., using images of eyes from the same subject obtained at the VIS and NIR wavelengths [4‚Äì7]. Recently, machine learning techniques based on deep learning have been achieving great popularity due to the results reported in the literature, which advance the stateoftheart in various prob lems, such as speech recognition [8‚Äì10], natural language process ing [11, 12], digit and character recognition [13‚Äì15] and face recog nition [16, 17]. In the Ô¨Åeld of ocular biometrics, using deep learning representation has been advocated both for the periocular [18, 19] This paper is a postprint of a paper submitted to and accepted for publication in IET Biometrics and is subject to Institution of Engineering and Technology Copyright. The copy of record is available at the IET Digital Library .and iris [6, 20‚Äì26] regions, with interesting and promising results being reported. As stated in previous works [20, 27], an often and open prob lem in ocular recognition is the matching heterogeneous images cap tured at different resolutions, distances and devices (crosssensor and crossspectral). Regarding these problems it is difÔ¨Åcult to design a robust handcrafted feature extractor to address the intraclass vari ations present in this scenarios. In this sense, several recent works demonstrate that deep representations report better results compared to handcrafted features in iris and periocular region recognition [18‚Äì 20, 25]. Having in mind that deep learning frameworks are typically able to produce robust representations, in this article we apply this fam ily of frameworks to extract and combine features from the ocular region, obtained at different wavelengths, e.g., VIS and NIR. The strategy described in this article is composed of some methodologies extracted from the literature. For both the iris and ocular traits we use as input the bounding box delimited regions used in the state oftheart methods [18, 26]. Then, the features from these traits were extracted using a similar approach proposed by [26]. In this direction, the main contribution of this article is the extensive ex periments on two datasets comparing iris, periocular, and fusion re sults for both crossspectral (VIS to NIR) and intraspectral (VIS to VIS, NIR to NIR) matching, reaching a new stateoftheart results. There is also the following fourfold contributions: (i) we show that deep learning yield robust representations on two wellknown cross spectral databases (PolyU and CrossEyed) for ocular veriÔ¨Åcation using closed and openworld protocols; (ii) we report how two off theshelf networks can be Ô¨Ånetuned from the face domain to the periocular and iris one; (iii) we analyze the use of a single deep rep resentation extraction schema, for both crossspectral and the same spectra scenarios; and (iv) we conclude about the beneÔ¨Åts of fus ing the periocular and iris representations to improve the recognition accuracy. The remainder of this work is organized as follows. In Section 2, we describe some recent works that use deep learning for iris and pe riocular recognition. Section 3 provides the details of the proposed approach. Section 4 presents the databases, metrics and evaluation protocol used in our empirical evaluation. The results are presented and discussed in Section 5. Lastly, the conclusions are given in Sec tion 6. 1arXiv:1911.09509v1  [cs.CV]  21 Nov 20192. RELATED WORK "
248,DualApp: Tight Over-Approximation for Neural Network Robustness Verification via Under-Approximation.txt,"The robustness of neural networks is fundamental to the hosting system's
reliability and security. Formal verification has been proven to be effective
in providing provable robustness guarantees. To improve the verification
scalability, over-approximating the non-linear activation functions in neural
networks by linear constraints is widely adopted, which transforms the
verification problem into an efficiently solvable linear programming problem.
As over-approximations inevitably introduce overestimation, many efforts have
been dedicated to defining the tightest possible approximations. Recent studies
have however showed that the existing so-called tightest approximations are
superior to each other. In this paper we identify and report an crucial factor
in defining tight approximations, namely the approximation domains of
activation functions. We observe that existing approaches only rely on
overestimated domains, while the corresponding tight approximation may not
necessarily be tight on its actual domain. We propose a novel
under-approximation-guided approach, called dual-approximation, to define tight
over-approximations and two complementary under-approximation algorithms based
on sampling and gradient descent. The overestimated domain guarantees the
soundness while the underestimated one guides the tightness. We implement our
approach into a tool called DualApp and extensively evaluate it on a
comprehensive benchmark of 84 collected and trained neural networks with
different architectures. The experimental results show that DualApp outperforms
the state-of-the-art approximation-based approaches, with up to 71.22%
improvement to the verification result.","Deep neural networks (DNNs) are the most crucial com ponents in AIempowered software systems. They must be guaranteed reliable and dependable when the hosting systems are safetycritical. Robustness is central to their safety and reliability, ensuring that neural networks can function correctly even under environmental perturbations and adversarial attacks [1]‚Äì[3]. Studying the robustness of DNNs from both training and engineering perspectives attracts researchers from both AI and SE communities [1], [2], [4]‚Äì[7]. More recently, the emerging formal veriÔ¨Åcation e orts on the robustness of neural networks aim at providing certiÔ¨Åable robustness guarantees for the neural networks (see the surveys [8]‚Äì[10] for details). CertiÔ¨Åed robustness of neural networks is necessity for guar anteeing that the hosting software systems are both safe andsecure. A provably robust neural network ensures that no adversarial examples can falsify a network to misclassify an input and thereafter cause unexpected behaviors in the hosting system. Robustness veriÔ¨Åcation is particularly crucial to the neural networks planted in safetycritical applications such as autonomous drivings [11], [12], medical diagnoses [13], and access controls by face recognition [14]. Formally verifying the robustness of neural networks is computationally complex and expensive due to the high non linearity and nonconvexity of neural networks. It has been proved to be NPcomplete even for the simple fullyconnected networks with the piecewise linear activation function ReLU [15]. It is signiÔ¨Åcantly more di cult for those networks that contain di erentiable Scurve activation functions such as Sig moid, Tanh, and Arctan [16]. To improve scalability, a practical solution is to overapproximate the nonlinear activation func tions using linear upper and lower bounds. The veriÔ¨Åcation problem is then transformed into an e ciently solvable linear programming problem. The linear overapproximation is a prerequisite for other advanced veriÔ¨Åcation approaches based on abstraction [17]‚Äì[19], interval bound propagation (IBP) [20], and convex optimization [21], [22]. As overapproximations inevitably introduce overestima tion, the corresponding veriÔ¨Åcation approaches sacriÔ¨Åce com pleteness and may fail to prove or disprove the robustness of a neural network [9]. Consequently, we cannot conclude that a neural network is not robust when we fail to prove it is robust by overapproximation. To resolve such uncertainties, an ideal approximation must be as tight as possible. Intuitively, an approximation is tighter if it introduces less overestimation. Considerable e orts have been devoted to Ô¨Ånding tight over approximations for precise veriÔ¨Åcation results [16], [23]‚Äì[26]. Unfortunately, most of the tightness deÔ¨Ånitions lack theoretical guarantees that a tighter approximation always implies a more precise veriÔ¨Åcation result. Recent work has shown that none of them is superior to the others in terms of the veriÔ¨Åcation results [27]. Lyu et al. [28] and Zhang et al. [27] claim that computing the tightest approximation is essentially a networkwise non convex optimization problem, which is almost impractical to solve directly due to high computational complexity. TheyarXiv:2211.11186v1  [cs.SE]  21 Nov 2022show that the scalability is signiÔ¨Åcantly reduced when resort ing to optimization. Hence, computing a tight approximation to each individual activation function is still an e ective and practical solution. As existing tightness characterizations of neuronwise overapproximations cannot guarantee the tight ness, it is highly desirable to explore the missing factors on deÔ¨Åning tighter neuronwise approximations. In this paper we report a new crucial factor for deÔ¨Åning tight overapproximations, namely the approximation domains of activation functions. It is overlooked by existing approaches which consider only overestimated domains of the activation functions to approximate. However, an overapproximation that is tight on the overestimated domain may not be tight on the actual domain of the approximated function. There can be a tighter approximation of the actual domain. Unfortunately, computing the actual domain of the activation function on each neuron in a neural network is as di cult as the veriÔ¨Åcation problem and thus impractical. Inspired by our new Ô¨Ånding, we propose a novel under approximationguided overapproximation approach to deÔ¨Åne tight linear approximations for the robustness veriÔ¨Åcation of neural networks. More speciÔ¨Åcally, we leverage the under approximation to compute an underestimated domain for the approximated activation function. Moreover, we use both the underestimated domain and the overestimated domain to deÔ¨Åne a tight linear approximation for the function. We call it a dualapproximation approach. We propose two under approximation approaches, i.e., samplingbased andgradient based , to compute underestimated domains. The former is more timewise e cient, while the latter is more precise in terms of veriÔ¨Åcation results. Our dualapproximation approach can produce tighter linear approximations than existing single approximation approaches. We evaluate our approach on a comprehensive benchmark of 84 neural networks. The ex perimental results show that our approach outperforms all existing tight approaches, with up to 71.22% improvement to the veriÔ¨Åcation result. In summary, we make three main contributions: (1) Identifying an crucial factor, namely approximation do main, in deÔ¨Åning tight overapproximations for neural network robustness veriÔ¨Åcation. (2) Presenting the Ô¨Årst dualapproximation approach, i.e., underapproximationguided overapproximation, which outperforms the stateoftheart approaches with up to 71.22% improvement to the robustness veriÔ¨Åcation results. (3) Proposing two underapproximation approaches, i.e., gradientdescentbased and samplingbased, for com puting underapproximated domains and experimentally demonstrating that the latter has a better performance than the former in the veriÔ¨Åcation. The remainder of this paper is organized as follows: Section II gives preliminaries. Section III discusses the interdepen dency between approximation domains and the tightness of approximations. We present our dualapproximation approach in Section IV and two underapproximation approaches in Section V, respectively. Section VI shows the experimentalresults. We discuss related work in Section VII and conclude the paper in Section VIII. II. P reliminaries This section introduces the basic notation and terminology used throughout the paper. A. Deep Neural Networks A deep neural network is a network of neurons as shown in Fig. 1, which implements a mathematical function F:Rn! Rm, e.g., n=3 and m=2 for the 2hiddenlayer DNN in Fig. 1. Neurons except input ones are also functions f:R!Rin the form of f(x)=(Wx+b), where() is called an activation function ,Wa matrix of weights and ba bias. A vector of n numbers are fed into the network from the input layer and propagated layer by layer through the internal hidden layers after being multiplied by the weights on the edges, summed at the successor neurons with the bias and then computed by the neurons using the activation functions. The neurons on the output layer compute the probabilities of classifying an input vector to the labels represented by the corresponding neurons. The vector can be an image, a sentence, a voice, or a system state, depending on the application domains of the networks. Given an llayer neural network, let kibe the number of the neurons on the ith layer, W(i)be the matrix of weights between the ith and ( i+1)th layers, and b(i)the biases on the corresponding neurons, where i=1;:::; l"
478,Binary Multi Channel Morphological Neural Network.txt,"Neural networks and particularly Deep learning have been comparatively little
studied from the theoretical point of view. Conversely, Mathematical Morphology
is a discipline with solid theoretical foundations. We combine these domains to
propose a new type of neural architecture that is theoretically more
explainable. We introduce a Binary Morphological Neural Network (BiMoNN) built
upon the convolutional neural network. We design it for learning morphological
networks with binary inputs and outputs. We demonstrate an equivalence between
BiMoNNs and morphological operators that we can use to binarize entire
networks. These can learn classical morphological operators and show promising
results on a medical imaging application.","While demonstrating considerable success in applications , there are few theo retical results in Deep Learning. Many elements are not well understood, with networks operating as black boxes, hindering critical appl ications such as medical imaging or robotics. Conversely, Mathematical Morphology (MM) is a computer vision discipline with solid theoretical foundations. In t his article, we propose to combine ideas from the two domains to construct a new type o f neural ar chitecture that is theoretically more justiÔ¨Åed and explain able. As argued in [1] combining the two Ô¨Åelds is promising, as MM can se used to cons truct simpler and more understandable deep neural networks. Using MM is mo re natural than convolutional neural networks (ConvNets) for some speciÔ¨Åc tasks. For example, ConvNets are not designed to deal with binary images, while M M is constructed on setrepresentation of images. Also, as stated in [9], des igning a correct se quence of morphological operators can be complicated and ti meconsuming. Past researchers have proposed to learn both operators and s tructuring el ements, e.g using the maxplus deÔ¨Ånition of dilations and er osion [12,4]. Other approaches introduce diÔ¨Äerentiable approximations of the max and min opera tors, such as the adaptive morphological layer [14], the PCo nv layer [10], and the most recent LMorph andSMorph layers [9]. However, these methods deal with greyscale morphology and greyscale images.2 T. Aouad and H. Talbot We introduces the Binary Morphological Neural Network (BiM oNN), a learn able morphological network with binary inputs and output, i nspired by the struc ture of ConvNets. We replace the convolution by elementary o perations from the set of erosions, dilations, antierosions, and antidilat ions: we can learn the type of operation and its associated structuring element as well as any intersection/u nion of these elementary operations. we show equivalence pr operties between our neural network and morphological operators. They can be used both as ex plainable results or as a way to binarize the network: once th ese equivalences are respected, the morphological operation can replace the neu ral network. Booleans weights can replace realvalued weights, improving the inf erence‚Äôs computing eÔ¨É ciency [6,7,15]. We demonstrate how we managed to learn some classical morpho logical operators as well as an intermediate step of a challe nging medical imaging problem. A preliminary version of our work is available at [2 ]. Our code is publicly available online at https://github.com/TheodoreAouad/Bimonn_DGMM2022 . 2 Method "
42,Provably Tightest Linear Approximation for Robustness Verification of Sigmoid-like Neural Networks.txt,"The robustness of deep neural networks is crucial to modern AI-enabled
systems and should be formally verified. Sigmoid-like neural networks have been
adopted in a wide range of applications. Due to their non-linearity,
Sigmoid-like activation functions are usually over-approximated for efficient
verification, which inevitably introduces imprecision. Considerable efforts
have been devoted to finding the so-called tighter approximations to obtain
more precise verification results. However, existing tightness definitions are
heuristic and lack theoretical foundations. We conduct a thorough empirical
analysis of existing neuron-wise characterizations of tightness and reveal that
they are superior only on specific neural networks. We then introduce the
notion of network-wise tightness as a unified tightness definition and show
that computing network-wise tightness is a complex non-convex optimization
problem. We bypass the complexity from different perspectives via two
efficient, provably tightest approximations. The results demonstrate the
promising performance achievement of our approaches over state of the art: (i)
achieving up to 251.28% improvement to certified lower robustness bounds; and
(ii) exhibiting notably more precise verification results on convolutional
networks.","The reliability concerns about deep neural networks (DNNs) are increasing more drastically than ever, especially as such networks are being embedded into software systems to make them intelli gent. Considerable efforts from both AI and software engineering communities have been devoted to achieving robust DNNs by lever aging testing and verification techniques [ 4,12,32,40,42,47,48,54]. Among these attempts, formal methods have been demonstrated ef fective in offering certified robustness guarantees, giving birth to an emerging research field called Trustworthy AI [50]. One distinguish ing feature of formal methods is that they could provide rigorous proofs of correctness automatically when the properties are sat isfied or disprove them by counterexamples (i.e., witnesses to the violations) [ 3,9]. Robustness is an important correctness property in DNN verification: Minor modifications to the neural network‚Äôs inputs must notalter its outputs [ 7]. Guaranteeing robustness is indispensable to prevent AIenabled systems from environmental perturbations and adversarial attacks. Formal robustness verification of DNNs has been well stud ied in recent years [ 14,16,20,32,33,42,45,47‚Äì49]. Most efforts are focused on the ReLU networks that only use the simple piece wise ReLU activation function. Despite their wide adoptions in modern AIenabled systems, another notable class of Sshaped (or Sigmoidlike) activation functions, such as Sigmoid, Tanh, and Arctan, have not attracted much attention yet. Due to their non linearity, Sigmoidlike activation functions are far more complex to be verified. A de facto solution is to overapproximate such func tions by linear bounds and to transform the verification problem into efficiently solvable linear programming. Many stateoftheart DNN verification techniques, e.g., abstract interpretation [ 16,40], symbolic interval propagation [45], model checking [33], differen tial verification [ 32], reachability and output range analysis [ 13,44], are based on linear approximation. Overapproximation inevitably introduces imprecision, render ing approximationbased verification incomplete: Unknown results may be returned when the neural network‚Äôs robustness cannot be verified. Considerable efforts have been devoted to finding the so called tighter approximations to achieve more precise verification results. For example, a larger certified lower robust bound [ 5,28]arXiv:2208.09872v1  [cs.LG]  21 Aug 2022ASE ‚Äô22, October 10‚Äì14, 2022, Rochester, MI, USA Zhaodi Zhang, Yiting Wu, Si Liu, Jing Liu, and Min Zhang (the perturbation distance under which a neural network is proved robust against any allowable perturbation) is preferable in approxi mation. Several characterizations of tightness and approximation approaches have been proposed for Sigmoidlike activation func tions [ 5,18,26,28,51,55]. However, they are all heuristic and lack theoretical foundations for the individual outperformance. We conduct a thorough empirical analysis of existing approaches and reveal that they are superior only on specific neural networks. In particular, we have found that the claimed tighter approximation actually produces smaller certified lower bounds according to the tightness defined and observed frequent occurrences of such cases. Motivated by these observations, we introduce the notion of networkwise tightness as a unified tightness definition to charac terize linear approximations of Sigmoidlike activation functions. This new definition ensures that a tighter approximation can al ways compute larger certified lower bounds (i.e., larger safe radius). However, we show that it unfortunately implies that computing the tightest approximation is essentially a networkwise nonconvex optimization problem [28], which is hard to solve in practice [31]. We bypass the complex optimization problem from two different perspectives, depending on the neural network architecture. For the networks with only one hidden layer , we leverage a gradientbased searching algorithm for computing the tightest approximations. Regarding the networks with multiple hidden layers , based on our empirically study of the stateoftheart tools, we have gained an insight that a larger robust bound can be computed when the intervals keep to be tighter during the layerbylayer propagation . Based on this insight, we propose a neuronwise tightest approximation and prove that it guarantees the networkwise tightest approximation when the networks are of nonnegative weights. Such networks have been demonstrated suitable in a wide range of applications such as effective defense for adversarial attacks in malware and spam detection [ 8,15,19] and balancing accuracy and robustness in autoencoding [1, 29]. We have implemented a prototype of our approach called NeWise1 and extensively compared it to three stateoftheart tools, namely DeepCert [51],VeriNet [18], and RobustVerifier [26]. Our ex perimental results show that NeWise (i) achieves up to 251.28% improvement to certified lower robustness bounds in the provably tightest cases and (ii) exhibits up to 122.22% improvement to certi fied lower robustness bounds on convolutional networks. To summarize, this paper makes three major contributions: (1)We have introduced a novel unified definition of network wise tightness to characterize the tightness of linear approxi mations for neural network robustness verification. (2)We have identified two cases where we can efficiently achieve provably tightest approximations; the corresponding ap proaches have been proposed. (3)We have implemented a verification tool and conducted comprehensive evaluation on its effectiveness and efficiency over three stateoftheart verifiers. The remainder of this paper proceeds as follows: Section 2 gives preliminaries on robustness verification of neural networks. Section 3 shows the tightness measurements of linear approximations and introduce our notion of networkwise tightness. Sections 4 and 5 1Our code is available at https://github.com/FormalAIze/NeWise.git. layer Hidden Output Dog Automobile Original = 0:05 Perturbed image image Input layers layer 0.16 0.62 ;b ;b0 w1 w2 w3Figure 1: A perturbed image of a dog is misclassified to an automobile with 62% probability in 0.05 perturbation radius. present our provably tightest approximations from two different perspectives, respectively. Section 6 describes our evaluation results. We discuss related work in Section 7 and conclude in Section 8. 2 PRELIMINARIES 2.1 Robustness Verification of Neural Networks 2.1.1 Deep Neural Network. A deep neural network is a directed network, where the nodes are called neurons and arranged layer by layer. Each neuron is associated with an activation function ùúé(ùë•)and a biasùëè. Except for the first layer, the neurons on a layer are connected to those on the preceding layer, as shown in Figure 1. Every edge is associated with a weight, which is computed by training. The first and last layers are called input and output layers, respectively. The others between them are called hidden layers. The execution of a neural network follows the style of layer bylayer propagation. Each neuron on the input layer admits a number. The number is multiplied by the weights on the edges and then passed to the successor neurons on the next layer. All the incoming numbers are summed. The summation is fed to the activation function ùúéand the output of ùúéis added with the bias ùëè. The result is then propagated to the next layer until reaching the output layer. Formally, a ùëòlayer neural network is a function ùëì:Rùëõ‚ÜíRùëö of the formùëìùëò‚ó¶ùúéùëò‚àí1‚ó¶...‚ó¶ùúé1‚ó¶ùëì1, withùúéùë°being a nonlinear and differentiable activation function for ùë°th layer. The function ùëìùë°is either an affine transformation ora convolutional operation: ùëì(ùë•)=ùëäùë•+ùëè, (Affine Transformation) ùëì(ùë•)=ùëä‚àóùë•+ùëè, (Convolutional Operation) whereùëä,ùëè, and‚àórefer to the weight matrix, the bias vector, and the convolutional product, respectively. In this work, we focus on the networks with the Sigmoidlike activation functions i.e., Sigmoid, Tanh, and Arctan, which are defined as follows, respectively. ùúé(ùë•)=1 1+ùëí‚àíùë•, ùúé(ùë•)=ùëíùë•‚àíùëí‚àíùë• ùëíùë•+ùëí‚àíùë•, ùúé(ùë•)=ùë°ùëéùëõ‚àí1(ùë•) The output of a neural network ùëìis a vector of ùëöfloating num bers between 0 and 1, denoting the probabilities of classifying an input to the ùëölabels. LetùëÜbe the set of ùëöclassification labels for the network ùëì. We useL(ùëì(ùë•))to represent the output label for the inputùë•with L(ùëì(ùë•))=arg max ùë†‚ààùëÜùëì(ùë•)[ùë†]. Intuitively,L(ùëì(ùë•))returns a label ùë†inùëÜsuch thatùëì(ùë•)[ùë†]is max imal among the numbers in the output vector.Provably Tightest Linear Approximation for Robustness Verification of Sigmoidlike Neural Networks ASE ‚Äô22, October 10‚Äì14, 2022, Rochester, MI, USA 2.1.2 Robustness and Robustness Verification. Neural networks are essentially ‚Äúprograms‚Äù composed by computers by finetuning the weights in the networks from training data. Unlike the handcrafted programs developed by programmers, neural networks lack formal requirements and are almost inexplicable, making it very challeng ing to formalize and verify their properties. A neural network is called robust if reasonable perturbations to its inputs do not alter the classification result. A perturbation is typically measured by the distance between the perturbed input ùë•‚Ä≤ and the original one ùë•by using‚Ñìùëùnorm, denoted by ||ùë•‚àíùë•‚Ä≤||ùëù‚âú ùëù‚àöÔ∏É |ùë•1‚àíùë•‚Ä≤ 1|ùëù+...+|ùë•ùëõ‚àíùë•‚Ä≤ùëõ|ùëù, whereùëùcan be 1,2or‚àû, andùëõis the length of the vectors ùë•. In this work, we consider the most general case when ùëù=‚àû. Example 1. We consider an example to explain how a perturbed image is misclassified. As shown in Figure 1, a normal image of a dog can be correctly classified by a neural network. We assume that the image can be perturbed within a 0.05 distance under ‚Ñì‚àû norm. There exists a perturbed image such that when it is fed into the network, the outputs of the two neurons labeled by dogand automobile are 0.16 and 0.62, respectively. It indicates that the image is classified to a dog (resp. automobile) with the probability of 16% (reps. 62%). Therefore, it is classified to be an automobile, although it still represents a dog to human eyes, apparently. The robustness of a neural network can be quantitively measured by a lower bound ùúñ, which refers to a safe perturbation distance such that any perturbations below ùúñhave the same classification result as the original input to the neural network. Definition 1 (Local Robustness). Given a neural network ùëì, an inputùë•0, and a bound ùúñunder‚Ñìùëùnorm,ùëìis called robust w.r.t. ùë•0 iffL(ùëì(ùë•))=L(ùëì(ùë•0))holds for each ùë•such that||ùë•‚àíùë•0||ùëù‚â§ùúñ. Suchùúñis called a certified lower bound. The twin problems of verifying ùëì‚Äôs robustness are: (i) to prove that, for each ùë•satisfying||ùë•‚àíùë•0||ùëù‚â§ùúñ, ùëìùë†0(ùë•)‚àíùëìùë†(ùë•)>0 (1) holds for each ùë†‚ààùëÜ‚àí{ùë†0}, whereùë†0=L(ùëì(ùë•0))andùëìùë†(ùë•)returns the probability, i.e., ùëÉ(L(ùëì(ùë•))=ùë†), of classifying ùë•to the label ùë† byùëì; and (ii) to compute a certified lower bound ‚Äî a larger certified lower bound implies a more precise robustness verification result. As directly computing ùúñis difficult due to the nonlinearity of the constraint (1), most of the stateoftheart approaches [ 5,51,55] adopt the efficient binary search algorithm to first determine a candidateùúñand then check whether (1) is true or false on ùúñ. 2.2 Approximationbased Robustness Verification A neural network ùëìis highly nonlinear due to the inclusion of activation functions. Proving Formula (1) is computationally expen sive, e.g., NPcomplete even for the simplest fully connected ReLU networks [ 20,37]. Many approaches have been investigated to im prove the verification efficiency while sacrificing completeness. Representative methods include interval analysis [ 46], abstract in terpretation [ 16,40], and output range estimation [ 13,52], etc. The technique underlying these approaches is to overapproximate the x1 ¬ª"
399,DT-SV: A Transformer-based Time-domain Approach for Speaker Verification.txt,"Speaker verification (SV) aims to determine whether the speaker's identity of
a test utterance is the same as the reference speech. In the past few years,
extracting speaker embeddings using deep neural networks for SV systems has
gone mainstream. Recently, different attention mechanisms and Transformer
networks have been explored widely in SV fields. However, utilizing the
original Transformer in SV directly may have frame-level information waste on
output features, which could lead to restrictions on capacity and
discrimination of speaker embeddings. Therefore, we propose an approach to
derive utterance-level speaker embeddings via a Transformer architecture that
uses a novel loss function named diffluence loss to integrate the feature
information of different Transformer layers. Therein, the diffluence loss aims
to aggregate frame-level features into an utterance-level representation, and
it could be integrated into the Transformer expediently. Besides, we also
introduce a learnable mel-fbank energy feature extractor named time-domain
feature extractor that computes the mel-fbank features more precisely and
efficiently than the standard mel-fbank extractor. Combining Diffluence loss
and Time-domain feature extractor, we propose a novel Transformer-based
time-domain SV model (DT-SV) with faster training speed and higher accuracy.
Experiments indicate that our proposed model can achieve better performance in
comparison with other models.","Speaker veriÔ¨Åcation (SV) is a binary classiÔ¨Åcation task that answers the question whether an unknown utterance belongs to its claimed identity. Usually, it can be divided into two categories: textdependent speaker veriÔ¨Åcation (TDSV) and textindependent speaker veriÔ¨Åcation (TISV) [1]. Therein, TISV has no constraint on text content and speakers can say anything to the veriÔ¨Åcation system, which brings great convenience to the users, hence we focus on TISV in this work. Generally speaking, there are two kinds of models in the research of SV: the statistical model and the neural network model [2]. As an efÔ¨Åcient statistical model, ivector [3] achieves great success in TISV task. It compresses both speaker and channel information into a Ô¨Åxeddimensional space called total variability subspace. Recently, with the increasing of the scale of labeled data, more and more re searchers start to pay attention to the neural network model. Under the supervised learning framework, the model could ‚Ä† Corresponding Author: Jianzong Wang, jzwang@188.comautomatically learn the speaker representation through the datadriven training method. Deep neural networks have been shown to be useful for ex tracting speakerdiscriminative feature vectors independently from the ivector framework [3]. With the help of an amount of training data, such approaches have obtained much bet ter results, particularly under the condition of shortduration utterances. In 2014, Ehsan et al. [4] introduced the neural network into speaker veriÔ¨Åcation. At the training step, four fully connected layers are utilized for speaker classiÔ¨Åcation. Meanwhile, the speaker embedding (‚Äòdvector‚Äô) is calculated from averaging the last hidden layer‚Äôs output over frames in veriÔ¨Åcation step. Using this pipeline, more welldesigned neural networks such as convolutional neural network(CNNs) [5], [6] and recurrent neural networks(RNNs) [7] have been proposed for SV task. However, it still needs more powerful deep neural networks to better extract the speaker feature. The attention mechanism [8], [9] is a powerful method which offers a way to obtain an even more discrimina tive utterancelevel feature by explicitly selecting framelevel representations that better represent speaker characteristics. Nowadays, Transformer with selfattention mechanism have become an effective model in a variety of application Ô¨Åelds [10]‚Äì[12], which mainly focus on the processing of deep neural networks on certain areas of feature maps or certain temporal slots, including the scenario of SV [2]. The success achieved by this approach in SV with selfattention mechanism allows models to learn the framelevel features, which are more precise to represent the speaker characteristics. Yet, there are still two issues. First, since it can not extract speaker discriminative features from the raw speech input, it relies on the melfbank or MFCC features. Secondly, the original Transformer structure may have framelevel information waste on output features, which could lead to restrictions on capacity and discrimination of speaker embeddings. Based on above issues, we propose a Transformerbased Timedomain model for SV named DTSV with two major im provements in comparison to the original Transformer in SV , a novel loss function named difÔ¨Çuence loss and a learnable mel fbank feature extractor named timedomain feature extractor . Features extracted by this extractor will be more appropriate to the neural network since the timedomain feature extractor is learned from the raw data distribution. Also, difÔ¨Çuence losscontributes to better obtain the utterancelevel embedding,arXiv:2205.13249v1  [cs.SD]  26 May 2022which summarizes the information from other embeddings via a selfattention mechanism. SpeciÔ¨Åcally, this loss indicates the distance among features of the Ô¨Årst frame and other frames on each layer, thus enhancing the speakerrelated information in the utterancelevel embedding while weakening the speaker related information among other frame embeddings. In par ticular, we propose two architectures with different numbers of layers, which are DTSVlight and DTSV . Both of them are wellperformed in our experiments while the DTSVlight could achieve competitive performance compared to other light models with 10 times smaller GFLOPs. Our main contributions are as follows: An utterancelevel speaker representation based on Trans former is presented, via proposing a novel difÔ¨Çuence loss to aggregate framelevel features on each layer to an utterancelevel speaker representation while weaken the speakerrelated information in the framelevel embed dings. A learnable melfbank features extractor named time domain feature extractor is introduced, which could ex tract features from speech signal like melfbank more precisely and efÔ¨Åciently than the standard melfbank extractor. A Transformerbased timedomain speaker veriÔ¨Åcation model is designed to take advantage of the above two modules, achieving faster training speed and higher ac curacy. II. R ELATED WORK "
400,Iris Verification with Convolutional Neural Network and Unit-Circle Layer.txt,"We propose a novel convolutional neural network to verify a~match between two
normalized images of the human iris. The network is trained end-to-end and
validated on three publicly available datasets yielding state-of-the-art
results against four baseline methods. The network performs better by a 10%
margin to the state-of-the-art method on the CASIA.v4 dataset. In the network,
we use a novel Unit-Circle Layer layer which replaces the Gabor-filtering step
in a common iris-verification pipeline. We show that the layer improves the
performance of the model up to 15% on previously-unseen data.","Iris veriÔ¨Åcation is a biometric technique used for human identiÔ¨Åcation. Given a pair of images of human irises, the task is to decide whether the irises match. Iris veriÔ¨Åcation is applied widely, e.g., in border control, citizen authentication, or in forensics [21]. Common iris veriÔ¨Åcation pipeline has three steps ‚Äì iris detection, feature extraction, and matching (see Fig. 2, interested reader is referred, e.g., to [ 5]). First, an iris is found and normalized. Second, the normalized iris is typically convolved with Gabor Ô¨Ålters and converted into a ‚Äúbitcode‚Äù, i.e. a matrix of binary numbers. Third, two bitcodes are compared. The bitcodes match if their Hamming distance is smaller than a given threshold. Feature extraction and matching are highly datadependent in a common iris veriÔ¨Åcation pipeline and therefore require parametertuning. Since the task is not convex, an exhaustive search for parameters is performed. In this paper, we propose a method which replaces the feature extraction and matching part of the iris veriÔ¨Åcation pipeline with a single fully convolutional neural network and a single learning rule ‚Äì the backward propagation of errors or backpropagation. The network is trained endtoend using the binary crossentropy loss function. The input of the network is a pair of normalized irises, the output is a single number which is interpreted as a posterior probability of a match (see Fig. 1). So far, convolutional neural networks were used in iris veriÔ¨Åcation for better feature encoding. To encode the features, standard blocks of convolutions, maxpooling, and batch normalization layers were used. We introduce a novel ‚ÄúUnit Circle layer‚Äù that replaces the feature extraction step in a common iris veriÔ¨Åcation pipeline and is learned optimally by backpropagation. The contributions of this paper are the following: (i) we propose a novel method of iris veriÔ¨Åcation that replaces feature extraction and matching steps of a commonly used iris veriÔ¨Åcation pipeline. We replace it with a single convolutional neural network (IrisMatchCNN) trained endtoend that is robust to changes in the iris image acquisition setup, (ii) as opposed to the metriclearning iris veriÔ¨Åcation, we compare two images of irises directly and learn the network with the binary crossentropy loss, (iii) we evaluate the method on three public datasets against four methods achieving stateoftheart results. Work performed during an internship at Microsoft Development Center Serbia d.o.o.arXiv:1906.09472v2  [cs.CV]  17 Sep 2019Iris VeriÔ¨Åcation with Convolutional Neural Network and UnitCircle Layer APREPRINT UnitCircle layers Matcher... Normalized iris 3233 4 4 6060 prediction47stride  1x1 sigmoidsingle  scalar (5x2) x 2 Figure 1: Iris veriÔ¨Åcation with IrisMatchCNN. Two irises are detected and normalized. The normalized irises are fed into the UnitCircle (UC) layers. The responses from the UC layers are concatenated and fed into the Matcher convolutional network. A single scalar is produced ‚Äì the probability of a match. Two irises match if the probability is greater than a given threshold. Compare with a common iris veriÔ¨Åcation pipeline in Fig. 2. 2 Related work "
210,QEBVerif: Quantization Error Bound Verification of Neural Networks.txt,"To alleviate the practical constraints for deploying deep neural networks
(DNNs) on edge devices, quantization is widely regarded as one promising
technique. It reduces the resource requirements for computational power and
storage space by quantizing the weights and/or activation tensors of a DNN into
lower bit-width fixed-point numbers, resulting in quantized neural networks
(QNNs). While it has been empirically shown to introduce minor accuracy loss,
critical verified properties of a DNN might become invalid once quantized.
Existing verification methods focus on either individual neural networks (DNNs
or QNNs) or quantization error bound for partial quantization. In this work, we
propose a quantization error bound verification method, named QEBVerif, where
both weights and activation tensors are quantized. QEBVerif consists of two
parts, i.e., a differential reachability analysis (DRA) and a mixed-integer
linear programming (MILP) based verification method. DRA performs difference
analysis between the DNN and its quantized counterpart layer-by-layer to
compute a tight quantization error interval efficiently. If DRA fails to prove
the error bound, then we encode the verification problem into an equivalent
MILP problem which can be solved by off-the-shelf solvers. Thus, QEBVerif is
sound, complete, and reasonably efficient. We implement QEBVerif and conduct
extensive experiments, showing its effectiveness and efficiency.","In the past few years, the development of deep neural networks (DNNs) has grown at an impressive pace owing to their outstanding performance in solving various complicated tasks [23,28]. However, modern DNNs are often large in size and contain a great number of 32bit floatingpoint parameters to achieve competitive performance. Thus, they often result in high computational costs and excessive storage requirements, hindering their deployment on resource constrained embedded devices, e.g., edge devices. A promising solution is to quantize the weights and/or activation tensors as fixedpoint numbers of lower bitwidth [17,21,25,35]. For example, TensorFlow Lite [18] supports quantiza tion of weights and/or activation tensors to reduce model size and latency, andarXiv:2212.02781v2  [cs.LG]  23 May 20232 Y. Zhang et al. Tesla FSDchip [61] stores all the data and weights of a network in the form of 8bit integers. In spite of the empirically impressive results which show there is only mi nor accuracy loss, quantization does not necessarily preserve properties such as robustness [16]. Even worse, input perturbation can be amplified by quantiza tion[11,36],worseningtherobustnessofquantizedneuralnetworks(QNNs)com pared to their DNN counterparts. Indeed, existing neural network quantization methods focus on minimizing its impact on model accuracy (e.g., by formulat ing it as an optimization problem that aims to maximize the accuracy [27,43]). However, they cannot guarantee that the final quantization error is always lower than a given error bound, especially when some specific safetycritical input re gions are concerned. This is concerning as such errors may lead to catastrophes when the quantized networks are deployed in safetycritical applications [14,26]. Furthermore, analyzing (in particular, quantifying) such errors can also help us understand how quantization affect the network behaviors [33], and provide in sights on, for instance, how to choose appropriate quantization bit sizes without introducing too much error. Therefore, a method that soundly quantifies the errors between DNNs and their quantized counterparts is highly desirable. There is a large and growing body of work on developing verification methods for DNNs [2,12,13,15,19,24,29,30,32,37,38,51,54,55,58‚Äì60,62] and QNNs [1,3, 16,22,46,65,67], aiming to establish a formal guarantee on the network behav iors. However, all the abovementioned methods focus exclusively on verifying individual neural networks. Recently, Paulsen et al. [48,49] proposed differen tial verification methods, aimed to establish formal guarantees on the difference between two DNNs. Specifically, given two DNNs N1andN2with the same network topology and inputs, they try to prove that |N1(x)‚àí N 2(x)|< œµfor all possible inputs x‚àà X, where Xis the interested input region. They presented fast and sound difference propagation techniques followed by a refinement of the input region until the property can be successfully verified, i.e., the property is either proved or falsified by providing a counterexample. This idea has been ex tended to handle recurrent neural networks (RNNs) [41] though the refinement is not considered therein. Although their methods [41,48,49] can be used to an alyze the error bound introduced by quantizing weights (called partially QNNs), they are not complete and cannot handle the cases where both the weights and activation tensors of a DNN are quantized to lower bitwidth fixedpoint num bers (called fullyQNNs). We remark that fully QNN can significantly reduces energyconsumption (floatingpointoperations consume much more energy than integeronlyoperations) [61]. Main Contributions. We propose a sound and complete Quantization Error BoundVerification method ( QEBVerif ) to efficiently and effectively verify if the quantization error of a fullyQNN w.r.t. an input region and its original DNN is always lower than an error bound (a.k.a. robust error bound [33]). QEBVerif first conducts a novel reachability analysis to quantify the quantization errors, which is referred to as differential reachability analysis (DRA). Such an analysis yields two results: (1) Proved, meaning that the quantization error is proved toQEBVerif : Quantization Error Bound Verification of Neural Networks 3 be always less than the given error bound; or (2) Unknown , meaning that it fails to prove the error bound, possibly due to a conservative approximation of the quantization error. If the outcome is Unknown , we further encode this quanti zation error bound verification problem into an equivalent mixedinteger linear programming (MILP) problem, which can be solved by offtheshelf solvers. There are two main technical challenges that must be addressed for DRA. First, the activation tensors in a fully QNN are discrete values and contribute additional rounding errors to the final quantization errors, which are hard to propagate symbolically and make it difficult to establish relatively accurate dif ference intervals. Second, much more activationpatterns (i.e., 3√ó6 = 18) have to consider in a forward propagation, while 9 activationpatterns are sufficient in [48,49], where an activationpattern indicates the status of the output range of a neuron. A neuron in a DNN under an input region has 3 patterns: always active (i.e., output ‚â•0), alwaysinactive (i.e., output <0), or both possible. A neuron in a QNN has 6 patterns due to the clamp function (cf. Definition 2). We remark that handling these different combinations efficiently and soundly is highly nontrivial. To tackle the above challenges, we propose sound transforma tions for the affine and activation functions to propagate quantization errors of two networks layerbylayer. Moreover, for the affine transformation, we provide two alternative solutions: intervalbased andsymbolicbased . The former directly computes sound difference intervals via interval analysis [42], while the latter leverages abstract interpretation [10] to compute sound and symbolic difference intervals, using the polyhedra abstract domain. In comparison, the symbolic based one is usually more accurate but less efficient than the intervalbased one. Note that though existing tools can obtain quantization error intervals by inde pendently computing the output intervals of two networks followed by interval subtractions, such an approach is often too conservative. To resolve those problems that cannot be proved via our DRA, we resort to the sound and complete MILPbased verification method. Inspired by the MILP encoding of DNN and QNN verification [39,40,67], we propose a novel MILP encoding for verifying quantization error bounds. QEBVerif represents both the computationsoftheQNNandtheDNNinmixedintegerlinearconstraintswhich are further simplified using their own output intervals. Moreover, we also encode the output difference intervals of hidden neurons from our DRA as mixedinteger linear constraints to boost the verification. We implement our method as an endtoend tool and use Gurobi [20] as our backend MILP solver. We extensively evaluate it on a large set of verifica tion tasks using neural networks for ACAS Xu [26] and MNIST [31], where the number of neurons varies from 310 to 4890, the number of bits for quantizing weights and activation tensors ranges from 4 to 10 bits, and the number of bits for quantizing inputs is fixed to 8 bits. For DRA, we compare QEBVerif with a naive method that first independently computes the output intervals of DNNs and QNNs using the existing stateoftheart (symbolic) interval analysis [22,55], and then conducts an interval subtraction. The experimental results show that both our interval and symbolicbased approaches are much more accurate and4 Y. Zhang et al. can successfully verify much more tasks without the MILPbased verification. We also find that the quantization error interval returned by DRA is getting tighter with the increase of the quantization bit size. The experimental results also confirm the effectiveness of our MILPbased verification method, which can help verify many tasks that cannot be solved by DRA solely. Finally, our re sults also allow us to study the potential correlation of quantization errors and robustness for QNNs using QEBVerif . We summarize our contributions as follows: ‚ÄìWe introduce the first sound, complete and reasonably efficient quantization error bound verification method QEBVerif for fully QNNs by cleverly combin ing novel DRA and MILPbased verification methods. ‚ÄìWe propose a novel DRA to compute sound and tight quantization error intervals accompanied by an abstract domain tailored to QNNs, which can significantly and soundly tighten the quantization error intervals. ‚ÄìWe implement QEBVerif as an endtoend opensource tool [64] and conduct extensive evaluation on various verification tasks, demonstrating its effective ness and efficiency. Outline. Section 2 defines our problem and briefly recap DeepPoly [55]. Sec tion 3 presents our quantization error bound verification method QEBVerif and Section 4 gives our symbolicbased approach used in QEBVerif . Section 5 reports experimental results. Section 6 discusses related work. Finally, we conclude this work in Section 7. The source code of our tool and benchmarks are available at https://github.com/S3Lofficial/QEBVerif. 2 Preliminaries We denote by R,Z,NandBthe sets of realvalued numbers, integers, natu ral numbers, and Boolean values, respectively. Let [n]denote the integer set {1, . . . , n }for given n‚ààN. We useBOLD UPPERCASE (e.g., W) andbold lowercase (e.g., x) to denote matrices and vectors, respectively. We denote by Wi,jthejentry in the ith row of the matrix W, and by xitheith entry of the vector x. Given a matrix Wand a vector x, we use cWandÀÜx(resp.fWand Àúx) to denote their quantized/integer (resp. fixedpoint) counterparts. 2.1 Neural Networks A deep neural network (DNN) consists of a sequence of layers, where the first layer is the input layer , the last layer is the output layer and the others are called hidden layers . Each layer contains one or more neurons. A DNN is feedforward if all the neurons in each noninput layer only receives inputs from the neurons in the preceding layer.QEBVerif : Quantization Error Bound Verification of Neural Networks 5 Definition 1 (Feedforward Deep Neural Network). A feedforward DNN N:Rn‚ÜíRswith dlayers can be seen as a composition of dfunctions such thatN=ld‚ó¶ld‚àí1‚ó¶¬∑¬∑¬∑‚ó¶ l1. Then, given an input x‚ààRn, the output of the DNN y=N(x)can be obtained by the following recursive computation: ‚ÄìInput layer l1:Rn‚ÜíRn1is the identity function, i.e., x1=l1(x) =x; ‚ÄìHidden layer li:Rni‚àí1‚ÜíRnifor2‚â§i‚â§d‚àí1is the function such that xi=li(xi‚àí1) =œï(Wixi‚àí1+bi); ‚ÄìOutput layer ld:Rnd‚àí1‚ÜíRsis the function such that y=xd=ld(xd‚àí1) = Wdxd‚àí1+bd; where n1=n,Wiandbiare the weight matrix and bias vector in the ith layer, andœï(¬∑)is the activation function which acts elementwise on an input vector. In this work, we focus on feedforward DNNs with the most commonly used acti vation functions:therectified linearunit(ReLU) function,definedas ReLU (x) = max(x,0). A quantized neural network (QNN) is structurally similar to its realvalued counterpart, except that all the parameters, inputs of the QNN, and outputs of all the hidden layers are quantized into integers according to the given quantiza tion scheme. Then, the computation over realvalued arithmetic in a DNN can be replaced by the computation using integer arithmetic, or equally, fixedpoint arithmetic. In this work, we consider the most common quantization scheme, i.e., symmetric uniform quantization [44]. We first give the concept of quantization configuration which effectively defines a quantization scheme. Aquantization configuration Cis a tuple ‚ü®œÑ, Q, F ‚ü©, where QandFare the total bit size and the fractional bit size allocated to a value, respectively, and œÑ‚àà {+,¬±}indicates if the quantized value is unsigned or signed. Given a real number x‚ààRand a quantization configuration C=‚ü®œÑ, Q, F ‚ü©, its quantized integer counterpart ÀÜxand the fixedpoint counterpart Àúxunder the symmetric uniform quantization scheme are: ÀÜx=clamp (‚åä2F¬∑x‚åâ,Clb,Cub)and Àúx= ÀÜx/2F where Clb= 0andCub= 2Q‚àí1ifœÑ= +,Clb=‚àí2Q‚àí1andCub= 2Q‚àí1‚àí1oth erwise, and ‚åä¬∑‚åâis the roundtonearest integer operator. The clamping function clamp (x, a, b )with a lower bound aand an upper bound bis defined as: clamp (x, a, b ) =Ô£± Ô£¥Ô£≤ Ô£¥Ô£≥a,ifx < a ; x,ifa‚â§x‚â§b; b,ifx > b. Definition 2 (Quantized Neural Network). Given quantization configura tions for the weights, biases, output of the input layer and each hidden layer as Cw=‚ü®œÑw, Qw, Fw‚ü©,Cb=‚ü®œÑb, Qb, Fb‚ü©,Cin=‚ü®œÑin, Qin, Fin‚ü©,Ch=‚ü®œÑh, Qh, Fh‚ü©, the quantized version (i.e., QNN) of a DNN Nwith dlayers is a function bN:Zn‚ÜíRssuch that bN=ÀÜld‚ó¶ÀÜld‚àí1‚ó¶ ¬∑¬∑¬∑ ‚ó¶ ÀÜl1. Then, given a quantized in putÀÜx‚ààZn, the output of the QNN ÀÜy=bN(ÀÜx)can be obtained by the following recursive computation:6 Y. Zhang et al. x!!x""!x!""x""""x#$ 1.2  0.7 0.8  0.2 0.3 0 .7 (a) DNN Ne x""!!x""""!x""!""x""!""x""!# 5  3 3  1 1 3 (b) QNN bNe Fig. 1:A 3layer DNN Neand its quantized version bNe. ‚ÄìInput layer ÀÜl1:Zn‚ÜíZn1is the identity function, i.e., ÀÜx1=ÀÜl1(ÀÜx) =ÀÜx; ‚ÄìHidden layer ÀÜli:Zni‚àí1‚ÜíZnifor2‚â§i‚â§d‚àí1is the function such that for each j‚àà[ni], ÀÜxi j=clamp (‚åä2FicWi j,:¬∑ÀÜxi‚àí1+ 2Fh‚àíFbÀÜbi j‚åâ,0,Cub h), where FiisFh‚àíFw‚àíFinifi= 2, and‚àíFwotherwise; ‚ÄìOutput layer ÀÜld:Znd‚àí1‚ÜíRsis the function such that ÀÜy=ÀÜxd=ÀÜld(ÀÜxd‚àí1) = 2‚àíFwcWdÀÜxd‚àí1+ 2Fh‚àíFbÀÜbd; where for every 2‚â§i‚â§dandk‚àà[ni‚àí1],cWi j,k=clamp (‚åä2FwWi j,k‚åâ,Clb w,Cub w)is the quantized weight and ÀÜbi j=clamp (‚åä2Fbbi j‚åâ,Clb b,Cub b)is the quantized bias. We remark that 2Fiand2Fh‚àíFbin Definition 2 are used to align the precision between the inputs and outputs of hidden layers, and Fifori= 2andi >2 becausequantizationbitsizesfortheoutputsoftheinputlayerandhiddenlayers can be different. 2.2 Quantization Error Bound and its Verification Problem We now give the formal definition of the quantization error bound verification problem considered in this work as follows. Definition 3 (Quantization Error Bound). Given a DNN N:Rn‚ÜíRs, the corresponding QNN bN:Zn‚ÜíRs, a quantized input ÀÜx‚ààZn, a radius r‚ààN and an error bound œµ‚ààR. The QNN bNhas a quantization error bound of œµw.r.t. the input region R(ÀÜx, r) ={ÀÜx‚Ä≤‚ààZn| ||ÀÜx‚Ä≤‚àíÀÜx||‚àû‚â§r}if for every ÀÜx‚Ä≤‚ààR(ÀÜx, r), we have ||2‚àíFhbN(ÀÜx‚Ä≤)‚àí N(x‚Ä≤)||‚àû< œµ, where x‚Ä≤=ÀÜx‚Ä≤/(Cub in‚àí Clb in). Intuitively, quantizationerrorbound is the bound of the output difference of the DNN and its quantized counterpart for all the inputs in the input region. In this work, we obtain the input for DNN via dividing ÀÜx‚Ä≤by(Cub in‚àí Clb in)to allow input normalization. Furthermore, 2‚àíFhis used to align the precision between the outputs of QNN and DNN. Example 1. Consider the DNN Newith 3 layers (one input layer, one hidden layer, and one output layer) given in Figure 1, where weights are associatedQEBVerif : Quantization Error Bound Verification of Neural Networks 7 with the edges and all the biases are 0. The quantization configurations for the weights, the output of the input layer and hidden layer are Cw=‚ü®¬±,4,2‚ü©, Cin=‚ü®+,4,4‚ü©andCh=‚ü®+,4,2‚ü©. Its QNN bNeis shown in Figure 1. Given a quantized input ÀÜx= (9,6)and a radius r= 1, the input region for QNNbNeisR((9,6),1) ={(x, y)‚ààZ2|8‚â§x‚â§10,5‚â§y‚â§7}. Since Cub in= 15 andClb in= 0, by Definitions 1, 2, and 3, we have the maximum quantization error as max (2‚àí2bNe(ÀÜx‚Ä≤)‚àí N e(ÀÜx‚Ä≤/15)) = 0 .067forÀÜx‚Ä≤‚ààR((9,6),1). Then, bNehas a quantization error bound of œµw.r.t. input region R((9,6),1)for any œµ >0.067. We remark that if only weights are quantized and the activation tensors are floatingpoint numbers, the maximal quantization error of bNefor the input region R((9,6),1)is 0.04422, which implies that existing methods [48,49] cannot be used to analyze the error bound for a fully QNN. In this work, we focus on the quantization error bound verification problem for classification tasks. Specifically, for a classification task, we only focus on the output difference of the predicted class instead of all the classes. Hence, given a DNN N, a corresponding QNN bN, a quantized input ÀÜxwhich is classified to class gby the DNN N, a radius rand an error bound œµ, the quantization error bound property P(N,bN,ÀÜx, r, œµ)for a classification task can be defined as follows: V ÀÜx‚Ä≤‚ààR(ÀÜx,r)"
513,Delta-net: Real-time Network Verification Using Atoms.txt,"Real-time network verification promises to automatically detect violations of
network-wide reachability invariants on the data plane. To be useful in
practice, these violations need to be detected in the order of milliseconds,
without raising false alarms. To date, most real-time data plane checkers
address this problem by exploiting at least one of the following two
observations: (i) only small parts of the network tend to be affected by
typical changes to the data plane, and (ii) many different packets tend to
share the same forwarding behaviour in the entire network. This paper shows how
to effectively exploit a third characteristic of the problem, namely:
similarity among forwarding behaviour of packets through parts of the network,
rather than its entirety. We propose the first provably amortized quasi-linear
algorithm to do so. We implement our algorithm in a new real-time data plane
checker, Delta-net. Our experiments with SDN-IP, a globally deployed ONOS
software-defined networking application, and several hundred million IP prefix
rules generated using topologies and BGP updates from real-world deployed
networks, show that Delta-net checks a rule insertion or removal in
approximately 40 microseconds on average, a more than 10X improvement over the
state-of-the-art. We also show that Delta-net eliminates an inherent bottleneck
in the state-of-the-art that restricts its use in answering Datalog-style ""what
if"" queries.","In an evermore interconnected world, network trafÔ¨Åc is increasingly diverse and demanding, ranging from com munication between small everyday devices to large scale data centres across the globe. This diversity has driven the design and rapid adoption of new open net working architectures (e.g. [41]), built on programmable network switches, which make it possible to separate the control plane from the data plane. This separation opensup interesting avenues for innovation [37], including rig orous analysis for Ô¨Ånding networkrelated bugs. Finding these bugs automatically poses the following challenges. Since the control plane is typically a Turingcomplete program, the problem of automatically proving the pres ence and absence of bugs in the control plane is generally undecidable. However, the data plane, which is produced by the control plane, can be automatically analyzed. While the problem of checking reachability properties in the data plane is generally NPhard [34], the prob lem becomes polynomialtime solvable in the restricted, but not uncommon, case where network switches only forward packets by matching IP preÔ¨Åxes [36]. This the oretical fact helps to explain why realtime data plane checkers [27, 25, 55] can often automatically detect vi olations of networkwide invariants on the data plane in the order of milliseconds, without raising false alarms. To achieve this, most realtime network veriÔ¨Åcation techniques exploit at least one of the following two ob servations: (i) only small parts of the network tend to be affected by typical changes to the data plane [27, 25], and (ii) many different packets often share the same forward ing behaviour in the entire network [27, 55]. Both ob servations are signiÔ¨Åcant because the former gives rise to incremental network veriÔ¨Åcation in which only changes between two data plane snapshots are analyzed, whereas the latter means that the analysis can be performed on a representative subset of network packets in the form of packet equivalence classes [27, 25, 55]. In spite of these advances, it is so far an open problem how to efÔ¨Åciently handle operations that involve swaths of packet equivalence classes [27]. This is problem atic because it limits the realtime analysis of network failures, which are common in industryscale networks, e.g. [13, 4]. Moreover, it essentially prevents data plane checkers from being used to answer ‚Äúwhat if‚Äù queries in the style of recent Datalog approaches [17, 33] because these hypothetical scenarios typically involve checking the fate of many or all packets in the entire network. 1arXiv:1702.07375v1  [cs.NI]  23 Feb 2017To address this problem, this paper shows how to effectively exploit a third characteristic of data plane checking, namely: similarity among forwarding be haviour of packets through parts of the network, rather than its entirety. We show that our approach addresses fundamental limitations ( x2) in the design of the cur rently most advanced data plane checker, VeriÔ¨Çow [27]. In this paper, we propose a new realtime data plane checker, Deltanet ( x3). Instead of constructing multi ple forwarding graphs for representing the Ô¨Çow of pack ets in the network [27], Deltanet incrementally trans forms a single edgelabelled graph that represents all Ô¨Çows of packets in the entire network. We present the Ô¨Årst provably amortized quasilinear algorithm to do so (Theorem 1). Our algorithm incrementally maintains the latticetheoretical concept of atoms : a set of mutually disjoint ranges through which it is possible to analyze all Boolean combinations of IP preÔ¨Åx forwarding rules in the network so that every possible forwarding table over these rules can be concisely expressed and efÔ¨Åciently checked. This approach is inspired by Yang and Lam‚Äôs atomic predicates veriÔ¨Åer [55]. While more general, their algorithm has a quadratic worstcase time complexity, whereas ours is quasilinear. Since Deltanet‚Äôs atom rep resentation is based on lattice theory, it can be seen as an abstract domain (e.g. [11]) for analyzing forwarding rules. What makes our abstract domain different from traditional ones is that we dynamically reÔ¨Åne its preci sion so that false alarms never occur. For our performance evaluation ( x4), we use data sets comprising several hundred million IP preÔ¨Åx rules gen erated from the UC Berkeley campus, four Rocketfuel topologies [49] and realworld BGP updates [46]. As part of our experiments, we run SDNIP [31, 47], one of the most mature and globally deployed softwaredeÔ¨Åned networking applications in the ONOS project [7, 42]. We show that Deltanet checks a rule insertion or removal in tens of microseconds on average, a more than 10 im provement over the stateoftheart [27]. Furthermore, as an exemplar of ‚Äúwhat if‚Äù scenarios, we adapt a link fail ure experiment by Khurshid et al. [27], and show that Deltanet performs several orders of magnitude faster than VeriÔ¨Çow [27]. We discuss related work in x5. Contributions. Our main contributions are as follows: Deltanet (x3), a new realtime data plane checker that incrementally maintains a compact representation about the Ô¨Çows of all packets in the network, thereby supporting a broader class of scenarios and queries. new realistic benchmarks ( x4.2.2) with an open source, globally deployed SDN application [47]. experimental results ( x4.3) that show Deltanet is more than 10faster than the stateoftheart in checking rule updates, while also making it now feasi ble to answer an expensive class of ‚Äúwhat if‚Äù queries. r1r2r3r4 r4r1r2r3 s1s2s3s4 G1G2G3Figure 1: When rule r4(red edge) is inserted into switch s1, VeriÔ¨Çow constructs at least three forwarding graphs, which signiÔ¨Åcantly overlap with each other. 2 Overview of approach In this section, we motivate and explain our approach through a simple example ( x2.1) that illustrates how Deltanet differs from the currently most advanced data plane checker, VeriÔ¨Çow [27]. In addition to performance considerations, we follow three design goals ( x2.2). 2.1 Example Our example is based on a small network of four switches, shown in the upperleft corner of Figure 1. The data plane in this network is depicted as a directed graph in which each edge denotes an IP preÔ¨Åx forwarding rule. For example, rule r1in Figure 1 is assumed to determine the packet Ô¨Çow for a speciÔ¨Åc destination IP preÔ¨Åx from switch s1tos2. Suppose the network comprises rules r1, r2andr3(black edges) installed on switches s1,s2and s3, respectively. Since each rule matches packets by a destination IP preÔ¨Åx, we can represent each rule‚Äôs match condition by an interval. For example, the IP preÔ¨Åx 0:0:0:10=31 (using the IPv4 CIDR format) corresponds to the halfclosed interval [10 : 12 ) =f10;11gbecause 0:0:0:10=31 is equivalent to the 32bit binary sequence that starts with all zeros and ends with 101 wherede notes an arbitrary bit. Here, we depict the intervals of all three rules as parallel black lines (in an arbitrary order) in the upperright half of Figure 1. The interpretation is that all three rules‚Äô IP preÔ¨Åxes overlap with each other. Let us assume we are interested in checking the data plane for forwarding loops. VeriÔ¨Çow then Ô¨Årst partitions all packets into packet equivalences classes , as explained next. Consider a new rule r4(red edge in Figure 1) to be installed on switch s1such that rule r4has a higher prior ity than the existing rule r1on switch s1. As depicted in the upper half of Figure 1, the new rule r4overlaps with 2r1r2r3r4Œ±1Œ±4Œ±2Œ±3Œ±1,	Œ±2,	Œ±3,	Œ±4Œ±2,	Œ±3Œ±3Œ±1Œ±3Œ±2,	Œ±3Œ±2,	Œ±3,	Œ±4r4r1r2r3 s1s2s3s4 Figure 2: Rather than constructing multiple forwarding graphs that potentially overlap (Figure 1), Deltanet in crementally transforms a single edgelabelled graph. all the existing rules in the network, irrespective of the switch on which they are installed. VeriÔ¨Çow identiÔ¨Åes at least three equivalence classes that are affected by the new rule, each of which denotes a set of packets that ex perience the same forwarding behaviour throughout the network. Here, we depict equivalence classes by three interval segments (gray vertical dashed lines). For each equivalence class, VeriÔ¨Çow constructs a for warding graph (denoted by G1,G2andG3in Figure 1) that represent how packets in each equivalence class can Ô¨Çow through the network. VeriÔ¨Çow can now check for, say, forwarding loops by traversing G1,G2andG3. Note that the edge that represents the packet Ô¨Çow from switch s1tos2is excluded from all three forwarding graphs be cause on switch s1, for the three depicted equivalence classes, the packet Ô¨Çow is determined by the higher priority rule r4rather than the lowerpriority rule r1. Crucially, in our example, the forwarding graphs that VeriÔ¨Çow constructs are essentially the same to previously constructed ones (dashed areas) except for the new edge from switch s1tos4. In addition, G1,G2andG2share much in common, e.g. G2andG3have the same edge from switch s2tos3. As the number of rules in the network increases, so may the commonality among for warding graphs. In real networks, this leads to inefÔ¨Åcien cies that pose problems under realtime constraints. We now illustrate how our approach avoids these kind of inefÔ¨Åciencies. For illustrative purposes, assume we start again with the network in which only rules r1,r2and r3(black edges) have been installed on switches s1,s2 ands3, respectively. The collection of IP preÔ¨Åxes in the network induces halfclosed intervals, each of which we call an atom . A set of atoms can represent an IP preÔ¨Åx. For example, as shown at the top of Figure 2, the set fa2;a3grepresents the IP preÔ¨Åx of rule r2. At the core of our approach is a directed graph whose Start  New atoms required? Modify forwarding table  Create new atoms   End Transform edge labelled graph Yes  No  More modifications?  No Yes  Check properties   Refine precision    of abstraction  ‚ë†  ‚ë°  ‚ë¢ Figure 3: Deltanet incrementally maintains atoms, a family of sets of packets that can represent all Boolean combinations of IP preÔ¨Åx forwarding rules. edges are labelled by atoms. The purpose of this edge labelled graph is to represent packet Ô¨Çows in the en tire network. For example, to represent that r2forwards packets from switch s2tos3we label the corresponding edge in the directed graph with the atoms a2anda3. Of course, an edgelabelled graph that represents all Ô¨Çows in the network may need to be transformed when a new rule is inserted or removed. The bottom of Figure 2 illustrates the nature of such a graph transformation in the case where rule r4is inserted into switch s1. The point of the drawing is threefold. First, observe that the rule insertion of r4results in the creation of a new atom a4(red label in the graph on the bottomleft corner). Us ing the newly created atom, r4‚Äôs IP preÔ¨Åx can now be precisely represented as the set of atoms fa2;a3;a4g. Second, when a new atom, such as a4, is created, exist ing atom representations may need to be updated. For example, r1‚Äôs IP preÔ¨Åx on the edge from switch s1tos2 needs to be now represented by four instead of only three atoms. Finally, since rule r4, recall, has higher priority than rule r1, three of those four atoms need be moved to the newly inserted edge from switch s1tos4(as shown by a dashed arrow in Figure 2). This results in the edge labelled graph shown in the bottomright corner of Fig ure 2 where the edges from switch s1correspond to the forwarding action of the rules r1andr4and are labelled by the set of atoms fa1gandfa2;a3;a4g, respectively. Crucially, note how our approach avoids the construction ofmultiple overlapping forwarding graphs by transform ing a single edgelabelled graph instead. Deltanet‚Äôs key components and sequence of steps are depicted in Figure 3. In this Ô¨Çowchart, the steps in shaded areas ‚Äî annotated by f1;2gandf3gin Fig ure 3 ‚Äî are new and described in x3.1 andx3.2, respec tively. Here, we only highlight two main fundamental differences between Deltanet and VeriÔ¨Çow: 3r4r1r2r3 s1s2s3s4(a) VeriÔ¨Çow r4r1r2r3 s1s2s3s4 (b) Deltanet Figure 4: Comparison of processed rules (black edges). VeriÔ¨Çow generally has to traverse rules in different switches to compute equivalence classes and forward ing graphs: in our example, when rule r4is inserted into switch s1, VeriÔ¨Çow traverses all rules in the net work (four black edges in Figure 4a). By contrast, our approach concentrates on the affected rules in the modiÔ¨Åed switch. For example, when rule r4is inserted into switch s1, the two black edges in Figure 4b show that only rules r1andr4on switch s1are inspected by Deltanet to transform the edgelabelled graph. VeriÔ¨Çow recomputes affected equivalence classes and forwarding graphs each time a rule is inserted or re moved, whereas Deltanet incrementally transforms a single edgelabelled graph to represent the Ô¨Çows of allpackets in the entire network. This signiÔ¨Åcantly broadens the scope of Deltanet ( x2.2) because it can more efÔ¨Åciently handle network failures and ‚Äúwhat if‚Äù queries regarding many or all packets in the network. 2.2 Functional design goals In addition to more stringent realtime constraints, our work is guided by the following three design goals: 1. Similar to Datalogbased approaches [17, 33], we want to efÔ¨Åciently Ô¨Ånd allpackets that can reach a node Bfrom A, avoiding restrictions of SAT/SMT based data plane checkers (e.g. [34]), which can solve a broader class of problems but require multiple calls to their underlying SAT/SMT solver to Ô¨Ånd more than one witness for the reachability from AtoB. 2. Our design should support known incremental net work veriÔ¨Åcation techniques that construct forward ing graphs for the purpose of checking reachabil ity properties each time a rule is inserted or re moved [27]. This is important because it preserves Priority IP PreÔ¨Åx Action High 0 :0:0:10=31 drop Low 0 :0:0:0=28 forward Table 1: A forwarding table for a network switch.one of the main characteristics of previous work, namely: it is practical, and no expertise in formal ver iÔ¨Åcation is required to check the data plane. 3. When realtime constraints are less important (as in the case of predeployment testing, e.g. [58]), we want to facilitate the answering of a broader class of (possibly incremental) reachability queries, such asallpairs reachability queries in the style of recent Datalog approaches [17, 33]. These kind of queries generally concern the reachability between allpack ets and pairs of nodes in the network. We also aim at efÔ¨Åciently answering queries in scenarios that involve many or all packets, such as link failures [27]. After explaining the technical details of Deltanet, we describe how it achieves these design goals ( x3.3). 3 Deltanet In this section, we explain Deltanet‚Äôs underlying atom representation (x3.1), and its algorithm for modifying rules through insertion and removal operations ( x3.2). Recall that these two subsections correspond to the steps annotated byf1;2gandf3gin Figure 3, respectively. We illustrate the internal workings of Deltanet using the simple forwarding table in Table 1. It features two rules, rHandrL, whose subscript corresponds to their pri ority: the higherpriority rule, rH, drops packets whose destination address matches the IP preÔ¨Åx 0 :0:0:10=31, whereas the lowerpriority rule, rL, forwards packets des tined to the IP preÔ¨Åx 0 :0:0:0=28. We elide details about the next hop (where a matched packet should be sent) because it is not pertinent to the example. As alluded to in the previous section ( x2.1), we can think of IP preÔ¨Åxes as halfclosed intervals: rH‚Äôs IP pre Ô¨Åx, 0 :0:0:10=31, corresponds to the halfclosed [10 : 12 ). Similarly, 0 :0:0:0=28= [0 : 16 )forrL‚Äôs IP preÔ¨Åx. Of course, this interval representation can be easily gener alized to IPv6 addresses. Next, we show how Deltanet represents rules with such IP preÔ¨Åxes, for some Ô¨Åxed IP address length. 3.1 Atom representation In this subsection, we describe the concept of atoms; how they are maintained is essential to the rule modiÔ¨Åcations algorithms in the next subsection ( x3.2). rH:a1=[10:12 )  rL:a0=[0:10)  a1=[10:12 )  a2=[12:16 )  Figure 5: Atoms for the IP preÔ¨Åx rules in Table 1. 4107!a1 MIN7!a0 87!a4167!a3 127!a2MAX7!a¬• Figure 6: Balanced binary search tree of key/value pairs after inserting the halfclosed intervals from Figure 5. Intuitively, we can segment the IP preÔ¨Åxes of all the rules in the network into disjoint halfclosed intervals, which we call atoms. This kind of segmentation is illus trated in Figure 5 using the rules rHandrLin Table 1.1 By construction of atoms, we can represent an IP preÔ¨Åx of a rule ras a set of atoms . We denote this IP preÔ¨Åx representation by Jinterval (r)K. For exam ple, rH‚Äôs IP preÔ¨Åx, Jinterval (rH)K, corresponds to the singleton set consisting of the atom a1, whereas rL‚Äôs IP preÔ¨Åx is Jinterval (rL)K=fa0;a1;a2g. Using these atoms, we can represent, for example, the set difference Jinterval (rL)K"
481,DeepSplit: Scalable Verification of Deep Neural Networks via Operator Splitting.txt,"Analyzing the worst-case performance of deep neural networks against input
perturbations amounts to solving a large-scale non-convex optimization problem,
for which several past works have proposed convex relaxations as a promising
alternative. However, even for reasonably-sized neural networks, these
relaxations are not tractable, and so must be replaced by even weaker
relaxations in practice. In this work, we propose a novel operator splitting
method that can directly solve a convex relaxation of the problem to high
accuracy, by splitting it into smaller sub-problems that often have analytical
solutions. The method is modular, scales to very large problem instances, and
compromises operations that are amenable to fast parallelization with GPU
acceleration. We demonstrate our method in bounding the worst-case performance
of large convolutional networks in image classification and reinforcement
learning settings, and in reachability analysis of neural network dynamical
systems.","Despite their superior performance, neural networks lack formal guarantees, raising serious concerns about their adoption in safetycritical applications such as autonomous vehicles [ 1] and medical machine learning [ 2]. Motivated by this drawback, there has been an increasing interest in developing tools to verify desirable properties for neural networks, such as robustness to adversarial attacks. Neural network veriÔ¨Åcation refers to the problem of verifying whether the output of a neural network satisÔ¨Åes certain properties for a bounded set of input perturbations. This problem can be framed as optimization problems of the form J‚ãÜ‚Üêminimize J(f(x))subject to x‚ààX, (1) wherefis given by a deep neural network, Jis a realvalued function representing a performance measure (or a speciÔ¨Åcation), and Xis a set of inputs to be veriÔ¨Åed. In this formulation, verifying the neural network amounts to certifying whether the optimal value of (1)is bounded below by a certain threshold. As an example, consider a classiÔ¨Åcation problem with nfclasses, in which for a data point x‚ààRnx,f(x)‚ààRnfdenotes the vector of scores for all the classes. The classiÔ¨Åcation rule is C(x) =arg max1‚â§i‚â§nfe/latticetop if(x)whereeidenotes the ith standard basis. Given a correctly classiÔ¨Åed ‚àóShaoru Chen is with the Department of Electrical and Systems Engineering, University of Pennsylvania, email: srchen@seas.upenn.edu; Eric Wong is with the Computer Science and ArtiÔ¨Åcial Intelligence Laboratory, Massachusetts Institute of Technology, email: wongeric@mit.edu; J. Zico Kolter is with the Computer Science Department, Carnegie Mellon University, email: zkolter@cs.cmu.edu; Mahyar Fazlyab is with the Mathematical Institute for Data Science, Johns Hopkins University, email: mahyarfazlyab@jhu.edu. ‚Ä†The Ô¨Årst two authors contribute equally to this paper. Codes of the presented method are available at https://github.com/ShaoruChen/DeepSplit . 1arXiv:2106.09117v3  [cs.LG]  8 Jul 2022x‚ãÜ‚ààRnxand a perturbation set X‚äÇRnxthat contains x, we say that fis locally robust at x‚ãÜ with respect toXifC(x) =C(x‚ãÜ)for allx‚ààX. Verifying the local robustness at x‚ãÜthen amounts to verifying that the optimal values of the following nf‚àí1optimization problems minimize x‚ààX(ei‚ãÜ‚àíei)/latticetopf(x), i/negationslash=i‚ãÜ, (2) are positive, where i‚ãÜ=C(x‚ãÜ)is the class index of x‚ãÜ. Problem (2)is an instance of (1)whereJis a linear function. Problem (1)is largescale and nonconvex, making it extremely diÔ¨Écult to solve eÔ¨Éciently‚Äìboth in terms of time and memory. For ReLUactivation functions and linear objectives, the problem in (1)can be cast as a MixedInteger Linear Program (MILP) [ 3,4,5,6], which can be solved for the global solution via, for example, BranchandBound (BaB) methods. While we do not expect these approaches to scale to large problems, for small neural networks they can still be practical. Instead of solving (1)for its global minimum, one can instead Ô¨Ånd guaranteed lower bounds on the optimal value via convex relaxations, such as Linear Programming (LP) [ 7] and SemideÔ¨Ånite Programming (SDP) [ 8,9,10]. VeriÔ¨Åcation methods based on convex relaxations are sound but incomplete, i.e., they are guaranteed to detect all false negatives but also produce false positives, whose rate depends on the tightness of the relaxation. Although convex relaxations are polynomial time solvable (in terms of number of decision variables), in practice they are not computationally tractable for largescale neural networks. To improve scalability, these relaxations must typically be further relaxed [7, 11, 12, 13, 14]. Contributions In this work, we propose an algorithm to solve LP relaxations of (1)for their global solution and for largescale feedforward neural networks. Our starting point is to express (1)as a constrained optimization problem whose constraints are imposed by the forward passes in the network. We then introduce additional decision variables and consensus constraints that naturally split the corresponding problem into independent subproblems, which often have closed form solutions. Finally, we employ an operator splitting technique based on the Alternating Direction Method of Multipliers (ADMM) [ 15], to solve the corresponding Lagrangian relaxation of the problem. This approach has several favorable properties. First, the method requires minimal parameter tuning and relies on simple operations, which scale to very large problems and can achieve a good tradeoÔ¨Ä between runtime and solution accuracy. Second, all the solver operations are amenable to fast parallelization with GPU acceleration. Third, our method is fully modular and applies to standard network architectures. We employ our method to compute exact solutions to LP relaxations on the worstcase perfor mance of adversarially trained deep networks, with a focus on networks whose convex relaxations are diÔ¨Écult to solve due to their size. SpeciÔ¨Åcally, we perform extensive experiments in the /lscript‚àû perturbation setting, where we verify robustness properties of image classiÔ¨Åers for CIFAR10 and deep Qnetworks (DQNs) in Atari games [ 16]. Our method is able to solve LP relaxations at scales that are too large for exact MILP veriÔ¨Åers, SDP relaxations, or commercial LP solvers such as Gurobi. We also demonstrate the use of our method in computing reachable set overapproximations of a neural network dynamical system over a long horizon, where our method is compared with the stateoftheart BaB method [17]. 1.1 Related work "
498,Feedforward Neural Networks for Caching: Enough or Too Much?.txt,"We propose a caching policy that uses a feedforward neural network (FNN) to
predict content popularity. Our scheme outperforms popular eviction policies
like LRU or ARC, but also a new policy relying on the more complex recurrent
neural networks. At the same time, replacing the FNN predictor with a naive
linear estimator does not degrade caching performance significantly,
questioning then the role of neural networks for these applications.","Caching is doubly benecial: it reduces data retrieval time by storing a copy at a closer/fasteraccessible location and, at the same time, decreases the load on the remote system where the original version is located. For this reason, caches are ubiquitous in IT systems, ranging from L2 caches built into the CPU to inmemory page caches managed by the operating systems, from local web proxy caches to Internetwide Content Delivery Authors are listed in alphabetical order. 1arXiv:1810.06930v1  [cs.NI]  16 Oct 2018Networks (CDNs) and cloudbased inmemory keyvalue stores like Amazon's ElastiCache. It is dicult to decide which contents should be stored in the cache and which ones should be evicted. Even when the sequence of future requests is known in advance, maximizing the hit ratio is in general a strongly NP complete problem [1]. Moreover, in most cases of practical interest, future requests are unknown and a caching policy may only try to guess what will happen. To this purpose, the policy usually looks at the past sequence of requests to exploit possible elements of predictability, like the fact that future requests are often more likely to be for recently referenced contents (temporal locality) or for related ones (spatial locality). But additional information could be benecial. For example, in a CDN the time of the day, users' proles, and information about what is happening at closeby caches are likely to be correlated with future requests. The rst paper to propose the idea to use machine learning to learn caching rules from available rich data was probably [2]. Nevertheless, the only practical example considered there was collaborative ltering to estimate content popularities at some locations from measurements at other locations. Surprisingly, the idea to use neural networks (NNs) for caching purposes was only explored during the last year in [3, 4, 5, 6, 7]. All these papers (described in Sect. 2) adopt recurrent neural networks with long shortterm memory units (LSTM in what follows), motivated by the fact that LSTM have proved to be very eective to address sequence prediction problems such as those found in natural language processing. LSTM neural networks (LSTMNNs), as all recurrent networks, have feedback loops which give them some kind of memory. They are then more complex (and more dicult to train) than the classic feedforward NNs (FNNs) where signals can only travel one way from the input layer to the output one. The question at the origin of our work was then if the simpler FNNs could also perform well for caching purposes. Answering this simple question has lead us to unexpected conclusions. The paper is organized as follows. After an overview of the related work in Sect. 2, we describe our caching policy and its FNN predictor for content popularity in Sect. 3. In Sect. 4 we present our performance evaluation results on real traces from Akamai CDN. Sect. 5 concludes the paper. 22 Related work "
30,A Neurosymbolic Approach to the Verification of Temporal Logic Properties of Learning enabled Control Systems.txt,"Signal Temporal Logic (STL) has become a popular tool for expressing formal
requirements of Cyber-Physical Systems (CPS). The problem of verifying STL
properties of neural network-controlled CPS remains a largely unexplored
problem. In this paper, we present a model for the verification of Neural
Network (NN) controllers for general STL specifications using a custom neural
architecture where we map an STL formula into a feed-forward neural network
with ReLU activation. In the case where both our plant model and the controller
are ReLU-activated neural networks, we reduce the STL verification problem to
reachability in ReLU neural networks. We also propose a new approach for neural
network controllers with general activation functions; this approach is a sound
and complete verification approach based on computing the Lipschitz constant of
the closed-loop control system. We demonstrate the practical efficacy of our
techniques on a number of examples of learning-enabled control systems.","Learningenabled components (LECs) oÔ¨Äer the promise of datadriven control, and hence they are becoming popular in many Cyberphysical system, CPS, applications. Among LECs, controllers trained using deep learning are becoming popular due to the advances in techniques like deep reinforcement learning and deep imitation learning. On one hand, the use of such LECs has the potential of achieving human level decision making in tasks like autonomous driving, aircraft collision avoidance, and control for aerial vehicles. On the other hand, the use of deep neural network (DNN)based controllers raises serious concerns of safety. ReasoningaboutDNNsisachallengebecauseDNNsarehighlynonlinear[41], and due to the nature of datadriven control, the behavior of a DNN controller at a previously unseen state can be diÔ¨Écult to predict [30]. To address this chal lenge,therehasbeensigniÔ¨Åcantresearchon veriÔ¨Åcation forDNNs.Broadly,therearXiv:2303.05394v1  [eess.SY]  7 Mar 20232 N. Hashemi et al. are two categories of veriÔ¨Åcation methods; the Ô¨Årst category considers DNN con trollersinisolationandreasonsaboutpropertiessuchasinputoutputrobustness [13,22,25], range analysis [12], symbolic constraint propagation through DNNs [29], and overapproximate reachable set computation for DNNs [43]. The sec ond category of methods reasons about DNN controllers in closedloop with a dynamical model of the environment/plant [12,21,20,23]. In this paper, we also address the closedloop veriÔ¨Åcation problem. In this problem, we are typically provided with a set of inital states and a set of unsafe states for the system, and the goal is to prove that starting from an arbitrary initial state, no system behavior ever reaches a state in the unsafe set. However, we extend this problem in a signiÔ¨Åcant manner. First, we assume that the de sired behavior of the closedloop system is speciÔ¨Åed as a bounded horizon Signal Temporal Logic (STL) [33] formula. Second, in contrast to most existing closed loop veriÔ¨Åcation methods that typically assume that an analytic representation of the system dynamics exists, we allow the system dynamics themselves to be represented as a DNN. Such a setting is quite common in techniques such as modelbased deep reinforcement learning [6,7]. This crucially allows us to reason about systems where the analytic representation of the system dynamics may not be available. The central idea in our paper is a neurosymbolic veriÔ¨Åcation approach: we reformulate the robust satisfaction (referred to as robustness) of an STL formula w.r.t. a given trajectory as a feedforward neural network with ReLUactivation functions. We call this transformation STL2NN. We show that the output of STL2NN is positive iÔ¨Ä the STL formula is satisÔ¨Åed by the trajectory. We note that the veriÔ¨Åcation problem only requires establishing that the given closed loop dynamical system satisÔ¨Åes a given STL speciÔ¨Åcation. However, by posing the veriÔ¨Åcation problem as that of checking robust satisfaction, it allows us to conclude that the given DNN controller robustlysatisÔ¨Åes the given speciÔ¨Åcation. We then show that when the DNNcontroller uses ReLUactivation func tions, the problem of closedloop STL veriÔ¨Åcation can be reduced to computing the reachable set for a ReLUDNN. If the controller is not a ReLUneural net work, we propose a technique called LipVerify based on computing the Lipschitz constant of the robustness of the given STL formula (as a function of the initial state). To summarize, the main contributions in this paper are: 1. We formulate a neurosymbolic approach for the closedloop veriÔ¨Åcation of a DNNcontrolled dynamical system against an STLbased speciÔ¨Åcation by converting the given bounded horizon speciÔ¨Åcation into a feedforward ReLUbased DNN that we call STL2NN. 2. For datadriven plant models using ReLUactivation and ReLUactivation based DNNcontrollers, we show that the veriÔ¨Åcation of arbitrary bounded horizon STL properties can be reduced to computing the reach set of the composition of the plant and controller DNNs with STL2NN.VeriÔ¨Åcation of Temporal Logic Properties 3 3. For arbitrary nonlinear plant models3and DNNcontrollers using arbitrary activation functions, we compute Lipschitz constant of the function compo sition of the system dynamics with STL robustness, and use this to provide a sound veriÔ¨Åcation result using systematic sampling. The rest of this paper is as follows. In Section 2, we present the background, primary concepts with STL semantics and problem deÔ¨Ånition. In Section 3, we presentthestepstocharacterize STL2NN.InSection4weclassifytheveriÔ¨Åcation problem based on the involved activation functions and propose a veriÔ¨Åcation method for each class. We also introduce a structure for formulation of veriÔ¨Åca tion problems and introduce our veriÔ¨Åcation toolbox. Finally, we present several case studies and experimental results for our veriÔ¨Åcation methods in Sections 4.3 and 5.1. We conclude with a discussion on related works in Section 6. 2 Preliminaries In this section, we Ô¨Årst provide the mathematical notation and terminology to formulate the problem deÔ¨Ånition. We use bold letters to indicate vectors and vectorvalued functions, and calligraphic letters to denote sets. We assume that thereaderisfamiliarwithfeedforwardneuralnetworks,see[17]forabriefreview. Neural Network Controlled Dynamical Systems (NNCS) . Let sandu respectively denote the state and input control variables that take values from compact setsSRnandCRm, respectively. We use sk(resp. uk) to denote the value of the state variable (resp. control input) at time k. We Ô¨Årst deÔ¨Åne deep neural network controlled systems (NNCS) as a recurrent diÔ¨Äerence equation4: sk+1=f(sk;uk);uk=(sk): (1) Here, fis assumed to be any computable function, and is a (deep) neural network. We note that we can include time as a state, which allows us to encode timevarying plant models as well (where the dynamics corresponding to the time variable simply increment it by 1). Neural Plant Models . In the modelbased development paradigm, designers typically create environment or plant models using laws of physics. However, with increasing complexity of real world environments, the data driven control paradigm suggests the use of machine learning models like Gaussian Process [36] or neural networks as function approximators. Such models typically take 3In the experimental results, we focus on linear and DNN plant models, but our method is applicable to other nonlinear plant models as well. 4We note that in some modeling scenarios, the dynamical equation describing the environment may be provided as continuoustime ODEs. In this case, we assume that we can obtain a diÔ¨Äerence equation (through numerical approximations such as a zeroorder hold of the continuous dynamics). Our veriÔ¨Åcation results are then applicable to the resulting discretetime approximation. Reasoning about behavior between sampling instants can be done using standard error analysis arguments that we do not consider in this paper [4].4 N. Hashemi et al. as input the values of the state and control input variables at time kand predict the value of the state at time k+ 1. In this paper, we focus on environment models that use deep neural networks5. On the other hand linear timeinvariant (LTI) models can be considered as a neural network with only linear activation functions. Finally, we note that our technique can also handle timevarying plant models such as linear timevarying models and DNN plant models that explicitly include time as an input. ClosedloopModelTrajectory,TaskObjectives,andSafetyConstraints . Given a discretetime NNCS as shown in (1), we deÔ¨Åne ISas a set of ini tial states of the system. For a given initial state s0, and a given Ô¨Ånite time horizonK2Z>0, a system trajectory s0is a function from [0;K]toS, where s0(0) = s0, and for all k2[0;K"
186,Knowing When to Stop: Evaluation and Verification of Conformity to Output-size Specifications.txt,"Models such as Sequence-to-Sequence and Image-to-Sequence are widely used in
real world applications. While the ability of these neural architectures to
produce variable-length outputs makes them extremely effective for problems
like Machine Translation and Image Captioning, it also leaves them vulnerable
to failures of the form where the model produces outputs of undesirable length.
This behavior can have severe consequences such as usage of increased
computation and induce faults in downstream modules that expect outputs of a
certain length. Motivated by the need to have a better understanding of the
failures of these models, this paper proposes and studies the novel output-size
modulation problem and makes two key technical contributions. First, to
evaluate model robustness, we develop an easy-to-compute differentiable proxy
objective that can be used with gradient-based algorithms to find
output-lengthening inputs. Second and more importantly, we develop a
verification approach that can formally verify whether a network always
produces outputs within a certain length. Experimental results on Machine
Translation and Image Captioning show that our output-lengthening approach can
produce outputs that are 50 times longer than the input, while our verification
approach can, given a model and input domain, prove that the output length is
below a certain size.","Neural networks with variable output lengths have be come ubiquitous in several applications. In particular, re current neural networks (RNNs) such as LSTMs [17], used work done during an internship at DeepMind |now at Facebook AI Researchto form ‚Äúsequence‚Äù models [30], have been successfully and extensively applied in in image captioning [34, 28, 21, 6, 12, 37, 26, 24, 1], video captioning [33, 38, 35, 40, 41], ma chine translation (MT) [30, 9], summarization [10], and in other sequencebased transduction tasks. The ability of these sequence neural models to generate variablelength outputs is key to their performance on com plex prediction tasks. However, this ability also opens a powerful attack for adversaries that try to force the model to produce outputs of speciÔ¨Åc lengths that, for instance, lead to increased computation or affect the correct operation of downstream modules. To address this issue, we introduce theoutputlength modulation problem where given a spec iÔ¨Åcation of the form that the model should produce out puts with less than a certain maximum length, we want to Ô¨Ånd adversarial examples, i.e.search for inputs that lead the model to produce outputs with a larger length and thus show that the model under consideration violates the speci Ô¨Åcation. Different from existing work on targeted or untar geted attacks where the goal is to perturb the input such that the output is another class or sequence in the development dataset (thus within the dataset distribution), the output modulation problem requires solving a more challenging task of Ô¨Ånding inputs such that the output sequences are outside of the training distribution, which was previously claimed difÔ¨Åcult [5]. The naive approach to the solution of the outputlength modulation problem involves a computationally intractable search over a large discrete search space. To overcome this, we develop an easytocompute differentiable proxy objective that can be used with gradientbased algorithms to Ô¨Ånd outputlengthening inputs. Experimental results on Machine Translation show that our adversarial output lengthening approach can produce outputs that are 50times longer than the input. However, when evaluated on the imagetotext image captioning model, the method is less 4321arXiv:1904.12004v1  [cs.LG]  26 Apr 2019successful. There could have been two potential reasons for this result: the imagetotext architecture is truly robust, or the adversarial approach is not powerful enough to Ô¨Ånd ad versarial examples for this model. To resolve this question, we develop a veriÔ¨Åcation method for checking and formally proving whether a network is consistent with the output size speciÔ¨Åcation for the given range of inputs. To the best of our knowledge, our veriÔ¨Åcation algorithm is the Ô¨Årst for mal veriÔ¨Åcation approach to check properties of recurrent models with variable output lengths. Our Contributions To summarize, the key contributions of this paper are as follows: We propose and formulate the novel outputsize mod ulation problem to study the behaviour of neural archi tectures capable of producing variable length outputs, and we study its evaluation and veriÔ¨Åcation problems. For evaluation, we design an efÔ¨Åciently computable differentiable proxy for the expected length of the out put sequence. Experiments show that this proxy can be optimized using gradient descent to efÔ¨Åciently Ô¨Ånd inputs causing the model to produce long outputs. We demonstrate that popular machine translation mod els can be forced to produce long outputs that are 50 times longer than the input sequence. The long output sequences help expose modes that the model can get stuck in, such as undesirable loops where they con tinue to emit a speciÔ¨Åc token for several steps. We demonstrate the feasibility of formal veriÔ¨Åcation of recurrent models by proposing the use of mixed integer programming to formally verify that a certain neural imagecaptioning model will be consistent with the speciÔ¨Åcation for the given range of inputs. Motivations and Implications Our focus on studying the outputlength modulation problem is motivated by the fol lowing key considerations: Achieving Computational Robustness: Many ML models are now offered as a service to customers via the cloud. In this context, ML services employing variableoutput models could be vulnerable to denial ofservice attacks that cause the ML model to perform wasteful computations by feeding it inputs that induce long outputs. This is particularly relevant for vari able compute models , like Seq2Seq [9, 30]. Given a trained instance of the model, no method is known to check for the consistency of the model with a speciÔ¨Åca tion on the number of computation steps. Understand ing the vulnerabilities of ML models to such output lengthening and computationincreasing attacks is im portant for the safe deployment of ML services.Understanding and Debugging Models: By designing inputs that cause models to produce long outputs, it is possible to reason about the internal representations learned by the model and isolate where the model ex hibits undesirable behavior. For example, we Ô¨Ånd that an English to German sequencetosequence model can produce outputs that end with a long string of ques tion marks (‚Äò?‚Äô). This indicates that when the output decoder state is conditioned on a sequence of ‚Äò?‚Äôs, it can end up stuck in the same state. Uncovering security vulnerabilities through adversar ial stresstesting: The adversarial approach to output length modulation tries to Ô¨Ånd parts of the space of inputs where the model exhibits improper behavior. Such inputs does not only reveal abnormal output size, but could also uncover other abnormalities like the pri vacy violations of the kind that were recently revealed by [4] where an LSTM was forced to output memo rized data. Canonical speciÔ¨Åcation for testing generalization of variableoutput models: Normbounded perturbations of images [31] have become the standard speciÔ¨Åca tion to test attacks and defenses on image classiÔ¨Åers. While the practical relevance of this particular speci Ô¨Åcation can be questioned [14], it is still served as a useful canonical model encapsulating the essential dif Ô¨Åculty in developing robust image classiÔ¨Åers. We be lieve stability of outputlengths can serve a similar pur pose: as a canonical speciÔ¨Åcation for variable output length models. The main difÔ¨Åculties in studying vari able output length models in an adversarial sense (the nondifferentiability of the objective with respect to in puts) are exposed in outputlengthening attack, mak ing it a fertile testing ground for both evaluating attack methods and defenses. We hope that advances made here will facilitate the study of robustness on variable compute models and other speciÔ¨Åcations for variable output models such as monotonicity. 2. Related Work "
439,Digital Image Forensics using Deep Learning.txt,"During the investigation of criminal activity when evidence is available, the
issue at hand is determining the credibility of the video and ascertaining that
the video is real. Today, one way to authenticate the footage is to identify
the camera that was used to capture the image or video in question. While a
very common way to do this is by using image meta-data, this data can easily be
falsified by changing the video content or even splicing together content from
two different cameras. Given the multitude of solutions proposed to this
problem, it is yet to be sufficiently solved. The aim of our project is to
build an algorithm that identifies which camera was used to capture an image
using traces of information left intrinsically in the image, using filters,
followed by a deep neural network on these filters. Solving this problem would
have a big impact on the verification of evidence used in criminal and civil
trials and even news reporting.","Images have become a signiÔ¨Åcant source of information in the modern era. The advent of the Internet and the increasing volume of data and storage facilities has further aided the ease of circulation of images to a large section of the population, be it friends, family or acquaintances. This problem leads to us often Ô¨Ånding ourselves in situations where we question the credibility of a certain image or video. At face value, this may seem inconsequential in most situations, however, this gives power to a large number of people to spread false news and doctored images to suit their own objectives. In this day and age, the advent of many social networking sites has made it imperative to validate images and their sources, to ensure they are authentic and not a false repre sentation of the facts. Most of the new approaches to solve this problem have been very computationally expensive and have required large amounts of data. They use models on large amounts of data with no preprocessing which results in a very brute force approach to solving this problem. These models with a enough data will be able to pick up on trace amounts of information enabling accurate classiÔ¨Åcation. However, we have taken a contrasting approach. We worked with a very small amount of data (2750 images in total) and took a more technical approach to solving the problem. We worked on explicitly extracting information embedded in an image instead of relying purely on the abilityof the network to do so. We explore different forms of in formation in this paper such as Ô¨Ånding Source Pattern Noise (SPN) information, probability plots of noise, detection of image interpolation and even extracting information using a Gray Level Dependency Matrix [2]. During our experiments, some of these methods worked exceedingly well while others led to dead ends, as further described. We are currently working on creating an ensemble of these models to give us the best result. The work we have done so far has given us fairly promising results however we believe that with some more Ô¨Ånetuning it will be a very competitive model. This objective of this project was to solve the multi faceted problem described in the abstract. We aim to prevent falsiÔ¨Åcation of facts and the propagation of fake images or videos through the Internet. II. R ELATED WORK "
228,Towards Probabilistic Verification of Machine Unlearning.txt,"The right to be forgotten, also known as the right to erasure, is the right
of individuals to have their data erased from an entity storing it. The status
of this long held notion was legally solidified recently by the General Data
Protection Regulation (GDPR) in the European Union. Consequently, there is a
need for mechanisms whereby users can verify if service providers comply with
their deletion requests. In this work, we take the first step in proposing a
formal framework to study the design of such verification mechanisms for data
deletion requests -- also known as machine unlearning -- in the context of
systems that provide machine learning as a service (MLaaS). Our framework
allows the rigorous quantification of any verification mechanism based on
standard hypothesis testing. Furthermore, we propose a novel backdoor-based
verification mechanism and demonstrate its effectiveness in certifying data
deletion with high confidence, thus providing a basis for quantitatively
inferring machine unlearning.
  We evaluate our approach over a range of network architectures such as
multi-layer perceptrons (MLP), convolutional neural networks (CNN), residual
networks (ResNet), and long short-term memory (LSTM), as well as over 5
different datasets. We demonstrate that our approach has minimal effect on the
ML service's accuracy but provides high confidence verification of unlearning.
Our proposed mechanism works even if only a handful of users employ our system
to ascertain compliance with data deletion requests. In particular, with just
5% of users participating, modifying half their data with a backdoor, and with
merely 30 test queries, our verification mechanism has both false positive and
false negative ratios below $10^{-3}$. We also show the effectiveness of our
approach by testing it against an adaptive adversary that uses a
state-of-the-art backdoor defense method.","Machine learning models, in particular neural networks, have achieved tremendous success in realworld applications and have driven technology companies, such as Google, Ama zon, Microsoft, to provide machine learning as a service (MLaaS). Under MLaaS, individual users upload personal datasets to the server, the server then trains a ML model on the aggregate dataset and then provides its predictive func tionality as a service to the users. However, recent works have shown that ML models memorize sensitive information of training data [1 ‚Äì4], indicating serious privacy risks to individ ual user data. At the same time, recently enacted legislation, such as the General Data Protection Regulation (GDPR) in the European Union [5] and the California Consumer Privacy Act (CCPA) in the United States [6], recognize the consumers‚Äô right to be forgotten , and legally requires companies to re move a user‚Äôs data from their systems upon the user‚Äôs deletion request. However, there is a noticeable lack of concrete mechanisms that enables individual users to verify compliance of their requests. Prior works in machine unlearning [7 ‚Äì11] focus on the scenario of an honest server who deletes the user data upon request, and do not provide any support for a mechanism to verify unlearning. In this work, we formalize an approach that allows users to rigorously verify, with high conÔ¨Ådence, if a server has ‚Äúdeleted their data‚Äù. Note that it is hard to ascertain if the data was actually physically deleted from storage, and in this work, deletion refers to the exclusion of a user‚Äôs data from a MLaaS‚Äô model training procedure. This is a reasonable model for real world systems such as Clearview AI which contains image data about millions of users and was reported to violate the privacy policies of Twitter [12, 13]. Formalizing Machine Unlearning. In this work, we take the Ô¨Årst step towards solving this open problem of veriÔ¨Åed machine unlearning by individual users in the MLaaS setting. First, we formulate the unlearning veriÔ¨Åcation problem as a hypothesis testing problem [14] (whether the server follows requests to delete users‚Äô data or not) and describe the metric used to evaluate a given veriÔ¨Åcation strategy. Note that for a veriÔ¨Åable unlearning strategy to be effective, it needs to satisfy two important objectives. On the one hand, the mecha 1arXiv:2003.04247v2  [cs.CR]  1 Dec 2020nism should enable individual users to leave a unique trace in the ML model after being trained on user data, which can be leveraged in the veriÔ¨Åcation phase. On the other hand, such a unique trace needs to have negligible impact on the model‚Äôs normal predictive behavior. One possible approach is enabled by membership inference attacks such as Shokri et al. [2], Song et al. [15], or Chen et al. [16]. However, this line of work suffers from a number of limitations ‚Äì low ac curacy due to the training data not being actively perturbed, extensive knowledge of the MLaaS model‚Äôs architecture for whitebox attack variants, access to auxiliary or shadow data and computational power in an extent similar to the MLaaS provider ‚Äì all of which limit the feasibility of such approaches for our problem setting. We propose a novel use of backdoor attacks in ML as our mechanism for probabilistically verify ing machine unlearning and demonstrate how it meets the two requirements above. Proposed Mechanism. In the classical backdoor at tacks [17, 18], the users (adversaries in these settings) ma nipulate part of training data such that the Ô¨Ånal trained ML model (1) returns a particular target label as the classiÔ¨Åca tion on inputs that contain a backdoor trigger (e.g., Ô¨Åxed pattern of pixel values at certain positions in the image) and (2) provides normal prediction in the absence of the trigger. In our machine unlearning veriÔ¨Åcation mechanism, we extend a backdoor proposed by Gu et al. [17]. In our approach, where a fraction of users called privacy enthusiasts are interested in the veriÔ¨Åcation, individually choose a backdoor trigger and the associated target label randomly, then add this trigger to a fraction of their training samples (called data poisoning) and set the corresponding labels as the target label. This lo cally poisoned data is then provided to the MLaaS server. While each privacy enthusiast acts independently, i.e., they do not share information about their individual backdoor or target label, our approach supports an arbitrary fraction of such enthusiasts, up to the point where every user in the train ing dataset is applying our method. We demonstrate that the ML model trained on such data has a high backdoor success rate (i.e., target label classiÔ¨Åcation in the presence of the trig ger) for every user‚Äôs backdoor trigger and target label pair. When the privacy enthusiast later asks the MLaaS provider to delete its data, it can verify whether the provider deleted its data from the ML model by checking the backdoor success rate using its own backdoor trigger with the target label. A low backdoor success rate is indicative of a model that is not trained on the poisoned data and thus signals that the server followed the deletion request. Through a rigorous hypothesis testing formulation, we can show that this mechanism can be used for high conÔ¨Ådence detection of deletion requests. Experimental Evaluation. We theoretically quantify the performance of our backdoorbased veriÔ¨Åcation mechanism under the proposed formulation of hypothesis testing. Further more, we experimentally evaluate our approach over a spec trum of 5 popular datasets (EMNIST, FEMNIST, CIFAR10,ImageNet, and AGNews) and 4 different neural network archi tectures ‚Äì multilayer perception (MLP), convolution neural network (CNN), residual network (ResNet), long shortterm memory (LSTM). We show that our mechanism has excellent performance ‚Äì using 50% poisoned samples and merely 30 test queries achieves both false positive and false negative value below 10"
403,Incremental Verification of Neural Networks.txt,"Complete verification of deep neural networks (DNNs) can exactly determine
whether the DNN satisfies a desired trustworthy property (e.g., robustness,
fairness) on an infinite set of inputs or not. Despite the tremendous progress
to improve the scalability of complete verifiers over the years on individual
DNNs, they are inherently inefficient when a deployed DNN is updated to improve
its inference speed or accuracy. The inefficiency is because the expensive
verifier needs to be run from scratch on the updated DNN. To improve
efficiency, we propose a new, general framework for incremental and complete
DNN verification based on the design of novel theory, data structure, and
algorithms. Our contributions implemented in a tool named IVAN yield an overall
geometric mean speedup of 2.4x for verifying challenging MNIST and CIFAR10
classifiers and a geometric mean speedup of 3.8x for the ACAS-XU classifiers
over the state-of-the-art baselines.","Deep neural networks (DNNs) are being increasingly deployed for safetycritical applications in many domains including autonomous driving [Bojarski et al .2016], healthcare [Amato et al . 2013], and aviation [Julian et al .2018]. However, the blackbox construction, vulnerability against adversarial changes to indistribution inputs [Madry et al .2017; Szegedy et al .2014], and fragility against outofdistribution data [Chen et al .2022; Gokhale et al .2021] is the main hindrance to the trustworthy deployment of deep neural networks in realworld applications. Recent years have witnessed increasing work on developing verifiers for formally checking whether the behavior of DNNs (see [Albarghouthi 2021; Urban and Min√© 2021] for a survey) on an infinite set of inputs is trustworthy or not. For example, existing verifiers can formally prove [Bak et al .2020; Bunel et al . 2020b,a; Ehlers 2017; Gehr et al .2018; Wang et al .2018] that the infinite number of images obtained after varying the intensity of pixels in an original image by a small amount will be classified correctly. Verification yields better insights into the trustworthiness of DNNs than standard testset accuracy measurements, which only check DNN performance on a finite number of inputs. The insights can be used for selecting the most trustworthy DNN for deployment among a set of DNNs trained for the Authors‚Äô addresses: Shubham Ugare, University of Illinois UrbanaChampaign, USA; Debangshu Banerjee, University of Illinois UrbanaChampaign, USA; Sasa Misailovic, University of Illinois UrbanaChampaign, USA; Gagandeep Singh, University of Illinois UrbanaChampaign and VMware Research, USA. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. ¬©2023 Copyright held by the owner/author(s). Publication rights licensed to ACM. 24751421/2023/6ART185 https://doi.org/10.1145/3591299 Proc. ACM Program. Lang., Vol. 7, No. PLDI, Article 185. Publication date: June 2023.arXiv:2304.01874v2  [cs.LG]  12 Jun 2023185:2 Shubham Ugare, Debangshu Banerjee, Sasa Misailovic, and Gagandeep Singh same task. Existing verifiers can be broadly classified as either complete or incomplete. Incomplete methods are more scalable but may fail to prove or disprove a trustworthiness property [Gehr et al . 2018; Salman et al .2019; Singh et al .2019a, 2018, 2019b; Xu et al .2020; Zhang et al .2018]. A complete verifier always verifies the property if the property holds or otherwise returns a counterexample. Complete verification methods are more desirable as they are guaranteed to provide an exact answer for the verification task [Anderson et al .2020; Bak et al .2020; Bunel et al .2020b,a; Ehlers 2017; Ferrari et al .2022; Fromherz et al .2021; Gehr et al .2018; Palma et al .2021; Wang et al .2018, 2021; Zhang et al. 2022]. Limitation of Existing Works: The deployed DNNs are modified for reasons such as approxi mation [Blalock et al .2020; Gholami et al .2021], finetuning [Tajbakhsh et al .2016], model repair [Sotoudeh and Thakur 2019], or transfer learning [Weiss et al .2016]. Various approximations such as quantization, and pruning slightly perturb the DNN weights, and the updated DNN is used for the same task [Gholami et al .2021; Laurel et al .2021; TFLite 2017]. Similarly, finetuning can also be performed to repair the network on buggy inputs while maintaining the accuracy on the original training inputs [Fu and Li 2022]. Each time a new DNN is created, expensive complete verification needs to be performed to check whether it is trustworthy. A fundamental limitation of all existing approaches for complete verification of DNNs is that the verifier needs to be run from scratch endtoend every time the network is even slightly modified. As a result, developers still rely on test set accuracy as the main metric for measuring the quality of a trained network. This limitation of existing verifiers restricts their applicability as a tool for evaluating the trustworthiness of DNNs. This Work: Incremental and Complete Verification of DNNs: In this work, we address the fundamental limitation of existing complete verifiers by presenting IVAN, the first general technique for incremental and complete verification of DNNs. An original network and its updated network have similar behaviors on most of the inputs, therefore the proofs of property on these networks are also related. IVAN accelerates the complete verification of a trustworthy property on the updated network by leveraging the proof of the same property on the original network. IVAN can be built on top of any Branch and Bound (BaB) based method. The BaB verifier recursively partitions the verification problem to gain precision. It is currently the dominant technology for constructing complete verifiers [Anderson et al .2019; Bak et al .2020; Bunel et al .2020b,a; Ehlers 2017; Ferrari et al. 2022; Fromherz et al. 2021; Palma et al. 2021; Wang et al. 2018, 2021; Zhang et al. 2022]. Challenges: The main challenge in building an incremental verifier on top of a nonincremental one is to determine which information to pass on and how to effectively reuse this information. Formal methods research has developed numerous techniques for incremental verification of programs, that reuse the proof from previous revisions for verifying the new revision of the program [Johnson et al.2013; Lakhnech et al .2001; O‚ÄôHearn 2018; Stein et al .2021]. However, often the program commits are local changes that affect only a small part of the big program. In contrast, most DNN updates result in weight perturbation across one or many layers of the network. This poses a different and more difficult challenge than incremental program verification. Additionally, DNN complete verifiers employ distinct heuristics for branching. A key challenge is to develop a generic method that incrementally verifies a network perturbed across multiple layers and is applicable to multiple complete verification methods, yet can provide significant performance benefits. Our Solution: IVAN computes a specification tree ‚Äì a novel tree data structure representing the trace of BaB ‚Äì from the execution of the complete verifier on the original network. We design new algorithms to refine the specification tree to create a more compact tree. At a high level, the refinement involves reordering the branching decisions such that the decisions that worked well in the original verification are prioritized. Besides, it removes the branching decisions that worked poorly in the original verification by pruning nodes and edges in the specification tree. IVAN also improves the branching strategy in BaB for the updated network based on the observed Proc. ACM Program. Lang., Vol. 7, No. PLDI, Article 185. Publication date: June 2023.Incremental Verification of Neural Networks 185:3 Fig. 1. Workflow of IVAN from left to right. ùêºùëâùê¥ùëÅ takes the original network ùëÅ, input specification ùúôand output specification ùúì. It is built on top of a BaBbased complete verifier that utilizes an analyzer ùê¥for the bounding, and heuristic ùêªfor branching. IVAN refines a specification tree ùëáùëÅ ùëì, result of verifying ùëÅ, to create a compact tree ùëáùëÅùëé 0and updated branching heuristic ùêªŒî. IVAN performs faster verification of ùëÅùëéexploiting bothùëáùëÅùëé 0andùêªŒî. effectiveness of branching choices when verifying the original DNN. The compact specification tree and the improved branching strategy guide the BaB execution on the updated network to faster verification, compared to nonincremental verification that starts from scratch. IVAN yields up to 43x speedup over the baseline based on stateoftheart nonincremental verification techniques [Bunel et al .2020b; Henriksen and Lomuscio 2021; Singh et al .2018]. It achieves a geometric mean speedup of 2.4x across challenging fullyconnected and convolutional networks over the baseline. IVAN is generic and can work with various common BaB branching strategies in the literature (input splitting, ReLU splitting). Main Contributions: The main contributions of this paper are: ‚Ä¢We present a novel, general framework for incremental and complete DNN verification by designing new algorithms and data structure that allows us to succinctly encode influential branching strategies to perform efficient incremental verification of the updated network. ‚Ä¢We identify a class of network modifications that can be efficiently verified by our framework by providing theoretical bounds on the amount of modifications. ‚Ä¢We implement our approach into a tool named IVAN and show its effectiveness over multiple stateoftheart complete verification techniques, using distinct branching strategies (ReLU splitting and input splitting), in incrementally verifying both local and global properties of fullyconnected and convolutional networks with ReLU activations trained on the popular ACASXU, MNIST, and CIFAR10 datasets. Our results show that for MNIST and CIFAR10 classifiers, using the ReLU splitting technique [Henriksen and Lomuscio 2021] IVAN yields a geometric mean speedup of 2.4x over the stateoftheart baseline [Bunel et al .2020b; Ehlers 2017]. For ACASXU, using the input splitting technique IVAN achieves a geometric mean speedup of 3.8x over RefineZono [Singh et al. 2019c]. IVAN implementation is opensource, publicly available at https://github.com/uiucfocallab/IVAN. An extended version of this paper containing all the proofs and additional experiments is available at https://arxiv.org/abs/2304.01874. Proc. ACM Program. Lang., Vol. 7, No. PLDI, Article 185. Publication date: June 2023.185:4 Shubham Ugare, Debangshu Banerjee, Sasa Misailovic, and Gagandeep Singh Fig. 2. Example original network ùëÅand its perturbation ùëÅùëé(blue weights). Each layer consists of a linear function followed by the ReLU activation function. ùúôis the input specification and ùúìis the output specification. 2 OVERVIEW Figure 1 illustrates the highlevel idea behind the workings of IVAN. It takes as input the original neural network ùëÅ, the updated network ùëÅùëé, a local or global input region ùúô, and the output property ùúì. The goal of IVAN is to check whether for all inputs in ùúô, the outputs of networks ùëÅandùëÅùëé satisfyùúì.ùëÅandùëÅùëéhave similar behaviors on the inputs in ùúô, therefore the proofs of the property on these networks are also related. IVAN accelerates the complete verification of the property (ùúô,ùúì)onùëÅùëéby leveraging the proof of the same property on ùëÅ. Neural Network Verifier: Popular verification properties considered in the literature have ùúì:= ùê∂ùëáùëå‚â•0, whereùê∂is a column vector and ùëå=ùëÅ(ùëã),forùëã‚ààùúô. Most stateoftheart complete verifiers use BaB to solve this problem. These techniques use an analyzer that computes the linear approximation of the network output ùëåthrough a convex approximation of the problem domain. This linear approximation of ùëåis used to perform the bounding step to show for the lower bound LB(ùê∂ùëáùëå)that LB(ùê∂ùëáùëå) ‚â• 0. If the bounding step cannot prove the property, the verification problem is partitioned into subproblems using a branching heuristic ùêª. The partitioning splits the problem space allowing a more precise convex approximation of the split subproblems. This leads to gains in the precision of LBcomputation. Various choices for the analyzer and the branching strategies exist which represent different tradeoffs between precision and speed. IVAN leverages a specification tree representation and novel algorithms to store and transfer the proof of the property from ùëÅtoùëÅùëéfor accelerating the verification on ùëÅùëé. We show the workings ofùêºùëâùê¥ùëÅ through the following illustrative example. 2.1 Illustrative Example We consider the two networks ùëÅandùëÅùëéwith the same architecture as shown in Figure 2. Most practical network updates result in network weight perturbations e.g., quantization, model repair, and finetuning. Network ùëÅùëéis obtained by updating (perturbing the weights) of network ùëÅ. These networks apply ReLU activation at the end of each affine layer except for the final layer. The weights for the affine layers are shown on the edges. We consider the verification property (ùúô,ùúì)such that ùúô={(ùëñ1,ùëñ2):ùëñ1‚àà[0,1]‚àßùëñ2‚àà[0,1]}andùúì=(ùëú1+14‚â•0). LetR={ùëü1,ùëü2,ùëü3,ùëü4}denote the set of ReLUs in the considered architecture. Ris a function of the architecture of the DNNs and is common for both ùëÅandùëÅùëé. Branch and Bound: We consider a complete verifier that uses a sound analyzer ùê¥based on the exact encoding of the affine layers and the common triangle linear relaxation [Bunel et al .2020b,a; Ehlers 2017] for overapproximating the nonlinear ReLU function. If due to overapproximation of Proc. ACM Program. Lang., Vol. 7, No. PLDI, Article 185. Publication date: June 2023.Incremental Verification of Neural Networks 185:5 the ReLU function, the analyzer cannot prove or disprove the property, the verifier partitions the problem by splitting the problem domain. The analyzer is more precise if it separately analyzes the split subproblems and merges the results. There are two main strategies for branching considered in the literature, input splitting [Anderson et al .2020; Wang et al .2018], and ReLU splitting [Bunel et al.2020b,a; Ehlers 2017; Ferrari et al .2022; Palma et al .2021]. We show IVAN‚Äôs effectiveness on both branching strategies in our evaluation (Section 6.1, Section 6.4). However, for this discussion, we focus on ReLU splitting which is scalable for the verification of highdimensional inputs. ReLU splitting: An unsolved problem is partitioned into two cases, where the cases assume the input ÀÜùë•ùëñto ReLU unit ùëüùëñsatisfies the predicates ÀÜùë•ùëñ‚â•0and ÀÜùë•ùëñ<0respectively. Splitting a ReLU ùëüùëñ eliminates the analyzer imprecision in the approximation of ùëüùëñ. When we split all the ReLUs in R, the analyzer is exact. Nevertheless, splitting all Ris expensive as it requires 2|R|analyzer bounding calls. The stateoftheart techniques use the heuristic function ùêªto find the best ReLU to split at each step, leading to considerably scalable complete verification. The branching function ùêªscores the ReLUsRfor branching at each unsolved problem to partition the problem. IfR‚Ä≤‚äÜR denotes the subset of ReLUs that are not split in the current subproblem, then the verifier computes ùëü=arg maxR‚Ä≤ùêªto choose the ùëüfor the current split. ùêªis a function of the exact subproblem that it branches and hence depends on ùúô,ùúì, the network, and the branching assumptions made for the subproblem. However, for the purpose of this running example, we consider a simple constant branching heuristic ùêªthat ranksùêª(ùëü1)>ùêª(ùëü3)>ùêª(ùëü4)>ùêª(ùëü2) independent of the subproblem and the network. This assumption is only for the illustration of our idea, we show in the evaluation (Section 6) that IVAN can work with stateoftheart branching heuristics [Bunel et al. 2020b; Henriksen and Lomuscio 2021]. 2.2 IVAN Algorithm Specification Tree: IVAN uses a rooted binary tree data structure to store the trace of splitting decisions during BaB execution. A specification split is a finer specification parameterized by the subset of ReLUs in R. The root node is associated with the specification (ùúô,ùúì). All other nodes represent the specification splits obtained by splitting the problem domain recursively. Each internal node in the tree has two children, the result of the branching of the associated specification. The split decision can be represented as a predicate. For a ReLU ùëüùëñwith input ÀÜùë•ùëñ, letùëü+ ùëñ:=(ÀÜùë•ùëñ‚â•0) andùëü‚àí ùëñ:=(ÀÜùë•ùëñ<0)denote the split decisions. A split of ReLU ùëüùëñat nodeùëõcreates two children nodes ùëõùëôandùëõùëü, each encoding the new specification splits. Each edge in the specification tree represents the split decision made at the branching step. An edge connects an internal node with its child node, and we label it with the additional predicate that is assumed by the child subproblem. A split of ReLUùëüat nodeùëõadds nodes ùëõùëôandùëõùëüthat are connected with edges labeled with predicates ùëü+ ùëñandùëü‚àí ùëñrespectively. If ùúëùëõ=(ùúô‚Ä≤,ùúì)is the specification split at ùëõ, thenùúëùëõùëô=(ùúô‚Ä≤‚àßùëü+,ùúì)and ùúëùëõùëü=(ùúë‚Ä≤‚àßùëü‚àí,ùúì). The names of the nodes have no relation to the networks or the property, they are used for referencing a particular specification. However, the edges of the tree are tied to the network architecture through the labels. Although the specification tree is created as a trace of verification of a particular network ùëÅ, it is only a function of the ReLU units in the architecture of ùëÅ. This allows us to use the branching decisions in the specification tree for guiding the verification of any updated network ùëÅùëéthat has the same architecture as ùëÅ. We use LBùëÅ(ùëõ)to denote the lower bound LB(ùê∂ùëáùëå)obtained by the analyzer ùê¥on for the subproblem encoded by ùëõ, on the networkùëÅ. Figure 3 demonstrates the steps of BaB execution on ùëÅ. Each node represents the specification refined by BaB. We use function LBùëÅ(ùëõ)to denote the LB(ùê∂ùëáùëå)=LB(ùëú1+14)value obtained by the analyzer ùê¥at nodeùëõ. The specification is verified for the subproblem of ùëõif the LBùëÅ(ùëõ)‚â•0. IfLBùëÅ(ùëõ)<0, the analyzer returns a counterexample (CE). The CE is a point in the convex Proc. ACM Program. Lang., Vol. 7, No. PLDI, Article 185. Publication date: June 2023.185:6 Shubham Ugare, Debangshu Banerjee, Sasa Misailovic, and Gagandeep Singh Fig. 3. Steps in Branch and Bound algorithm for complete verification of ùëÅ. The nodes are labeled with a name and the LBùëÅ(ùëõ). The nodes in the specification tree are annotated with their specifications. The edges are labeled with the branching predicates. Each step in BaB partitions unsolved specifications in ùëáùëÅ ùëñinto specification splits in ùëáùëÅ ùëñ+1. The proof is complete when all specification splits corresponding to the leaf nodes are solved. approximation of the problem domain and it may be possible that it is spurious, and does not belong to the concrete problem domain. If the CE is not spurious, the specification is disproved and the proof halts. But, if the CE is spurious then the problem is unsolved, and it is further partitioned. In the first step, for the specification (ùúô,ùúì)encoded by the root node ùëõ0, the analyzer computes LBùëÅ(ùëõ0)=‚àí7, which is insufficient to prove the specification. Further, the CE provided by the analyzer is spurious, and thus the analyzer cannot solve the problem. The root node ùëõ0specification (ùúô,ùúì)is split by ReLU split of ùëü1chosen by the heuristic function ùêª. Accordingly, in the specification tree, the node ùëõ0is split into two nodes ùëõ1andùëõ2, with the specification splits (ùúô‚àßùëü+ 1,ùúì)and (ùúô‚àßùëü‚àí 1,ùúì)respectively. This procedure of recursively splitting the problem and correspondingly updating the specification tree continues until either all the specifications of the leaf nodes are verified, or a CE is found. In the final specification tree ( ùëáùëÅ 3in this case), the leaf nodes are associated with the specifications that the analyzer could solve, and the internal nodes represent the specifications that the analyzer could not solve for network ùëÅ. For BaB starting from scratch, each node in the specification tree maps to a specification that invoked an analyzer call in BaB execution. Figure 3 presents that the verifier successfully proves the property with a specification tree containing 9 nodes. Thus, the verification invokes the analyzer 9 times and performs 4 nodes branchings for computing LB. Figure 4a presents the specification tree for ùëÅùëéat end of the verifying the property (ùúô,ùúì). Although the ùêøùêµ(ùê∂ùëáùëå)computed by the analyzer for each node specifications is different for ùëÅùëé compared to ùëÅ, the final specification tree is identical for both networks. Our techniques in IVAN are motivated by our observation that the final specification tree for network ùëÅand its updated versionùëÅùëéhave structural similarities. Moreover, we find that for a DNN update that perturbs the network weight within a fixed bound, these trees are identical. We claim that there are two reasons for this: (i) the specifications that are solved by the analyzer for ùëÅare solved by the analyzer for ùëÅùëé (specifications of the leaf nodes of the specification tree) and (ii) the specifications that are unsolved by the analyzer for ùëÅare unsolved for ùëÅùëé(specifications of the internal nodes of the specification tree). In Section 4.4, we provide theoretical bounds on the network perturbations such that these Proc. ACM Program. Lang., Vol. 7, No. PLDI, Article 185. Publication date: June 2023.Incremental Verification of Neural Networks 185:7 (a) BaB specification tree for ùëÅùëé. It requires 9 node boundings and 4 node branchings. (b) BaB specification tree for ùëÅùëéwith reuse. It requires 5 node boundings and 0 node branchings. (c) BaB specification tree for ùëÅùëéwith reorder. It requires 5 node boundings and 2 node branchings. (d) BaB specification tree for ùëÅùëéwith IVAN. It requires 3 node boundings and 0 node branchings. Fig. 4. BaB specification tree for various techniques proposed for incremental verification. claims hold true (Theorem 4). Nevertheless, for networks obtained by perturbation beyond the theoretical bounds, the specification trees are still similar if not identical. In our evaluation, we observe this similarity for large networks with practical updates e.g., quantization (Section 6). Reuse: We first introduce our concept of specification tree reuse which uses ùëáùëÅ ùëì, the final tree after verifying ùëÅ, as the starting tree ùëáùëÅùëé 0for the verification of ùëÅùëé. In contrast, the standard BaB verification starts with a single node tree that represents the unpartitioned initial specification (ùúô,ùúì). In the reuse technique, IVAN starts BaB verification of ùëÅùëéfrom the leaves of ùëáùëÅùëé 0= ùëáùëÅ ùëì. For our running example, analyzer ùê¥successfully verifies ùëÅùëéspecifications for all the leaf nodes of the specification tree ùëáùëÅùëé 0(Figure 4b). We show that for any specification tree (created on the same network architecture), verifying the subproblem property on all the leaves of the specification tree is equivalent to verifying the main property (ùúô,ùúì)(Lemma 1). Verifying the property on ùëÅùëéfrom scratch requires 9 analyzer calls and 4 node branchings. However, with the reuse technique, we could prove the property with 5 analyzer calls corresponding to the leaves ofùëáùëÅùëé 0and without any node branching. Theorem 4 guarantees that the specification of the leaf nodes should be verified on ùëÅùëéby the analyzer if the network perturbations are lower than a fixed bound. Although for larger perturbations, we may have to split leaves of ùëáùëÅùëé 0further for complete verification, we empirically observe that the reuse technique is still effective to gain speedup on most practical network perturbations. Reorder: A split is more effective if it leads to fewer further subproblems that the verifier has to solve to prove the property. Finding the optimal split is expensive. Hence, the heuristic ùêªis used to estimate the effectiveness of a split, and to choose the split with the highest estimated effectiveness. Often the estimates are imprecise and lead to ineffective splits. We use LBùëÅ(ùëõ)to give an approximation to quantifying the effectiveness of a split. We discuss this exact formulation of the observed effectiveness scores ùêªùëúùëèùë†in Section 4.3. Our second concept in IVAN is based on our Proc. ACM Program. Lang., Vol. 7, No. PLDI, Article 185. Publication date: June 2023.185:8 Shubham Ugare, Debangshu Banerjee, Sasa Misailovic, and Gagandeep Singh Fig. 5. IVAN removes the ineffective split ùëü1atùëõ0and construct a new specification tree ùëáP. insight that if a particular branching decision is effective for verifying ùëÅthen it should be effective for verifying ùëÅùëé. Likewise, if a particular branching decision is ineffective in the verification of ùëÅ, it should be ineffective in verifying ùëÅùëé. Based on this insight, we use the observed effectiveness score of splits in verifying ùëÅto modify the original branching heuristic ùêªto an improved heuristic ùêªŒî. ùêªŒîtakes the weighted sum of original branching heuristic ùêªand observed effectiveness scores on ùëÅdenoted byùêªùëúùëèùë†. We formulate the effectiveness of a split and ùêªŒîin Section 4.3. For simplicity, in the running example, we rerank the ReLUs based on the observed effectiveness of the splits as ùêªŒî(ùëü4)>ùêªŒî(ùëü3)>ùêªŒî(ùëü2)>ùêªŒî(ùëü1). Figure 4c presents the specification tree for verifying ùëÅùëéwith the updated branching heuristic ùêªŒîthat requires 5 analyzer calls and 2 node branchings. Reorder technique starts from scratch with a different branching order ùêªŒîand it is incomparable in theory to the reuse technique. In Section 6.2, we observe that reorder works better in most experiments. Bringing All Together: Our main algorithm combines our novel concepts of specification tree reuse and reorder yielding larger speedups than possible with only reuse or reorder. Specification tree reuse and reorder are not completely orthogonal and thus combining them is not straightforward. Since in reuse we start verifying ùëÅùëéwith the final specification tree ùëáùëÅ ùëì, the splits are already performed with the original order ( ùëü1,ùëü4,ùëü3,ùëü2in our example). Our augmented heuristic function ùêªŒîwill have a limited effect if we reuse ùëáùëÅùëé 0=ùëáùëÅ ùëì, since the existing tree branches may already be sufficient to prove the property. Constructing a Pruned Specification Tree: It is difficult to predict the structure of the tree with augmented order. For instance, in our example, ùëÅis verified with ùëü1,ùëü4,ùëü3,ùëü2order and we have ùëáùëÅ ùëìbranched in that order. However, we cannot predict the final structure of the specification tree if branched with our augmented order ùëü4,ùëü3,ùëü2,ùëü1without actually performing those splits from scratch (as it was done in Figure 4c). We solve this problem with our novel pruning operation that removes ineffective splits from ùëáùëÅ ùëìand constructs a new compact tree ùëáP. Figure 5 shows the construction of pruned tree ùëáPfor our running example. We remove the split ùëü1atùëõ0as it is less effective. Removing ùëü1fromùëáùëÅ 3also eliminates the nodes ùëõ1andùëõ2. The subtrees rooted at ùëõ1andùëõ2are the result of split ùëü1. If we undo the splitùëü1at nodeùëõ0, thenùëõ0should follow the branching decisions taken by one of its children. For this, we can choose either the subtree of ùëõ0orùëõ1, and attach it to ùëõ0. We describe the exact method of choosing which subtree to keep in Section 4.3. For this example, our approach chooses to keep the subtree of node ùëõ2and eliminates the subtree at node ùëõ1. The pruning procedure leads to the discarding of entire subtrees creating a tree with fewer leaf nodes (leaf nodes ùëõ3,ùëõ4are deleted in the example along with internal nodes ùëõ1,ùëõ2). Consequently, we obtain a more compact tree with only influential splits in the specification tree. We start the verification of ùëÅùëéfrom the leaf nodes of the pruned tree i.e. ùëáùëÅùëé 0=ùëáP. For our running example specification splits of all leaf nodes of ùëáPare verified by the analyzer and no further splitting is needed. Figure 4d presents the final specification tree in case we initialize the Proc. ACM Program. Lang., Vol. 7, No. PLDI, Article 185. Publication date: June 2023.Incremental Verification of Neural Networks 185:9 proof with the compact tree obtained from the IVAN algorithm. We show the time complexity of incremental verification in Section 4.2. For the running example, the incremental proof requires only 3 analyzer calls and no branching calls, and it is a significant reduction to the 9 analyzer calls and 5 node branchings performed by the baseline starting from scratch. 3 PRELIMINARIES In this section, we provide the necessary background on complete neural network verification. 3.1 Neural Network Verification Neural Networks Neural networks are functions ùëÅ:Rùëõ0‚ÜíRùëõùëô. In this work, we focus on layered neural networks obtained by a sequential composition of ùëôlayersùëÅ1:Rùëõ0‚ÜíRùëÅ1,...,ùëÅùëô: Rùëõùëô‚àí1‚ÜíRùëõùëô. Each layer ùëÅùëñapplies an affine function (convolution or linear function) followed by a nonlinear activation function to its input. The choices for nonlinear activation functions are ReLU, sigmoid, or tanh. ùëÖùëíùêøùëà(ùë•)=ùëöùëéùë•(0,ùë•)is most commonly used activation function. In Section 4, we focus on the most common BaB verifiers that partition the problems using ReLU splitting in ReLU networks. The ùëñth layer of each network ùëÅùëñ:Rùëõùëñ‚àí‚ÜíRùëõùëñ+1is defined as ùëÅùëñ(ùë•)=ReLU(ùê¥ùëñùëã+ùêµùëñ) whereùëñ‚àà[ùëô]. At a high level, neural network verification involves proving that all network outputs correspond ing to a chosen set of inputs satisfying the input specification ùúôsatisfy a given logical property ùúì. We first define the input and output specifications that we consider in this work: Definition 1 (Input specification). For a neural network ùëÅ:Rùëõ0‚ÜíRùëõùëô,ùúôùë°is a connected region andùúôùë°‚äÜRùëõ0.Input specification ùúô:Rùëõ0‚Üí{ùë°ùëüùë¢ùëí,ùëìùëéùëôùë†ùëí}is a predicate over the input regionùúôùë°. Definition 2 (output specification). For a neural network with ùëõùëôneurons in the output layer. output specification ùúì:Rùëõùëô‚Üí{ùë°ùëüùë¢ùëí,ùëìùëéùëôùë†ùëí}is a predicate over the output region. The output property ùúìcould be any logical statement taking a truth value true or false. In our paper, we focus on properties that can be expressed as Boolean expressions over linear forms. Most DNN verification works consider such properties. ùúì(ùëå)=(ùê∂ùëáùëå‚â•0) (1) We next define the verification problem solved by the verifiers: Definition 3 (Verification Problem). Theneural network verification problem for a neural networkùëÅ, an input specification ùúôand a logical property ùúìis to prove whether ‚àÄùëã‚ààùúôùë°.ùúì(ùëÅ(ùëã))= true or provide a counterexample otherwise. A complete verifier always verifies the property if it holds or returns a counterexample otherwise. Formally, it can be defined as: Definition 4 (Complete Verifier). Acomplete verifier ùëâfor an input specification ùúô, a neural networkùëÅ, an output property ùúìsatisfies the following property: ùëâ(ùúô,ùúì,ùëÅ)=Verified‚áê‚áí‚àÄùëã‚ààùúôùë°.ùúì(ùëÅ(ùëã))=true 3.2 Branch and Bound for Verification In this Section, we discuss the branch and bound techniques for complete verification of DNNs. The BaB approach in these techniques use a divideandconquer algorithm to compute the LB(ùê∂ùëáùëå)for proving(ùê∂ùëáùëå‚â•0)(Eq. 1). We next discuss the bounding and branching steps in BaB techniques. Proc. ACM Program. Lang., Vol. 7, No. PLDI, Article 185. Publication date: June 2023.185:10 Shubham Ugare, Debangshu Banerjee, Sasa Misailovic, and Gagandeep Singh Bounding: The bounding step uses an analyzer to find a lower bound LB(ùê∂ùëáùëå). In complete verifiers, the analyzers are exact for linear functions (e.g., DeepZ [Singh et al .2018], DeepPoly [Singh et al .2019b]). However, they overapproximate the nonlinear activation function through a convex overapproximation. We define these sound analyzers as: Definition 5 (Sound Analyzer). Asound analyzer ùê¥on an input specification ùúô, a DNNùëÅ, an output property ùúìreturns Verified ,Unknown , orCounterexample . It satisfies the following properties: ùê¥(ùúô,ùúì,ùëÅ)=Verified =‚áí ‚àÄùëã‚ààùúôùë°.ùúì(ùëÅ(ùëã))=true ùê¥(ùúô,ùúì,ùëÅ)=Counterexample =‚áí ‚àÉùëã‚ààùúôùë°.ùúì(ùëÅ(ùëã))=false Branching: If the analyzer cannot prove a property, the BaB verifier partitions the problem into easier subproblems to improve analyzer precision. Algorithm 1 presents the pseudocode for the BaB verification. The algorithm maintains a ùëàùëõùë†ùëúùëôùë£ùëíùëë list of problems that are currently not proved or disproved. It initializes the list with the main verification problem. Line 5 performs the bounding step in the BaB algorithm using the analyzer ùê¥. For simplicity, we abuse the notation and use ùê¥(ùëùùëüùëúùëè,ùëÅ)for denoting the analyzer output instead of ùê¥(ùúô,ùúì,ùëÅ). Here, theùëùùëüùëúùëè encapsulates the input and output specifications ùúô,ùúì. Line 13 partitions the unsolved problem into subproblems. The algorithm halts when either the ùê¥finds a counterexample on one of the subproblems or the list of unsolved problems is empty. There are two common branching strategies for BaB verification, input splitting and ReLU splitting, which we describe next. Algorithm 1 Branch and Bound 1:function BaB(ùëÅ,ùëùùëüùëúùëèùëôùëíùëö ) 2:ùëàùëõùë†ùëúùëôùë£ùëíùëë‚Üê[(ùëùùëüùëúùëèùëôùëíùëö)] 3: whileùëàùëõùë†ùëúùëôùë£ùëíùëë is not empty do 4: forùëùùëüùëúùëè‚ààùëàùëõùë†ùëúùëôùë£ùëíùëë do 5: ùë†ùë°ùëéùë°ùë¢ùë†[ùëùùëüùëúùëè]=ùê¥(ùëùùëüùëúùëè,ùëÅ) ‚ä≤Bounding step 6: forùëùùëüùëúùëè‚ààùëàùëõùë†ùëúùëôùë£ùëíùëë do 7: ifùë†ùë°ùëéùë°ùë¢ùë†[ùëùùëüùëúùëè]=Verified then 8: ùëàùëõùë†ùëúùëôùë£ùëíùëë.ùëüùëíùëöùëúùë£ùëí(ùëùùëüùëúùëè) ‚ä≤Remove verified subproblems 9: ifùë†ùë°ùëéùë°ùë¢ùë†[ùëùùëüùëúùëè]=Counterexample then 10: return Counterexample forùëùùëüùëúùëè ‚ä≤Return if a counterexample is found 11: ifùë†ùë°ùëéùë°ùë¢ùë†[ùëùùëüùëúùëè]=Unknown then 12: ùëàùëõùë†ùëúùëôùë£ùëíùëë.ùëüùëíùëöùëúùë£ùëí(ùëùùëüùëúùëè) 13:[subprob1,subprob2]‚Üê split(prob) ‚ä≤Branching step 14: ùëàùëõùë†ùëúùëôùë£ùëíùëë.ùëñùëõùë†ùëíùëüùë°(subprob1,subprob2) 15: return Verified Input Splitting: In input splitting, the input region ùúôùë°for verification is partitioned. The typical choice is to cut a selected input dimension in half while the rest of the dimensions are unchanged. The dimension to cut is decided by the branching strategy used. This technique is known to be ùõø complete for any activation function [Anderson et al .2019], but does not scale for highdimensional input space. In many computer vision tasks, the input is an image with 1000s of pixels. Thus, a high dimensional perturbation region on such input cannot be branched efficiently for fast verification. ReLU Splitting: Stateoftheart techniques that focus on verifying DNNs with highdimensional input and ReLU activation, use ReLU splitting. We denote a ReLU unit for ùëñth layer and ùëóth index as a function ùë•ùëñ,ùëó=max(ÀÜùë•ùëñ,ùëó,0), where ÀÜùë•ùëñ,ùëóandùë•ùëñ,ùëóare the preactivation and postactivation values respectively. The analyzer computes lower bounds ùëôùëèand upper bounds ùë¢ùëèfor each intermediate Proc. ACM Program. Lang., Vol. 7, No. PLDI, Article 185. Publication date: June 2023.Incremental Verification of Neural Networks 185:11 variable in the DNN. If ùëôùëè(ÀÜùë•ùëñ,ùëó)‚â•0, then the ReLU unit simply acts as the identify function ùë•ùëñ,ùëó=ÀÜùë•ùëñ,ùëó. Ifùë¢ùëè(ÀÜùë•ùëñ,ùëó)‚â§0, then the ReLU unit operates as a constant function ùë•ùëñ,ùëó=0. In both of these cases, the ReLU unit is a linear function. However, if ùëôùëè(ÀÜùë•ùëñ,ùëó)<0<ùë¢ùëè(ÀÜùë•ùëñ,ùëó), we cannot linearize the ReLU function exactly. We call such ReLU units ambiguous ReLUs. In ReLU splitting, the unsolved problem is partitioned into two subproblems such that one subproblem assumes ÀÜùë•ùëñ,ùëó<0and the other assumes ÀÜùë•ùëñ,ùëó‚â•0. This partition allows us to linearize the ReLU unit in both subproblems leading to a boost in the overall precision of the analyzer. The heuristic used for selecting which ReLU to split significantly impacts the verifier speed. BaB for Other Activation Functions: BaBbased verification can work with the most commonly used activation functions (tanh, sigmoid, leaky ReLU). (1)For piecewise linear activation functions such as leaky ReLU, activation splitting approaches (e.g, ReLU splitting) can be used for complete verification. (2)For other activation functions (tanh, sigmoid), BaB with activation splitting cannot yield complete verification but can be used to improve the precision of sound and incomplete verification [Dutta et al. 2017; M√ºller et al. 2021]. (3)Although input splitting is less efficient in the aforementioned cases for high dimensional DNN inputs, it can be applied with any activation function (tanh, sigmoid, ReLU, leaky ReLU). 4 INCREMENTAL VERIFICATION In this section, we describe our main technical contributions and the IVAN algorithm. We first formally define the specification tree structure used for incremental verification (Section 4.1). Next, we formulate the problem of incremental verification (Section 4.2). In Section 4.3, we illustrate the techniques used in our algorithm. We characterize the effectiveness of our technique by computing a class of networks for which our incremental verification is efficiently applicable in Section 4.4. 4.1 Specification Tree for BaB IVAN uses the specification tree to store the trace of splitting decisions that the BaB verifier makes on its execution. A specification tree can be used for any BaB branching method (e.g, input splitting), but without loss of generality, our discussion focuses on ReLU splitting. Let Ndenote the class of networks with the same architecture, and let Rdenote the set of ReLUs in this architecture. The specification tree captures the ReLU splitting decisions and the split specifications in the execution of BaB for a property (ùúô,ùúì), where we define(ùúô,ùúì):=ùúô‚Üíùúì. For a ReLUùëüùëñwith input ÀÜùë•ùëñ, letùëü+ ùëñ:=(ÀÜùë•ùëñ‚â•0)andùëü‚àí ùëñ:=(ÀÜùë•ùëñ<0). We define a split decision as: Definition 6 (Split Decision). For a ReLUùëü‚ààR, a split decision is ùëü?‚àà{ùëü+,ùëü‚àí}whereùëü?is assigned the predicate ùëü+orùëü‚àí. A specification split of (ùúô,ùúì)is a specification stronger than (ùúô,ùúì)parameterized by the subset of ReLUs inRand the corresponding split decisions. Formally, Definition 7 (Specification Split). For a set of ReLUsR‚Ä≤={ùëü1,ùëü2...ùëüùëò}‚äÜR , and ReLU split decisionùëü? ùëñ‚àà{ùëü‚àí ùëñ,ùëü+ ùëñ}for eachùëüùëñ, the corresponding specification split of (ùúô,ùúì)is(ùúô‚àßùëü? 1‚àßùëü? 2‚àß...ùëü? ùëò,ùúì). Since‚àÖ‚äÜR ,(ùúô,ùúì)is a split specification of itself. Let Sdenote the set of specification splits that can be obtained from (ùúô,ùúì). Each node ùëõin the tree encodes a specification split in S. Each edge in the specification tree is labeled with a ReLU split decision ùëü?. Let Nodes(ùëá)denote the nodes of the treeùëáandLeaves(ùëá)denote the leaves of the tree ùëá. Mapping Nodes to Specification Splits: The specification associated with the root node is (ùúô,ùúì). The function Children(ùëõ)maps a node ùëõto either the pair of its children or ‚àÖifùëõhas no children. If ùëõùëô andùëõùëüare the children of node ùëõandùúëùëõ=(ùúô‚Ä≤,ùúì)is the specification split at ùëõ, thenùúëùëõùëô=(ùúô‚Ä≤‚àßùëü+,ùúì) Proc. ACM Program. Lang., Vol. 7, No. PLDI, Article 185. Publication date: June 2023.185:12 Shubham Ugare, Debangshu Banerjee, Sasa Misailovic, and Gagandeep Singh andùúëùëõùëü=(ùúë‚Ä≤‚àßùëü‚àí,ùúì). For the specifications ùúëùëõ,ùúëùëõùëô,ùúëùëõùëüthe following statement holds: (ùúëùëõùëô‚àßùúëùëõùëü)‚áê‚áíùúëùëõ (2) This relationship implies that verifying the parent node specification is equivalent to verifying the two children node‚Äôs specifications. Formally, we can now define the specification tree as: Definition 8 (specification tree). Given a set of ReLU R, a rooted full binary tree ùëáis aspeci fication tree , if for a node ùëõ‚ààNodes(ùëá), and nodesùëõùëô,ùëõùëü‚ààChildren(ùëõ), edge(ùëõ,ùëõùëô)is labeled with predicateùëü+and edge(ùëõ,ùëõùëü)is labeled with predicate ùëü‚àí, forùëü‚ààR. Algorithm 2 Split operation 1:function Split (ùëá,ùëõ,ùëü ) 2: Input: Specification tree ùëá, a leaf node ùëõ‚àà Leaves(ùëá), a ReLUùëü‚ààRfor splitting the node 3: Output: returns newly added nodes 4:ùëõùëô‚ÜêAdd_Child(ùëõ,ùëü+) 5:ùëõùëü‚ÜêAdd_Child(ùëõ,ùëü‚àí) 6: returnùëõùëô,ùëõùëüBaB uses a branching function ùêªfor choos ing the ReLU to split. We define this branching function in terms of the node ùëõof the specifi cation tree as: Definition 9 (Branching Heuristic). Given a set of ReLU R, a networkùëÅ, and a node ùëõin the specification tree, if P‚äÜR denote the set of ReLUs split in the path from the root node of the specification tree to ùëõthen the branching heuristic ùêª(ùëÅ,ùëõ,ùëü)computes a score ‚Ñé‚ààRestimating the effectiveness of ReLU ùëü‚ààR/P for splitting the specification ( ùúëùëõ) of the node ùëõ. We next state the split operation on a specification tree. Algorithm 2 presents the steps in the split operation. ‚Ä¢Split Operation: Every ReLU split adds two nodes to the specification tree at a given leaf node ùëõ. The BaB algorithm chooses the ReLU arg maxùëü‚ààR/Pùêª(ùëÅ,ùëõ,ùëü)to split at node ùëõusing the heuristic function. 4.2 Incremental Verification: Problem Formulation Give a set of networks Nwith the same architecture with a set of ReLUs R,TNbe the set of all specification trees defined over R. There exists a partial order (<)onTNthrough standard subgraph relation. BaB execution on a network ùëÅ‚ààN traces a sequence of trees ùëá0,ùëá1...ùëáùëì‚ààTNsuch that ùëáùëñ<ùëáùëñ+1. It halts with the final tree ùëáùëìwhen it either verifies the property or finds a counterexample. The construction of ùëáùëñ+1fromùëáùëñdepends on the branching function ùêª(Definition 9). Incremental Verification: The incremental verification problem is to efficiently reuse the infor mation from the execution of verification of network ùëÅfor the faster verification of its updated versionùëÅùëé. Standard BaB for verification of ùëÅùëéstarts with a single node tree while the incremental verifier starts with a tree ùëáùëÅùëé 0‚ààTNthat is not restricted to be a tree with a single node. We modify the final specification tree ùëáùëÅ ùëìfrom the verification of ùëÅto construct ùëáùëÅùëé 0. The branching heuristic ùêªŒîfor incremental verification is derived from the branching heuristic ùêªbased on the efficacy of various branching decisions made during the proof for ùëÅ. Formally, the complete incremental verifier we propose is defined as: Definition 10 (Complete and Incremental Verifier). AComplete and Incremental Verifier ùëâŒîtakes a neural network ùëÅùëé, an input specification ùúô, an output property ùúì, analyzerùê¥, the branching heuristicùêªŒîand the initial tree ùëáùëÅùëé 0.ùëâŒî(ùëÅùëé,ùúô,ùúì,ùëáùëÅùëé 0,ùêªŒî)returns Verified ifùëÅùëésatisfies the property (ùúô,ùúì), otherwise, it returns a Counterexample . Algorithm 3 presents the incremental verifier algorithm for verifying the perturbed network. It takesùêªŒîandùëáùëÅùëé 0as input. It maintains a list of active nodes which are the nodes corresponding to the specifications that are yet to be checked by the analyzer. It initializes the list of active nodes with leaves of tree ùëáùëÅùëé 0(line 2). The main loop runs until the active list is empty (line 3) or it Proc. ACM Program. Lang., Vol. 7, No. PLDI, Article 185. Publication date: June 2023.Incremental Verification of Neural Networks 185:13 Algorithm 3 Verifying Perturbed Network Input:ùëÅùëé, property (ùúô,ùúì), Initial specification tree ùëáùëÅùëé 0, branching heuristic ùêªŒî Output: Verified if the specification ( ùúô,ùúì) is verified, otherwise a Counterexample 1:ùëáùëÅùëé‚ÜêInitializeùëáùëÅùëéasùëáùëÅùëé 0 2:ùê¥ùëêùë°ùëñùë£ùëí =Leaves(ùëáùëÅùëé 0) ‚ä≤Initialize active list as Leaves(ùëáùëÅùëé 0) 3:whileùê¥ùëêùë°ùëñùë£ùëí is not empty do 4: forùëõ‚ààùê¥ùëêùë°ùëñùë£ùëí do 5:ùë†ùë°ùëéùë°ùë¢ùë†[ùëõ]‚Üêùê¥(ùëõ) ‚ä≤Bounding step 6: forùëõ‚ààùê¥ùëêùë°ùëñùë£ùëí do 7: ifùë†ùë°ùëéùë°ùë¢ùë†[ùëõ]=Verified then 8: ùê¥ùëêùë°ùëñùë£ùëí.ùëüùëíùëöùëúùë£ùëí(ùëõ) ‚ä≤Remove verified nodes 9: ifùë†ùë°ùëéùë°ùë¢ùë†[ùëõ]=Counterexample then 10: ùê¥ùëêùë°ùëñùë£ùëí.ùëíùëöùëùùë°ùë¶() 11: return Counterexample forùëõ ‚ä≤Return if a counterexample is found 12: ifùë†ùë°ùëéùë°ùë¢ùë†[ùëõ]=Unknown then 13: ùê¥ùëêùë°ùëñùë£ùëí.ùëüùëíùëöùëúùë£ùëí(ùëõ) 14: ùëüùëê‚Ñéùëúùë†ùëíùëõ‚Üêarg maxùëü‚ààRùêªŒî(ùëÅ,ùëõ,ùëü) ‚ä≤UseùêªŒîto choose the split ReLU 15: ùëõùëô,ùëõùëü‚ÜêSplit(ùëáùëÅùëé,ùëõ,ùëüùëê‚Ñéùëúùë†ùëíùëõ) ‚ä≤Branching step 16: ùê¥ùëêùë°ùëñùë£ùëí.ùëñùëõùë†ùëíùëüùë°(ùëõùëô,ùëõùëü) 17:return Verified discovers a counterexample (line 9). At each iteration, it runs the analyzer on each node in the active list (line 5). The nodes that are Verified are removed from the list (line 8), whereas the nodes that result in Unknown are split. The new children are added to the active list (line 12). Optimal Incremental Verification: We define the partial function Time Œî:TN√óTN‚áÅR, Time Œî(ùëáùëÅùëé 0,ùëáùëÅùëé ùëì)for a fixed complete incremental verifier ùëâŒîas the time taken by ùëâŒîthat starts fromùëáùëÅùëé 0and halts with the final tree ùëáùëÅùëé ùëì.Time‚Ñé(ùêª,ùêª Œî)and Timeùë°(ùëáùëÅ ùëì,ùëáùëÅùëé 0)are the time for constructing ùêªŒîfrom H, andùëáùëÅùëé 0fromùëáùëÅ ùëìrespectively. We pose the optimal incremental verification problem as an optimization problem of finding the best ùêªŒî,ùëáùëÅùëé 0such that the time of incremental verification is minimized. Formally, we state the problem as: arg min ùêªŒî,ùëáùëÅùëé 0 Time Œî(ùëáùëÅùëé 0,ùëáùëÅùëé ùëì)+Time‚Ñé(ùêª,ùêª Œî)+Timeùë°(ùëáùëÅ ùëì,ùëáùëÅùëé 0) (3) The search space for ùëáùëÅùëé 0is exponential in terms of R, and the search space for ùêªŒîis infinite. Further, Time Œîis a complicated function of ùêªŒî,ùëáùëÅùëé 0that does not have a closedform formulation. As a result, it is not possible to find an optimal solution. Simplifying Assumptions: To make the problem tractable we make a simplifying assumption that for all networks with the same architecture, each branching and bounding step on each invocation takes a constant time ùë°Handùë°Arespectively. We can now compute Time Œî(ùëáùëÅùëé 0,ùëáùëÅùëé ùëì)as: Theorem 1. (Time Œîfor incremental verification). If the incremenatl verifier ùëâŒîhalts with the final treeùëáùëÅùëé ùëì, then Time Œî(ùëáùëÅùëé 0,ùëáùëÅùëé ùëì)=(ùë°A+ùë°H)¬∑ |Nodes(ùëáùëÅùëé ùëì)|+1‚àí|Nodes(ùëáùëÅùëé 0)| 2 ‚àíùë°H¬∑|Leaves(ùëáùëÅùëé ùëì)|. The proof of the theorem is in Appendix 9.2. Proc. ACM Program. Lang., Vol. 7, No. PLDI, Article 185. Publication date: June 2023.185:14 Shubham Ugare, Debangshu Banerjee, Sasa Misailovic, and Gagandeep Singh In this work, we focus on a class of algorithms for which the preprocessing times Time‚Ñé(ùêª,ùêª Œî) andTimeùë°(ùëáùëÅ ùëì,ùëáùëÅùëé 0)are<<Time Œî(ùëáùëÅùëé 0,ùëáùëÅùëé ùëì). Furthermore, we also focus on branching heuristics used in practice where ùë°H<<ùë°A. Equation 3 simplifies to finding ùêªŒîandùëáùëÅùëé 0such that the following expression Time Œî(ùëáùëÅùëé 0,ùëáùëÅùëé ùëì)=ùë°A¬∑ |Nodes(ùëáùëÅùëé ùëì)|+1‚àí|Nodes(ùëáùëÅùëé 0)| 2 is minimized. Rewriting and ignoring the constant term we get Time Œî(ùëáùëÅùëé 0,ùëáùëÅùëé ùëì)=ùë°A¬∑ |Nodes(ùëáùëÅùëé ùëì)|‚àí| Nodes(ùëáùëÅùëé 0)| 2+|Nodes(ùëáùëÅùëé ùëì)| 2! (4) 4.3 IVAN Algorithm for Incremental Verification We describe the novel components of our algorithm and present the full workflow in Algorithm 5. Our first technique called reuse focuses on minimizing |Nodes(ùëáùëÅùëé ùëì)|‚àí| Nodes(ùëáùëÅùëé 0)|in Equa tion 4. Our second reorder technique focuses on minimizing |Nodes(ùëáùëÅùëé ùëì)|. TheùêªŒî,ùëáùëÅùëé 0obtained by reuse and reorder are distinct. IVAN algorithm combines these distinct solutions, to reduce Time Œî(ùëáùëÅùëé 0,ùëáùëÅùëé ùëì). Reuse: This technique is based on the observation that the BaB specification trees should be similar for small perturbations in the network. Accordingly, in the method, we use the final specification tree forùëÅas the initial tree for the verification of ùëÅùëéi.e.ùëáùëÅùëé 0=ùëáùëÅ ùëì, and keep the ùêªŒî=ùêªunchanged. We formally characterize a set of networks obtained by small perturbation for which ùëáùëÅùëé 0=ùëáùëÅ ùëìis sufficient for verifying ùëÅùëéwithout any further splitting in Section 4.4. Reorder: Reorder technique focuses on improving the branching heuristic ùêªsuch that it reduces |Nodes(ùëáùëÅùëé ùëì)|, andùëáùëÅùëé 0is single node tree with ùëõ0encoding the specification (ùúô,ùúì). If we start ùëáùëÅùëé 0=ùëáùëÅ ùëì,|Nodes(ùëáùëÅùëé ùëì)|is at least|Nodes(ùëáùëÅ ùëì)|, and thus, we start ùëáùëÅùëé 0from scratch allowing the technique to minimize |Nodes(ùëáùëÅùëé ùëì)|. We create a branching function ùêªŒîfromùêªwith the following two changes. (i) The splits that worked effectively for the verification of the ùëÅshould be prioritized. (ii) The splits that were not effective should be deprioritized. To formalize the effectiveness of splits, we define the LBùëÅ(ùëõ)as the lower bound computed by the analyzer ùê¥on the network ùëÅ for proving the property ùúëùëõencoded by the node ùëõ. Further, using the function LBùëÅwe define an improvement function ùêºùëÅrepresents the effectiveness of a ReLU split at a specific node as: ùêºùëÅ(ùëõ,ùëü)=min(LBùëÅ(ùëõùëü)‚àíLBùëÅ(ùëõ),LBùëÅ(ùëõùëô)‚àíLBùëÅ(ùëõ)) (5) whereùëõùëô,ùëõùëü‚ààChildren(ùëõ)in the specification tree ùëáùëÅ ùëì. We useùêºùëÅto define the observed effective nessùêªùëúùëèùë†(ùëü)from a split ùëüon the entire specification tree for ùëÅ. It is defined as the mean of the improvement over each node where split ùëüwas made. Let ùëÑ‚äÇNodes(ùëáùëÅ ùëì)denote a set of nodes where splitùëüwas made. Then, ùêªùëúùëèùë†(ùëü)=√ç ùëõ‚ààùëÑùêºùëÅ(ùëõ,ùëü) |ùëÑ|. (6) Using theùêªùëúùëèùë†(ùëü)score we update the existing branching function as: ùêªŒî(ùëõ,ùëü)=ùõº¬∑ùêª(ùëõ,ùëü)+(1‚àíùõº)¬∑(ùêªùëúùëèùë†(ùëü)‚àíùúÉ). (7) Here, we introduce two hyperparameters ùõºandùúÉ. The hyperparameter ùõº‚àà[0,1]controls the importance given to the actual heuristic score and the observed improvement from the verification onùëÅ. Ifùõº=1, thenùêªŒîdepends only on the original branching heuristic score. If ùõº=0, then it fully relies on observed split scores. The hyperparameter ùúÉensures that our score positively changes score forùëüthat haveùêªùëúùëèùë†(ùëü)>ùúÉand negatively change scores for ùêªùëúùëèùë†(ùëü)<ùúÉ. Proc. ACM Program. Lang., Vol. 7, No. PLDI, Article 185. Publication date: June 2023.Incremental Verification of Neural Networks 185:15 Constructing a Pruned Specification Tree: The two reordering goals of prioritizing and depriori tizing effective and ineffective splits are difficult to combine with reuse. However, instead of starting from scratch, we can construct a specification tree ùëáPfromùëáùëÅ ùëìexcluding the ineffective splits. For ùëõ‚ààNodes(ùëáùëÅ ùëì), where ReLU ùëüsplitsùëõ, we denote the set of bad splits as the set B(ùëáùëÅ ùëì)of the pairs (ùëõ,ùëü)such that the improvement score ùêºùëÅ(ùëõ,ùëü)‚â§ùúÉ. For(ùëõ,ùëü)‚ààB(ùëáùëÅ ùëì)while constructing the pruned tree our algorithm chooses a child ùëõùëòofùëõ. If a ReLUùëüùëòis split atùëõùëòinùëáùëÅ ùëì, it performs a splitùëüùëòin the corresponding node in ùëáP, and skips over the bad split ùëü. The subtree corresponding to the other child ùëõùëò‚Ä≤is eliminated and not added to our pruned tree. We choose ùëõùëòsuch that: ùëõùëò=arg min ùëõùë¢‚ààChildren(ùëõ)LBùëÅ(ùëõùë¢)‚àíLBùëÅ(ùëõ) (8) We choose such ùëõùëòoverùëõùëò‚Ä≤since LBùëÅ(ùëõ)is closer to LBùëÅ(ùëõùëò)than LBùëÅ(ùëõùëò‚Ä≤). Further, combining Equation 5 and 8, we can show (LBùëÅ(ùëõùëò)‚àíLBùëÅ(ùëõ))<ùúÉ, i.e. their difference is bounded. We anticipate that on the omission of the split ùëü, the subtree corresponding to ùëõùëòis a better match to the necessary branching decisions following ùëõthanùëõùëò‚Ä≤. Algorithm 4 presents the topdown construction of ùëáP. The algorithm starts from the root of ùëáùëÅ ùëì and recursively traverses through the children constructing ùëáP. It maintains a queue ùëÑof nodes yet to be explored and a map ùëÄthat maps nodes from the tree ùëáùëÅ ùëìto the corresponding new nodes in ùëáP. At a nodeùëõ, if(ùëõ,ùëü)is not a bad split, it performs the split ùëüat the corresponding mapping ÀÜùëõ. Otherwise, if ùëüùëòis the split at ùëõùëò, it skips over ùëüand performs the split of ùëüùëòatÀÜùëõ. The newly created children from a split of ÀÜùëõare associated with children of ùëõùëòusingùëÄ. The children of ùëõùëòare added in theùëÑand they are recursively processed in the next iteration for further constructing ùëáP.ùëáPis still a specification tree satisfying the Definition 4.1 by construction. The specifications ùúëùëõof a nodeùëõinùëáPcan be constructed using a path from the root to ùëõ. Algorithm 4 Creating a Pruned Tree Input: specification tree ùëáùëÅùëé ùëì, hyperparameter ùúÉ Output: Pruned tree ùëáP 1:ùëõroot‚Üêroot ofùëáùëÅùëé ùëì,ÀÜùëõroot‚Üêcopy ofùëõroot 2:ùëáP‚ÜêInitialize a new tree with ÀÜùëõroot 3:ùëÑ‚ÜêInitialize list with ùëõroot 4:ùëÄ‚ÜêInitialize an empty map 5:ùëÄ[ùëõroot]‚Üê ÀÜùëõroot 6:whileùëÑis not empty do 7:ùëõ‚ÜêùëÑ.pop() ;ùëü‚Üêsplit at node ùëõ;ÀÜùëõ‚ÜêùëÄ[ùëõ] 8: ifùêºùëÅ(ùëõ,ùëü)<ùúÉthen 9:ùëõùëò‚Üêarg minùëõùëò‚ààChildren(ùëõ)LBùëÅ(ùëõùëò)‚àíLBùëÅ(ùëõ) 10:ùëüùëò‚Üêsplit at node ùëõùëò 11:ùëõùëô,ùëõùëü‚Üêùëõùëò.children ;ÀÜùëõùëô,ÀÜùëõùëü‚ÜêSplit(ùëáP,ÀÜùëõ,ùëüùëò) 12:ùëÄ[ùëõùëô]‚Üê ÀÜùëõùëô;ùëÄ[ùëõùëü]‚Üê ÀÜùëõùëü 13:ùëÑ.push(ùëõùëô);ùëÑ.push(ùëõùëü) 14: else 15:ùëõùëô,ùëõùëü‚Üêùëõ.children ;ÀÜùëõùëô,ÀÜùëõùëü‚ÜêSplit(ùëáP,ÀÜùëõ,ùëü) 16:ùëÄ[ùëõùëô]‚Üê ÀÜùëõùëô;ùëÄ[ùëõùëü]‚Üê ÀÜùëõùëü 17:ùëÑ.push(ùëõùëô);ùëÑ.push(ùëõùëü) 18:returnùëáPAlgorithm 5 Incremental Verification Algorithm Input: Original network ùëÅ, Perturbed network ùëÅùëé, property (ùúô,ùúì), analyzerùê¥, branching heuristic ùêª, hyperparameters ùõºandùúÉ, incremental verifier ùëâŒî Output: Verification result for ùëÅandùëÅùëé 1:resultN ,ùëáùëÅ ùëì‚Üêùëâ(ùëÅ,ùúô,ùúì,ùêª) 2:ùëáùëÅùëé 0‚ÜêPrunedTree(ùëáùëÅ ùëì,ùúÉ) 3:ùêªŒî‚ÜêUpdateH(ùêª,ùëáùëÅ ùëì,ùúÉ,ùõº) 4:resultNùëé‚ÜêùëâŒî(ùëÅùëé,ùúô,ùúì,ùëáùëÅùëé 0,ùêªŒî)‚ä≤ Incremental verification step calls Algo rithm 3 5:return resultN,resultNùëé Proc. ACM Program. Lang., Vol. 7, No. PLDI, Article 185. Publication date: June 2023.185:16 Shubham Ugare, Debangshu Banerjee, Sasa Misailovic, and Gagandeep Singh Main algorithm: Algorithm 5 presents IVAN‚Äôs main algorithm for incremental verification that combines all the aforementioned techniques. It takes as inputs the original network ùëÅ, a perturbed networkùëÅùëé, input specification ùúô, and an output property ùúì. It prunes the final tree ùëáùëÅ ùëìobtained in the verification of ùëÅand constructs ùëáùëÅùëé 0(line 2). It computes the updated branching heuristic ùêªŒîusing Equation 7 (line 3). It uses ùëáùëÅùëé 0andùêªŒîfor performing fast incremental verification of networksùëÅùëé(line 4). We next state the following lemma that states  verifying the property (ùúô,ùúì)is equivalent to verifying the specifications for all the leaves. Lemma 1. The specifications encoded by the leaf nodes of a specification tree ùëámaintain the following invariance.  √õ ùëõ‚ààùëôùëíùëéùë£ùëíùë†(ùëá)ùúëùëõ! ‚áê‚áí(ùúô‚Üíùúì) We next use the lemma to prove the soundness and completeness of our algorithm. All the proofs are in Appendix 9.2. Theorem 2. (Soundness of Verification Algorithm). If Algorithm 5 verifies the property (ùúô,ùúì)for the networkùëÅùëé, then the property must hold. Theorem 3. (Completeness of Verification Algorithm). If for the network ùëÅùëé, the property(ùúô,ùúì) holds then Algorithm 5 always terminates and produces Verified as output. Scope of IVAN: IVAN utilizes the specification tree to store the trace of the BaB proof. The IVAN algorithm enhances this tree by reusing and refining it to enable faster BaB proof of updated networks. Our paper focuses on using IVAN to verify ReLU networks with BaB that implements ReLU splitting. However, we expect that IVAN‚Äôs principles can be extended to networks with other activation functions (tanh, sigmoid, leaky ReLU) for which BaB has been applied for verification. 4.4 Network Perturbation Bounds In this section, we formally characterize a class of perturbations on a network ùëÅwhere our proposed ""Reuse"" technique attains maximum possible speedup. Specifically, we focus on modifications affecting only the last layer which represent many practical network perturbations (e.g, transfer learning, finetuning). The last layer modification assumption is only for our theoretical results in this section. Our experiments make no such assumption and consider perturbations applied across the original network. We leave the derivation of perturbation bounds corresponding to the full IVAN to future work as it requires theoretically modeling the effect of arbitrary network perturbations on DNN output as well as complex interactions between ""Reuse"" and ""Reorder"" techniques. Given a specification tree ùëáand network architecture N, we identify a set of neural networks Cùëá(N) such that any network ùëÅùëé‚ààCùëá(N) can be verified by reusing ùëá. We assume the weights are changed by the weight perturbation matrix E. IfùëÅùëô=ReLU(ùê¥ùëô¬∑ùëã+ùêµùëô) then last layer of ùëÅùëéisùëÅùëé ùëô=ReLU((ùê¥ùëô+E)¬∑ùëã+ùêµùëô). Definition 11 (Last Layer Perturbed Network). Given a network ùëÅwith architectureN, the set of last layer perturbed networks is M(ùëÅ,ùõø)‚äÜN , such that if ùëÅùëé‚ààM(ùëÅ,ùõø)then(‚àÄùëñ‚àà [ùëô‚àí1])¬∑ùëÅùëñ=ùëÅùëé ùëñ,ùëÅùëô=ReLU(ùê¥ùëô¬∑ùëã+ùêµùëô),ùëÅùëé ùëô=ReLU((ùê¥ùëô+E)¬∑ùëã+ùêµùëô)and‚à•E‚à•ùêπ‚â§ùõø.1 We next compute the upper bound of ùõø, for which if the property can be proved/disproved using specification tree ùëáinùëÅthen the same property can be proved/disproved in ùëÅùëéusing the same ùëá. Therefore, once we have the proof tree ùëáthat verifies the property in ùëÅwe can reuse ùëáfor 1‚à•¬∑‚à•ùêπdenotes the Frobenius norm of a matrix Proc. ACM Program. Lang., Vol. 7, No. PLDI, Article 185. Publication date: June 2023.Incremental Verification of Neural Networks 185:17 Table 1. Models and the perturbation ùúñused for the evaluation for incremental verification. Model Architecture Dataset #Neurons Training Method ùúñ ACASXU Networks 6√ó50linear layers ACASXU 300 Standard [Julian et al. 2019]  FCNMNIST 2√ó256linear layers MNIST 512 Standard 0.02 CONVMNIST 2 Conv, 2 linear layers MNIST 9508 Certified Robust [Balunovic and Vechev 2020] 0.1 CONVCIFAR 2 Conv, 2 linear layers CIFAR10 4852 Empirical Robust [Dong et al. 2018]2 255 CONVCIFARWIDE 2 Conv, 2 linear layers CIFAR10 6244 Certified Robust [Wong and Kolter 2018a]4 255 CONVCIFARDEEP 4 Conv, 2 linear layers CIFAR10 6756 Certified Robust [Wong and Kolter 2018a]4 255 verifying any perturbed network ùëÅùëé‚ààM(ùëÅ,ùõø). Assuming the property (ùúô,ùúì)and the analyzer ùê¥ are the same for any perturbed network ùëÅùëé‚ààM(ùëÅ,ùõø)the upper bound of ùõøonly depends on ùëÅ andùëá. We next introduce some useful notations that help us explicitly compute the upper bound of ùõø. GivenùëáletF(ùëÅùëñ,ùëá)be the overapproximated region computed by the analyzer ùê¥that contains all feasible outputs ùëÅùëñof theùëñth layer of the original network. Note F(ùëÅùëñ,ùëá)depends on the ùúôand analyzerùê¥but we omit them to simplify the notation. Let ùëâT(ùëÅ,ùëá)denote whether the property (ùúô,ùúì)can be verifed on network ùëÅwithùëá. Proof of Theorem 4 is presented in Section 9.3 ùêøùêµ(F(ùëÅùëô,ùëá))= min ùëå‚ààF(ùëÅùëô,ùëá)Cùëáùëå (9) ùëâT(ùëÅ,ùëá)=(ùêøùêµ(F(ùëÅùëô,ùëá))‚â• 0) (10) ùúÇ(ùëÅ,ùëá)= max ùëå‚ààF(ùëÅùëô‚àí1,ùëá)‚à•ùëå‚à•2 (11) Theorem 4. Ifùõø‚â§|ùêøùêµ(F(ùëÅùëô,ùëá))| ‚à•C‚à• 2¬∑ùúÇ(ùëÅ,ùëá)then for any perturbed network ùëÅùëé‚ààM(ùëÅ,ùõø)ùëâT(ùëÅ,ùëá) ‚áê‚áí ùëâT(ùëÅùëé,ùëá). The proof of the theorem is in Appendix 9.3. 5 METHODOLOGY "
51,Expediting Neural Network Verification via Network Reduction.txt,"A wide range of verification methods have been proposed to verify the safety
properties of deep neural networks ensuring that the networks function
correctly in critical applications. However, many well-known verification tools
still struggle with complicated network architectures and large network sizes.
In this work, we propose a network reduction technique as a pre-processing
method prior to verification. The proposed method reduces neural networks via
eliminating stable ReLU neurons, and transforming them into a sequential neural
network consisting of ReLU and Affine layers which can be handled by the most
verification tools. We instantiate the reduction technique on the
state-of-the-art complete and incomplete verification tools, including
alpha-beta-crown, VeriNet and PRIMA. Our experiments on a large set of
benchmarks indicate that the proposed technique can significantly reduce neural
networks and speed up existing verification tools. Furthermore, the experiment
results also show that network reduction can improve the availability of
existing verification tools on many networks by reducing them into sequential
neural networks.","Deep neural networks have been widely applied in real world applications. At the same time, it is indispensable to guarantee the safety properties of neural networks in those critical scenarios. As neural networks are trained to be larger and deeper, researchers have deployed various techniques to speed up the verification process. For example, to over approximate the whole network behavior [1]‚Äì[4]; to deploy GPU implementation [5]‚Äì[7]; or to merge neurons in the same layer in an overapproximate manner so as to reduce the number of neurons [8], [9]. This work aims to further accelerate the verification process by ‚Äúpreprocessing‚Äù the tested neural network with ReLU acti vation function and constructing a reduced network with fewer number of neurons and connections. We propose the network reduction technique, which returns a reduced network (named asREDNet ) that captures the exact behavior of the original network rather than overapproximating the original network. Therefore verification over the reduced network equals the original verification problem yet requires less execution cost. The REDNet could be instantiated on different verification techniques and is beneficial for complex verification processes ¬ßEqual contribution ‚Ä†Corresponding authorsuch as branchandbound based (bab) or abstract refinement based methods. For example, branchandbound based meth ods [6], [7], [10], [11] generate a set of subproblems to verify the original problem. Once deployed with REDNet before the branchandbound phase, all the subproblems are built on the reduced network, thus achieving overall speed gain. For abstract refinement based methods, like [4], [12], [13], they collect and encode the network constraints and refine individual neuron bounds via LP (linear program) or MILP (mixedinteger linear program) solving. This refinement process could be applied to a large set of neurons, and the number of constraints in the network encoding can be significantly reduced with the deployment of REDNet. We have implemented our proposed network reduction technique in a prototypical system named REDNet (the reduced net work), which is available at https://github.com/ REDNetverifier/IDNN. The experiments show that the ReLU neurons in the reduced network could be up to 95 times smaller than those in the original network in the best case and 10.6 times smaller on average. We instantiated REDNet on the stateoftheart complete verifier Œ±, Œ≤CROWN [14], VeriNet [15] and incomplete verifier PRIMA [12] and assessed the effectiveness of REDNet over a wide range of benchmarks. The results show that, with the deployment of REDNet, Œ±, Œ≤ CROWN could verify more properties given the same timeout and gain average 1.5√óspeedup. Also, VeriNet with REDNet verifies 25.9% more properties than the original and can be1.6√ófaster. REDNet could also assist PRIMA to gain 1.99√óspeedup and verifies 60.6% more images on average. Lastly, REDNet is constructed in a simple network architecture and making it amenable for existing tools to handle network architectures that they could not support previously. We summarize the contributions of our work as follows: ‚Ä¢We define stable ReLU neurons and deploy the stateof theart bounding method to detect such stable neurons. ‚Ä¢We propose a network reduction process to remove stable neurons and generate REDNet that contains a smaller number of neurons and connections, thereby boosting the efficiency of existing verification methods. ‚Ä¢We prove that the generated REDNet preserves the input output equivalence of the original network. ‚Ä¢We instantiate the REDNet on several stateoftheartarXiv:2308.03330v1  [cs.SE]  7 Aug 2023verification methods. The experiment results indicate that the same verification processes execute faster on the REDNet than on the original network; it can also respond accurately to tougher queries the verification of which were timeout when running on the original network. ‚Ä¢REDNet is constructed with a simple network architec ture, it can assist various tools in handling more networks that they have failed to be supported previously. ‚Ä¢Lastly, we export REDNet as a fullyconnected network in ONNX, which is an open format that is widely accepted by the most verification tools. II. P RELIMINARIES Afeedforward neural network is a function Fdefined as a directed acyclic diagram (V,E)where every node Liin Vrepresents a layer of |Li|neurons and each arc (Li, Lj) inEdenotes that the outputs of the neurons in Liare inputs of the neurons in Lj. For each layer Li‚àà V , in(Li) ={Lj|(Lj, Li)‚àà E} is the preceding layers ofLiand out(Li) ={Lj|(Li, Lj)‚àà E} denotes the succeeding layers ofLi. If the set in(Li)of preceding layers is nonempty, then the layer Lirepresents a computation operator, e.g. the ReLU and GEMM operators; otherwise Liis an input layer of the neural network. In addition, Liis an output layer of the neural network if out(Li)is empty. In this paper, we consider the ReLUbased neural network with one input layer and one output layer. Note that multiple input layers (and output layers) can be concatenated as one input layer (and one output layer). Then a neural network is considered as a sequential neural network if|in(Li)|= 1and |out(Li)|= 1 for all layers Liin the neural network except the input and output layers. We use a vector ‚Éó ato denote the input of a neural network F, and the input space IofFincludes all possible inputs of F. For any input ‚Éó a‚ààI,Li(‚Éó a)is a vector denoting the outputs of neurons in a layer Ligiven this input ‚Éó a. The output F(‚Éó a) of the neural network is the output of its output layer. Theneural network verification problem is to verify that for all possible inputs ‚Éó afrom a given input space I, the outputs F(‚Éó a)of a neural network Fmust satisfy a specific condition. For example, the robustness verification problem is to verify that for all inputs within a specified input space, the neural network‚Äôs output must satisfy that the value of the neuron corresponding to the ground truth label is greater than the values of the other neurons in the output layer. III. O VERVIEW In this section, we present a simple network Fand illustrate how to construct the reduced network via the deletion of stable neurons, where stable neurons refer to those ReLU neurons whose inputs are completely nonnegative or nonpositive. The example is a fullyconnected network with ReLU activation function y=max(0, x)as shown in Figure 1, where the connections are recorded in the linear constraints near each affine neuron. We set the input space Ito be [‚àí1,1]√ó[‚àí1,1], and apply one of the stateoftheart boundx1[‚àí1,1] x2[‚àí1,1]x4x3 x5 x6 x7x9x8 x10 x11 x12y1 y2max(0 , x3) max(0 , x4) max(0 , x5) max(0 , x6) max(0 , x7)x3‚àà[‚àí4,0]‚àíx1‚àíx2‚àí2 x4‚àà[1,5]x1+x2+ 3 x5‚àà[0,4]x1‚àíx2+ 2 x6‚àà[0,4]x1+x2+ 2 x7‚àà[‚àí2,2]‚àíx1+x2x8‚àà[0,0] x9‚àà[1,5] x10‚àà[0,4] x11‚àà[0,4] x12‚àà[0,2]x11‚àíx12x8‚àíx9+x10+ x8+x9+ x10+x11+x12 Figure 1: The example network with initial concrete bounds propagators CROWN [16] to propagate the input intervals to other neurons of the network. The deployment of CROWN returns us the concrete bounds for intermediate neurons, which are displayed next to the corresponding neurons in Figure 1. From this initial computation, we observe that four ReLU neurons are stable :x8is stably deactivated as its input x3‚â§0yields x8= 0 ;x9, x10, x11are stably activated as their inputs are always greater or equal to zero, yielding x9=x4, x10=x5, x11=x6. Given the observation, we could remove those stable ReLU neurons together with their input neurons: we could directly eliminate neurons x3, x8; and delete x4, x5, x6, x9, x10, x11while connecting y1, y2directly to the preceding neurons of x4, x5, x6, which are x1, x2. After removal, the connections are updated as in Figure 2. The new affine constraint of y1is computed as follows: y1=x8‚àíx9+x10+x11‚àíx12 = 0‚àíx4+x5+x6‚àíx12 =x1‚àíx2+ 1‚àíx12(1) Similarly, the computation of y2is updated as follows: x1[‚àí1,1] x2[‚àí1,1] x7 x12y1 y2 max(0 , x7) x7‚àà[‚àí2,2] ‚àíx1+x2x12‚àà[0,2]x1‚àíx2‚àíx12+ 1 3x1+x2+x12+ 7 Figure 2: The network connections after neuron removal 2y2=x8+x9+x10+x11+x12 = 0 + x4+x5+x6+x12 = 3 x1+x2+ 7 + x12(2) The above computation only involves equality replacement; therefore, the two networks in Figure 2 and Figure 1 func tions the same given the specified input space I. However, the network architecture has been modified, and the output neurons are now defined over its preceding layer together with the input layer. To preserve the network architecture without introducing new connections between layers, we merge the stably activated neurons into a smaller set of neurons instead of directly deleting them. The final reduced network is shown below in Figure 3, where we transform the connection between y1, y2andx1, x2 in Figure 2 into two merged neurons m1=x1‚àíx2+1;m2= 3x1+x2 + 7 . Since m2is stably activated given the input space, we have m4=m2, thus y2=m4+x12which equals to the definition of y2in Figure 2. To further enforce m1to remain stably activated, we increase the bias of m1to be 2, which leads to m3=m1, thus y2=m3‚àíx12‚àí1. Therefore, the final reduced network in Figure 3 remains to be a fully connected network, but the stably deactivated neuron x3has been removed, and the original set of stably activated neurons x4, x5, x6are merged into a smaller set of stably activated neurons m1, m2. Note that the connection between y1, y2and m1, m2are actually identity matrix: y1 y2 =1 0 0 1 ¬∑m1 m2 +‚àí1 1 ¬∑x12+‚àí1 0 (3) Therefore, the number of merged neurons depends on the number of neurons in the succeeding layer (e.g., the output layer in this example). Generally speaking, the number of output neurons is significantly smaller than the number of intermediate neurons. Therefore we conduct the reduction in a backward manner from the last hidden layer to the first hidden layer, and the experiments in section VI show that a major proportion of the neurons could be deleted, which boosts verification efficiency and therefore improve precision within a given execution timeout. IV. S TABLE RELU N EURONS REDUCTION A. Stable ReLU neurons Given a ReLU layer Xin a neural network and an input ‚Éó a, the layer Xhas exactly one preceding layer Y(i.e.in(X) = {Y}) and the preactivation of the kthReLU neuron xinX is the output y(‚Éó a)of the kthneuron yinY. For simplicity, we use ÀÜx(‚Éó a) =y(‚Éó a)to denote the preactivation of x. Definition 1. A ReLU neuron xin a neural network is deactivated w.r.t. (with respect to) an input space IifÀÜx(‚Éó a)‚â§0 for all inputs ‚Éó a‚ààI, and xisactivated w.r.t. the input space IifÀÜx(‚Éó a)‚â•0for all ‚Éó a‚ààI. Then xisstable w.r.t. Iifxis deactivated or activated w.r.t. I. It is NPcomplete to check whether the output of a neural network is greater than or equal to 0 [17]. In addition, we can add an additional ReLU layer behind the output layer of thex1[‚àí1,1] x2[‚àí1,1] x7m2m2‚àà[3,11]3x1+x2+ 7 m4m4‚àà[3,11]m1m1‚àà[0,4]x1‚àíx2+ 2 m3m3‚àà[0,4] x12y1 y2 max(0 , x7)max(0 , m1) max(0 , m2) x7‚àà[‚àí2,2] ‚àíx1+x2x12‚àà[0,2]m3‚àíx12‚àí1 m4+x12 Figure 3: The final network after reduction (REDNet), where the dashed connection means the coefficient equals to 0 neural network where the output of the original neural network becomes the preactivation of ReLU neurons, therefore, it is straightforward that checking the stability of ReLU neurons w.r.t. an input space is NPhard. Theorem 1. It is NPhard to check whether a ReLU neuron is stable w.r.t. an input space I. Table I: Bound propagation methods Methods for Stability Detection Other Methods Interval [18], DeepZ/Symbolic [2], [19], [20] Œ≤Crown [21] CROWN [16], FCrown [22], Œ±Crown [23] GCPCrown [24] Deepoly [25], kPoly [26], PRIMA [12] ARENA [13] RefineZono [27],OptC2V [28] DeepSRGR [4] SDPRelaxation [29]‚Äì[31] LP/Lagrangian Dual [32]‚Äì[34] Many methods have been proposed to compute the lower and upper bounds of the preactivation of ReLU neurons. Usu ally, these methods use different constraints to tighten the pre activation bounds, such as linear relaxations, split constraints, global cuts and output constraints. For detecting the stability of ReLU neurons w.r.t. an input space, we only consider the methods which employ the linear relaxations of ReLU neurons alone, as the other constraints may filter out inputs from the input space, e.g. a ReLU neuron is compulsory to be stably deactivated despite the input space if the propagator uses a split constraint to enforce that the preactivation input value is always nonpositive. We enumerate various bound propagation methods in Table I. The methods using other constraints are not suitable for detecting the stability of intermediate neurons, such as Œ≤Crown employs split constraints. In our experiments, we use the GPUbased bound propaga tion method CROWN to detect stable ReLU neurons, which leads to a reasonably significant reduction with a small time cost, as displayed in Table III. B. ReLU layer reduction As illustrated in the example given in section III, after computation of concrete neuron bounds, we detect and handle those stable ReLU neurons in the following ways: 3‚Ä¢For a stably deactivated ReLU neuron whose input value is always nonpositive, it is always evaluated as 0and thereby will be directly deleted from the network as it has no effect on the actual computation; ‚Ä¢For a stably activated ReLU neurons (the input values of which are always nonnegative) in the same layer, we reconstruct this set of stably activated neurons into a smaller set of stably activated neurons as we reduce x4, x5, x6intom1, m2in section III. Reconstruction of Stably Activated Neurons. Figure 2 illustrates that the deletion of stably activated neurons requires creating new connections between the preceding and succeed ing neurons of the deleted neurons. We follow the convention that every intermediate ReLU layer only directly connects to one preceding layer and one succeeding layer, which conducts linear computation (and we defer the details of how to simplify a complicated network with multiple preceding/succeeding connections into such simpler architecture in section V). An example of a ReLU layer pending reduction is shown in Figure 4, where M1indicates the linear connection between layer VandX;M2indicates the connection between layer Y andZ. Biases are recorded in B1andB2respectively. Suppose that the uppermost kneurons in layer Yare stably activated, and we delete them together with their inputs in layer X from Figure 4. After deletion, we need to generate a new connection between layers ZandV. As stably activated ReLU neurons behave as identity functions, the new connection matrix between layer ZandVcan be computed from existing connection matrices M1(sizem√óq) and M2(matrix with size n√óm). Assume that M[0 :k,:]indicates that we slice the matrix to contain only the first krows; and M[:,0 :k]means we only take the leftmost kcolumns of the matrix, we define a matrix M‚Ä≤ V Zwith size n√óqthat is computed as: M‚Ä≤ V Z=M2[:,0 :k]¬∑M1[0 :k,:] (4) Layer V qneuronsAffine X B1 mneuronsReLU Y mneuronsB2Affine Z nneuronsM1 ReLU () M2 Figure 4: Layer XandYwith pending reduction, together with its preceding layer Vand succeeding affine layer Z. We consider this new connection M‚Ä≤ V Zwith size n√óqas: M‚Ä≤ V Z=MI¬∑M‚Ä≤ V X, (5) where M‚Ä≤ V X equals to M‚Ä≤ V Zand functions as the affine connection between layers Vandnewly constructed neurons in layer X;MIdenotes an n√ónidentity matrix and is the affine connection between layer Zand the newly constructed neurons in layer Y, as shown in Figure 5. Here, the additional weight matrix between layers VandZis actually computedasM‚Ä≤ V Z=MI¬∑ReLU ()¬∑M‚Ä≤ V X. For Equation 5 to hold, we need to make sure that the ReLU function between M andM‚Ä≤becomes an identity, which means Mmust be non negative and M‚Ä≤is stably activated. So we will compute the concrete bounds of Mand add an additional bias Bto enforce it as nonnegative as we did for neuron m1in section III. This additional bias will be canceled out at layer Zwith‚àíBoffset. Note that we conduct this reduction in a backward manner from the last hidden layer (whose succeeding layer is the output layer that usually consists of a very small number of neurons, e.g. 10) to the first hidden layer. Therefore, upon reduction of layers XandY, layer Zhas already been reduced and contains a small number nof neurons. In the end, the kstably activated neurons will be reduced into n stably activated neurons and we obtain a smallersized affine layer with m‚àík+nneurons, where kis usually much bigger thann. Therefore, we are able to observe a significant size reduction as shown in Table III. Layer V qneuronsAffine X MB B1[k:m] m‚àík+nneuronsReLU Y M‚Ä≤ m‚àík+nneuronsB‚Ä≤+B2‚àíBAffine Z nneuronsM1[k:m,:] ReLU () M2[:, k:m]ReLU () M‚Ä≤ V X MI Figure 5: The block after reduction of stably activated neurons. M1[k:m,:]contains the last m‚àíkrows of M1, while M2[: , k:m]takes the rightmost m‚àíkcolumns of M2.B‚Ä≤is computed as M2[:,0 :k]¬∑B1[0 :k]. The newly constructed neurons are dashed and colored in blue. Lemma 1. The reduction process preserves the inputoutput equivalence of the original network. That is, for any input ‚Éó a‚ààI,F(‚Éó a)‚â° F‚Ä≤(‚Éó a)where Fis the original network and F‚Ä≤ is the reduced one. Proof. The reduction process operates on ReLU neurons that are stable w.r.t. the input space I. Specifically, (i) Stably deactivated ReLU neurons are always evaluated as 0and can be deleted directly as they have no effect on the subsequent computation; (ii) Stably activated ReLU neurons are recon structed in a way that their functionality are preserved before (Figure 4) and after (Figure 5) reconstruction. For any ‚Éó a‚ààI,V(‚Éó a)is the output of Layer Vand the output of Layer Zis computed as Z(‚Éó a) =M2¬∑ReLU (M1¬∑V(‚Éó a) + B1) +B2in Figure 4. we decompose Z(‚Éó a)‚àíB2as M2[:,0 :k]¬∑ReLU (M1[0 :k,:]¬∑V(‚Éó a) +B1[0 :k])(6) +M2[:, k:m]¬∑ReLU (M1[k:m,:]¬∑V(‚Éó a) +B1[k:m])(7) Without loss of generality , we assume the uppermost kneu rons in layer Yare stably activated. Formula 6 thus simplifies toM2[:,0 :k]¬∑M1[0 :k,:]¬∑V(‚Éó a) +M2[:,0 :k]¬∑B1[0 :k] = MI¬∑M‚Ä≤ V X¬∑V(‚Éó a)+B‚Ä≤, where M‚Ä≤ V X=M2[:,0 :k]¬∑M1[0 :k,:], B‚Ä≤=M2[:,0 :k]¬∑B1[0 :k]andMIis an identity matrix. 4Input NN: ReLU, MaxPooling, Conv, GeMM, Add, Sub, Concat, Reshape, Flatten, MatMul, BatchNormalization, ¬∑¬∑¬∑Intermediate NN: ReLU, SumLinear Simple NN: ReLU, LinearREDNet: ReLU, GeMMVerifiers: Œ±,Œ≤crown, PRIMA, VeriNet, ¬∑¬∑¬∑encode transform reduce verify Figure 6: The procedure of neural network reduction. The encoding session is described in subsection VA; the trans formation is discussed in subsection VB; and the reduction part is explained in section IV. Furthermore, we compute an additional bias Bto ensure that M‚Ä≤ V X¬∑V(‚Éó a) +B‚â•0for all ‚Éó a‚ààI. Thus Formula 6 finally simplifies to: MI¬∑ReLU (M‚Ä≤ V X¬∑V(‚Éó a) +B)‚àíB+B‚Ä≤(8) Based on Formula 8, we obtain Z(‚Éó a) =MI¬∑ReLU (M‚Ä≤ V X¬∑ V(‚Éó a) +B) +M2[:, k:m]¬∑ReLU (M1[k:m,:]¬∑V(‚Éó a) + B1[k:m]) +B‚Ä≤+B2‚àíB, which equals to the computation conducted in Figure 5. Thus, the network preserves input output equivalence after reduction. V. N EURAL NETWORK SIMPLIFICATION In section IV, we describe how reduction is conducted on a sequential neural network, where each intermediate layer only connects to one preceding Linear layer and one succeeding Linear layer. In this paper, a Linear layer refers to a layer whose output is computed via linear computation. Nonethe less, there exist many complicated network architectures (e.g., residual networks) that are not sequential. In order to handle a wider range of neural networks, we propose a neural network simplification process to transform complex network architectures into simplified sequential neural networks and then conduct reduction on the simplified network. We now introduce how to transform a complex ReLUbased neural network into a sequential neural network consisting of Linear and ReLU layers so that stable ReLU neurons can be reduced. Note that we only consider the neural network layers that can be encoded as Linear and ReLU layers; further discussion about this can be found in section VII. The network simplification process involves two main steps (shown in Figure 6): (i) Encode various layers as SumLinear blocks and ReLU layers (we defer the definition of SumLinear block to subsection VA); (ii) Transform SumLinear blocks into Linear layers. Here, Linear layers refer to layers that conduct linear computation. A. Encode various layers into SumLinear blocks ASumLinear block is a combination of a set of Linear layers and a Sum layer such that the Linear layers are preceding layers of the Sum layer, where the output of the Sum layeris the elementwise sum of its inputs. The output of the SumLinear block is equal to the elementwise sum of the outputs of the Linear layers, and the preceding layers of the SumLinear block include the preceding layers of all the Linear layers. Any Linear layer can be encoded as a SumLinear block by adding a Sum layer behind the Linear layer. A main difference between them is that the SumLinear block can have more than 1 preceding layer. Many neural network layers can be directly transformed into SumLinear blocks, such as Conv, GeMM, Add, Sub, Concat, Reshape, Split, Squeeze, Unsqueeze, ¬∑¬∑¬∑, Flatten, MatMul, and BatchNormalization layers used in ONNX models.1Note that the Linear layer only has one preceding layer, while the Add and Concat layers can have more than one preceding layer; hence, they cannot be directly encoded as a Linear layer (this motivates the introduction of SumLinear blocks). X YConcat (a) A Concat layerX YLinear LinearSum SumLinear (b) A SumLinear block Figure 7: Encode a Concat layer into a SumLinear block. Figure 7 shows a SumLinear block encoding a Concat layer with 2 precedessors XandY. The biases of the two Linear layers are zero and the concatenation of their weights is an identity matrix. Thus, each neuron of the layers X, Y is mapped to a neuron of the Sum layer. Assume |X|=|Y|= 1. Their weights are represented by matrices:1 0 and0 1 which can be concatenated into an identity matrix1 0 0 1 . In the same spirit, the Add layer could also be encoded as a SumLinear block as shown in Figure 8. Assume that |X|and |Y|are each equal to 2, the weights of the two Linear layers are represented by identity matrices1 0 0 1 . X YAdd (a) An Add layerX YLinear LinearSum SumLinear (b) A SumLinear block Figure 8: Encode an Add layer into a SumLinear block. 1In general, Maxpooling can be encoded as Conv and ReLU layers with existing tools such as DNNV [35]. Note that max (x, y) =ReLU (x‚àíy)+y. 5B. Transform SumLinear blocks into Linear Layers In this subsection, we show how to encode SumLinear blocks as Linear layers. Firstly, we need to transform Sum Linear blocks into normalized SumLinear blocks. To this end, a SumLinear block Lisnormalized if it does not have any Linear layer of which the preceding layer is a SumLinear block (i.e.in(L)does not have SumLinear blocks), and each of the Linear layers in Lhas different preceding layers. For example, the SumLinear given in Figure 7 is normalized if its preceding layers XandYare not SumLinear blocks. SumLinear Block Normalization . If a SumLinear block L‚Ä≤includes a Linear layer L‚Ä≤ jwith a weight M‚Ä≤ jand a bias B‚Ä≤ jsuch that the preceding layer of L‚Ä≤ jis another SumLinear block L‚Ä≤‚Ä≤including kLinear layers L‚Ä≤‚Ä≤ 1,¬∑¬∑¬∑L‚Ä≤‚Ä≤ kwith weights M‚Ä≤‚Ä≤ 1,¬∑¬∑¬∑, M‚Ä≤‚Ä≤ kand biases B‚Ä≤‚Ä≤ 1,¬∑¬∑¬∑, B‚Ä≤‚Ä≤ k, then we can normalize L‚Ä≤by replacing L‚Ä≤ jwithknew Linear layers L1,¬∑¬∑¬∑Lkwhere for any 1‚â§i‚â§k, the layer Lihas the same preceding layer as that of L‚Ä≤‚Ä≤ i, and the weight and bias of Liare computed as: Mi=M‚Ä≤ j¬∑M‚Ä≤‚Ä≤ i (9) Bi=( B‚Ä≤ j+M‚Ä≤ j¬∑B‚Ä≤‚Ä≤ iifi= 1 M‚Ä≤ j¬∑B‚Ä≤‚Ä≤ i otherwise(10) During the normalization, if the succeeding layers of the block L‚Ä≤‚Ä≤become empty, then L‚Ä≤‚Ä≤is directly removed. In addition, if two Linear layers La, Lbin a SumLinear block have the same preceding layer, then in normalization, we can replace them by one new Linear layer Lcsuch that Lchas the same preceding layer as them and the weight (and bias) of Lcis the sum of the weights (and biases) of La, Lb. Lemma 2. SumLinear block normalization does not change the functionality of a neural network. Proof. Let‚Éó a‚Ä≤‚Ä≤ ibe any input of a Linear layer L‚Ä≤‚Ä≤ iin the block L‚Ä≤‚Ä≤where L‚Ä≤‚Ä≤is the preceding layer of L‚Ä≤ j. Thus, the input of L‚Ä≤ j(called ‚Éó a‚Ä≤ j) equals toPk i=1(M‚Ä≤‚Ä≤ i¬∑‚Éó a‚Ä≤‚Ä≤ i+B‚Ä≤‚Ä≤ i). Then the output ofL‚Ä≤ jisB‚Ä≤ j+Pk i=1(M‚Ä≤ j¬∑M‚Ä≤‚Ä≤ i¬∑‚Éó a‚Ä≤‚Ä≤ i+M‚Ä≤ j¬∑B‚Ä≤‚Ä≤ i)which is equal to the sum of the outputs of the layers L1,¬∑¬∑¬∑Lk. Therefore, replacing L‚Ä≤ jwith L1,¬∑¬∑¬∑Lkdoes not change the output of the SumLinear block L‚Ä≤. If the succeeding layers of L‚Ä≤‚Ä≤become empty, then removing L‚Ä≤‚Ä≤does not affect the outputs of other layers and the network. In addition, the sum of the outputs of the two linear layers La, Lbin a SumLinear Block with the same preceding layer is equal to the output of the new layer Lc, thus, the output of the block does not change after replacing La, LbwithLc. So SumLinear block normalization does not change the functionality of a neural network. We next show how to encode normalized SumLinear blocks as Linear layers. Linear Layer Construction . First, we say that a ReLU layer Liisblocked by a SumLinear block LifLis the only succeeding layer of Li. Then, we use RLto denote the set of ReLU layers blocked by the SumLinear block L. LetPL include other preceding layers of Lwhich are not in RL. IfLis normalized, then Land the set of ReLU layers in RLcan be replaced by a Linear layer Ll, a ReLU layer Lrand a new SumLinear block Lssuch that ‚Ä¢the weight Ml(the bias Bl) of the linear layer Llis a concatenation (the sum) of the weights (the bias) of the Linear layers in Land the preceding layer of LlisLr andLlhas the same succeeding layers as L; ‚Ä¢the SumLinear block Lsencodes a concatenation of layers in PLand the preceding layers of layers in RL; ‚Ä¢Lsis the preceding layer of Lr. Additionally, in order to make sure that the outputs of the layers in PLcan pass through the ReLU layer Lr, the neurons inLrwhich connect to the layers in PLare enforced as activated neurons by adding an additional bias Bto a Linear layer in Lsand minus Ml¬∑Bfrom the bias of Ll. Lemma 3. Linear layer construction does not change the functionality of a neural network. Proof. The preactivation of Lris the output of Lsthat equals toBplus the concatenation of the outputs of layers in PL and the preactivation of Layers in RL. This ensures that the output of Lrequals to Bplus the concatenation (call it ‚Éó a) of the outputs of layers in PLandRL. Next, the output of Ll equals to Ml¬∑(B+‚Éó a) +Bl‚àíMl¬∑B=Ml¬∑‚Éó a+Blwhich is equal to the output of original layer L. In addition, Lis the only succeeding layer of layers in RL, so replacing RL,Lwith the layers Ls,Lr,Lldoes not change the functionality of the neural network. Network simplification. We use algorithm 1 to transform ReLUbased neural networks (V,E)into a sequential neural network consisting of Linear and ReLU layers. At line 1, the function Initialization (V,E)encodes all layers in Vas SumLinear blocks and ReLU layers. Between line 3 and line 8, the algorithm repeatedly selects the last SumLinear block Lin Vand reconstructs Linto Linear layers, where a SumLinear block is the last block means there is not any path from it to another SumLinear block. (V,E)only has 1 output layer, and the Linear and ReLU layers only have 1 preceding layer, thus, there is only one last SumLinear block. Algorithm 1: Neural Network Simplification Input: A neural network (V,E) Output: A sequential neural network 1V,E ‚Üê Initialization (V,E); 2while (V,E)has SumLinear blocks do 3 LetLbe the last SumLinear block in (V,E); 4V,E, L‚ÜêNormalization (V,E, L); 5 if|in(L)|>1then 6 V,E ‚Üê LinearLayerConstruction (V,E, L); 7 else 8 V,E ‚Üê Linearization (V,E, L); 9return (V,E); 6At line 4, the function Normalization (V,E, L)is used to normalize the last SumLinear block L. If the normalized L has more than one preceding layer (i.e. |in(L)|>1), then the function LinearLayerConstruction (V,E, L)is used to replace Lwith the layers Ll, Lr, Lsintroduced in the Lin ear layer construction (at line 6), otherwise the function Linearization (V,E, L)is used to directly replace Lwith the only Linear layer included in L(at line 8). In the rest of this subsection, we show that line 6 in algorithm 1 can only be visited at most |V|times, thus, the algorithm can terminate and generate an equivalent sequential neural network consisting of Linear and ReLU layers. Lemma 4. Assume (V,E)is a neural network consisting of Linear, ReLU layers and SumLinear blocks and Lis the last SumLinear block in V. If|in(L)|>1andin(L)does not have SumLinear blocks and Linear layers, then RLis not empty. Proof. (V,E)only has one output layer and all layers behind Lhave at most one preceding layer, thus, a path from any layer before Lto the output layer must pass L. LetLibe the last ReLU layer in in(L). IfLihas a succeeding layer Ljsuch that LjÃ∏=L, then Lmust be in all paths from Ljto the output layer, and there would be a ReLU layer in in(L)included by a path from LjtoL, which meant that Liwas not the last layer in in(L), a contradiction. Hence, Liis inRLandRLÃ∏=‚àÖ. Based on lemma 4, if |in(L)|>1, then|RL| ‚â•1, thus, the number of ReLU layers before the last SumLinear block in V is decreased after replacing Land the layers in RLwith the layers Ll, Lr, Lsintroduced in the Linear layer construction where Lsbecomes the last SumLinear block in V. So we can get that algorithm 1 can terminate and generate a neural network consisting of Linear and ReLU layers. Theorem 2. Algorithm 1 can terminate and generate a neural network consisting of Linear and ReLU layers. Proof. From lemma 4, we know that line 6 in algorithm 1 re duces the number of ReLU neurons before the last SumLinear block in V, therefore, it can only be visited at most |V|times. Note that SumLinear block normalization (at line 4) does not affect ReLU layers and the layers behind L. Then line 8 can directly replace all SumLinear blocks having one preceding layer in Vwith Linear layers. There fore, algorithm 1 can terminate and return a neural network consisting of Linear and ReLU layers. Theorem 3. Our constructed REDNet is inputoutput equiv alent to the original network given the input space I. Proof. (Sketch.) Our reduction technique contains two steps: (i) network simplification presented in section V; (ii) stable ReLU neuron reduction described in section IV. Each step is designed deliberately to preserve inputoutput equivalence. Simplification equivalence. Function Initialization (V,E) at line 1 in algorithm 1 encodes ONNX layers into a uniform network representation; such encoding preserves inputoutputequivalence. Then lemma 2 and lemma 3 show that line 4 and line 6 do not change network functionality. In addition, line 8, replacing a SumLinear Block with the only Linear layer in the block, also does not change network output. Therefore, algorithm 1 can construct a sequential neural network that has the same functionality as the original neural network. Reduction equivalence. The proof is given in lemma 1. C. Illustrative example of network simplification In this subsection, we use a simple network block to illus trate how to perform algorithm 1 on a nonsequential structure (Figure 9(a)) to get a sequential neural network consisting of Linear and ReLU layers (Figure 9(b)). In Figure 9, each rectangular node (including n1, n2, n3, n4) represents a set of neurons whose values are derived from the preceding connected node(s) and the connections between them. Note that redcolored rectangular nodes are ReLU nodes that rep resent the output neurons of the ReLU layer; blue nodes are convolutional nodes; the black node is an Add layer. The connections between nodes are represented with directed edges, and the connected functions are displayed near the edges (e.g. conv1, ReLU). Symbol ‚äïrepresents concatenation. n1 n2 n3 n4conv3conv1 ReLU conv2 (a) Before simplificationn1 n2‚äïn‚Ä≤ 1 n3‚äïn‚Ä≤‚Ä≤ 1 n4conv1‚äïidentity ReLU conv2‚äïconv3 (b) After simplification Figure 9: The simplification of a nonsequential block Firstly, we apply function Initialization (V,E)at line 1 to encode Figure 9(a) as SumLinear blocks and ReLU layers, where the weights and biases of each Linear layer are dis played above the layer. We name the two ReLU nodes n1, n3 as ReLU1, ReLU2 respectively. ReLU1 Linear Sum ReLU2 Linear Sum Linear Sum Linear Sum Linearconv1weightsconv1biases conv2weightsconv2biases identity matrixbias=0 identity matrixbias=0 conv3weightsconv3biases Figure 10: Network in Figure 9(a) encoded with SumLinear blocks and ReLU layers 7Then we take the last SumLinear block from Figure 10 and normalize this block (Figure 11(a)) and obtain the normalized block as in Figure 11(b). The whole network is now updated as Figure 12. Linear Sum Linear Sum Linear Sum Linearconv2weightsconv2biases identity matrixbias=0 identity matrixbias=0 conv3weightsconv3biases (a) The last block before normalizationLinear Sum Linearconv2weightsconv2biases conv3weightsconv3biases (b) After normalization Figure 11: Normalization of the last SumLinear block ReLU1 Linear Sum ReLU2 Linear Sum Linearconv1weightsconv1biases conv2weightsconv2biases conv3weightsconv3biases Figure 12: The network after the first normalization At this step, we notice that ReLU layer ReLU2 is blocked by the last SumLinear block, and ReLU1 is not blocked as it has another path to a subsequent ReLU layer. Therefore, we perform the Linear layer construction at line 6 and obtain the network in Figure 13. ReLU1Linear Sum Linear Sum ReLU2‚äïReLU1 Linear Linearconv1weightsconv1biases 1 0bias=0  0 1bias=0 The new LrThe new Ll The new Lsconv2w ‚äïconv3wconv2b +conv3b Figure 13: The network after the Linear layer construction. For simplicity to show the weight matrices, we assume that ReLU2 and ReLU1 all have one neuron; and ‚Äúbiases/weights‚Äù are abbreviated as ‚Äúb/w‚Äù respectively. Lastly, we take out the last SumLinear block in Figure 13 and perform normalization to obtain Figure 14. At Figure 14, the last SumLinear block includes two Linear layers having the same preceding layer ReLU1 (Figure 14), which requires further normalization. The final architecture of the network is given in Figure 15, where we haveconv1w identity =conv1w ‚äïidentity. Now the oringal network has been simplified into a sequential one.ReLU1Linear Sum ReLU2‚äïReLU1 Linear Linear conv1w 0  0 identity conv1b 0 bias=0conv2w ‚äïconv3wconv2b +conv3b Figure 14: The network after the second normalization ReLU1 Linear ReLU2‚äïReLU1 Linear conv1w identity conv1b 0 conv2w ‚äïconv3wconv2b +conv3b Figure 15: The sequential network after the third normalization VI. E XPERIMENTS In this section, we present our experimental results of instantiation of network reduction technique on Œ±, Œ≤CROWN [14], VeriNet [15] and PRIMA [12] to show evidence that: given the same verification problem, the same verification algorithm runs faster on the reduced network compared to the original network, which gives us confidence in the ability of our method as in enhancing the efficiency of existing verification methods. Furthermore, the simple architecture in REDNet allows existing verification tools that only support limited network benchmarks to handle more networks. A. Experiment Setup The evaluation machine has two 2.40GHz Intel(R) Xeon(R) Silver 4210R CPUs with 384 GB of main memory and a NVIDIA RTX A5000 GPU. Evaluation Benchmarks. The evaluation datasets include MNIST [36] and CIFAR10/CIFAR100 [37]. MNIST dataset contains handwritten digits with 784 pixels, while CI FAR10/CIFAR100 includes colorful images with 3072 pixels. We chose fullyconnected, convolutional and residual networks with various sizes from two wellknown benchmarks: the academic ERAN system [38] and VNNCOMP2021/2022 (In ternational Verification of Neural Networks Competition) [39], [40]. The number of activation layers (#Layers), the number of ReLU neurons (#Neurons), and the trained defense of each network are listed in Table II, where a trained defense refers to a defense method against adversarial samples to improve robustness. Please note that ‚ÄúMixed‚Äù means mixed training, which combines adversarial training and certified defense training loss. This could lead to an excellent balance between model clean accuracy and robustness, and is beneficial for obtaining higher verified accuracy [41]. Verification Properties. We conduct robustness analysis, where we determine if the classification result of a neural 8network ‚Äì given a set of slightly perturbed images derived from the original image (input specification) ‚Äì remains the same as the ground truth label obtained from the original unperturbed image (output specification). The set of images is defined by a userspecified parameter œµ, which perturbs each pixel pito take an intensity interval [pi‚àíœµ, pi+œµ]. Therefore, the input space Iisn i=1[pi‚àíœµ, pi+œµ]. In our experiment, we acquire the verification properties from the provided vnnlib files [44] that record the input and output specification or via a selfspecified œµ. We aim to speed up the analysis process for those properties that are tough to be verified . Hence we filter outthose falsified properties. We obtain around 30 properties for each tested network, as enumerated in Table II. B. Network reduction results Table III shows the size of reduced networks, where the bound propagation methods crown and Œ±crown are used to compute concrete bounds and detect stable neurons. Here we present the number of neurons in the original network and the average size after reduction (under column ‚ÄúAvgN‚Äù) and reduction time (under column ‚ÄúAvgT‚Äù) for the two methods. We have outofmemory problem when running Œ±crown on network C 100 Large, thus we mark the result as ‚Äú‚Äù. The table shows that a significant number of neurons could be reduced within a reasonable time budget by leveraging the concrete bounds returned by CROWN. Therefore, we use CROWN as our bound propagator for the rest of the experiments. On average, the reduced networks are 10.6√ó smaller than the original networks. Figure 16(a) shows the reduction ratio distribution where each dot (Œ±, Œ≤)in the figure means that the reduction ratio is greater than Œ≤onŒ±percent properties. The reduction ratio can be up to 95 times at the best case and greater than 20 times on 10% properties. Figure 16(b) gives the size distribution of reduced networks. Each dot (Œ±, Œ≤)in the figure means the reduced networks have at most Œ≤ReLU neurons on Œ±percent properties. We can see that on more than 94% properties, there are at most 8000 ReLU neurons in the reduced networks. Table II: Detailed information of the experimental networks Network Type #Layers #Neurons Defense #Property M256x6 fullyconnected 6 1,536 None 30 MConvMed convolutional 3 5,704 None 31 MConvBig convolutional 6 48,064 DiffAI [42] 29 MSkipNet residual 6 71,650 DiffAI 31 C8255Simp convolutional 3 16,634 None 30 CWideKW convolutional 3 6,244 None 32 CConvBig convolutional 6 62,464 PGD [43] 37 CResnet4b residual 10 14,436 None 30 CResnetA residual 8 11,364 None 32 CResnetB residual 8 11,364 None 29 C100 Med residual 10 55,460 Mixed 24 C100 Large residual 10 286,820 Mixed 24Table III: The average number of ReLU neurons on reduced networks and the mean reduction time in seconds. NetworkOriginal Reduced (CROWN) Reduced ( Œ±Crown) #Neurons AvgN AvgT(s) AvgN AvgT(s) M256x6 1,536 991.77 0.14 901.10 3.10 MConvMed 5,704 2210.77 0.21 2189.32 2.05 MConvBig 48,064 3250.93 0.32 3229.76 5.03 MSkipNet 71,650 7019.00 0.72 6796.58 7.79 C8255Simp 16,634 2168.13 0.33 2117.90 1.92 CWideKW 6,244 567.06 0.28 563.47 2.08 CConvBig 62,464 6495.00 0.39 6451.57 4.77 CResnet4b 14,436 7606.73 0.64 7449.23 10.97 CResnetA 11,364 4654.84 0.64 4583.06 8.08 CResnetB 11,364 4425.90 0.60 4368.03 10.67 C100 Med 55,460 2394.63 1.25 2352.33 12.09 C100 Large 286,820 7207.29 3.50   2021222324252627 0 20 40 60 80 100Reduction Ratio %Properties (a) Reduction ratio 2829210211212213214 0 20 40 60 80 100#Neurons %Properties (b) Size distribution Figure 16: Visualized results of the reduction with CROWN C. Instantitation on Œ±, Œ≤CROWN Œ±, Œ≤CROWN is GPU based and the winning verifier in VN NCOMP 2021 [39] and VNNCOMP 2022 [40], the methodol ogy of which is based on linear bound propagation framework and branchandbound. We first instantiate our technique on Œ±, Œ≤CROWN, and we name the new system as Œ±, Œ≤CROWN R. We set the timeout of verification as 300 seconds, and if the tool fails to terminate within the timeout, we deem the result to be inconclusive. The results are listed in Table IV, where we explicitly enumerate the number of timeout properties, the number of verified properties, and the average execution time of Œ±, Œ≤CROWN (column Œ±, Œ≤CROWNO ) and our in stantiated system (column Œ±, Œ≤CROWNR ) on the properties where both methods can terminate within timeout.2 From the result, we observe that Œ±, Œ≤CROWNR could verify more tough properties that have failed to be verified within 300 seconds in Œ±, Œ≤CROWNO. This indicates that our reduction preprocessing does not only benefit those easy verification problems but also helps verify more difficult properties within a decent time. In general, Œ±, Œ≤CROWNR verifies 11 more properties and boosts the efficiency of Œ±, Œ≤ CROWNO with average 1.52√óspeedup on all 12 networks. 2When the original method is timeout or fails to execute for all properties, e.g. C 100 Med in Table V and M ConvBig in Table VI, the average time is computed on the properties where our method can terminate within timeout. 9In addition, the performance of REDNet is affected by the network reduction ratio. For example, Œ±, Œ≤CROWNR only has average 1.12 speedup on M 256√ó6 whose reduction ratio is only 1.55, while Œ±, Œ≤CROWNR can have average 2.52 √ó speedup on C 100 large whose mean reduction ratio is 39.80. D. Instantitation on PRIMA PRIMA [12] is one of the stateoftheart incomplete verifi cation tools. It introduces a new convex relaxation method that considers multiple ReLUs jointly in order to capture the correlation between ReLU neurons in the same layer. Furthermore, PRIMA leverages LPsolving or MILPsolving to refine individual neuron bounds within a userconfigured timeout. Note that PRIMA stores the connection between neurons in two ways: 1. Dense expression, which encodes the fullyconnected computation in a fullyconnected layer; 2. Sparse expression, that only keeps the nonzero coefficients and the indexes of preceding neurons of which the corre sponding coefficients are nonzero (e.g. convolutional layer). As some affine connections between layers in our reduced network contain many zero elements (since we introduce the identity matrix in the newly constructed connection), we elect to record them as sparse expressions in the instantiated PRIMA (abbreviated as PRIMAR). The comparison results are given in Table V, and we set a 2000 seconds timeout for each verification query as PRIMA runs on the CPU and usually takes a long execution time for deep networks. Note that PRIMA returns segmentation fault for M SkipNet, thus the results are marked as ‚Äú‚Äù; PRIMA times out for all properties of C 100 Med and C 100 Large, hence marked as ‚ÄúTO‚Äù. Note that there are some cases where PRIMAR runs slower than PRIMAO, e.g., for network CConvBig. This happens because PRIMA conducts refined verification by pruning the potential adversarial label one by one within a certain timeout. Once an adversarial label fails to be pruned within the timeout, PRIMA returns unknown Table IV: The results of Œ±, Œ≤CROWN on the original network and the reduced network. The time is the average execution time of the properties where both methods terminate before timeout. Neural NetŒ±, Œ≤CROWNO (on original network)Œ±, Œ≤CROWNR (on reduced network) #Timeout #Verfied Time(s) #Timeout #Verfied Time(s) M256x6 1 29 100.53 1 29 89.81 MConvMed 4 27 48.29 2 29 40.41 MConvBig 3 26 43.34 1 28 26.16 MSkipNet 5 26 38.66 2 29 22.35 CWideKW 1 31 13.46 1 31 11.76 C8255Simp 0 30 19.23 0 30 16.92 CConvBig 1 36 26.93 0 37 19.97 CResnet4b 1 29 39.25 1 29 30.84 CResnetA 0 32 40.16 0 32 29.96 CResnetB 1 28 28.08 0 29 20.54 C100 Med 4 20 22.96 3 21 9.32 C100 Large 3 21 14.29 2 22 5.68Table V: The experiment results of PRIMA on the original network and the reduced network. When PRIMAO fails to execute or times out for all the properties, e.g. M SkipNet or C100 Med, the average time is computed on the properties where our method can terminate within the timeout. Neural NetPRIMAO (on original network)PRIMAR (on reduced network) #Unknown #Verfied Time(s) #Unknown #Verfied Time(s) M256x6 30 0 299.94 30 0 281.77 MConvMed 23 8 244.45 22 9 196.83 MConvBig 23 6 352.71 23 6 75.13 MSkipNet    30 1 432.08 CWideKW 3 29 53.80 3 29 10.21 C8255Simp 30 0 329.94 27 3 255.97 CConvBig 32 5 227.81 23 14 282.40 CResnet4b 25 5 912.37 25 5 757.86 CResnetA 28 4 537.36 28 4 459.67 CResnetB 25 4 486.68 23 6 416.12 C100 Med 24 0 TO 14 10 135.97 C100 Large 24 0 TO 13 11 243.92 immediately without checking the rest of the adversarial labels. In PRIMAR, we could prune those failed labels that previ ously timed out in PRIMAO, thus continuing the verification process, which may take more overall time. But accordingly, we gain significant precision improvement, e.g. PRIMAR can verify 9 more properties on C ConvBig. On average, PRIMAR gains 1.99√óspeedup than PRIMA O and verifies 60.6% more images, which indicates the strength of REDNet to improve both efficiency and precision. E. Instantiation on VeriNet VeriNet [15] is the stateoftheart complete symbolic in terval propagation based toolkit. It is the secondplace winner in VNNCOMP 2021. Similarly, we present the result of the original VeriNet tool under the column VeriNetO at Table VI; the instantiation of REDnet on VeriNet is named VeriNetR. The time reported is the average execution time on properties where both VeriNetO and VeriNetO terminate within 300 seconds of timeout. We use a free FICO Community license for the XPress solver called by VeriNet. Thus, we only consider 8 networks which fit the limits of the license. In general, VeriNetR can verify 25.9% more properties than VeriNetO. On average, VeriNetR can be 1.65√ófaster than VeriNetO. Additionally, the result in Table VI marked with ‚Äú‚Äù means that the neural networks M ConvMed and MConvBig are not supported by VeriNet. This shows that network reduction can improve the availability of VeriNet. F . Overall comparison in visualized figures Figure 17 gives a visualized comparison between the veri fication tools on the original network and those on REDNet. Figure 17(a), Figure 17(c) and Figure 17(d) shows the exe cution time of the verification tools on all tested properties. Each dot in the figures denotes a property, and both the x axis and yaxis indicate execution time in seconds. The result of a verification tool on an unsupported network is regarded 10Table VI: The experiment results of VeriNet. The time is the average execution time of the properties where both methods terminate before timeout. When VeriNetO fails to execute, e.g. M ConvBig, the average time is computed on the properties where our method can terminate within the timeout. Neural NetVeriNetO (on original network)VeriNetR (on reduced network) #Timeout #Verfied Time(s) #Timeout #Verfied Time(s) M256x6 27 3 52.94 27 3 47.78 MConvMed    19 12 23.96 MConvBig    23 6 48.81 CWideKW 3 29 27.12 2 30 22.74 C8255Simp 10 20 63.26 10 20 52.56 CResnetA 25 7 129.49 25 7 83.35 CResnetB 21 8 116.80 20 9 74.98 C100 Med 10 14 69.71 9 15 21.15 as timeout. Then Figure 17(b) shows the execution time distribution of Œ±, Œ≤CROWNR and Œ±, Œ≤CROWNO, where each position (Œ±, Œ≤)denotes that the tool can verify Œ≤percent properties in Œ±seconds. For example, by setting the time limit to 10 seconds, Œ±, Œ≤CROWNR can verify 32.9% properties, andŒ±, Œ≤CROWNO only verifies 18.3% properties. On most properties, the verification tools on REDNet are faster than the tools on the original network. Despite its generality, REDNet may achieve marginal effectiveness on certain tools or benchmarks due to the following factors: ‚Ä¢The reduction ratio affects the subsequent verification acceleration. A less significant reduction ratio plus the reduction cost could cause marginal overall speedup. Figure 17(e) and Figure 17(f) depict the effect of the re duction ratio on the speedup gained. Despite other factors affecting the final speedup, there is a general trend that a significant reduction ratio leads to better speedup, which may cause superb effectiveness on networks C 100 Med and C 100 Large. ‚Ä¢Different tools may use distinct bound propagation meth ods, which have different degrees of dependency on the network size. PRIMA deploys DeepPoly whose time complexity depends on N3where each layer has at most Nneurons [45]; as such reduction in network size can lead to better performance. Œ±, Œ≤CROWN, on the other hand, uses Œ≤crown. Œ≤crown is used to generate con straints of output neurons defined over preceding layers until the input layer. Thus, the number of constraints does not vary, and the number of intermediate neurons can only affect the number of variables that appear in the constraint; as such, deployment of REDNET may reap a marginal effect in speedup on Œ±, Œ≤CROWN compared to PRIMA. For VeriNet, it uses symbolic interval propa gation to generate constraints of intermediate and output neurons defined over the input neurons. Thereby interme diate neuron size only affects the number of constraints while the number of defined variables in the constraint is fixed as the input dimension. Hence, REDNet could be less effective on VeriNet compared to PRIMA in general. 202122232425262728 202122232425262728Œ±,Œ≤CROWNO Œ±,Œ≤CROWNR(a)Œ±, Œ≤CROWNR/O 020406080100 2122232425262728%Properties Time (in seconds)Œ±,Œ≤CROWNR Œ±,Œ≤CROWNO (b)Œ±, Œ≤CROWN time distribution 242526272829210211 242526272829210211PRIMAO PRIMAR (c) PRIMAR v.s. PRIMAO 232425262728 23 24 25 26 27 28VeriNetO VeriNetR (d) VeriNetR v.s. VeriNetO 0.511.522.533.544.5 21 22 23 24 25 26Speedup Reduction Ratio (e)Œ±, Œ≤CROWN and VeriNet results 0510152025 0 5 10 15 20Speedup Reduction Ratio (f) PRIMA speedup results Figure 17: Visualized comparison results. ‚Ä¢Some layer types (e.g. Conv) may compute faster than fullyconnected layers; since our method transforms these layers into fullyconnected layers before performing net work reduction, its efficiency may not be that significant as compared to the original layers. On the other hand, it is worthnoticing that the use of fullyconnected layers improves the availability of existing tools. ‚Ä¢Œ±, Œ≤CROWN and VeriNet are branchandbound based and they generate subproblems from their respective branching heuristics, which are dependent on the original network structures. The REDNet changes the network structure, and hence the heuristic can generate different subproblems. This may affect the performance. We conclude empirically that REDNet has better perfor mance (significant speedup or much more properties verified) on large networks, i.e. networks with more than 40k ReLU neurons. On the large networks, the average speedup of Œ±, Œ≤ CROWNR is 1.94 √ó, and the average speedup of VeriNetR is 113.29√ó; and PRIMAR verifies 42 properties while PRIMAO only verifies 11 properties. G. Support of other verifiers for the benchmarks As can be seen from subsection VID, PRIMA fails to analyze M SkipNet because it does not support its network ar chitecture. However, with the introduction of REDNet, which is constructed as a fullyconnected neural network, PRIMA is now able to verify M SkipNet. A similar improvement happens to VeriNet. Therefore, our REDNet not only speeds up the verification process but also allows existing tools to handle network architectures that are not supported originally. To further testify that the reduced network adds support to existing verification tools, we select four tools  Debona [46], Venus [47], Nnenum [48], PeregriNN [49]  from VN NCOMP2021/2022 that only support limited network archi tectures. We select one representative verification property for each of our tested networks to check if the four designated tools can support the networks. Table VII: The networks supported by existing verification tools. A fully black circle indicates both the original and the reduced networks are supported. A righthalf black circle indicates that the tool supports only the reduced network. Networks(12)Tools Venus Debona Nnenum PeregriNN M256x6      MConvMed H #H #H #H # MConvBig H #H #H #H # MSkipNet ReLUerror H #H #H # CWideKW  H #   C8255Simp H # H # CConvBig H #H #H #H # CResnet4b H #H #H #H # CResnetA H #H #H #H # CResnetB H #H #H #H # C100 MedH #H #H #H # C100 LargeH #H #H #H # We present the results in Table VII where we color the left half of the circle black to indicate that the original network is supported by the tool (and white otherwise); we also color the right half of the circle black if the reduced network is supported by the tool (and white otherwise.) In general, the black color implies the network is supported and the white color implies the network is not supported . Note that Venus does not support networks whose output layer is a ReLU layer; therefore, it cannot be executed for both the original and the reduced network for M SkipNet. These results boost our confidence that our constructed REDNet not only accelerates the verification but also produces a simple neural network architecture that significantly expands the scope of neural networks which various tools can handle. VII. D ISCUSSION We now discuss the limitation of our work. Supported layer types. As described in section V, our re duced neural network contains only Affine layers (e.g. GEMMlayers) and ReLU layers, therefore we could only represent nonactivation layers that conduct linear computation. For example, an Add layer that takes layer Œ±and layer Œ≤conducts linear computation as the output is computed as Œ±+Œ≤. A Convolutional layer conducts linear computation as well as it only takes one input layer and the other operands are constant weights and bias. However, we couldn‚Äôt support aMultiplication layer if it takes layer Œ±and layer Œ≤and computes Œ±√óŒ≤as the output. For future work, we will explore the possibility of handling more nonlinear computations. Floatingpoint error. As presented in Theorem 3, our re duction process preserves the inputoutput equivalence of the original network in the realnumber domain. However, like many existing verification algorithms [12], [14], [24], [26] that use floatingpoint numbers when conducted on physical machines, our implementation involves floatingpoint number computation, thus inevitably introducing floatingpoint error. The error could be mitigated by deploying float data type with higher precision during implementation. VIII. R ELATED WORK "
367,Zonotope Domains for Lagrangian Neural Network Verification.txt,"Neural network verification aims to provide provable bounds for the output of
a neural network for a given input range. Notable prior works in this domain
have either generated bounds using abstract domains, which preserve some
dependency between intermediate neurons in the network; or framed verification
as an optimization problem and solved a relaxation using Lagrangian methods. A
key drawback of the latter technique is that each neuron is treated
independently, thereby ignoring important neuron interactions. We provide an
approach that merges these two threads and uses zonotopes within a Lagrangian
decomposition. Crucially, we can decompose the problem of verifying a deep
neural network into the verification of many 2-layer neural networks. While
each of these problems is provably hard, we provide efficient relaxation
methods that are amenable to efficient dual ascent procedures. Our technique
yields bounds that improve upon both linear programming and Lagrangian-based
verification techniques in both time and bound tightness.","With the growing prevalence of machine learning in realwor ld applications, the brittleness of deep learning systems poses an even greater threat. It is wellkn own that deep neural networks are vul nerable to adversarial examples, where a minor change in the input to a network can cause a major change in the output [1]. There is a long history of defense te chniques being proposed to improve the robustness of a network, only to be completely broken sho rtly thereafter [2]. This has inspired researchers to focus instead on neural network veriÔ¨Åcation , which, for a given network and a range of input, aims to verify whether a certain property is satisÔ¨Å ed for every input in that range. A typical adversarial attack seeks to minimize the output of a scalar valued network subject to certain input constraints. VeriÔ¨Åcation provides lower bounds on the mini mum output value achievable by such an adversary. Concretely, for a scalarvalued network fand input range X, veriÔ¨Åcation provides lower bounds to the problem minx‚ààXf(x). As observed in [3], prior works in veriÔ¨Åcation can be broadly categorized into primal and dual views. In the primal view, convex relaxations are applied to attain, for every intermediate layer of the network, a convex superset of the true attainable range. For example, if f=fL‚ó¶¬∑¬∑¬∑‚ó¶f1, convex setsZkare obtained such that {fk‚ó¶¬∑¬∑¬∑‚ó¶f1(x)|x‚àà X} ‚äÜ Z kfork‚àà {1,...,L}. ‚àóEqual contribution ‚Ä†Github Repo: https://github.com/revbucket/dualverification 36th Conference on Neural Information Processing Systems ( NeurIPS 2022).Under the dual lens, veriÔ¨Åcation is treated as a stagewise op timization problem and Lagrangian re laxation is applied to yield a dual function that always prov ides valid lower bounds. Often, this dual function is decomposable into a sum of minimization problem s which are efÔ¨Åciently computable. One hallmark of all existing dual veriÔ¨Åcation techniques is that intermediate bounds Zkare required. In this case, either an efÔ¨Åcient primal veriÔ¨Åcation algorit hm must Ô¨Årst be applied or, for example, the dual veriÔ¨Åer can be run iteratively on each neuron to prov ide upper and lower bounds for each intermediate layer. Our approach is an attempt to combine the primal and dual thre ads of veriÔ¨Åcation. We Ô¨Årst apply a primal veriÔ¨Åcation algorithm that generates bounds on the a ttainable range of each intermediate layer. To do this we leverage zonotopes, a more expressive class of p olytopes than axisaligned hyperboxes. Notably, we offer an improvement to existing zonotope bound s when we are also provided with incomparable hyperbox bounds. These zonotopic intermedia te bounds are then applied to a dual veriÔ¨Åcation framework, for which dual ascent can be perform ed. Our formulation may be viewed as taking the original nonconvex veriÔ¨Åcation problem and de composing it into many subproblems, where each subproblem is a veriÔ¨Åcation problem for a 2layer neural network. However, as even verifying a 2layer network is hard in general, we further de velop efÔ¨Åcient relaxation techniques that allow for tractable dual ascent. We introduce a novel algorithm, which we call ZonoDual, whic hi) is highly scalable and amenable to GPU acceleration, ii) provides tighter bounds than both the prior primal and dual techniques upon which our approach is built, iii) is highly tunable and able to effectively balance the compe ting objectives of bound tightness and computation speed, and iv) is applicable as an addon to existing dual veriÔ¨Åcation frameworks to further boost their perform ance. We apply ZonoDual to a variety of networks trained on MNIST and CIFAR10 and demonstrate that ZonoDual outperforms the linear programming relaxation in both tightness and runtime, and y ields a tighter bounding algorithm than the prior dual approaches. We Ô¨Årst discuss prior works in the veriÔ¨Åcation domain. Then, we examine the existing dual frame work that serves as the backbone for our algorithm, paying pa rticular attention to the areas in which this may be tightened. Then, we discuss how we attain zonotop ebased intermediate bounds and introduce the fundamental subproblem required by our dual ascent algorithm. Ultimately, we com bine these components into our Ô¨Ånal algorithm and demonstra te the scalability and tightness of our approach on networks trained on the MNIST and CIFAR10 datas ets. 2 Related Work "
319,Measurement error models: from nonparametric methods to deep neural networks.txt,"The success of deep learning has inspired recent interests in applying neural
networks in statistical inference. In this paper, we investigate the use of
deep neural networks for nonparametric regression with measurement errors. We
propose an efficient neural network design for estimating measurement error
models, in which we use a fully connected feed-forward neural network (FNN) to
approximate the regression function $f(x)$, a normalizing flow to approximate
the prior distribution of $X$, and an inference network to approximate the
posterior distribution of $X$. Our method utilizes recent advances in
variational inference for deep neural networks, such as the importance weight
autoencoder, doubly reparametrized gradient estimator, and non-linear
independent components estimation. We conduct an extensive numerical study to
compare the neural network approach with classical nonparametric methods and
observe that the neural network approach is more flexible in accommodating
different classes of regression functions and performs superior or comparable
to the best available method in nearly all settings.","The study of nonparametric regression with measurement error is a classical problem in statistics and has received a lot of attentions (Carroll et al., 2006). In a typical setting, the response Y2RsatisÔ¨Åes that E[YjX] =f(X), whereX2Rdare the covariates and f:Rd!Ris an unknown regression function. The covariates are observed with additive errors, i.e., we observe W=X+Uinstead ofX, whereUis a meanzero random vector whose distribution is known. Given (W;Y ), the problem of interest is to estimate the nonparametric functionf. Most existing methods for Ô¨Åtting measurement error models (MEMs) heavily use classical techniques in nonparametric statistics, such as kernel estimators, splines, and local polynomi als. The deconvolution method (Fan and Truong, 1993) combines the kernel estimator in nonparametric regression with the deconvolution technique in density estimation. Another The authors gratefully acknowledge the support of the NSF grant DMS1943902. 1arXiv:2007.07498v1  [stat.ML]  15 Jul 2020class of methods approximate the regression function fby splines and estimate the spline coeÔ¨Écients using estimating equations (Jiang et al., 2018). The simulation extrapolation method (Carroll et al., 1999) starts from a standard nonparametric regression method (e.g., splines or local polynomials) and utilizes simulations to estimate and correct its bias when the covariates have errors. While these methods enjoy nice theoretical properties, they still face some major challenges in applications. The Ô¨Årst issue is that each method is limited to a particular function class, such as nonparametric functions that are suÔ¨Éciently smooth or functions that can be well approximated by splines. It is unclear how well they perform when the regression function fis generated by a Gaussian process with a nonsmooth kernel or whenfis a complicated function arising from scientiÔ¨Åc problems. Ideally, we hope to have a method that works for various function classes. Second, these methods require selecting critical tuning parameters, such as the bandwidth in a kernel estimator or the knots for splines. These tuning parameters can signiÔ¨Åcantly aÔ¨Äect the performance, but how to select them in a datadriven fashion is a hard problem. Especially, since the common bandwidth selection techniques were mainly designed for nonparametric regression without measurement errors, they may perform unsatisfactorily when the covariates have errors. The third challenge is generalization to multiple covariates (i.e., d>1). Most existing methods were only studied and evaluated for the case of d= 1. Although some of them have extensions to d>1, the practical implementation can be inconvenient. For example, constructing a multivariate kernel estimator requires selecting the optimal bandwidth matrix, which is diÔ¨Écult in practice. At the same time, the rapid growth of research on deep neural networks opens a new direction for addressing some diÔ¨Écult problems in classical statistics. Attempts have been made for density estimation (Liang, 2018; Singh et al., 2018) and nonparametric regression (SchmidtHieber, 2017; Bauer and Kohler, 2019). In this paper, we aim to integrate deep neural networks into the estimation of measurement error models. Some nice features of the neural network make it promising for overcoming the challenges faced by classical nonparametric methods. First, it has been widely observed, empirically and theoretically, that deep neural networks have the ability of representing a variety of function classes (Barron, 1993; Mhaskar, 1996; Maiorov and Meir, 2000; Lin et al., 2017; Rolnick and Tegmark, 2018), including many smooth function classes considered in classical nonparametric statistics. Hence, we can potentially use neural networks to develop a universal approach that works for all kinds of function classes. Second, deep neural networks tend to be resistant to overÔ¨Åtting and have great generalization power even when the parameter space has a very high complexity (Golowich et al., 2018; Soudry et al., 2018). We note that, in classic nonparametric measurement error models, even a moderate dsigniÔ¨Åcantly increases the complexity of parameter space, and thus may beneÔ¨Åt signiÔ¨Åcantly from using neural networks. The tuning for neural networks is also less critical than the selection of smooth parameters (e.g., bandwidth) in nonparametric methods. For the latter, suboptimal tuning parameters easily lead to overÔ¨Åtting or underÔ¨Åtting. For the former, the major tuning parameters are the architecture of the neural network. We shall use fully connected feedforward neural networks (FNNs), which boils down to selecting the number of layers and the number of nodes for each layer. The resistancetooverÔ¨Åtting by neural networks encourages us to set those numbers large without Ô¨Åne tuning. In this article, we introduce our method of Neural Network for Measurement Error models 2(NNME), which uses a fully connected FNN to approximate the regression function f(x), a normalizing Ô¨Çow (Tabak and Turner, 2013) to approximate the prior distribution of X, and an inference network (Kingma and Welling, 2014; Rezende et al., 2014) to approximate the posterior distribution of X. The training algorithm utilizes some recent advancements in variational inference methods for neural networks, particularly, the importance weighted autoencoder (Burda et al., 2016) and the doubly reparametrized gradient estimator (Tucker et al., 2018). In fact, viewing the MEM as a latent variable model, our problem has a similar setting as the variational autoencoder (VAE). However, a direct application of VAE yields unsatisfactory performance. There is a nascent literature on improvements and alternatives of VAE (Burda et al., 2016; Roeder et al., 2017; Le et al., 2018; Rainforth et al., 2018; Tucker et al., 2018), which is unfortunately not familiar to the statistics community. The description of our method also serves as introducing and elaborating these ideas to the statistics community. We conducted an extensive numerical study to compare NNME with classical nonpara metric methods for estimating MEMs. Although the neural network approach is promising, there is no guarantee that it will indeed outperform classical methods. A theoretical com parison is extremely diÔ¨Écult, as the theoretical understanding of deep learning is known to be challenging (Zhang et al., 2017). We thus focus on numerical comparison and hope to get a practical guideline of when the neural network method excels and to gain useful insight for future theoretical study. We investigate diÔ¨Äerent function classes for f, including smooth functions suitable for classical nonparametric methods, functions generated from Gaussian processes (such functions can be nonsmooth), and functions generated by some other unknown neural networks. We discover that the neural network approach has a great Ô¨Çexibility in accommodating diÔ¨Äerent function classes. It has reasonably good performance (sometimes, the best) in all the settings, while each competitor only works well for some speciÔ¨Åc function classes. In addition, the neural network approach is convenient to apply to the case of multiple covariates, but many classical nonparametric methods are diÔ¨Écult to implement for d>1. The remaining part of this article is organized as follows: Section 2 introduces the NNME algorithm. Section 3 contains the comparison with other existing methods for MEMs. Section 4 presents the application in two real datasets. Section 5 makes concluding remarks. 2 The Neural Network for Nonparametric Regression with Measurement Errors LetY2Rbe the response, and let W2Rdbe the vector of errorprone covariates. We assume Y=f(X) +; N(0;2)andXpX(x); W=X+U; UpU(u); (1) where (X;U; )are mutually independent, pX(x)is the (prior) distribution of errorfree covariates, and pU(u)is the distribution of measurement errors satisfying that EU= 0. Given f(wi;yi);i= 1;2;:::;ngthat are independent and identically distributed (IID) realizations 3WyŒº…∏fŒ∏(X)X=Œº…∏+Œ£…∏1/2ZŒ£…∏Z‚àºN(0,Id)ùõâ…∏ùû¨ùëù!(ùëã)Figure 1: A neural network structure for NNME. The input is wandy, and the output is the estimated regression function f(x). The left green block is an ‚Äúencoder,‚Äù which consists of several fully connected layers with ReLU activation functions and the last layer with a linear function; the output of the encoder are parameters for the proposal distribution. The right green block is a ‚Äúdecoder,‚Äù which has the same network structure as the encoder; the input are random samples of x, and the output are estimated values of f(x). The top green block is another ‚Äúdecoder,‚Äù which consists of a few coupling layers of a normalizing Ô¨Çow; the input are random samples of x, and the output is the estimated marginal density of X. of(W;Y ), the goal is to estimate the regression function f. We follow the convention to assume that the analytical form of the measurement error distribution pU()is precisely known (in practice, this distribution is often estimated from other data source or determined by the prior knowledge). The distribution pX()and the variance of observation noise, 2, are unknown. Note that the assumption that YjXfollows a normal distribution is only for convenience. It can be replaced by other parametric distributions, with minor modiÔ¨Åcations of our method. 2.1 The neural network structure We use a fully connected feedforward neural network (FNN) to model the regression function f. Withdenoting parameters of this FNN, we can write f=f. Next, we use a normalizing Ô¨Çow (Tabak and Turner, 2013) to represent the prior distribution pX. A normalizing Ô¨Çow is a sequence of transformations g1;g2;:::;gm, where each gjis an invertible mapping fromRdtoRd. LetV2Rdbe a random vector whose density has a simple analytic form (e.g., VN (0;Id)). We model the density of Xby assuming X=g"
38,Incremental Satisfiability Modulo Theory for Verification of Deep Neural Networks.txt,"Constraint solving is an elementary way for verification of deep neural
networks (DNN). In the domain of AI safety, a DNN might be modified in its
structure and parameters for its repair or attack. For such situations, we
propose the incremental DNN verification problem, which asks whether a safety
property still holds after the DNN is modified. To solve the problem, we
present an incremental satisfiability modulo theory (SMT) algorithm based on
the Reluplex framework. We simulate the most important features of the
configurations that infers the verification result of the searching branches in
the old solving procedure (with respect to the original network), and
heuristically check whether the proofs are still valid for the modified DNN. We
implement our algorithm as an incremental solver called DeepInc, and
exerimental results show that DeepInc is more efficient in most cases. For the
cases that the property holds both before and after modification, the
acceleration can be faster by several orders of magnitude, showing that DeepInc
is outstanding in incrementally searching for counterexamples. Moreover, based
on the framework, we propose the multi-objective DNN repair problem and give an
algorithm based on our incremental SMT solving algorithm. Our repair method
preserves more potential safety properties on the repaired DNNs compared with
state-of-the-art.","Deep neural networks (DNN) have achieved exceptional performance in many Ô¨Åelds like computer vision, natural language processing, game playing [36], and malware detection. However, DNNs are vulnerable to adversarial samples [43], thus lack robust ness. Even for a welltrained DNN, a very small (and even imperceptible) perturbation on the input may fool the network. This raises the concerns on the safety and reliability of DNNs when we deploy them in safetycritical applications like selfdriving cars [46] and medical systems [35]. Formal veriÔ¨Åcation is a sound way to guarantee the robustness of DNNs. In this work, we focus on safety properties of DNNs, i.e. given an input set of a DNN, we determine whether the output of the DNN is in a given safety region. The wellknown local robustness of DNNs is also a safety property. Constraint solving is an elementary and classical way for DNN veriÔ¨Åcation. The behaviour of the DNN and the negation of the property are encoded as constraints in the form of equations or inequalities of thearXiv:2302.06455v1  [cs.AI]  10 Feb 20232 P. Yang, et al. involved realvalued variables and it is determined whether there exists an assignment for these variables such that the constraints hold. If so, the solver returns SAT, and the assignment we Ô¨Ånd corresponds to a counterexample which violates the property, or otherwise it returns UNSAT , and there does not exist an assignment that violates the property, so the property holds. In 2017, Katz et al. [18] and Ehlers [11] independently implemented Reluplex and Planet, two satisÔ¨Åability module theory (SMT) solvers to verify DNNs with the ReLU activation function on properties expressible with SMT constraints, respectively. Relu plex encodes the ReLU activation function as a ReLU pair, and conducts a local search through pivoting for a given set of assertions. Differently, Planet uses the classical lin ear SMT to overapproximate the constraints and heuristically invokes constraintdriven clause learning (CDCL) to cut branches in the search tree. In 2020, as an optimized ver sion of Reluplex, Marabou [19] showed a better experimental performance, although it still did not include a CDCL design. Except for SMT, a DNN veriÔ¨Åcation problem can also be encoded as a mixedinteger linear programming (MILP), a semideÔ¨Ånite pro gramming (SDP) or a linear programming (LP) problem. Abstract interpretation based methods like AI2[14] and DeepPoly [39] are frequently used for the initialization of constraint solving, since they can efÔ¨Åciently offer an overapproximation of the seman tics of the constraint solving problem. Incremental constraint solving is aimed to efÔ¨Åciently determine a satisÔ¨Åablity prob lem when the constraints vary only a little bit. The basic idea of constraint solving is that we refer to the old solving procedure for the original constraints, and consider whether the inferences in the old solving procedure can be inherited for the new constraints. Since the changes in the constraints are rather small, most inferences are preserved with a quick check, and only a small number of branches which involve the changed con straints need a second calculation. Incremental constraint solving has been widely used in formal methods, like incremental SAT solving in bounded model checking [10,41,34] and combinational equivalence checking [7], sensitivity analysis for linear program ming, etc. [31,54,13,4,48] In the domain of AI safety, DNNs are often subject to such incremental situations. Constraints in DNN veriÔ¨Åcation consist of the property and the behaviour of DNNs, so small changes in the weights or even the structure of a DNN result in an incremen tal situation for DNN veriÔ¨Åcation. The DNN repair problem, which aims to modify a DNN to Ô¨Åx its bad behaviors, usually results in a small change in its weights or even the structure. If we verify whether the repair is effective based on an old veriÔ¨Åcation procedure, then it is natural to consider incremental constraint solving. Another appli cation that may involve incremental constraint solving is the counterexampleguided abstraction reÔ¨Ånement (CEGAR) framework of DNN veriÔ¨Åcation, where we start with an abstraction of the DNN, and iteratively reÔ¨Åne it if the veriÔ¨Åcation returns a spu rious counterexample. An reÔ¨Ånement of the current DNN results in small changes in the structure and weights, and we naturally consider an incremental constraint solving for the veriÔ¨Åcation of the reÔ¨Åned DNN. Other incremental situations for DNNs include adversarial training, backdoor attack, etc. In this paper, we investigate algorithms for the incremental constraint solving prob lem for DNN veriÔ¨Åcation. Different from traditional incremental SAT solving or sensiIncremental SatisÔ¨Åability Modulo Theory for VeriÔ¨Åcation of Deep Neural Networks 3 tivity analysis for linear programming, the changes of an incremental DNN veriÔ¨Åcation problem are often quantitatively (in the weights), but not qualitatively. That is, the num ber of changed constraints might be large, and even all the constraints may be affected within an small perturbation, but the sum of the absolute values of the weight changes is limited. Thus, the incremental veriÔ¨Åcation problem for DNN is substantially differ ent to the classical one. Particularly, this brings us difÔ¨Åculties in borrowing techniques from classical incremental SAT solving technique like reusing clauses and incremental solving with assumptions is not suitable for our setting. Based on the Reluplex framework, we propose the problem of incremental SMT solving for DNN veriÔ¨Åcation. We consider the incremental situation that the DNN is only modiÔ¨Åed on its weights with its structure unchanged. In this situation, there is a natural onetoone correspondence between the neurons of the original DNN and the modiÔ¨Åed one, and we can simulate the conÔ¨Ågurations that immediately infer the solv ing result in their branches in the modiÔ¨Åed DNN. In the simulation, we extract the most important features of these conÔ¨Ågurations, including the assertions of the branch, the set of basic variables, and the location of the linear equation that immediately infer an UNSAT result. By calculation on the conjunction of the assertions and the semantics of the modiÔ¨Åed DNN, we can easily reach the desired node in the search tree to simulate the assertions. Via a Gauss elimination, the tableau of linear equations can be trans formed to the form with the same set of basic variables. The key linear equation that infers UNSAT can be located with the basic variable appearing in it. We notice that the key to successfully checking the old UNSAT proofs for the modiÔ¨Åed DNN is to tighten the numerical bounds of the variables in the key linear equation. Here we invoke linear programming in a standard way of encoding uncertain ReLU relations with a linear ap proximation [11]. For the branch where a counterexample was found in the old solving procedure, we design some heuristic methods to search the corresponding branch and the branches near it for a counterexample of the modiÔ¨Åed DNN. DNN repair is an incremental situation closely related to what we consider in incre mental SMT solving. Based on our incremental techniques, we Ô¨Ånd that our incremental SMT solving is quite beneÔ¨Åcial for DNN repair on safety properties, especially when we want to Ô¨Åx the violated properties and maintain a potential large set of properties at the same time ‚Äì which we refer to as the multiobjective DNN repair problem. Based on the repair method ART [23], we add a restriction on the weight change rate in the repair so that most safety properties are highly likely to still hold. Our incremental SMT solving works for checking whether the violating property is successfully Ô¨Åxed in this algorithm. The main contributions of this work are as follows: ‚ÄìWe propose the problem of incremental constraint solving for DNN veriÔ¨Åcation, and give an incremental SMT algorithm based on the Reluplex framework. ‚ÄìWe implement our algorithm as an incremental SMT solver DeepInc for DNN ver iÔ¨Åcation based on the SMTbased veriÔ¨Åer Marabou. The experimental results show that our incremental constraint solving is more efÔ¨Åcient in most cases when the modiÔ¨Åcation to the DNNs is not large. Also, we analyse in detail the cases that incremental solving is less efÔ¨Åcient, and all these cases show evidence that the4 P. Yang, et al. x1 x2x3 x4x5 x6ybias"
36,Understanding Neural Networks with Logarithm Determinant Entropy Estimator.txt,"Understanding the informative behaviour of deep neural networks is challenged
by misused estimators and the complexity of network structure, which leads to
inconsistent observations and diversified interpretation. Here we propose the
LogDet estimator -- a reliable matrix-based entropy estimator that approximates
Shannon differential entropy. We construct informative measurements based on
LogDet estimator, verify our method with comparable experiments and utilize it
to analyse neural network behaviour. Our results demonstrate the LogDet
estimator overcomes the drawbacks that emerge from highly diverse and
degenerated distribution thus is reliable to estimate entropy in neural
networks. The Network analysis results also find a functional distinction
between shallow and deeper layers, which can help understand the compression
phenomenon in the Information bottleneck theory of neural networks.","USING Information Bottleneck theory (IB) [1][2] to ana lyze neural network‚Äôs behaviour has been found applica ble in various domain. According to IB Theory, the learning process can be characterized as Ô¨Ånding an optimal repre sentation that captures most target information, while having the least dependency on the original signal. However, recent analytical research of neural network‚Äôs informative behaviour achieves highly diversiÔ¨Åed results, where both works that ap prove and oppose are reported, hardly reaching a certain con sensus. Criticisms state that current information estimators are vulnerable to different model and saturate in high dimension feature space[3][4][5], some are accused fallacious measure the sample geometry, rather than informative behaviour[6][7]. These debates and accuses discredit analytic results and attach importance to revisit informative estimators. Facing the chal lenge, this work provides a reliable matrixbased Logarithm Determinant (LogDet) entropy estimator. Rather than counting numbers of resembling samples, it recognizes featurewise dependency and is derived directly from Shannon differential entropy. Our experiments reveal LogDet estimator is robust to noise and random perturbation in any dimension of feature space. Information Bottleneck Theory (IB), as an extension of min imal sufÔ¨Åcient statistics and rate distortion theory [1], describe the learning process as extracting minimal representation T from inputX, where it contains the most relevant information Manuscript received ; revised ** **, . Corresponding author: Ding Liu (email: liuding@tiangong.edu.cn).of targetY. Thus, the objective of IB is described with mutual information as: minI(X;T)"
280,Adversarial Learning of Robust and Safe Controllers for Cyber-Physical Systems.txt,"We introduce a novel learning-based approach to synthesize safe and robust
controllers for autonomous Cyber-Physical Systems and, at the same time, to
generate challenging tests. This procedure combines formal methods for model
verification with Generative Adversarial Networks. The method learns two Neural
Networks: the first one aims at generating troubling scenarios for the
controller, while the second one aims at enforcing the safety constraints. We
test the proposed method on a variety of case studies.","Controlling CyberPhysical Systems (CPS) is a well established problem in classic control theory [Howes et al., 2018]. State of the art solutions apply to all those models in which a complete knowledge of the system is available, i.e., scenarios in which the environment is supposed to follow deterministic rules. For such models a high level of predictability, along with good robustness, is achieved. However, as soon as these unpredictable scenarios come into play, traditional controllers are challenged and could fail. Ongoing research is trying to guarantee more  exibil ity and resilience in this context by using Deep Learning [Mnih, 2015] and, in particular, Reinforcement Learning for robust control. State of the art solutions perform rea sonably well, but they still present evident limits in case of unexpected situations. The so called open world scenarios are dicult to model and to control, due to the signicant amount of stochastic variables that are needed in their modelling and to the variety of uncertain scenarios that they present. Therefore, while trying to ensure safety and robustness, we need to be cautious about not trading them with model eectiveness. In this work we investigate autonomous learning of safe and robust controllers in open world scenarios. Our ap proach consists in training two neural networks, inspired by Generative Adversarial Networks (GAN) [Goodfellow et al., 2014], that have opposite goals: the attacker net work tries to generate troubling scenarios for the defender , which in turn tries to learn how to face them without violating some safety constraints. The outcome of this training procedure is twofold: on the one hand we get a ?This work has been partially supported by the PRIN project \SEDUCE"" n. 2017TWRCNB.robust controller, whereas on the other hand we get a generator of adverse tests.1 The learned controller is a blackbox device capable of dealing with adverse or unobserved scenarios, though without any worstcase guarantee. In this regard, one could complement our method with a shieldbased approach, as proposed e.g. by Avni et al. [2019]. 2. PROBLEM STATEMENT AND RELATED WORK Safety of a system can be formalised as the satisfaction of a set of safety requirements. A popular approach to mathematically express such safety requirements is Signal Temporal Logic (STL) [Donz e and Maler, 2010]. Temporal logic is used in the context of formal verication to express the desired behaviour of a system in terms of time. It ex tends propositional logic with a set of modal operators cap turing the temporal relation among events [Goranko and Rumberg, 2020]. STL formulas, in particular, deal with properties of continuoustime realvalued signals, such as CPS trajectories. In our application, we express safety requirements only by means of timebounded formulas over xedlength trajectories. In particular, we rely on STL quantitative semantics , which is capable of capturing, for each trajectory, the level of satisfaction of the desired property by measuring how much the input trajectory can be shifted without changing its truth value. Such measure is often referred to as robustness and it is exploited in this work as the objective function of an optimization problem. We model the interaction of an agent with an adversarial environment as a zerosum game , similarly to the strategy behind GANs. The concept of zerosum game is borrowed from game theory and denotes those situations in which one player's gain is equivalent to another's loss. In such 1Code is available at: https://github.com/ginevracoal/ adversarialGAN/arXiv:2009.02019v2  [eess.SY]  26 Mar 2021situations, the best strategy for each player is to minimize its loss, while assuming that the opponent is playing at its best. This concept is known in literature as minmax strategy . In practice, we use GAN architectural and the oretical design to reach two main objectives: a controller, that safely acts under adverse conditions, and an attacker, which gains insights about troubling scenarios for the opponent. The concept is closely related to that of Robust Adversarial Reinforcement Learning (RARL) [Pinto et al., 2017], a Reinforcement Learning framework, involving an agent and a destabilizing opponent, that is robust to ad verse environmental disturbances. In this case the term \robustness"" does not refer to Signal Temporal Logic, but instead, to the cumulative reward computed on the learned policy with respect to the varying test conditions. Other recent RL techniques involving STL constraints include Balakrishnan and Deshmukh [2019], Bozkurt et al. [2020], Liu et al. [2021] 3. METHODOLOGY "
491,DNN Speaker Tracking with Embeddings.txt,"In multi-speaker applications is common to have pre-computed models from
enrolled speakers. Using these models to identify the instances in which these
speakers intervene in a recording is the task of speaker tracking. In this
paper, we propose a novel embedding-based speaker tracking method.
Specifically, our design is based on a convolutional neural network that mimics
a typical speaker verification PLDA (probabilistic linear discriminant
analysis) classifier and finds the regions uttered by the target speakers in an
online fashion. The system was studied from two different perspectives:
diarization and tracking; results on both show a significant improvement over
the PLDA baseline under the same experimental conditions. Two standard public
datasets, CALLHOME and DIHARD II single channel, were modified to create
two-speaker subsets with overlapping and non-overlapping regions. We evaluate
the robustness of our supervised approach with models generated from different
segment lengths. A relative improvement of 17% in DER for DIHARD II single
channel shows promising performance. Furthermore, to make the baseline system
similar to speaker tracking, non-target speakers were added to the recordings.
Even in these adverse conditions, our approach is robust enough to outperform
the PLDA baseline.","Speaker tracking is the process of identifying all regions uttered by a target speaker in an audio [1]. Similarly to speaker diariza tion, which answers the question ‚Äùwho spoke when?‚Äù , speaker tracking searches for those regions, but assigns speaker identi ties. This process is an important preprocessing step for many multispeaker applications such as virtual assistants and broad cast news transcription and indexing [2]. As shown in [3], diarization and tracking are two methods closely related. Although tracking would beneÔ¨Åt from the di arization, in this research, we explored the possibility to include a neural network as a robust classiÔ¨Åer that can operate similarly to the PLDA. The goal is that it can naturally provide results for diarization and tracking. Since there are just a few studies on speaker tracking [1, 2, 4], we use diarization as the main background and inspiration of this work. Most of the standard speaker diarization systems focus on ofÔ¨Çine clustering as it uses all the contextual information to label the speech regions. Examples of such algorithms in clude agglomerative hierarchical clustering (AHC) [5, 6], k means [7, 8], spectral clustering [9, 10], etc. These clustering methods cannot be used in realtime applications since they re quire the complete speech data upfront. If the application is latencysensitive it requires to have speaker labels generated as Figure 1: Pipeline of proposed speaker tracking system. soon as speech segments are available for the system. [11] presents an embedding based speaker diarization sys tem. dvectors were used [12] along with an LSTMbased speaker veriÔ¨Åcation in combination with spectral clustering to successfully perform ofÔ¨Çine diarization; however, the diariza tion error rate almost doubles in its online modality. Another online diarization approach is introduced in [13]. They pro pose a DNN (deep neural network) embedding suitable for on line processing referred as speakercorrupted embedding. The diarization algorithm uses cosine similarity to compare the speaker models and the embedding in order to make the labeling decisions. In this paper, we propose an online speaker tracking pipeline by replacing the unsupervised ofÔ¨Çine clustering mod ule from the standard diarization system with a online track ing method that uses a DNN as an embedding robust clas siÔ¨Åer. As shown in Figure 1, our speaker tracking system shares many of its components with the standard diarization pipeline [14, 15, 16], with the main difference being the clus tering algorithm. The experimental results on CALLHOME and DIHARD II single channel reveal that our method achieves signiÔ¨Åcant im provements over the PLDA baseline.1 2. Methodology "
469,A Unified Approach to Kinship Verification.txt,"In this work, we propose a deep learning-based approach for kin verification
using a unified multi-task learning scheme where all kinship classes are
jointly learned. This allows us to better utilize small training sets that are
typical of kin verification. We introduce a novel approach for fusing the
embeddings of kin images, to avoid overfitting, which is a common issue in
training such networks. An adaptive sampling scheme is derived for the training
set images to resolve the inherent imbalance in kin verification datasets. A
thorough ablation study exemplifies the effectivity of our approach, which is
experimentally shown to outperform contemporary state-of-the-art kin
verification results when applied to the Families In the Wild, FG2018, and
FG2020 datasets.","The goal of kin veriÔ¨Åcation [1], [2], [3], [4] is to verify whether or not two people are related by a particular kin relationship given their face images. The kinship classes are depicted in Fig. 1, where given a pair of face images fi;'igand a kinship class i2 =fBB, FS, MD, SS, FD, MS, SIBS g, we aim to verify whether iand 'iare related by i. In contrast to face recognition, kin faces are nonidentical, and their visual similarity is often unintuitive, even for human observers, as kins might differ by gender and notable age differences. The facial similarity of kins varies signiÔ¨Åcantly between different families and even within the kins of a particular family, implying sig niÔ¨Åcant intraclass variability. As face recognition schemes aim to identify individual subjects, kins will be identiÔ¨Åed as different individuals. Following the common approach in face recognition, classical kin veriÔ¨Åcation schemes encoded the input facesfi;'igusing handcrafted featuresn bi;b'io [5], [6], [7] such as LBP , HOG, and Gabor. The representation was reÔ¨Åned using metriclearning [8], [9], [10], and the kin ship was classiÔ¨Åed by applying KNN and SVM classiÔ¨Åers. With the emergence of deep learning, it was applied to kin veriÔ¨Åcation. Facial features were derived by training face recognition CNNs on largescale face recognition datasets [11] and using transfer learning to apply them to kin ver iÔ¨Åcation [11]. Recent results by Wang et al. [12] applied a Generative Adversarial Net (GAN) to mitigate the age differences by synthesizing face images depicting interme diate ages. Smallscale datasets were initially utilized in kin E. Dahan & Y. Keller are with the Faculty of Engineering, BarIlan University, Email:yosi.keller@gmail.com SIBS BB SSMSFS MD 1Fig. 1. The kinship veriÔ¨Åcation task is to determine whether two face images are related by a particular kinship class, such as Brothers (B B), Sisters (SS), FatherDaughter (FD), FatherSon (FS), MotherSon (MS), MotherDaughter (MD), and Siblings (SIBS). veriÔ¨Åcation [5], [13], [14], most of which were shown [15], [16] to be biased, as the faces of kins were often cropped from the same photo, implying that the kinship could be inferred from the similar chromatic properties of the photo crops. The largescale RFIW dataset [17] was the only one shown to be unbiased, consisting of kin pairs cropped from different photos. The novel FIW in Multimedia (FIWMM) database, recently introduced by Robinson et al. [18], is a largescale multimodal kin veriÔ¨Åcation dataset, consisting of of video, audio, and contextual transcripts In this work, we propose a deep learningbased ap proach for kin veriÔ¨Åcation using a siamese CNN. We apply multitask learning to train a single uniÔ¨Åed CNN for allkin ship classes, allowing to leverage their training samples to reÔ¨Åne the face embedding backbone CNN. We show that kin veriÔ¨Åcation, in contrast to face recognition, is prone to over Ô¨Åtting and derive a novel CNN architecture for the fusion of face embeddings based on transposed 11convolutions. We also show that kin veriÔ¨Åcation datasets are inherently imbalanced in terms of the number of samples per family, and samples per kin (father, mother, etc.), implying that the training process might be biased. For that, we propose an adaptive sampling scheme for the training set, which is shown to improve the kin veriÔ¨Åcation accuracy. Some kin veriÔ¨Åcation classes, such as BB and DD, are symmetrical, allowing to utilize siamese CNNs. In contrast, other kinship classes, such as FD, FS, etc., are asymmetric in terms of age and gender, requiring different CNNs for each class. For that, we applied an asymmetric weighting layer that improves accuracy.arXiv:2009.05871v1  [cs.CV]  12 Sep 20202 In particular, we propose the following contributions: (1) We present a uniÔ¨Åed approach for kin veriÔ¨Åcation that applies multitask learning to jointly utilize the training sets of all kinship classes. (2) We show that kin veriÔ¨Åcation is prone to overÔ¨Åtting and suggest a novel subnetwork for the fusion of feature maps based on cascaded 11convolutions. (3) To overcome the imbalanced training set, we introduce an adaptive approach for sampling the training pairs, that is shown to improve the kin veriÔ¨Åcation accuracy. (4) The proposed scheme is experimentally shown to outperform contemporary stateoftheart approaches, when applied to the RFIW [17], FG2018, and FG2020 [19] datasets. 2 R ELATED WORK "
380,A model-based framework for learning transparent swarm behaviors.txt,"This paper proposes a model-based framework to automatically and efficiently
design understandable and verifiable behaviors for swarms of robots. The
framework is based on the automatic extraction of two distinct models: 1) a
neural network model trained to estimate the relationship between the robots'
sensor readings and the global performance of the swarm, and 2) a probabilistic
state transition model that explicitly models the local state transitions
(i.e., transitions in observations from the perspective of a single robot in
the swarm) given a policy. The models can be trained from a data set of
simulated runs featuring random policies. The first model is used to
automatically extract a set of local states that are expected to maximize the
global performance. These local states are referred to as desired local states.
The second model is used to optimize a stochastic policy so as to increase the
probability that the robots in the swarm observe one of the desired local
states. Following these steps, the framework proposed in this paper can
efficiently lead to effective controllers. This is tested on four case studies,
featuring aggregation and foraging tasks. Importantly, thanks to the models,
the framework allows us to understand and inspect a swarm's behavior. To this
end, we propose verification checks to identify some potential issues that may
prevent the swarm from achieving the desired global objective. In addition, we
explore how the framework can be used in combination with a ""standard""
evolutionary robotics strategy (i.e., where performance is measured via
simulation), or with online learning.","The goal of swarm robotics is to design behaviors that enable several relatively simple robots to collab orate toward a common objective. The complexity of this paradigm stems from the fact that each robot can only sense and act according to local information, yet the goals are only observable at the global level. The complexity of swarming makes the manual design of successful controllers diÔ¨Écult. Machine learning approaches, however, oÔ¨Äer an attractive way to do so automatically. State of the art techniques in the Ô¨Åeld primarily adopt evolutionary algorithms that optimize a policy with respect to a centrally measured objective (Brambilla et al., 2013; Francesca and Birattari, 2016). Other learning methods, such as reinforcement learning, have received less attention. This is because of issues such as low sample eÔ¨É ciency or credit assignment problems, whereby it is not clear how to relate a swarm‚Äôs global performance with the local states and actions of its individual robots. Alternatively, with evolutionary strategies, the global performance of a population of controllers is assessed across multiple generations in order to Ô¨Ånd a suitable candidate. The approach has been used to optimize multiple controller architectures, including neural networks (Duarte et al., 2016) and behavior trees (Jones et al., 2018, 2019). Neural network controllers can approximate complex functions eÔ¨Éciently. However, their ‚Äúblack box‚Äù architec ture can be a disadvantage in this context, particularly for safetycritical control. They are diÔ¨Écult to interpret and understand without resorting to experimentation on the swarm. Behavior trees and other explicit controllers are more transparent. Behavior trees, in particular, feature an attractive mixture of expressiveness and understandability (Colledanchise and √ñgren, 2017). They are humanreadable and can be understood, inspected, and even Ô¨Ånetuned. In prior research on single robots, this has also given the ability to modify a behavior by hand to better transfer from simulation to the real world (Scheper et al., 2016). Nevertheless, understanding a behavior tree within the context of a swarm of robots also requires careful qualitative and experimental analysis (Jones et al., 2019). This is because the local state transitions experienced by a robot are not modeled. The local objectives of the robots, and how these correlate with the global performance, are also not explicitly known. This paper proposes a novel modelbased framework in order to automatically design the behavior of a swarm of robots. The framework makes use of two separate models: 1) a neural network model that maps the local states of the robots in the swarm to the global performance value, and 2) a probabilistic transition model that describes the local transitions as experienced by a single robot in the swarm. Both models are trained automatically from a data set of random behaviors. The Ô¨Årst model is used to extract the local states that contribute to maximizing the swarm‚Äôs global performance. We refer to these local states as desiredlocal states. These are extracted automatically, reducing a global goal to locally observable constituents. Then, the second model is used to determine a policy that maximizes the probability that a robot in the swarm transitions to any one of the desired local states. The transition model enables us to examine the behavior of the swarm, given a policy. A set of conditions is proposed in order to identify, based on the models, potential issues that could prevent the swarm from achieving a collective goal. Overall, the proposed framework has two main advantages: 1) the extraction of understandableandveriÔ¨Åablecontrollers, and2)increasedevaluationandoptimizationeÔ¨Éciencythrough the models. The framework can also be combined with a standard evolutionary algorithm (i.e., one which uses simulations to measure the swarm‚Äôs performance) for increased eÔ¨Éciency. It can also be used online, such that each robot in the swarm locally optimizes its behavior according to a model of its experiences that it generates onboard. Implementations of the framework in both of these contexts are also provided in this paper. Thispaperisstructuredasfollows. InSect.2, weplaceourcontributioninthecontextofrecentswarm robotics and machine learning research. In Sect. 3, the modelbased framework is explained. In Sect. 4, its performance is analyzed via four case studies, involving aggregation and foraging. It is also shown how the proposed modelbased framework can be used in: 1) a hybrid modelbased evolutionary algorithm, and 2) a modelbased online learning approach. Sect. 5 discusses the advantages and limitations of the framework, highlighting potential future extensions and research. Sect. 6 provides concluding remarks. 2 Related work and research context "
339,Audio Spoofing Verification using Deep Convolutional Neural Networks by Transfer Learning.txt,"Automatic Speaker Verification systems are gaining popularity these days;
spoofing attacks are of prime concern as they make these systems vulnerable.
Some spoofing attacks like Replay attacks are easier to implement but are very
hard to detect thus creating the need for suitable countermeasures. In this
paper, we propose a speech classifier based on deep-convolutional neural
network to detect spoofing attacks. Our proposed methodology uses acoustic
time-frequency representation of power spectral densities on Mel frequency
scale (Mel-spectrogram), via deep residual learning (an adaptation of ResNet-34
architecture). Using a single model system, we have achieved an equal error
rate (EER) of 0.9056% on the development and 5.32% on the evaluation dataset of
logical access scenario and an equal error rate (EER) of 5.87% on the
development and 5.74% on the evaluation dataset of physical access scenario of
ASVspoof 2019.","Biometrics technologies play a critical role in regulating access to informational resources in today's world. One of the reliable approaches for attaining a suitable secure system is speaker ver iÔ¨Åcation. Automatic speaker veriÔ¨Åcation (ASV) has undergone rapid improvements in the recent decade but continues to show high vulnerability towards different spooÔ¨Ång attacks. SpooÔ¨Ång methods are categorized as speech synthesis (SS), voice conver sion (VC), impersonation and replay attacks [1]. Among these, replay attacks are arguably the most simple yet highly indistin guishable ASV spooÔ¨Ång technique as they do not require the at tackers to have any specialized knowledge, and can be mounted with relative ease using consumer devices. For the Ô¨Årst automatic speaker veriÔ¨Åcation spooÔ¨Ång and countermeasures challenge (ASVspoof 2015 [2]) even though the best results showed an overall average detection EER of less than 1.5%, the EER of unknown attacks is Ô¨Åve times higher than that of known attacks. In addition, while some attacks were eas ily and consistently detected, others provoked extremely high error rates nearing 50%. Systems submitted under ASVspoof 2017 [3] challenge in spected distinct frontend features and the usage of various classiÔ¨Åers to detect replay attack under conditions. Among them, the bestperforming system [4], had an equal error rate (EER) of 6.73% and used a light convolutional neural network (LCNN) to extract highlevel features from the log power spec trum, together with a Gaussian Mixture Model (GMM) as clas siÔ¨Åer. Variable length Teager energy operatorenergy separation algorithminstantaneous frequency cosine coefÔ¨Åcients (VESA IFCCs) [5] were proposed as a single system with the aim ofcapturing the spectral changes due to the transmission and chan nel characteristic of replay devices. A single frequency Ô¨Åltering feature with a high spectrotemporal resolution was proposed [6] to capture the channel information embedded in the low sig nal to noise ratio region. ASVspoof 2019 [7] Challenge was organized to empha size the development of reliable countermeasures that could efÔ¨Åciently segregate bona Ô¨Åde and spoofed speech. The ini tiative aims speciÔ¨Åcally to encourage the design of general ized countermeasures, i.e. countermeasures that would per form well when encountered with spooÔ¨Ång attacks which are unpredictable in nature. The data used for ASVspoof 2015 [2] contained spoofed speech samples generated using textto speech (TTS) and voice conversion (VC) systems at that time. The ASVspoof 2017 [3] challenge emphasized on the design of countermeasures strived at detecting replay spooÔ¨Ång attacks that could be implemented easily by anyone using conventional devices. The ASVspoof 2019 [7] edition was the Ô¨Årst to focus on countermeasures for all three major spooÔ¨Ång attack types, namely those originating from TTS, VC and replay attacks. ASVspoof 2019 [7] focuses to develop nextgeneration counter measures for the automatic detection of spoofed or fake audio. The challenge encloses two separate subchallenges in logical and physical access control and provides a common database of the most advanced spooÔ¨Ång attacks to date. The aim was to study the extremities of spooÔ¨Ång countermeasures with respect to automatic speaker veriÔ¨Åcation and spoofed audio detection. In this paper, we propose the use of Melspectrograms [8] which is obtained from the audio frames as a timefrequency representation of power spectral density, for the training of deepconvolutional neural networks for audio spooÔ¨Ång attack detection. The use of Melspectrograms provides a time frequency representation with sufÔ¨Åcient spectral resolution, which is required for robust replay attack detection. Our frame work is based on adapting the ResNet34 architecture [9]. 2. Methodology "
157,GaitPrivacyON: Privacy-Preserving Mobile Gait Biometrics using Unsupervised Learning.txt,"Numerous studies in the literature have already shown the potential of
biometrics on mobile devices for authentication purposes. However, it has been
shown that, the learning processes associated to biometric systems might expose
sensitive personal information about the subjects. This study proposes
GaitPrivacyON, a novel mobile gait biometrics verification approach that
provides accurate authentication results while preserving the sensitive
information of the subject. It comprises two modules: i) a convolutional
Autoencoder that transforms attributes of the biometric raw data, such as the
gender or the activity being performed, into a new privacy-preserving
representation; and ii) a mobile gait verification system based on the
combination of Convolutional Neural Networks (CNNs) and Recurrent Neural
Networks (RNNs) with a Siamese architecture. The main advantage of
GaitPrivacyON is that the first module (convolutional Autoencoder) is trained
in an unsupervised way, without specifying the sensitive attributes of the
subject to protect. The experimental results achieved using two popular
databases (MotionSense and MobiAct) suggest the potential of GaitPrivacyON to
significantly improve the privacy of the subject while keeping user
authentication results higher than 99% Area Under the Curve (AUC). To the best
of our knowledge, this is the first mobile gait verification approach that
considers privacy-preserving methods trained in an unsupervised way.","The use of biometrics on mobile devices is currently one of the most popular authentication approaches [1; 2]. In particular, behavioural biometrics, which are based on the way subjects perform actions such as writing [3] and walking [4], allow the recognition in a passive way through smart devices, for exam ple, using the accelerometer and gyroscope data [5; 6]. Despite the popularity of mobile behavioural biometrics, the data acquired can contain a large amount of personal and sen sitive information such as demographics (e.g., gender, age, eth Corresponding author. email: p.delgadodesantos@kent.ac.uk (Paula DelgadoSantos), ruben.tolosana@uam.es (Ruben Tolosana), r.m.guest@kent.ac.uk (Richard Guest), ruben.vera@uam.es (Ruben VeraRodriguez), f.deravi@kent.ac.uk (Farzin Deravi), aythami.morales@uam.es (Aythami Morales)nicity, etc.) or the activity the subject is performing (e.g., walk ing, sitting, etc.) [7]. As a result, this technology might be considered as an invasion of personal privacy. Privacy is a concept that has been deÔ¨Åned in numerous ways [8], one example of which is the recent General Data Protection Regulation (GDPR) of the European Union [9]. This deÔ¨Ånes personal data as ‚Äúany information relating to an identiÔ¨Åed or identiÔ¨Åable natural person‚Äù. Within this set of data, there is a subgroup called sensitive data which includes ‚Äúracial or ethnic origin, political opinions, religious or philosophical beliefs, trade union membership, genetic data, biometric data for the purpose of uniquely identifying a natural person, health data or data concerning the individual‚Äôs sex life or sexual orientation‚Äù. The automatic processing of such data without the explicit consent of the subject for any speciÔ¨Åc purpose is prohibited.arXiv:2110.03967v2  [cs.CV]  19 Jul 20222 Enrolled Sample Gait  Verification  SystemGaitPrivacyON ‡∑†ùëãùëí ‡∑†ùëãùë° ùëãùëí ùëãùë° Test SampleAccess  Granted Access  Denied Time Signals Extraction (accelerometer and gyroscope sensors) Time6 Time Signals 6 Time Signals ‚Ä¶ ‚Ä¶ Autoencoder  (Privacy Preserving Representation) Autoencoder  (Privacy Preserving Representation)Shared weights Fig. 1: Diagram of GaitPrivacyON, which comprises two modules: i)two Autoencoders that are in charge of removing automatically the sensitive data; and ii)a gait veriÔ¨Åcation system. Time signals extracted from the accelerometer and gyroscope sensors of the mobile devices are considered as input to GaitPrivacyON. Xe: Enrolled sample, Xt: Test sample, bXe: Transformed enrolled sample, bXt: Transformed test sample. The main contributions of this study are: ¬àA novel mobile gait biometrics veriÔ¨Åcation approach, GaitPrivacyON, that provides accurate authentication re sults while preserving the privacy of the subject. Fig. 1 represents the general diagram of our proposed approach. It comprises two modules: i)two convolutional Autoen coders with shared weights that transform the biomet ric raw data into a new privacypreserving representa tion (e.g., gender or activity), and ii)a mobile gait veri Ô¨Åcation system based on a combination of Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs) with a Siamese architecture. ¬àAn indepth quantitative analysis of GaitPrivacyON over three popular databases in the Ô¨Åeld of gait recognition, MotionSense [10], MobiAct [11], and OUISIR [12], achieving accurate veriÔ¨Åcation results (higher than 96.6% Area Under the Curve, AUC) while reducing the recogni tion rate of sensitive data to 50% AUC. ¬àTo the best of our knowledge, this is the Ô¨Årst mobile gait veriÔ¨Åcation approach that considers privacypreserving methods trained in an unsupervised way. The remainder of the paper is organised as follows. Sec. 2 summarises previous studies in the Ô¨Åeld. Sec. 3 explains all details of our proposed GaitPrivacyON approach. Sec. 4 sum marises the databases considered. Sec. 5 and 6 describes the proposed experimental protocol and results, respectively. Fi nally, Sec. 7 draws the Ô¨Ånal conclusions. 2. Related Work "
521,CPMLHO:Hyperparameter Tuning via Cutting Plane and Mixed-Level Optimization.txt,"The hyperparameter optimization of neural network can be expressed as a
bilevel optimization problem. The bilevel optimization is used to automatically
update the hyperparameter, and the gradient of the hyperparameter is the
approximate gradient based on the best response function. Finding the best
response function is very time consuming. In this paper we propose CPMLHO, a
new hyperparameter optimization method using cutting plane method and
mixed-level objective function.The cutting plane is added to the inner layer to
constrain the space of the response function. To obtain more accurate
hypergradient,the mixed-level can flexibly adjust the loss function by using
the loss of the training set and the verification set. Compared to existing
methods, the experimental results show that our method can automatically update
the hyperparameters in the training process, and can find more superior
hyperparameters with higher accuracy and faster convergence.","Withtherapiddevelopmentofdeeplearning,itisessentialtoadjusthyperparametersinorderto achievetheoptimalperformanceinchallengingdatasetssuchasimagedatasets[6].Traditional hyperparameteroptimizationmethods,suchasgridsearch,randomsearch[2]andBayesian optimization[20],performwellinthelowdimensionalhyperparameterspaces,butthesemethodsneed tofixtheinitialvalueofthehyperparameter,requiremanytrainingrunsandalotofcomputing resources. Thegradientbasedbileveloptimizationmethodhasachievedexcellentperformancein hyperparameteroptimization[7],metalearning[19]andneuralnetworksearch[5].Formally,the hyperparametergradientbasedmethodcanbeexpressedasabileveloptimizationproblem[12]: argmin(,)valLÔÄ™ ÔÄ™ÔÄΩ ŒªŒª wŒª ..argmin(,)tr st LÔÄ™ÔÄΩ ww wŒª (1) . ,m nvarÔÉéÔÉé w ŒªÔÇ°ÔÇ° mÔÉéwÔÇ°representsnetworkweight,nÔÉéŒªÔÇ°determinesthehyperparameters,trLandvalLdenotethe losseswithrespecttotrainingdataandvalidationdatawithwandŒªrespectively. Atpresent,thehyperparameteroptimizationinbileveloptimizationismainlybasedonimplicit function[16],dynamicalsystem[18]andhypernetwork[13].Theimplicitdifferentiationmethodneeds tocalculatetheinverseHessian.Thedynamicalsystembasedmethodneedstheinverseorforward gradientcalculation.Thesetwomethodsarecomputationallyexpensive.Thehypernetworkmethodusesthebestresponsefunction()argmin(,)trLÔÄΩ wwŒª wŒªtojointlyupdatethehypernetworkandthe hyperparameters.Inordertofindthebestresponsefunctionintheinnerlayer,selftuning network(STN)[15]constructsahypernetworkforeachlayer.ÔÅÑSTN[1]usesthethebestresponse Jacobiantogettheoptimalsolution.Itisdifficulttofindthebestresponsefunctionforbilevel optimizationbasedonhypernetwork.Thetimecostisveryhigh,whichrequireshundredsoftraining epochs.Andthedeviationofthebestresponsefunctionwillleadtothedeviationoftheapproximate gradientandthetruegradientofthehyperparameter. Tosolvetheproblemthatthebestresponsefunctionisdifficulttofind,weintroducethecutting planemethodtoapproximatethefeasibleregionofanoptimizationproblem[22,23].Cuttingplane methodismainlyusedinsolvingintegerlinearprogramming[8,24]andconvexoptimization problems[14].Itcanalsobeusedtotacklenonconvexoptimizationproblems[17].Weusethecutting planemethodtolimitthesearchspaceoftheresponsefunctionandfindtheoptimalsolutionmore quickly.Inaddition,cuttingplanemethodalsofacilitatesdistributedimplementation[21]. Inaddition,thebileveloptimizationonlyusestheverificationsetlosstocalculatethe hyperparametergradienttoupdatethehyperparameter.Thisdoesnotutilizethepotentialrelationship betweenthetrainingsetandtheverificationset,andusestheapproximategradientbasedonthe approximationofw,causinggradienterror.Mixedlevelwasoriginallyusedinneuralnetwork architecturesearch[9].Weintroducemixedlevelobjectivefunctiontoflexiblyadjustthelossofthe trainingsetandtheverificationsetwhencalculatingthegradientofthehyperparameter. Inthiswork,weusethebileveloptimizationmethodbasedonthehypernetworktoupdatethe hyparameters.Thegradientoftheinnerlayeriscalculatedtoupdatethenetworkparametersand responsefunction,andthegradientoftheouterlayeriscalculatedtoupdatethehyperparameter.When searchingforthebestresponsefunctionintheinnerlayer,weusethecuttingplanemethodto constrainthesearchscopeoftheresponsefunctionuntilthebestresponsefunctionissearched.Finally, weusemixedlevelobjectivefunctiontoavoidthegradienterrorcausedbythelossofonlyusingthe verificationsetwhencalculatingthegradientofthehyperparameterintheouterlayer.Thegradientof thetrainingsetandtheverificationsetguaranteestheupdatingdirectionofthehyperparameter gradient,whichcanmakethehyperparametersmorestableandaccurate.Experimentsshowthat comparedwithexistingmethod,ourmethodcanfindmorestableandaccuratehyperparametersand achievesuperiorperformanceindifferentdatasets. 2.Relatedwork Colsonprovidestheideaofabilevelproblem[4].Snellusedbileveloptimizationprogramtooptimize metalearningtolearnthecommonparametersofalltasks[19].Cortesetal.describeneuralnetwork architecturesearchasabilevelproblem,andusebileveloptimizationtofindthebestneuralnetwork architecture[5].Usingbileveloptimizationtoadjusthyperparametersnotonlyusesrichgradient information,butalsomakesfulluseofnetworkstructureandexpandstheoptimizationofthenumber ofhyperparameters.Recently,avarietyofbileveloptimizationmethodsforhyperparameter optimizationhavebeenproposed,includingimplicitdifferentiationbasedmethod[16],dynamic systemsbasedmethod[18]andhypernetworkbasedmethod[13].Methodsbasedonimplicit differentiationanddynamicsystemsintroducealargecomputationaloverhead.Basedon hypernetwork,suchasselftuningnetwork(STN)[15],thebestresponsefunctionisusedtocalculate thehypergradientofthehyperparameterandautomaticallyupdatethehyperparameter.ÔÅÑSTN[1] improvessomeoftheshortcomingsofSTNbyusingastructuredresponsejacobians.The hypernetworkbasedmethodisverydependentonfindingthebestresponsefunction.Oncethe deviationoccurs,theapproximategradientoftheouterfunctiontothehyperparameterwillbewrong. Andthesearchforthebestresponsefunctionalsobringsalotoftimeoverhead. ThecuttingplanemethodismainlyusedinintegerlinearprogrammingsuchasGomory'scut[8], ChvatalGomorycut[3],impliedboundcut[11].Huangusedthecuttingplanemethodtosolvethe neuralnetworkverificationproblem[23].Cuttingplanemethodisaneffectiveconvexoptimizationmethod.Convexfunctionsaresubdifferentiableanywhereintheirdomain[10].Cuttingplanemethod cansolveallconvexproblems,includingthosewheretheunavailablegradientappliestoboth differentiableandnondifferentiable[14].Weusecuttingplanemethodtoconstrainthesearchspaceof theresponsefunction,soastofindthebestresponsefunction. 3.Method "
279,The use of Data Augmentation as a technique for improving neural network accuracy in detecting fake news about COVID-19.txt,"This paper aims to present how the application of Natural Language Processing
(NLP) and data augmentation techniques can improve the performance of a neural
network for better detection of fake news in the Portuguese language. Fake news
is one of the main controversies during the growth of the internet in the last
decade. Verifying what is fact and what is false has proven to be a difficult
task, while the dissemination of false news is much faster, which leads to the
need for the creation of tools that, automated, assist in the process of
verification of what is fact and what is false. In order to bring a solution,
an experiment was developed with neural network using news, real and fake,
which were never seen by artificial intelligence (AI). There was a significant
performance in the news classification after the application of the mentioned
techniques.","The COVID19 pandemic emerged within a context in which people are informed more by headlines on social media like Facebook than by the content of the newspaper article, opening up gaps for the phenomenon of fake news. The discovery of a new virus demands news dealing with the symptoms, severity, and forms of transmission. Furthermore, as everything is new and volatile, it is a fertile ground for the insertion of disinformation, especially in a scenario in which the habit of checking the veracity of information does not happen often. The production of fake news happens at a speed that is impossible to be checked by a small group of journalists, and these professionals must also cover the news coming from reliable sources. Given this context, the automation of this activity seems to be the only effective way to combat fake news through ArtiÔ¨Åcial Intelligence (AI). It is worth mentioning that the Ô¨Åght against fake news has a huge importance and responsibility of determining something as being false or true. Given that, there is the ability to innovate in producing new frauds. That‚Äôs why works like this and others mentioned in this article have a lot of relevance in this pandemic context. Several authors such as [ 1], [2] and [ 3] have already proposed algorithms, many using modern AI techniques such as Neural Processing Language (NLP) or multilayered Perceptron (MLP). Most of this work is related to contenders promoted on the Kaggle platform1. Some authors like [ 4] and [ 2] use the term infodemic to describe this phenomenon of fake news about the coronavirus. Some social networks, like Twitter and Facebook, have released tools to combat fake news. In the Facebook‚Äôs case, a series of authentications to ensure that the person responsible for the post is the real owner of the account [ 5] and Twitter‚Äôs Birdwatch2, a tool that allows the user to report posts as fake news. However, there are several reasons to 1Kaggle: an online community of data scientists and machine learning professionals subsidiary of Google. 2Source: https://tinyurl.com/ferramentamessengerarXiv:2205.00452v1  [cs.CL]  1 May 2022suspect the interest of these corporations in combating this practice since, when verifying the source, the user leaves the platform, in contrast with the business model of a social network that focus on engagement. 2 Background With the advance of the COVID19 pandemic, the discussion of whether access to internet is one of the fundamental rights for survival (as well as water, electricity, and basic sanitation) is no longer controversial and has become a consensus, given the fact that the dynamics of modern society demands that, for a citizen to be included, he must be connected. [ 6], talks about how the democratization of the internet is fundamental for the maintenance of the basic right to education provided in the Brazilian constitution of 1988. According to the Collins Dictionary, lockdown is the word of the year for 2020, considering that the dictionary recorded around 250 thousand uses against only 4 thousand the previous year [7]. For many years, the media‚Äôs credibility, so be it print, radio or television, was practically irrefutable. Today, with the democratization of access, and especially the production of information and content, new vehicles, websites, blogs , YouTube channels, and other platforms have also started to act as press [ 8]. [8] goes on to say that, even after the fake news is denied, it still inÔ¨Çuences the population, as it attacks not only the facts but also the credibility of important institutions such as press vehicles. In addition, social networks have a tremendous impact on the way people think and show themselves as a powerful weapon of manipulation, leading political groups to create fake news or spread halftruths in order to create or inÔ¨Çuence a movement. In 2020, some authors analyzed the impact and danger of fake news during the pandemic. Kalsnes cites in his work that the main reasons behind fake news include political, Ô¨Ånancial, and social issues [ 8]. [9] Shows how a series of fake news can be at the service of an ideology such as the privatization of the Brazilian UniÔ¨Åed Health System (Sistema √önico de Sa√∫de  SUS) since these false articles try to discredit an organ of such tradition and importance. Still, in his analysis [ 9], says that fake news in the Brazilian context about COVID19 is divided into Ô¨Åve categories. They are information related to health authorities, therapy, prevention measures, disease prognosis, and vaccination. These are the Ô¨Åve main points, and their primary vehicles are social networks, especially WhatsApp . The power of fake news has been extremely underestimated in the past. From the 2016 elections in the United States to the elections in Brazil in 2018 and now during the coronavirus pandemic, where President Bolsonaro accused press vehicles like Globo Television, and the Folha de SP newspaper in 2018 [ 10]. This behavior is similar to that of the President of the United States, Donald Trump, whom several times classiÔ¨Åed information coming from CNN and New York Times as fake news [8]. Efforts to combat fake news have proved quite challenging for traditional methods, as producing fake news takes less time and effort than debunking it. One of these efforts is Lupa, a project carried out by the Folha de S√£o Paulo newspaper, which is a FactChecking agency, the Ô¨Årst in Brazil [ 11]. However, it has been observed that there is a pattern in fake news created by the context of the pandemic, and through it, it‚Äôs possible to automate this validation. 3 Related Works "
24,Deep Face Quality Assessment.txt,"Face image quality is an important factor in facial recognition systems as
its verification and recognition accuracy is highly dependent on the quality of
image presented. Rejecting low quality images can significantly increase the
accuracy of any facial recognition system. In this project, a simple approach
is presented to train a deep convolutional neural network to perform end-to-end
face image quality assessment. The work is done in 2 stages : First, generation
of quality score label and secondly, training a deep convolutional neural
network in a supervised manner to predict quality score between 0 and 1. The
generation of quality labels is done by comparing the face image with a
template of best quality images and then evaluating the normalized score based
on the similarity.","Human face is a very dynamic biometric system as compared to other biometric systems such as Ô¨Ångerprint which is largely static. The performance of a facial recognition system highly depends upon the quality of the image that it acquires. The utility of a face image to a facial image recognition can be deÔ¨Åned by its image quality[ 2]. Low quality images tend to make any facial recognition to perform worse. The various factors that results in false recognition are variations in pose, illumination, occlusion, expression, age, lifestyle, etc.[ 14] Under controlled acquisition environment such as uniform lighting, frontal facial pose, neutral expression, high resolution image, etc. the facial recognition system can achieve very low False Acceptance Rate (FAR) in comparison to images taken in the wild[ 3,5]. Before processing the face image for veriÔ¨Åcation or recognition, we can do a qualitycheck assessment as a preprocessing step. Depending upon the score, the system may decide to reject low quality images and only process certain qualiÔ¨Åed images for veriÔ¨Åcation or recognition. A critical application for the assessment is Negative IdentiÔ¨Åcation Systems such as security checks at banks or airports where suspects try to provide low quality image to evade recognition[ 2]. In such cases, the system should Ô¨Çag such users and access should be provided only after providing perfect aligned facial image. The primary goal of this project is to develop an endtoend system for automatic facial quality assessment. Instead of using handengineered feature designed approach, a datadriven, transfer learning approach is implemented in this work. The overview of the approach is as follows. First, a database of quality score is generated as similarity score by comparing facial images with a gallery of images using Google‚Äôs FaceNet embeddings[ 7]. To predict the desired quality score, a pretrained FaceNet model with Inception v3 architecture and custom added layers is used which outputs value between 0 and 1. This model is trained using the generated quality labelled facial data in a supervised setting.arXiv:1811.04346v1  [cs.CV]  11 Nov 2018Figure 1: Inception v3 architecture 2 Previous work There are generally two ways that exists in literature to come up with a quality metric : one is FullReference based and the other is NoReference based. Based on the above classiÔ¨Åcation, there are mainly two approaches that is used by most people. First, using some facial textures and properties such as resolution, pose, illumination, etc., design handengineered features and functions to predict an absolute quality index[ 12]. Secondly, we can compare the image under consideration to a standard reference image and use some comparison technique to get our desired quality metric[ 8,11]. However, the effectiveness of these methods are limited by the applicability of artiÔ¨Åcially deÔ¨Åned facial properties and empirically selected reference image and may not generalize well to different databases or face images with multiple quality factors present. 3 Methodology "
35,A Stock Trading System for a Medium Volatile Asset using Multi Layer Perceptron.txt,"Stock market forecasting is a lucrative field of interest with promising
profits but not without its difficulties and for some people could be even
causes of failure. Financial markets by their nature are complex, non-linear
and chaotic, which implies that accurately predicting the prices of assets that
are part of it becomes very complicated. In this paper we propose a stock
trading system having as main core the feed-forward deep neural networks (DNN)
to predict the price for the next 30 days of open market, of the shares issued
by Abercrombie & Fitch Co. (ANF) in the stock market of the New York Stock
Exchange (NYSE).
  The system we have elaborated calculates the most effective technical
indicator, applying it to the predictions computed by the DNNs, for generating
trades. The results showed an increase in values such as Expectancy Ratio of
2.112% of profitable trades with Sharpe, Sortino, and Calmar Ratios of 2.194,
3.340, and 12.403 respectively. As a verification, we adopted a backtracking
simulation module in our system, which maps trades to actual test data
consisting of the last 30 days of open market on the ANF asset. Overall, the
results were promising bringing a total profit factor of 3.2% in just one month
from a very modest budget of $100. This was possible because the system reduced
the number of trades by choosing the most effective and efficient trades,
saving on commissions and slippage costs.","Stock market forecasting is considered a research Ô¨Åeld with promising returns for investors. However, there are considerable challenges to predicting stock market trends accurately and precisely enough due to their chaotic and nonlinear nature, and also complexity. At the state of the art, there are numerous approaches for generating, processing, and optimizing a dataset, such as (Letteri et al. [2020a]). Many artiÔ¨Åcial intelligence methods have been employed to classify cyber attacks (Letteri et al. [2018]), predict network trafÔ¨Åc anomalies (Letteri et al. [2019a]), course of a disease, and even the price trend in the stock market. ArtiÔ¨Åcial neural networks (ANNs) to date remain a fairly popular choice for these kinds of tasks and are widely studied (Letteri et al. [2019b]), having exhibited good performance (Yetis et al. [2014]). In particular, although deep neural networks (DNNs) are predominantly used for image recognition and natural language processing, showing surprising results (Soniya et al. [2015]), they have also been applied to Ô¨Ånancial markets for stock price prediction using textual news analysis (Day and Lee [2016]). In this paper, we propose a trading system for the stock market that uses forecasts by four Price Action (PA)based DNNs to generate trading signals, and subsequently evaluate their performance in the stock market. This constitutes part of a work that aims to convert the DNNs forecasts into a proÔ¨Åtable investment and trading system that can be automated, using a robot advisor. 2 Data Set This section describes the methodology with which the dataset is collected, the criteria adopted for the statistical analysis of the data collected, the training process and the series of tests conducted on the DNNs with optimized processes (Letteri et al. [2020b]). In the next section we will show the trading rules applied on the forecast output with the related tests on proÔ¨Åtability veriÔ¨Åed by our backtracking system. 2.1 Technical Analysis Technical analysis (TA) constitutes the type of investment analysis that uses simple mathematical formulations or graphical representations of the time series of Ô¨Ånancial assets to explore trading opportunities. In its algorithmic form, TA uses the analysis of asset price history series (Wang et al. [2021]), deÔ¨Åned as OHLC, i.e., the opening, highers, lowest and closing prices of an asset, typically represented with candlesticks charts (see, e.g. in Ô¨Åg. 1). For each timeframet, the OHLC of an asset is represented as a 4dimensional vector Xt= (x(o) t;x(h) t;x(l) t;x(c) t)T, where x(l) t>0,x(l) t<x(h) tandx(o) t;x(c) t2[x(l) t;x(h) t]. Figure 1: Example of candlestick chart. Some stocks are more volatile than others. For example the shares of a large bluechip company may not have large price Ô¨Çuctuations and are therefore said to have low volatility , whereas the shares of a tech stock may Ô¨Çuctuate often and therefore have high volatility . There are also stocks with medium volatility2, and this is the case of the asset that we studied in this article. 2https://www.fool.com/investing/howtoinvest/stocks/stockmarketvolatility/ 2arXiv Template A P REPRINT The dataset used in this work consists of historical OHLC prices data from the New York Stock Exchange (NYSE), the world‚Äôs largest stock exchange by trading volume and the second largest by number of listed companies. Its share volume was surpassed by NASDAQ in the 1990s, but the total capitalization of the 2800 companies on the NYSE is Ô¨Åve times that of the competing technology exchange. The asset on which we conducted our study is the shares issued by Abercrombie & Fitch Co. (ANF). From a summary of results for the third quarter ended October 30, 2021 compared to the third quarter ended October 31, 2020, ANF reported net sales of $905 million, up 10% yearoveryear and 5% compared to net sales in the third quarter preCOVID 2019. Digital net sales of $413 million increased 8% compared to last year and 55% compared to preCOVID 2019 third quarter digital net sales. Gross proÔ¨Åt rate of 63.7%, down approximately 30 basis points from last year and up approximately 360 basis points from 2019 (source GlobeNewswire3). Figure 2: ANF all trend. ANF was born at the end of September 1996, and from April to October 2011 it came close to the All Time High (ATH) at various times, meeting punctually a resistance. This peculiarity, together with the others previously mentioned, has led us to observe this stock with attention starting from the end of October 2011 (see Ô¨Åg. 2) when the downtrend period below $70 begins, with the further intent to determine a potential opportune moment for a market entry by buying this asset. It is certainly an asset with a sometimes controversial trend and consequently well proÔ¨Åtable if rightly analyzed, especially in the particular period of 2020/2021 due to the global pandemic (see Ô¨Åg. 3(a)) and because it lacks the leverage effect (Black [1976]) that explains the negative correlation between equity returns and return volatility (see Ô¨Åg. 3(b) and 3(c)) where most of the measures of the volatility of the asset are negatively correlated with its return. Furthermore, in this long period analysed, ANF is not the classic always proÔ¨Åtable stock (e.g. Tesla, Apple, Microsoft, or Bitcoin) to which trivially apply a passive Buy and Hold strategy4for gains. The dataset consists of the time series of the price of the above mentioned stocks, over the time period from October 16, 2011 to November 20, 2021, for a total period of 2537 open market days. The time series of price observations can be downloaded from Yahoo Finance5and then split into train and test sets, or directly from our github repository6. In particular, only the 30 days of the market open was used for the validation of the values composed by the features characterized by the OHLC prices aforementioned. In Ô¨Åg. 4, we can see the scatter matrix, which indicates that there are few positive correlations between them, even looking at the distribution of each individual variable along the diagonal represented with the Kernel Density Estimation (KDE) (see Chen [2017]), which denotes a smoother distribution surface across the plots. Intuitively, KDE has the effect of smoothing out each data point into a smooth bump. The shape of curve is determined by the kernel function K(x)which sums overall the bumps to obtain the density estimator. The regions with many observations, KDE yield a large value because there are many bumps around. To the other side, for regions with few observations, the density value from summing over the bumps is low, because only few bumps contribute to the density estimate. 2.1.1 Stationarity Test A time series is considered stationary when statistical properties such as mean, variance, and covariance are constant over time. For making predictions, the stationarity is a preferred characteristic, to the other side nonstationarity cannot exploit valuable timedependent models, and variance can be misspeciÔ¨Åed by them. 3www.globenewswire.com/newsrelease/2021/11/23/2339734/0/en/AbercrombieFitchCoReportsThirdQuarter Results.html 4https://www.investopedia.com/terms/b/buyandhold.asp 5https://it.Ô¨Ånance.yahoo.com/quote/ANF?p=ANF&.tsrc 6https://github.com/IvanLetteri/StockTradingSystemMLPRegressor 3arXiv Template A P REPRINT Figure 3: ANF price (a), return (b), and volatility (c) from October 30th 2011 to November 30th 2021. To test whether our dataset is composed of a stationary time series, we used the stationary unit root as a statistical test. Given the time series yt=ayt"
281,Safety Verification for Neural Networks Based on Set-boundary Analysis.txt,"Neural networks (NNs) are increasingly applied in safety-critical systems
such as autonomous vehicles. However, they are fragile and are often
ill-behaved. Consequently, their behaviors should undergo rigorous guarantees
before deployment in practice. In this paper we propose a set-boundary
reachability method to investigate the safety verification problem of NNs from
a topological perspective. Given an NN with an input set and a safe set, the
safety verification problem is to determine whether all outputs of the NN
resulting from the input set fall within the safe set. In our method, the
homeomorphism property of NNs is mainly exploited, which establishes a
relationship mapping boundaries to boundaries. The exploitation of this
property facilitates reachability computations via extracting subsets of the
input set rather than the entire input set, thus controlling the wrapping
effect in reachability analysis and facilitating the reduction of computation
burdens for safety verification. The homeomorphism property exists in some
widely used NNs such as invertible NNs. Notable representations are invertible
residual networks (i-ResNets) and Neural ordinary differential equations
(Neural ODEs). For these NNs, our set-boundary reachability method only needs
to perform reachability analysis on the boundary of the input set. For NNs
which do not feature this property with respect to the input set, we explore
subsets of the input set for establishing the local homeomorphism property, and
then abandon these subsets for reachability computations. Finally, some
examples demonstrate the performance of the proposed method.","Machinelearninghasseenrapidgrowthduetothehighamountofdataproduced in many industries and the increase in computation power. NNs have emerged ?Corresponding authorarXiv:2210.04175v1  [cs.AI]  9 Oct 20222 Z. Liang et al. as a leading candidate computation model for machine learning, which promote the prosperity of artiÔ¨Åcial intelligence in various Ô¨Åelds, such as computer vision [38,7], natural language processing [49,23] and so on. In recent years, NNs are increasingly applied in safety critical systems. For example, a neural network has been implemented in the ACAS Xu airborne collision avoidance system for unmanned aircraft, which is a highly safetycritical system and currently being developed by the Federal Aviation Administration. Consequently, to gain users‚Äô trust and ease their concerns, it is of vital importance to ensure that NNs are able to produce safe outputs and satisfy the essential safety requirements before the deployment. Safety veriÔ¨Åcation of NNs, which determines whether all outputs of an NN satisfy speciÔ¨Åed safety requirements via computing output reachable sets, has attracted a huge attention from diÔ¨Äerent communities such as machine learning [29,1],formalmethods[19,39,28],andsecurity[41,11].BecauseNNsaregenerally large, nonlinear, and nonconvex, exact computation of output reachable sets is challenging. Although there are some methods on exact reachability analysis such as SMTbased [24] and polyhedronbased approaches [43,40], they are usu ally timeconsuming and do not scale well. Moreover, these methods are limited to NNs with ReLU activation functions. Consequently, overapproximate reach ability analysis, which mainly involves the computation of super sets of output reachable sets, is often resorted to in practice. The overapproximate analysis is usually more eÔ¨Écient and can be applied to more general NNs beyond ReLU ones. Due to these advantages, an increasing attention has been attracted and thus a large amount of computational techniques have been developed for over approximate reachability analysis [27]. Overly conservative overapproximations, however, often render many safety properties unveriÔ¨Åable in practice. This conservatism mainly results from the wrapping eÔ¨Äect, which is the accumulation of overapproximation errors through layerbylayerpropagation.AstheextentofthewrappingeÔ¨Äectcorrelatesstrongly with the size of the input set [44], techniques that partition the input set and independently compute output reachable sets of the resulting subsets are often adapted to reduce the wrapping eÔ¨Äect, especially for large input sets. Such par titioning may, however, produce a large number of subsets, which is generally exponential in the dimensionality. This will induce extensive demand on compu tationtimeandmemory,oftenrenderingexistingreachabilityanalysistechniques not suitable for safety veriÔ¨Åcation of complex NNs in real applications. There fore, exploring subsets of the input set rather than the entire input set could help reduce computation burdens and thus accelerate computations tremendously. In this work we investigate the safety veriÔ¨Åcation problem of NNs from the topological perspective and extend the setboundary reachability method, which is originally proposed for verifying safety properties of systems modeled byODEsin[45],tosafetyveriÔ¨ÅcationofNNs.In[45],thesetboundaryreachabil ity method only performs overapproximate reachability analysis on the initial set‚Äôs boundary rather than the entire initial set to address safety veriÔ¨Åcation problems. It was built upon the homeomorphism property of ODEs. This niceSafety VeriÔ¨Åcation for Neural Networks Based on Setboundary Analysis 3 property also widely exists in NNs, and typical NNs are invertible NNs such as neural ODEs [5] and invertible residual networks [4]. Consequently, it is straight forward to extend the setboundary reachability method to safety veriÔ¨Åcation of these NNs, just using the boundary of the input set for reachability analysis which does not involve reachability computations of interior points and thus re ducing computation burdens in safety veriÔ¨Åcation. Furthermore, we extend the setboundary reachability method to general NNs via exploiting the local home omorphism property with respect to the input set. This exploitation is instru mental for constructing a subset of the input set for reachability computations, which is gained via removing a set of points in the input set such that the NN is a homeomorphism with respect to them. The above methods of extracting subsets for performing reachability computations can also be applied to intermediate layers of NNs rather than just between the input and output layers. Finally, we demonstrate the performance of the proposed method on several examples. Main contributions of this paper are listed as follows. ‚ÄìWe investigate the safety veriÔ¨Åcation problem of NNs from the topological perspective. More concretely, we exploit the homeomorphism property and aim at extracting a subset of the input set rather than the entire input set for reachability computations. To the best of our knowledge, this is the Ô¨Årst workontheuseofthehomeomorphismpropertytoaddresssafetyveriÔ¨Åcation problems of NNs. This might on its own open research directions on digging into topological properties of facilitating reachability computations for NNs. ‚ÄìThe proposed method is able to enhance the capabilities and performances of existing reachability computation methods for safety veriÔ¨Åcation of NNs via reducing computation burdens. Based on the homeomorphism property, the computation burdens of solving the safety veriÔ¨Åcation problem can be reduced for invertible NNs. We further show that the computation burdens can also be reduced for more general NNs via exploiting this property on subsets of the input set. 2 Related Work "
408,Universal Property of Convolutional Neural Networks.txt,"Universal approximation, whether a set of functions can approximate an
arbitrary function in a specific function space, has been actively studied in
recent years owing to the significant development of neural networks. However,
despite its extensive use, research on the universal properties of the
convolutional neural network has been limited due to its complex nature. In
this regard, we demonstrate the universal approximation theorem for
convolutional neural networks. A convolution with padding outputs the data of
the same shape as the input data; therefore, it is necessary to prove whether a
convolutional neural network composed of convolutions can approximate such a
function. We have shown that convolutional neural networks can approximate
continuous functions whose input and output values have the same shape. In
addition, the minimum depth of the neural network required for approximation
was presented, and we proved that it is the optimal value. We also verified
that convolutional neural networks with sufficiently deep layers have
universality when the number of channels is limited.","The convolutional neural network(CNN) (O‚ÄôShea and Nash, 20 15; LeCun et al., 1998), one of the most widely used deep learning modules, has achieved t remendous accomplish ment in numerous Ô¨Åelds, including object detection (Zaidi e t al., 2022), image classiÔ¨Åcation (Elngar et al., 2021), and sound processing (Tan et al., 2021 ). Starting with the most ba sic architecture like LeNet5 (LeCun et al., 1998), many well known deep learning models such as VGGNet (Simonyan and Zisserman, 2014), ResNet (He et al., 2016), and ResNeXt (Xie et al., 2017) have been constructed based on CNN. In this regard, it would be natural to be interested in the universal property of CNN, which just iÔ¨Åes using a speciÔ¨Åc network. Universal property or universal approximation is the abili ty of a particular set of func tions to approximate the suÔ¨Éciently wide range of the functi ons. However, despite its ex tensive range of applications, research on the universal pr operty of CNN has been barely conducted. One of the rare studies is Zhou (2020). The paper c onsidered the convolutional neural network with a linear layer combined in the last layer and proved the universal prop erty of thenetwork asthefunction from RdtoR.However, networks sometimes are expected 1Geonho Hwang to retain the output data in the same shape as the input data. R epresentative examples include object segmentation (Long et al., 2015), depth esti mation (Bhoi, 2019), or image processingsuch as deblurring(Zhang et al., 2022), inpaint ing (Suthar and Patel, 2014), and denoising (Fan et al., 2019). Another common usage of CNN is a s a feature extractor. The feature extractor extracts information from the data and fe eds it to the latter part of the deep learning model. Typically, the feature extracted by CN N is multidimensional, and to achieve the purpose of being a module that can be used in com mon across multiple networks, CNN needs to have universal property. Also, the pa per assumed an unrealistic situation in which each convolutional layer expands the dim ension of the data, which makes the contribution restrictive. Someotherresearch paperstackle theuniversalpropertyof CNNwithmultidimensional output as a translation invariant function. Approaches tha t tackle the universal property of CNN with multidimensional output are investigating the ap proximation of the translation invariant function with convolutional neural networks (Ya rotsky, 2022; Maron et al., 2019). These papers consider the convolutional network as a functi on fromRdtoRd. However, the invariance of the network inevitably prevents the use of pra ctically used padding methods like zero padding. In addition, invariance fundamentally c ontradicts the universal property in the more general continuous function space. In this regard, we studied the universal property of the conv olutional neural network consisting of the convolutional layer with zero padding. Un like the previous methods that only consider scalar output or the translationally invaria nt functions, We directly tackle the universal property of CNN as a vectortovector functio n. Despite its dominant use in CNN, zero padding convolution has been outside the intere sts of the study because it deteriorates the invariance of the network. However, we r evealed that zero padding is critical in achieving universal property. More speciÔ¨Åcall y, universal property occurs because zero padding interferes with invariance. We scrutinize the threekernel convolutional neural network withzeropaddingandexploretheminimaldepthandw idthboundfortheuniversal property. Our contributions are as follows: ‚Ä¢We proved that CNN has the universal property in the continuo us function space as a function that preserves the shape of the input data. ‚Ä¢Wefoundtheoptimalnumberofconvolutional layers forafun ctionwith ddimensional input to have universal property. ‚Ä¢We proved that deep CNN with cx+cy+2 has the universal property, where cxand cyare the number of channels of the input and output data, respe ctively. 2. Related Works "
88,Exploring Faithful Rationale for Multi-hop Fact Verification via Salience-Aware Graph Learning.txt,"The opaqueness of the multi-hop fact verification model imposes imperative
requirements for explainability. One feasible way is to extract rationales, a
subset of inputs, where the performance of prediction drops dramatically when
being removed. Though being explainable, most rationale extraction methods for
multi-hop fact verification explore the semantic information within each piece
of evidence individually, while ignoring the topological information
interaction among different pieces of evidence. Intuitively, a faithful
rationale bears complementary information being able to extract other
rationales through the multi-hop reasoning process. To tackle such
disadvantages, we cast explainable multi-hop fact verification as subgraph
extraction, which can be solved based on graph convolutional network (GCN) with
salience-aware graph learning. In specific, GCN is utilized to incorporate the
topological interaction information among multiple pieces of evidence for
learning evidence representation. Meanwhile, to alleviate the influence of
noisy evidence, the salience-aware graph perturbation is induced into the
message passing of GCN. Moreover, the multi-task model with three diagnostic
properties of rationale is elaborately designed to improve the quality of an
explanation without any explicit annotations. Experimental results on the
FEVEROUS benchmark show significant gains over previous state-of-the-art
methods for both rationale extraction and fact verification.","The wide availability of userprovided content on online so cial media facilitates the rapid dissemination of unfounded rumors and misinformation. Fact veriÔ¨Åcation, automatically assessing the veracity of a textual claim against multi ple pieces of evidence retrieved from external sources, has gained intense attention to combat misinformation spread on the internet (Zhou and Zafarani 2020; Guo, Schlichtkrull, and Vlachos 2022; Si et al. 2021). However, as the opaque ness of the model diminishes user conÔ¨Ådence and impedes the discovery of harmful biases (Kotonya and Toni 2020a), it is essential to understand the ‚Äúreasoning‚Äù behind the model prediction, i.e, the explainability of the fact veriÔ¨Åcation ap proaches. *Corresponding author. Copyright ¬© 2023, Association for the Advancement of ArtiÔ¨Åcial Intelligence (www.aaai.org). All rights reserved. Claim: Olympic athlete May Wafic Sardouk  represented  Lebanon  at the 1988 Summer Olympics in Seoul , Korea ,  landing in the 6th position in the Heat 4 event . Evidence: S1(wiki/May Sardouk ): May Wafic Sardouk  (Arabic: ŸÖŸä ŸàŸÅŸäŸÇ  ÿ≥ÿ±ÿØŸàŸÉ ; born June 4, 1963 ) is a Lebanese  Olympic athlete . S2(wiki/May Sardouk ): She represented Lebanon in 1988   Summer Olympics in Seoul . S3(wiki/May Sardouk ): Sardouk and Nancy Khalaf were the  only female participants for Lebanon in that tournament  among a total of 21 participant for Lebanon. S4(wiki/Seoul ): Seoul , officially the Seoul Special City, is  the capital and largest metropolis of South Korea . S5(wiki/1988 Summer Olympics ): The 1988 Summer  Olympics , ‚Ä¶,  was an international multi sport event held  from 17 September to 2 October 1988 in Seoul, South Korea. T6(wiki/May Sardouk ): Label:  SUPPORTSHeat 4Heat 4 Rank Athlete Time 1 ¬† Diane Dixon¬† (USA) 52.45 2 ¬† Ute Thimm¬† (FRG) 52.79 6 ¬† May Sardouk¬† (LIB) 1:00.01‚Ä¶‚Ä¶Heat 4 Rank Athlete 6 May Sardouk (LIB)Figure 1: An example from FEVEROUS dataset, where S1, S2, S4 and two table cells in T6are considered as rationales. A straightforward way to generate explanations for fact veriÔ¨Åcation is to use rationale extraction (Zaidan, Eisner, and Piatko 2007; DeYoung et al. 2020; Atanasova et al. 2020; Glockner, Habernal, and Gurevych 2020; Atanasova et al. 2022), a posthoc technique searching for a minimal portion of input (i.e., rationales) that can be sufÔ¨Åcient (i.e., solely based on the rationales) to derive a veracity predic tion. The intuition is that the retrieved evidence for verify ing the claim comprises noisy evidence inevitably, and the interaction of true evidence1is adequate for the multihop fact veriÔ¨Åcation model to reach a disposition accurately. It 1Note that we make a distinction between true evidence and noisy evidence conceptually, and deÔ¨Åne the true evidence as therationale since the term ‚Äúrationale‚Äù implies humanlike in tent (Wiegreffe and Marasovic 2021).arXiv:2212.01060v1  [cs.CL]  2 Dec 2022contrasts with the methods heuristically exploring the im portance of input features, such as attentionbased meth ods (Chen et al. 2022; Wu et al. 2021) or gradientbased methods (Sundararajan, Taly, and Yan 2017), which in evitably induce lowscoring features, drawing criticism re cently (Jain and Wallace 2019). In this work, we focus on how to extract valid rationales for explaining multihop fact veriÔ¨Åcation model. Existing rationale extraction methods for multihop fact veriÔ¨Åcation model usually rely on the FEVER dataset (Thorne et al. 2018; DeYoung et al. 2020; Bekoulis, Papagiannopoulou, and Deligiannis 2021). These methods typically decompose the model into the extractor module and the predictor module independently (Lei, Barzilay, and Jaakkola 2016; Jain et al. 2020; Kotonya and Toni 2020b), where the former is trained to assign a mask score over the subset (e.g., sentences or tokens) of inputs to capture the rationale, then the latter makes predictions exclusively on the rationales provided by the extractor. The quality of the explanation depends upon the strategy of the mask vector training. However, despite the salient progress, there are still lim itations required to be addressed for explainable multihop fact veriÔ¨Åcation (Jiang et al. 2020; Ostrowski et al. 2021; Aly et al. 2021; Atanasova et al. 2020; Jain et al. 2020; Atanasova et al. 2022). Inherently, in multihop fact veriÔ¨Åca tion, the claims may be veriÔ¨Åed by aggregating and reason ing over multiple pieces of rationales. For example in Fig.1, the truthfulness of the claim can be assessed by aggregat ing four pieces of true evidence (i.e., rationales), including sentences and table cells, surrounded by multiple pieces of noisy evidence. Intuitively, the rationale S1carries the com plementary information capable of extracting the rationale S2through the multihop reasoning process. However, in the mask vector learning process, current rationale extraction methods are mainly based on the semantic information of individual semantic units (sentence or token) within the in put, failing to capture the topological information interaction among multiple pieces of the semantic unit in the multihop reasoning process for rationale extraction, which we argue is crucial for the explainable multihop fact veriÔ¨Åcation. To address such disadvantage, we introduce a GCNbased model (Kipf and Welling 2017) with Salienceaware Graph Perturbation, namely SaGP, where multihop fact veriÔ¨Åca tion and sentencelevel rationale extraction are optimized jointly. The core novelty here is that we frame the ratio nale extraction of multihop fact veriÔ¨Åcation as subgraph extraction via searching for the rationale subgraph with min imal nodes while sufÔ¨Åciently maintaining the prediction ac curacy. SpeciÔ¨Åcally, we use GCN to integrate the topologi cal interaction of information among different pieces of evi dence to update evidence representation. Meanwhile, to alle viate the inÔ¨Çuence of the noisy evidence in this process, we induce a learnable salienceaware perturbation (edge mask, node mask) into the message passing process of GCN to ap proximate the deletion of the superÔ¨Çuous edges or nodes in the input graph. It guarantees that the information masked out from the graph is not propagated for evidence repre sentation learning. Then the assignment vector over eachnode is learned to indicate whether the evidence could be contained in the rationale subgraph, which approximates the mask vector learning following prior works. Moreover, we incorporate the multitask learning paradigm and deÔ¨Åne three diagnostic properties (i.e., Fidelity ,Compact ,Topol ogy) as additional optimizing signals to guide the learning of rationale subgraph. The main contributions are listed as follows: (I) We frame the explainable multihop fact veriÔ¨Åcation as subgraph ex traction, where a GCNbased model with salienceaware graph learning is proposed. (II) The multitask model with three diagnostic properties is designed and optimized to im prove the quality of extracted explanations without access ing the rationale supervision. (III) Experimental results on the FEVEROUS dataset show the superior performance of the proposed approach. 2 Related Works "
468,On Optimizing Back-Substitution Methods for Neural Network Verification.txt,"With the increasing application of deep learning in mission-critical systems,
there is a growing need to obtain formal guarantees about the behaviors of
neural networks. Indeed, many approaches for verifying neural networks have
been recently proposed, but these generally struggle with limited scalability
or insufficient accuracy. A key component in many state-of-the-art verification
schemes is computing lower and upper bounds on the values that neurons in the
network can obtain for a specific input domain -- and the tighter these bounds,
the more likely the verification is to succeed. Many common algorithms for
computing these bounds are variations of the symbolic-bound propagation method;
and among these, approaches that utilize a process called back-substitution are
particularly successful. In this paper, we present an approach for making
back-substitution produce tighter bounds. To achieve this, we formulate and
then minimize the imprecision errors incurred during back-substitution. Our
technique is general, in the sense that it can be integrated into numerous
existing symbolic-bound propagation techniques, with only minor modifications.
We implement our approach as a proof-of-concept tool, and present favorable
results compared to state-of-the-art verifiers that perform back-substitution.","Deep neural networks (DNNs) are dramatically changing the way modern software is written. In many domains, such as image recognition [43], game playing [42], protein folding [2] and autonomous vehicle control [12], [30], stateofthea rt solutions involve deep neural networks ‚Äî which are artifact s learned automatically from a Ô¨Ånite set of examples, and whic h often outperform carefully handcrafted software. Along with their impressive success, DNNs present a sig niÔ¨Åcant new challenge when it comes to quality assurance. Whereas many best practices exist for writing, testing, ver ify ing and maintaining handcrafted code, DNNs are automati cally generated, and are mostly opaque to humans [24], [25]. Consequently, it is difÔ¨Åcult for human engineers to reason about them and ensure their correctness and safety ‚Äî as most existing approaches are illsuited for this task. This chal lenge is becoming a signiÔ¨Åcant concern, with various faults being observed in modern DNNs [5]. One notable example is that ofadversarial perturbations ‚Äî small perturbation that, when added to inputs that are correctly classiÔ¨Åed by the DNN, resu lt in severe errors [20], [48]. This issue, and others, call int o question the safety, security and interpretability of DNNs , and could hinder their adoption by various stakeholders. In order to mitigate this challenge, the formal methods community has taken up interest in DNN veriÔ¨Åcation. In the past few years, a plethora of approaches have been proposed for tackling the DNN veriÔ¨Åcation problem , in which we aregiven a DNN and a condition abouts its inputs and outputs; and seek to either Ô¨Ånd an input assignment to the DNN that satisÔ¨Åes this condition, or prove that it is not satisÔ¨Åable [ 1], [8], [10], [14], [21], [27], [29], [31], [33], [39], [51], [5 6]. The usefulness of DNN veriÔ¨Åcation has been demonstrated in several settings and domains [21], [27], [31], [47], but most existing approaches still struggle with various limit ations, speciÔ¨Åcally relating to scalability. A key technical challenge in verifying neural networks is to reason about activation functions , which are nonlinear (e.g., piecewise linear) transformations applied to the output o f each layer in the neural network. Precisely reasoning about such nonlinear behaviors requires a casebycase analysis of t he activation phase of each activation function, which quickl y becomes infeasible as the number of nonlinear activations increases. Instead, before performing such a search proced ure, stateoftheart solvers typically Ô¨Årst consider linear a bstrac tions of activation functions, and use these abstractions t o overapproximate the values that the activation functions can take in the neural network. Often, these overapproximatio ns signiÔ¨Åcantly curtail the search space that later needs to be explored, and expedite the veriÔ¨Åcation procedure as a whole . A key operation that is repeatedly invoked in this compu tation of overapproximations is called backsubstitution [45], where the goal is to compute, for each neuron in the DNN, lower and upper bounds on the values it can take with respect to the input region of interest. This is done by Ô¨Årst express ing the lower and upper bounds of a neuron symbolically as a function of neurons from previous layers, and then concretizing these symbolic bounds with the known bounds of neurons in those previous layers. Such a technique is essential in stateoftheart solvers (e.g., [32], [45], [ 54]) and is often able to obtain sufÔ¨Åciently tight bounds for proving the properties with respect to small input regions. However , it tends to signiÔ¨Åcantly lose precision when the input region ( i.e., perturbation radius) grows, preventing one from efÔ¨Åcientl y verifying more challenging problems. In this work, we seek to improve the precision and scala bility of DNN veriÔ¨Åcation techniques, by reducing the over approximation error in the backsubstitution process. Our key insight is that, as part of the symbolicbound propagation, one can measure the error accumulated by the overapproximatio ns used in backsubstitution. Often, the currently computed b ound can then be signiÔ¨Åcantly improved by ‚Äúpushing‚Äù it towards th e true function, in a way that maintains its validity. For exam ple, https://doi.org/This article is licensed under a Creative Commons Attribution 4.0 International Licensesuppose that we upperbound a function fwith a function g, i.e.‚àÄx. g(x)‚â•f(x). If we discover that the minimal approximation error is 5, i.e.minx{g(x)‚àíf(x)}= 5, then g(x)‚àí5can be used as a better upper bound for fthan the original g. By integrating this simple principle into the backsubstitution process, we show that we can obtain much tighter bounds, which eventually translates to the ability to verify more difÔ¨Åcult properties. We propose here a veriÔ¨Åcation approach, called Deep MIP, that uses symbolicbound tightening enhanced with our erroroptimization method. At each iteration of the back substitution, DeepMIP invokes an external MIP solver [26] to compute bounds on the error of the current approximation, and then uses these bounds to improve that approximation. As we show, this leads to an improved ability to solve veriÔ¨Åcation benchmarks when compared to stateoftheart , symbolicbound tightening techniques. We discuss the diff er ent advantages of the approach, as well as the extra overhead that it incurs, and various enhancements that could be used t o expedite it further. The rest of the paper is organized as follows. We begin by presenting the necessary background on DNNs, DNN veriÔ¨Åca tion, and on symbolicbound propagation in Sec. II. Next, in Sec. III we show how one can express the approximation error incurred as part of the backsubstitution process. In Sec. I V we present the DeepMIP algorithm, followed by its evaluation i n Sec. V. Related work is discussed in Sec. VI, and we conclude in Sec. VII. II. B ACKGROUND Neural networks. A fullyconnected feedforward neural net work with k+1layers is a function N:Rm‚ÜíRn. Given an inputx‚ààRm, we useNi(x)to denote the values of neurons in theithlayer (0‚â§i‚â§k). The output of the neural network N(x)is deÔ¨Åned as Nk(x), which we refer to as the output layer. More concretely, for 1‚â§i‚â§k, Ni(x) =œÉ(Wi‚àí1Ni‚àí1(x)+bi‚àí1) whereWi‚àí1is a weight matrix ,bi‚àí1is a bias vector ,œÉis an activation function (in this paper, we focus on the ReLU activation function, deÔ¨Åned as ReLU (x) = max{0,x}and useœÉand ReLU interchangeably unless otherwise speciÔ¨Åed) andN0(x) =x. We refer to N0as the input layer. Typically, nonlinear activations are not applied to the output layer. Thus, wheni=k, we letœÉbe the identity function. We note that our techniques are general, and apply to other activation funct ions (MaxPool, LeakyReLU) and architectures (e.g., convolutio nal, residual). Neural network veriÔ¨Åcation. Theneural network veriÔ¨Åcation problem [31], [39] is deÔ¨Åned as follows: given an input domain Di‚äÜRmand an output domain domain Do‚äÜRn, the goal is to determine whether ‚àÄx‚ààDi,N(x)‚ààDo. If the answer is afÔ¨Årmative, we say that the veriÔ¨Åcation property pair /an}bracketle{tDi,Do/an}bracketri}ht holds. In this paper, we assume that the neural network has a single output neuron and that the veriÔ¨Åcation problem canbe reduced to the problem of Ô¨Ånding the minimum and/or maximum values for that single output neuron: min x‚ààDi(N(x)) max x‚ààDi(N(x)) (1) For example, ifDois the interval [‚àí2,7]and we discover thatminx‚ààDi(N(x)) = 1 andmaxx‚ààDi(N(x)) = 3 , then we are guaranteed that the property holds. We will focus on solving just the maximization problem, although the method that we present next can just as readily be applied towards th e minimization problem. A straightforward way to solve the optimization problem in Eq. 1 is to encode the neural network as a mixed integer programming (MIP) instance [11], [31], [49], and then solve the problem using a MIP solver, which often employs a branchandbound procedure. While this approach has prove n effective at verifying small DNNs, it faces a scalability barrier when it comes to larger networks. Therefore, before invoking the branchandbound procedure, existing solver s typically Ô¨Årst seek to prove the property with abstraction based techniques (symbolicbound propagation), which have more tractable runtime. Symbolicbound propagation. Symbolicbound propaga tion [21], [51] is a method of obtaining bounds on the concret e values a neuron may obtain. When applied to a network‚Äôs output neuron, it enables us to obtain an approximate soluti on to the optimization problems from Eq. 1, which may be sufÔ¨Åcient to determine that the property holds. For example , continuing the example from before, if we are unable to exactly compute that maxx‚ààDi(N(x)) = 3 but can determine thatmaxx‚ààDi(N(x))<5, this is enough for concluding that the property in question holds. The idea underlying symboli c bound propagation is to start from the bounds for the input layer provided in Di, and then propagate them, layerby layer, up to the output layer. It has been observed that while afÔ¨Åne transformations allow us to precisely propagate boun ds from a layer to its successor, activation functions introdu ce inaccuracies [45]. Before formally deÔ¨Åning symbolic bound propagation, we start with an intuitive example using the network in Fig. 1. Letxidenote the preactivation values of the neurons in layeri, and let yi=œÉ(xi)denote their postactivation values; similarly, let xi jandyi j=œÉ(xi j)denote the pre and postactivation values of neuron jin layeri; and let li j,ui j denote the concrete (scalar) lower and upperbound for xi j, i.e.li j‚â§xi j‚â§ui jwhen the DNN is evaluated on any input fromDi. Assume thatDiis the following box domain: Di={‚àí1‚â§x0 i‚â§1|i‚àà{0,1,2}} and that we wish to compute bounds for the single output neuron,x3 0. We begin by propagating the bounds through the Ô¨Årst afÔ¨Åne layer. According to the network‚Äôs weights and biases, we get : x1 0=x0 0+x0 1, x1 1=x0 0‚àíx0 1, x1 2=x0 2 these equations allow us to compute concrete lower and upper bounds for each of these neurons, by substituting the inputx0 0 x0 1 x0 2x1 0 x1 1 x1 2y1 0 y1 1 y1 2x2 0 x2 1 x2 2y2 0 y2 1 y2 2x3 01 1 1 ‚àí1 1ReLU ReLU ReLU1 1 ‚àí1 1 1 ‚àí11 ‚àí1ReLU ReLU ReLU1 1 1[‚àí1,1] [‚àí1,1] [‚àí1,1][‚àí2,2] [‚àí2,2] [‚àí1,1][0,2] [0,2] [0,1][0,2] [‚àí2,3] [‚àí3,2][0,2] [0,3] [0,2][0,6] Fig. 1: A neural network. neurons ( x0 0,x0 1,x0 2) with their corresponding concrete bounds (according to the sign of their coefÔ¨Åcients). Using this pro cess, we obtain: x1 0‚àà[‚àí2,2], x1 1‚àà[‚àí2,2], x1 2‚àà[‚àí1,1] this propagation, often referred to as interval arithmetic [15], is precise for individual neurons: indeed, x1 0,x1 1andx1 2can each take on any value in their respective computed ranges. However, much important information is lost when using just interval arithmetic: for example, it is impossible for x1 0and x1 1tosimultaneously be assigned 2. As we will later see, symbolicbound propagation addresses this issue by captur ing some of the dependencies between neurons, and using these dependencies in producing tighter bounds. For now, we continue propagating our computed bounds to neuronsy1 0,y1 1andy1 2. The output range of a ReLU is the nonnegative part of its input range, which yields: y1 0‚àà[0,2], y1 1‚àà[0,2], y1 2‚àà[0,1] and the next, afÔ¨Åne layer is again handled using interval arithmetic. Using the expressions x2 0=y1 0+y1 1, x2 1=‚àíy1 0+y1 1+y0 2, x2 2=‚àíy1 0+y1 1‚àíy0 2 and substituting each y1 iwith the appropriate bound, we obtain: x2 0‚àà[0,4], x2 1‚àà[‚àí2,4], x2 0‚àà[‚àí4,2] Unfortunately, as we soon show, the bounds computed for x2 0,x2 1,x2 2are not tight. A better approach is to compute symbolic bounds , as opposed to concrete ones, in a way that lets us carry additional information about the dependencie s between neurons. In symbolicbound propagation, we seek to express the upper and lower bounds of each neuron as a linear combination of neurons from earlier layers, using a process known as backsubstitution . The main difÔ¨Åculty is to propagate these bounds across ReLU layers, which are not convex; and this is performed by using a triangle relaxation of the ReLU function, illustrated in Fig. 2. Assume x‚àà[l,u]; then, using this relaxation, we can deduce the following bounds: Ô£± Ô£¥Ô£≤ Ô£¥Ô£≥0‚â§œÉ(x)‚â§0 ifu‚â§0 x‚â§œÉ(x)‚â§x ifl‚â•0 Œ±x‚â§œÉ(x)‚â§u u‚àíl(x‚àíl)otherwise, for any 0‚â§Œ±‚â§1Different symbolic bound propagation methods use differen t heuristics for choosing Œ±[45], [54]; but this is beyond our scope here, and our proposed technique is compatible with any such heuristic. For our running example, we arbitrarily choose the values of Œ±; and for our implementation, we use an existing heuristic [54]. ‚àí1‚àí0.5 0 .5 1 ‚àí0.50.51 xReLU(x) Fig. 2: A triangle relaxation of a ReLU function for x‚àà [‚àí1,1]. The solid lines correspond to the exact ReLU function, and the dotted lines represent the relaxed lower and upper bounds, for different values of Œ±. Using this relaxation, we show how to compute symbolic bounds that yield tighter bounds for the x2 ineurons. First observe neuron x2 0, given as x2 0=y1 0+y1 1=œÉ(x1 0)+œÉ(x1 1). To obtain its lower bound we Ô¨Årst substitute both y1 0=œÉ(x1 0)and y1 1=œÉ(x1 1)with their corresponding triangle relaxation lower bounds, with the choice of Œ±= 0 for both (we note that it is possible to choose different Œ±values for different variables). For the upper bound, we use the linear upper bound from the triangle relaxation. By using the bounds we already know for nodes in previous layers, we get that: x2 0‚â•0¬∑x1 0+0¬∑x1 1= 0 x2 0‚â§1 2/parenleftbig x1 0+2/parenrightbig +1 2/parenleftbig x1 1+2/parenrightbig =1 2/parenleftbig x1 0+x1 1/parenrightbig +2 =1 2/parenleftbig/parenleftbig x0 0+x0 1/parenrightbig +/parenleftbig x0 0‚àíx0 1/parenrightbig/parenrightbig +2 =x0 0+2‚â§3 which indeed produces a tighter upper bound than the one obtained for x2 0using interval propagation. Similarly, we get that forx2 1: x2 1‚â•‚àí1 2/parenleftbig x1 0+2/parenrightbig +0¬∑x1 1+0¬∑x1 2 =‚àí1 2/parenleftbig x0 0+x0 1/parenrightbig ‚àí1 =‚àí2 x2 1‚â§‚àí0¬∑x1 0+1 2/parenleftbig x1 1+2/parenrightbig +1 2/parenleftbig x1 2+1/parenrightbig =1 2/parenleftbig x1 1+x1 2/parenrightbig +1.5 =1 2/parenleftbig x0 0‚àíx0 1+x0 2/parenrightbig +1.5‚â§3and forx2 2: x2 2‚â•‚àí1 2/parenleftbig x1 0+2/parenrightbig +0¬∑/parenleftbig x1 1/parenrightbig ‚àí1 2/parenleftbig x1 2+1/parenrightbig =‚àí1 2/parenleftbig x1 0+x1 2/parenrightbig ‚àí1.5 =‚àí1 2/parenleftbig x0 0+x0 1+x0 2/parenrightbig ‚àí1.5‚â•‚àí3 x2 2‚â§‚àí0¬∑x1 0+1 2/parenleftbig x1 1+2/parenrightbig ‚àí0¬∑x1 2 =1 2x1 1+1 =1 2/parenleftbig x0 0‚àíx0 1/parenrightbig +1‚â§2 We have thus obtained the following bounds: x2 0‚àà[0,3], x2 1‚àà[‚àí2,3], x2 2‚àà[‚àí3,2] We note that while these bounds are tighter than the ones produced by interval propagation, and are in fact optimal fo r x2 1,x2 2, this is not the case for x2 0(the optimal bounds are displayed in square brackets in Fig. 1). The reason for this suboptimality is discussed in Section III. We continue to propagate our bounds through the next layer, obtaining: y2 0‚àà[0,3], y2 1‚àà[0,3], y2 2‚àà[0,2] and Ô¨Ånally reach: x3 0=y2 0+y2 1+y2 2=œÉ(x2 0)+œÉ(x2 1)+œÉ(x2 2) ‚â§x2 0+3 5/parenleftbig x2 1+2/parenrightbig +2 5/parenleftbig x2 2+3/parenrightbig = 2y1 1+1 5y1 2+12 5= 2œÉ(x1 1)+1 5œÉ(x1 2)+12 5 ‚â§2¬∑1 2/parenleftbig x1 1+2/parenrightbig +1 5¬∑1 2/parenleftbig x1 2+1/parenrightbig +12 5 =x0 0‚àíx0 1+1 10x0 2+4.5‚â§6.6 More generally, the backsubstitution process for upper bounding a neuron xk i(assuming we already have valid bounds for all neurons in earlier layers) is iteratively deÔ¨Åned as: max(xk i) = max( Wk‚àí1 iœÉ(xk‚àí1)) ‚â§max(Wk‚àí1 iRk‚àí2 Uxk‚àí1) = max(Wk‚àí1 iRk‚àí2 UWk‚àí2œÉ(xk‚àí2)) ‚â§max(Wk‚àí1 iRk‚àí2 UWk‚àí2Rk‚àí3 Uxk‚àí2) =...‚â§max(Wk‚àí1 i0/productdisplay j=k‚àí2/parenleftBig Rj UWj/parenrightBig x0) (Biases and constants are handled similarly, and are omitte d for clarity.) At each step, we can replace the variables of xi by their respective concrete bounds [li j,ui j], in an interval arithmetic fashion, to obtain a valid concrete upper bound f or the value of max(xk i). We refer to this operation as concretiza tion. We call the matrices Ri L,Ri Uthe respective lower and upperbound relaxation matrices [54]. These matrices apply the appropriate triangle relaxation to each ReLU, allowing us to replace it with a linear bound, and are deÔ¨Åned using the current symbolic bounds for each ReLU as well as the weight matrix of the layer the precedes it. The two matrices are deÔ¨Åned such that ‚àÄx‚ààDi: œâiRi Lx+cL‚â§œâiœÉ(x)‚â§œâiRi Ux+cUwherecLandcUare scalar constants; and œâiis a row vector containing the coefÔ¨Åcients of each œÉ(xj), resulting in linear bounds for the sum of ReLUs. A precise deÔ¨Ånition of these matrices appears in Sec. A of the Appendix; and a similar procedure can be applied for lowerbounding xk i. At Ô¨Årst glance, the iterative backsubstitution process ma y seem counter productive; indeed, in each iteration where we move to an earlier layer of the network, we use a less thanequals transition, which seems to indicate that the up per bound that we will eventually reach is more loose than the present bound. This, however, is not so; and the reason is theconcretization process. When we concretize the bounds in some later iteration, it is possible that the known bounds fo r the variables in that layer of the network will lead to a tight er upper bound than the one that can be derived presently. More generally, this process can be regarded as a tradeoff betwe en computing looser expressions for the bound, but being able to concretize them over more exact domains ‚Äî which could result in tighter bounds [45]. III. E RRORS IN BACKSUBSTITUTION As previously mentioned, although symbolicbound com putation using backsubstitution can derive tighter bound s than na¬® ƒ±ve interval propagation, there are cases in which t he computed bounds are suboptimal: for example, while the bounds computed for x2 1andx2 2were tight (i.e., there exists an input inDifor which they are met), the bounds for x2 0andx3 0 were not. In this section, we analyze the reasons behind such suboptimal bounds. We begin with the following deÔ¨Ånitions : DeÔ¨Ånition 1 (Optimal bias for bound): letf:Rn‚ÜíR be a function and let Uf(x)‚â°œâx+b(œâ‚ààRn, b‚ààR) be a valid linear upper bound for fover the domainD, i.e., ‚àÄx‚ààD:Uf(x)‚â•f(x). We say that bis the optimal bias forUf(x)if‚àÄb‚àó:b‚àó< b, it holds that U‚àó f(x)‚â°œâx+b‚àó is no longer a valid upper bound for f. The deÔ¨Ånition for the optimal bias for f‚Äôs lower bound is symmetrical. An example of optimal and suboptimal upper bounds appears in Fig. 3. In the graph depicted therein, we plot an upper bound for the function ReLU (x). The bias value of the Ô¨Årst bound (in red) is 1; and as we can see, the resulting bound is not tight. When we set the bias value to 1/2, the bound becomes tight, equaling the function at points x=‚àí1 andx= 1, and so that is the optimal bias value for that bound. DeÔ¨Ånition 2 (Bound error): Letf:Rn‚ÜíR, and let g(x) be an upper bound for fover domainD, such that we have: ‚àÄx‚ààD:g(x)‚â•f(x). We deÔ¨Åne the error of gwith respect tofas the function: E(x) =g(x)‚àíf(x). The case for a lower bound is symmetrical. We observe that a linear bound gforfover the domainDi hasoptimal bias iff‚àÉx‚ààDi:E(x) = 0 . We refer to any bound that has a suboptimal bias, i.e. ‚àÄx‚ààDi:E(x)>0, as a detached bound . We show that these detachments occur naturally as part of the backsubstitution process, and are partially responsible for the discovery of suboptimal con crete bounds. It is straightforward to see that the aforementioned triang le relaxation for ReLUs produces linear bounds that are bias‚àí1‚àí0.5 0 .5 10.511.5 ReLU(x)1 2x+1 1 2x+1 2 xy Fig. 3: A simpliÔ¨Åed illustration of an optimal and suboptim al bounds for a ReLU function over x‚àà[‚àí1,1]. optimal for each individual ReLU. However, as it turns out, this may not be the case when multiple ReLUs are involved. In a typical DNN, a neuron‚Äôs value is computed as a weighted sum of the ReLUs of values from its preceding layer. Con sequently, when we calculate an upper bound for the neuron using backsubstitution, we are in fact upperbounding a su m of ReLUs by summing their individual upper bounds. This can result in a detached bound , where, despite the fact that each ReLU was approximated using a bound with an optimal bias, the resulting combined bound does not have optimal bias. An illustration of this phenomenon appears in Fig. 4. Sub Ô¨Ågures aand btherein show the graph of ReLU functions, plotted along their trianglerelaxation upper bound (in or ange). SubÔ¨Ågure cthen shows the graph of the sum of the two ReLU functions from subÔ¨Ågures aand b, along with the sum of their individual upper bounds (again, in orange). As we can see, although the upper bounds in aandbtouch the functions they are approximating in at least one point (and are hence biasoptimal), the bound in cis detached, and is hence not biasoptimal. Each Ô¨Ågure in the lower row of Fig. 4 shows the overapproximation error of the Ô¨Ågure directly above it. More formally, the error of the upper bound for ReLU (x) with current bounds l <0< u is: E(x) =u u‚àíl(x‚àíl)‚àíœÉ(x)x‚àà[l,u] and we note that E(l) =E(u) = 0 . In more complex cases, such as the case of the multivariate function x2 0=y1 0+y1 1 depicted in Fig. 4, the coordinates where the bound error equals zero could be different for y1 0andy1 1‚Äî resulting in the bound obtained for x2 0, their sum, becoming detached from the true value of the function. We now show it for the case of x2 0in greater detail: x2 0=œÉ(x1 0)+œÉ(x1 1) =œÉ(x0 0+x0 1)+œÉ(x0 0‚àíx0 1)‚àí1‚àí0.500.51‚àí101 012a ‚àí1‚àí0.500.51‚àí101 012b ‚àí1‚àí0.500.51‚àí101 02c ‚àí1‚àí0.500.51‚àí101 012d ‚àí1‚àí0.500.51‚àí101 012e ‚àí1‚àí0.500.51‚àí101 012f Fig. 4: Illustration of the formation of detached bounds as a result of summed errors. SubÔ¨Ågures aandbcorrespond toy1 0=ReLU(x0 0+x0 1),y1 1=ReLU(x0 0‚àíx0 1)and their relaxed upper bounds (in orange); and subÔ¨Ågure ccorresponds tox2 0=y1 0+y1 1and its symbolic upper bound, computed using backsubstitution. An upper bound is computed using the relaxations: œÉ(x0 0+x0 1)‚â§1 2/parenleftbig x0 0+x0 1+2/parenrightbig œÉ(x0 0‚àíx0 1)‚â§1 2/parenleftbig x0 0+x0 1+2/parenrightbig where each relaxation has its own relaxation error: E1 0(x0 0,x0 1) =1 2(x0 0+x0 1+2)‚àíœÉ(x0 0+x0 1) E1 1(x0 0,x0 1) =1 2(x0 0+x0 1+2)‚àíœÉ(x0 0‚àíx0 1) The relaxed linear bound obtained is: x2 0‚â§1 2(x0 0+x0 1+2)+1 2(x0 0+x0 1+2) =x0 0+2 And its error is the sum of the errors of its summands: Etotal(x0 0,x0 1)‚â°E1 0+E1 1 =x0 0+2‚àíœÉ(x0 0+x0 1)‚àíœÉ(x0 0‚àíx0 1) We note that: min(E1 0) =E1 0(‚àí1,‚àí1) =E1 0(1,1) = 0 min(E1 1) =E1 1(‚àí1,1) =E1 1(1,‚àí1) = 0 However: min(Etotal) =Etotal/parenleftbig ‚àí1,x0 1/parenrightbig = 1 The reason for this is that at the coordinates /an}bracketle{t‚àí1,‚àí1/an}bracketri}htand /an}bracketle{t1,1/an}bracketri}htwhereE1 0(‚àí1,‚àí1) =E1 0(1,1) = 0 , we have that E1 1(‚àí1,‚àí1) =E1 1(1,1) = 1 ; and viceversa, for the coordi nates/an}bracketle{t‚àí1,1/an}bracketri}htand/an}bracketle{t1,‚àí1/an}bracketri}ht, whereE1 1(‚àí1,1) =E1 1(1,‚àí1) = 0andE1 0(‚àí1,1) =E1 0(1,‚àí1) = 1 . The optimal linear bound for x2 0=œÉ(x0 0+x0 1)+œÉ(x0 0‚àíx0 1) is in fact x2 0‚â§x0 0+1, which is the biasoptimal version of the existing linear bound of x2 0‚â§x0 0+2.IV. D EEPMIP: M INIMIZING BACKSUBSTITUTION ERRORS During a backpropagation execution, the over approximations of individual ReLUs are repeatedly summed up, which leads to bounds that become increasingly more detached with each iteration ‚Äî and this results in very loose concrete bounds that hamper veriÔ¨Åcation. We now describe our method, which we term DeepMIP , for ‚Äútightening‚Äù detached bounds, with the goal of eventually obtaining tighter concrete bounds. The idea is to alter the back propagation mechanism, so that in each iteration it minimizes the sum of errors that result from the relaxation of the current activation layer ‚Äî effectively pushing loose upper bounds down towards the function, by decreasing their bias values (a symmetrical mechanism can be applied for lower bounds). More speciÔ¨Åcally, we propose to rewrite the genera l backsubstitution rule for a single iteration as follows: max(xk i) = max( Wk‚àí1 iœÉ(xk‚àí1)) = max/parenleftbig Wk‚àí1 iRk‚àí2 Uxk‚àí1 ‚àí/parenleftbig Wk‚àí1 iRk‚àí2 Uxk‚àí1‚àíWk‚àí1 iœÉ(xk‚àí1)/parenrightbig/parenrightbig = max(Wk‚àí1 iRk‚àí2 Uxk‚àí1‚àíEk‚àí1) ‚â§max(Wk‚àí1 iRk‚àí2 Uxk‚àí1)‚àímin(Ek‚àí1) Observe that while min(Ek‚àí1)is nonconvex, it contains no nested ReLUs, and can often be efÔ¨Åciently solved by MIP solvers [49]. Thus, as DeepMIP performs the iterative back substitution process, it can invoke a MIP solver to minimize the error in each iteration, and use it to improve the deduced bounds. The pseudocode for the algorithm appears in Sec. B of the Appendix. Observe that MiniMIP can be regarded as a generalization of modern backsubstitution methods [45], [54], in the sense that they only use the nonnegativity of the erro r to produce a trivial bound: min(Ek‚àí1) = min( Wk‚àí1 iRk‚àí2 Uxk‚àí1‚àíWk‚àí1 iœÉ(xk‚àí1))‚â•0 which is correct, since the error of an upper bound is non negative by deÔ¨Ånition (in the lower bound case, the error is nonpositive, and so 0can be used as a trivial upper bound). To continue our computation we denote the error caused by the overapproximation of the activation of layer tduring backsubstitution as: Et‚â°Wk‚àí1 it‚àí1/productdisplay j=k‚àí2(Rj UWj)(Rt‚àí1 Uxt‚àíœÉ(xt)) (2) In the deÔ¨Ånition above, iis the index of the neuron beingbounded by the backsubstitution. We get: max(xk i)‚â§max(Wk‚àí1 iRk‚àí2 Uxk‚àí1)‚àímin(Ek‚àí1) = max(Wk‚àí1 iRk‚àí2 UWk‚àí2œÉ(xk‚àí2))‚àímin(Ek‚àí1) = max(Wk‚àí1 iRk‚àí2 UWk‚àí2Rk‚àí2 Uxk‚àí2‚àíEk‚àí2) =‚àímin(Ek‚àí1) ‚â§max(Wk‚àí1 iRk‚àí2 UWk‚àí2Rk‚àí2 Uxk‚àí2) =‚àímin(Ek‚àí2)‚àímin(Ek‚àí1) =... ‚â§max(Wk‚àí1 i0/productdisplay j=k‚àí2(Rj UWj)x0)‚àí0/summationdisplay j=k‚àí1min(Ej) Finally, the maximization problem is transformed into a lin ear sum over a box domain, which is easy to solve. Since each Ej is shallow (contains no nested ReLUs), it can be minimized efÔ¨Åciently using MIP solvers, and each nontrivial minimum that is found will improve the tightness of the Ô¨Ånal upper bound. However, we note that the number of MIP problems generated by this process increases linearly with the depth of the neuron within the network ‚Äî i.e., for a neuron in layer k, there are kminimization problems to solve. For deeper networks, especially ones with large domains or ones where many layers only have very loose bounds, minimizing the erro r terms could become computationally expensive. Optimization: Direct MIP encoding. As part of its operation, DeepMIP dispatches MIP problems, each corresponding to the overapproximation error of a particular layer. SpeciÔ¨Å cally when it overapproximates the Ô¨Årst layer: max(Wk‚àí1 i1/productdisplay j=k‚àí2(Rj UWj)œÉ(W0x0))‚àí1/summationdisplay j=k‚àí2min(Ej) ‚â§max(Wk‚àí1 i0/productdisplay j=k‚àí2(Rj UWj)x0)‚àímin(E0) ‚àí1/summationdisplay j=k‚àí2min(Ej) it will directly solve the linear optimization problem: max(Wk‚àí1 i0/productdisplay j=k‚àí2(Rj UWj)x0) and use a MIP solver to solve: min(E0) = min/parenleftbigg Wk‚àí1 i1/productdisplay j=k‚àí2(Rj UWj)(R0 Uxt‚àíœÉ(x0)/parenrightbigg We observe that in this particular case, since we reached the input layer, the initial term can instead be directly solved as a separate MIP query: max(Wk‚àí1 i1/productdisplay j=k‚àí2(Rj UWj)œÉ(W0x0))which may result in tighter bounds, since it prevents any additional imprecision. We note that this optimization to DeepMIP generalizes the common practice of directly Ô¨Ånding the concrete bounds of the neurons in the Ô¨Årst layer using MIP solvers, and only applying backsubstitution from the seco nd layer onward [37], [54]. We illustrate this approach by repeating the back substitution process for x3 0from our running example: max(x3 0) = max( y2 0+y2 1+y2 2) = max(œÉ(x2 0)+œÉ(x2 1)+œÉ(x2 2)) = max/parenleftbigg œÉ(y1 0+y1 1)+œÉ(‚àíy1 0+y1 1+y1 2) +œÉ(‚àíy1 0+y1 1‚àíy1 2)/parenrightbigg = max(A‚àíE2 U)‚â§max(A)‚àímin(E2 U) where A= (y1 0+y1 1)+3 5(‚àíy1 0+y1 1+y1 2)+2 5(‚àíy1 0+y1 1‚àíy1 2)+12 5 = 2y1 1+1 5y1 2+12 5 andE2 Uis deÔ¨Åned as per Eq. 2: E2 U= (y1 0+y1 1)+3 5(‚àíy1 0+y1 1+y1 2) +2 5(‚àíy1 0+y1 1‚àíy1 2)+12 5‚àíœÉ(y1 0+y1 1) ‚àíœÉ(‚àíy1 0+y1 1+y1 2)‚àíœÉ(‚àíy1 0+y1 1‚àíy1 2) = 2y1 1+1 5y1 2+12 5‚àíœÉ(y1 0+y1 1) ‚àíœÉ(‚àíy1 0+y1 1+y1 2)‚àíœÉ(‚àíy1 0+y1 1‚àíy1 2) Simplifying these expressions, we get that max(x3 0)‚â§max(A)‚àímin(E2 U) = max(2 y1 1+1 5y1 2+12 5)‚àímin(E2 U) Using a MIP solver to Ô¨Ånd the minimum of E2 Uover the variables of y1reveals that min(E2 U) =2 5. We substitute this, and get: max(x3 0)‚â§max(2y1 1+1 5y1 2+12 5)‚àí2 5 Finally, since we have reached the Ô¨Årst layer, we write: max(x3 0)‚â§max(2y1 1+1 5y1 2+12 5)‚àí2 5 = max(2 œÉ(x1 1)+1 5œÉ(x1 2)+12 5)‚àí2 5 = max(2 œÉ(x0 0‚àíx0 1)+1 5œÉ(x0 2)+12 5)‚àí2 5 and then, using our proposed enhancement, we directly solve this maximization over the input layer instead of back substituting it any further. The MIP solver replies that: max(2œÉ(x0 0‚àíx0 1)+1 5œÉ(x0 2)+12 5) = 62 5and we then substitute this value to obtain: max(x3 0)‚â§62 5‚àí2 5= 6 As we can see, minimizing the errors by using MIP (which is very fast in practice) allows us to backsubstitute bound s with optimal bias, which yields tighter bounds for the outpu t variable. MiniMIP. While DeepMIP produces very strong bounds, for each neuron it must solve multiple MIP instances during back  substitution ‚Äî many of them for bounds that may already be biasoptimal. This large number of instances to solve can result in a large overhead, and makes it worthwhile to explor e heuristics for only solving some of these instances. To illustrate this, we propose a particular, aggressive heu ris tic that we call MiniMIP . Instead of minimizing all error terms during backsubstitution, MiniMIP only solves the Ô¨Ånal que ry in this series ‚Äî that is, the query in which the bounds of the current layer are expressed as sums of ReLUs of input neurons . This approach signiÔ¨Åcantly reduces overhead: exactly one M IP instance is solved in each iteration, regardless of the dept h of the layer currently being processed. As we later see in our evaluation, even this is already enough to achieve stateof  theart performance and very tight bounds; and the resultin g queries can be solved very efÔ¨Åciently [49]. V. E VALUATION Implementation. For evaluation purposes, we created a proof ofconcept implementation of our approach in Python. The implementation code, alongside all the benchmarks describ ed in this section, is publicly available online [55]. Our impl emen tation uses the PyTorch library [40] for computing the optim al value ofŒ±for each ReLU‚Äôs triangle relaxation, as is done in other tools [54]. We use Gurobi [26] as the MIP solver for the minimization of errors and direct concretization of bounds . We ran all experiments on a compute cluster consisting of Xeon E52637 CPUs, and a 2hour timeout per experiment. We note that our implementation currently runs on CPUs only, and extending it to support GPUs is left for future work. Abstraction reÔ¨Ånement cascade. For each veriÔ¨Åcation query, prior to applying our iterative error minimization scheme, we conÔ¨Ågured our implementation to Ô¨Årst run a lightweight, ‚Äúordinary‚Äù symbolicbound propagation pass. SpeciÔ¨Åcally , we ran a single pass of the DeepPoly mechanism [45]. A similar technique is applied by other tools [37]. Benchmarks. We evaluated our approach on fullyconnected, ReLU networks trained over the MNIST dataset, taken from the ERAN repository [19]. The topologies of the networks we used appear in Table I. For veriÔ¨Åcation queries, we followed standard practice [31 ], [37], [54], and attempted to prove the adversarial robustness of the Ô¨Årst 1000 images of the MNIST test set: that is, we used veriÔ¨Åcation to try and prove that «´perturbations to correctly classiÔ¨Åed inputs in the dataset cannot change the classiÔ¨Åca tion assigned by the DNN.TABLE I: The DNNs used in our evaluation. Dataset Model Type Neurons Hidden Layers Activation MNIST6√ó100 FC510 5 ReLU9√ó100 810 8 6√ó200 1010 5 9√ó200 1610 8 We compared the DeepMIP approach (speciÔ¨Åcally, Min iMIP) to two stateoftheart veriÔ¨Åcation approaches [9]: the PRIMA solver [37], and our implementation of the Œ± CROWN method [54], which represents the state of the art in symbolicbound tightening with backsubstitution. Ind eed, many other veriÔ¨Åcation tools integrate backsubstitution with additional techniques, such as searchbased techniques [3 2] or abstractionreÔ¨Ånement [7], making it more difÔ¨Åcult to meas ure the effectiveness of the backsubstitution component alon e. However, since the Œ±CROWN implementation in our eval uation also served as the baseline backsubstitution metho d to which we added our methods, any difference between the two is solely due to the addition of our suggested technique. The results of our experiments are summarized in Table II. Recal l that symbolicbound propagation techniques are incomplet e, and may fail to prove a given query; the Solved columns indi cate the number of instances (out of 1000 ) that each method was able to prove to be robust to adversarial perturbations. The Time columns indicate the run time of each method (including timeouts), averaged over the 1000 benchmarks solved. Our results clearly indicate the superiority of the bounds discovered by DeepMIP: indeed, in all categories, our ap proach was able to solve the largest number of instances, solving a total of 2378 instances, compared to 2183 instance s solved by PRIMA (198 extra instances solved) and 1087 instances solved by Œ±CROWN (1291 extra instances solved). These improvements come with an overhead, due to the additional MIP queries that need to be solved: our approach is approximately 5.6 times slower than Œ±CROWN, and 2.5 times slower than PRIMA. Furthermore, DeepMIP timed out on 2 out of the 3829 total benchmarks tested ( ‚âà0.05%), while PRIMA and Œ±CROWN did not have any timeouts. The main conclusions that we draw from these experiments are that (i) the DeepMIP approach has a signiÔ¨Åcant potential for solving queries that other approaches cannot; and (ii) a d ditional work, in the form of improved heuristics, engineer ing improvements, and support for GPUs is still required to make our approach faster. Our results also indicate that a portfo lio based approach, which starts from lightweight techniques and then progresses towards DeepMIP for difÔ¨Åcult queries, coul d enjoy the beneÔ¨Åts of both worlds. VI. R ELATED WORK "
152,Verification-Aided Deep Ensemble Selection.txt,"Deep neural networks (DNNs) have become the technology of choice for
realizing a variety of complex tasks. However, as highlighted by many recent
studies, even an imperceptible perturbation to a correctly classified input can
lead to misclassification by a DNN. This renders DNNs vulnerable to strategic
input manipulations by attackers, and also oversensitive to environmental
noise.
  To mitigate this phenomenon, practitioners apply joint classification by an
*ensemble* of DNNs. By aggregating the classification outputs of different
individual DNNs for the same input, ensemble-based classification reduces the
risk of misclassifications due to the specific realization of the stochastic
training process of any single DNN. However, the effectiveness of a DNN
ensemble is highly dependent on its members *not simultaneously erring* on many
different inputs.
  In this case study, we harness recent advances in DNN verification to devise
a methodology for identifying ensemble compositions that are less prone to
simultaneous errors, even when the input is adversarially perturbed --
resulting in more robustly-accurate ensemble-based classification.
  Our proposed framework uses a DNN verifier as a backend, and includes
heuristics that help reduce the high complexity of directly verifying
ensembles. More broadly, our work puts forth a novel universal objective for
formal verification that can potentially improve the robustness of real-world,
deep-learning-based systems across a variety of application domains.","In recent years, deep learning [32] has emerged as the stateoftheart solution for a myriad of tasks. Through the automated training of deep neural networks (DNNs ), engineers can create systems capable of correctly handling previously unencountered inputs. DNNs excel at tasks ranging from image recognition and natural language processing to game playing and protein folding [2], [20], [37], [47], [75], [76], and are expected to play a key role in various complex systems [14], [43]. Despite their immense success, DNNs suffer from severe vulnerabilities and weaknesses. A prominent example is the sensitivity of DNNs to adversarial inputs [33], [48], [81], i.e., slight perturbations of correctlyclassiÔ¨Åed inputs that result in misclassiÔ¨Åcations. The susceptibility of DNNs to input perturbations involves two risks that limit the applicability of deep learning to missioncritical tasks: (1) falling victim to strategic input manipulations by attackers , and (2) failing togeneralize well in the presence of environmental noise. In light of the above, recent work has focused on enhancing the robustness of DNNbased classiÔ¨Åcation to adversarial inputs while preserving accuracy [12], [28], [62], [83], [99]. Infor mally, a classiÔ¨Åer is robustly accurate (aka astute [88]) with respect to a given distribution over inputs, if it continues to [*] This is an extended version of a paper with the same title that appeared at FMCAD 2022.correctly classify inputs drawn from this distribution, with high probability, even when these inputs are arbitrarily perturbed (up to some maximally allowed perturbation). We focus here on a classic technique for improving clas siÔ¨Åcation quality [8], [52]: combining the outputs of an ensemble [27], [36], [82] of DNNbased classiÔ¨Åers on an input to derive a joint classiÔ¨Åcation decision for that input. By incorporating the outputs of independentlytrained DNNs, ensembles mitigate the risk of misclassiÔ¨Åcation of a single DNN due to a speciÔ¨Åc realization of its stochastic training process and the speciÔ¨Åcs of its training data traversal. For a DNN ensemble to provide a meaningful improvement over utilizing a single DNN, its members should not frequently misclassify the same input. Consider, for instance, an extreme example, where an ensemble with k= 10 members is used, but for some part of the input space, the 10DNNs effectively behave identically, making mistakes on the exact same inputs. In this scenario, the ensemble as a whole is no more robust on this input subspace than each of its individual members. Our objective is to demonstrate how recent advances in DNN veriÔ¨Åcation [39], [44] can be harnessed to provide system designers and engineers with the means to avoid such scenarios, by constructing adequately diverse ensembles. SigniÔ¨Åcant progress has recently been made on formal veriÔ¨Åcation techniques for DNNs [1], [7], [10], [11], [25], [56], [68], [77], [92]. The basic DNN veriÔ¨Åcation query is to determine, given a DNN N, a precondition P, and a postcon ditionQ, whether there exists an input xsuch thatP(x)and Q(N(x))both hold. Recent veriÔ¨Åcation work has focused on identifying adversarial inputs to DNNbased classiÔ¨Åcation, or formally proving that no such inputs exist [29], [34], [58]. We demonstrate the applicability of DNN veriÔ¨Åcation to solving a new kind of queries, pertaining to DNN ensembles, which could signiÔ¨Åcantly boost the robustness of these ensembles (as opposed to just measuring the robustness of individual DNNs). We note that despite great strides in recent years [46], [58], [77], even stateoftheart DNN veriÔ¨Åcation tools face severe scalability limitations. This renders solving veriÔ¨Åcation queries pertaining to ensembles extremely challenging, since the complexity of this task grows exponentially with the number of ensemble members (see Section III). In this casestudy paper, we propose and evaluate an efÔ¨Å cient and scalable approach for verifying that different ensem ble members do not tend to err simultaneously. SpeciÔ¨Åcally, our scheme considers small subsets of ensemble members,1 and dispatches veriÔ¨Åcation queries to seek perturbations of 1While our technique is applicable to subsets of any size, we focused on pairs in our evaluation, as we later elaborate.arXiv:2202.03898v2  [cs.LG]  25 Jul 20222 inputs for which allmembers in the subset err simultaneously . By identifying such inputs, we can assign a mutual error score to each subset. Using these mutual error scores, we compute, for each individual ensemble member, a uniqueness score that signiÔ¨Åes how often it errs simultaneously with other ensemble members. This score can be used to detect the ‚Äúweakest‚Äù ensemble members, i.e. those most prone to erring in parallel to others, and replace them with fresh DNNs ‚Äî thus enhancing the diversity among the ensemble members, and improving the overall robust accuracy of the ensemble. To evaluate our scheme, we implemented it as a proof ofconcept tool, and used this tool to conduct extensive ex perimentation on DNN ensembles for classifying digits and clothing items. Our results demonstrate that by identifying the weakest ensemble members (using veriÔ¨Åcation) and replac ing them, the robust accuracy of the ensemble as a whole may be signiÔ¨Åcantly improved. Additional experiments that we conducted also demonstrate that our veriÔ¨Åcationdriven approach affords signiÔ¨Åcant advantages when compared to competing, nonveriÔ¨Åcationbased, methods. Together, these results showcase the potential of our approach. Our code and benchmarks are publicly available online [6]. The rest of the paper is organized as follows. Section II con tains background on DNN ensembles and DNN veriÔ¨Åcation. In Section III we present our veriÔ¨Åcationbased methodology for ensemble selection, and then present our case study in Section IV. Next, in Section V we compare our veriÔ¨Åcation based approach to stateoftheart, gradientbased, methods. Related work is covered in Section VI, and we conclude and discuss future work in Section VII. II. B ACKGROUND Deep Neural Networks. A deep neural network (DNN) [32] is a directed graph, comprised of layers of nodes (also known asneurons ). In feedforward DNNs, data Ô¨Çows sequentially from the Ô¨Årst ( input ) layer, through a sequence of intermediate (hidden ) layers, and Ô¨Ånally into an output layer. The network‚Äôs output is evaluated by assigning values to the input layer‚Äôs neurons and computing the value assignment for neurons in each of the following layers, in order, until reaching the output layer and returning its neuron values to the user. In classiÔ¨Åcation networks, which are our subject matter here, each output neuron corresponds to an output class ; and the output neuron with the highest value represents the class, or label, which the particular input is being classiÔ¨Åed as. v1 1 v2 1v1 2 v2 2v1 3 v2 3v1 4 v2 41 "
476,Programmatic Policy Extraction by Iterative Local Search.txt,"Reinforcement learning policies are often represented by neural networks, but
programmatic policies are preferred in some cases because they are more
interpretable, amenable to formal verification, or generalize better. While
efficient algorithms for learning neural policies exist, learning programmatic
policies is challenging. Combining imitation-projection and dataset aggregation
with a local search heuristic, we present a simple and direct approach to
extracting a programmatic policy from a pretrained neural policy. After
examining our local search heuristic on a programming by example problem, we
demonstrate our programmatic policy extraction method on a pendulum swing-up
problem. Both when trained using a hand crafted expert policy and a learned
neural policy, our method discovers simple and interpretable policies that
perform almost as well as the original.","While neural policy representations are by far the most common in modern Rein forcement Learning (RL), other representations are worth considering. Program matic policies provide a number of potential benets: For example, a program might be read and understood by a human, something that generally is not pos sible with a neural network. Programs are also inherently compositional, which allows for not only reuse of policies in new combinations, but also compositional reasoning about their behavior. However, learning programmatic policies is challenging. The structured, dis crete space of programs does not allow for the gradient based optimization that neural policies benet greatly from. Compared to a more standard inductive synthesis setting, programmatic policies must be evaluated in an environment that, whether simulated or real, is expensive to interact with. Several approaches exist that attempt to handle this interaction issue, such as learning a parametric environment model [6], imitating an existing policy [1, 14], or evaluating fewer programs by learning to search more eciently [2]. Furthermore, [13] extend thearXiv:2201.06863v1  [cs.AI]  18 Jan 20222 R. Larsen, M. N. Schmidt imitation setting by providing a framework for intertwining RL and program matic policy imitation. This imitationprojection framework brings us a step closer to programmatic RL, where programs can be learned gradually through interaction with the en vironment. Essentially, this allows similar sample eciency when compared to policy gradient methods, since the imitationprojection step is performed oine by scoring programs according to an imitation learning objective. One could even plausibly imagine that the inductive bias in a problemspecic policy language could lead to improved learning. The framework leaves many choices open in terms of how the policy update and programmatic policy projection steps are performed, as well as in terms of dening the program space. [13] perform ex periments with a specic choice of update and projection, using two tailored program spaces based on PID controllers with either decision tree regression or Bayesian optimisation over some parameters as the projection operator. In this paper we experiment with a more general program space based on Domain Specic Languages (DSLs) implemented in a typed lambda calculus. We demonstrate a method for reusing projections by local search around a previous projection, potentially reducing the required computational eort while allow ing much longer programmatic policies to be found. Since imitationprojection greatly reduces environment interaction, the presented method takes advantage of this and performs relatively large searches in program space. Demonstrating the method on the pendulum swingup task, we show that a simple and eective programmatic policy can be found by imitating a learned neural policy. 2 Methods "
446,Robustness Verification for Transformers.txt,"Robustness verification that aims to formally certify the prediction behavior
of neural networks has become an important tool for understanding model
behavior and obtaining safety guarantees. However, previous methods can usually
only handle neural networks with relatively simple architectures. In this
paper, we consider the robustness verification problem for Transformers.
Transformers have complex self-attention layers that pose many challenges for
verification, including cross-nonlinearity and cross-position dependency, which
have not been discussed in previous works. We resolve these challenges and
develop the first robustness verification algorithm for Transformers. The
certified robustness bounds computed by our method are significantly tighter
than those by naive Interval Bound Propagation. These bounds also shed light on
interpreting Transformers as they consistently reflect the importance of
different words in sentiment analysis.","Deep neural networks have been successfully applied to many domains. However, these black box models are generally difÔ¨Åcult to analyze and their behavior is not guaranteed. Moreover, it has been shown that the predictions of deep networks become unreliable and unstable when tested in unseen situations, e.g., in the presence of small adversarial perturbations to the input (Szegedy et al., 2013; Goodfellow et al., 2014; Lin et al., 2019). Therefore, neural network veriÔ¨Åcation has become an important tool for analyzing and understanding the behavior of neural networks, with applications in safetycritical applications (Katz et al., 2017; Julian et al., 2019; Lin et al., 2019), model explanation (Shih et al., 2018) and robustness analysis (Tjeng et al., 2019; Wang et al., 2018c; Gehr et al., 2018; Wong & Kolter, 2018; Singh et al., 2018; Weng et al., 2018; Zhang et al., 2018). Formally, a neural network veriÔ¨Åcation algorithm aims to provably characterize the prediction of a network within some input space. For example, given a Kway classiÔ¨Åcation model f:Rd!RK, wherefi(x)stands for the predicted score of class i, we can verify some linear speciÔ¨Åcation (deÔ¨Åned by a vector c) as below: min xX icifi(x)s.t.x2S; (1) where Sis a predeÔ¨Åned input space. In the robustness veriÔ¨Åcation problem ,S=fxjkx"
75,Equivariant neural networks and equivarification.txt,"We provide a process to modify a neural network to an equivariant one, which
we call equivarification. As an illustration, we build an equivariant neural
network for image classification by equivarifying a convolutional neural
network.","One key issue in deep neural network training is the difÔ¨Åcult y of tuning parameters, especially when the network size grows larger a nd larger [6]. In order to reduce the complexity of the network, many techniqu es have been proposed by analyzing the structural characteristics of da ta, for example, sparsity [18], invariance in movement [5]. In particular, convolutional neural network (CNN) is a type of network that uses Ô¨Ålters to reduce the number of parameters compared with fully connected networks by observing the invariance of various m ovements, such as the shift of an object in the photo [7]. However, to han dle the case of rotation and reÔ¨Çection, people usually use the data augment ation approach to generate additional input data that has a bunch of trainin g images with different rotation angles of the original images. However, these may require Date : This version: June 1, 2019. Key words and phrases. equivariant, equivariÔ¨Åcation, neural network, cnn. 12 ERKAO BAO AND LINQI SONG extra training overhead as the augmented data increase. In c ontrast to data augmentation approach, another idea is to design more sophi sticated neural networks, such that the input data with certain symmetries c an be trained together and applied to reduce the training complexity. Rec ent attempts have been made in the equivariant CNN [2, 3, 17]. These existi ng works explore several special cases of equivariÔ¨Åcation which nee d to design equi variant layers according to detailed functions of each laye r and cannot be generalized to arbitrary networks or functions. In this paper, we take advantage of the symmetry of the data an d design a scalable equivariant neural network that is able to capture and preserve the symmetries, e.g., the rotation symmetry. In stark contrast to existing works, by leveraging a group action theory, our proposed equivariÔ¨Å cation method enables to design an equivariant neural network uniformly across layers of feedforward neural networks, such as multilayer percep trons, convo lutional neural networks. A key feature is that our equivari Ô¨Åcation method can be applied without knowledge of the detailed functions o f a layer in a neural network, and hence, can be generalized to any feedfor ward neural networks. This is the reason we call our solution a uniform on e. Another important property of our designed scalable equivariant ne ural network is that the number of parameters we need to train can still be the same as the original network. In addition, we can also output how does ea ch data in stance have been changed from the original canonical form (f or example, how many degrees the cat image is rotated from original upsid eup image) using the same network. Note that, here, the equivariance is important and indispen sable, as this ensures that the structure of data is maintained and propaga ted across layers, and hence, our design method can guarantee that a uniform des ign will work across layers without the knowledge of the detailed mapping s. To be speciÔ¨Åc, leveraging group action theory, our solution provides a uniform way to modify an existing neural network to an equiva riant one, the process of which is called equivariÔ¨Åcation . Without being aware of the detailed functions of each layer, our proposed equivari Ô¨Åcation method use group theory to directly perform group actions on each la yer where the equivariant layers could easily be deployed. We theoretica lly proved that our equivariÔ¨Åcation method would be able to design an equiva riant neural network and achieve the expected performance. Practically , we equivarify a CNN as an illustration. We conduct experiments using the MN IST data set where the resulted equivariant neural network predicts the number and also the angle. If we forget the angle and keep only the number , we get an invariant neural network. The equivariance of our neural ne twork is built into the structure of the neural network, and it is independe nt of the loss function, and the data set. For example, for the training dat a, it does notEQUIV ARIANT NEURAL NETWORKS AND EQUIV ARIFICATION 3 make any difference in results whether we prepare it by rando mly rotating and recording the angles, or not rotating and labeling every thing as degree 0. 1.1. Illustration Example. Let us consider a simple cat image classiÔ¨Åca tion example. For example, consider the space of all images. One can build a cat classiÔ¨Åer that assigns a number between 0and1to each image indi cating the probability that it is an image of a cat. If one imag e is a rotation (say90degree counterclockwise) of another one, then it makes sens e to require a classiÔ¨Åer to assign the same probability to these t wo images. A classiÔ¨Åer that satisÔ¨Åes this property is said to be invariant under 90degree rotation, which is a special case of being equivariant . To give an example of an (noninvariant) equivariant neural network, we further more require our classiÔ¨Åer not only produces the probability of being a cat im age, but also outputs an angle, say in {0,90,180,270}(more precisely, the probability of each angle). Suppose that the classiÔ¨Åer predicts that an ima ge is rotated by 90degrees, then it should predict a 270degrees rotation for the same image but rotated by 180degrees. 1.2. Related Work. Equivariant mappings based on group actions are pop "
393,Discriminative Pattern Mining for Breast Cancer Histopathology Image Classification via Fully Convolutional Autoencoder.txt,"Accurate diagnosis of breast cancer in histopathology images is challenging
due to the heterogeneity of cancer cell growth as well as of a variety of
benign breast tissue proliferative lesions. In this paper, we propose a
practical and self-interpretable invasive cancer diagnosis solution. With
minimum annotation information, the proposed method mines contrast patterns
between normal and malignant images in unsupervised manner and generates a
probability map of abnormalities to verify its reasoning. Particularly, a fully
convolutional autoencoder is used to learn the dominant structural patterns
among normal image patches. Patches that do not share the characteristics of
this normal population are detected and analyzed by one-class support vector
machine and 1-layer neural network. We apply the proposed method to a public
breast cancer image set. Our results, in consultation with a senior
pathologist, demonstrate that the proposed method outperforms existing methods.
The obtained probability map could benefit the pathology practice by providing
visualized verification data and potentially leads to a better understanding of
data-driven diagnosis solutions.","Breast cancer is the second most common cancer in women. Invasive, malignant properties of breast cancer cell growth contribute to poor patient prognosis [1], and dictate precise early diagnosis and treatment, with an aim to reduce breast cancer morbidity rate. In this study, we particularly focus on the qualiÔ¨Åcation of risky, aggressive characteristics of breast histomorphological patterns, as one of the basic features of invasiveness of breast carcinoma. With the advance of imaging device and machine learning technology, digital histopathology image analysis becomes a promising approach to consistent and costefÔ¨Åcient cancer diagnosis. Particularly for invasive breast cancer, based on the common knowledge that cancerous cells break through the basement membrane of ductulolobular structures and inÔ¨Åltrate Xingyu Li (xingyu.li@mail.utoronto.ca) and Konstantinos N. Plataniotis (kostas@ece.utoronto.ca) are with Multimedia Lab, The Edward S. Rogers Department of Electrical and Computer Engineering, University of Toronto, Toronto, Ontario, Canada. Marko Radulovic and Ksenija Kanjer are with the National Cancer Research Centre, Department of Experimental Oncology, Institute for Oncology and Radiology, Belgrade, Serbia. ¬©20xx IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works. Fig. 1. Examples of hemotoxylin and eosin stained images for (a) normal breast tissue and (b) invasive carcinoma with a magniÔ¨Åcation of 40. The left image corresponds to a normal tissue where normal epithelial cells lie on the membrane of ductulolobular structures; while in the right image malignant cells invade and spread into surrounding tissue. into surrounding tissues  the feature of invasiveness [2] (as shown in Fig. 1), many algorithms were proposed to classify breast histopathology images using nuclei‚Äôs morphology and spatialdistribution features [3]. In literature, the most common solution to breast cancer image diagnosis is to train a classiÔ¨Åer in a supervised learning manner. Then handcrafted features of a query image are passed to the trained algorithm for a yes/no label [4]‚Äì[10]. With the success of deep learning, datadriven methods, especially the endtoend training of convolutional neural network, are adopted more often in recent breast cancer histopathology image classiÔ¨Åcation studies [11]‚Äì[13]. Though breast cancer image diagnosis has achieved impressive progress, the issue of selfinterpretability in existing diagnosis approaches is less addressed. Selfinterpretability refers to the capability of an approach to explain and verify its reasoning and results. Without selfinterpretability, attempts to improve histopathology image diagnosis is prone to be limited to trial anderror. To address the selfinterpretability issue in breast cancer pathology image diagnosis, one solution is to generate labels for image pixels or small image patches in order to infer loca tions of suspected abnormalities in a query image. To this end, several studies made efforts to classify small image patches or pixels via supervised/semisupervised learning [14]‚Äì[18]. It should be noted that these solutions require a large amount of images manuallyannotated at the image pixel level. Due to the complexity and timeintensive properties of pathological annotations and privacy concerns in clinical practice, sufÔ¨Åcient amount of welllabeled patches are difÔ¨Åcult to collect. This study attempts to tackle the selfinterpretability issue in breast cancer diagnosis and presents a novel convolutionalarXiv:1902.08670v3  [cs.CV]  5 May 20202 autoencoderbased contrast pattern mining approach to detect the invasive component of malignant breast epithelial growth in routine hematoxylin and eosin (H&E) stained histopathol ogy images. As opposed to prior studies that require image sets with pixel annotation, our method requires only image labels as the minimal prior knowledge in training. By mining dom inant patterns in images of normal breast tissues, the method generates a probability map to infer locations of abnormalities in an image. As a pathology image may contain both normal and cancerous tissues, the proposed method divides an image into small patches to facilitate local characteristics learning. It should be noted that due to the lack of pixel annotation indicating the locations of abnormal cell growth patterns in images, this problem is very challenging in two folds. 1) The algorithm is expected to learn contrast patterns between normal and malignant/invasive growth based on the knowledge of image labels. Effective differen tiation between normal and abnormal histomorphology via unsupervised learning is the key issue for the correct identiÔ¨Åcation of cancerous growth. 2) As a histopathology image may contain both normal and cancerous tissue, labels of local patches may be inconsistent with the known image label. The method needs to learn a mapping function between local patches and image labels. Note that though we do not know whether patches from images labeled as malignant really contain malignant cells/structures, patches from normal images do not contain cancerous cells certainly. So, we name a patch from a normal image ‚Äùtruenormal‚Äù in this paper. Our original approach learns patterns in truenormal patches Ô¨Årst and then assigns a normal/malignant label to a patch which resembles/deviates from those true normal ones. Intuition behind this originality is that in pathology, malignant cells and their growth patterns are diagnosed and graded by how different these cells are to normal cells. SpeciÔ¨Åcally, to address the Ô¨Årst challenge, we exploit the dataspeciÔ¨Åc property of autoencoder (AE) networks [19], [20] and innovate to train an undercomplete deep fully convolutional AE using small patches from pathol ogy images annotated as normal. Since the network learns local patterns in truenormal patches only, its performance degrades when the input instance is different from training patches. Hence, autoencoder‚Äôs reconstruction residue suggests the similarity between the query instance and normal cases. It is noteworthy that different from standard autoencoders targeting to minimize mean square error (MSE) between input and output training instances, the proposed method trains the deep net by optimizing the structural similarity (SSIM) index [21], which enforces the network to learn the contrast and structural patterns in truenormal patches. In this study, the trained AE network is treated as a pattern mining and represen tation method and then combined with downstream classiÔ¨Åers to identify whether an image patch contains malignant cells. To tackle the second challenge which is to infer whether a local patch contains morphological abnormalities derived by malignant cell growth, we cast the problem into the anomaly detection scenario, and introduce a novel malignant patchdetector to distinguish patches containing cancerous cells from the normal ones. Particularly, the proposed detector makes the use of one class support vector machine (SVM) [22] to identify regions occupied by truenormal patches in the feature space and assigns abnormal labels to patches whose numerical features are located outside of the detected normal regions. Taking into account the obtained patch labels, the problem of breast cancer image classiÔ¨Åcation with localization of abnormality areas is simpliÔ¨Åed to a patchbased supervised learning problem. Finally, a 1 layer neural network (NN) is trained to infer the existence of malignant tumor in a patch, followed by the generation of a probability map of abnormality in the query image. In summary, this study proposes a practical, generalizable, and selfinterpretable solution to pathology image based can cer diagnosis. With the minimal prior knowledge on whose slideimaging (WSI) labels which can be easily acquired in clinic practice, the proposed method learns discriminative patterns in unsupervised manner from histopathology images and explains its diagnosis results via inferring locations of abnormalities in an image. It is noteworthy that the proposed method is very userfriendly to pathologists, as the obtained abnormality map helps pathologists to understand and verify how machines make decisions. To the best of our knowledge, our work constitutes the Ô¨Årst attempt in literature to tackle the selfinterpretability issue in histopathology image classiÔ¨Åca tion. The rest of this paper is organized as follows. Section II provides brief introduction of machine learning techniques exploited in the proposed method and the public breast cancer biopsy image set used in this study. The problem‚Äôs formal statement with notations and implementation details are presented in Section III and Section IV, respectively. Experimental results and discussions are presented in Section V, followed by conclusions in Section VI. II. B ACKGROUND In this section, we will Ô¨Årst introduce notations used in this study in Table I. Then brief description of fully convo lutional autoencoder and oneclass support vector machine is presented, followed by information on the public image set used to evaluate the proposed method in this study. A. Fully Convolutional AE Networks Fully convolutional network is deÔ¨Åned as the neural network composed of convolutional layers without any fullyconnected layers [23]. It learns representations and makes decisions based on local spatial knowledge only. Because of its efÔ¨Åcient learning, fully convolutional net has been popular in many imagetoimage inference tasks, e.g. semantic segmentation. Fully convolutional autoencoder is one instance of fully convolutional neural networks. The net takes input of arbitrary size and produces correspondingsized output. SpeciÔ¨Åcally, it encodes an image data xof arbitrary size into a low dimensional representation ^xsuch that the important properties of the original data can be reconstructed and maintained in the output ~x. Mathematically, a fully convolutional autoencoder is3 TABLE I TABLE OF NOTATIONS . Notations Explanations A,B Trainable parameters of 1layer NN D() Decorder of AE E() Encoder of AE F() Patch labeling function G() Decision function of oneclass SVM I Histopathology image L Loss function of AE M Number of normal images N Number of malignant images T Number of training patches c, Hyperparameter of oneclass SVM k() Gaussian kernel wi,vi Trainable parameteres of AE x Input of AE (i.e. greayscale truenormal patches) ~x Output of AE ~x residue of AE‚Äôs reconstruction y Patch labels z Input of oneclass SVM y Histopathology image Label ;;  Hyperparameters of SSIM () Dirac delta function  Lagrangian multiplier of oneclass SVM composed of an encoder E()and a decorderD(), each of which is a composition of a sequence of Clayers, i.e. ~x=D(^x;v1;:::;vC) (1) =D(E(x;w1;:::;wC);v1;:::;vC); where ~x=D(^x;v1;:::;vC) =DC(;vC)D 1(^x;v1)and ^x=E(x;w1;:::;wC) =EC(;wC)E 1(x;w1).D()E(x) = D(E(x))and wiand viare the weights and bias for the ithencoder layerEi()and decoder layer Di(), respectively. Conventionally,Ei()performs one of the following operations: a) convolution with a bank of Ô¨Ålters, b) downsample by spatial pooling, and c) nonlinear activation; and Di()takes actions including: d) convolution with a bank of deconvolution Ô¨Ålters, e) upsample by interpolations, and f) nonlinear activation. Given a set of Ttraining samplefx1;:::;xTg, the parameter set of autoencoder fwk;vk;0< kCgis optimized such that reconstruction ~xresembles input x: arg min wk;vk;0<kC1 TTX i=1L(xi;~xi); (2) whereLis a loss function measuring the similarity between xiand~xi, e.g. MSE. B. Oneclass Support Vector Machine Oneclass SVM is an approach for semisupervised anomaly detection. It models the normal data as a single class that occupies a dense subset of the feature space corresponding to the kernel and aims to Ô¨Ånd the ‚Äùnormal‚Äù regions. A test instance that resides in such a region is accepted by the model whereas anomalies are not [22]. That is, it returns a function for inputzthat takes the value +1 in the small region capturing most of normal points, and 1 elsewhere. With the training setfz1;:::;zTg, the duel problem of the oneclass SVM solution can be formulated by min i;0<iT1 2TX i;j=0ijk(zi;zj) (3) s.t. 0<i1 T;TX i=0i= 1; (4) whereiis a Lagrangian multiplier for sample zi,k(zi;zj) = e"
409,Safe Networked Robotics with Probabilistic Verification.txt,"Autonomous robots must utilize rich sensory data to make safe control
decisions. To process this data, compute-constrained robots often require
assistance from remote computation, or the cloud, that runs compute-intensive
deep neural network perception or control models. However, this assistance
comes at the cost of a time delay due to network latency, resulting in past
observations being used in the cloud to compute the control commands for the
present robot state. Such communication delays could potentially lead to the
violation of essential safety properties, such as collision avoidance. This
paper develops methods to ensure the safety of robots operated over
communication networks with stochastic latency. To do so, we use tools from
formal verification to construct a shield, i.e., a run-time monitor, that
provides a list of safe actions for any delayed sensory observation, given the
expected and maximum network latency. Our shield is minimally intrusive and
enables networked robots to satisfy key safety constraints, expressed as
temporal logic specifications, with desired probability. We demonstrate our
approach on a real F1/10th autonomous vehicle that navigates in indoor
environments and transmits rich LiDAR sensory data over congested WiFi links.","Today, an increasing number of robotic applications re quire remote assistance, ranging from remote manipula tion for surgery [1] to emergency takeover of autonomous vehicles [2]. Teleoperation is often used to collect rich demonstration data for imitation learning [3] or even to control fleets of food delivery robots from command cen ters hundreds of miles away [4]. For robots operated over communication networks, network latency is a key concern for safe operation since actuation based on delayed state information can lead to unsafe behavior. Despite the rise of robots operating over communication networks, we lack formal guarantees for their safe operation. Today‚Äôs approaches for robotic safety range from reachability analysis [5], [6], [7], [8] to shielding that restricts unsafe actions based on a formal safety specification [9], [10], [11], [12]. However, there is little to no research that provides such rigorous safety analysis for networked robotics. This paper asks: How do we ensure safe networked control over wireless networks with stochastic communication delays? Communication delay is the cumulative time delay in sending the observation to the cloud and receiving an action back at the robot. We develop the intuition that if the interac tion between a remotely controlled robot and the surrounding ‚àóEqual contribution.‚Ä†Corresponding author. 1Sai Shankar Narasimhan, Sharachchandra Bhat, and Sandeep P. Chin chali are affiliated with the department of Electrical and Computer En gineering, The University of Texas at Austin, USA. {nsaishankar, sharachchandra, sandeepc }@utexas.edu Environment RobotObservation (1) Shield (3)Safe action (4) Action (2) Measured WiFi Latency DNN Fig. 1: Safe Networked Control for Robotics: A resourceconstrained robot transfers sensor observations (RGBD images or LiDAR point clouds) through a wireless network with stochastic latency. At the receiving end, a control module or a human teleoperator processes the observation to generate the corresponding action. The action is filtered by the shield, which enforces a particular safety specification that the robot has to maintain. The filtered, ‚Äúsafe‚Äù action is then executed by the robot. environment can be modeled as a Markov Decision Process (MDP) (which is often the case), then the communication delay is analogous to sensing or actuation delays. A plethora of work has modeled MDPs with sensing and actuation delays for Networked Control Systems (NCS) [13], [14], [15]. However, these studies often rely on assumptions such as constant delays [13], [15] or that the delay between consecutive time steps cannot reduce [14]. In this paper, we propose Delayed Communication MDP, a novel approach to model MDPs with delays that aligns naturally with the transmission of observations and control commands when operating a robot via wireless networks in practice. Fig. 1 shows our approach, tested on a real F1/10th autonomous racecar [16] controlled over a wireless link. Our approach is extremely general ‚Äì we can either have a remote human teleoperator or an automatic controller running in the cloud. For example, if our robot is constrained by computing, memory, or power, it can offload the inference of a Deep Neural Network (DNN) perception model and deep reinforcement learning (RL) controller to the cloud. First, sensor observations (RGBD images or LiDAR point clouds) are transferred via wireless links (step 1) and processed to compute the corresponding control command (step 2). The control command is transmitted back to the robot and filtered by the shield. The shield is a runtime monitor, constructed offline, that disallows actions that violate a formal safety specification. Since the shield runs on the robot, it has access to the delay corresponding to the received control command.arXiv:2302.09182v3  [cs.RO]  12 Jul 2023Finally, the robot implements the shielded action (steps 3 4), which guarantees safe behavior amidst stochastic network latency. We design the shield using tools from formal veri fication [17], given knowledge of the network latency and a model of the surrounding environment‚Äôs behavior. Shields, as implemented in [9], provide an absolute mea sure of safety. For networked control with stochastic network latency, patching the cloud control commands with shields results in perfectly safe operation at the cost of task effi ciency. In this paper, we propose a shield synthesis approach that, when combined with the cloud controller, allows the networked control system to meet safety requirements with a desired probability. Our experimental findings indicate that a slight reduction in the desired safety probability leads to a significant increase in task efficiency. In this paper, 1) We present the Delayed Communication MDP, a novel approach that accurately models the interaction between a remotely controlled robot and the environment, in the presence of stochastic network latency. 2) We propose an algorithm to synthesize a shield that, when executed with the cloud controller, guarantees the desired probability of satisfying a safety property. 3) We demonstrate our approach in simulation as well as on an F1/10th autonomous vehicle that must closely (and safely) follow an unpredictable leader in indoor environments over congested wireless networks (Fig. 2). II. R ELATED WORK "
330,Efficiently Computing Local Lipschitz Constants of Neural Networks via Bound Propagation.txt,"Lipschitz constants are connected to many properties of neural networks, such
as robustness, fairness, and generalization. Existing methods for computing
Lipschitz constants either produce relatively loose upper bounds or are limited
to small networks. In this paper, we develop an efficient framework for
computing the $\ell_\infty$ local Lipschitz constant of a neural network by
tightly upper bounding the norm of Clarke Jacobian via linear bound
propagation. We formulate the computation of local Lipschitz constants with a
linear bound propagation process on a high-order backward graph induced by the
chain rule of Clarke Jacobian. To enable linear bound propagation, we derive
tight linear relaxations for specific nonlinearities in Clarke Jacobian. This
formulate unifies existing ad-hoc approaches such as RecurJac, which can be
seen as a special case of ours with weaker relaxations. The bound propagation
framework also allows us to easily borrow the popular Branch-and-Bound (BaB)
approach from neural network verification to further tighten Lipschitz
constants. Experiments show that on tiny models, our method produces comparable
bounds compared to exact methods that cannot scale to slightly larger models;
on larger models, our method efficiently produces tighter results than existing
relaxed or naive methods, and our method scales to much larger practical models
that previous works could not handle. We also demonstrate an application on
provable monotonicity analysis. Code is available at
https://github.com/shizhouxing/Local-Lipschitz-Constants.","Lipschitz constants are important for characterizing many properties of neural networks, including robustness [ 43,19,44,58,21], fairness [ 12,24], generalization [ 3], and explanation [ 14]. Local Lipschitz constants, which only need to hold for a small local region, can more precisely characterize the local behavior of a network. Intuitively they characterize how fast the output of the network changes between any two input within the region. It is challenging to exactly and efÔ¨Åciently compute local Lipschitz constants. Naive approaches such as computing the product of the induced norm for all layers cannot capture local information and typically produce vacuous bounds. To compute tight and exact local Lipschitz constants, Jordan & Dimakis [23] considered small ReLU networks (e.g., up to tens of neurons), by solving a mixedinteger programming (MIP) problem to bound the norm of Clarke‚Äôs generalized Jacobian [ 8]. However, solving MIP is often too costly and cannot scale to slightly larger networks. On the other hand, RecurJac [ 58] (an improved version of FastLip [ 50]) is a specialized recursive algorithm for bounding the Jacobian and computing local Lipschitz constants, which is also relatively efÔ¨Åcient but the produced bounds are relatively loose. Moreover, most of the existing works on local Lipschitz constants only used small toy models and cannot feasibly handle larger practical networks. 36th Conference on Neural Information Processing Systems (NeurIPS 2022).arXiv:2210.07394v1  [cs.LG]  13 Oct 2022Recently, in the Ô¨Åeld of neural network veriÔ¨Åcation, many methods are proposed to compute provable output bounds for neural networks [ 25,6,11]; especially, linear bound propagation methods [ 51, 47,57,40] are becoming very successful [ 48,60] because they are scalable and can be efÔ¨Åciently accelerated on GPUs. These methods propagate the linear relationship between layers, where nonlinearities in networks are relaxed into linear bounds. In this work, we ask the question if we can borrow these successful techniques from neural network veriÔ¨Åcation to scale up the computation of local Lipschitz constants to larger and more practical networks. In this paper, we aim to efÔ¨Åciently compute relatively tight `1local Lipschitz constants for neural networks using the bound propagation framework. We formulate this problem as upper bounding the`1norm of the Clarke Jacobian, and we formulate the computation for the Clarke Jacobian from a chain rule and its norm as a higherorder backward computational graph augmented to the original forward graph of the network. On the augmented computational graph, we generalize linear bound propagation to bound the Clarke Jacobian, and we thereby reformulate the problem of computing local Lipschitz constants under a linear bound propagation framework. On the backward graph, applying Clarke gradients in the chain rule is nonlinear and requires a linear relaxation. It is essentially formed by a group of functions and is different from single activation functions in regular neural network veriÔ¨Åcation. We propose a tight and closedform linear relaxation for Clarke gradients with an optimality guarantee on the tightness, and thereby we efÔ¨Åciently bound the Clarke Jacobian with linear bound propagation. We also show that RecurJac is a special case under our formulation where loose interval bounds instead of tight linear relaxation are used for nontrivial cases. Our formulation also allows us to develop a scalable and Ô¨Çexible framework enhanced by progress from recent neural network veriÔ¨Åers using linear bound propagation. We demonstrate that we can further tighten our bounds by BranchandBound when time budget allows, for a tradeoff between tightness and time cost. Experiments show that our method efÔ¨Åciently produces tightest `1local Lipschitz constants compared to other relaxed methods, and is much more efÔ¨Åcient than the exact MIP method. Moreover, our method scales to much larger models including practical convolutional neural networks (CNN) that previous works could not handle. We also demonstrate an application of our method for provably analyzing the monotonicity of neural networks. 2 Related Work "
346,General Cutting Planes for Bound-Propagation-Based Neural Network Verification.txt,"Bound propagation methods, when combined with branch and bound, are among the
most effective methods to formally verify properties of deep neural networks
such as correctness, robustness, and safety. However, existing works cannot
handle the general form of cutting plane constraints widely accepted in
traditional solvers, which are crucial for strengthening verifiers with
tightened convex relaxations. In this paper, we generalize the bound
propagation procedure to allow the addition of arbitrary cutting plane
constraints, including those involving relaxed integer variables that do not
appear in existing bound propagation formulations. Our generalized bound
propagation method, GCP-CROWN, opens up the opportunity to apply general
cutting plane methods for neural network verification while benefiting from the
efficiency and GPU acceleration of bound propagation methods. As a case study,
we investigate the use of cutting planes generated by off-the-shelf mixed
integer programming (MIP) solver. We find that MIP solvers can generate
high-quality cutting planes for strengthening bound-propagation-based verifiers
using our new formulation. Since the branching-focused bound propagation
procedure and the cutting-plane-focused MIP solver can run in parallel
utilizing different types of hardware (GPUs and CPUs), their combination can
quickly explore a large number of branches with strong cutting planes, leading
to strong verification performance. Experiments demonstrate that our method is
the first verifier that can completely solve the oval20 benchmark and verify
twice as many instances on the oval21 benchmark compared to the best tool in
VNN-COMP 2021, and also noticeably outperforms state-of-the-art verifiers on a
wide range of benchmarks. GCP-CROWN is part of the $\alpha,\!\beta$-CROWN
verifier, the VNN-COMP 2022 winner. Code is available at
http://PaperCode.cc/GCP-CROWN","Neural network (NN) veriÔ¨Åcation aims to formally prove or disprove certain properties (e.g., cor rectness and safety properties) of a NN under a certain set of inputs. These methods can provide worstcase performance guarantees of a NN, and have been applied to missioncritical applications that involve neural networks, such as automatic aircraft control [ 31,4], learningenabled cyberphysical systems [54], and NN based algorithms in an operating system [51]. The NN veriÔ¨Åcation problem is generally NPcomplete [ 30]. For piecewise linear networks, it can be encoded as a mixed integer programming (MIP) [ 53] problem with the nonlinear ReLU neurons 36th Conference on Neural Information Processing Systems (NeurIPS 2022).arXiv:2208.05740v2  [cs.LG]  4 Dec 2022described by binary variables. Thus, fundamentally, the NN veriÔ¨Åcation problem can be solved using the branch and bound (BaB) [ 10] method similar to generic MIP solvers, by branching some binary variables and relaxing the rest into a convex problem such as linear programming (LP) to obtain bounds on the objective. Although early neural network veriÔ¨Åers relied on offtheshelf CPUbased LP solvers [ 36,9] for bounding in BaB, LP solvers do not scale well to large NNs. Thus, many recent veriÔ¨Åers are instead based on efÔ¨Åcient and GPUaccelerated algorithms customized to NN veriÔ¨Åcation, such as bound propagation methods [ 60,57], Lagrangian decomposition methods [ 8,17] and others [ 16,11]. Bound propagation methods, presented in a few different formulations [ 58, 18,56,61,50,25], empower stateoftheart NN veriÔ¨Åers such as ;CROWN [ 61,60,57] and VeriNet [ 3], and can achieve two to three orders of magnitudes speedup compared to solving the NN veriÔ¨Åcation problem using an offtheshelf solver directly [57], especially on large networks. Despite the success of existing NN veriÔ¨Åers, we experimentally Ô¨Ånd that stateoftheart NN veriÔ¨Åers may timeout on certain hard instances which a generic MIP solver can solve relatively quickly, sometimes even without branching. Compared to an MIP solver, a crucial factor missing in most scalable NN veriÔ¨Åers is the ability to efÔ¨Åciently generate and solve general cutting planes (or ‚Äúcuts‚Äù). In generic MIP solvers, cutting planes are essential to strengthen the convex relaxation, so that much less branching is required. Advanced cutting planes are among the most important factors in modern MIP solvers [ 6]; they can strengthen the convex relaxation without removing any valid integer solution from the MIP formulation. In the setting of NN veriÔ¨Åcation, cutting planes reÔ¨Çects complex intralayer and interlayer dependencies between multiple neurons, which cannot be easily captured by existing bound propagation methods with single neuron relaxations [ 45]. This motivates us to seek the combination of efÔ¨Åcient bound propagation method with effective cutting planes to further increase the power of NN veriÔ¨Åers. A few key factors make the inclusion of general cutting planes in NN veriÔ¨Åers quite challenging. First, existing efÔ¨Åcient bound propagation frameworks such as CROWN [ 61] andCROWN [ 57] cannot solve general cutting plane constraints that may involve variables across different layers in the MIP formulation. Particularly, these frameworks do not explicitly include the integer variables in the MIP formulation that are crucial when encoding many classical strong cutting planes, such as Gomory cuts and mixed integer rounding (MIR) cuts. Furthermore, although some existing works [ 47,52,40] enhanced the basic convex relaxation used in NN veriÔ¨Åcation (such as the Planet relaxation [ 19]), these enhanced relaxations involve only one or a few neurons in a single layer or two adjacent layers, and are not general enough. In addition, an LP solver is often required to handle these additional cutting plane constraints [ 40], for which the efÔ¨Åcient and GPUaccelerated bound propagation cannot be used, so the use of these tighter relaxations may not always bring improvements. In this paper, we achieve major progress in using general cutting planes in bound propagation based NN veriÔ¨Åers. To mitigate the challenge of efÔ¨Åciently solving general cuts, our Ô¨Årst contribution is to generalize existing bound propagation methods to their most general form, enabling constraints involving variables from neurons of any layer as well as integer variables that encode the status of a ReLU neuron. This allows us to consider any cuts during bound propagation without relying on a slow LP solver, and opens up the opportunity for using advanced cutting plane techniques efÔ¨Åciently for the NN veriÔ¨Åcation problem. Our second contribution involves combining a cuttingplanefocused, offtheshelf MIP solver with our GPUaccelerated, branchingfocused bound propagation method capable of handling general cuts. We entirely disable branching in the MIP solver and use it only for generating high quality cutting planes not restricting to neurons within adjacent layers. Although an MIP solver often cannot verify large neural networks, we Ô¨Ånd that they can generate high quality cutting planes within a short time, signiÔ¨Åcantly helping bound propagation to achieve better bounds. Our experiments show that general cutting planes can bring signiÔ¨Åcant improvements to NN veriÔ¨Åers: we are the Ô¨Årst veriÔ¨Åer that completely solves allinstances in the oval20 benchmark, with an average time of less than 5 seconds per instance; on the even harder oval21 benchmark in VNN COMP 2021 [ 3], we can verify twice as many instances compared to the competition winner. We also outperform existing stateoftheart boundpropagationbased methods including those using multineuron relaxations [20] (a limited form of cutting planes). 2 Background The NN veriÔ¨Åcation problem We consider the veriÔ¨Åcation problem for an Llayer ReLUbased Neural Network (NN) with inputs ^x(0):=x2Rd0, weights W(i)2Rdidi"
406,Deep Spiking Convolutional Neural Network for Single Object Localization Based On Deep Continuous Local Learning.txt,"With the advent of neuromorphic hardware, spiking neural networks can be a
good energy-efficient alternative to artificial neural networks. However, the
use of spiking neural networks to perform computer vision tasks remains
limited, mainly focusing on simple tasks such as digit recognition. It remains
hard to deal with more complex tasks (e.g. segmentation, object detection) due
to the small number of works on deep spiking neural networks for these tasks.
The objective of this paper is to make the first step towards modern computer
vision with supervised spiking neural networks. We propose a deep convolutional
spiking neural network for the localization of a single object in a grayscale
image. We propose a network based on DECOLLE, a spiking model that enables
local surrogate gradient-based learning. The encouraging results reported on
Oxford-IIIT-Pet validates the exploitation of spiking neural networks with a
supervised learning approach for more elaborate vision tasks in the future.","Computer vision has shown great progress with the advent of ArtiÔ¨Åcial Neural Networks (ANN) and deep learning, which achieves stateoftheart performance for most vision tasks [1]. However, modern deep learning approaches require a high computational complexity, which leads to high energy consumption. Although many works focus on reducing the computational complexity of ANNs [2], they are still energy intensive compared to the biological brain, which only requires around two dozens of Watts for its full activity. Therefore, bioinspired methods are good candidates to design lowpower solutions and solve the problem of energy consumption. Spiking Neural Networks (SNNs), often known as the third generation of neural networks [3], are strongly inspired from biological neurons [4]. They consist of spiking neurons, which communicate through discrete spatiotemporal events called‚Äùspikes‚Äù. As opposed to ANNs, they are amenable to imple mentation in efÔ¨Åcient and lowpower neuromorphic hardware [5]. However, their performance is still behind ANNs. It can be explained by the nondifferentiable nature of spikes, making it impossible to use the standard backpropagation algorithm [6]. Concerning computer vision using SNNs, their applications in computer vision are still limited compared to ANNs. One of the reasons is that many research papers mainly focus on simple tasks like digit recognition [7]. Therefore, we argue that there is a lack of works aiming at more complex computer vision tasks with SNNs (e.g. object detection). Our objective in this paper is to validate the ability of SNNs trained with recent supervised methods [8] to deal with more complex vision tasks. To do so, we propose a Deep Convolutional SNN (DCSNN) to perform object localization of one object in grayscale images, as a Ô¨Årst step towards a fully functional object detection solution. Our proposed DCSNN is based on Deep Continuous Local Learning (DECOLLE) [9], a spiking model based on supervised local synaptic plasticity rule. We report proofofconcept results on OxfordIIITPet [10] and discuss the perspective of this preliminary work. The rest of the paper is organized as follows: Section II discusses the existing works on SNNs related to vision tasks and training methods. Section III formulates the preliminary notions on SNNs and brieÔ¨Çy introduces DECOLLE. Section IV describes our DCSNN approach based on DECOLLE. Section V reports our experimental proofofconcept for object localization using DCSNN. Section VI concludes our work and discusses the perspectives for our approach. II. R ELATED WORKS "
85,InFIP: An Explainable DNN Intellectual Property Protection Method based on Intrinsic Features.txt,"Intellectual property (IP) protection for Deep Neural Networks (DNNs) has
raised serious concerns in recent years. Most existing works embed watermarks
in the DNN model for IP protection, which need to modify the model and lack of
interpretability. In this paper, for the first time, we propose an
interpretable intellectual property protection method for DNN based on
explainable artificial intelligence. Compared with existing works, the proposed
method does not modify the DNN model, and the decision of the ownership
verification is interpretable. We extract the intrinsic features of the DNN
model by using Deep Taylor Decomposition. Since the intrinsic feature is
composed of unique interpretation of the model's decision, the intrinsic
feature can be regarded as fingerprint of the model. If the fingerprint of a
suspected model is the same as the original model, the suspected model is
considered as a pirated model. Experimental results demonstrate that the
fingerprints can be successfully used to verify the ownership of the model and
the test accuracy of the model is not affected. Furthermore, the proposed
method is robust to fine-tuning attack, pruning attack, watermark overwriting
attack, and adaptive attack.","DEEP Neural Networks (DNN) have been widely de ployed in many domains. Training a highperformance DNN model requires a large amount of labeled data, comput ing resources and expert knowledge, and the training process is very timeconsuming [1]. Hence, the welltrained DNN model can be considered as valuable intellectual property (IP) of the model owner and needs to be protected from being infringed. Most existing DNN IP protection methods (e.g., [2]‚Äì[5]) aim to embed the watermark into the DNN model in the training stage. For example, parameterbased work [2] embed watermark into the parameters of the model. Backdoorbased methods [4], [5] use backdoor instances with speciÔ¨Åc labels to verify the ownership of the DNN model. However, all the existing methods lack of interpretability, which is emerged as an important requirement for DNN intellectual property protection. In this paper, we propose the Ô¨Årst interpretable DNN Intellectual P roperty protection method based on In trinsic Features (InFIP), which does not require to modify the DNN model. We extract intrinsic features of the DNN model as its Ô¨Ångerprints for ownership veriÔ¨Åcation. The intrinsic features of the DNN model are extracted by Deep Taylor Decomposition M. Xue, X. Wang, Y . Wu, S. Ni, Y . Zhang are with the College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, China. W. Liu is with the College of Electronic and Information Engineering, Nanjing University of Aeronautics and Astronautics, Nanjing, China.(DTD) [6] method. In DTD, the neurons of the model can be decomposed on input variables (i.e., pixels). The decomposi tion of the neurons are aggregated into a saliency map, which is regarded as the Ô¨Ångerprint of the model. Since the Ô¨Ångerprint indicates the relevance between each pixel in the image and the decision of the model, the Ô¨Ångerprint can uniquely represent the DNN model, which is used to verify the ownership of the model. The structural similarity index measure (SSIM) [7] is used to calculate the similarity between the Ô¨Ångerprints of the original model and the suspected model. If the average SSIM is greater than the threshold T, the model owner can claim the ownership of the suspected model. Otherwise, the suspected model is not the pirated model. Experimental results demonstrate that the proposed method can effectively verify the ownership of the model. Moreover, when the model is modiÔ¨Åed by Ô¨Ånetuning attack, pruning attack, watermark overwriting attack or adaptive attack, the Ô¨Ångerprint is still robust for ownership veriÔ¨Åcation. The main contributions of this paper are fourfold: For the Ô¨Årst time, we propose an explainable intellectual property protection method for DNN. SpeciÔ¨Åcally, we utilize DTD to extract the intrinsic features of the model. Then the intrinsic features is converted as Ô¨Ångerprint images which can uniquely represent the DNN model. These Ô¨Ångerprints are used to verify the ownership of the model. Compared with most existing DNN IP protection meth ods, we extract Ô¨Ångerprints of the DNN model for own ership veriÔ¨Åcation instead of embedding any watermarks into the DNN model. In other words, the Ô¨Ångerprint is extracted from the clean DNN model, thus, the proposed IP protection method does not require to modify the DNN model. The computational overhead of the proposed method is much lower than existing watermarking methods. Specif ically, existing watermarking methods require to Ô¨Åne tune the model or even train the model from scratch to embed the watermark. In comparison, the proposed method extracts Ô¨Ångerprints from models by inputting a batch of images, which will not introduce any extra training. The proposed method is demonstrated to be robust against model Ô¨Ånetuning attack, model pruning attack, water mark overwriting attack and adaptive attack. The rest of this paper is organized as follows. Related works on DNN IP protection are reviewed in Section II. The proposed method is presented in Section III. Experimental results arearXiv:2210.07481v1  [cs.CV]  14 Oct 20222 discussed in Section IV. This paper is concluded in Section V. II. R ELATED WORKS "
352,ExClaim: Explainable Neural Claim Verification Using Rationalization.txt,"With the advent of deep learning, text generation language models have
improved dramatically, with text at a similar level as human-written text. This
can lead to rampant misinformation because content can now be created cheaply
and distributed quickly. Automated claim verification methods exist to validate
claims, but they lack foundational data and often use mainstream news as
evidence sources that are strongly biased towards a specific agenda. Current
claim verification methods use deep neural network models and complex
algorithms for a high classification accuracy but it is at the expense of model
explainability. The models are black-boxes and their decision-making process
and the steps it took to arrive at a final prediction are obfuscated from the
user. We introduce a novel claim verification approach, namely: ExClaim, that
attempts to provide an explainable claim verification system with foundational
evidence. Inspired by the legal system, ExClaim leverages rationalization to
provide a verdict for the claim and justifies the verdict through a natural
language explanation (rationale) to describe the model's decision-making
process. ExClaim treats the verdict classification task as a question-answer
problem and achieves a performance of 0.93 F1 score. It provides subtasks
explanations to also justify the intermediate outcomes. Statistical and
Explainable AI (XAI) evaluations are conducted to ensure valid and trustworthy
outcomes. Ensuring claim verification systems are assured, rational, and
explainable is an essential step toward improving Human-AI trust and the
accessibility of black-box systems.","Information on the web has grown remarkably in the recent few decades, and misinformation has become a signiÔ¨Åcant challenge. Misinformation can weaken public trust in institu tions, and economies. For instance, in 2013 Associated Press published a false tweet claiming that President Barack Obama suffered injuries from an explosion in the White House and within seconds S&P 500 lost $130 billion in stock value [1]. The impact of such information is not only on global Copyright and Reprint Permission: Abstracting is permitted with credit to the source. Libraries are permitted to photocopy beyond the limit of U.S. copyright law for private use of patrons those articles in this volume that carry a code at the bottom of the Ô¨Årst page, provided the percopy fee indicated in the code is paid through Copyright Clearance Center, 222 Rosewood Drive, Danvers, MA 01923. For reprint or republication permission, email to IEEE Copyrights Manager at pubs permissions@ieee.org. All rights reserved. Copyright ¬©2022 by IEEE. Fig. 1. ExClaim Approach Example economies but also on all aspects of our lives since it has become commonplace to consume news digitally. A leading cause for the rise of misinformation is that it can now be created cheaper and distributed faster with the internet when compared to traditional platforms such as newspapers and television [2]. The growth of social media usage has also allowed effortless mass sharing of information. The recent progress with Language Models (LM) in Natural Language Processing (NLP) has made it even easier, cheaper, and faster for a machine to generate artiÔ¨Åcial text [3]. Gener ative LMs have become sophisticated such as GPT3 at text generation, and their results are almost on par with human written text in terms of readability, coherence, and grammatical accuracy [4]. In [5], the authors demonstrate that LMs are improving 10x every year in terms of parameters and model size and that there is an incredible amount of progress with natural language text generation that is bound to happen. There is a possibility that these models will reach (or even surpass) human performance in a few years. Such advances can likely lead to more rampant misinforma tion than what we have today online. There has been a growingarXiv:2301.08914v1  [cs.CL]  21 Jan 2023interest in identifying the authenticity and truthfulness of on line content. Professional factcheckers and independent fact checking organizations exist, but their work cannot be scaled linearly with the amount of digital content growth. This led to an increase in interest in automated factchecking, also known as claim veriÔ¨Åcation [6]. By fusing deep learning techniques with complex networks and algorithms, claim veriÔ¨Åcation sys tems have achieved respectable performance but have become blackboxes. Optimizing for the task performance comes at the expense of model explainability. The developers of the model and the endusers which we refer to as the nonexperts do not fully know the internals or understand its decisionmaking processes. Furthermore, [6] points that there exists no system that offers explanations for subtasks in the claim veriÔ¨Åcation pipeline. Currently, a claim is fed into the system, the model checks against an evidence dataset, and it returns a binary verdict as the output; true if the evidence supports the claim otherwise false. This approach has become commonplace [7]; however, many questions still remain unanswered. What evidence in Ô¨Çuenced the prediction? Is the evidence trustworthy? How can the nonexpert understand the model internals? These are all missing components of the process and there are no wide standards to assure the outcomes of these blackbox systems [8]. Explainability techniques are available but they are insufÔ¨Å cient because many require specialized domain knowledge to understand. Claim veriÔ¨Åcation systems are tools which would generally be used by a wide public audience. They need to be explainable in the sense that they appropriately justify their outcomes and are comprehensible to the nontechnical users. Local Interpretable Modelagnostic Explanations (LIME), At tention scores and saliency heatmaps are generally helpful to the model developer, but not the enduser. An emerging NLP explainable technique is called Ratio nalization [9]. It provides a rationale also known as a natural language explanation (NLE) to justify a model‚Äôs prediction. The reasoning behind a model‚Äôs prediction can be understood simply by reading the rationale, thereby revealing the model‚Äôs decisionmaking process. Rationalization can be an attractive explainable technique because it is intuitive and human comprehensible, and does not require domain knowledge [10]. It is a type of local explanation because there is a unique explanation for each prediction [11]. Rationalization frames explainability as an outcomeexplanation problem. It looks at explainability from the perspective of an enduser whose aim is to understand how the model arrives at its Ô¨Ånal outcome [12]. This process is encapsulated in the rationales statement. Rationales are also widely used in the legal system. A judge rules a verdict and it cannot be upheld without a legal opinion which is a written explanation laying out the rationale for a ruling. Inspired by this, we propose a novel approach, namely, ExClaim which leverages rationalization for an explainable neural claim veriÔ¨Åcation system that is accessible and trustworthy to the nonexpert. It can not only predict a verdict but also defend and rationalize its output asa NLE. We also introduce NLP Assurance and incorporate extensive explainable evaluations to assure the verdict and NLE outcomes are valid to help reinforce HumanAI trust [13]. The following are the contributions of this paper: 1) Introduces a new benchmark claim veriÔ¨Åcation dataset with credible foundational information and a novel ex plainable claim veriÔ¨Åcation approach called ExClaim. 2) Uses transfer learning and presents an effective method to generate abstractive rationales in an unsupervised manner without any ground truth. 3) Treats the verdict classiÔ¨Åcation task as a questionanswer problem and demonstrates that it can signiÔ¨Åcantly help improve the classiÔ¨Åcation performance. 4) Presents the problem of claim veriÔ¨Åcation through the lens of explainability and is the Ô¨Årst to introduce sub task explanations in the claim veriÔ¨Åcation space. The structure of this paper is as follows: in Section 2, we present related work. In Section 3, we introduce a new bench mark claim veriÔ¨Åcation dataset. In Section 4, we demonstrate our experiment methodology, while Section 5 describes exper imental results. Lastly, in Section 6, we provide a conclusion and future directions. II. R ELATED WORK "
284,"GI-NNet \& RGI-NNet: Development of Robotic Grasp Pose Models, Trainable with Large as well as Limited Labelled Training Datasets, under supervised and semi supervised paradigms.txt","Our way of grasping objects is challenging for efficient, intelligent and
optimal grasp by COBOTs. To streamline the process, here we use deep learning
techniques to help robots learn to generate and execute appropriate grasps
quickly. We developed a Generative Inception Neural Network (GI-NNet) model,
capable of generating antipodal robotic grasps on seen as well as unseen
objects. It is trained on Cornell Grasping Dataset (CGD) and attained 98.87%
grasp pose accuracy for detecting both regular and irregular shaped objects
from RGB-Depth (RGB-D) images while requiring only one third of the network
trainable parameters as compared to the existing approaches. However, to attain
this level of performance the model requires the entire 90% of the available
labelled data of CGD keeping only 10% labelled data for testing which makes it
vulnerable to poor generalization. Furthermore, getting sufficient and quality
labelled dataset is becoming increasingly difficult keeping in pace with the
requirement of gigantic networks. To address these issues, we attach our model
as a decoder with a semi-supervised learning based architecture known as Vector
Quantized Variational Auto Encoder (VQVAE), which works efficiently when
trained both with the available labelled and unlabelled data. The proposed
model, which we name as Representation based GI-NNet (RGI-NNet), has been
trained with various splits of label data on CGD with as minimum as 10%
labelled dataset together with latent embedding generated from VQVAE up to 50%
labelled data with latent embedding obtained from VQVAE. The performance level,
in terms of grasp pose accuracy of RGI-NNet, varies between 92.13% to 95.6%
which is far better than several existing models trained with only labelled
dataset. For the performance verification of both GI-NNet and RGI-NNet models,
we use Anukul (Baxter) hardware cobot.","Recently, with the advancement of deep learning tech nologies, the capability of robots are enhancing day by day from manipulating very rudimentary type of tasks such as palletizing, picking/placing [3], [4] to the complicated tasks like trying to grasp and manipulate previously seen as well as unseen objects intelligently, the way we do, so that robots can share work space with us in a social environment including many household applications. However, to make it happen, we need to solve many challenging problems one of them is to make it learn the tasks it requires to perform like human kids learn over the years. A child normally has poor grasping skill and that‚Äôs the reason we are reluctant to allow them to grasp sophisticated items for fear of damaging them. But the same child when grew up develops enough grasping skills based on learning through experience, the mechanism of which we need to know before we apply similar mechanisms to train robots including social robots so that they can manipulate tasks more adaptively in a realistic household and industrial environment. As expanding research is being continued to make the robots more intelligent, there exists an interest for a summed up method to induce quick and powerful grasps for any sort of item that the robot sees. In the present research we intend to address some of the problems associated with the intelligent grasping. More speciÔ¨Åcally, we have contributed in designing a lightweight and object independent model, GINNet which predicts grasps from the trained model and gives output as three sets of images. Our proposed model generates quality, angle and width images and grasps are inferred from these images at the pixel level. This model is designed based on the concept of generative grasping which is similarly proposed in Gener ative Grasping Convolutional Neural Network (GGCNN) [5] and Generative Residual Convolutional Neural Network (GR ConvNet) [1]. We have used InceptionBlocks which employ the similar idea as presented in InceptionV1 [6] along with the ReLU activation function with learning rate of 0.001 in order to facilitate inference of information from a variety of kernel sizes as well as to keep the trainable parameters comparatively low (one third reduction) with signiÔ¨Åcant improvement in accuracy (98.87%) than the SOTA performing model [1]. But somehow the performance of all the above mentioned models highly depends on the availability of labelled data. OwingarXiv:2107.07452v1  [cs.RO]  15 Jul 2021Fig. 1: Structural overview of our approach to predict an optimal grasp for an object. to the scarcity of labelled data in the grasping domain, we subsequently propose to attach our model as decoder with a semisupervised learning based architecture known as Vector Quantized Variational Auto Encoder (VQV AE), which we design to work efÔ¨Åciently when we train it with available labelled dataset as well as unlabelled data [2]. Our proposed GINNet integrated VQV AE model, which we name as Rep resentation based GINNet (RGINNet), has been trained with various splits of label data on CGD with as minimum as 10% labelled dataset together with latent embedding generated from VQV AE up to 50% labelled data with latent embedding obtained from VQV AE. The performance level, in terms of grasp pose accuracy of RGINNet, varies between 92.13% to 95.6% which is far better than many other existing SOTA models trained with only labelled dataset. Fig. 1 illustrates the overview of our proposed model. We have trained our proposed models, GINNet and RGINNet over RGBD and RGB images respectively to obtain corre sponding grasps from generated Quality, Angle and Width images, which are then has been used to infer an optimal grasp at the pixel level. Following are the major contributions of the present research: In this research, two novel grasp prediction models, GI NNet and RGINNet, have been designed to predict an optimal grasp at the pixel level. Subsequently, both the models have been trained and evaluated on CGD. Evaluation of GINNet on CGD provides promising increase in grasp accuracy of 98.87% whereas GGCNN [5] and GRConvNet model [1] reports SOTA success rate of 73.0% and 97.7% respectively. GINNet shows an improved success rate incorporating a lesser number of total trainable model parameters (592,300) as compared to GRConvNet [1] (1,900,900). The performance of proposed RGINNet architecture is analysed on CGD for split ratios of 0.1, 0.3, 0.5, 0.7, and 0.9 respectively. For minimal (10%) labelled training data, it obtains an accuracy of 92.13% which shows a signiÔ¨Åcant performance on limited available grasping dataset. In the Ô¨Ånal output of the convolutional layers we have experimented with two transfer functions, Sigmoid and Tanh which provide quality output and angle output (sin2	and cos2 	) respectively. The rest of this paper is arranged in the following format: Section II discusses previous related research works with their limitations. In Section III the problem formulation is elabo rated. Section IV depicts the grasp pose preliminaries with the concept of generative grasp approach, inception module, Vari ational Auto Encoder (V AE) and Vector Quantized Variational Auto Encoder (VQV AE) architectures, training dataset details and grasping metric formulation. Section V describes detailed methodologies of our proposed model architecture along with the reasons for designing this model on rectifying the limita tion of the previously proposed approaches. It also comprises the training method with incorporating loss and activation functions. Section VI illustrates the details about robotic grasp pose generation and execution. Section VII present results and their comparative analyses. Conclusions and recommendations for the future research have been presented in the Section VIII. II. R ELATED WORK "
229,Template Adaptation for Face Verification and Identification.txt,"Face recognition performance evaluation has traditionally focused on
one-to-one verification, popularized by the Labeled Faces in the Wild dataset
for imagery and the YouTubeFaces dataset for videos. In contrast, the newly
released IJB-A face recognition dataset unifies evaluation of one-to-many face
identification with one-to-one face verification over templates, or sets of
imagery and videos for a subject. In this paper, we study the problem of
template adaptation, a form of transfer learning to the set of media in a
template. Extensive performance evaluations on IJB-A show a surprising result,
that perhaps the simplest method of template adaptation, combining deep
convolutional network features with template specific linear SVMs, outperforms
the state-of-the-art by a wide margin. We study the effects of template size,
negative set construction and classifier fusion on performance, then compare
template adaptation to convolutional networks with metric learning, 2D and 3D
alignment. Our unexpected conclusion is that these other methods, when combined
with template adaptation, all achieve nearly the same top performance on IJB-A
for template-based face verification and identification.","Face recognition performance using deep learning has seen dramatic improvements in recent years. Convolutional networks trained with large datasets of millions of images of thousands of subjects have shown remarkable capability of learning facial representations that are invariant to age, pose, illumination and expression (APIE) [4, 5, 6, 7, 8, 9]. These representations have shown strong performance for recognition of imagery and video inthewild in uncon strained datasets, with recent approaches demonstrating capabilities that exceed human performance on the well known Labeled Faces in the Wild dataset [1].The problem of face recognition may be described in terms of face veriÔ¨Åcation and face identiÔ¨Åcation. Face veri Ô¨Åcation involves computing a onetoone similarity between a probe image and a reference image, to determine if two image observations are of the same subject. In contrast, face identiÔ¨Åcation involves computing a onetomany sim ilarity between a probe media and a gallery of known sub jects in order to determine a probe identity. Face veriÔ¨Åcation is important for access control or reidentiÔ¨Åcation tasks, and face identiÔ¨Åcation is important for watchlist surveillance or forensic search tasks. Face recognition performance evaluations have tradition ally focused on the problem of face veriÔ¨Åcation. Over the past Ô¨Åfteen years, face datasets have steadily increased in size in terms of number of subjects and images, as well as complexity in terms controlled vs. uncontrolled collection and amount of APIE variability [10]. The Labeled Faces in the Wild dataset [1] contains 13233 images of 1680 sub jects, and compares speciÔ¨Åc pairs of images of subjects to characterize 1:1 veriÔ¨Åcation performance. Similarly, the YouTubeFaces dataset [2] contains 3425 videos of 1595 subjects, and compares pairs of videos of subjects for veriÔ¨Å cation. These datasets have set the established standard for face recognition research, with steadily increasing perfor mance [11, 5, 6, 4]. Recently, protocols for face identiÔ¨Åca tion have been introduced for LFW [12] to address the per formance evaluation for identiÔ¨Åcation on a common dataset. However, the imagery in LFW was constructed with a well known nearfrontal selection bias, which means evaluations are not predictive of performance for large inthewild pose variation. In fact, recent studies have shown that while al gorithm performance for near frontal recognition is equal to or better than humans, performance of automated systems at the extremes of illumination and pose are still well behind human performance [13]. The IJBA dataset [3] was created to provide the newest and most challenging dataset for both veriÔ¨Åcation and iden 1arXiv:1603.03958v3  [cs.CV]  6 Apr 2016tiÔ¨Åcation. This dataset includes both imagery and video of subjects manually annotated with facial bounding boxes to avoid the near frontal bias, along with protocols for evalu ation of both veriÔ¨Åcation and identiÔ¨Åcation. Furthermore, this dataset performs evaluations over templates [14] as the smallest unit of representation, instead of imagetoimage or videotovideo. A template is a set of all media (im ages and/or videos) of a subject that are to be combined into a single representation suitable for matching. Template based representations are important for many face recog nition tasks, which take advantage of an historical record of observations to further improve performance. For exam ple, a template provides a useful abstraction to capture the mugshot history of a criminal for forensic search in law en forcement, or lifetime enrollment images for visa or driver‚Äôs licenses in civil identity credentialing for improved access control. Biometric templates have been studied for face recognition, where performance on older algorithms have increased given an historical set of images [14]. The IJBA dataset is the only public dataset that enables a controlled evaluation of templatebased veriÔ¨Åcation and identiÔ¨Åcation at the extremes of pose, illumination and expression. In this paper, we study the problem of template adapta tion. Template adaptation is an example of transfer learning, where the target domain is deÔ¨Åned by the set of media of a subject in a template. In general, transfer learning includes a source domain for feature encoding of subjects trained of Ô¨Çine, and a speciÔ¨Åc target domain with limited available ob servations of new subjects. In the case of template adapta tion, the source domain may be a deep convolutional net work trained ofÔ¨Çine to predict subject identity, and the tar get domain is the set of media in templates of never before seen subjects. In this paper, we study perhaps the simplest form of template adaptation based on deep convolutional networks and onevsrest linear SVMs. We combine deep CNN features trained ofÔ¨Çine to predict subject identity, with a simple linear SVM classiÔ¨Åer trained at test time using all media in a template as positive features to classify each new subject. Extensive evaluation of template adaptation on the IJB A dataset has generated surprising results. First, template adaptation outperforms all top performing techniques in the literature: convolutional networks combined with triplet loss similarity [6, 4, 15], joint Bayesian metric learning [16], pose specialized networks [17], 2D alignment [4], 3D frontalization [5] and novel convolutional network archi tectures [18]. Second, template adaptation when combined with these other techniques results in nearly equivalent per formance. Third, we show a clear tradeoff between the size of a template (e.g. the number of unique media in the tem plate) and performance, which leads to the conclusion that if the average largest template size is big enough, then a sim ple template adaptation strategy is the best choice for bothveriÔ¨Åcation and identiÔ¨Åcation on template based datasets. 2. Related Work "
1,Faith: An Efficient Framework for Transformer Verification on GPUs.txt,"Transformer verification draws increasing attention in machine learning
research and industry. It formally verifies the robustness of transformers
against adversarial attacks such as exchanging words in a sentence with
synonyms. However, the performance of transformer verification is still not
satisfactory due to bound-centric computation which is significantly different
from standard neural networks. In this paper, we propose Faith, an efficient
framework for transformer verification on GPUs. We first propose a
semantic-aware computation graph transformation to identify semantic
information such as bound computation in transformer verification. We exploit
such semantic information to enable efficient kernel fusion at the computation
graph level. Second, we propose a verification-specialized kernel crafter to
efficiently map transformer verification to modern GPUs. This crafter exploits
a set of GPU hardware supports to accelerate verification specialized
operations which are usually memory-intensive. Third, we propose an
expert-guided autotuning to incorporate expert knowledge on GPU backends to
facilitate large search space exploration. Extensive evaluations show that
Faith achieves $2.1\times$ to $3.4\times$ ($2.6\times$ on average) speedup over
state-of-the-art frameworks.","Transformers [ 8,21,25,32,33,38,45] is an important cate gory of neural networks (NNs) in machine learning research and industry. Transformers are Ô¨Årst designed for natural lan guage processing (NLP) and have achieved stateoftheart accuracy across many NLP tasks such as neural machine trans lation [ 1,26,31] and sentiment analysis [ 7,37,48]. Due to its success, transformers have been widely used in many indus trial products such as Facebook for hate speech detection [ 10] and Alexa for question answering [ 14]. Recently, transformers also show extraordinary accuracy for many computer vision tasks [ 9,19,44,47,55] and become the new trending model. 1The project is opensourced at https://github.com/BoyuanFeng/Faith Ice is Cold Original Input Ice is Cold Ice is         Cold FrigidFrosty Transformer Verification0.4 ‚â§  P(‚ÄúPos‚Äù) ‚â§ 0.8  0.1 ‚â§ P(‚ÄúNeg‚Äù) ‚â§ 0.39 Prediction BoundsFigure 1: Illustration of transformer veriÔ¨Åcation. Here, all perturbed inputs share the same prediction ‚Äúpositive‚Äù since the lower bound probability for ‚Äúpositive‚Äù (0.4) is higher than the upper bound probability for ‚Äúnegative‚Äù (0.39). However, similar to prior NNs, transformers are also vulnera ble to adversarial attacks that add imperceptible perturbations to input data for maliciously changing transformer predictions [2,3,16,17,22]. One speciÔ¨Åc example of adversarial attack is to exchange words ( e.g., cold) in a sentence with carefully selected synonyms ( e.g., frigid). This vulnerability may result in security concerns for realworld applications. For example, an intentionally crafted hate speech may spread widely on social network. Transformer veriÔ¨Åcation has been proposed to formally verify the robustness of a transformer against adversarial attacks [ 4,18,35,42]. Given an input data xand a trans former F(x), transformer veriÔ¨Åcation identiÔ¨Åes a maximal bound e, such that all inputs x0that are ‚Äúclose‚Äù to the input data ( i.e.,jx0"
235,Fast and Complete: Enabling Complete Neural Network Verification with Rapid and Massively Parallel Incomplete Verifiers.txt,"Formal verification of neural networks (NNs) is a challenging and important
problem. Existing efficient complete solvers typically require the
branch-and-bound (BaB) process, which splits the problem domain into
sub-domains and solves each sub-domain using faster but weaker incomplete
verifiers, such as Linear Programming (LP) on linearly relaxed sub-domains. In
this paper, we propose to use the backward mode linear relaxation based
perturbation analysis (LiRPA) to replace LP during the BaB process, which can
be efficiently implemented on the typical machine learning accelerators such as
GPUs and TPUs. However, unlike LP, LiRPA when applied naively can produce much
weaker bounds and even cannot check certain conflicts of sub-domains during
splitting, making the entire procedure incomplete after BaB. To address these
challenges, we apply a fast gradient based bound tightening procedure combined
with batch splits and the design of minimal usage of LP bound procedure,
enabling us to effectively use LiRPA on the accelerator hardware for the
challenging complete NN verification problem and significantly outperform
LP-based approaches. On a single GPU, we demonstrate an order of magnitude
speedup compared to existing LP-based approaches.","Although neural networks (NNs) have achieved great success on various complicated tasks, they remain susceptible to adversarial examples (Szegedy et al., 2013): imperceptible perturbations of test samples might unexpectedly change the NN predictions. Therefore, it is crucial to conduct formal veriÔ¨Åcation for NNs such that they can be adopted in safety or securitycritical settings. Formally, the neural network veriÔ¨Åcation problem can be cast into the following decision problem: Given a neural network f(), an input domainC, and a propertyP.8x2C, doesf(x)satisfyP? The propertyPis typically a set of desirable outputs of the NN conditioned on the inputs. Typically, consider a binary classiÔ¨Åer f(x)and a positive example x0(f(x0)0), we can setPto be non negative numbers R+andxis bounded within an l1norm ballC=fxjkx"
12,Achieving Verified Robustness to Symbol Substitutions via Interval Bound Propagation.txt,"Neural networks are part of many contemporary NLP systems, yet their
empirical successes come at the price of vulnerability to adversarial attacks.
Previous work has used adversarial training and data augmentation to partially
mitigate such brittleness, but these are unlikely to find worst-case
adversaries due to the complexity of the search space arising from discrete
text perturbations. In this work, we approach the problem from the opposite
direction: to formally verify a system's robustness against a predefined class
of adversarial attacks. We study text classification under synonym replacements
or character flip perturbations. We propose modeling these input perturbations
as a simplex and then using Interval Bound Propagation -- a formal model
verification method. We modify the conventional log-likelihood training
objective to train models that can be efficiently verified, which would
otherwise come with exponential search complexity. The resulting models show
only little difference in terms of nominal accuracy, but have much improved
verified accuracy under perturbations and come with an efficiently computable
formal guarantee on worst case adversaries.","Deep models have been shown to be vulnerable against adversarial input perturbations (Szegedy et al., 2013; Kurakin et al., 2016). Small, seman tically invariant input alterations can lead to dras tic changes in predictions, leading to poor perfor mance on adversarially chosen samples. Recent work (Jia and Liang, 2017; Belinkov and Bisk, zWork done during an internship at DeepMind. xEqual contribution. 1The source code is available at https://github. com/deepmind/intervalboundpropagation/ tree/master/examples/language/ fantasticConvReLUFCFCInput perturbationsInterval boundsPropagated regionsDecision boundarylogitsconferenceoccasiongood    great event greateventUpper boundsFigure 1: Illustration of veriÔ¨Åcation with the input simplex and Interval Bound Propagation. From the left, input perturbations deÔ¨Åne the extreme points of a simplex (in red, projected to 2D here) around the statement ‚Äúgreat event‚Äù that is propagated through a model. At each layer, this shape deforms itself, but can be bounded by axisparallel bounding boxes, which are propagated similarly. Finally, in logit space, we can compute an upper bound on the worstcase speciÔ¨Åca tion violation (e.g., prediction changes). 2018; Ettinger et al., 2017) also exposed the vul nerabilities of neural NLP models, e.g. with small character perturbations (Ebrahimi et al., 2018) or paraphrases (Ribeiro et al., 2018; Iyyer et al., 2018). These adversarial attacks highlight often unintu itive model failure modes and present a challenge to deploying NLP models. Common attempts to mitigate the issue are ad versarial training (Ebrahimi et al., 2018) and data augmentation (Belinkov and Bisk, 2018; Li et al., 2017), which lead to improved accuracy on adver sarial examples. However, this might cause a false sense of security, as there is generally no guarantee that stronger adversaries could not circumvent de fenses to Ô¨Ånd other successful attacks (Carlini and Wagner, 2017; Athalye et al., 2018; Uesato et al., 2018). Rather than continuing the race with adver saries, formal veriÔ¨Åcation (Baier and Katoen, 2008; Barrett and Tinelli, 2018; Katz et al., 2017) offers a different approach: it aims at providing provable guarantees to a given model speciÔ¨Åcation. In thearXiv:1909.01492v2  [cs.CL]  20 Dec 2019case of adversarial robustness, such a speciÔ¨Åcation can be formulated as prediction consistency under anyaltered ‚Äì but semantically invariant ‚Äì input change. In this paper, we study veriÔ¨Åed robustness, i.e., providing a certiÔ¨Åcate that for a given network and test input, no attack or perturbation under the speciÔ¨Åcation can change predictions, using the ex ample of text classiÔ¨Åcation tasks, Stanford Sen timent Treebank (SST) (Socher et al., 2013) and AG News (Zhang et al., 2015). The speciÔ¨Åcation against which we verify is that a text classiÔ¨Åcation model should preserve its prediction under char acter (or synonym) substitutions in a character (or word) based model. We propose modeling these input perturbations as a simplex and then using Interval Bound Propagation (IBP) (Gowal et al., 2018; Mirman et al., 2018; Dvijotham et al., 2018) to compute worst case bounds on speciÔ¨Åcation sat isfaction, as illustrated in Figure 1. Since these bounds can be computed efÔ¨Åciently, we can fur thermore derive an auxiliary objective for models tobecome veriÔ¨Åable. The resulting classiÔ¨Åers are efÔ¨Åciently veriÔ¨Åable and improve robustness on ad versarial examples, while maintaining comparable performance in terms of nominal test accuracy. The contributions of this paper are twofold: To the best of our knowledge, this paper is the Ô¨Årst to introduce veriÔ¨Åcation and veriÔ¨Å able training for neural networks in natural language processing ( x3). Through a series of experiments ( x4), we demonstrate (a) the effectiveness of model ing input perturbations as a simplex and using simplex bounds with IBP for training and test ing, (b) the weakness of adversarial training under exhaustive veriÔ¨Åcation, (c) the effects of perturbation space on the performance of different methods, and (d) the impact of using GloVe and counterÔ¨Åtted embeddings on the IBP veriÔ¨Åcation bounds. 2 Related Work "
84,OVERT: An Algorithm for Safety Verification of Neural Network Control Policies for Nonlinear Systems.txt,"Deep learning methods can be used to produce control policies, but certifying
their safety is challenging. The resulting networks are nonlinear and often
very large. In response to this challenge, we present OVERT: a sound algorithm
for safety verification of nonlinear discrete-time closed loop dynamical
systems with neural network control policies. The novelty of OVERT lies in
combining ideas from the classical formal methods literature with ideas from
the newer neural network verification literature. The central concept of OVERT
is to abstract nonlinear functions with a set of optimally tight piecewise
linear bounds. Such piecewise linear bounds are designed for seamless
integration into ReLU neural network verification tools. OVERT can be used to
prove bounded-time safety properties by either computing reachable sets or
solving feasibility queries directly. We demonstrate various examples of safety
verification for several classical benchmark examples. OVERT compares favorably
to existing methods both in computation time and in tightness of the reachable
set.","Deep learning has found application in a wide variety of Ô¨Åeld s, from computer vision and natural language processing to control of autonomous agent s. In particular, recent innova tions in deep reinforcement learning have yielded impressi ve results, such as training neural networks to play Atari video games (Mnih et al., 2015) and boa rd games like Go (Silver et al., 2016). As a result, there is increasing interest in ap plying deep learning to safety critical control problems such as autonomous driving (Boja rski et al., 2016; C. Chen et al., 2015) and aircraft collision avoidance (Julian et al., 2016 ). Although neural networks can provide Ô¨Çexible representations of complex control strate gies, there is concern that they can result in unexpected behavior (Papernot et al., 2016; Szege dy et al., 2014). Testing can play an important role in identifying undesirab le behavior in a system, but testing alone is not suÔ¨Écient to prove the absence of failure s. It is possible that rare, catastrophic failures exist that intelligent testing sche mes are required to discover (Corso et al., 2020). Instead, formalveriÔ¨Åcation canbeusedonamode lofthesysteminordertoprove the absence of failures. More speciÔ¨Åcally, in this work, we d evelop an algorithm to prove 1Sidrane, Maleki, Irfan & Kochenderfer or disprove safety properties of nonlinear discretetime d ynamical systems with deep neural network control policies. Theincorporationof nonlinearf unctionsaswell asneuralnetworks makes these systems challenging to verify. Katz et al. (2017 ) demonstrated that verifying ReLU neural networks alone is an NPcomplete problem. Tools like those developed by Cimatti et al. (2018) can verify properties of discretetim e systems with nonlinear functions. However, these tools cannot eÔ¨Éciently handle the complexit y of neural networks, which can contain thousands of smooth nonlinear or piecewiselinear activation functions (Katz et al., 2017). Thisproblem has led to the development a family of neu ral network veriÔ¨Åcation tools that are able to eÔ¨Éciently verify properties of neural netwo rks (Liu et al., 2021). Together with a small but growing body of research, this work aims to br idge the gap between the existing literature on veriÔ¨Åcation of closedloop systems and literature on neural network veriÔ¨Åcation. There is extensive literature for formal veriÔ¨Åcation of dis cretetime closedloop systems (also known as transition systems ) (Clarke et al., 2018). Much of this work focuses on linear systems. Although nonlinear model checkers such as t he tool developed by Cimatti et al. (2018) can handle nonlinear dynamics, they are not des igned for use with neural networks. Even if a network can be encoded into the tool, whic h may not be possible, the large number of nonlinear activation functions present diÔ¨Éculties. For example, if the network has ReLU activation functions, each would be expand ed eagerly to a disjunction, leading to an intractable runtime. The inability of existing model checking tools or other auto mated reasoning tools to verify neural networks has led to a recent surge in developme nt of veriÔ¨Åcation tools that are capable of reasoning about neural networks with ReLU act ivation functions (Katz et al., 2017; Liu et al., 2021). When the network that we would li ke to verify represents a control policy, these tools may be used to verify inputout put properties of the control policy in isolation. However, verifying properties of the c ontrol policy in isolation does not address the entire closedloop system of which the control p olicy is just one part. Our work uses these recent developments in neural network veriÔ¨Åcati on in order to reason about the closedloop system. There is prior work that also uses new neural network veriÔ¨Åca tion tools to reason about the closedloop system. Some of these works can be used for di scretetime systems (Julian & Kochenderfer, 2021; Tran et al., 2020). The methods presen ted in both Tran et al. (2020) and Julian and Kochenderfer (2021) work by computing polyto pes containing the reachable set of the control policy and the dynamics at each timestep in an iterative fashion. These methods are complementary to ours, but have two main limitat ions. The Ô¨Årst is that they are based on hybrid systems reachability tools, which scale poorly with the number of state variables (X. Chen et al., 2013). The second is that the under lying reachability algorithm based on iterative computation of concrete reachable sets l eads to a compounding looseness of the approximation, known as the wrapping eÔ¨Äect (Neumaier, 1993). To Ô¨Åx this, the initial set may be split into smaller cells across each dimen sion, but this too can lead to poorscaling inthenumberofstate variables. Themethodsde veloped here, incontrast, have either no explicit dependence on the number of state variabl es or only linear dependence. All methods presented mitigate the wrapping eÔ¨Äect by preserv ing a symbolic representation across multiple timesteps. 2Safety Verification of Neural Network Control Policies for Nonlinear Systems There is related work that assumes piecewiselinear system dynamics, or approximates (neither underapproximates nor overapproximates) potent ially nonlinear system dynamics using datadriven models (Akintunde et al., 2020; Akintund e et al., 2018; Dutta et al., 2018; Xiang, Tran, Rosenfeld, et al., 2018). However, if the syste m dynamics are approximated with a data driven model, proving that there are no counterex amples for the approximate system does not allow a sound claim that there are no countere xamples for the original nonlinear dynamics. Our method makes an overapproximation thatdoesallow such a sound claim to be made. Finally, there is adjacent work that a ddresses continuoustime systems (Dutta et al., 2019; Huang et al., 2019; Ivanov et al. , 2019). These methods are closely related but not directly applicable to the problem a t hand. Contributions . We present a method that we call OVERT that reasons about non lin ear discretetime closedloop systems that contain neural network control policies. OVERT overapproximates nonlinear dynamical systems using piece wiselinear relations, making the entire closedloop system a conjunction of piecewiseline ar relations. The resultant system of piecewiselinear relations can be eÔ¨Éciently reasoned ab out using ReLU neural network veriÔ¨Åcation tools. The experiments we present are encoded a nd solved as a mixedinteger programs. We prove boundedtime safety properties for the c losedloop system by unrolling the system in time. Reachability queries can be solved direc tly as feasibility problems or by explicitly computing the reachable set. The use of hybrids ymbolic reachable set computa tion preserves both tightness of the reachable set and tract ability of its computation. The methods presented have at most linear explicit dependenceo n the numberof state variables. The use of an overapproximation allows the sound claim that a proof of no counterexamples for the approximation implies no counterexamples for the or iginal system. We have released two Julia packages, OVERT.jl and OVERTVerify.jl, which pro vide implementations of the sound overapproximation and veriÔ¨Åcation algorithms, resp ectively. 2. Background This paper borrows ideas from formal veriÔ¨Åcation, control t heory, and machine learning. This background section reviews prerequisite concepts and terminology. 2.1 ClosedLoop Systems Aclosedloop system is adynamical system paired with a feedback control policy . The termdynamical system originates in control theory and describes a model of a state ful system that evolves in time. To illustrate, we use a system of an inverted pendulum as a running example. The state, x, of the inverted pendulum may be represented by the angle of the pendulum, Œ∏, and the angular velocity of the pendulum, ÀôŒ∏:x= [Œ∏,ÀôŒ∏]T. The set of all possible states is [ ‚àíœÄ,œÄ]√óR. We can also deÔ¨Åne an initial set of states, also known as an initial condition. A dynamical system evolves in time according to an update function, which is commonly called the equation of motion or the plant in control theory. A dynamical system may be discretetime or continuoustime . We focus on discretetime systems. For discretetime systems, the update function htakes as input the state at time tand returns the state at time t+1:xt+1=h(xt). Additionally, a dynamical system may be linear or nonlinear. A nonlinear system has a nonlinear up date function h. In this work, we consider nonlinear systems where hmay contain polynomials, transcendentals (sin, cos, 3Sidrane, Maleki, Irfan & Kochenderfer exp), piecewiselinear functions, and compositions there of. The dynamical systems that arise in classical mechanics can typically be expressed usi ng a function in this class. A dynamical system may also incorporate external inputs, ca lled control inputs, that allow us to generate desired behavior. The update function i s thenxt+1=f(xt,ut) where utis the control input at time tproduced by the control policy . The control policy is also called the controller in control theory or the policy in reinforcement learning. In the inverted pendulum example, a control input could be torque a pplied at the pivot joint. This torque may be used to produce desired behavior, such as b alancing the pendulum up right. A feedback control policy produces control input utas a function of the current state, ut=c(xt), making it reactive to changes in the system. The prevalenc e of deep learning and deep reinforcement learning has led to the use of neural n etwork based control policies. Consequently, this work focuses on nonlinear discretetim e closedloop systems with neural network control policies. 2.2 Transition Systems Readers from formal veriÔ¨Åcation and model checking may be fa miliar with the notion of atransition system . A discretetime dynamical system, paired with an initial c ondition (initial set of states), may be equivalently modeled as a sym bolic transition system. A symbolic transition system has states that evolve in discre te time according to a transition relation, beginning from a speciÔ¨Åc initial set. Such a symbo lic transition system is deÔ¨Åned by a tuple ( X,I,TR), where Xis a set of state variables. Here, I(X) represents the set of initial states using a formula over the variables in X. Aformula is a Boolean combination (using standard logical operators) of constraints. A const raint is of the form p ‚ä≤‚ä≥0, where pis a polynomial (summation of monomials) and ‚ä≤‚ä≥‚àà{‚â§,<,=,‚â•,>}. Atransition relation TRdescribes how the state evolves in time. The transition rela tion is symbolically deÔ¨Åned as a formula over the state variables associated with the cur rent and next time step. Let xtbe the current state at time tandxt+1be a next state at time t+ 1. The formula TR(xt,xt+1) returns true if state xt+1is a valid successor of state xt. A transition system does not require that there be a single valid successor state for a given state. The update function of a dynamical system corresponds to the transitio n relation when modeling a dynamical system as a transition system. 2.3 Proving Properties We prove safety properties and goalreaching properties fo r closedloop systems, which can equivalently be described as model checking for transition systems; speciÔ¨Åcally, bounded time model checking. For readers from control theory, this c an also be described as solving discretetime reachability problems . A reachability problemreasons about whethertheset of states reachable over time intersects with an unsafe set, or reaches a goal set. For example, consider modeling the motion of an inverted pendulum as a tra nsition system or discrete time dynamical system. The properties we prove can be condit ions that we would like to always hold, known as invariant properties, e.g. it is always true that the angle of the pendulum with respect to vertical is greater than ‚àí5¬∞, or conditions that we would eventually like to hold, such as the angle of the pendulum with respect to vertical is eventua lly greater than‚àí5¬∞. Formally, a property is deÔ¨Åned as a Booleanvalued predica te over the states of 4Safety Verification of Neural Network Control Policies for Nonlinear Systems the system, e.g. Œ∏‚â•‚àí5¬∞, which is then combined with a temporal modal operator such asG(Globally) or F(Finally) as well as a Ô¨Ånite range of timesteps to form a bound ed temporal property. For example, F1:10(Œ∏‚â•‚àí5¬∞) expresses that Œ∏must be greater than ‚àí5¬∞ at some point in the Ô¨Årst 10 timesteps. The notation G1:10(Œ∏‚â•‚àí5¬∞) expresses that Œ∏must be greater than‚àí5¬∞at all steps in the Ô¨Årst 10 timesteps. OVERT has the capabilit y to reason about a larger fragment of temporal logic than just th eFandGoperators. In this paper, the Goperator is used to express safety properties, and the Foperator is used to express goalreaching properties. In order to prove that a property (e.g., G1:10œÜ) holds, the negation of the property must beproven unsatisÔ¨Åable(UNSAT). If a traceof thesystem is foundthat satisÔ¨Åes the negation oftheproperty,thistraceisacounterexampledemonstrat ingwherethepropertyisviolated. A trace may also be described as a trajectory in the control th eory context. The FandG operators are dual, meaning that ¬¨GœÜis equivalent to F¬¨œÜas well as¬¨FœÜis equivalent to G¬¨œÜ. In order to prove G1:10œÜholds, we would test whether the complement, F1:10¬¨œÜ, is unsatisÔ¨Åable. At each timestep t‚àà1 : 10, the property ¬¨œÜshould be unsatisÔ¨Åable. 3. Methods "
528,SEVEN: Deep Semi-supervised Verification Networks.txt,"Verification determines whether two samples belong to the same class or not,
and has important applications such as face and fingerprint verification, where
thousands or millions of categories are present but each category has scarce
labeled examples, presenting two major challenges for existing deep learning
models. We propose a deep semi-supervised model named SEmi-supervised
VErification Network (SEVEN) to address these challenges. The model consists of
two complementary components. The generative component addresses the lack of
supervision within each category by learning general salient structures from a
large amount of data across categories. The discriminative component exploits
the learned general features to mitigate the lack of supervision within
categories, and also directs the generative component to find more informative
structures of the whole data manifold. The two components are tied together in
SEVEN to allow an end-to-end training of the two components. Extensive
experiments on four verification tasks demonstrate that SEVEN significantly
outperforms other state-of-the-art deep semi-supervised techniques when labeled
data are in short supply. Furthermore, SEVEN is competitive with fully
supervised baselines trained with a larger amount of labeled data. It indicates
the importance of the generative component in SEVEN.","Different from traditional classiÔ¨Åcation tasks, the goal of ver iÔ¨Åcation tasks is to determine whether two samples belong to the same class or not, without predicting the class di rectly [Chopra et al. , 2005 ]. VeriÔ¨Åcation tasks arise from ap plications where thousands or millions of classes are present with very few samples within each category (in some cases just one). For example, in face and signature veriÔ¨Åcation, faces and signatures of a person are considered to belong to a class. While there can be millions of persons in the database, very few examples for each person are available. In such ap plications, it is also necessary to handle new classes withoutthe need to train the model from the scratch. It is not triv ial to address such challenges with traditional classiÔ¨Åcation techniques. Motivated by the impressive performance brought by deep networks to many machine learning tasks [LeCun et al. , 2015; Bahaadini et al. , 2017; Zheng et al. , 2017 ], we pursue a deep learning model to improve existing veriÔ¨Åcation mod els. However, deep networks require a large amount of la beled data for each class, which are not readily available in veriÔ¨Åcation. There are semisupervised training methods for deep network to tap on the large amount of unlabeled data. These semisupervised methods usually have separate learn ing stages [Sun et al. , 2017; Nair and Hinton, 2010 ]. They Ô¨Årst pretrain a model using unlabeled data and then Ô¨Ånetune the model with labeled data to Ô¨Åt the target tasks. Such two phase methods are not suitable for veriÔ¨Åcation. First, the large number of classes and the lack of data (be it labeled or un labeled) within each category prohibit us from any form of within class pretraining and Ô¨Ånetuning. Second, if we pool data from all categories for pretraining, the learned features are general but not speciÔ¨Åc towards each category, and the later Ô¨Ånetuning within each category may not be able to cor rect such bias due to the lack of labeled data. To address such challenges, we propose Deep SEmi supervised VEriÔ¨Åcation Networks (SEVEN) that consists of a generative and a discriminative component to learn general and category speciÔ¨Åc representations from both unlabeled and labeled data simultaneously. We cross the category barrier and pool unlabeled data from all categories to learn salient structures of the data manifold. The hope is that by tapping on the large amount of unlabeled data, the structures that are shared by all categories can be learned for veriÔ¨Åcation. SEVEN then adapts the general structures to each cate gory by attaching the generative component to the discrimi native component that uses the labeled data to learn category speciÔ¨Åc features. In this sense, the generative component works as a regularizer for the discriminative component, and aids in exploiting the information hidden in the unlabeled data. On the other hand, as the discriminative component de pends on the structures learned by the generative component, it is desirable to inform the generative component about the subspace that is beneÔ¨Åcial to the Ô¨Ånal veriÔ¨Åcation tasks. To wards this end, instead of training the two components sepa rately or sequentially, SEVEN chooses to train the two comarXiv:1706.03692v2  [cs.LG]  14 Jun 2017ponents simultaneously and allow the generative component to learn more informative general features. We evaluate SEVEN on four datasets and compare it to four stateoftheart semisupervised and supervised algo rithms. Experimental results demonstrate that SEVEN out performs all the baselines in terms of accuracy. Furthermore, it has shown that by using very small amount of labeled ex amples, SEVEN reaches competitive performance with the supervised baselines trained on a signiÔ¨Åcantly larger set of labeled data. The rest of this paper is organized as follows. In Section 2 we give an overview of the related works. In Section 3 we present SEVEN in detail. Section 4 gives the experimental evaluation and analysis of the proposed model, followed by a conclusion. 2 Related Work "
110,GrOVe: Ownership Verification of Graph Neural Networks using Embeddings.txt,"Graph neural networks (GNNs) have emerged as a state-of-the-art approach to
model and draw inferences from large scale graph-structured data in various
application settings such as social networking. The primary goal of a GNN is to
learn an embedding for each graph node in a dataset that encodes both the node
features and the local graph structure around the node. Embeddings generated by
a GNN for a graph node are unique to that GNN. Prior work has shown that GNNs
are prone to model extraction attacks. Model extraction attacks and defenses
have been explored extensively in other non-graph settings. While detecting or
preventing model extraction appears to be difficult, deterring them via
effective ownership verification techniques offer a potential defense. In
non-graph settings, fingerprinting models, or the data used to build them, have
shown to be a promising approach toward ownership verification. We present
GrOVe, a state-of-the-art GNN model fingerprinting scheme that, given a target
model and a suspect model, can reliably determine if the suspect model was
trained independently of the target model or if it is a surrogate of the target
model obtained via model extraction. We show that GrOVe can distinguish between
surrogate and independent models even when the independent model uses the same
training dataset and architecture as the original target model. Using six
benchmark datasets and three model architectures, we show that consistently
achieves low false-positive and false-negative rates. We demonstrate that is
robust against known fingerprint evasion techniques while remaining
computationally efficient.","Graph data is ubiquitous and used to model networks such as social networks, chemical compounds, and financial transactions. However, the noneuclidean nature of graph data makes it difficult to analyze using traditional machinelearning algorithms. Unlike Euclidean datasets, where the data points are independent, graph data follows homophily, where similar nodes share an edge. To analyze such graph data, special deep neural networks (DNNs) called Graph Neural Networks (GNNs) have been introduced [ 17,28, 65,77]. These models learn an embedding for each node in the graph that encodes the node features and local graph structure. They can perform node classification [ 17,28,65,77], link prediction [ 4,79‚Äì 81], visualization [72], and recommendations [33, 53, 69, 78].Model builders spend significant time and resources to prepare the training data, perform hyperparameter tuning, and optimize the model to achieve stateoftheart performance. This makes the deployed GNNs a critical intellectual property for model owners. For instance, Amazon Neptune1provides a framework to train and use GNNs; Facebook [ 32] and Twitter [ 47] extensively use graphbased ML models. This broad adoption of GNNs makes them vulnerable to model extraction attacks where an adversary tries to train a local surrogate model with similar functionality as the deployed target model [2, 6, 22, 42, 45, 62]. Model extraction attacks use the inputoutput pairs from the target model to train the surrogate model. The goal is to achieve similar utility on the primary task for a fraction of the cost. These at tacks violate the company‚Äôs intellectual property and allow further attacks such as evasion using adversarial inputs and membership inference [ 45]. While prior work has indicated the feasibility of model extraction attacks on various domains [ 2,43,45,58], recent work introduced such attacks against GNNs as well [9, 51, 74]. Current approaches to address model extraction attacks rely on posthoc ownership verification in which the model owner requests a trusted verifier to decide whether a suspect model was stolen from their target model. Ownership verification is done using either fingerprinting or watermarking. Watermarking has been shown to degrade model accuracy [ 24,27,31] and can be evaded [ 36,37]. Hence, we identify fingerprinting as a potential scheme that can be used for model ownership verification. Model fingerprinting uses inherent features of the model to distinguish between surrogates and independent models. [ 5,36,46,67,85,87]. On the other hand, dataset fingerprinting uses the training data as a fingerprint, such that any model trained on the same data as the target model is classified as stolen [ 37]. Such fingerprinting schemes have been proposed for nongraph DNNs, but there is currently no such work for GNNs. In this work, we present the first fingerprinting scheme for GNNs . We claim the following main contributions: (1)identify GNN embeddings as a potential fingerprint and show that they are useful for verifying model ownership but not dataset ownership (Section 4). (2)present GrOVe , embeddingbased fingerprinting for GNN model ownership verification (Section 5). (3)extensively evaluate GrOVe on six datasets and three architec tures showing that GrOVe is: ‚Ä¢effective at distinguishing between surrogate and indepen dent models with close to zero false positives or false nega tives (Section 7.1), 1https://aws.amazon.com/neptune/machinelearning/arXiv:2304.08566v1  [cs.LG]  17 Apr 2023‚Ä¢robust against known fingerprint removal techniques (Sec tion 7.2), and ‚Ä¢computationally efficient (Section 7.3). We plan to open source our implementation.2 2 BACKGROUND We describe some preliminaries for GNNs and notations used in this work (Section 2.1), followed by an overview of model extraction attacks and defenses (Section 2.2). 2.1 Graph Neural Networks Several realworld applications can be modeled as graphs that in clude nodes that represent different entities in the graph (e.g., au thors in citation networks or users in social networks) and edges that represent the connections between nodes. Formally, a graph can be represented as G=(V,E), whereVis a set of nodes and Eis a set of edges connecting these nodes. We represent a single node asùë£‚ààV and an edge between nodes ùë¢andùë£asùëíùë¢ùë£‚ààE. The entire graph structure, including all the nodes and corresponding edges, can be represented using a binary adjacency matrix Aof size|V|√ó|V| :Aùë¢ùë£=1,‚àÄ(ùëíùë¢ùë£)‚ààE . ML on Graphs. Due to the large scale of these graph datasets, ML approaches for processing them have gained significant attention. Specifically, GNNs have shown tremendous performance in pro cessing graph data for node and edge classification, clustering, and other tasks. Following prior work [ 9,51,74], we consider node classification tasks in this work. Each node has a feature vector ùë•‚ààXand corresponding classifi cation labelùë¶‚ààY whereXandYare the set of features and labels across all nodes respectively. We can denote the graph dataset as D=(A,X,Y)which is a tuple of the adjacency matrix, the set of node features, and the set of labels respectively. GNNs are trained to take the graph‚Äôs adjacency matrix and the features as input and map it to the corresponding classification labels. Once trained, GNNs output a node embedding ‚Ñé‚ààH. Em beddings are lowdimensional representations of each node and the graph structure and can be used for downstream tasks such as classi fication, recommendations, etc. We note that since His dependent on the graph structure and the node features, two GNNs trained on different datasets should differ in their output of H[17,65]. Formally, the mapping for a GNN is written as: F:A√óX‚ÜíH . There are two training paradigms for GNNs: ‚Ä¢Transductive where the model trains on mapping some graph nodes to classification labels but uses the remaining graph nodes for prediction during testing. Here, the underlying graph struc tureA, passed as input to the model, remains the same. This is useful for labeling a partiallylabeled graph. ‚Ä¢Inductive where the model is trained on a training graph dataset but evaluated on an unseen and disjoint testing dataset. Following prior work [ 51], we consider the more prevalent and practical setting of inductive training, which is applicable for ML as a service on graph data. GNN Computation. Training and evaluating a GNN involves ag gregating information from neighboring nodes to compute the 2An anonymized version of the source can be made available on request to facilitate doubleblinded reviewing.embeddings for a specific node. Formally, each layer of a GNN performs the following operation: ‚Ñéùëô ùë£=AGG(‚Ñéùëô‚àí1 ùë£,MSG(‚Ñéùëô‚àí1 ùë£,‚Ñéùëô‚àí1 ùë¢:ùë¢‚ààN(ùë£))) (1) N(ùë£)denotes the nodes that share an edge with ùë£.‚Ñéùëôùë£denotes the embedding of node ùë£at layerùëô.‚Ñé0ùë£is initialized as the feature vector ùë•for nodeùë£.MSG(¬∑)gathers information from the neighbouring nodes ofùë£, andAGG(¬∑)aggregates this information with ‚Ñéùëô‚àí1ùë£to produce‚Ñéùëôùë£. The primary difference between different GNN archi tectures is the implementation of these two functions. GraphSAGE [17] uses the mean aggregation operation: ‚Ñéùëô ùë£=CONCAT(‚Ñéùëô‚àí1 ùë£,MEAN(‚Ñéùëô‚àí1 ùë¢:ùë¢‚ààN(ùë£))) (2) where CONCAT is the concatenation operation, and MEAN is the mean operation. Graph Attention Networks (GAT) [65] includes masked self attention layers in the GNN, which allows the model to assign a different weight to each neighbor of a node. This captures the variation in the contribution of different neighboring nodes. The aggregation function is: ‚Ñéùëô ùë£=CONCATùêæ ùëò=1ùúé(‚àëÔ∏Å ùë¢‚ààN(ùë£)ùõºùëò ùë¢ùë£Wùëò‚Ñéùëô‚àí1 ùë¢) (3) where CONCAT is the concatenation operation, ùêæis the total num ber of projection heads in the attention mechanism, ùõºùëòùë¢ùë£is the attention coefficient in the ùëòùë°‚Ñéprojection head, Wùëòis the linear transformation weight matrix, and ùúé(¬∑)is the activation function. Graph Isomorphism Network (GIN) [77] extends GraphSAGE and uses the aggregation function: ‚Ñéùëô ùë£=ùëÄùêøùëÉùëô((1+ùúñùëô)¬∑‚Ñéùëô‚àí1 ùë£+‚àëÔ∏Å ùë¢‚ààN(ùë£)‚Ñéùëô‚àí1 ùë¢) (4) where MLP is a multilayer perceptron and ùúñis a learnable parame ter to adjust the weight of node ùë£. This treats ‚Ñéùëô‚àí1ùë¢:ùë¢‚ààN(ùë£)as a multiset ,i.e., a set with possible repeating elements. 2.2 Model Extraction Attacks and Defences Model extraction attacks consider an adversary ( Aùëëùë£) who trains a local surrogate model ( Fùë†) to mimic the functionality of a target model (Fùë°) [62]. These attacks have been extensively studied in many domains including images [ 22,42,45], text [ 30,43], and graphs [ 9,51,74] and across different types of models including generative models [ 21,58], and large language models [ 66]. This attack has been identified as a realistic threat that violates the confidentiality of the company‚Äôs proprietary model and thereby their intellectual property [2]. We denote the training dataset of Fùë°(respectivelyFùë†) asDùë° (Dùë†). Additionally, we refer to models trained independently on a datasetDùëñ(in the absence of model extraction attack) are called independent models ( Fùëñ). NonGraph Model Extraction Attacks. Aùëëùë£, given query access toFùë°, sends queries and obtains corresponding predictions. Aùëëùë£ then uses these inputprediction pairs to train Fùë†. Most attacks trainFùë†using specially crafted adversarial examples as inputs to Fùë°[22,42,45,62]. This helps to ensure that the decision bound ary ofFùë†is similar toFùë°. After a successful attack, Aùëëùë£can use 2Fùë†to generate effective transferrable adversarial examples [ 45] or perform membership inference attacks [52]. NonGraph Model Extraction Defenses. Preventing model ex traction attacks without affecting model performance is difficult [ 2, 6,30]. However, ownership verification as a posthoc approach helps identify whether a suspect model ( F?) is stolen via model extraction. Normally, this involves a thirdparty verifier ( Vùëíùëü) that verifies ownership. There are currently two main schemes for own ership verification: ‚Ä¢watermarking [1,7,16,20,39,48,57,63,68,89] where some secret information is embedded into the model during training which is extracted later during verification. ‚Ä¢fingerprinting [5,36,37,46,85,87] where inherent features are extracted from a model, without affecting the training process. Prior work has shown watermarking is brittle and can be easily evaded [ 35]. Hence, fingerprinting is currently the most promising technique for ownership verification. In this work, we focus on fingerprinting. Prior work has explored two fingerprinting schemes based on whether the fingerprint is for dataset ownership ormodel ownership . The subtle difference between them is how a different model trained from scratch on the same dataset asFùë°is treated. Datasetownership based fingerprinting classifies such a model as a surrogate. However, modelownershipbased fingerprinting classifies such a model as independent. Here, only models derived (e.g., transferlearning, model extraction) from Fùë°are classified as a surrogate. We describe the main prior works for fingerprinting below. For dataset ownershipbased fingerprinting, Maini et al. [37] propose dataset inference on the following intuition: the distance of the training data points from the model‚Äôs decision boundary is increased during training. Hence, the distance of a data point from the decision boundary can help infer its membership in Dùë°. VùëíùëüqueriesF?with data points from Dùë°and unseen public data to compute their distances from the decision boundary. F?is classified as a surrogate if the distances corresponding to Dùë°are large, and the distances corresponding to unseen public data are small. Most prior work on model ownershipbased fingerprinting iden tifies adversarial examples that can transfer from Fùë°toFùë†but not toFùëñ[5,36,67,85]. They vary in how to identify such adversarial examples. For instance, data points close to the decision boundary can be used to differentiate between Fùë†andFùëñmodels [ 5,67]. Alter natively, untargeted adversarial examples can be used as well [ 85]. However, these works consider Fùë†derived using transferlearning and finetuning but do not consider model extraction attacks [36]. Two prior model ownershipbased fingerprinting works are eval uated explicitly with respect to model extraction attacks. We de scribe them below. Lukas et al. [36] use an ensemble of models to generate con ferrable adversarial examples , i.e., adversarial examples that transfer fromFùë°toFùë†, but are not misclassified by Fùëñ. During verification, Vùëíùëücomputes the error between the predictions of Fùë°andF?on the conferrable examples. If the error rate exceeds a certain thresh old, it is classified as independent, and surrogate otherwise. Peng et al. [46] use universal adversarial perturbations (UAPs), small imperceptible perturbations which, when added to any image, result in misclassification. They compute a fingerprint by addingUAP to some data points and compute the change in output before and after UAP. They train an encoder to ensure that the fingerprints ofFùë°andFùë†are similar but distinct from Fùëñ. We explain in Section 3.4 why these techniques ([ 36,37,46]) are not easily applicable to GNNs. Model Extraction Attacks on GNNs. There is limited literature on model extraction attacks in GNNs. One approach is to use adver sarial examples to perform model extraction attacks, similar to the work in nongraph settings [ 9]. However, the input perturbation for adversarial examples in graph setting is too high to be stealthy. Wu et al. [ 74] presented seven attacks with different Aùëëùë£background knowledge. However, these works are limited to transductive train ing, impractical in ML as a service setting [51]. We focus on the more practical case of inductive learning where the training and testing graph datasets are disjoint. Shen et al. [ 51] presented the first work on model extraction against inductive GNNs. Here,Aùëëùë£has access to a query dataset Dùë†=(Aùë†,Xùë†,Yùë†) and the query response (a set of embeddings ( Hùë°) corresponding to the node features (Xùë†) it receives fromFùë°. UsingHùë°and the ground truth labels (Yùë†),Aùëëùë£trainsFùë†to mimic the behavior of Fùë°. They propose two attacks depending on Aùëëùë£‚Äôs background knowledge: inType I attack,Aùëëùë£has access toXùë†,Yùë†, and the adjacency matrix (Aùë†) forDùë†; inType II attack,Aùëëùë£only has access toXùë†,Yùë†, and uses an edgeestimation algorithm to compute Aùë†. In their attack, the architecture for Fùë†consists of two compo nents: ‚Ä¢a GNN that takesXùë†andAùë†as input and outputs Hùë†. While training, this module minimizes the mean squared error (MSE) loss betweenHùë†andHùë°: Hùë†=Gùëõùëõ(Xùë†,Aùë†) (5) LùëÖ=1 ùëõùê∑ùë†‚à•Hùë†‚àíHùë°‚à•2,1 (6) whereùëõùê∑ùë†is the number of nodes in Dùë†. ‚Ä¢an MLP classifier (C) which takesHùë†as input and outputs a class. This is trained to minimize the prediction loss between Yùë†and the predicted labels. In each epoch,Gùëõùëõis first optimized using LùëÖ; then, the parameters are fixed while parameters corresponding to Care optimized. Both modules are combined to form Fùë†. The same training strategy is used to train Fùë†using Type I and Type II attacks. However, for Type II attacks, Aùëëùë£first estimates Aùë†. A graph structure is initialized by creating a ùëònearest neigh bors graph fromXùë†. A search algorithm looks for hidden graph structure that augments the initial ùëònearest neighbors graph [ 74]. The graph structure is obtained by minimizing a joint loss function that combines prediction loss for node classification and a graph regularization loss that controls the graph‚Äôs smoothness, connec tivity, and sparsity. Additional details about the model extraction attack can be found in [51]. Model Extraction Defenses For GNNs. To the best of our knowl edge, there are two prior works on watermarking in the context of GNNs [ 76,86]. Zhao et al. [ 86] embed randomly generated sub graphs with random feature vectors as a key. These can be used later to extract the watermark. However, they only focus on node 3classification tasks. Xu et al. [ 76] extend the prior work by includ ing graph classification tasks. There are no known fingerprinting schemes for GNNs in the current literature. 3 PROBLEM STATEMENT Our goal is to design an effective fingerprinting scheme that allows Vùëíùëüto identify whether F?is a surrogate ofFùë°or an independent model. We consider the stateoftheart model extraction attacks in an inductive setting [ 51] to evaluate our scheme. To this end, we outline a system model that defines the interactions between model owners andVùëíùëü(Section 3.1), an adversary model describing Aùëëùë£‚Äôs capabilities and goals (Section 3.2), requirements to design an ideal fingerprinting scheme (Section 3.3) and limitations of prior defenses against GNN model extraction (Section 3.4). Table 1 summarizes the notations used in this work. Table 1: Summary of notations used in this work Notation Description D=(A,X,Y) A graph dataset A Adjacency matrix X Set of node features ùë• Y Set of labels ùë¶ H Set of node embeddings ‚Ñé ùëíùë¢ùë£ An edge between nodes ùë¢andùë£ N(ùë£) Neighbouring nodes of ùë£ Fùë° Target model Fùë† Surrogate model Fùëñ Independent Model F? Suspect model to be verified Dùë°/Dùë†/DùëñTarget / Surrogate / Independent dataset Aùëëùë£ Adversary Vùëíùëü Verifier Aùëêùëêùë¢ùë†ùëíùëü Owner ofFùë° Rùëíùë†ùëùùëúùëõùëëùëíùëü Owner ofF? Aùëëùë£.R MaliciousRùëíùë†ùëùùëúùëõùëëùëíùëü Aùëëùë£.A MaliciousAùëêùëêùë¢ùë†ùëíùëü ùëêùë°/ùëê? Commitment ofFùë°/F? ùë°ùë°/ùë°? Timestamp ofFùë°/F? 3.1 System Model We consider a setting where a proprietary GNN model ( Fùë°) has been developed and deployed as a service. However, Fùë°is susceptible to model extraction. An ownership verification system, intended to thwart model extraction, consists of three actors: an Aùëêùëêùë¢ùë†ùëíùëü (the owner ofFùë°), a trusted third party Vùëíùëü, and aRùëíùë†ùëùùëúùëõùëëùëíùëü (the owner of a suspect model F?) who is accused of stealing Fùë°by Aùëêùëêùë¢ùë†ùëíùëü . The role of theVùëíùëüis to verify whether F?was obtained through a model extraction attack on Fùë°. We refer to a malicious Rùëíùë†ùëùùëúùëõùëëùëíùëü asAùëëùë£.Rand a maliciousAùëêùëêùë¢ùë†ùëíùëü asAùëëùë£.A. System Design Goals. An ideal system must be robust against bothAùëëùë£.RandAùëëùë£.A. Case 1Aùëëùë£.Rwants its modelF?, extracted fromAùëêùëêùë¢ùë†ùëíùëü ‚ÄôsFùë°, to evade detection.Case 2Aùëëùë£.Awants to maliciously claim that Rùëíùë†ùëùùëúùëõùëëùëíùëü ‚ÄôsF?is extracted fromFùë°. To address both scenarios, similar to prior work [ 57,87], we as sume that all model owners are required to securely timestamp their models in a registration step before deployment. This will address Aùëëùë£.AsinceAùëêùëêùë¢ùë†ùëíùëü cannot successfully make an ownership claim againstF?unlessFùë°was registered prior to F?. In Section 9, we explore possible incentives for model owners to register their models. In the rest of this paper, we will focus on robustness against a maliciousAùëëùë£.R. Model Registration. Model owners are required to: (1)generate a cryptographic commitment ùëêof their model such that any subsequent modification to the model can be de tected. One way to compute such a commitment is using a cryptographic hash function. (2)obtain a secure timestamp ùë°onùëêthatVùëíùëücan later verify, e.g., by adding ùëêto a blockchain, or utilizing a publicly veri fiable timestamping service3, or receiving a signature from Vùëíùëübindingùëêto the current time. We use subscripts to associate timestamps and commitments to the respective models (e.g., ùë°ùë°is the secure timestamp on the commitment ùëêùë°ofFùë°) Dispute Initiation. Aùëêùëêùë¢ùë†ùëíùëü initiates a dispute by submitting ùëêùë° andùë°ùë°toVùëíùëü, and identifying a suspect Rùëíùë†ùëùùëúùëõùëëùëíùëü .Vùëíùëüthen asks Rùëíùë†ùëùùëúùëõùëëùëíùëü to submitùëê?andùë°?to begin the verification process. Verification Process. Vùëíùëüdoes the following: (1)verifies that ùë°ùë°,ùëêùë°, andFùë°are consistent; and ùë°?,ùëê?, andF? are consistent. (2)confirms that ùë°ùë°<ùë°?. If this condition is not met, the claim is rejected. (3) checks thatFùë°andF?are wellformed (see below). (4)samples a verification dataset Dùë£from the same distribution asDùë°. (5)queriesFùë°andF?withDùë£and passes the outputs to a veri fication algorithm which decides whether F?is a surrogate ofFùë°or trained independently. Step 3 requiresVùëíùëüto check that a model does not have any non standard layers. In Section 7.2, we explain why this check is neces sary. The simplest way for Vùëíùëüto conduct the checks in the first three steps is for the model owners to send their models ( Fùë°and F?) toVùëíùëü. This may not be feasible for confidentiality or privacy reasons. Thus, the checks can be done either via cryptographic techniques like oblivious inference [ 25,34] in conjunction with zeroknowledge proofs [ 3,26] or by using hardwarebased trusted execution environments [ 11,61]. The specific implementation of such protocols is out of the scope of this work. For ease of exposition, we limit our discussion to the case where the model owners in a dispute are willing to share their models with Vùëíùëü. Note that it is still necessary to check that the models sent to Vùëíùëüare indeed the models that were deployed. Vùëíùëücan do this via a fidelity check [ 22]. 3E.g., https://www.surety.com/digitalcopyrightprotection 43.2 Adversary Model Aùëëùë£.R‚Äôs goal is to trainFùë†such that its utility is comparable to Fùë°. Additionally,Aùëëùë£.Rwants high fidelity forFùë†, i.e., that its infer ences matchFùë°‚Äôs. This is useful for mounting subsequent evasion or membership inference attacks against Fùë°[45]. Shen et al.‚Äôs [ 51] attack satisfies both these requirements. Aùëëùë£.Rmay also take ad ditional steps to evade detection. Attack Setting. Following [ 51], we consider the blackbox setting whereAùëëùë£.Rhas no knowledge of Fùë°‚Äôs hyperparameters or archi tecture and can only observe Fùë°‚Äôs outputs for given inputs. As in prior work [ 51], we assume that the output contains node embed dings (H), useful for downstream tasks such as classification, rec ommendation engines, visualizations, etc. We assume that Aùëëùë£.R has access to a dataset Dùë†from the same distribution as Fùë°‚Äôs train ing dataDùë°. However,Dùë†andDùë°are disjoint. We revisit the details of dataset splits in Section 6. 3.3 Requirements for Ownership Verification We list desiderata for ideal GNN fingerprinting schemes that Vùëíùëü can use to decide if F?is stolen fromFùë°: R1 NonInvasive in that it does not require modifications to the training ofFùë°. R2 Effective in differentiating between Fùë†andFùëñwith low false positive/negative rates. R3 Robust in remaining effective against Aùëëùë£.R. R4 Efficient by imposing a low computational overhead. 3.4 Limitations of Prior Work We now discuss how different prior works (Section 2.2), applicable to nongraph and graph datasets, do not satisfy the above require ments. NonGraph Datasets. Focusing only on approaches tested against model extraction attacks, we discuss how the three prior fingerprint ing approaches for the image domain are not directly applicable to GNNs. We describe the limitations of prior nongraph fingerprint ing schemes below. Maini et al.‚Äôs [ 37] compute the distance of a data point to the decision boundary by adding noise to the data points, which is not clear for interconnected graph nodes [ 9]. Moreover, prior works have indicated that dataset inference incurs false positives [ 59,89]. Lukas et al. [ 36] and Peng et al. [ 46] rely on adversarial examples as fingerprints. However, unlike images, generating adversarial examples is not trivial for graphs [8, 90]. In summary, adapting nongraph fingerprinting approaches to graph datasets is not trivial, as data records in the image domain are independent. In contrast, nodes in graphs are related and satisfy homophily. Graph Datasets. Watermarking schemes have been proposed pre viously for GNNs [ 76,86]. However, watermarks in nongraph datasets can be easily removed by model extraction attacks and are hence not robust R3[35]. Their effectiveness R2against stateof theart model extraction attacks is not clear. Finally, watermarks require modifying how the model is trained, violating the non invasive requirement R1. Hence, in this work, we focus on usingfingerprints for ownership resolution in GNNs instead of water marking, which satisfies all the desirable requirements. 4 CAN GNN EMBEDDINGS SERVE AS FINGERPRINTS? We now motivate our use of GNN embeddings as a potential fin gerprinting scheme for GNNs against model extraction attacks. We then evaluate whether embeddings are helpful for model finger printing or dataset fingerprinting. Embeddings as Fingerprint for GNNs. Recall from Section 2.1 that two independently trained GNNs should differ in their output ofH. Furthermore, the stateoftheart model extraction attack against GNNs [ 51] focuses on optimizing fidelity , i.e., ensuring alignment in predictions between Fùë†andFùë°. Hence,Fùë†is likely to generate embeddings more similar to Fùë°on the same input graph thanFùëñ. This intuition forms the basis of our fingerprinting scheme, GrOVe , which uses node embeddings as a fingerprint to distinguish between Fùë†andFùëñfor ownership verification. Note thatHis inherent to GNN model computation. Hence, they are noninvasive, satisfying requirement R1. Model Ownership vs. Dataset Ownership. Having identified graph embeddings as a potential fingerprint, we want to verify whether they are helpful for model or dataset ownership. Recall from Sec tion 2.2 that the difference in fingerprinting for model ownership and dataset ownership is in how models trained on the same train ing dataset are classified. If embeddings generated from two GNNs trained on the same dataset cannot be distinguished, then embed dings are useful as fingerprints for dataset ownership. On the other hand, if embeddings generated from Fùë†, regardless of the train ing data, can be distinguished, they are helpful as fingerprints for model ownership. We test this using tSNE projections of the em beddings to visualize them for different model architectures and datasets [ 46,64]. We refer to embeddings generated from Fùë°,Fùë†, andFùëñasHùë°,Hùë†, andHùëñ, respectively. We describe our experimental setup to infer whether embeddings can be used for data or model ownership verification. Dataset Ownership. We train two models using either different or the same architecture and training dataset. When the training datasets are different, we split the dataset into three sets: D1and D2, and a verification dataset Dùë£. We use three different architec tures for each model, leading to nine pairwise combinations. We use six datasets, resulting in 54 model pairs with the same training datasets and 54 model pairs with differing training datasets. We passDùë£to both models to generate embeddings and visualize their tSNE projections. The representative graphs are shown in Figure 1. We found that in every case, the tSNE projections of the embeddings generated from Dùë£are distinguishable, even when the two models use the same dataset and architecture. This shows us thatembeddings cannot be used as a dataset fingerprint. Model Ownership. To check for model ownership, we use three models:Fùë°,Fùë†,Fùëñ, which may or may not share the same architec ture and training data as Fùë°. We set up a similar experiment to the one before. We split the dataset into two training datasets: D1and D2.D1is used to train both Fùë°andFùëñsince this is the worstcase scenario for triggering false accusations using the fingerprinting 5‚àí60‚àí40‚àí20 0 20 40 60 80‚àí75‚àí50‚àí250255075 Model 1 Model 2(a) Different Training Data ‚àí50 0 50 100‚àí100‚àí75‚àí50‚àí250255075100 Model 1 Model 2 (b) Same Training Data Figure 1: tSNE projections of the embeddings from two models trained using the same architecture on CoAuthor are distinguishable. The graphs for the other datasets can be found in Appendix A.1 scheme.Fùë†is derived fromFùë°usingD2with Shen et al.‚Äôs [ 51] state oftheart GNN model extraction attack described in Section 2.2. Similar to the previous experiment, we build multiple combinations of the three models. We use three architectures for Fùë°andFùëñ, and two forFùë†, resulting in 108 model combinations across six datasets. We plot the embeddings of Dùë£from each of the three models. We represent two of the representative graphs in Figure 2. We found that regardless of the architecture or the training data, the tSNE projections ofHùë°andHùë†are similar but distinct from Hùëñ. This motivates our choice to use embeddings as a fingerprint for model ownership. 5GROVE : FINGERPRINTING FOR GNN OWNERSHIP VERIFICATION We now describe the design of GrOVe , which uses embeddings as fingerprints. Recall thatVùëíùëüaims to identify whether F?was obtained via a model extraction attack on Fùë°(Section 3.1). As shown in Section 4, we know that the embeddings generated by Fùë°andFùë†are similar. Our verification scheme relies on this observation and identifies whether the distances between H?(generated byF?) andHùë°are close enough to suggest a model extraction attack. The simplest way to identify this is to calculate a distance metric betweenH?andHùë°. If the aggregated distances are smaller than a tuned threshold, we can classify F?andFùë†, andFùëñotherwise. However, our experiments found that the distances between ( Fùë°,Fùëñ) pairs and (Fùë°,Fùë†) pairs overlapped, leading to high error rates. This phenomenon is visualized in the distance plots in Appendix A.3. Thus, similar to the intuition used for Siamese Networks [ 29], we use an ML classifier to classify a pair of embeddings as similar or not similar . An MLbased approach stretches the distance between similar data points and compresses the distance between dissimilar data points. The ML classifier is a multilayer perceptron, denoted asCùë†ùëñùëö. Our verification scheme is divided into two phases: Phase 1 involves trainingCùë†ùëñùëö; Phase 2 includes querying Cùë†ùëñùëöwith pairs of embeddings generated by F?andFùë°onDùë£to classifyF?as either a surrogate or independent model. Cùë†ùëñùëöTraining. Figure 3 shows the process of generating training data forCùë†ùëñùëö. For eachFùë°, we train multiple sets of Fùë†andFùëñ using different architectures. VùëíùëüqueriesFùë°,Fùë†andFùëñwithDùë£ ‚àí75‚àí50‚àí25 0 25 50 75‚àí100‚àí75‚àí50‚àí250255075100Target Independent Surrogate(a) Models trained on CoAuthor dataset ‚àí60‚àí40‚àí20 0 20 40 60 80‚àí60‚àí40‚àí20020406080 Target Independent Surrogate (b) Models trained on DBLP dataset Figure 2: tSNE projections of the embeddings from Fùë†and Fùë°overlap, while those from Fùëñare distinct. The models in this plot are all trained with the GAT architecture. The plots for the rest of the datasets are in Appendix A.2 to generate embeddings. Each node in Dùë£will thus have three corresponding embeddings from each GNN, denoted as ‚Ñéùë°,‚Ñéùë†, and ‚Ñéùëñ, respectively.Vùëíùëügenerates a distance vector between ‚Ñéùë°and‚Ñéùë†, representing a positive (similar) data point. In contrast, the distance vector between ‚Ñéùë°and‚Ñéùëñis represented as a negative (not similar) data point. The distance vector is the elementwise squared distance between the two embeddings. This allows Vùëíùëüto generate many data points from one pair of models equal to the size of Dùë£.Vùëíùëü then uses this data to optimize Cùë†ùëñùëöto classify whether a pair of embeddings is similar. Verification. OnceCùë†ùëñùëöhas been trainedVùëíùëücan use it to make inferences aboutF?.Vùëíùëüqueries bothF?andFùë°withDùë£to gen erate embeddings. The distance vector is calculated between corre sponding embeddings and passed to Cùë†ùëñùëö, which outputs whether the pair is similar. If more than 50% of the pairs of embeddings are classified as similar, VùëíùëüclassifiesF?as a surrogate, and inde pendent otherwise. In our experiments we found that the precise threshold does not matter. In general, for ( Fùë°,Fùë†) pairs,‚âà90% of 6Verification Graph Dùë£Fùë°Fùë† Fùëñ Embeddings from each modelCalculate Distance Vector Calculate Distance VectorPositive Data Points Negative Data Points Figure 3: To generate training data for Cùë†ùëñùëö, an input ‚Äúverification‚Äù graph is passed to Fùë°,Fùë†andFùëñ. We then compute the distance vectors between the embeddings obtained from each of the models, namely, ( Fùë°,Fùë†) and (Fùë°,Fùëñ) which act as positive and negative data points respectively. the embeddings are similar, while for ( Fùë°,Fùëñ) pairs, only‚âà10% embeddings are classified as similar. 6 EXPERIMENTAL SETUP We evaluate GrOVe using six datasets, three model architectures, and two model extraction attacks. We describe the datasets and their splits (Section 6.1), model architectures (Section 6.2), met rics for evaluation (Section 6.3), and the model extraction attacks (Section 6.4). 6.1 Datasets Following prior work [ 51], we consider six benchmark graph datasets representing different types of graph networks. We describe the details of each of these datasets below. DBLP [44] is a citation network where the 17,716 nodes represent publications and 105,734 edges indicate citations between different publications. Each node has 1,639 features based on the keywords in the paper. This is a node classification problem with four classes indicating the publication category. Citeseer [15] is a citation network where the 4,120 nodes rep resent publications and 5,358 edges indicate citations between dif ferent publications. Each node has 602 features indicating the ab sence/presence of the corresponding word from the dictionary. This is a node classification task where the publications are categorized into six classes. Pubmed [49] is a citation network where the 19,717 nodes rep resent publications and 88,648 edges indicate citations between different publications. Each node has 500 features described by a TF/IDF weighted word vector from a dictionary which consists of 500 unique words. This is a node classification task where the publications are categorized into three classes. CoAuthor [50] is a coauthorship network where the 34,493 nodes represent different authors, which are connected with 495,924 edges if they coauthored a paper. Here, the 8,415 node features represent paper keywords for each author‚Äôs papers. This node clas sification task is to predict the most active field of study out of five possibilities for each author.ACM [70] is a heterogeneous graph that contains 3025 papers published in KDD, SIGMOD, SIGCOMM, MobiCOMM, and VLDB. Papers that the same author publishes have an edge between them, resulting in 26,256 edges. Each paper is divided into three classes (Database, Wireless Communication, Data Mining), and the 1,870 features for each node are the bagofwords representation of their keywords. Amazon [38] is an abbreviation for Amazon Copurchase Network for Photos. The 7,650 nodes represent items, and the 143,663 edges indicate whether the two items are bought together. Each of the 745 nodes features are bagofwords encoded product reviews. Each of the items is classified into one of eight product categories. Dataset Splits for Model Extraction. We split all the datasets into nonoverlapping sets. Both Fùë°andFùë†are trained and validated on two disjoint sets, each being 40% of the dataset. While the origi nal model extraction attacks use overlapping and nonoverlapping training data forFùë†, we choose a nonoverlapping dataset since that is the most challenging case for Vùëíùëü, asFùë†is distinct from Fùë°. For the same reason, Fùë°andFùëñare trained on the same set. We evaluateFùë°andFùë†on a test set that is 10% of the dataset. Finally, Dùë£is the remaining 10%. The dataset sizes are shown in Table 2 Table 2: Data splits for training and evaluating different models. DatasetFùë°TrainFùë†Train TestDùë£ CoAuthor 13797 13797 3449 3449 Pubmed 7887 7887 1972 1972 DBLP 7086 7086 1772 1772 Amazon 3060 3060 765 765 Citeseer 1648 1648 412 412 ACM 1210 1210 303 303 6.2 Model Architectures Following prior work [ 51], we use the GAT, GIN, and GraphSAGE architectures (Section 2.1). For all architectures, the hidden layer size is 256, and the final hidden layer is connected to a dense layer 7for classification. The embeddings are extracted from the last hidden layer. We use the crossentropy loss as the node classification loss, the ReLU activation function, and the Adam optimizer with an initial learning rate of 0.001. All models are trained for 200 epochs, and the model with the highest validation accuracy is selected. GIN. We use a threelayer GIN model. The neighborhood sample size is fixed at ten samples at each layer. GAT. We use a threelayer GAT model with a fixed neighborhood sample size of 10 at each layer. The first and second layers have four attention heads each. GraphSAGE. We use a twolayer GraphSAGE model. The neigh borhood sample sizes are set to 25 and 10, respectively. Following prior work [ 17], the MEAN aggregation function is used at each layer, and the dropout is set to 0.5 to prevent overfitting. Similarity Model. We use the ScikitLearn implementation of an MLPClassifier to train Cùë†ùëñùëö. We train three versions of Fùë°for each dataset using the three architectures. Each Fùë°has its ownCùë†ùëñùëö. We train three versions of Fùëñand two versions of Fùë†for eachFùë° which we use to generate the positive and negative data points as explained in Section 5. We use a twolayer MLP and find the best hyperparameters using a grid search. The hidden layer sizes in the search are either 64 or 128, and the activation function is either Tanh or ReLU. We select the best model based on 10fold cross validation. We only train Cùë†ùëñùëöon Type 1 attacks unless otherwise stated. To evaluateCùë†ùëñùëö, we train nine different versions of Fùëñand Fùë†, i.e., 45 test models with different random initialization. These additional models are used to ensure the statistical significance of the results. We ran each experiment five times and reported the average with a 95% confidence interval. 6.3 Metrics Following prior work [ 22,51], we use two metrics for evaluating the effectiveness of model extraction attacks: accuracy and fidelity. Accuracy measures the number of predictions Fùë†classifies cor rectly, compared to the groundtruth. Fidelity measures the agreement between Fùë°andFùë†. To evaluate the effectiveness of GrOVe , we use two additional metrics: False Positive Rate (FPR) is the ratio of false positives to the sum of false positives and true negatives. This indicates the fraction of independent models incorrectly classified as surrogate. False Negative Rate (FNR) is the ratio of false negatives to the sum of false negatives and true positives. This indicates the fraction of surrogate models incorrectly classified as independent. 6.4 Model Extraction Attack We use Shen et al.‚Äôs [ 51] model extraction attack against inductive GNNs from their source code4. The details of the attack have been explained in Section 2.2. As mentioned in Section 6.1, we train Fùë† onDùë†that is disjoint from Dùë°. All the hyperparameters are set to the default values presented in the original paper. The performance of these models is summarized in Table 3, and our results are similar to those reported in the original attack paper. 4https://github.com/xinleihe/GNNStealing7 EVALUATION OF GROVE We show that GrOVe satisfies the requirements outlined in Sec tion 3.3. To this end, we evaluate GrOVe ‚Äôs effectiveness (require ment R2) in differentiating between Fùë†, derived from the two types of model extraction attacks, and Fùëñ(Section 7.1). We evalu ateGrOVe ‚Äôs robustness (requirement R3) toAùëëùë£.A‚Äôs attempts at false accusations and Aùëëùë£.R‚Äôs attempts at evading verification (Section 7.2). Finally, we evaluate GrOVe ‚Äôs efficiency (requirement R4) (Section 7.3). 7.1 Effectiveness We first show that GrOVe is effective at distinguishing between Fùëñ andFùë†(requirement R2). To this end, we train three Fùëñmodels and twoFùë†models using the Type 1 attack to train Cùë†ùëñùëö. During the testing phase ofCùë†ùëñùëö, we train additional Fùëñmodels to compute the FPR andFùë†models from both Type 1 and Type 2 attacks to compute the FNR. Ideally, we expect GrOVe to have low FPR and FNR while dif ferentiating between FùëñandFùë†usingCùë†ùëñùëö. As seen in Table 4, we find that GrOVe indeed has zero false negatives against both model extraction attacks. We observe close to zero false positives across four datasets ( DBLP ,Pubmed ,Citeseer , and CoAuthor ). For the Amazon andACM datasets, we note a low false positive rate of 3.4% and 2.2%, respectively. These results show that GrOVe is effective at distinguishing be tweenFùë†andFùëñacross different datasets and different architectures, satisfying R2. 7.2 Adversarial Robustness of GrOVe We now discuss the robustness of GrOVe against attempts to evade detection byAùëëùë£.R(requirement R3).Aùëëùë£.Rcan evade detection by differentiatingFùë†fromFùë°via (1) simple evasion or (2) model retraining. Simple evasion techniques can be used by Aùëëùë£.Rto evade de tection without retraining Fùë†: (a)model replacement and (b) post processing . These are described below. Model replacement occurs when during the verification process, Vùëíùëüintends to query the model that Rùëíùë†ùëùùëúùëõùëëùëíùëü has deployed (Fùë†), butAùëëùë£.Rreplaces it by an independent model Fùëñto deceive Vùëíùëü. Our system model (Section 3.1) preempts this by requiring Rùëíùë†ùëùùëúùëõùëëùëíùëü to registerFùë†before deployment. During verification, Vùëíùëüconducts a fidelity check between the outputs of the registered and deployed models (i.e., both outputs should match perfectly) to confirm that they are the same. As both models should be identical, the fidelity score between embeddings of the same input should be perfect. Postprocessing occurs whenAùëëùë£.Rapplies a (linear) transfor mation onHùë†to change its distribution while maintaining utility. If the distances between the embeddings of any two nodes of an input graph remain relatively the same after the transformation, it will not affect the result of any downstream task. Our system model preempts this by requiring Aùëëùë£.Rto sendFùë†toVùëíùëü, who verifies whether the outputs are generated directly from Fùë†without being postprocessed. Furthermore, Vùëíùëücan inspectFùë†to ensure there are no nonstandard layers that arbitrarily transform the output (Step 3 of the Verification Process in Section 3.1). 8Table 3: Average accuracy and fidelity values (with 95% confidence intervals) of Fùë°,Fùëñ, andFùë†used in the evaluation. Values are averaged across multiple architectures (Section 6.2). DatasetFùë°AccuracyFùëñAccuracy Type 1Fùë†Accuracy Type 1Fùë†Fidelity Type 2Fùë†Accuracy Type 2Fùë†Fidelity ACM 0.906¬±0.025 0.919¬±0.021 0.888¬±0.019 0.931¬±0.019 0.896¬±0.010 0.954¬±0.020 Amazon 0.879¬±0.064 0.876¬±0.050 0.861¬±0.022 0.870¬±0.051 0.842¬±0.007 0.848¬±0.009 Citeseer 0.804¬±0.047 0.809¬±0.028 0.757¬±0.014 0.907¬±0.041 0.796¬±0.000 0.902¬±0.012 CoAuthor 0.926¬±0.005 0.928¬±0.011 0.919¬±0.019 0.949¬±0.034 0.919¬±0.004 0.948¬±0.003 DBLP 0.696¬±0.028 0.693¬±0.030 0.674¬±0.009 0.833¬±0.018 0.680¬±0.008 0.851¬±0.017 Pubmed 0.846¬±0.022 0.846¬±0.021 0.829¬±0.007 0.923¬±0.016 0.832¬±0.005 0.937¬±0.014 Table 4: Performance of GrOVe against Type 1 and Type 2 attacks. Average FPR and FNR values are reported across 5 experiments with 95% confidence intervals. Dataset FPR Type 1 FNR Type 2 FNR ACM 0.022¬±0.022 0.000¬±0.000 0.000¬±0.000 Amazon 0.034¬±0.029 0.000¬±0.000 0.000¬±0.000 Citeseer 0.000¬±0.000 0.000¬±0.000 0.000¬±0.000 CoAuthor 0.000¬±0.000 0.000¬±0.000 0.000¬±0.000 DBLP 0.000¬±0.000 0.000¬±0.000 0.000¬±0.000 Pubmed 0.002¬±0.002 0.000¬±0.000 0.000¬±0.000 Model retraining. We identify three possible techniques from prior work to evade detection via model retraining [ 36,46]: (a) finetuning , (b) double extraction , and (c) pruning . Finetuning retrains a previously trained model on a new dataset to improve model performance or change the classification task by replacing the model‚Äôs final layer. While this is popular in prior work [ 36,37,46], we argue that it cannot be used by Aùëëùë£.Rto evade detection of extracted GNN models. Recall from Section 6.4 thatFùë†consists of two independent components: the first out puts embeddings, and the second outputs class labels. Recalling (6), the embeddings are updated using an MSE loss with embeddings fromFùë°. Traditional finetuning based on different class labels will only update the classifier, not affecting the embeddings. Therefore, Aùëëùë£.Rcannot modify the embeddings using finetuning to evade detection. Double extraction involvesAùëëùë£.Rrunning two model extraction attacks to obtain the final Fùë†: first againstFùë°to get an intermediate model, followed by another attack against the intermediate model to obtainFùë†. This additional attack is to make the Fùë†distinct from Fùë°. We refer to such surrogates as Fùë†2 To satisfy the robustness experiment, GrOVe should achieve low FNR against double extraction even if Fùë†2accuracy drops by up to 5% points. An accuracy drop greater than 5% points greatly reduces model utility. We use the previously trained Cùë†ùëñùëödirectly and build additionalFùë†2models on the previously trained Fùë°models. We use the same attack for both extractions since the difference between the two attacks is the knowledge of Aùëëùë£.R, and it is unrealistic forAùëëùë£.Rto have differing knowledge when running two attacks sequentially. As before, we use two architectures for each Fùë†2per Fùë°, and create nine versions using random initialization (a total of 18 test models perFùë°). We repeat each experiment five times.We evaluated GrOVe againstFùë†2models reported in Table 5. We find that while the adversary experiences a significant loss in utility (at least 3% points in accuracy) on ACM ,Amazon , and Citeseer datasets, GrOVe still achieves zero false negatives across all datasets. This shows that GrOVe is effective in mitigating double extraction attacks against both Type 1 and Type 2 attacks and across different datasets. Pruning removes model weights to reduce computational com plexity while maintaining model utility. This alters the output dis tribution (in our case, embeddings), which could potentially affect the success of GrOVe . We experiment with prune ratios (ratio of weights set to 0) rang ing from 0.1 to 0.7 as pruning beyond resulted in a high accuracy loss (>20% points for all datasets). As before, GrOVe is robust if it achieves low FNR against Fùë†models with less than a 5% point drop in accuracy. We use the same experimental setup of training nine versions ofFùë†and pruning each one with the ratios above (a total of 18 test models per prune ratio). We report our results in Figure 5. We observe that Fùë†accuracy falls significantly after 0.4 (>5% points for all datasets). However, we also observe that the FNR increases at 0.2 for some datasets and 0.3 for others. Only the FNR for CoAuthor stays small until a ratio of 0.6. This shows that GrOVe in its basic form fails against pruning. GrOVe can be made robust against pruning attacks by adver sarially optimizing Cùë†ùëñùëö(Section 5). We do this by including the output from pruned models up to a ratio of 0.4 into the training data. Beyond a prune ratio of 0.4, the accuracy drop is large enough (> 5% points) to deter Aùëëùë£.R. Using the same experimental setup, we evaluate the success of the more robust GrOVe to mitigate pruning. We observe that GrOVe still achieves zero false negatives against the basic and double extraction attacks mentioned before. Addition ally, it achieves a lower FPR, with only a 1.4% FPR for Amazon , 0.7% FPR for Pubmed , and a 0% FPR for the other datasets. We report the results for pruning in Figure 5. It achieves nearly zero FNR for all datasets up to a prune ratio of 0.4. Noting the success of robust optimization, we conjecture that this can be used to make GrOVe robust against future evasion techniques. We, therefore, conclude that GrOVe remains effective ( R2) even in the presence of adversaries ( R3). Furthermore, adversarially training GrOVe allowsVùëíùëüto choose between resource utilization and performance. The larger and more diverse the training data for Cùë†ùëñùëö, the longer it would take to train GrOVe , and the more robust 9Table 5: Performance of Fùë†2. The model utility is comparable to Fùë†in most cases, but drops by ‚âà8%points for Amazon and ‚âà12% points for Citeseer . Dataset Type 1Fùë†2Accuracy Type 1Fùë†2Fidelity Type 2Fùë†2Accuracy Type 2Fùë†2Fidelity ACM 0.876¬±0.023 0.932¬±0.018 0.882¬±0.017 0.930¬±0.020 Amazon 0.780¬±0.046 0.782¬±0.056 0.698¬±0.216 0.695¬±0.219 Citeseer 0.681¬±0.086 0.719¬±0.086 0.679¬±0.064 0.736¬±0.093 CoAuthor 0.918¬±0.006 0.943¬±0.011 0.916¬±0.009 0.943¬±0.004 DBLP 0.686¬±0.009 0.786¬±0.027 0.678¬±0.019 0.784¬±0.036 Pubmed 0.829¬±0.005 0.923¬±0.007 0.831¬±0.004 0.930¬±0.005 0.00.10.20.30.40.50.60.70.80.9 False Negative Rate 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 Prune Ratio0.00.10.20.30.40.50.60.70.80.9Accuracy EÔ¨Äect of Prune Ratio on FNR and Utility acm amazon citeseer coauthor dblp pubmed Figure 4: GrOVe performance against pruning. Dotted lines representFùë†accuracy, and solid lines represent FNR. As the pruning ratio increases, the accuracy decreases, and the FNR increases. By default, GrOVe fails against prune ratios of 0.30.4 for most datasets. 0.00.10.20.30.40.50.60.70.80.9 False Negative Rate 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 Prune Ratio0.00.10.20.30.40.50.60.70.80.9Accuracy EÔ¨Äect of Prune Ratio on FNR and Utility acm amazon citeseer coauthor dblp pubmed Figure 5: A more robust GrOVe performs better against pruning. Dotted lines represent Fùë†accuracy, and solid lines represent FNR. Robust GrOVe works up till a prune ratio of 0.4, after which Fùë†utility decreases more than 5%. it would be. We have shown the minimum training data required to perform well against the evasion techniques we identified.7.3 Efficiency of GrOVe Table 6: Average total time in seconds (with 95% confidence intervals) taken to generate training data and train Cùë†ùëñùëö. Architectures Dataset GAT GIN GraphSAGE CoAuthor 7451¬±1548 7600¬±1205 7432¬±1237 Pubmed 2778¬±492 2612¬±257 2619¬±288 DBLP 2878¬±462 2781¬±498 2526¬±202 Amazon 2212¬±218 2228¬±171 2380¬±323 Citeseer 2214¬±124 2044¬±204 1907¬±186 ACM 1928¬±165 1888¬±223 1846¬±134 We now evaluate the efficiency of GrOVe (requirement R4). We want to ensure the computation overhead of GrOVe is reasonable. To this end, we measure the execution time to generate the training data forCùë†ùëñùëöand train it. Recall from Section 6.2 that we train multiple versions of FùëñandFùë†to generate the training data forCùë†ùëñùëö. For GrOVe , this involves building six versions of Fùëñand two versions ofFùë†along with their pruned variants (10 versions ofFùë†). These models can be trained in parallel, making it faster. However, we train them sequentially to accurately measure the total time taken, assuming just one available machine. The models were trained on a machine with two AMD EPYC 7302 16Core CPUs and eight Nvidia A100 GPUs with 40GB VRAM per GPU. We summarize the results for each target model in Table 6. It generally takes less than 3 hours to train GrOVe . The time taken to train GrOVe includes the time taken to train the additional surrogate and independent models to generate the training data and to trainCùë†ùëñùëö. The size of the dataset influences the time taken to train the additional models. CoAuthor is the largest dataset, with the longest training times, followed by DBLP andPubmed . The variation in time taken within datasets is caused by the optimization ofCùë†ùëñùëö. For instance, for Amazon , the time taken to train Cùë†ùëñùëöfor GATbasedFùë°was 187 seconds on average, while for GINbased Fùë°it took 340 seconds on average. There is no trend for which architecture takes the longest time; it is affected by the combination of dataset and architecture. GrOVe built for ACM based models was the fastest to train, with Cùë†ùëñùëötraining taking less than 100 seconds. For CoAuthor , however,Cùë†ùëñùëötraining took much longer, between 1561 to 2103 seconds. Recall that in the practical setting we describe in Section 3.1, Vùëíùëüonly trains GrOVe whenAùëêùëêùë¢ùë†ùëíùëü initiates a dispute with 10Rùëíùë†ùëùùëúùëõùëëùëíùëü . Considering most models will not encounter ownership disputes, we consider the numbers in Table 6 to be reasonable. In conclusion, we show that GrOVe satisfies the requirement of being an effective ( R2) robust ( R3) and efficient ( R4) fingerprinting scheme. 8 RELATED WORK "
164,Uncertainty Quantification in Deep Residual Neural Networks.txt,"Uncertainty quantification is an important and challenging problem in deep
learning. Previous methods rely on dropout layers which are not present in
modern deep architectures or batch normalization which is sensitive to batch
sizes. In this work, we address the problem of uncertainty quantification in
deep residual networks by using a regularization technique called stochastic
depth. We show that training residual networks using stochastic depth can be
interpreted as a variational approximation to the intractable posterior over
the weights in Bayesian neural networks. We demonstrate that by sampling from a
distribution of residual networks with varying depth and shared weights,
meaningful uncertainty estimates can be obtained. Moreover, compared to the
original formulation of residual networks, our method produces well-calibrated
softmax probabilities with only minor changes to the network's structure. We
evaluate our approach on popular computer vision datasets and measure the
quality of uncertainty estimates. We also test the robustness to domain shift
and show that our method is able to express higher predictive uncertainty on
out-of-distribution samples. Finally, we demonstrate how the proposed approach
could be used to obtain uncertainty estimates in facial verification
applications.","Uncertainty quantiÔ¨Åcation plays an important role in many realworld computer vision applications, such as au tonomous driving, cancer cell segmentation or facial recog nition. Building safe and reliable vision systems requires algorithms capable of expressing uncertainty about their deci sions. However, most current deep learning based computer vision models [ 22,28,30,36] are unable to express uncer tainty or extract reliable information about the conÔ¨Ådence in their predictions. They provide point estimates, such as predictive probabilities from the softmax layer, which are often misinterpreted as model conÔ¨Ådence [8]. A standard framework for reasoning about model uncer CONV1 R1 . . . R9 FC Residual blocks2  Figure 1. Uncertainty quantiÔ¨Åcation in deep residual neural net works. Green blocks depict active residual units whereas red blocks represent inactive units. Uncertainty estimates are obtained by performing several stochastic passes through the network while randomly switching Nresidual blocks according to the Bernoulli distribution with probability pifor every block i2[1; N]. The predictive variance 2expresses how much the model is conÔ¨Ådent in its prediction. Image source: http://pics.stir.ac.uk tainty is given by the Bayesian probability theory. However, when applied to deep neural networks Bayesian inference be comes an intractable mathematical problem typically solved by means of approximation algorithms, such as Markov Chain Monte Carlo (MCMC) [ 2] or more recent Variational Inference (VI) [ 2]. Both methods exhibit slow convergence and low efÔ¨Åciency, especially with large datasets, which are inevitable in deep learning. Recently, the focus shifted to socalled stochastic regularization techniques (SRT) such as dropout [ 31] or batch normalization [ 18] as efÔ¨Åcient approx imations to Bayesian neural networks. Gal and Ghahramani [7,8] proposed a method for estimating uncertainty in deep learning by using dropout layers. They showed that any neural network trained with dropout can be interpreted as a Bayesian approximation of a Gaussian process. Uncertainty estimates can be obtained by applying dropout masks at each forward pass and computing the variance or entropy of multiple predictions. However, most modern deep learning architectures, including residual networks [ 14], do not use dropout layers. Instead, they employ batch normalization, which itself is a strong regularization technique, rendering dropout ineffective when used within one model [17]. Ioffe and Szegedy [ 18] argue that batch normalization can be used 1arXiv:2007.04905v1  [cs.CV]  9 Jul 2020instead of dropout while using both in one model creates redundancy and might increase training time. Contributions. In this work, we study another regular ization technique introduced by Huang et al. [17], called stochastic depth . The approach exploits skip connections in deep residual networks by randomly dropping a subset of layers during training and utilizing the full depth of the network at test time. We build upon this idea and propose a novel approach for obtaining uncertainty estimates in deep residual networks. Unlike in Huang et al. [17], we do not utilize the full depth of the network at test time. Instead, we sample from a distribution of shorter networks and ob tain the expected model output by averaging the predictions. This corresponds to performing several stochastic passes through the network while randomly dropping a subset of residual blocks. Each block is dropped independently with probabilitypaccording to the Bernoulli distribution. We show that our method is effective and provides meaningful uncertainty estimates for outofdistribution samples. The approach does not require any additional layers and does not increases training time. Furthermore, it could be applied to any type of network with skip connections, including Pyra midNet [ 12] and DenseNet [ 16] or Dual Path Networks [ 5]. We present our Ô¨Åndings on the CIFAR10/100 and SVHN datasets and demonstrate an application of our method to face recognition. 2. Related Work "
416,Accelerating Robustness Verification of Deep Neural Networks Guided by Target Labels.txt,"Deep Neural Networks (DNNs) have become key components of many
safety-critical applications such as autonomous driving and medical diagnosis.
However, DNNs have been shown suffering from poor robustness because of their
susceptibility to adversarial examples such that small perturbations to an
input result in misprediction. Addressing to this concern, various approaches
have been proposed to formally verify the robustness of DNNs. Most of these
approaches reduce the verification problem to optimization problems of
searching an adversarial example for a given input so that it is not correctly
classified to the original label. However, they are limited in accuracy and
scalability. In this paper, we propose a novel approach that can accelerate the
robustness verification techniques by guiding the verification with target
labels. The key insight of our approach is that the robustness verification
problem of DNNs can be solved by verifying sub-problems of DNNs, one per target
label. Fixing the target label during verification can drastically reduce the
search space and thus improve the efficiency. We also propose an approach by
leveraging symbolic interval propagation and linear relaxation techniques to
sort the target labels in terms of chances that adversarial examples exist.
This often allows us to quickly falsify the robustness of DNNs and the
verification for remaining target labels could be avoided. Our approach is
orthogonal to, and can be integrated with, many existing verification
techniques. For evaluation purposes, we integrate it with three recent
promising DNN verification tools, i.e., MipVerify, DeepZ, and Neurify.
Experimental results show that our approach can significantly improve these
tools by 36X speedup when the perturbation distance is set in a reasonable
range.","Deep Neural Networks (DNNs) have achieved remarkable performance and ac complished unprecedented breakthrough in many complex tasks such as image classication [27,18] and speech recognition [20]. The progress makes it possi ble to apply DNNs to realworld safetycritical domains, e.g., autonomous driv ing [21,1,54] and medical diagnostics [10,41,37]. Systems in such domains mustarXiv:2007.08520v2  [cs.LG]  27 Jul 20202 Wan et al. be highly dependable and hereby their safety should be comprehensively certi ed before deployments. One of the most challenging problems in this domain is that DNNs have been shown suering from poor robustness. That is, a small modication to a valid input may cause systems to make completely wrong de cisions [47,17,35,30,7,11], which consequently result in serious consequences and even disasters. For instance, a Tesla car in autopilot mode caused a fatal crash as it failed to detect a white truck against a bright sky with white clouds [45]. Therefore, it is important and necessary to certify the robustness of DNNbased systems before deployments by proving that the neural networks can always make the same prediction for a valid input even if the input is slightly perturbed within an allowed range due to uncertainties from the environment or adversarial attacks. Many eorts have been made to certify the robustness of DNNs using formal verication techniques [6,26,38,19,12,55,58,16,42,50,13,43,44,52]. The essence of certifying the robustness is to prove mathematically the absence of adversarial examples for a DNN within a range of allowable perturbations, which are usu ally provided by a valid input and a Lnorm distance threshold. There are three main criteria of evaluating verication approaches: soundness ,completeness and scalability . The rst states that if a DNN passes the verication, then there are no adversarial examples. The second states that every robust DNN should pass the verication. The last one indicates the scale of DNNs that a verication method can handle. It is known that the verication problem of DNNs with Rec tied Linear Unit (ReLU) activation function is NPcomplete [26]. This means that sound and complete verication approaches usually have limited scalabil ity. Existing formal verication approaches either have limited scalability and can only handle small networks [26,32,8,15], or rely on abstraction techniques that simplify the verication problem for better scalability, but they may pro duce false positives [16,42,43] after loosing the completeness property due to the introduction of abstraction. Our contribution . In this work, we propose a generic approach that can en hance neural network verication techniques by guiding the verication with target labels | thus making it more amenable to verication. Our approach is based on the following key insights. Many existing approaches reduce the verication problem to some optimization problems of searching an adversarial example for a given input so that it is not correctly classied to the original la bel. We found that by xing a target label during verication, the search space could be drastically reduced so that the verication problem with respect to the target label can be eciently solved, while the overall verication problem can be solved by verifying the DNN for all the possible target labels. Specically, guided by the target label, we can eciently compute an adversarial example if there exists one for the given input and Lnorm distance threshold . In this case, the robustness of the DNN is falsied and the verication for other target labels can be avoided. Furthermore, rather than choosing target labels randomly, we propose an algorithmically ecient approach to sort the target labels by lever aging the symbolic interval propagation andlinear relaxation techniques, so thatAccelerating Robustness Verication of Deep Neural Networks 3 the target labels to which some inputs are misclassied by the DNN with larger probabilities are processed rst. This often allows us to quickly disprove the robustness of the DNN when the target DNN is not robust. Our approach is orthogonal to, and can be integrated with, many existing verication techniques which are leveraged to verify the robustness of DNNs for target labels. To evaluate the eectiveness and eciency of our approach, we integrate it with three recent promising neural network verication tools, i.e. MipVerify [50], DeepZ [42], and Neurify [52]. We compare both the verication result and the time cost for verication of the original tools and the tools in tegrated with our approach. Experimental results show that our approach can help the three tools achieve up to 36X acceleration in time eciency under rea sonable perturbation thresholds. Furthermore, the properties i.e.soundness and completeness (if satised) of the original tools are still preserved. In summary, this paper makes the following three main contributions: {A novel, generic approach for accelerating the robustness verication of neu ral networks guided by target labels. {An approach for sorting target labels by leveraging the symbolic interval propagation and linear relaxation techniques. {Extensions of three recent promising neural network verication tools with the proposed approach. Outline. Section 2 brie y introduces some preliminaries used in this work. Sec tion 3 presents our verication approach. Section 4 reports experimental results. Section 5 discusses related work. Section 6 nally concludes the paper and dis cusses some future work. 2 Preliminaries In this section, we recap some preliminaries such as feedforward deep neural networks, interval analysis, symbolic interval propagation and linear relaxation that are necessary to understand our approach. 2.1 FeedForward Deep Neural Networks In this work, we consider feedforward deep neural networks (FNNs). An llayer FNN can be considered as a function f:I!O, mapping the set of vectors I to the set of vectors O. Functionfis recursively dened as follows: x0=x; xk+1=(Wkxk+bk) fork= 0;:::;l"
267,Information Flow Coverage Metrics for Hardware Security Verification.txt,"Security graphs model attacks, defenses, mitigations, and vulnerabilities on
computer networks and systems. With proper attributes, they provide security
metrics using standard graph algorithms. A hyperflow graph is a
register-transfer level (RTL) hardware security graph that facilitates security
verification. A hyperflow graph models information flows and is annotated with
attributes that allow security metrics to measure flow paths, flow conditions,
and flow rates. Hyperflow graphs enable the understanding of hardware
vulnerabilities related to confidentiality, integrity, and availability, as
shown on the OpenTitan hardware root of trust under several threat models.","Security graphs have a long history of modeling attacks and de fenses in computer and network systems [1]‚Äì[4]. Security graphs can be automatically generated from speciÔ¨Åcations and vulnerabilities [5]. Securityrelated attributes are added to the nodes and edges, enabling security metrics to understand and reason about an attack‚Äôs severity and a vulnerability‚Äôs effectiveness. The graph can be analyzed with efÔ¨Åcient graph algorithms, e.g., shortest path, breadth and depthÔ¨Årst search, cutsets, and min/max Ô¨Çows. HyperÔ¨Çow graphs translate the salient ideas of security graphs to RTL hardware security. HyperÔ¨Çow graphs use attributes related to hardware information Ô¨Çow tracking (IFT) to model security vulnera bilities related to conÔ¨Ådentiality, integrity, and availability. HyperÔ¨Çow graphs enable hardware security metrics using graph algorithms. HyperÔ¨Çow graphs are automatically built using opensource hardware compilers [6] and can be visualized with opensource tools [7]. HyperÔ¨Çow analysis assesses information Ô¨Çows across the hardware, which is crucial for understanding security behaviors. While existing compiler dependency analysis provides information about data and control dependencies, it falls short of efÔ¨Åciently expressing and succinctly summarizing information Ô¨Çow relationships. HyperÔ¨Çow analysis expands the traditional analysis to consider noninterference and other hyperproperties. The critical innovation is to augment the analysis to consider the security labels provided by hardware information Ô¨Çow tracking. This moves the analysis beyond trace properties to hyperproperties [8]. The hyperÔ¨Çow graph is annotated with simulationbased attributes to extract securityrelevant information from a functional testbench. Thus, the hyperÔ¨Çow graph contains information relevant to functional simulation and data from the IFT security labels. Security label values summarize noninterference related to the assets in a design, which is crucial for verifying design properties pertaining to conÔ¨Ådentiality, integrity, and integrity. Simulation data provide crucial attributes like the number of times a statement is executed and how many times a statement is executed with a speciÔ¨Åc security label. The hyperÔ¨Çow graph naturally enables visualizations of infor mation Ô¨Çows that help security veriÔ¨Åcation engineers more readily understand a design‚Äôs security posture. Propertydriven hardware security veriÔ¨Åcation [9] marks design assets and aims to understand where the information related to that asset could go and under whatconditions. The hyperÔ¨Çow graph visualizes information Ô¨Çows by summarizing conditions and other relevant information related to the Ô¨Çows. This gives unique visual insights into the design‚Äôs security and provides veriÔ¨Åcation engineers with better intuition to assess weaknesses, understand vulnerabilities, and derive security properties. The contributions of this work include the following: Introducing the hyperÔ¨Çow graph ‚Äì a register transfer level security analysis and visualization model. DeÔ¨Åning attributes and metrics on the hyperÔ¨Çow graph, which gives an understanding of hardware security vulnerabilities. Demonstrating the value of the hyperÔ¨Çow graph on the Open Titan hardware root of trust. II. B ACKGROUND A. Graphbased Security Modeling and Metrics Graphs are an important abstraction for modeling and under standing security attacks, defenses, vulnerabilities, and mitigations. Security graphs enable metrics to measure the system‚Äôs vulnerabilities and mitigation effectiveness can be derived based on wellknown and efÔ¨Åcient graph algorithms. As such, there have been many security research efforts that use graphs to model attacks and defenses. The privilege graph is one of the earliest works to use graphs to understand system security [1]. It models system access control where a node denotes a user (group) privileges, and edges represent the ability of one user to extend their privileges to another user (group). The privilege graph helps understand access control policies, deÔ¨Åne vulnerabilities via path search, and evaluate probabilities of successful attacks using attributes and graph search algorithms. Attack trees formalize how to attack an asset [2], [3]. The tree‚Äôs root is the attack‚Äôs goal, and the leaf nodes deÔ¨Åne how to achieve that goal. The edges hold logical AND/OR labels that relate child nodes to their parents. The nodes have attributes that are Boolean or continuous values. Metrics can be deÔ¨Åned on the tree to determine the best plans of attack, compare the costs of attacks, understand the potential vulnerabilities, and decide where to apply mitigations. Attackdefense trees more holistically model system security by adding countermea sures and describing their interactions with attacks [4]. Attack graphs are used extensively to analyze network security problems where nodes identify a logical statement of the network conÔ¨Åguration and edges represent causal relationships between net work conÔ¨Ågurations and the attacker‚Äôs privileges [5], [10], [11]. The edges are annotated with attributes related to the probability of the attack success, time to perform the attack, or cost. Shortest path algorithms identify the attacks with the highest probability. The attack graph literature is, by and large, focused on problems related to network security. However, some recent works adopt these ideas to issues more closely related to hardware security. Koteshwara extends graphbased metrics to PCBlevel server ar chitectures [12]. Components and interfaces are nodes and edges,arXiv:2304.08263v1  [cs.CR]  12 Apr 2023respectively. They assign nodes with a base score ‚Äì a metric of its risk severity based on the common vulnerability scoring systems (CVSS) where higher is more vulnerable. The base score is somewhat ad hoc, e.g., SPI, LPC, Processors, Ethernet sockets, VGA, USB, PCIe, UART, and I2C components are vulnerable ( 0:95) since they have Trojans listed in TrustHub. The root of trust is a lot less vulnerable (0:05) since it uses mitigations and protections. And the FLASH is not vulnerable ( 0:0) since the root of trust protects it. Saha et al. [13] make a preliminary attempt to extend this to systemon chip architectures. Their analysis is performed on two small ( <30 vertices) SoClevel graphs using predeÔ¨Åned impact probabilities. HyperÔ¨Çow graphs translate securitygraph analysis to RTL hard ware. HyperÔ¨Çow graphs use hardware information Ô¨Çow tracking to model important information related to conÔ¨Ådentiality, integrity, and availability. This enables succinct metrics that help understand potential weaknesses and determine vulnerabilities. B. Hardware Information Flow Tracking Hardware information Ô¨Çow tracking (IFT) enables veriÔ¨Åcation engineers to track the information stored in assets (e.g., registers, memory locations, and signals) as it propagates throughout the hardware. Hardware IFT automates security analysis with minimal effort. Using a propertydriven design Ô¨Çow, veriÔ¨Åcation engineers identify assets and describe where their information can and cannot propagate [9]. Hardware IFT facilitates the veriÔ¨Åcation of hardware vulnerabilities related to conÔ¨Ådentiality, integrity, availability, side channels, and other threat models [14]. Hardware IFT automates tracking assets using security labels. Every RTL variable is associated with a security label that denotes the presence of relevant information Ô¨Çows. Explicit Ô¨Çows occur as a result of direct data movement, i.e., RTL assignments. Implicit Ô¨Çows are contextdependent, i.e., a Ô¨Çow from a variable in a conditional statement to a variable in the assignments that can occur due to that conditional statement. HyperÔ¨Çow graphs are unique in their ability to model information Ô¨Çows on RTL designs, which provides a succinct summary of potential security vulnerabilities. HyperÔ¨Çow graphs are annotated with attributes based on IFTenhanced simulations. Graph algorithms applied to the hyperÔ¨Çow graph uncover weaknesses and provide metrics related to different vulnerabilities. We formally deÔ¨Åne hy perÔ¨Çow graphs in the next section, describe how to automatically derive a hyperÔ¨Çow graph from a RTL hardware design, and deÔ¨Åne its annotation process. III. H YPERFLOW GRAPH AhyperÔ¨Çow graph is an intermediate representation (IR) that aids security analysis and visualization. HyperÔ¨Çow graphs depict the rela tionships between hardware design variables, including direct Ô¨Çows, conditional Ô¨Çows, information relevant to security veriÔ¨Åcation (assets, boundaries), functional simulation (assignments executed), and other important information required for hardware security analysis. A. Formal DeÔ¨Ånition A hyperÔ¨Çow graph Gis a directed graph G= (V; E)where: Vis a set of vertices annotated with attributes; Eis a set of directed edges annotated with attributes. Each vertex v2Vis an ordered pair (s;Mv)with sbeing a single design signal in the RTL design under analysis and Mvbeing a set containing simulation metadata associated with the signal s. V=fv1; v 2; :::; v n"
218,MSV Challenge 2022: NPU-HC Speaker Verification System for Low-resource Indian Languages.txt,"This report describes the NPU-HC speaker verification system submitted to the
O-COCOSDA Multi-lingual Speaker Verification (MSV) Challenge 2022, which
focuses on developing speaker verification systems for low-resource Asian
languages. We participate in the I-MSV track, which aims to develop speaker
verification systems for various Indian languages. In this challenge, we first
explore different neural network frameworks for low-resource speaker
verification. Then we leverage vanilla fine-tuning and weight transfer
fine-tuning to transfer the out-domain pre-trained models to the in-domain
Indian dataset. Specifically, the weight transfer fine-tuning aims to constrain
the distance of the weights between the pre-trained model and the fine-tuned
model, which takes advantage of the previously acquired discriminative ability
from the large-scale out-domain datasets and avoids catastrophic forgetting and
overfitting at the same time. Finally, score fusion is adopted to further
improve performance. Together with the above contributions, we obtain 0.223%
EER on the public evaluation set, ranking 2nd place on the leaderboard. On the
private evaluation set, the EER of our submitted system is 2.123% and 0.630%
for the constrained and unconstrained sub-tasks of the I-MSV track, leading to
the 1st and 3rd place in the ranking, respectively.","Speaker veriÔ¨Åcation (SV) is the task of verifying whether an input utterance matches the claimed identity ( Rosenberg ,1976 ). In recent years, deep learning has achieved remarkable success in SV ‚àó* Corresponding author.tasks, but current methods usually rely on a huge amount of labeled training data ( Nagrani et al. , 2017 ;Fan et al. ,2020 ). However, obtaining mas sive labeled data for every language is a time consuming and costly task. Therefore, the 2022 MSV challenge has been particularly designed for understanding and comparing current SV tech niques in lowresource Asian languages, where the labeled speaker data is limited in quantity. SpeciÔ¨Å cally, the challenge includes two evaluation tracks, AMSV and IMSV . The former focuses on the development of SV systems in various Asian lan guages while the latter particularly focuses on SV for Indian languages. In this challenge, we partic ipate in the IMSV track, which includes the con strained and unconstrained subtasks. For the con strained task, the speaker veriÔ¨Åcation model can be trained only with the given Ô¨Åxed training set given by the challenge organizer, while extra train ing data can be used for the unconstrained task. In particular, the Ô¨Åxed training set consists of 1000 audio recordings spoken by 100 speakers, about 155 hours in total, which is not enough to train a robust speaker veriÔ¨Åcation system from scratch. So the major challenge in the IMSV track is the data limitation. Low data resource speaker veriÔ¨Åcation has drawn much attention recently. The straightfor ward idea for the low resource problem is to leverage high resource labeled datasets (e.g., from another language) to pretrain the speaker veriÔ¨Å cation models ( Zhang et al. ,2020 ;Gusev et al. , 2020 ;Shahnawazuddin et al. ,2021 ). However, bringing in additional training datasets usually leads to a domain mismatch problem, which means that there is a distribution change or do main shift between two domains that degrades the performance of SV systems ( Wang and Deng , 2018 ). To deal with domain mismatch prob lems, recent approaches include domain adver2sarial training ( Wang et al. ,2018 ;Rohdin et al. , 2019 ), backend processing ( GarciaRomero et al. , 2014 ;Lee et al. ,2019 ), and Ô¨Ånetuning strategy (Zhang et al. ,2021a ;Tong et al. ,2020 ). In this challenge, we Ô¨Årst explore different popular speaker veriÔ¨Åcation models in the con strained IMSV subtask, most of which are vari ants of ECAPATDNN ( Desplanques et al. ,2020 ) and Resnet34 ( Heo et al. ,2020 ). Particularly for the unconstrained IMSV , we Ô¨Årst leverage high resource English language datasets, V ox Celeb1&2 ( Nagrani et al. ,2017 ,2020 ), as pre trained datasets to improve the performance of SV systems. Then to address the domain mismatch problem induced by the language difference, we study vanilla Ô¨Ånetuning and weight transfer Ô¨Åne tuning ( Zhang et al. ,2022 ;Li et al. ,2023 ) strate gies to transfer the pretrained model to the in domain model with the given Indian language dataset. SpeciÔ¨Åcally, the weight transfer Ô¨Åne tuning ( Zhang et al. ,2022 ;Li et al. ,2023 ) aims to constrain the distance of the weights between the pretrained model and the Ô¨Ånetuned model to mitigate catastrophic forgetting and overÔ¨Åtting problems during Ô¨Ånetuning. In addition, we also use score average fusion to improve the perfor mance of our SV systems. The experimental re sults demonstrate the effectiveness of the above methods and we Ô¨Ånally get 1st and 3rd place in the constrained and the unconstrained IMSV sub tasks, respectively. Our Ô¨Ånal code1is based on the SpeechBrain ( Ravanelli et al. ,2021 ). 2 Methodology "
289,Listen only to me! How well can target speech extraction handle false alarms?.txt,"Target speech extraction (TSE) extracts the speech of a target speaker in a
mixture given auxiliary clues characterizing the speaker, such as an enrollment
utterance. TSE addresses thus the challenging problem of simultaneously
performing separation and speaker identification. There has been much progress
in extraction performance following the recent development of neural networks
for speech enhancement and separation. Most studies have focused on processing
mixtures where the target speaker is actively speaking. However, the target
speaker is sometimes silent in practice, i.e., inactive speaker (IS). A typical
TSE system will tend to output a signal in IS cases, causing false alarms. It
is a severe problem for the practical deployment of TSE systems. This paper
aims at understanding better how well TSE systems can handle IS cases. We
consider two approaches to deal with IS, (1) training a system to directly
output zero signals or (2) detecting IS with an extra speaker verification
module. We perform an extensive experimental comparison of these schemes in
terms of extraction performance and IS detection using the LibriMix dataset and
reveal their pros and cons.","Enhancing a speech signal corrupted by interfering speakers has been one of the major challenges of speech signal processing. One way to tackle this problem is to use speech separation [1], which separates a speech mixture into all its sources. Research in speech separation has progressed rapidly with the advent of deep learning [2‚Äì4]. However, there are two fundamental lim itations with most separation techniques. First, separation re quires knowing or estimating the number of sources in the mix ture. Then, there is a global permutation ambiguity; the map ping between outputs speakers is arbitrary. Target speech extraction (TSE) [5] is an alternative to en hance speech in a mixture. TSE focuses on extracting only a tar get speaker‚Äôs speech instead of separating all sources by exploit ing a speaker clue to identify that speaker [5‚Äì16]. For example, we can use an enrollment utterance consisting of a short record ing containing only the voice of the target speaker [6, 7, 10]. Because TSE estimates only the speech of the target speaker, it naturally alleviates the issues of separation systems, i.e., the processing is independent of the number of sources in the mix tures, and there is no speaker ambiguity at the output. We can realize TSE using a neural network (NN) condi tioned on the target speaker clue, which directly estimates the target speech from the mixture [5‚Äì7, 10, 11, 16]. Such a TSE system must perform thus both separation andspeaker identiÔ¨Å cation internally. Most studies about TSE have assumed the tar Katerina Zmolikova was partly supported by European Union‚Äôs Horizon 2020 project No. 833635 ROXANNE.get speaker was always actively speaking in the mixtures, i.e., active speaker (AS) case. However, we argue that measuring TSE performance in such conditions does not fully represent thespeaker identiÔ¨Åcation capabilities of TSE systems. Indeed, in practice, a target speaker may be silent, i.e., inactive speaker (IS)case. In such a case, a TSE should output nothing or a zero signal. However, a TSE system trained only on AS conditions would always try to output a speechlike signal, which would cause false alarms or false positive. It is thus essential to con sider IS conditions in the design and evaluation of TSE systems. There have been only a few works dealing with the IS is sue of TSE [17‚Äì19]. These works offer two different strate gies to address the problem. The TSE with internal IS detec tion (TSEIS) scheme trains a TSE system to directly output zero signals for IS cases by including IS samples during train ing [17, 18]. The TSE+VeriÔ¨Åcation (TSEV) scheme combines TSE with speaker veriÔ¨Åcation and detects IS samples when the extracted signals do not match the target speaker characteristics of the enrollment [19]1. TSEIS is a simpler system than TSE V, but it is potentially easier to control false alarm and miss detection2with TSEV. However, these schemes have not been compared, and their impact on TSE performance has not been fully revealed. In this paper, we address this shortcoming and perform a comprehensive comparison in terms of the detection of IS and extraction performance in order to answer the follow ing question: How well can TSE systems handle IS samples? The contribution of this paper is as follows: (1) We pro pose two simple implementations of the TSEIS and TSEV schemes based on the SpeakerBeam TSE framework [16], and perform an comprehensive experimental comparison in terms of extraction and AS/IS detection performance. (2) We reveal that a TSEIS system trained with a modiÔ¨Åed signaltonoise ratio (SNR) loss can predict IS in about 90 % of the cases but also signiÔ¨Åcantly increases the number of extraction failures for AS cases. (3) We show that we can build a TSEV system from a TSE system trained only with AS samples. Such a TSEV sys tem can detect AS/IS better than a TSEIS, while maintaining high extraction performance. (4) Finally, we reveal that the en rollment duration impacts moderately extraction performance but greatly affects AS/IS detection errors of TSEV. With en rollment of 15 sec or more, we can achieve AS/IS detection with a Equal error rate (EER) of about 5 %. These results demon strate the potential of current TSE systems to detect and extract a target speaker. 2. Related works "
457,THOR -- A Neuromorphic Processor with 7.29G TSOP$^2$_mm$^2$Js Energy-Throughput Efficiency.txt,"Neuromorphic computing using biologically inspired Spiking Neural Networks
(SNNs) is a promising solution to meet Energy-Throughput (ET) efficiency needed
for edge computing devices. Neuromorphic hardware architectures that emulate
SNNs in analog/mixed-signal domains have been proposed to achieve
order-of-magnitude higher energy efficiency than all-digital architectures,
however at the expense of limited scalability, susceptibility to noise, complex
verification, and poor flexibility. On the other hand, state-of-the-art digital
neuromorphic architectures focus either on achieving high energy efficiency
(Joules/synaptic operation (SOP)) or throughput efficiency (SOPs/second/area),
resulting in poor ET efficiency. In this work, we present THOR, an all-digital
neuromorphic processor with a novel memory hierarchy and neuron update
architecture that addresses both energy consumption and throughput bottlenecks.
We implemented THOR in 28nm FDSOI CMOS technology and our post-layout results
demonstrate an ET efficiency of 7.29G $\text{TSOP}^2/\text{mm}^2\text{Js}$ at
0.9V, 400 MHz, which represents a 3X improvement over state-of-the-art digital
neuromorphic processors.","Neuromorphic computing using biologically inspired Spik ing Neural Networks (SNN) has arisen as a new paradigm that can accommodate energy and throughput requirements of edge AI processing [1]. Neuromorphic hardware aims to emulate human brain operations and offers various advantages over traditional systems, including sparse lowpower computation and highly scalable parallel processing [2]. Energy efÔ¨Åciency (Joules/synaptic operation (SOP)) and throughput efÔ¨Åciency (SOPs/second/area) are the two key metrics to evaluate a Neu romorphic architecture for edge AI applications. We combine these two metrics into one single Ô¨Ågure of merit called Energy Throughput (ET) efÔ¨Åciency in terms of GSOP2=mm2Js to efÔ¨Åciently capture the tradeoff between them and to fairly compare the different Neuromorphic architectures. Digital neuromorphic architectures have made considerable progress in recent years, however, little focus has been given to opti mizing ET efÔ¨Åciency. Based on our analysis of energy consumption, silicon area usage and throughput of the stateoftheart alldigital neuromorphic processors [3]‚Äì[7], we identify the following challenges that needs to be tackled for achieving the highest ET efÔ¨Åciency: (1) The synapse memory, which holds the individual states and parameters of the synapses is typically very large and contributes signiÔ¨Åcantly to the overall energy consumption (and area usage) as can be seen in Figure 1, which shows the energy consumption breakdown in different components of the processor. Figure 1: Energy breakdown of a stateoftheart neuromorphic processor [3] running MNIST for a single neuron event (using technology library 28nm FDSOI at 0.9V@100MHz). Different components of the architecture are explained in section III. SRAMs are typically used as onchip memory in most of the alldigital neuromorphic architectures. However, SRAMs comes with different conÔ¨Ågurations in terms of number of banks, IO or word width, depth, internal multiplexing fac tor etc, requiring an extensive design space exploration. In addition, Standard Cell Memories (SCMs) [8] are becoming increasingly popular as a substitute to relatively smaller sized SRAMs due to high energy efÔ¨Åciency despite the poor area efÔ¨Åciency. Optimizing the energy consumption and area usage of synapse memory requires an extensive analysis of memory hierarchy for the synapse memory including different memory architectures and types. (2) The neuron and synapse memories are idle between successive accesses, which contributes to a signiÔ¨Åcant amount of idle energy consumption and wastage of expensive onchip memory bandwidth. This requires a novel architecture with efÔ¨Åcient time multiplexing and pipelining of operations. (3) The scheduler is designed with Ô¨Åxed number of neurons to be processed in parallel, which is a limiting factor for scaling up the architecture for increased throughput. To address these limitations in the stateoftheart neuromor phic processing architectures and to achieve the highest ET efÔ¨Åciency, this paper contributes the following: 1) A neuromorphic processor THOR with a novel archi tecture for neuron update including a parallel neuron update scheme in the neuron event, a multithreaded scheduler for an increased throughput, and a detailed analysis on the impact of parallelism on the energy consumption. (section IV) 2) A detailed analysis of the memory hierarchy using multiple memory types and conÔ¨Ågurations. Based on our analysis we present the memory selection for THORarXiv:2212.01696v1  [cs.NE]  3 Dec 2022with conÔ¨Åguration options of the different parameters (number of banks, IO or word width, depth, internal multiplexing factor etc). (section V) 3) We perform postlayout implementation of THOR in 28nm FDSOI CMOS technology and show a high ET ef Ô¨Åciency of 7.29 GSOP2=mm2Js at 0.9V , 400 MHz). (sec tion VI) We review stateoftheart architectures in section II and relevant background information in section III. In section IV, we present THOR‚Äôs architecture followed by an energy ex ploration of different design choices and memory hierarchy in section V where we make our design choices. Finally, we present our implementation results in section VI and make a comparison with stateoftheart architectures and conclude our paper with section VII. II. R ELATED WORK "
276,A hypothesize-and-verify framework for Text Recognition using Deep Recurrent Neural Networks.txt,"Deep LSTM is an ideal candidate for text recognition. However text
recognition involves some initial image processing steps like segmentation of
lines and words which can induce error to the recognition system. Without
segmentation, learning very long range context is difficult and becomes
computationally intractable. Therefore, alternative soft decisions are needed
at the pre-processing level. This paper proposes a hybrid text recognizer using
a deep recurrent neural network with multiple layers of abstraction and long
range context along with a language model to verify the performance of the deep
neural network. In this paper we construct a multi-hypotheses tree architecture
with candidate segments of line sequences from different segmentation
algorithms at its different branches. The deep neural network is trained on
perfectly segmented data and tests each of the candidate segments, generating
unicode sequences. In the verification step, these unicode sequences are
validated using a sub-string match with the language model and best first
search is used to find the best possible combination of alternative hypothesis
from the tree structure. Thus the verification framework using language models
eliminates wrong segmentation outputs and filters recognition errors.","Most Optical Character Recognition (OCR) algorithms as sume perfect segmentation of lines and words, which is not true. In Indic scripts, the presence of vowel modiÔ¨Åers and conjucts furthur aggrevate the errors in segmentation as these modiÔ¨Åers are present in the upper or lower zone. This makes the text layout dense and decreases the interline separation. This paper proposes a text recognition framework to hypothesize and verify the sequences obtained from multi ple segmentation techniques using a deep BLSTM network and a language model to verify the performance of the deep neural network. In this paper we aim to Ô¨Ånd the best possible recognition of word sequences by searching sub strings of words derived from multiple segmentation routines. We construct a hypothesizeandverify framework in which candidate segments of word sequences derived from multiple segmentation routines are at different branches. A deep re current neural network is trained on perfectly segmented data and tests each of the candidate segments, generating unicode sequences. This work is an extension of the work on printed text recognition using Deep BLSTM wherein Deep BLSTM architecture for text recognition was proposed [1]. In the veriÔ¨Åcation stage these unicode sequences are validated using a substring match with the language model and best Ô¨Årst searchis used to Ô¨Ånd the best possible combination of alternative hypothesis from the tree structure. The search region uses a spatial context considering the preceeding and suceeding word to Ô¨Ånd the best match. This algorithm is able to learn the sequence alignment, solving the unicode reordering issues. This veriÔ¨Åcation framework eliminates insertion and deletion errors of the recognizer due to the substring match with the ngrams. This is a segmentation free script independent framework and in this paper we presents results on Oriya printed text. The language model is independently learnt on the script under recognition and character ngrams are saved. Oriya script is used due to the unavailability of OCR for this script and due to the challenges involved such as the huge number of classes and shape complexities of the script. The paper is organized as follows: Section 2 gives a brief review of the work done in this area, Section 3 presents the Deep BLSTM architecture in detail followed by Section 4 where the data processing and multihypotheses framework is discussed. The experimental results are presented in Section 5 followed by conclusion in Section 6. II. R ELATED WORK "
487,Zero-shot Fact Verification by Claim Generation.txt,"Neural models for automated fact verification have achieved promising results
thanks to the availability of large, human-annotated datasets. However, for
each new domain that requires fact verification, creating a dataset by manually
writing claims and linking them to their supporting evidence is expensive. We
develop QACG, a framework for training a robust fact verification model by
using automatically generated claims that can be supported, refuted, or
unverifiable from evidence from Wikipedia. QACG generates question-answer pairs
from the evidence and then converts them into different types of claims.
Experiments on the FEVER dataset show that our QACG framework significantly
reduces the demand for human-annotated training data. In a zero-shot scenario,
QACG improves a RoBERTa model's F1 from 50% to 77%, equivalent in performance
to 2K+ manually-curated examples. Our QACG code is publicly available.","Fact veriÔ¨Åcation aims to validate a claim in the con text of evidence. This task has attracted growing interest with the rise in disinformation in news and social media. Rapid progress has been made by training large neural models (Zhou et al., 2019; Liu et al., 2020b; Zhong et al., 2020) on the FEVER dataset (Thorne et al., 2018), containing more than 100K humancrafted (evidence, claim) pairs based on Wikipedia. Fact veriÔ¨Åcation is demanded in many domains, including news articles, social media, and scientiÔ¨Åc documents. However, it is not realistic to assume that largescale training data is available for every new domain that requires fact veriÔ¨Åcation. Creating training data by asking humans to write claims and 1https://github.com/teacherpeterpan/ ZeroshotFactVerificationsearch for evidence to support/refute them can be extremely costly. We address this problem by exploring the possi bility of automatically generating largescale (ev idence, claim) pairs to train the fact veriÔ¨Åcation model. We propose a simple yet general frame work Question Answering for Claim Generation (QACG ) to generate three types of claims from any given evidence: 1) claims that are supported by the evidence, 2) claims that are refuted by the evidence, and 3) claims that the evidence does Not have Enough Information ( NEI) to verify. To generate claims, we utilize Question Gener ation (QG) (Zhao et al., 2018; Liu et al., 2020a; Pan et al., 2020), which aims to automatically ask questions from textual inputs. QG has been shown to beneÔ¨Åt various NLP tasks, such as enriching QA corpora (Alberti et al., 2019), checking factual con sistency for summarization (Wang et al., 2020), and data augmentation for semantic parsing (Guo et al., 2018). To the best of our knowledge, we are the Ô¨Årst to employ QG for fact veriÔ¨Åcation. As illustrated in Figure 1, given a passage Pas the evidence, we Ô¨Årst employ a Question Genera torto generate a question‚Äìanswer pair (Q; A )for the evidence. We then convert (Q; A )into a claim C(QAtoClaim ) based on the following logical assumptions: a) if Pcan answer QandAis the correct answer, then Cis asupported claim; b) ifPcan answer QbutAis an incorrect answer, thenCis arefuted claim; c) if Pcannot answer Q, then Cis aNEI claim. The Question Genera tor and the QAtoClaim model are offtheshelf BART models (Lewis et al., 2020), Ô¨Ånetuned on SQuAD (Rajpurkar et al., 2016) and QA2D (Dem szky et al., 2018) datasets. We generate 100K (evidence, claim) pairs for each type of claim, which we then use to train a RoBERTa (Liu et al., 2019) model for fact veriÔ¨Å cation. We evaluate the model on three test setsarXiv:2105.14682v1  [cs.CL]  31 May 2021Evidence (ùìü)1992	Los	Angeles	riotsThe 1992 Los Angeles riots, also known as the Rodney King riots were a series of riots, lootings, arsons, and civil disturbances that occurred in Los Angeles County, California in April and May 1992. By thetime the riots ended, 63people had been killed. Extra Contexts (ùìüùíÜùíôùíï)‚ãØ‚ãØ‚ãØ‚ãØ‚ãØ‚ãØQ: Where did the Rodney King   riots happen?A: Los Angeles County Q: How many people were killed in  the Rodney King riots?A: 63Question Generator Q: Where did the Rodney King riots happen?A: San Francisco CountyAnswer ReplacementThe Rodney King riots took place in Los Angeles County.  The Rodney King riots took place in San Francisco County. 63 people were killed in the Rodney King riots.  SUPPORTEDREFUTEDNOT ENOUGH INFOQAtoClaim Model Figure 1: Overview of our QACG framework, consisting of two modules: 1) Question Generator generates questions from the evidence Pand the extra contexts Pextgiven different answers extracted from the passage (in green), and 2) QAtoClaim converts questionanswer pairs into claims with different labels. based on the FEVER dataset. Although we do not use any humanlabeled training examples, the model achieves over 70% of the F1performance of a fullysupervised setting. By Ô¨Ånetuning the model with only 100 labeled examples, we further close the performance gap, achieving 89.1% of fully supervised performance. The above results show that pretraining the fact veriÔ¨Åcation model with generated claims greatly reduces the demand for indomain human annotation. When evaluating the model on an unbiased test set for FEVER, we Ô¨Ånd that training with generated claims also produces a more robust fact veriÔ¨Åcation model. In summary, our contributions are: To the best of our knowledge, this is the Ô¨Årst work to investigate zeroshot fact veriÔ¨Åcation. We propose QACG , a novel framework to gener ate highquality claims via question generation. We show that the generated training data can greatly beneÔ¨Åt the fact veriÔ¨Åcation system in both zeroshot and fewshot learning settings. 2 Methodology "
312,Convex Formulation of Overparameterized Deep Neural Networks.txt,"Analysis of over-parameterized neural networks has drawn significant
attention in recentyears. It was shown that such systems behave like convex
systems under various restrictedsettings, such as for two-level neural
networks, and when learning is only restricted locally inthe so-called neural
tangent kernel space around specialized initializations. However, there areno
theoretical techniques that can analyze fully trained deep neural networks
encountered inpractice. This paper solves this fundamental problem by
investigating such overparameterizeddeep neural networks when fully trained. We
generalize a new technique called neural feature repopulation, originally
introduced in (Fang et al., 2019a) for two-level neural networks, to analyze
deep neural networks. It is shown that under suitable representations,
overparameterized deep neural networks are inherently convex, and when
optimized, the system can learn effective features suitable for the underlying
learning task under mild conditions. This new analysis is consistent with
empirical observations that deep neural networks are capable of learning
efficient feature representations. Therefore, the highly unexpected result of
this paper can satisfactorily explain the practical success of deep neural
networks. Empirical studies confirm that predictions of our theory are
consistent with results observed in practice.","Deep Neural Networks (DNNs) have achieved great successes in numerous real applications, such as image classication (Krizhevsky et al., 2012; Simonyan & Zisserman, 2014; He et al., 2016), face recognition (Sun et al., 2014), video understanding (YueHei Ng et al., 2015), neural language processing (Bahdanau et al., 2014; Luong et al., 2015), etc. However, compared to the empirical successes, the theoretical understanding of DNNs falls far behind. Part of the reasons might be the general perception that DNNs are highly nonconvex learning models. In recent years, there has been signicant breakthroughs (Mei et al., 2018; Chizat & Bach, 2018; Du et al., 2019a; AllenZhu et al., 2019) in analyzing overparameterized Neural Networks (NNs), which are NNs with massive neurons in hidden layer(s). It is observed from empirical studies that such NNs are easy to train (Zhang et al., 2016). And it was noted that under some restrictive settings, such as twolevel NNs (Mei et al., 2018; Chizat & Bach, 2018) and when learning is only This work was done when Cong Fang was an intern at Shenzhen Research Institute of Big Data. The author is now with Princeton University. 1arXiv:1911.07626v1  [cs.LG]  18 Nov 2019restricted locally in the neural tangent kernel space around certain initializations (Du et al., 2019a; AllenZhu et al., 2019), NNs behave like convex systems when the number of the hidden neurons goes to innity. Unfortunately, to the best of our knowledge, existing studies failed to analyze fully trained DNNs encountered in practice. In particular, the existing analysis cannot explain how DNNs can learn discriminative features specically for the underlying learning task, as observed in real applications (Zeiler & Fergus, 2014). To remedy the gap between the existing theories and practical observations, this paper develops a new theory that can be applied to fully trained DNNs. Following a similar argument in the analysis of twolevel NNs in Fang et al. (2019a), we introduce a new theoretical framework called neural feature repopulation (NFR), to reformulate overparameterized DNNs. Our results show that under suitable conditions, in the limit of innite number of hidden neurons, DNNs are innitydimensional convex learning models with appropriate reparameterization. In our framework, given a DNN, the hidden layers are regraded as features and the model output is given by a simple linear model using features of the top hidden layer. The output of a DNN, in the limit of innite number of hidden neurons, depends on the distributions of the features and the nal linear model. We show that using the NFR technique, it is possible to decouple the distributions of the features from the loss function and their impact can be integrated into the regularizer. This largely simplies the objective function. Under our framework, the feature learning process is characterized by the regularizer. When suitable regularizers are imposed, the overall objective function under special reparameterization is convex, and it guarantees that the DNN learns useful feature representations under mild conditions. Unlike the Neural Tangent Kernel approach, our theoretical framework for DNN does not require the variables to be conned in an innitesimal region. Therefore it can explain the ability of fully trained DNNs to learn target feature representations. This matches the empirical observations. More concretely, the paper is organized as follows. Section 2 discusses the relationship of this paper to earlier studies, especially recent works on the analysis of overparameterized NNs. Section 3 introduces the denition of discrete DNNs, and we introduce an importance weighting formulation which eventually motivates our NFR formulation. Section 4 describes the continuous DNN when the number of hidden nodes goes to innity in the discrete DNN. In this formulation, each hidden layer is represented by a distribution over its hidden nodes that represent functions of the input. We can further interpret a discrete DNN as a random sample of hidden nodes from a continuous DNN at each layer, and then study the variance of such random discretization. The variance formula motivates the study of a class of regularization conditions for DNNs. Using the connection between discrete and continuous (overparameterized) DNNs, we introduce the process of NFR in Section 5. In this process, an overparameterized DNN can be reformulated as a convex system that learns eective feature representations for the underlying task. Experiments are presented in Section 6 to demonstrate that our theory is consistent with empirical observations. In Section 6.1, we consider a new optimization procedure inspired by the NFR view to verify its eectiveness. Final remarks are given in Section 7. The main contributions of this work can be described as follows. We propose a new framework for analyzing overparameterized deep NN called neural feature repopulation (NFR). It can be used to remove the eect of learned feature distributions over hidden nodes from the loss function, and conne the eect only to the regularizer. This signicantly simplies the objective function. We study a class of regularizers. With these regularizers, the overparameterized DNN can 2Table 1: Some Representative Works on the Three Views for Overparameterize NNs Views Twolevel Multilevel Mean FieldMei et al. 2018 Chizat & Bach 2018Nguyen 2019 Neural Tangent KernelDu et al. 2019b Li & Liang 2018Du et al. 2019a AllenZhu et al. 2018, 2019 Neural Feature RepopulationFang et al. 2019a this work be reformulated as a convex system using NFR under certain conditions. The global solution of such a convex model guarantees useful feature representations for the underlying learning task. Our theory matches empirical ndings, and hence this theory can satisfactorily explain the success of fully trained overparameterized deep NNs. We shall also mention that the paper focuses on presenting the intuitions and consequences of the new framework. In order to make the underlying ideas easier to understand, some of the analyses are not stated with complete mathematical rigor. A more formal treatment of the results will be left to future works. Notations. For a vector x2Rd, we denotekk 1andkkto be its`1and`2norms, respectively. We letx>be the transpose of xand letxkbe the value of kth dimension of xwithk= 1;:::;d . Let [m] =f1;2;:::;mgfor a positive integer m. For a function f(x) :Rd!R, we denoterxfto be the gradient of fwith respect to x. For two real valued numbers aandb, we denote a_bto be max(a;b). Ifandare two measures on the same measurable space, we denote ifis absolutely continuous with respect to , andifand. 2 Related Work "
29,Lagrangian Decomposition for Neural Network Verification.txt,"A fundamental component of neural network verification is the computation of
bounds on the values their outputs can take. Previous methods have either used
off-the-shelf solvers, discarding the problem structure, or relaxed the problem
even further, making the bounds unnecessarily loose. We propose a novel
approach based on Lagrangian Decomposition. Our formulation admits an efficient
supergradient ascent algorithm, as well as an improved proximal algorithm. Both
the algorithms offer three advantages: (i) they yield bounds that are provably
at least as tight as previous dual algorithms relying on Lagrangian
relaxations; (ii) they are based on operations analogous to forward/backward
pass of neural networks layers and are therefore easily parallelizable,
amenable to GPU implementation and able to take advantage of the convolutional
structure of problems; and (iii) they allow for anytime stopping while still
providing valid bounds. Empirically, we show that we obtain bounds comparable
with off-the-shelf solvers in a fraction of their running time, and obtain
tighter bounds in the same time as previous dual algorithms. This results in an
overall speed-up when employing the bounds for formal verification. Code for
our algorithms is available at
https://github.com/oval-group/decomposition-plnn-bounds.","As deep learning powered systems become more and more common, the lack of robustness of neural networks and their reputation for being ‚ÄúBlack Boxes‚Äù is increasingly worrisome. In order to deploy them in critical scenarios These authors contributed equally to this work. Proceedings of the 36thConference on Uncertainty in ArtiÔ¨Åcial Intelligence (UAI) , PMLR volume 124, 2020.where safety and robustness would be a prerequisite, we need to invent techniques that can prove formal guarantees for neural network behaviour. A particularly desirable property is resistance to adversarial examples (Goodfel low et al., 2015, Szegedy et al., 2014): perturbations ma liciously crafted with the intent of fooling even extremely well performing models. After several defenses were pro posed and subsequently broken (Athalye et al., 2018, Ue sato et al., 2018), some progress has been made in being able to formally verify whether there exist any adversarial examples in the neighbourhood of a data point (Tjeng et al., 2019, Wong and Kolter, 2018). VeriÔ¨Åcation algorithms fall into three categories: unsound (some false properties are proven false), incomplete (some true properties are proven true), and complete (all prop erties are correctly veriÔ¨Åed as either true or false). A critical component of the veriÔ¨Åcation systems developed so far is the computation of lower and upper bounds on the output of neural networks when their inputs are con strained to lie in a bounded set. In incomplete veriÔ¨Åca tion, by deriving bounds on the changes of the predic tion vector under restricted perturbations, it is possible to identify safe regions of the input space. These results allow the rigorous comparison of adversarial defenses and prevent making overconÔ¨Ådent statements about their efÔ¨Åcacy (Wong and Kolter, 2018). In complete veriÔ¨Åca tion, bounds can also be used as essential subroutines of Branch and Bound complete veriÔ¨Åers (Bunel et al., 2018). Finally, bounds might also be used as a training signal to guide the network towards greater robustness and more veriÔ¨Åability (Gowal et al., 2018, Mirman et al., 2018, Wong and Kolter, 2018). Most previous algorithms for computing bounds are either computationally expensive (Ehlers, 2017) or sacriÔ¨Åce a lot of tightness in order to scale (Gowal et al., 2018, Mirman et al., 2018, Wong and Kolter, 2018). In this work, we design novel customised relaxations and their correspond ing solvers for obtaining bounds on neural networks. Our approach offers the following advantages:arXiv:2002.10410v3  [cs.LG]  17 Jun 2020While previous approaches to neural network bounds (Dvijotham et al., 2018) are based on La grangian relaxations, we derive a new family of opti mization problems for neural network bounds through Lagrangian Decomposition , which in general yields duals at least as strong as those obtained through La grangian relaxation (Guignard and Kim, 1987). We in fact prove that, in the context of ReLU networks, for any dual solution from the approach by Dvijotham et al. (2018), the bounds output by our dual are as least as tight. We demonstrate empirically that this deriva tion computes tighter bounds in the same time when using supergradient methods. We further improve on the performance by devising a proximal solver for the problem, which decomposes the task into a series of strongly convex subproblems. For each, we use an iter ative method for which we derive optimal step sizes. Both the supergradient and the proximal method op erate through linear operations similar to those used during network forward/backward passes. As a con sequence, we can leverage the convolutional struc ture when necessary, while standard solvers are of ten restricted to treating it as a general linear opera tion. Moreover, both methods are easily paralleliz able: when computing bounds on the activations at layerk, we need two solve two problems for each hidden unit of the network (for the upper and lower bounds). These can all be solved in parallel. In com plete veriÔ¨Åcation, we need to compute bounds for sev eral different problem domains at once: we solve these problems in parallel as well. Our GPU implementation thus allows us to solve several hundreds of linear pro grams at once on a single GPU, a level of parallelism that would be hard to match on CPUbased systems. Most standard linear programming based relax ations (Ehlers, 2017) will only return a valid bound if the problem is solved to optimality. Others, like the dual simplex method employed by offtheshelf solvers (Gurobi Optimization, 2020) have a very high cost per iteration and will not yield tight bounds with out incurring signiÔ¨Åcant computational costs. Both methods described in this paper are anytime (terminat ing it before convergence still provides a valid bound), and can be interrupted at very small granularity. This is useful in the context of a subroutine for complete veriÔ¨Åers, as this enables the user to choose an appropri ate speed versus accuracy tradeoff. It also offers great versatility as an incomplete veriÔ¨Åcation method. 2 RELATED WORKS "
464,One-Shot Speaker Identification for a Service Robot using a CNN-based Generic Verifier.txt,"In service robotics, there is an interest to identify the user by voice
alone. However, in application scenarios where a service robot acts as a waiter
or a store clerk, new users are expected to enter the environment frequently.
Typically, speaker identification models need to be retrained when this occurs,
which can take an impractical amount of time. In this paper, a new approach for
speaker identification through verification has been developed using a Siamese
Convolutional Neural Network architecture (SCNN), where it learns to
generically verify if two audio signals are from the same speaker. By having an
external database of recorded audio of the users, identification is carried out
by verifying the speech input with each of its entries. If new users are
encountered, it is only required to add their recorded audio to the external
database to be able to be identified, without retraining. The system was
evaluated in four different aspects: the performance of the verifier, the
performance of the system as a classifier using clean audio, its speed, and its
accuracy in real-life settings. Its performance in conjunction with its
one-shot-learning capabilities, makes the proposed system a viable alternative
for speaker identification for service robots.","It is of great interest that machines, specially service robots, interact with humans in a similar manner as a human would. Thus, there is a growing regard to correctly identify the speaker with whom the robot is interacting by their voice alone, and to do so in a reallife setting [1], [2]. In such scenarios, however, new users are often introduced in the environment, such as when a new customer enters a restaurant or when a family member visits the user‚Äôs home. Accommodating these new users is expected from a service robot, which includes iden tifying them by their voice. However, typical speaker identiÔ¨Åcation systems require a retraining process every time a new speaker is added [3]. In this work, we propose an approach that does not have this requirement (known as oneshot learning ). It relies on a generic veriÔ¨Åcation model that establishes if two audio recordings are from the same speaker. This is complemented by having an external database of audio Instituto de Investigaciones en Matem ¬¥aticas Aplicadas y en Sistemas (IIMAS), Universidad Nacional Aut ¬¥onoma de M ¬¥exico (UNAM), Mex ico. 1ijvelezt@gmail.com 2caleb.rascon@iimas.unam.mx 3gibranfp@unam.mxrecordings of the users to be identiÔ¨Åed and applying the model to each of its entries to verify if the speech input is of any of the users in the database. Once all the entries are veriÔ¨Åed, the results are used to establish from which known speaker is the speech input; this process can also deem the user as unknown. Additionally, and more im portantly, if the user is unknown and their identiÔ¨Åcation is of interest in the future, it is only required to add their speech input as another entry in the database; the veriÔ¨Åcation model does not requires to be retrained. The architecture of the proposed model is based on a Siamese Convolutional Neural Network (SCNN). The resulting veriÔ¨Åcation model in this work is able to extract proper audio features and a function that determines the similarity between both inputs so as to verify if the two recordings are from the same speaker. This system is planned to be carried out over a service robot in a reallife setting. To beneÔ¨Åt the rhythm of the humanrobot interaction, the proposed system is expected to perform in a fast manner, and it will be evaluated in this aspect. Additionally, the system is expected to have a high level of performance, so that it does not frequently mistake a user for another and cause frustration. As it is discussed in Section II, most speaker identiÔ¨Åcation systems in reallife settings have an accuracy of around 80%, and those that have greater accuracy than this require to know the speakers a priori . Moreover, most service robotics settings assume that there are a limited number of users with which to interact. Thus, we are considering any level of perfor mance above 80% with a limited number of speakers as acceptable, given the oneshotlearning nature of the proposed system. A video demonstration of the full system, as well as all relevant downloads (corpora, source code, models, etc.) can be found at http://calebrascon.info/ oneshotid/ . The remainder of this paper is organized as follows: a summary of the related works is presented in Section II; in Section III the proposed system is described, as well as the 3 main components of the core model (training data set, the representation of the data and its architecture); the methodology used for evaluating the models as well as their results are presented in Section IV; and, we conclude our work in Section V.arXiv:1809.04115v1  [eess.AS]  11 Sep 2018II. RELATED WORKS "
510,Transferring Rich Deep Features for Facial Beauty Prediction.txt,"Feature extraction plays a significant part in computer vision tasks. In this
paper, we propose a method which transfers rich deep features from a pretrained
model on face verification task and feeds the features into Bayesian ridge
regression algorithm for facial beauty prediction. We leverage the deep neural
networks that extracts more abstract features from stacked layers. Through
simple but effective feature fusion strategy, our method achieves improved or
comparable performance on SCUT-FBP dataset and ECCV HotOrNot dataset. Our
experiments demonstrate the effectiveness of the proposed method and clarify
the inner interpretability of facial beauty perception.","Facial beauty analysis [1] has been widely used in many Ô¨Åelds such as facial image beautiÔ¨Åcation APPs (e.g., MeiTu and Facetune), plastic surgery, and facebased pose analy sis [2]. In the mobile computing era, billions of images per day are acquired and uploaded to social networks and online platform, leading to the demand for better image processing and analyzing technology. Recently, thanks to the big data and highperformance computational hardware, computational and datadriven approaches have been proposed for solving these questions such as face recognition, facial expression recognition, facial beauty analysis and etc. The existing methods resort to machine learning and com puter vision techniques to analyze facial beauty and achieve promising results [3]. The methods often include image feature descriptors (such as HOG, SIFT, LBP, etc) and supervised machine learning predictors (such as SVM, KNN, DNN, LR, etc). In order to explore the best facial beauty prediction ap proach that precisely maps highlevel features into face beauty ratings, we propose a method that combines transfer learning and Bayesian regression. The method achieves the improved or comparable performance on SCUTFBP dataset [4] and ECCV HotOrNot dataset [5]. The main contributions of this paper are as follows: We apply transfer learning to our facial beauty predic tion problems for feature extraction. Experimental results show that the transferred deep features can attain more impressive performance compared with the traditionalimage feature descriptors such as HOG, LBP and gray value features. We make a detailed analysis about deep features based on knowledge adaptation. Additionally, we perform an effective feature fusion strategy to build more informative facial features in our facial beauty prediction task. Studies found that the neural networks are lack of satisfactory interpretation. We make ablative studies by visualizing the face feature and reveal the elements that inÔ¨Çuence facial beauty perception. The rest of this paper is organized as follows. Section II reviews the related works of facial descriptor and learning methods. Section III describes our proposed method in details, which include deep feature extraction and Bayesian ridge re gression. Experimental results and comparisons are presented in Section IV and Section V concludes this paper with a summary and future work. II. RELATED WORK "
418,Self-Constrained Inference Optimization on Structural Groups for Human Pose Estimation.txt,"We observe that human poses exhibit strong group-wise structural correlation
and spatial coupling between keypoints due to the biological constraints of
different body parts. This group-wise structural correlation can be explored to
improve the accuracy and robustness of human pose estimation. In this work, we
develop a self-constrained prediction-verification network to characterize and
learn the structural correlation between keypoints during training. During the
inference stage, the feedback information from the verification network allows
us to perform further optimization of pose prediction, which significantly
improves the performance of human pose estimation. Specifically, we partition
the keypoints into groups according to the biological structure of human body.
Within each group, the keypoints are further partitioned into two subsets,
high-confidence base keypoints and low-confidence terminal keypoints. We
develop a self-constrained prediction-verification network to perform forward
and backward predictions between these keypoint subsets. One fundamental
challenge in pose estimation, as well as in generic prediction tasks, is that
there is no mechanism for us to verify if the obtained pose estimation or
prediction results are accurate or not, since the ground truth is not
available. Once successfully learned, the verification network serves as an
accuracy verification module for the forward pose prediction. During the
inference stage, it can be used to guide the local optimization of the pose
estimation results of low-confidence keypoints with the self-constrained loss
on high-confidence keypoints as the objective function. Our extensive
experimental results on benchmark MS COCO and CrowdPose datasets demonstrate
that the proposed method can significantly improve the pose estimation results.","Human pose estimation aims to correctly detect and localize keypoints, i.e., hu man body joints or parts, for all persons in an input image. It is one of the funda mental computer vision tasks which plays an important role in a variety of down stream applications, such as motion capture [5,24], activity recognition [1,31], ‚ãÜCorresponding authorarXiv:2207.02425v1  [cs.CV]  6 Jul 20222 Z. Kan et al. Fig. 1. Illustration of the proposed idea of selfconstrained inference optimization of structural groups for human pose estimation. and person tracking [35,30]. Recently, remarkable process has been made in hu man pose estimation based on deep neural network methods [2,3,27,10,23,25]. For regular scenes, deep learningbased methods have already achieved remark ably accurate estimation of body keypoints and there is little space for further performance improvement [37,29,11]. However, for complex scenes with person person occlusions, large variations of appearance, and cluttered backgrounds, pose estimation remains very challenging [32,11]. We notice that, in complex scenes, the performance of pose estimation on different keypoints exhibits large variations. For example, for those visible keypoints with little interference from other persons or background, their estimation results are fairly accurate and reliable. However, for some keypoints, for example the terminal keypoints at tip locations of body parts, it is very challenging to achieve accurate pose estima tion. The low accuracy of these challenging keypoints degrades the overall pose estimation performance. Therefore, the main challenge in pose estimation is how to improve the estimation accuracy of these challenging keypoints. As summarized in Fig. 1, this work is motivated by the following two impor tant observations: (1) human poses, although exhibiting large variations due to the free styles and flexible movements of human, are however restricted by the biological structure of the body. The whole body consists of multiple parts, such as the upper limbs and lower limbs. Each body part corresponds to a subgroup of keypoints. We observe that the keypoint correlation across different body parts remains low since different body parts, such as the left and right arms, can move with totally different styles and towards different directions. However, within the same body part or within the same structural group, keypoints are more spa tially constrained by each other. This implies that keypoints can be potentially predictable from each other by exploring this unique structural correlation. Mo tivated by this observation, in this work, we propose to partition the body parts into a set of structural groups and perform groupwise structure learning and keypoint prediction refinement. (2) We have also observed that, within each group of keypoints, terminal keypoints at tip locations of the body parts, such as ankle and wrist keypoints, often suffer from lower estimation accuracy. This is because they have muchSCIO on Structural Groups for Human Pose Estimation 3 Fig. 2. Keypoints at the tip locations of body parts suffer from low confidence scores obtained from the heatmap during pose estimation. larger freedom of motion and are more easily to be occluded by other objects. Fig. 2 shows the average prediction confidence (obtained from the heatmaps) of all keypoints with yellow dots and bars representing the locations and estimation confidence for terminal keypoints, for example, wrist or ankle keypoints. We can see that the average estimation confidence of terminal keypoints are much lower than the rest. Motivated by the above two observations, we propose to partition the body keypoints into 6 structural groups according to their biological parts, and each structural group is further partitioned into two subsets: terminal keypoints and base keypoints (the rest keypoints). We develop a selfconstrained prediction verification network to learn the structural correlation between these two sub sets within each structural group. Specifically, we learn two tightly coupled networks, the prediction network Œ¶which performs the forward prediction of terminal keypoints from base keypoints, and the verification network Œìwhich performs backward prediction of the base keypoints from terminal keypoints. This predictionverification network aims to characterize the structural correla tion between keypoints within each structural group. They are jointly learned using a selfconstraint loss. Once successfully learned, the verification network Œì is then used as a performance assessment module to optimize the prediction of lowconfidence terminal keypoints based on local search and refinement within each structural group. Our extensive experimental results on benchmark MS COCO datasets demonstrate that the proposed method is able to significantly improve the pose estimation results. The rest of the paper is organized as follows. Section 2 reviews related work on human pose estimation. The proposed selfconstrained inference optimization of structural groups is presented in Section 3. Section 4 presents the experimental results, performance comparisons, and ablation studies. Section 5 concludes the paper.4 Z. Kan et al. 2 Related Work and Major Contributions "
373,A Statistical Approach to Assessing Neural Network Robustness.txt,"We present a new approach to assessing the robustness of neural networks
based on estimating the proportion of inputs for which a property is violated.
Specifically, we estimate the probability of the event that the property is
violated under an input model. Our approach critically varies from the formal
verification framework in that when the property can be violated, it provides
an informative notion of how robust the network is, rather than just the
conventional assertion that the network is not verifiable. Furthermore, it
provides an ability to scale to larger networks than formal verification
approaches. Though the framework still provides a formal guarantee of
satisfiability whenever it successfully finds one or more violations, these
advantages do come at the cost of only providing a statistical estimate of
unsatisfiability whenever no violation is found. Key to the practical success
of our approach is an adaptation of multi-level splitting, a Monte Carlo
approach for estimating the probability of rare events, to our statistical
robustness framework. We demonstrate that our approach is able to emulate
formal verification procedures on benchmark problems, while scaling to larger
networks and providing reliable additional information in the form of accurate
estimates of the violation probability.","The robustness of deep neural networks must be guaranteed in missioncritical applications where their failure could have severe realworld implications. This motivates the study of neural network veriÔ¨Åcation, in which one wishes to assert whether certain inputs in a given subdomain of the net work might lead to important properties being violated (Zakrzewski, 2001; Bunel et al., 2018). For example, in a classiÔ¨Åcation task, one might want to ensure that small perturbations of the inputs do not lead to incorrect class labels being predicted (Szegedy et al., 2013; Goodfellow et al., 2015). The classic approach to such veriÔ¨Åcation has focused on answering the binary question of whether there exist any counterexamples that violate the property of interest. We argue that this approach has two major drawbacks. Firstly, it provides no notion of how robust a network is whenever a counterexample can be found. Secondly, it creates a computational problem whenever no coun terexamples exist, as formally verifying this can be very costly and does not currently scale to the size of networks used in many applications. To give a demonstrative example, consider a neural network for classifying objects in the path of an autonomous vehicle. It will almost certainly be infeasible to train such a network that is perfectly ro bust to misclassiÔ¨Åcation. Furthermore, because the network will most likely need to be of signiÔ¨Åcant size to be effective, it is unlikely to be tractable to formally verify the network is perfectly robust, even if such a network exists. Despite this, it is still critically important to assess the robustness of the network, so that manufacturers can decide whether it is safe to deploy. Author for correspondence at info@stefanwebb.me 1arXiv:1811.07209v4  [stat.ML]  21 Feb 2019Published as a conference paper at ICLR 2019 To address the shortfalls of the classic approach, we develop a new measure of intrinsic robustness of neural networks based on the probability that a property is violated under an input distribution model. Our measure is based on two key insights. The Ô¨Årst is that for many, if not most, applications, full formal veriÔ¨Åcation is neither necessary nor realistically achievable, such that one actually desires a notion of how robust a network is to a set of inputs, not just a binary answer as to whether it is robust or not. The second is that most practical applications have some acceptable level of risk, such that it is sufÔ¨Åcient to show that the probability of a violation is below a certain threshold, rather than conÔ¨Årm that this probability is exactly zero. By providing a probability of violation, our approach is able to address the needs of applications such as our autonomous vehicle example. If the network is not perfectly robust, it provides an explicit measure of exactly how robust the network is. If the network is perfectly robust, it is still able to tractability assert that a violation event is ‚ÄúprobablyunsatisÔ¨Åable‚Äù. That is it is able to statistically conclude that the violation probability is below some tolerance threshold to true zero, even for large networks for which formal veriÔ¨Åcation would not be possible. Calculating the probability of violation is still itself a computationally challenging task, correspond ing to estimating the value of an intractable integral. In particular, in most cases, violations of the target property constitute (potentially extremely) rare events. Consequently, the simple approach of constructing a direct Monte Carlo estimate by sampling from the input model and evaluating the property will be expensive and only viable when the event is relatively common. To address this, we adapt an algorithm from the Monte Carlo literature, adaptive multilevel splitting (AMLS) (Guyader et al., 2011; Nowozin, 2015), to our network veriÔ¨Åcation setting. AMLS is explicitly de signed for prediction of rare events and our adaptation means that we are able to reliably estimate the probability of violation, even when the true value is extremely small. Our resulting framework is easy to implement, scales linearly in the cost of the forward operation of the neural network, and is agnostic both to the network architecture and input model. Assump tions such as piecewise linearity, Lipschitz continuity, or a speciÔ¨Åc network form are not required. Furthermore, it produces a diversity of samples which violate the property as a sideproduct. To summarize, our main contributions are: Reframing neural network veriÔ¨Åcation as the estimation of the probability of a violation, thereby providing a more informative robustness metric for nonveriÔ¨Åable networks; Adaptation of the AMLS method to our veriÔ¨Åcation framework to allow the tractable esti mation of our metric for large networks and rare events; Validation of our approach on several models and datasets from the literature. 2 R ELATED WORK "
179,Contraction Mapping of Feature Norms for Classifier Learning on the Data with Different Quality.txt,"The popular softmax loss and its recent extensions have achieved great
success in the deep learning-based image classification. However, the data for
training image classifiers usually has different quality. Ignoring such
problem, the correct classification of low quality data is hard to be solved.
In this paper, we discover the positive correlation between the feature norm of
an image and its quality through careful experiments on various applications
and various deep neural networks. Based on this finding, we propose a
contraction mapping function to compress the range of feature norms of training
images according to their quality and embed this contraction mapping function
into softmax loss or its extensions to produce novel learning objectives. The
experiments on various classification applications, including handwritten digit
recognition, lung nodule classification, face verification and face
recognition, demonstrate that the proposed approach is promising to effectively
deal with the problem of learning on the data with different quality and leads
to the significant and stable improvements in the classification accuracy.","In recent years, the performance of classification systems  has been significantly improved using deep neural networks  trained with softmax loss. The classical softmax loss is good  at optimi zing the inter class difference. B ut it ignor es to re duce the intra class variation.  Recently, this shortcoming is  improved by adding  the margin to the angle between the fea ture vector and the weight vector  [1], or constraining  the fea ture norms  to be fixed [2] and normalizing the  weight s to 1  [3], or utilizing these three  strategies  simultaneously  [4, 5].  Although the above extensions of softmax loss can reduce  the intraclass variance and thus improve the overall classi fication accuracy, they still suf fer from a small amount of  hardclassified samples (simplified as ‚Äúhard samples‚Äù in the   following) like classical softmax loss . This problem cannot  be solved by increasing the training iterations. The reason  behind such phenomenon is the ignorance to the difference  of data in quality  in the training or, in other words , the data  with differen t quality are treated equall y in the training. This brings disadvantages  to the low quality data, since they are   harder to be identified than good quality data .   In this paper w e discover that there is a positive correla tion between the quality of a sample and its feature norm  learned with softmax loss. We conduct the experiments on  three different applications with three different deep neural  networks to reveal this fact, and inspired by which, we pro pose a contraction mapping function of feature norms and  use it to develop novel softmax losses . By using our con traction mapping function , the feature norms of training  samples  are transformed to a narrower range according to  their quality . The good quality data‚Äôs feature norm will be  decreased and the low quality data‚Äôs feature norm will be  increased, under the constraint that the feature norm of low  quality data is still less than that of good quality one. Such  contraction mapping of feature norms  bring s the following  novel advantages  to the learning  of classifiers . First, the low  quality data will receive more attentions  in the training , in stead of be treated equally with good quality data. Second,  the difference of good and low qu ality data in learned fea ture norm will be decreas ed to reduce the intra class vari ance. Third, it is a general learning strategy and can be easily  integrated into the loss definition s, for example, integrat ed  into classical and large margin based softmax losses in this  paper. Be cause of these advantages, the resultant  new soft max losses can dramatically im prove  the classificatio n ac curacy for low quality data  and brings  the better results for  good quality one. In summary, this paper contributes to the  following aspects:    1) To the best of our knowledge, this is the first attempt  to consider the problem of data quality difference in the de sign of learning objecti ve for deep neural networks;    2) The positive correlation between the data‚Äôs quality and  its feature norm learned from  the softmax loss are discov ered;   3) A new learning idea based on the contraction mapping  of feature norms is proposed for dealing with the pro blem of  data quality difference;   4) The proposed contraction mapping of feature norms is  embedded into classical and large margin based softmax  losses to produce  new learning objectives, which lead to sig nificant and stable performance boost in their applications  to various classification tasks with various types of deep  neural networks.   2 Related Works   "
57,Neurosymbolic Reinforcement Learning with Formally Verified Exploration.txt,"We present Revel, a partially neural reinforcement learning (RL) framework
for provably safe exploration in continuous state and action spaces. A key
challenge for provably safe deep RL is that repeatedly verifying neural
networks within a learning loop is computationally infeasible. We address this
challenge using two policy classes: a general, neurosymbolic class with
approximate gradients and a more restricted class of symbolic policies that
allows efficient verification. Our learning algorithm is a mirror descent over
policies: in each iteration, it safely lifts a symbolic policy into the
neurosymbolic space, performs safe gradient updates to the resulting policy,
and projects the updated policy into the safe symbolic subset, all without
requiring explicit verification of neural networks. Our empirical results show
that Revel enforces safe exploration in many scenarios in which Constrained
Policy Optimization does not, and that it can discover policies that outperform
those learned through prior approaches to verified exploration.","Guaranteeing that an agent behaves safely during exploration is a fundamental problem in reinforce ment learning (RL) [ 13,1]. Most approaches to the problem are based on stochastic deÔ¨Ånitions of safety [ 23,7,1,7], requiring the agent to satisfy a safety constraint with high probability or in expectation. However, in applications such as autonomous robotics, unsafe agent actions ‚Äî no matter how improbable ‚Äî can lead to cascading failures with high human and Ô¨Ånancial costs. As a result, it can be important to ensure that the agent behaves safely even on worstcase inputs . A number of recent efforts [ 3,11] use formal methods to offer such worstcase guarantees during exploration. Broadly, these methods construct a space of provably safe policies before the learning process starts. Then, during exploration, a safety monitor observes the learner, forbidding all actions that cannot result from one of these safe policies. If the learner is about to take a forbidden action, a safe policy (a safety shield ) is executed instead. So far, these methods have only been used to discover policies over simple, Ô¨Ånite action spaces. Using them in more complex settings ‚Äî in particular, continuous action spaces ‚Äî is much more challenging. A key problem is that these safety monitors are constructed a priori and are blind to the internal state of the learner. As we experimentally show later in this paper, such a ‚ÄúonesizeÔ¨Åtsall‚Äù strategy can unnecessarily limit exploration and impede learner performance. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.arXiv:2009.12612v2  [cs.LG]  26 Oct 2020In this paper, we improve this state of the art through an RL framework, called REVEL1that allows learning over continuous state and action spaces, supports (partially) neural policy representations and contemporary policy gradient methods for learning, while also ensuring that every intermediate policy that the learner constructs during exploration is safe on worstcase inputs. Like previous efforts, REVEL uses monitoring and shielding. However, unlike in prior work, the monitor and the shield are updated as learning progresses. A key feature of our approach is that we repeatedly invoke a formal veriÔ¨Åer from within the learning loop. Doing this is challenging because of the high computational cost of verifying neural networks. We overcome this challenge using a neurosymbolic policy representation in which the shield and the monitor are expressed in an easilyveriÔ¨Åable symbolic form, whereas the normalmode policy is given by a neural network. Overall, this representation admits efÔ¨Åcient gradientbased learning as well as efÔ¨Åcient updates to both the shield and monitor. To learn such neurosymbolic policies, we build on PROPEL [29], a recent RL framework in which policies are represented in compact symbolic forms (albeit without consideration of safety), and design a learning algorithm that performs a functional mirror descent in the space of neurosymbolic policies. The algorithm views the set of shields as being obtained by imposing a constraint on the general policy space. Starting with a safe but suboptimal shield, it alternates between: (i) safely lifting the current shield into the unconstrained policy space by adding a neural component; (ii) safely updating this neurosymbolic policy using approximate gradients; and (iii) using a form of imitation learning to project the updated policy back into the constrained space of shields. Importantly, none of these steps requires direct veriÔ¨Åcation of neural networks. Our empirical evaluation, on a suite of continuous control problems, shows that REVEL enforces safe exploration in many scenarios where established RL algorithms (including CPO[1], which is motivated by safe RL) do not, while discovering policies that outperform policies based on static shields. Also, building on results for P ROPEL , we develop a theoretical analysis of R EVEL . In summary, the contributions of the paper are threefold. First, we introduce the Ô¨Årst RL approach to use deep policy representations and policy gradient methods while guaranteeing formally veriÔ¨Åed exploration. Second, we propose a new solution to this problem that combines ideas from RL and formal methods, and we show that our method has convergence guarantees. Third, we present promising experimental results for our method in the continuous control setting. 2 Preliminaries Safe Exploration. We formulate our problem in terms of a Markov Decision Process (MDP) that has the standard probabilistic dynamics, as well as a worstcase dynamics that is used for veriÔ¨Åcation. Formally, such an MDP is a structure M= (S;A;P;c; ;p 0;P#;SU). Here,Sis a set of environment states; Ais a set of agent actions; P(s0js;a)is a probabilistic transition function; c:SA! Ris a stateaction cost function; 0<  < 1is a discount factor; p0(s)is an initial state distribution with support S0;P#:SA! 2Sis a deterministic function that deÔ¨Ånes worstcase bounds on the environment behavior; and SUis a designated set of unsafe states that the learner must always avoid. Because our focus is on continuous domains, we assume that SandAare real vector spaces. The function P#is assumed to be available in closed form to the learner; because it captures worstcase dynamics, we require that supp(P(s0js;a))P#(s;a)for alls;a. In general, the method for obtaining P#will depend on the problem under consideration. In Section 4 we explain how we generate these worst case bounds for our experimental environments. Apolicy forMis a (stochastic) map :S!A that determines which action the agent should take in a given state. Each policy induces a probability distribution on the cost ciat each time step i. The aggregate cost of a policy isJ() = E[P i ici], whereciis the cost at the ith time step. For a setSS, we deÔ¨Åne the set of states reachi(;S)that are reachable from Sinisteps under worstcase dynamics: reach 1(;S) =S s2S;a2supp((js))P#(s;a) reach i+1(;S) = reach 1(;reachi(;S)): The policyissafeif(S ireachi(;S0))\SU=?. Ifis safe, we write Safe(). 1REVEL stands for Reinforcement learning with veriÔ¨Åed exp loration. The current implementation is available athttps://github.com/gavlegoat/safelearning . 2Algorithm 1 Reinforcement Learning with Formally VeriÔ¨Åed Exploration (R EVEL ) 1:Input: Symbolic Policy Class G& Neural Policy Class F. 2:Input: Initialg02G, with the guarantee 0`Safe(g0)for some0 3: DeÔ¨Åne neurosymbolic policy class H=fh(s)ifP#(s;f(s))thenf(s)elseg(s)g 4:fort= 1;:::;T do 5:ht LIFTH(gt;t) //lifting the new symbolic policy and proof into the blended space 6:ht UPDATEF(ht;) //policy gradient in neural policy space with learning rate  7: (gt+1;t+1) PROJECT (ht)//synthesis of safe symbolic policy and corresponding invariant 8:end for 9:Return: PolicyhT We deÔ¨Åne a learning process as a sequence of policies L=0;1;:::;m. We assume that the initial policy 0in this sequence is worstcase safe. Our algorithmic objective is to discover a learning processLsuch that the Ô¨Ånal policy mis safe and optimal, and every intermediate policy is safe: m= arg min s.t.Safe()J() (1) 80im:Safe(i): (2) Formal VeriÔ¨Åcation. Our learning algorithm relies on an oracle for formal veriÔ¨Åcation of policies. Given a policy , such a veriÔ¨Åer tries to construct an inductive proof of the property Safe(). Such a proof takes the form of an inductive invariant , deÔ¨Åned as a set of states such that: (i) includes the initial states, i.e.,S0; (ii)is closed under the worstcase transition relation, i.e., reach 1(); and (iii)does not overlap with the unsafe states, i.e., \SU=;. Intuitively, states sinare such that even under worstcase dynamics, MDP trajectories from scan never encounter an unsafe state. We use the notation `to indicate that policy can be proven safe using inductive invariant . Inductive invariants can be constructed in many ways. Our implementation uses abstract interpre tation [9], which maintains some abstract state that approximates the concrete states which the system can reach. For example, the abstract state might be a hyperinterval in the state space of the program that deÔ¨Ånes independent bounds on each state variable. Critically, this abstract state is an overapproximation , meaning that while the abstract state may include states which are not actually reachable, it will always include at least every reachable state. By starting with an abstraction of the initial states and using abstract interpretation to propagate this abstract state through the environment transitions and the policy, we can obtain an abstract state which includes all of the reachable states of the system (that is, we compute approximations of reachi(S0)for increasing i). Then if this abstract state does not include any unsafe states, we can be sure that none of the unsafe states are reachable by any concrete trajectory of the system either. 3 Learning Algorithm Our learning method is a functional mirror descent in policy space, based on approximate gradients, similar to P ROPEL [29]. The algorithm relies on two policy classes GandH, withGH . The classGcomprises the policies that we use as shields. These policies are safe and can be efÔ¨Åciently certiÔ¨Åed as such. Because automatic veriÔ¨Åcation works better on functions that belong to certain restricted classes and are represented in compact, symbolic forms, we assume some syntactic restrictions on our shields. The speciÔ¨Åc restrictions depend on the power of the veriÔ¨Åcation oracle; we describe the choices made in our implementation in Section 3.1. The larger classHconsists of neurosymbolic policies. Let Fbe a predeÔ¨Åned class of neural policies. We assume that each shield in Gcan also be expressed as a policy in F, i.e.,GF . Policiesh2H are of the form: h(s) =if(P#(s;f(s)))thenf(s)elseg(s) whereg2G,f2F, andis an inductive invariant that establishes Safe(g). We commonly denote a policyhas above by the notation (g;;f ). The ‚Äútrue‚Äù branch in the deÔ¨Ånition of hrepresents the normal mode of the policy. The condition P#(s;f(s))is the safety monitor. If this condition holds, then the action f(s)is safe, as it can 3Algorithm 2 Implementation of P ROJECTG 1:Input: A neurosymbolic policy h= (g;;f )whereg= [(g1;1);:::; (gn;n)] 2:g g 3:fort= 1;:::;T do 4:  CUTTING PLANE (i)for heuristically selected i 5:g1 i IMITATE SAFELY (f;gi; i^ );g2 i IMITATE SAFELY (f;gi; i^: ) 6:g0 SPLIT(g;i;(g1 i;i^ );(g2 i;i^: )) 7: ifD(g0;h)<D(g;h)then 8:g g0 9: end if 10:end for 11: SAFESPACE(g) 12:return (g;) only lead to states in (which does not overlap with the unsafe states). If the condition does not hold, thenfcan violate safety, and the shield gis executed in its place. In either case, his safe. As for updates to h, we do not assume that the policy gradient rHJ(h)in the spaceHexists, and approximate it by the gradient rFJ(h)in the spaceFof neural policies. We sketch our learning procedure in Algorithm 1. The algorithm starts with a (manually constructed) shieldg02Gand a corresponding invariant 0, then iteratively performs the following steps. LIFTH.This step takes as input a shield g2Gand its accompanying invariant , and constructs the policy (g;;g )2H. Note that the neural component of this policy is just the input shield g(in a neural representation). In practice, to construct this component, we can train a randomly initialized neural network to imitate g, using an algorithm such as DAGGER [26]. Because the safety of any policy (g;;f0)only depends on gand, this step is safe. UPDATEF.This procedure performs a series of gradient updates to a neurosymbolic policy h= (g;;f ). As mentioned earlier, this step uses the approximate policy gradient rFJ(h). This means that after an update, the new policy is (g;;f"
351,Scaling Model Checking for DNN Analysis via State-Space Reduction and Input Segmentation (Extended Version).txt,"Owing to their remarkable learning capabilities and performance in real-world
applications, the use of machine learning systems based on Neural Networks
(NNs) has been continuously increasing. However, various case studies and
empirical findings in the literature suggest that slight variations to NN
inputs can lead to erroneous and undesirable NN behavior. This has led to
considerable interest in their formal analysis, aiming to provide guarantees
regarding a given NN's behavior. Existing frameworks provide robustness and/or
safety guarantees for the trained NNs, using satisfiability solving and linear
programming. We proposed FANNet, the first model checking-based framework for
analyzing a broader range of NN properties. However, the state-space explosion
associated with model checking entails a scalability problem, making the FANNet
applicable only to small NNs. This work develops state-space reduction and
input segmentation approaches, to improve the scalability and timing efficiency
of formal NN analysis. Compared to the state-of-the-art FANNet, this enables
our new model checking-based framework to reduce the verification's timing
overhead by a factor of up to 8000, making the framework applicable to NNs even
with approximately $80$ times more network parameters. This in turn allows the
analysis of NN safety properties using the new framework, in addition to all
the NN properties already included with FANNet. The framework is shown to be
efficiently able to analyze properties of NNs trained on healthcare datasets as
well as the well--acknowledged ACAS Xu NNs.","The continuous improvement of Machine Learning (ML) systems, often wielding Neural Networks (NNs), has lead to an evergrowing popularity of these systems in real‚Äìworld applications. Owning to their efficient learning and relearning capabilities, high classification accuracy for testing datasets, and adaptability via transfer learning, they often find their way to numerous classification and decision‚Äìmaking tasks. These include face identification [ 73], speech recognition [30], anomaly detection [ 57], and even safety critical applications like autonomous driving [ 25] and healthcare [ 5,24]. However, as observed in numerous recent works, the NNs deployed in such systems are rarely resilient , i.e., they are extremely susceptible to misclassify or arrive at an unsafe output decision in the presence of slight input modifications [50,62]. These modifications can be in the form of imperceptible noise [ 36,37], adversarial cues [ 27], backdoors [ 42], or simply affine and photometric transformations [ 50]. Earlier attempts to ensure correct functioning of these NNs Authors‚Äô addresses: Mahum Naseer, Institute of Computer Engineering, Vienna University of Technology, Vienna, 1040, Austria, mahum.naseer@tuwien. ac.at; Osman Hasan, School of Electrical Engineering & Computer Science (SEECS), National University of Sciences & Technology (NUST), Islamabad, Pakistan, osman.hasan@seecs.nust.edu.pk; Muhammad Shafique, Division of Engineering, New York University Abu Dhabi (NYUAD), Abu Dhabi, United Arab Emirates, muhammad.shafique@nyu.edu. 1arXiv:2306.17323v2  [cs.LG]  3 Jul 2023involved empirical approaches, for instance using gradient based methods [ 46,62] to identify the adversarial noise patterns that would lead the NN to misclassify benign inputs. Although such attempts provide evidence to the lack of resilience of NNs, they are insufficient to provide any guarantees regarding NNs‚Äô resilience in the case when no adversarial noise is found. To deal with the aforementioned problem, there has been a great interest towards the rigorous evaluation of NNs, using formal verification, in recent years [ 9,35,63]. This usually involves checking resilience properties, like robustness and safety, of the NNs using Satisfiability (SAT) checking or Linear Programming (LP). However, the exploration of formal approaches beyond SAT and LP, to analyze wider variety of NN‚Äôs properties, remains largely neglected. To the best of our knowledge, our prior work on Formal Analysis of Neural Networks (FANNet) [ 48] was the first attempt to analyze NN using model checking. The framework was applicable for the verification and analysis of multiple NN properties namely: robustness under constrained noise bounds, noise tolerance, training bias and input node sensitivity. However, the FANNet framework provided limited scalability for formal analysis owing to the large state‚Äìtransition system it generated, even for relatively small NNs. Hence, the applicability of the framework was limited to small NNs only. This work introduces FANNet +1, an enhanced model checking‚Äìbased formal analysis framework for NNs that overcomes the limitations of FANNet, and provides significant improvement over FANNet in terms of scalability, timing‚Äìefficiency and the scope of NN properties analyzed by the framework. In particular, the novel contributions of this work are as follows : (1)Providing novel state‚Äìspace reduction techniques to reduce the size of the NN‚Äôs state‚Äìtransition system (Section 5.1). (2)Providing coarse‚Äìgrain and random input segmentation approaches, to split the input domain into more man ageable sub‚Äìdomains, to aid model checking (Section 5.2). (3)Leveraging the framework for the automated collection of a large database of counterexamples, which assist in an improved analysis of the sensitivity of input nodes and the detection of training bias (Section 5.3). (4)Comparing the timing overhead of simulation‚Äìbased testing, FANNet [ 48] and the proposed framework. The proposed framework reduces the timing‚Äìcost of model checking by a factor of up to 8000 (Section 7.1). (5)Making use of the input sub‚Äìdomains to verify safety properties of NNs, in addition to robustness under constrained noise, noise tolerance, training bias and input node sensitivity properties (Section 7.4). (6)Deploying the above techniques to demonstrate the applicability of the new framework on NN case studies with up to 80times more parameters than the ones used in FANNet, thereby illustrating better scalability and applicability to more complex networks (Sections 6 and 7). Paper Organization .The rest of the paper is organized as follows. Section 2 provides an overview of the formal analysis approaches available in the literature for NNs. Section 3 defines the basic NN and model checking concepts and formalism relevant to this paper. Section 4 gives a summary of the framework FANNet. Section 5 provides an overview for our proposed framework FANNet +for the formal NN analysis, while elaborating on the proposed optimizations to improve the scalability, timing‚Äìefficiency and scope of addressed NN properties of the framework. Section 6 highlights the NNs and datasets used to demonstrate the applicability of our framework for the various NN properties. Section 7 presents the results of analysis for the given NNs, also comparing timing‚Äìoverhead of testing, FANNet and FANNet +. Finally, Section 8 concludes the paper. 1https://github.com/Mahum123/FANNetPlus 22 RELATED WORK "
141,Efficient FPGA-based ECDSA Verification Engine for Permissioned Blockchains.txt,"As enterprises embrace blockchain technology, many real-world applications
have been developed and deployed using permissioned blockchain platforms
(access to network is controlled and given to only nodes with known
identities). Such blockchain platforms heavily depend on cryptography to
provide a layer of trust within the network, thus verification of cryptographic
signatures often becomes the bottleneck. The Elliptic Curve Digital Signature
Algorithm (ECDSA) is the most commonly used cryptographic scheme in
permissioned blockchains. In this paper, we propose an efficient implementation
of ECDSA signature verification on an FPGA, in order to improve the performance
of permissioned blockchains that aim to use FPGA-based hardware accelerators.
  We propose several optimizations for modular arithmetic (e.g., custom
multipliers and fast modular reduction) and point arithmetic (e.g., reduced
number of point double and addition operations, and optimal width NAF
representation). Based on these optimized modular and point arithmetic modules,
we propose an ECDSA verification engine that can be used by any application for
fast verification of ECDSA signatures. We further optimize our ECDSA
verification engine for Hyperledger Fabric (one of the most widely used
permissioned blockchain platforms) by moving carefully selected operations to a
precomputation block, thus simplifying the critical path of ECDSA signature
verification. From our implementation on Xilinx Alveo U250 accelerator board
with target frequency of 250MHz, our ECDSA verification engine can perform a
single verification in $760\mu s$ resulting in a throughput of 1,315
verifications per second, which is ~2.5x faster than state-of-the-art
FPGA-based implementations. Our Hyperledger Fabric-specific ECDSA engine can
perform a single verification in $368\mu s$ with a throughput of 2,717
verifications per second.","Beyond the hype, blockchain technology is emerging as one of the most disruptive technologies, with realworld use cases in many domains from digital identity management to financial services, supply chains, and product provenance. The blockchain technology essentially provides a mechanism to execute and record transac tions (representative of business logic) in an immutable ledger, by grouping transactions into blocks and creating a hashlinked chain of those blocks. The nodes in a blockchain network agree upon a total order of the blocks and transactions in each block (consensus), and each node maintains its own copy of the ledger, resulting in a ‚àóWork done during internship at Xilinx.distributed ledger. The beauty of blockchain technology is that it seamlessly combines consensus mechanisms with cryptography to provide a layer of trust for executing and recording transactions within a network of mutually untrusting nodes. Blockchains are generally categorized into two types. In public blockchains, such as Bitcoin and Ethereum, any node can participate in the network without a specific identity and proofofwork based consensus is used. Proofofwork consensus is computationally very intensive because of the massive amounts of hashes that need to be computed, and thus becomes the bottleneck. Consequently, public blockchains use hardware acceleration for hashing. For ex ample, Bitcoin network is dominated by ASIC based nodes while GPU based nodes dominate the Ethereum network [ 29]. In permis sioned blockchains, on the other hand, only nodes with known identities are part of and allowed to interact with the network, while the consensus is delegated to only a few nodes (based on BFT or CFT protocols [ 1]). Consequently, nodes are authenticated and transactions are validated cryptographically, thus cryptographic operations become the bottleneck rather than the consensus mech anism [ 35]. Typically, permissioned blockchains are deployed on multicore servers to benefit from some parallelism available across processing of multiple transactions. Since permissioned blockchains provide trust through crypto graphic authentication, and data integrity and replication through distributed ledger, they are becoming increasingly popular for implementation of enterprise applications. Many permissioned blockchain platforms such as Hyperledger Fabric [ 13], Quorum [ 5] and Corda [ 27] are now available. Fabric is an opensource and enterprisegrade implementation of a permissioned blockchain, and is one of the most widely used platforms with many realworld applications already developed and deployed from finance and sup ply chain domains [6, 7]. In a Hyperledger (HL) Fabric network, one of the nodes is a validator peer, which is responsible for validating a block and all of its transactions, before committing that block to the ledger. Many recent works [ 3,9,15,35] have shown that validator peer is the major bottleneck and critically affects the peak throughput. Some of these works [ 3,15,36] further demonstrated that verification of cryptographic signatures is the major bottleneck inside a validator peer. By default, Fabric uses 256bit ECDSA scheme for signature generation and verification. Validation of a block involves veri fication of its creator‚Äôs ECDSA signature, and validation of each transaction in a block involves verification of multiple ECDSA sig natures (from creator and different peers in the network). Similar validation nodes exist in other permissioned blockchains such as Quorum [ 5] and Hyperledger Besu [ 14] (permissioned variants of Ethereum).arXiv:2112.02229v1  [cs.CR]  4 Dec 2021Rashmi Agrawal, Ji Yang, and Haris Javaid Hardware acceleration was recently proposed for validation of blocks in permissioned blockchains, specifically HL Fabric. The work in [ 16] proposed a CPUFPGA based system where a multi core server with a networkattached FPGA card (connected to the CPU via PCIe) is used to accelerate validator peer of a Fabric net work. All the computeintensive operations of validation were of floaded to the FPGA accelerator, including verification of ECDSA signatures. Although the work in [ 16] demonstrated an order of magnitude speedup in block validation compared to CPUonly implementation, interestingly enough, the ECDSA signature verifi cation still turned out to be the critical path in the FPGA accelerator. Therefore, in this paper, we focus on an efficient FPGAbased im plementation of ECDSA signature verification, in order to improve performance of permissioned blockchains that aim to use FPGA based accelerators. More specifically, we focus on accelerating ECDSA signature verification over NIST ùëÉ256elliptic curve. Working with NIST ùëÉ 256curve requires performing 256bit modular and point arithmetic operations. This is challenging to implement on FPGAs because 256 bit wide multipliers, adders/subtractors, and dividers are not readily available. Therefore, a naive implementation will lead to a resource intensive design, leaving less resources for other operations of an accelerator. This, in turn, makes it challenging to fit the entire accelerator on an FPGA and meet the required timing constraints. In particular, we make the following contributions: ‚Ä¢FPGAspecific optimizations for modular arithmetic: We present algorithmic optimizations for modular arithmetic mod ules to enable optimized FPGAbased implementations. We specif ically propose a custom 256bit multiplier for integer multiplica tion (used in modular multiplication) and a 258bit multiplier for Barrett reduction module. These multipliers efficiently leverage internal multipliers and registers of the DSP blocks in FPGA for better performance. We also propose an efficient algorithm to perform fast modular reduction over ùëÉ256without using expensive 256bit comparators. ‚Ä¢Algorithmic optimizations for point arithmetic: We present optimizations for simultaneouspoint and fixedpoint multipli cation algorithms (used in ECDSA verification) by reducing the overall number of point double and addition operations respec tively. We use projective Chudnovsky coordinate system alongwith optimal width for nonadjacent form (NAF) representation to further reduce the total number of point arithmetic operations. ‚Ä¢HL Fabricspecific ECDSA verification: We present a fast ECDSA signature verification engine by leveraging the fact that the generator point Gis fixed and the public key Kcan be extracted in advance. This allows us to move a major chunk of point arithmetic from ECDSA verification to a precompute block. Consequently, the point arithmetic during actual ECDSA computation reduces to just point addition operations, resulting in a much faster signature verification. We implemented our optimized ECDSA verification engines on Xilinx Alveo U250 board [ 40] with a target frequency of 250MHz. For modular arithmetic modules, we observe on average 1.5√óspeed up compared to [ 10], while for point arithmetic modules, we ob serve on average 3.2√óspeedup compared to the stateoftheart implementations [ 10,19,21,22,31,37]. Our ECDSA verification engine, using these modules, performs a signature verification in 760ùúáùë†resulting in a throughput of 1,315verifications per second, which is ~ 2.5√ófaster than the existing FPGAbased implementa tions [ 8,18]. With HL Fabricspecific optimizations, our ECDSA verification engine can perform a signature verification in 368ùúáùë† resulting in a throughput of 2,717verifications per second. 2 BACKGROUND AND PRELIMINARIES 2.1 Blockchain Machine Figure 1(a) depicts a simplified overview of hardware accelerator for HL Fabric that was proposed in [ 16]. The blocks are received in the FPGA accelerator card through the integrated network inter face. The first module, ProtocolProcessor, processes the incoming packets and extracts relevant data, such as block id, number of trans actions in the block, ECDSA signatures, public keys from identity certificates, etc. The second module, BlockProcessor, uses this data to validate the block and its transactions, before committing the transactions. Once a block is validated, the Fabric software running on CPU accesses validation results from hardware and continues on with committing the block to the ledger. Internally, the BlockProcessor uses a configurable number of ECDSA verification engines distributed across multiple stages to process the ECDSA verifications as fast as possible. Each ECDSA engine accepts a verification request in the form of {signature, key, (a)                                                                            Server FPGA CardBlockProcessor TxVerifyProtocolProcessor BlockVerify . . .ECDSA enginePacket ProcessorData Processor Hash Calc.Data Writer Register Map Network InterfaceCPU PCIe ECDSA engine ECDSA engineTxVscc . . .ECDSA engine ECDSA engineTxCommit Elliptic curv e parameter , a = 3  Gener ator point on the curv e,                       = 6b17d1f2e12c4247 f8bce6e563a440f2       77037d812deb33a0 f4a13945d898c296     = 4fe342e2fe1a7f9b 8ee7eb4a7c0f9e16       2bce33576b315ece cbb6406837bf51f5    Order of the curv e, n   n = ffffffff00000000 ffffffffffffffff       bce6faada7179e84 f3b9cac2fc632551  Prime P256, p = 2256  2224 + 2192 + 296  1   p = ffffffff00000001 0000000000000000        00000000ffffffff ffffffffffffffff (b) Domain Parameters Figure 1: Blockchain Machine: (a) FPGAbased hardware accelerator, (b) Domain parameters for Hyperledger Fabric.Efficient FPGAbased ECDSA Verification Engine for Permissioned Blockchains hash}, where signature includes both its r and s components, key is the public key of the signer with both x and y components, and hash corresponds to the hash of message (e.g., block or transaction). Typi cally, the hash is computed as part of the ECDSA verification, but in Blockchain Machine, it is precomputed by the ProtocolProcessor for better performance. The work in [ 16] reported that a single ECDSA verification was the slowest operation in their hardware accelerator. Therefore, in this paper, we design an efficient FPGAbased ECDSA verification engine that can be used inside the Blockchain Machine, or similar hardware accelerators for permissioned blockchains. 2.2 ECC An elliptic curveEover a prime field Fùëùis defined by a pair of tuple(ùë•,ùë¶)satisfying the Weierstrass equation ùë¶2=ùë•3+ùëéùë•+ùëè (1) whereùëéandùëèbelong to a Galois field ùê∫ùêπ(ùëù)withùëù>3and Fùëù=ùê∫ùêπ(ùëù). Point arithmetic allows us to compute any point Pùëñ=(ùë•ùëñ,ùë¶ùëñ)on the elliptic curve. Addition of two points PandQ, whereP‚â†Q, is defined byR=P+Q . However, whenP=Q, point addition is performed as a point double operation, resulting in2P. Although point addition and double operations can be per formed in affine or projective coordinates, affine coordinates are not preferred as they require expensive modulo inverse computa tions [ 18]. In this work, we focus on performing point addition and point double operations in projective Chudnovsky coordinates [ 4] where each pointPis represented as a quintuple (ùëã,ùëå,ùëç,ùëç2,ùëç3), which corresponds to the affine point (ùë•=ùëã/ùëç2,ùë¶=ùëå/ùëç3). These coordinates give a speed benefit over affine coordinates when the cost for modulo inversion is significantly higher than the modular multiplication. Therefore, we use projective Chudnovsky coordi nates because FPGAs have DSP blocks with multipliers that can perform fast multiplications. The point addition and double equa tions in projective Chudnovsky coordinates are given in Table 1. For NIST Prime curves, which include ùëÉ256that is used in HL Fabric, domain parameters are given in FIPS 186‚àí4[23] and are listed along with Figure 1(b) for reference. Table 1: Point addition and double equations in projective Chudnovsky coordinates. Point Addition (ùëã1,ùëå1,ùëç1,ùëç2 1,ùëç3 1,ùëã2,ùëå2,ùëç2,ùëç2 2,ùëç3 2)Point Double (ùëã,ùëå,ùëç,ùëç2,ùëç3) ùëà1=ùëã1‚àóùëç2 2,ùëà2=ùëã2‚àóùëç2 1ùëÜ=4‚àóùëã‚àóùëå2 ùëÜ1=ùëå1‚àóùëç3 2,ùëÜ2=ùëå2‚àóùëç3 1ùëÄ=3‚àóùëã2+ùëé‚àó(ùëç2)2 ùêª=ùëà2‚àíùëà1,ùëÖ=ùëÜ2‚àíùëÜ1 ùëã1=ùëÄ2‚àí2‚àóùëÜ ùëã3=ùëÖ2‚àíùêª3‚àí2‚àóùëà1‚àóùêª2ùëå1=ùëÄ‚àó(ùëÜ‚àíùëã1)‚àí8‚àóùëå4 ùëå3=ùëÖ‚àó(ùëà1‚àóùêª2‚àíùëã3)‚àíùëÜ1‚àóùêª3ùëç1=2‚àóùëå‚àóùëç ùëç3=ùêª‚àóùëç1‚àóùëç2 ùëç2 1=ùëç2 1 ùëç2 3=ùëç2 3,ùëç3 3=ùëç2 3‚àóùëç3 ùëç3 1=ùëç2 1‚àóùëç1 Return(ùëã3,ùëå3,ùëç3,ùëç2 3,ùëç3 3) Return(ùëã1,ùëå1,ùëç1,ùëç2 1,ùëç3 1) 3 RELATED WORK "
369,Spatially Varying Nanophotonic Neural Networks.txt,"The explosive growth of computation and energy cost of artificial
intelligence has spurred strong interests in new computing modalities as
potential alternatives to conventional electronic processors. Photonic
processors that execute operations using photons instead of electrons, have
promised to enable optical neural networks with ultra-low latency and power
consumption. However, existing optical neural networks, limited by the
underlying network designs, have achieved image recognition accuracy much lower
than state-of-the-art electronic neural networks. In this work, we close this
gap by introducing a large-kernel spatially-varying convolutional neural
network learned via low-dimensional reparameterization techniques. We
experimentally instantiate the network with a flat meta-optical system that
encompasses an array of nanophotonic structures designed to induce
angle-dependent responses. Combined with an extremely lightweight electronic
backend with approximately 2K parameters we demonstrate a nanophotonic neural
network reaches 73.80\% blind test classification accuracy on CIFAR-10 dataset,
and, as such, the first time, an optical neural network outperforms the first
modern digital neural network -- AlexNet (72.64\%) with 57M parameters,
bringing optical neural network into modern deep learning era.","Increasing demands for highperformance artificial intelligence in the last decade have levied im mense pressure on computing architectures across domains, including robotics, transportation, per sonal devices, medical imaging and scientific imaging. Although electronic microprocessors have undergone drastic evolution over the past 50 years1, providing us with generalpurpose CPUs and custom accelerator platforms ( e.g., GPU, DSP ASICs), this growth rate is far outpaced by the ex plosive growth of AI models. Specifically, Moore‚Äôs law delivers a doubling in transistor counts every two years2whereas deep neural networks (DNN)3, arguably the most influential algorithms in AI, have doubled in size every six months4. However, in fact, the end of voltage scaling has made the power consumption, and not the number of transistors, the principal factor limiting further im provements in computing performance5. Overcoming this limitation and radically reducing com pute latency and power consumption could drive unprecedented applications from lowpower edge computation in the camera, potentially enabling computation in thin eyeglasses or microrobots, and reducing power consumption in data centers used for training of neural network architectures. ‚àóIndicates equal contribution. 1arXiv:2308.03407v1  [cs.CV]  7 Aug 2023Optical computing has been proposed as an approach to alleviate several inherent limit ations of digital electronics, e.g., compute speed, heat dissipation, and power, and could po tentially boost computational throughput, processing speed, and energy efficiency by orders of magnitude6‚Äì8. Although generalpurpose optical computing has yet to be practically realized due to obstacles such as larger physical footprints and inefficient optical switches9, 10, several signific ant advances have already been made towards optical/photonic processors tailored specifically for AI11‚Äì13. Representative examples include optical computers that perform widelyused sig nal processing operators14‚Äì18, (e.g., spatial/temporal differentiation, integration, and convolution) and mathematical solvers19, 20with performance far beyond those of contemporary electronic pro cessors. Most strikingly, optical neural networks (ONN)21‚Äì37can perform AI inference tasks such as image recognition when implemented as fullyoptical or hybrid optoelectronical computers. Existing ONNs can be broadly classified into two categories based upon either integrated photonics21‚Äì27(e.g., Mach‚ÄìZehnder interferometers23, phase change materials21, microring resonators26, multimode fibers27) for physically realizing multiply‚Äìaccumulate (MAC) operations, or with free space optics28‚Äì38that implement convolutional layers with light propagation through diffractive elements ( e.g., 3Dprinted surfaces28, 4F optical correlators37, optical masks35, metasurfaces36). The design of these ONN architectures has been fundamentally restricted by the underlying net work design, including the challenge of scaling to large numbers of neurons (within integrated photonic circuits) and the lack of scalable energyefficient nonlinear optical operators. As a result, even the most successful ensemble ONNs31that employ dozens of ONNs in parallel, have only achieved LeNet39level accuracy on image classification, which was achieved by their electronic counterparts over 30 years ago. Moreover, most highperformance ONNs can only operate under coherent illumination, prohibiting the integration into the camera optics under natural lighting con ditions. Although hybrid optoelectronic networks35, 36working on incoherent light do exist, they yield inferior results as their optical frontend is designed to execute only a single convolutional layer. In this work, we report a novel nanophotonic neural network that lifts the aforementioned limitations, allowing us to close the gap to the first modern DNN architectures40with optical compute in a flat form factor of only 2mm length. We leverage the ability of a lens system to perform largekernel spatiallyvarying convolutions tailored specifically for image recognition and semantic segmentation. In order to design these kernels, we learn these large kernels via low dimensional reparameterization techniques which circumvent spurious local extremum caused by direct optimization. To physically realize the ONN, we develop a differentiable spatially varying inverse design framework that solves for metasurfaces41, 42that can produce the desired angle dependent responses under spatially incoherent illumination. Because of the compact footprint and CMOS sensor compatibility, the resulting optical system is not only a photonic accelerator, but also an ultracompact computational camera that directly structures lights in ambient envir onments. By onchip integration of this flatoptics frontend ( >99% MACs) with an extremely lightweight electronic backend ( <1% MACs), we achieve higher classification performance than modern fullyelectronic classifiers (73.80% on CIFAR1043compared to 72.64% by AlexNet40) 2while simultaneously reducing the number of electronic parameters by four orders of magnitude, thus bringing optical neural networks into the modern deep learning era. Results LargeKernel SpatiallyVarying Parameterization The working principle and optoelectronic implementation of the proposed spatially varying nanophotonic neural network (SVN3) are illus trated in Figure 1a. The physical forward model and the neural network design are detailed in Supplementary Note 1 and 2, respectively. The SVN3is an optoelectronic neuromorphic computer that comprises a metalens array nanophotonic frontend and a lightweight electronic backend (embedded in a lowcost microcontroller unit) for image classification or semantic segmentation. The metalens array frontend consists of 50 metalens elements that are made of 350 nm pitch nanoantennas and are optimized for incoherent light in a band around 525 nm. The wavefront modulation induced by each metalens can be represented by the optical convolution of the incident field and the point spread functions (PSF) of the individual device. Therefore, the nanophotonic frontend performs parallel multichannel convolutions, at the speed of light, without any power consumption. Unlike existing ONNs35‚Äì38, 44that engineer the optical response to mimic a convolutional layer that consists of spatiallyinvariant smallsized kernels, the SVN3employs largesized an gularly varying PSFs (Figure 1b) as the convolution kernels to construct a largekernel spatially varying (LKSV) convolutional layer. Such an LKSV convolutional layer is seldom used in deep neural networks due to immense computation costs and challenges in training. Nevertheless, we demonstrate that with lowdimensional reparametrization techniques, namely large kernel factor ization, and lowrank spatiallyvarying reparameterization, this computing layer can be effect ively learned in silicon, circumventing spurious local minima that can arise from na ¬®ƒ±ve over parametrization (Supplementary Note 2). We reparameterize a large ( 15√ó15) convolutional kernel into a stack of (seven) small 3√ó3 kernels, which are convolved sequentially to the large kernel (Figure 1d). The spatiallyvarying structure is reparameterized through a spatiallyvariant weighted linear combination of a (large) kernel basis, which resembles the lowrank approximation of a general spatiallyvarying kernel. As such, we construct a 3layer convolutional neural network (CNN) composed of an LKSV con volutional stem, a depthwise separable convolutional layer, and a fullyconnected classification head, for CIFAR10 image classification. This CNN is trained in silicon by minimizing the stand ard crossentropy loss with tailored regularizations (an isotropic total variation regularization and a specialized spectrum regularization) on the spatiallyvarying kernels (Supplementary Note 3). Validated by the spatial combining weights and the Fourier spectrum profiles of learned kernels in Figure S4, these regularizations enforce smooth transitions of spatiallyvarying kernels and pen alize highpass and illconditioned kernels, which are challenging to implement in an optical sys tem. After insilicon training, our LKSV design performs favorably compared to the conventional 3smallkernel spatiallyinvariant (SKSI) counterpart by a sizable margin, lifting from the LeNet level accuracy (65.45%) to the AlexNetlevel accuracy (73.80%) (Table 1) The high computational cost of LKSV convolution in silicon can be entirely eliminated by designing a passive optical system with metalenses whose PSFs are inverse designed to mimic the designated target kernels. While the target kernels may contain both positive and negative values, optical PSFs contain only nonnegative values. Thus, to generate each target kernel we employ a pair of metalenses and we take the subtraction of their image features postconvolution to achieve positive and negative values. To optically realize a 25channel LKSV convolutional layer, we instantiate an onchip metalens array that consists of 50 metalenses with the device layout shown in Figure 1a and 2a. To engineer spatiallyvarying PSFs, we simulate the optical system and use a differentiable spatiallyvarying inverse design framework to compute the phase profiles of the metalenses via stochastic gradient based optimization. The angularly varying PSFs are optimized by minimizing the mean square error loss with respect to the target electronic kernels and employing an energy regularization to maximize the localized energy in the region of interest on the sensor plane. By employing energy regularization, we improve the light efficiency of the designed metalenses from 39.37% to 93.88% without impacting the PSF accuracy (Figure S5c) and make the ONNs more robust to unwanted scattering light and other noise in realworld measurement (Supplementary Note 4). The proposed optical simulation framework allows for prefabrication evaluation of the design quality through metrics such as PSF approximation normalized root mean square error (NRMSE), image feature discrepancy in NRMSE, and light efficiency (Figure S5). The PSF error map, as shown in Figure S5a, indicates that the simulated spatially varying PSFs at each of the 32√ó32 sampling incident angles closely resemble those of the target electronic kernels with 10.49% mean NRMSE. The bar plots in Figure S5b show the image feature discrepancies (NRMSE) for the 50 metalenses. The feature discrepancies in NRMSE ( 43.80% at average) are higher than the PSF errors owing to inaccuracies that can arise from representing discrete convolution kernels using spatially continuous light fields, as well as the error amplification caused by illconditioned target kernels. Note that these target kernels were regularized by the specialized spectrum penalty at the training phase (Supplementary Note 3), which reduced their condition numbers and thus reduced the average image feature discrepancy (NRMSE) from 66.46% to43.80%. Although enforcing stronger condition regularization can further close the gap between simulated device performance and realworld device performance, this would severely degrade the model recognition accuracy, as less regularized kernels could extract more discriminative features for classification. Experimental Validation The inversedesignoptimized metalens array was fabricated in a single chip in a silicon nitride on quartz film. We used a nanopatterning approach using electron beam lithography to define the outline of the design in a resist, deposited a hard mask, and subsequently 4transferred the pattern into the underlying silicon nitride using reactive ion etching. To exclude transmission of light through nonpatterned sections we further deposited a metal aperture around the ONN metalens kernels. The chip closeup and the microscope image of one of the metalenses are shown in Figure 2a, where the fabricated nanophotonic structure is visually consistent with the designed phase profile. The PSFs (over 3√ó3varied sampling incident angles) of three ran domly selected kernels are illustrated in Figure 2c, which illustrates the spatiallyvarying features of the designed optical kernels. To experimentally realize the optical system and measure the im age features of the metalenses, we built the setup as shown in Figure 2b. The green channel of a smartphone OLED display, which is placed at the designed object distance, is used as the in coherent light source, and a largearea CMOS sensor is placed at the focal plane of the metalens array device. When the dataset images are displayed on the smartphone, the sensor captures the corresponding image features of all the metalens elements in one shot. The captured positive, neg ative, and realvalued features thru subtraction closely resemble the electronic ground truth from both qualitative and quantitative comparisons, which verifies the effectiveness of the implemented inverse design framework (Figure 2d). See Figure S6 for more examples. To extensively assess the performance of our optoelectronic neural network SVN3, we cap tured the entire grayscale CIFAR10 dataset, including 50,000 training images and 10,000 testing images, with the setup described above and shown in Figure 2b. The image features in each frame are equally spaced in a regular 6√ó9array with the four corners being traditional hyperbolic metalenses used for device alignment (Figure S7). After cropping the image features of all the metalenses and computing the realvalued target features through paired subtraction, the resulting multichannel optical features are fed into the pretrained lightweight electronic backend to obtain the final predictions. We finetune the electronic backend using the crossentropy loss on the exper imentally captured CIFAR10 training dataset. The finetuning procedure is identical to the prior insilicon training of the target electronic neural network, except no extra regularization losses are applied (Supplementary Note 3). Our SVN3reaches to 73.12% on the projected CIFAR10 testing dataset, which is comparable to 73.80% of the corresponding electronic model. Similar observa tions are also drawn in the confusion matrices in Figure 3b, which reveals the similar recognition behavior of the SVN3in real experiment and simulation. We emphasize that almost all compu tation ( >99% of MACs) of SVN3is executed on the optical side with zero energy consumption (Table 1). This AlexNetlevel classification accuracy is thus achieved with an ultralow power device. Versatile Computational Camera Our approach is generic which we validate by instantiating SVN3for other datasets and tasks. Next, we describe such an instance for ImageNet classification with 1000 object categories. ImageNet is the first largescale image classification dataset with 1.28 million labeled training data, serving as a major driving factor to advance modern AI. To the best of our knowledge, no existing ONN has reported results on ImageNet classification so far. Using the physical parameters specified in Table S1, we inverse design and fabricate an onchip metasurface array to optically encode features for 64√ó64lowresolution ImageNet classification. Notice with 5a larger form factor, our system facilitates scaling to support original 224√ó224highresolution recognition. As for the CIFAR10 experiment, the entire training and validation datasets of Im ageNet are encoded into optical features by the imaging system for finetuning and evaluation. The experimentally captured features consistently align with their electronic ground truth (Fig ure 3b), validating the scalability and effectiveness of SVN3to process largesized image features. After finetuning the electronic backend on the projected ImageNet training set, the SVN3achieves 51.28% top5 classification accuracy in ImageNet validation set, outperforming AlexNet by 3.6%. Note that the SVN3for64√ó64ImageNet classification has 1.67M digital multiplyaccumulate operations (MACs), which is only 0.9%of AlexNet (180.26M). Although the optical frontend (encoder) in SVN3is not programmable after being fabricated, we demonstrate by designing the optical kernels in the largescale dataset (ImageNet), SVN3can serve as a versatile computational camera with a universal optical encoder. By adjusting the elec tronic backend (decoder) using transfer learning, SVN3is capable of performing diverse vision tasks beyond the initially designed task. Using the same physical setup for ImageNet classi fication, we conduct image recognition experiments on the CIFAR100, Flowers102, and Pet37 datasets. For all of these datasets, we achieve comparable or better performance than AlexNet (Figure 5b), consistently validating the flexibility of our hybrid optoelectronic system without adapting the optical frontend. This capability also manifests in other computer vision tasks, e.g., semantic segmentation in PASCAL VOC dataset, where our hybrid network is competitive to the AlexNetbased segmentation network as validated in Figure 5d. Our SVN3leads to pixel accuracy of65.73% compared with 66.34% of AlexNetbased segmentation on the PASCAL VOC testing set. Discussion In this work, we investigate a novel nanophotonic neural network, that transcends the limitations of existing optical neural networks, propelling them to performance parity with the first modern digital neural network, AlexNet. By introducing a largekernel spatiallyvarying convolutional neural network, learned via lowdimensional reparameterization techniques, and physically real izing it via a metaoptical system, we have achieved an image classification accuracy of (top1) 73.12% on CIFAR10 and (top5) 51.28% on ImageNet. The proposed method shifts almost all computation from electronic processors into the optical domain. Specifically, we reduce the num ber of multiplyadd floating point operations by 99.38%. The proposed regularization and para meterization reduce the discrepancy between electronic and optically implemented convolutions, and as a result, we achieve an optical implementation NRMSE of 43.80%. In the future, further reducing this discrepancy and extending the design framework to the broadband visible light re gime could enable ultrafast computer vision for a wide gamut of applications. We believe that the proposed optical neural network is a first step to bridging the gap between photonic and elec tronic artificial intelligence, and we anticipate that these devices could enable ultralow latency computing at the edge. 6Methods "
306,Verifying Recurrent Neural Networks using Invariant Inference.txt,"Deep neural networks are revolutionizing the way complex systems are
developed. However, these automatically-generated networks are opaque to
humans, making it difficult to reason about them and guarantee their
correctness. Here, we propose a novel approach for verifying properties of a
widespread variant of neural networks, called recurrent neural networks.
Recurrent neural networks play a key role in, e.g., natural language
processing, and their verification is crucial for guaranteeing the reliability
of many critical systems. Our approach is based on the inference of invariants,
which allow us to reduce the complex problem of verifying recurrent networks
into simpler, non-recurrent problems. Experiments with a proof-of-concept
implementation of our approach demonstrate that it performs orders-of-magnitude
better than the state of the art.","The use of recurrent neural networks (RNN s) [13] is on the rise. RNNs are a particular kind of deep neural networks (DNNs), with the useful ability to store information from previous evaluations in constructs called memory units . This dierentiates them from feedforward neural networks (FFNNs ), where each evaluation of the network is performed independently of past evaluations. The presence of memory units renders RNNs particularly suited for tasks that in volve context, such as machine translation [7], health applications [24], speaker recognition [33], and many other tasks where the network's output might be aected by previously processed inputs. Part of the success of RNNs (and of DNNs in general) is attributed to their very attractive generalization properties: after being trained on a nite set of examples, they generalize well to inputs they have not encountered before [13]. Unfortunately, it is known that RNNs may react in highly undesirable ways to certain inputs. For instance, it has been observed that many RNNs are vul nerable to adversarial inputs [6,31], where small, carefullycrafted perturbations are added to an input in order to fool the network into a classication error. This example, and others, highlight the need to formally verify the correctness of RNNs, so that they can reliably be deployed in safetycritical settings. How ever, while DNN verication has received signicant attention in recent yearsarXiv:2004.02462v2  [cs.AI]  10 Aug 2020(e.g., [2,4,5,8,10,12,15,18,19,25,26,32,34,35]), almost all of these eorts have been focused on FFNNs, with very little work done on RNN verication. To the best of our knowledge, the only existing general approach for RNN verication is via unrolling [1]: the RNN is duplicated and concatenated onto itself, creating an equivalent feedforward network that operates on a sequence ofkinputs simultaneously, as opposed to one at a time. The FFNN can then be veried using existing verication technology. The main limitation of this approach is that unrolling increases the network size by a factor of k(which, in realworld applications, can be in the hundreds [33]). Because the complexity of FFNN verication is known to be worstcase exponential in the size of the network [17], this reduction gives rise to FFNNs that are dicult to verify | and is hence applicable primarily to small RNNs with short input sequences. Here, we propose a novel approach for RNN verication, which aords far greater scalability than unrolling. Our approach also reduces the RNN verica tion problem into FFNN verication, but does so in a way that is independent of the number of inputs that the RNN is to be evaluated on. Specically, our approach consists of two main steps: (i) create an FFNN that overapproximates the RNN, but which is the same size as the RNN; and (ii) verify properties over this overapproximation using existing techniques for FFNN verication. Thus, our approach circumvents any duplication of the network or its inputs. In order to perform step (i), we leverage the wellstudied notion of inductive invariants : our FFNN encodes timeinvariant properties of the RNN, which hold initially and continue to hold after the RNN is evaluated on each additional input. Automatic inference of meaningful inductive invariants has been studied extensively (e.g., [27,29,30]), and is known to be highly dicult [28]. We propose here an approach for generating invariants according to predened templates . By instantiating these templates, we automatically generate a candidate invariant I, and then: (i) use our underlying FFNN verication engine to prove that I is indeed an invariant; and (ii) use Iin creating the FFNN overapproximation of the RNN, in order to prove the desired property. If either of these steps fail, we reneI(either strengthening or weakening it, depending on the point of failure), and repeat the process. The process terminates when the property is proven correct, when a counterexample is found, or when a certain timeout value is exceeded. We evaluate our approach using a proofofconcept implementation, which uses the Marabou tool [19] as its FFNN verication backend. When compared to the state of the art on a set of benchmarks from the domain of speaker recog nition [33], our approach is ordersofmagnitude faster. Our implementation, together with our benchmarks and experiments, is available online [16]. The rest of this paper is organized as follows. In Sec. 2, we provide a brief background on DNNs and their verication. In Sec. 3, we describe our approach for verifying RNNs via reduction to FFNN verication, using invariants. We describe automated methods for RNN invariant inference in Sec. 4, followed by an evaluation of our approach in Sec. 5. We then discuss related work in Sec. 6, and conclude with Sec. 7.2 Background 2.1 FeedForward Neural Networks and their Verication An FFNNNwithnlayers consists of an input layer, n"
104,Predicting Side Effect of Drug Molecules using Recurrent Neural Networks.txt,"Identification and verification of molecular properties such as side effects
is one of the most important and time-consuming steps in the process of
molecule synthesis. For example, failure to identify side effects before
submission to regulatory groups can cost millions of dollars and months of
additional research to the companies. Failure to identify side effects during
the regulatory review can also cost lives. The complexity and expense of this
task have made it a candidate for a machine learning-based solution. Prior
approaches rely on complex model designs and excessive parameter counts for
side effect predictions. We believe reliance on complex models only shifts the
difficulty away from chemists rather than alleviating the issue. Implementing
large models is also expensive without prior access to high-performance
computers. We propose a heuristic approach that allows for the utilization of
simple neural networks, specifically the recurrent neural network, with a 98+%
reduction in the number of required parameters compared to available large
language models while still obtaining near identical results as top-performing
models.","MOLECULAR property prediction is one of the oldest and most fundamental tasks within the Ô¨Åeld of drug discovery [1], [2]. Applying in silico methods to molecular property prediction offers the potential of releasing safer drugs to the market while reducing test time and cost. Historically, these in silico approaches relied on complex feature engineer ing methods to generate their molecule representations for processing [3], [4]. These approaches are bound by the bias of the descriptor, which means the generated features are not reusable for different tasks as some valuable information may be removed. The feature vectors also depended on current molecular comprehension; upon discovery, the feature vectors could become redundant. Graph Neural Networks (GNN) remove the dependence on complex and temporal descriptors. GNNs became favorable due to the common practice of drawing molecules using graph representations which offers a generic form of input allowing for machine learning models to build their interpretation of information, rather than rely on human capabilities. Using this generic form, GNNs have been able to perform well on multiple cheminformatic tasks, especially molecular property prediction [5], [6]. GNNs are limited by the ability to build an understanding of a shared dependence and have scalability issues. The size of the graphical input increases exponentially with each additional molecule that is represented. With this growth, the cost of communication between graphicalnodes also exponentially increases. Compared to other neural network types, GNNs perform worse at molecular property prediction than both feedforward neural networks, despite their builtin generic representation [7]. With the recent success of large language models, newer attempts aim to build transformer based approaches with promising signs of success [8]. While new large language models offer comparable performance to GNNs, they require up to 120 billion parameters to achieve similar performance. Due to the rapid explosion of parameters caused by GNNs, feedforward neural networks, and transformers, we propose a heuristic approach using a recurrent neural network. Our approach can obtain close to stateoftheart results with 99+% fewer parameters than Galactica [8]. In the following sections, we review the SIDER data set and compare the SMILES and SELFIES formats and the basic concepts of a recurrent neural network, and also discuss a few of the related works that perform classiÔ¨Åcation on SIDER dataset (Section II). We then discuss the data preprocessing and model implementation details (Section III), followed by the model performance and a comparison to other stateoftheart options (Section IV). Finally we conclude the paper by giving a summary (Section V). II. B ACKGROUND & R ELATED WORKS A. Side Effect Resource (SIDER) The principal molecular property in terms of human con sumption is the side effect associated with the molecule. The Side Effect Resource (SIDER) data set attempts to create a single source of combined public records for known side effects [9]. The data set consists of 28 columns, the Ô¨Årst column is the SMILES representation of a given molecule, and the next 27 columns are potential side effects. The side effects of each molecule are marked with a one if it is known to have a side effect or a zero otherwise. B. SimpliÔ¨Åed MolecularInput Line Entry System (SMILES) SimpliÔ¨Åed molecularinput lineentry system (SMILES) uses characters to build a molecular representation [10]. Letters represent various elements within a molecule, where the Ô¨Årst letter of an element can be uppercase, denoting that the element is nonaromatic, or lowercase, denoting that the element is aromatic. Assuming an element requires a second letter, it will be lowercase. Another possible representation of aromaticity is the colon, which is the aromatic bond symbol. Other potentialarXiv:2305.10473v1  [qbio.QM]  17 May 2023JOURNAL OF L ATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021 2 bond symbols are a period (.), a hyphen (), a forward slash (/), a backslash ( n), an equal sign (=), an octothorpe (#), and a dollar sign ( $). Periods represent a no bond, hyphens represent a single bond, and the forward slash and backslash represent single bonds adjacent to a double bond. However, the forward slash and backslash are only necessary when rendering stereochemical molecules. The equal sign represents a double bond, the octothorpe represents the triple bond, and the dollar sign represents a quadruple bond. In cases where stereochemical molecules are used, the asperand (@) can be used in a double instance to represent clockwise or in a single occurrence to represent counterclockwise. Numbers are used within a molecule to characterize the opening and closing of a ring structure, or if an element is within brackets, the number can represent the number of atoms associated with an element. Numbers appearing within brackets before an element represent an isotope. A parenthesis (()) denotes branches from the base chain. C. SelfReferencing Embedded Strings (SELFIES) SelfReferencing Embedded Strings (SELFIES) improve the initial idea of SMILES for usage in machine learning processes; by creating a robust molecular string representation [11]. SMILES offered a simple and interpretable characterization of molecules that was able to encode the elements of molecules and their spatial features. The spatial features rely on an overly complex grammar where rings and branches are not locally represented features. This complexity causes issues, especially in generative models, where machines frequently produce either syntactically invalid or physically invalid strings. To remove this nonlocality, SELFIES uses a single ring or branch symbol, and the length of this spatial feature is supplied directly; ensuring that any SELFIES string has a valid physical representation. D. Recurrent Neural Networks (RNN) Elman networks, more commonly known as vanilla recurrent neural networks (RNN), attempt to introduce the concept of a timedependent dynamic memory [12]. The idea is to make predictions about certain inputs based on contextual information. These contextbased predictions can be done for four different inputoutput schemes, onetoone, onetomany, manytoone, and manytomany. Onetoone models are a variation of a classic neural network, onetomany models are best for image caption generation, manytoone models are best for sentiment analysis, and manytomany is best for translation or video frame captioning. Figure 1 is an example of the basic structure of a vanilla RNN. In Figure 1, the Xtrepresents some input, Ht"
178,Verification system based on long-range iris and Graph Siamese Neural Networks.txt,"Biometric systems represent valid solutions in tasks like user authentication
and verification, since they are able to analyze physical and behavioural
features with high precision. However, especially when physical biometrics are
used, as is the case of iris recognition, they require specific hardware such
as retina scanners, sensors, or HD cameras to achieve relevant results. At the
same time, they require the users to be very close to the camera to extract
high-resolution information. For this reason, in this work, we propose a novel
approach that uses long-range (LR) distance images for implementing an iris
verification system. More specifically, we present a novel methodology for
converting LR iris images into graphs and then use Graph Siamese Neural
Networks (GSNN) to predict whether two graphs belong to the same person. In
this study, we not only describe this methodology but also evaluate how the
spectral components of these images can be used for improving the graph
extraction and the final classification task. Results demonstrate the
suitability of this approach, encouraging the community to explore graph
application in biometric systems.","Soft biometric information, i.e., physical and behavioural traits such as gender, height, iris, and voice, can be helpful in security, authentication, and validation processes [ 42]. The main advantage of using biometric information over traditional methods is that instead of requiring information that the user should know or possess (password, codes, PIN, etc.), they use characteristics that univocally and biologically define the users (fingerprints, iris, face, etc.). In particular, these characteristics are universal (all users can be measured), singular (each user has its own measures), permanent in time and context, and can be quantitatively measured [33]. Soft biometrics can be divided into two groups: physical and behavioural biometrics. Techniques of the first category use physical characteristics like face, iris, and fingerprint for their tasks [ 4], whereas techniques of the second one, use information extracted from user behaviours such as signature, voice, and keyboard typing [39]. Among the physical biometrics, face [ 15] and fingerprint [ 2] methodology have been the most explored, and have already been used in many realworld applications such as airport scanners, banking, military access control, smartphones or forensics [ 7,36]. However, in the last decade, the use of iris has begun to attract interest in applications such as gender classification [27], iris liveness detection [8], border control [45] and citizen confirmation [22]. In fact, iris biometric represents a secure biometric with low forgery and error rates due to its highly certain features [43]. Furthermore, this biometric information is usually combined with Artificial Intelligence (AI) and Machine Learning techniques (ML) in order to implement user identification and verification systems. However, one of the main drawbacks ‚àóF. Zola is also with the Public University of Navarre and the Netherlands Forensic Institute. Authors‚Äô addresses: Francesco Zola, fzola@vicomtech.com; Jose Alvaro FernandezCarrasco, jafernandez@vicomtech.org; Jan Lukas Bruse, jbruse@ vicomtech.org, Vicomtech Foundation, Basque Research and Technology Alliance, Donostia, Spain; Mikel Galar, mikel.galar@unavarra.es, Institute of Smart Cities, Department of Statistics, Computer Science and Mathematics, Public University of Navarre, Pamplona, Spain; Zeno Geradts, z.geradts@nfi.nl, Netherlands Forensic Institute, The Hague, The Netherlands. 1arXiv:2208.00785v1  [cs.CV]  28 Jul 20222 Zola, et al. of these irisbased approaches, is that for their real application, they require specific hardware such as retina scanners, sensors, HD cameras, etc, to achieve relevant results in security and authentication tasks. At the same time, they require the users to be very close to the camera to extract highresolution information. Consequently, the majority of the works in the literature that propose to use longrange (LR) iris images are focused on improving the acquisitions system using specific technologies [5, 13, 37, 49]. In contrast, in this work, we present a novel approach for LR iris verification based on graph analysis. Our idea consists of extracting relevant information from each LR iris image captured from standard cameras and representing it as a graph. In fact, graph representations are widely applied in social media [ 44], biology [ 1], program analysis [ 52] and cybersecurity [ 55] tasks, showing promising results. However, they are not extensively applied in biometrics tasks. For this reason, in this work, not only we propose to exploit their potential for representing LR iris images, but also to use these graphs for training a verification system based on graph Machine Learning. In particular, our idea is to implement Graph Siamese Neural Network (GSNN) for identifying the similarities and differences between two graphs, returning as a result whether the two graphs belong to the same person. The whole process is firstly validated using original LR iris images, then using spectral enhanced iris images, i.e., LR iris images in which convolutional filters are applied for highlighting spectral components. Finally, the best configurations are tested increasing the number of users to be distinguished, to evaluate the generalization of our approach. To the best of our knowledge, this is the first work that proposes to extract graph representations from LR iris images and use them directly for user verification using GSNN. The rest of the paper is organized as follows. In Section 2, concepts regarding iris classification and SNN are introduced. Section 3 presents the methodology used to solve the problem, meanwhile, in Section 4, the dataset used is presented, as well as the preprocessing operations and the GSNN architecture. Then, experiments, results and discussion are outlined in Section 5 and finally, Section 6, provides conclusions and guidelines for future work. 2 PRELIMINARIES In this section, concept related to iris classification and Siamese Neural Networks (SNN) are introduced. More specifically, in Section 2.1 iris classification steps are described, whereas in Section 2.2 Siamese Neural Networks are introduced. 2.1 Iris classification Traditionally, the biometric iris recognition process involved 5key steps [ 10,38]. In step 1, the subject‚Äôs iris (or irises) is acquired using (various) cameras and optical sensors. Of course, in this phase, it should be ensured that the entire eye is captured, i.e., at least the pupil, iris, and sclera (Figure 1). Then, in step 2, several preprocessing operations can be performed to reduce eventual noise, enhance the quality of the images, reduce dimensionality, and so on. In this step, an operation of segmentation is also performed, which usually consists in isolating the region of interest (i.e., the iris portion). This operation strongly depends on the image quality. In step 3, the iris regions are normalized in order to fit the same (constant) dimensions. In fact, rotating the head, pupil dilatation or contraction, and so on, can generate different regions of interest. In step 4, highly discriminative features are extracted from each normalized image. Finally, in step 5, these features are used for training a classifier, which can be further used for classifying incoming subjects. Since deep learningbased models have increasingly been used in different recognition systems in recent years, their good results have led researchers to apply them also in the biometric domain. More precisely, they are widely used in steps 4 and 5, i.e., for feature extraction and matching. For example, in [ 35] and [ 3], convolutional neural networks (CNN) are used for extracting the feature vector to be used for the final classification. In [ 11], a deep convolutional network and a Support Vector Machine (SVM) classifier are combined for detecting contact lenses in human eyes usingVerification system based on longrange iris and Graph Siamese Neural Networks 3 pupil sclerairis Fig. 1. Image of iris, pupil and sclera in human eye. highquality raw iris images, whereas in [ 53], authors propose a liveness detection based on Hierarchical Multiclass Iris Classification (HMC). In [ 14], a method based on a feedforward architecture and kmeans clustering algorithm for iris pattern classification is introduced, whereas, in [ 22], authors propose an approach in which the Hough Transformation is applied to localize the region of interest (i.e., iris region), and then a CNN is used for the classification. Another wellexplored scope in iris biometrics involves the genderidentification. In particular in [ 26] deep convolutional neural are applied for this goal, while in [ 27], invariant moments and SVM are combined. Superresolution convolutional neural networks (SRCNNs) for increasing the iris resolution from selfie images and the final gender classification are used in [ 48]. Despite all these approaches, however, other work suggests that the genderrelated information in the iris is not enough, and they advise using the whole periocular region [28]. 2.2 Siamese Neural Networks (SNNs) Siamese Neural Networks (SNNs) are a type of neural network composed of multiple instances of the same model [ 6], which share the same architecture and weights, but different inputs called branch or sister networks as shown in Figure 2. The outputs of these two branch networks are combined in an additional layer (loss/distance layer), which is in charge of detecting if both outputs belong to the same input or not. This architecture is wellsuited for measuring the similarity among the network inputs. In fact, the idea of the model is to try to minimize the loss (or distance) between inputs of the same class while trying to maximize the loss (or distance) between inputs of different classes [12]. One of the main advantages of using SNNs is that if a new class is introduced in the dataset, it is unnecessary to retrain the whole model. This is because such networks do not learn how to predict specific classes, but they learn how to measure the similarity between two inputs. SNNs have shown their usefulness in facial expression recognition [ 19], face recognition [ 51], matching local image patches [ 18], and generic image retrieval [ 34], and for object tracking [ 17]. Furthermore, these networks have shown an advantage when used with limited data [ 9]. SNN has also been used in biometric tasks, for example, for identifying if pairs of speech samples belong to a ‚Äúgenuine"" or ‚Äúreplayed"" user [ 46]. In [ 16], SNNs are used to compare the similarity between two keystroke patterns and so lead the authentication process. A similar approach is applied in [ 54], however in this case for evaluating the similarity of two input palmprints according to their convolutional features. To the best of our knowledge, SNNs are not yet explored for iris verification operations, as well as their applications with graphs directly extracted from LR iris images. For this reason, this work represents a first step toward the usage of LR iris images for extracting graphbased information and then applying GSNN technology directly over this graph structure as a verification system.4 Zola, et al. Fig. 2. General architecture of a Siamese Neural Network (SNN). 3 METHODOLOGY "
364,Text-Independent Speaker Verification Using 3D Convolutional Neural Networks.txt,"In this paper, a novel method using 3D Convolutional Neural Network (3D-CNN)
architecture has been proposed for speaker verification in the text-independent
setting. One of the main challenges is the creation of the speaker models. Most
of the previously-reported approaches create speaker models based on averaging
the extracted features from utterances of the speaker, which is known as the
d-vector system. In our paper, we propose an adaptive feature learning by
utilizing the 3D-CNNs for direct speaker model creation in which, for both
development and enrollment phases, an identical number of spoken utterances per
speaker is fed to the network for representing the speakers' utterances and
creation of the speaker model. This leads to simultaneously capturing the
speaker-related information and building a more robust system to cope with
within-speaker variation. We demonstrate that the proposed method significantly
outperforms the traditional d-vector verification system. Moreover, the
proposed system can also be an alternative to the traditional d-vector system
which is a one-shot speaker modeling system by utilizing 3D-CNNs.","Speaker VeriÔ¨Åcation (SV), is verifying the claimed identity of a speaker by using their voice characteristics as captured by a recording device such as a microphone. The concept of SV belongs within the general area of Speaker Recognition (SR), and can be subdivided to textdependent and textindependent types. In textdependent mode, a predeÔ¨Åned Ô¨Åxed text, such as a passphrase, is employed for all stages in speaker veri Ô¨Åcation process. One the other hand, in textindependent SV , no prior constraints are considered for the spoken phrases by the speaker, which makes it much more challenging com pared to textdependent scenario. Generally, there are three steps in a SV process: development, enrollment, and evalua tion. In the development step, the background model will be created for the speaker representation. In the enrollment step, the speaker models of new users are generated using the background model. Finally, in the evaluation phase, the claimed identity of the test utterances should be conÔ¨Årmed/rejected by comparing with available previously generated speaker mod els. Successful SV methods often employ unsupervised gener ative models such as the Gaussian Mixture ModelUniversal Background Model (GMMUBM) framework [1]. Some models, such as ivector, based on GMMUBM, have demon strated effectiveness as well [2]. Although the aforementioned models proved to be effective for SV tasks, the main issue is the disadvantage of unsupervised methods in which the model training is not necessarily supervised by speaker discrimina tive features. Different approaches, such as the SVM model for GMMUBMs [3] and PLDA ivectors model [4], have been developed as discriminative models to supervise the gen erative framework and demonstrated promising results. Re cent research efforts on deep learning approaches have pro posed data driven feature learning methods. Inspired by using Deep Neural Networks (DNNs) in Automatic Speech Recog nition (ASR) [5], other research efforts have been conducted on the application of DNNs in SR [6,7], and have shown to be promising for learning taskoriented features. Convolutional neural networks (CNNs) have been applied for feature extrac tion, which has often been utilized for 2D inputs. However, 3D CNN architectures have recently been employed for action recognition [8] and audiovisual matching [9]. For the work presented here, we use 3D CNNs to capture withinspeaker variations in addition to extracting the spatial and temporal information jointly. In this paper, we focus on the textindependent scenario where no prior information is available in the context of the speakers‚Äô utterances for all stages. The difÔ¨Åculty of the cho sen setting is that the proposed system should be able to dis tinguish between the speaker and speech related information as different utterances (contextwise) from the same speaker that are fed to the system. In this paper, we extend the appli cation of DNNbased feature extraction to a textindependent SV task, the objective of which is to build a speakerrelated bridge between the development and enrollment stages to cre ate more generalizable speaker models. Our source code is 9781538617373/18/$31.00 ¬©2018 IEEEarXiv:1705.09422v7  [cs.CV]  6 Jun 2018available online1as an open source project [10]. 2. RELATED WORKS "
501,Black-box Dataset Ownership Verification via Backdoor Watermarking.txt,"Deep learning, especially deep neural networks (DNNs), has been widely and
successfully adopted in many critical applications for its high effectiveness
and efficiency. The rapid development of DNNs has benefited from the existence
of some high-quality datasets ($e.g.$, ImageNet), which allow researchers and
developers to easily verify the performance of their methods. Currently, almost
all existing released datasets require that they can only be adopted for
academic or educational purposes rather than commercial purposes without
permission. However, there is still no good way to ensure that. In this paper,
we formulate the protection of released datasets as verifying whether they are
adopted for training a (suspicious) third-party model, where defenders can only
query the model while having no information about its parameters and training
details. Based on this formulation, we propose to embed external patterns via
backdoor watermarking for the ownership verification to protect them. Our
method contains two main parts, including dataset watermarking and dataset
verification. Specifically, we exploit poison-only backdoor attacks ($e.g.$,
BadNets) for dataset watermarking and design a hypothesis-test-guided method
for dataset verification. We also provide some theoretical analyses of our
methods. Experiments on multiple benchmark datasets of different tasks are
conducted, which verify the effectiveness of our method. The code for
reproducing main experiments is available at
\url{https://github.com/THUYimingLi/DVBW}.","DEEP neural networks (DNNs) have been widely and successfully used in many missioncritical applications and devices for their high effectiveness and efÔ¨Åciency. For example, within a smart camera, DNNs can be used for identifying human faces [1] or pose estimation [2]. In general, highquality released ( e:g:, opensourced or commercial) datasets [3], [4], [5] are one of the key factors in the prosperity of DNNs. Those datasets allow researchers and developers to easily verify their model effectiveness, which in turn accelerates the development of DNNs. Those datasets are valuable since the data collection is timeconsuming and expensive. Besides, according to related regulations ( e:g:, GDPR [6]), their copyrights deserve to be protected. Yiming Li and Mingyan Zhu are with Tsinghua Shenzhen Interna tional Graduate School, Tsinghua University, Shenzhen, China (email: li ym18@mails.tsinghua.edu.cn, zmy20@mails.tsinghua.edu.cn). Xue Yang is with School of Information Science and Technology, Southwest Jiaotong University, Chengdu, China (email: xueyang@swjtu.edu.cn). Yong Jiang, and ShuTao Xia are with Tsinghua Shenzhen International Graduate School, Tsinghua University, and also with the Research Center of ArtiÔ¨Åcial Intelligence, Peng Cheng Laboratory, Shenzhen, China (email: jiangy@sz.tsinghua.edu.cn, xiast@sz.tsinghua.edu.cn). Tao Wei is with Ant Group, Hangzhou, Zhejiang, China (email: lenx.wei@antgroup.com). Corresponding Author(s): Xue Yang and ShuTao Xia.In this paper, we discuss how to protect released datasets. In particular, those datasets are released and can only be used for speciÔ¨Åc purposes. For example, opensourced datasets are available to everyone while most of them can only be adopted for academic or educational rather than commercial purposes. Our goal is to detect and prevent unauthorized dataset users. Currently, there were some techniques, such as encryption [7], [8], [9], digital watermarking [10], [11], [12], and dif ferential privacy [13], [14], [15], for data protection. Their main purpose is also precluding unauthorized users to utilize the protected data. However, these methods are not suitable to protect released datasets. SpeciÔ¨Åcally, encryption and differen tial privacy will hinder the normal functionalities of protected datasets while digital watermarking has minor effects in this case since unauthorized users will only release their trained models without disclosing their training samples. How to protect released datasets is still an important open question. This problem is challenging because the adversaries can get access to the victim datasets. To the best of our knowledge, there is no prior work to solve it. In this paper, we formulate this problem as an ownership veriÔ¨Åcation, where defenders intend to identify whether a suspicious model is trained on the (protected) victim dataset. In particular, we consider the blackbox setting, which is more difÔ¨Åcult compared with the whitebox one since defenders can only get model predictions while having no information about its training details and model parameters. This setting is more practical, allowing defenders to perform ownership veriÔ¨Åcation even when they only have access to the model API. To tackle this problem, we design a novel method, dubbed dataset veriÔ¨Åcation via backdoor watermarking (DVBW). Our DVBW consists of two main steps, including dataset watermarking and dataset veriÔ¨Åcation. SpeciÔ¨Åcally, we adopt the poisononly backdoor attacks [16], [17], [18] for dataset watermarking, inspired by the fact that they can embed special behaviors on poisoned samples while maintaining high prediction accuracy on benign samples, simply based on data modiÔ¨Åcation. For the dataset veriÔ¨Åcation, defenders can verify whether the sus picious model was trained on the watermarked victim dataset by examining the existence of the speciÔ¨Åc backdoor. To this end, we propose a hypothesistestguided veriÔ¨Åcation. Our main contributions can be summarized as follows: We propose to protect datasets by verifying whether they are adopted to train a suspicious thirdparty model. We design a blackbox dataset ownership veriÔ¨Åcation (i:e:, DVBW), based on the poisononly backdoor attacks and pairwise hypothesis tests.arXiv:2209.06015v2  [cs.CR]  31 Mar 2023IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY 2 We provide some theoretical insights and analyses of our dataset ownership veriÔ¨Åcation. Experiments on benchmark datasets of multiple types of tasks (i:e:, image classiÔ¨Åcation, natural language process ing, and graph recognition) are conducted, which verify the effectiveness of the proposed method. The rest of this paper is organized as follows: In the next section, we brieÔ¨Çy review related works. After that, we introduce the preliminaries and deÔ¨Åne the studied problem. We introduce the technical details of our method in section IV. We conduct experiments on multiple benchmark datasets to verify our effectiveness in Section V. We compare our work with model ownership veriÔ¨Åcation in Section VI and conclude this paper in Section VII at the end. We hope that our paper can provide a new angle of data protection, to preserve the interests of dataset owners and facilitate secure dataset sharing. II. R ELATED WORKS "
436,Training Neural Networks without Backpropagation: A Deeper Dive into the Likelihood Ratio Method.txt,"Backpropagation (BP) is the most important gradient estimation method for
training neural networks in deep learning. However, the literature shows that
neural networks trained by BP are vulnerable to adversarial attacks. We develop
the likelihood ratio (LR) method, a new gradient estimation method, for
training a broad range of neural network architectures, including convolutional
neural networks, recurrent neural networks, graph neural networks, and spiking
neural networks, without recursive gradient computation. We propose three
methods to efficiently reduce the variance of the gradient estimation in the
neural network training process. Our experiments yield numerical results for
training different neural networks on several datasets. All results demonstrate
that the LR method is effective for training various neural networks and
significantly improves the robustness of the neural networks under adversarial
attacks relative to the BP method.","Neural networks have increasingly more successful applications, such as face recognition [ 1‚Äì4], voice veriÔ¨Åcation [ 5‚Äì8] and automation vehicles [ 9‚Äì11]. Different model architectures are suitable for processing different tasks. For example, multilayer perceptron (MLP) [ 12] has a good performance on structural data, convolutional neural network (CNN) [ 13] is typically adopted for image tasks, recurrent neural network (RNN) [ 14] is usually employed to process time series data, and graph neural network (GNN) [ 15] is often used to extract potential relationships between entities. Brainlike neural network structure includes spiking neural networks (SNNs) [ 16] where neurons communicate via discrete spike sequences, and they are ideal models for eventdriven information processing. Backpropagation (BP) [ 12] is the most important gradient estimation method used for training neural networks [ 17,18]. It relies on the chainrule of differentiation to backpropagate the residual error from the loss function to the previous layers for gradient computation. Despite its widespread use, recent research has highlighted the vulnerability of neural networks trained by BP, particularly under adversarial attacks [ 19,20]. Adversarial attacks refer to the subtle manipulation of input data that is imperceptible to humans but can easily deceive neural networks [ 21]. Meanwhile, BP requires the activation and loss function of the neural networks to be continuous, which limits the freedom of network architecture for modeling complex environments [22]. In contrast to BP, some existing methods entirely abandon the backward process and only require the forward pass for gradient estimation in optimizing the neural networks [ 23,24]. One family *These authors contributed equally to this work. ‚Ä†Corresponding author. Preprint. Under review.arXiv:2305.08960v1  [cs.LG]  15 May 2023of training methods without BP performs optimization following the gradient estimated from the correlation between the parameter perturbation and network outcomes. Unfortunately, they usually suffer from curseofdimensionality and require signiÔ¨Åcant manual tuning to identify appropriate hyperparameters [25, 26], so their applicability to deep neural network training is limited. The likelihood ratio (LR) method has emerged as a promising alternative to BP for training neural networks [ 27]. It provides an unbiased gradient estimation without relying on the recursive gradient calculation. Previous study has developed an LR method to train MLPs on the MNIST dataset. However, there is still signiÔ¨Åcant work to be done in extending the LR method to more widely used neural network architectures. In our paper, we develop a new LR method to train a broader range of neural network architectures. We further propose several methods to reduce the variance of gradient estimation, thereby enhancing the stability of the neural network training process. We conduct extensive experiments on various neural network architectures, i.e., the CNN, RNN, GNN, and SNN, for corresponding classical tasks to verify the effectiveness of the proposed method, including classiÔ¨Åcation on the Cifar10 [ 28], AgNews [ 29], Cora [ 30], MNIST [ 31], and FashionMNIST [ 32] datasets. Our experimental results demonstrate the efÔ¨Åcacy of our proposed method in achieving comparable or even better performance with BP while also improving the robustness of the trained models. 2 Related Work "
299,Automatic Fact-Checking Using Context and Discourse Information.txt,"We study the problem of automatic fact-checking, paying special attention to
the impact of contextual and discourse information. We address two related
tasks: (i) detecting check-worthy claims, and (ii) fact-checking claims. We
develop supervised systems based on neural networks, kernel-based support
vector machines, and combinations thereof, which make use of rich input
representations in terms of discourse cues and contextual features. For the
check-worthiness estimation task, we focus on political debates, and we model
the target claim in the context of the full intervention of a participant and
the previous and the following turns in the debate, taking into account
contextual meta information. For the fact-checking task, we focus on answer
verification in a community forum, and we model the veracity of the answer with
respect to the entire question--answer thread in which it occurs as well as
with respect to other related posts from the entire forum. We develop annotated
datasets for both tasks and we run extensive experimental evaluation,
confirming that both types of information ---but especially contextual
features--- play an important role.","Recent years have seen the proliferation of deceptive information online. With the increasing necessity to validate information from the Internet, automatic factchecking has emerged as an important research topic. Factchecking is at the core of multiple applications, e.g., discovery of fake news [Lazer et al .2018], rumor detection in social media [Vosoughi et al .2018], information verification in question answering systems [Mihaylova et al .2018], detection of information manipulation agents [Chen et al .2013; Darwish et al .2017; Mihaylov et al .2015b], and assistive technologies for investigative journalism [Hassan et al .2015]. It touches many aspects, such as credibility of users and sources, information veracity, information verification, and linguistic aspects of deceptive language. There has been work on automatic claim identification [Hassan et al .2015, 2016], and also on checking the factuality/credibility of a claim, of a news article, or of an information source [Ba et al .2016; Castillo et al .2011; Hardalov et al .2016; Karadzhov et al . 2017a,b; Ma et al .2016; Nakov et al .2017b; Rashkin et al .2017; Zubiaga et al .2016]. In general, previous work has not paid much attention to explicitly modeling contextual information and linguistic properties of the discourse in order to identify and verify claims, with some rare recent exceptions [Gencheva et al. 2017; Popat et al. 2017]. In this article, we focus on studying the role of contextual information and discourse , which provide important information that is typically not included in the usual feature sets, which are mostly based on properties of the target claim, and its similarity to a set of validation documents or snippets. In particular, we focus on the following tasks: Checkworthy claim identification. We address the automatic identification of claims in political debates which a journalist should factcheck. In this case, the text is dialogstyle: with long turns by the candidates and orchestrated by a moderator around particular topics. Journalists had to challenge the veracity of claims in the 2016 US presidential campaign, and this was particularly challenging during the debates as a journalist had to prioritize which claims to factcheck first. Thus, we developed a model that ranks the claims by their checkworthiness. Answers factchecking. We address the automatic verification of answers in communitydriven Web forums (e.g., Quora, StackOverflow). The text is threadstyle, but is subject to potential dialogues: a user posts a question and others post po tential answers. That is, the answers are verified in the context of discussion threads in a forum and are also interpreted in the context of an initial question. Here we deal with social media content. The text is noisier and the information being shared is not always factual; mainly due to misunderstanding, ignorance, or maliciousness of the responder. We run extensive experiments for both tasks by training and applying classifiers based on neural networks, kernel based support vector machines, and combinations thereof. The results confirm that the contextual and the discourse information are crucial to boost the models and to achieve stateoftheart results for both tasks.1In the former task, using context yields 4.2 MAP points of absolute improvement, while using discourse information adds 1.5 MAP absolute points; in the latter task, considering the discourse and the contextual information improves the performance by a total of 4.5 MAP absolute points. The rest of this article is organized as follows: Section 2 describes our supervised approach to predicting the check worthiness of text fragments with focus on political debates. Section 3 presents our approach to verifying the factuality of the answers in a community question answering forum. Section 4 provides a more qualitative analysis of the outcome of all our experiments. Section 5 discusses related work. Finally, Section 6 presents the conclusions and the lessons learned, and further outlines some possible directions for future research. 1We make available the datasets and source code for both tasks: https://github.com/pgencheva/claimrank and https://github.com/qcri/QLFactChecking Manuscript submitted to ACMAutomatic FactChecking Using Context and Discourse Information 3 Medium 1st 2nd VP 3rd Total ABC News 35 50 29 28 142 Chicago Tribune 30 29 31 38 128 CNN 46 30 37 60 173 FactCheck.org 15 45 47 60 167 NPR 99 92 91 89 371 PolitiFact 74 62 60 57 253 The Guardian 27 39 54 72 192 The New York Times 26 25 46 52 149 The Washington Post 26 19 33 17 95 Total annotations 378 391 428 473 1,670 Annotated sentences 218 235 183 244 880 Table 1. Number of annotations in each medium for the 1st, 2nd and 3rd presidential and the vicepresidential debates. The last row shows the number of annotated sentences that become the positive examples in the CWUSPD2016 dataset. 2 CLAIM IDENTIFICATION In this section, we focus on the problem of automatically identifying which claims in a given document are most checkworthy and thus should be prioritized for factchecking. We focus on how contextual and discourse information can help in this task. We further study how to learn from multiple sources simultaneously (e.g., PolitiFact, FactCheck, ABC), with the objective of mimicking the selection strategies of one particular target source; we do this in a multitask learning setup. 2.1 Data We used the CWUSPD2016 dataset, which is centered around political debates [Gencheva et al .2017]. It contains four transcripts of the 2016 US Presidential election debates: one vicepresidential and three presidential. Each debate is annotated at the sentence level as checkworthy or not, but the sentences are kept in the context of the full debate, including metadata about the speaker, speaker turns, and system messages about the public reaction. The annotations were derived using publiclyavailable manual analysis of these debates by nine reputable factchecking sources, shown in Table 1. This analysis was converted into a binary annotation: whether a particular sentence was annotated for factuality by a given source. Whenever one or more annotations were about part of a sentence, the entire sentence was selected, and when an annotation spanned over multiple sentences, each of them was selected. The dataset with the four debates contains 5,415 sentences, out of which 880 are positive examples (i.e., selected for factchecking by at least one of the sources). Table 2 presents an excerpt of this corpus. Note that the investigative journalists did not select the checkworthy claims in isolation, ignoring the context. Our analysis shows that these include claims that were highly disputed during the debate, that were relevant to the topic introduced by the moderator, etc. We will make use of these contextual dependencies below. 2.2 Modeling Context and Discourse We developed a rich input representation in order to model and to predict the checkworthiness of a sentence. In particular, we included a variety of contextual and discoursebased features. They characterize the sentence in the context of the full segment by the same speaker, sometimes also looking at the previous and the following segments. We define a segment as a maximal set of consecutive sentences by the same speaker, without intervention by another speaker or the moderator, i.e., a turn. We start by describing these contextbased features, which are the focus of attention of this work. Manuscript submitted to ACM4 Atanasova et al. Speaker Text Annotation Sources CT ABC CNN WP NPR PF TG NYT FC All Check? Clinton: So we‚Äôre now on the precipice of having a potentially much better economy, but the last thing we need to do is to go back to the policies that failed us in the first place.0 0 0 0 0 0 0 0 0 0 No Clinton: Independent experts have looked at what I‚Äôve proposed and looked at what Donald‚Äôs proposed, and basically they‚Äôve said this, that if his tax plan, which would blow up the debt by over $5 trillion and would in some in stances disadvantage middleclass families compared to the wealthy, were to go into effect, we would lose 3.5 million jobs and maybe have another recession.1 1 0 0 1 1 0 1 1 6 Yes Clinton: They‚Äôve looked at my plans and they‚Äôve said, OK, if we can do this, and I intend to get it done, we will have 10 million more new jobs, because we will be making investments where we can grow the economy.1 0 0 0 0 0 0 0 0 1 Yes Clinton: Take clean energy. 0 0 0 0 0 0 0 0 0 0 No Clinton: Some country is going to be the clean energy super power of the 21st century.0 0 0 0 0 0 0 0 0 0 No Clinton: Donald thinks that climate change is a hoax perpetrated by the Chinese.1 1 1 1 0 0 1 0 1 6 Yes Clinton: I think it‚Äôs real. 0 0 0 0 0 0 0 0 0 0 No Trump: I did not. 1 1 0 1 1 1 0 0 0 5 Yes Table 2. Excerpt from the transcript of the first US Presidential Debate in 2016, annotated by nine sources: Chicago Tribune (CT), ABC News, CNN, Washington Post (WP), NPR, PolitiFact (PF), The Guardian (TG), The New York Times (NYT) and Factcheck.org (FC). Whether the media factchecked the claim or not is indicated by a 1 or 0, respectively. The total number of sources that annotated an example is shown in column ‚ÄúAll‚Äù. Column ‚ÄúCheck?‚Äù indicates the class label, i.e., whether the example is checkworthy or not. The positive examples are also highlighted in blue. 2.2.1 Position ( 3 features ).A sentence on the boundaries of a speaker‚Äôs segment could contain a reaction to another statement or could provoke a reaction, which in turn could signal a checkworthy claim. Thus, we added information about the position of the target sentence in its segment: whether it is first/last, as well as its reciprocal rank in the list of sentences in that segment. 2.2.2 Segment sizes ( 3 features ).The size of the segment belonging to one speaker might indicate whether the target sentence is part of a long speech, makes a short comment or is in the middle of a discussion with lots of interruptions. The size of the previous and of the next segments is also important in modeling the dialogue flow. Thus, we include three features with the size of the previous, the current, and the next segments. 2.2.3 Metadata ( 8 features ).Checkworthy claims often contain accusations about the opponents, as the example below shows (from the 2nd presidential debate): Trump: Hillary Clinton attacked those same women and attacked them viciously. ... Clinton: They‚Äôre doing it to try to influence the election for Donald Trump . Thus, we use a feature that indicates whether the target sentence mentions the name of the opponent, whether the speaker is the moderator, and also who is speaking (3 features). We further use three binary features, indicating whether the target sentence is followed by a system message: applause ,laugh , orcrosstalk . Manuscript submitted to ACMAutomatic FactChecking Using Context and Discourse Information 5 2.2.4 Topics ( 303 features ).Some topics are more likely to be associated with checkworthy claims, and thus we have features modeling the topics in the target sentence as well as in the surrounding context. We trained a Latent Dirichlet Allocation (LDA) topic model [Blei et al .2003] on all political speeches and debates in The American Presidency Project2using all US presidential debates in the 2007‚Äì2016 period3. We had 300 topics, and we used the distribution over the topics as a representation for the target sentence. We further modeled the context using cosines with such representations for the previous, the current, and the next segment. 2.2.5 Embeddings ( 303 features ).We also modeled semantics using word embeddings. We used the pretrained 300dimensional Google News word embeddings by Mikolov et al .[2013a] to compute an average embedding vector for the target sentence, and we used the 300 dimensions of that vector. We also modeled the context as the cosine between that vector and the vectors for three segments: the previous, the current, and the following one. 2.2.6 Contradictions. (5 features ) Many claims selected for factchecking contain contradictions to what has been said earlier, as in the example below (from the 3rd presidential debate): Clinton: [...] about a potential nuclear competition in Asia, you said, you know, go ahead, enjoy yourselves, folks. Trump: I didn‚Äôt say nuclear. We model this by counting the negations in the target sentence as found in a dictionary of negation cues such as not, didn‚Äôt , and never . We further model the context as the number of such cues in the two neighboring sentences from the same segment and the two neighboring segments. 2.2.7 Similarity of the sentence to known positive/negative examples ( 3 features ).We used three more features that measure the similarity of the target sentence to other known examples. The first one computes the maximum over the training sentences of the number of matching words between the target and the training sentence, which is further multiplied by 1 if the latter was not checkworthy. We also used another version of the feature, where we multiplied it by 0 if the speakers were different. A third version took as a training set all claims checked by PolitiFact4(excluding the target sentence). 2.2.8 Discourse ( 20 features ).We saw above that contradiction can signal the presence of checkworthy claims and contradiction can be expressed by a discourse relation such as Contrast . As other discourse relations such as Background ,Cause , and Elaboration can also be useful, we used a discourse parser [Joty et al .2015] to parse the entire segment. This parser follows the Rhetorical Structure Theory (RST). It produces a hierarchical representation of the discourse by linking first the elementary discourse units with binary discourse relations (indicating also which unit is the nucleus and which is the satellite ), and building up the tree by connecting with the same type of discourse relations the more general crosssentence nodes until a root node covers all the text. From this tree, we focused on the direct relationship between the target sentence and the other sentences in its segment; this gave rise to 18 contextual indicator features. We further analyzed the internal structure of the target sentence ‚Äîhow many nuclei and how many satellites it contains‚Äî, which gave rise to two sentencelevel features. 2http://www.presidency.ucsb.edu/debates.php 3https://github.com/paigecm/2016campaign 4http://www.politifact.com/ Manuscript submitted to ACM6 Atanasova et al. Bias Type Sample Cues Factives realize, know, discover, learn Implicatives cause, manage, hesitate, neglect Assertives think, believe, imagine, guarantee Hedges approximately, estimate, essentially Reportverbs argue, admit, confirm, express Wikibias capture, create, demand, followBias Type Sample Cues Modals can, must, will, shall Negations neither, without, against, never, none Strongsubj admire, afraid, agreeably, apologist Weaksubj abandon, adaptive, champ, consume Positives accurate, achievements, affirm Negatives abnormal, bankrupt, cheat, conflicts Table 3. Some cues for various bias types. 2.3 Other Features 2.3.1 ClaimBusterbased ( 1,045 core features ).In order to be able to compare our model and features directly to the previous state of the art, we reimplemented, to the best of our ability, the sentencelevel features of ClaimBuster [Hassan et al.2015], namely TFIDFweighted bag of words (998 features), partofspeech tags (25 features), named entities as recognized by Alchemy API5(20 features), sentiment score from Alchemy API (1 feature), and number of tokens in the target sentence (1 feature). Apart from providing means of comparison to the state of the art, these features also make a solid contribution to our final system for checkworthiness estimation. However, note that we did not have access to the training data of ClaimBuster , which is not publicly available, and we thus train on our own dataset. 2.3.2 Sentiment ( 2 features ).Some sentences are highly negative, which can signal the presence of an interesting claim to check, as the two following example sentences show (from the 1st and the 2nd presidential debates): Trump: Murders are up. Clinton: Bullying is up. We used the NRC sentiment lexicon [Mohammad and Turney 2013] as a source of words and ngrams with posi tive/negative sentiment, and we counted the number of positive and of negative words in the target sentence. These features are different from those in ClaimBuster , where these lexicons were not used. 2.3.3 Named entities (NE) ( 1 feature ).Sentences that contain named entity mentions are more likely to contain a claim that is worth factchecking as they discuss particular people, organizations, and locations. Thus, we have a feature that counts the number of named entities in the target sentence; we use the NLTK toolkit for named entity recognition [Loper and Bird 2002]. Unlike the ClaimBuster features above, here we only have one feature; we also use a different toolkit for named entity recognition. 2.3.4 Linguistic features (13 features). We use as features the presence and the frequency of occurrence of linguistic markers such as factives andassertives from [Hooper 1974], implicatives from [Karttunen 1971], hedges from [Hyland 2005], Wikibias terms from [Recasens et al. 2013], subjectivity cues from [Riloff and Wiebe 2003], and sentiment cues from [Liu et al .2005].6We compute a feature vector according to Equation (1)where for each bias type Biand answer Aj, the frequency of the cues for BiinAjis computed and then normalized by the total number of words in Aj: Bi(Aj)=√ç cue‚ààBicount(cue ,Aj) √ç wk‚ààAjcount(wk,Aj)(1) 5http://www.ibm.com/watson/alchemyapi.html 6Most of these bias cues can be found at http://people.mpisws.org/~cristian/Biased_language.html Manuscript submitted to ACMAutomatic FactChecking Using Context and Discourse Information 7 Below we describe these cues in more detail. ‚Ä¢Factives (1 feature ) [Hooper 1974] are verbs that imply the veracity of their complement clause. In E1,know suggests that ‚Äúthey will open a second school . . . ‚Äù and ‚Äúthey provide a qualified french education . . . ‚Äù are factually true statements. E1:know that they will open a second school; and they are a nice french school. . . I know that they provide aqualified french education and add with that the history and arabic language to be adapted to the qatar. I think that‚Äôs an interesting addition. ‚Ä¢Assertives (1 feature ) [Hooper 1974] are verbs that imply the veracity of their complement clause with a level of certainty. E.g., in E1,think indicates some uncertainty, while verbs like claim cast doubt on the certainty of their complement clause. ‚Ä¢Implicatives (1 feature ) [Karttunen 1971] are verbs that imply the (un)truthfulness of their complement clause, e.g., decline andsucceed . ‚Ä¢Hedges (1 feature ) [Hyland 2005] reduce the person‚Äôs commitment to the truth, e.g., may andpossibly . ‚Ä¢Reporting verbs (1 feature ) are used to report a statement from a source, e.g., argue andexpress . ‚Ä¢Wikibias cues (1 feature ) [Recasens et al .2013] are extracted from the NPOV corpus from Wikipedia and cover bias cues (e.g., provide inE1), and controversial words, such as abortion andexecute . These words are not available in neither of the other bias lexicons. ‚Ä¢Modals (1 feature ) are used to change the certainty of the statement (e.g., willorcan), make an offer (e.g., shall ), ask permission (e.g., may), or express an obligation or necessity (e.g., must ). ‚Ä¢Negations (1 feature ) are used to deny or make negative statements such as no,never . ‚Ä¢Subjectivity cues (2 features ) [Riloff and Wiebe 2003] are used when expressing personal opinions and feelings. There are strong andweak cues, e.g., in E1,niceandinteresting arestrong , while qualified isweak . ‚Ä¢Sentiment cues (2 features ). We use positive andnegatives sentiment cues [Liu et al .2005] to model the attitude, thought, and emotions of the speaker. In E1,nice,interesting andqualified are positive cues. The above bias and subjectivity cues are mostly single words. Sometimes a multiword cue (e.g., ‚Äúwe can guarantee‚Äù) can be a stronger signal for user‚Äôs certainty/uncertainty in their answers. We thus further generate multiword cues (1 feature) by combining implicative ,assertive ,factive andreport verbs with first person pronouns ( I/we),modals and strong subjective adverbs , e.g., I/we+verb (e.g. ‚ÄúI believe‚Äù), I/we+adverb+verb (e.g., ‚ÄúI certainly know‚Äù), I/we+modal+verb (e.g., ‚Äúwe could figure out‚Äù) and I/we+modal+adverb+verb (e.g., ‚Äúwe can obviously see‚Äù). 2.3.5 Tense ( 1 feature ).Most of the checkworthy claims mention past events. In order to detect when the speaker is making a reference to the past or is talking about his/her future vision and plans, we include a feature with three values ‚Äîindicating whether the text is in past, present or future tense. The feature is extracted in a simplified fashion from the verbal expressions, using POS tags and a list of auxiliary phrases. In particular, we consider a sentence to be in the past tense if it contains a past verb ( VBD), and in the future tense if it contains willorhave to ; otherwise, we assume it to be in the present tense. 2.3.6 Length ( 1 feature ).Shorter sentences are generally less likely to contain a checkworthy claim.7Thus, we have a feature for the length of the sentence in terms of characters. Note that this feature was not part of the ClaimBuster features, as there length was modeled in terms of tokens, but here we do so using characters. 7One notable exception are short sentences with negations, e.g., Wrong. ,Nonsense. , etc. Manuscript submitted to ACM8 Atanasova et al. Our System MAP RPr P@5 P@10 P@20 P@50 All features 0.427 0.432 0.800 0.725 0.713 0.600 All\discourse 0.412 0.431 0.800 0.700 0.685 0.550 All\context 0.385 0.390 0.550 0.500 0.550 0.540 Only context+discourse 0.317 0.404 0.725 0.563 0.465 0.465 Reference systems Random 0.164 0.007 0.200 0.125 0.138 0.160 TFIDF 0.314 0.333 0.550 0.475 0.413 0.360 Claimbuster‚ÄìPlatform 0.317 0.349 0.500 0.550 0.488 0.405 Claimbuster‚ÄìFeatures 0.357 0.379 0.500 0.550 0.550 0.510 Table 4. Overall results for checkworthy claims identification, focusing on the impact of the contextual and discourse features. 2.4 Experiments Learning Algorithm. We used a feedforward neural network (FNN) with two hidden layers (with 200 and 50 neurons, respectively) and a softmax output unit for the binary classification.8We used ReLU [Glorot et al .2011] as the activation function and we trained the network with Stochastic Gradient Descent [LeCun et al .1998] for 300 epochs with a batch size of 550. We set the L2 regularization to 0.0001, and we kept a constant learning rate of 0.04. We further enhanced the learning process by using a Nesterov‚Äôs momentum [Sutskever et al. 2013] of 0.9. Setting. We trained the models to classify sentences as positive if one or more media had factchecked a claim inside the target sentence, and negative otherwise. We then used the classifier scores to rank the sentences with respect to checkworthiness .9We tuned the parameters and we evaluated the performance using 4fold crossvalidation, using each of the four debates in turn for testing while training on the remaining three. Implementation Details. We used gensim [≈òeh≈Ø≈ôek and Sojka 2010] for LDA and word embeddings, NLTK [Loper and Bird 2002] for NER and POS tagging, and scikitlearn [Buitinck et al. 2013] for deep learning. Evaluation. We use ranking measures such as Precision at k(P@k) and Mean Average Precision (MAP). As Table 1 shows, most media rarely check more than 50 claims per debate, which means that there is no need to factcheck more than 50 sentences. Thus, we report P@kfork‚àà{5,10,20,50}.10MAP is the mean of the Average Precision across the four debates. Finally, we also measure the recall at the Rth position of returned sentences for each debate, where Ris the number of relevant documents for that debate and the metric is known as RPrecision ( RPr). As with MAP, we provide the average across the 4 debates. Results. Table 4 shows all the results of our claim ranking system with several feature variants. In order to put the numbers in perspective, we also show the results for four increasingly competitive baselines (‚ÄòReference Systems‚Äô). The first one is a random baseline. It is then followed by an SVM classifier based on a bagofwords representation with TF IDF weights estimated on the training data. Then come two versions of the ClaimBuster system: Claimbuster‚ÄìPlatform refers to the performance of ClaimBuster using the scores obtained from their online demo,11which we accessed on December 20, 2016, and Claimbuster‚ÄìFeatures is our reimplementations of ClaimBuster using our FNN classifiers trained on our dataset with their features. 8Previous work [Gencheva et al. 2017] showed that the neural network performs better on the task than support vector machine classifiers. 9We also tried using ordinal regression, and SVMperf (an instantiation of SVMstruct), to directly optimize precision, but they performed worse. 10Note that as far as the difference between the P@k metrics (especially between 5 and 10) is in terms of a few sentences, the deviation between them can seem large, while caused by a few correctly/wrongly classified sentences. 11http://idirserver2.uta.edu/claimbuster/demo Manuscript submitted to ACMAutomatic FactChecking Using Context and Discourse Information 9 We can see that our system with all features outperforms all reference systems by a large margin for all metrics. The two versions of ClaimBuster also outperform the TFIDF baseline on most measures. Moreover, our reimplementation ofClaimBuster is better than the online platform, especially in terms of MAP. This is expected as their system is trained on a different dataset and it may suffer from testing on slightly outofdomain data. Our advantage with respect to ClaimBuster implies that the extra information coded in our model, mainly more contextual, structural, and linguistic features, has an important contribution to the final performance. Rows 2‚Äì4 in Table 4 show the effect of the discourse and of the contextual features implemented in our system. The contextual features have a major impact on performance: excluding them yields major drop for all measures, e.g., MAP drops from 0.427 to 0.385, and P@5 drops from 0.800 to 0.550. The discourse features also have an impact, although it is smaller. The most noticeable difference is in the quality at the lower positions in the rank, e.g., P@5 does not vary when removing discourse features, but P@10, P@20 and P@50 all drop by 2.5 to 5 percent points. Finally, row 4 in the table shows that contextual+discourse features alone already yield a competitive system, performing about the same asClaimbuster‚ÄìPlatform (which uses no contextual features at all). In Section 4, we will present a further qualitative description of the results including some examples. 2.5 Multitask Learning Experiments Unlike the above singlesource approaches, in this subsection, we explore a multisource neural network framework, in which we try to predict the selections of each and every factchecking organization simultaneously. We show that, even when the goal is to mimic the selection strategy of one particular factchecking organization, it is beneficial to leverage on the selection choices by multiple such organizations. Setting. We approach the task of checkworthiness prediction using the same features, while at the same time modeling the problem as multitask learning, using different sources of annotation over the same training dataset. As a result, we can learn to mimic the selection strategy of each and every of these individual sources. As we have explained above, in our dataset the individual judgments come from nine independent factchecking organizations, and we thus predict the selection choices of each of them in isolation plus a collective label ANY , which indicates whether at least one source would judge that claim as checkworthy. Architecture. Figure 1 illustrates the architecture of the full neural multisource learning model, which predicts the selection choices of each of the nine individual sources (tasks) and of the special cumulative source: task ANY . There is a hidden layer (of size 300) that is shared between all ten tasks. Then, each task has its own taskspecific hidden layer (each of size 300). Finally, each taskspecific layer is followed by an output layer: a single sigmoid unit that provides the prediction of whether the utterance was factchecked by the corresponding source. Eventually, we make use of the probability of the prediction to prioritize claims for factchecking. During training, each task modifies the weights of both its own taskspecific layer and of the shared layer. For our neural network architecture, we used ReLU units, Stochastic Gradient Descent with Nesterov momentum of 0.7, iterating for 100 epochs with batches of size 500 and a learning rate of 0.08. This kind of neural network architecture for multitask learning is known in the literature as hard parameter sharing [Caruana 1993], and it can greatly reduce the risk of overfitting. In particular, it has been shown that the risk of overfitting the shared parameters in the hidden layer is an order nsmaller than overfitting the taskspecific parameters in the output layers, where nis the number of tasks at hand [Baxter 1997]. The input to our neural network consists of the various domainspecific features that have been previously described. Manuscript submitted to ACM10 Atanasova et al. Fig. 1. The architecture of the full neural multisource learning model, predicting the selection choices of each of the nine individual sources (tasks) and of one cumulative source: task ANY . Implementation Details. We implemented the neural network using Keras. We tried adding more shared and task specific layers as well as having some taskspecific layers linked directly to the input, but we eventually settled on the architecture in Figure 1. We also tried to optimize directly for average precision and adding loss weights to task ANY , but using the standard binary crossentropy loss yielded the best results. Results. As before, we perform 4fold crossvalidation, where each time we leave one debate out for testing. Moreover, in order to stabilize the results, we repeat each experiment three times with different random seeds, and we report the average over these three reruns.12We should note that in most cases this was not really needed, as the standard deviation for the reruns was generally tiny: 0.001 or less, absolute. Table 5 presents the results, with all evaluation metrics, when predicting each of the nine sources. We experiment with three different configurations of the model described in the previous section. All of them aim at learning to mimic the selection choices by one single factchecking organization (source). The first one is a singletask baseline singleton where a separate neural network is trained for each source. The other two are multitask learning configurations: multi trains to predict labels for each of the nine tasks, one for each factchecker; and multi+any trains to predict labels for each of the nine tasks (one for each factchecker), and also for task ANY (as shown in Figure 1). We can see in Table 5 that, for most of the sources, multitask learning improves over the singlesource system. The results of the multitask variations that improve over the single baseline are boldfaced in the table. The improvements are consistent across evaluation metrics and vary largely depending on the source and the metric. One notable exception is NYT, for which the singletask learning shows the highest scores. We hypothesize that the network has found some distinctive features of NYT, which make it easy to predict. These relations are blurred when we try to optimize for multiple tasks at once. However, it is important to state that removing NYT from the learning targets worsens the results for the other sources, i.e., it carries some important relations that are worth modeling. 12Having multiple reruns is a standard procedure to stabilize an optimization algorithm that is sensitive to the random seed, e.g., this strategy has been argued for when using MERT for tuning hyperparameters in Statistical Machine Translation [Foster and Kuhn 2009]. Manuscript submitted to ACMAutomatic FactChecking Using Context and Discourse Information 11 Model MAP RPr P@5 P@10 P@20 P@50 ABC singleton 0.097 0.112 0.250 0.175 0.162 0.100 multi 0.119 0.157 0.333 0.225 0.217 0.122 multi+any 0.118 0.160 0.300 0.233 0.229 0.132 The Washington Post (WP) singleton 0.106 0.110 0.150 0.100 0.112 0.110 multi 0.127 0.127 0.350 0.233 0.162 0.123 multi+any 0.130 0.129 0.350 0.250 0.171 0.110 CNN singleton 0.087 0.091 0.250 0.150 0.121 0.090 multi 0.113 0.132 0.250 0.208 0.183 0.140 multi+any 0.109 0.126 0.167 0.200 0.167 0.128 FactCheck (FC) singleton 0.084 0.114 0.117 0.125 0.088 0.100 multi 0.105 0.136 0.250 0.175 0.146 0.118 multi+any 0.117 0.110 0.333 0.242 0.196 0.107 PolitiFact singleton 0.201 0.278 0.250 0.250 0.262 0.262 multi 0.209 0.258 0.400 0.367 0.317 0.270 multi+any 0.210 0.252 0.500 0.350 0.333 0.272Model MAP RPr P@5 P@10 P@20 P@50 NPR singleton 0.175 0.195 0.250 0.250 0.283 0.228 multi 0.186 0.210 0.333 0.342 0.300 0.245 multi+any 0.180 0.207 0.333 0.283 0.250 0.227 The Guardian (TG) singleton 0.127 0.174 0.200 0.150 0.196 0.178 multi 0.133 0.199 0.183 0.175 0.192 0.193 multi+any 0.130 0.159 0.217 0.175 0.200 0.167 Chicago Tribune (CT) singleton 0.079 0.110 0.100 0.100 0.125 0.075 multi 0.081 0.090 0.100 0.133 0.104 0.082 multi+any 0.087 0.087 0.133 0.100 0.108 0.093 The New York Times (NYT) singleton 0.187 0.221 0.350 0.325 0.238 0.192 multi 0.150 0.213 0.233 0.200 0.196 0.180 multi+any 0.147 0.197 0.200 0.167 0.158 0.162 Table 5. Evaluation results for each of the nine factchecking organizations as a target to mimic. Shown are results for singlesource baselines and for multitask learning. The improvements over the corresponding baselines are marked in bold. Model MAP RPr P@5 P@10 P@20 P@50 CB online 0.090 0.138 0.144 0.143 0.121 0.117 singletonG 0.120 0.142 0.228 0.206 0.179 0.137 any 0.128 0.225 0.194 0.186 0.178 0.153 singleton (embed.) 0.058 0.065 0.055 0.055 0.068 0.072 singleton CB 0.072 0.077 0.106 0.076 0.081 0.079 singleton 0.127 0.156 0.213 0.181 0.176 0.148 multi 0.136 0.169 0.270 0.229 0.202 0.164 multi+any 0.136 0.159 0.281 0.222 0.201 0.155 any 0.125 0.153 0.204 0.197 0.175 0.153 singleton+any 0.130 0.153 0.237 0.220 0.184 0.148 Table 6. Evaluation results averaged over nine factchecking organizations. The improvements over singleton are in bold. The first three rows of Table 6 present the same results but averaged over the nine sources. Again, we can see that multitask learning yields sizable improvement over the singletask learning baseline for all evaluation measures. Another conclusion that can be drawn is that including the task anydoes not help to improve the multitask model. This is probably due to the fact that this information is already contained in the multitask model with nine distinct sources only. The last two rows in Table 6 present two additional variants of the model: the singletask learning anysystem, which is trained on the union of the selected sentences by all nine factcheckers to predict the target factchecker only; and the system singleton+any that predicts labels for two tasks: ( i) for the target factchecker, and ( ii) for task ANY . Manuscript submitted to ACM12 Atanasova et al. q:If wife is under her husband‚Äôs sponsorship and is willing to come Qatar on visit, how long she can stay after extending the visa every month? I have heard it‚Äôs not possible to extend visit visa more than 6 months? . . . a1: Maximum period is 9 Months.... a2: 6 months maximum a3:This has been answered in QL so many times. Please do search for information regarding this. BTW answer is 6 months. Fig. 2. Example from the Qatar Living forum. We can see that the model anyperforms comparably to the singleton baseline, thus being clearly inferior than the multitask learning variants. Finally, singleton+any is also better than the singletask learning variants, but it falls short compared to the other multitask learning variants. Including output units for all nine individual media seems crucial for getting advantage of the multitask learning, i.e., considering only an extra output prediction node for task ANY is not enough. 3 FACTCHECKING With the ever growing amount of unreliable content online, veracity will almost certainly become an important component of question answering systems in the future. In this section, we focus on factchecking in the context of community question answering (cQA), i.e., predicting whether an answer to a given question is likely to be true. This aspect has been ignored, e.g., in recent cQA tasks at NTCIR and SemEval [Ishikawa et al .2010; Nakov et al .2017a, 2015, 2016], where an answer is considered as Good if it tries to address the question, irrespective of its veracity. Yet, veracity is an important aspect, as highquality automatic factchecking can offer a better experience to the users of cQA systems; e.g., a possible application scenario would be that in which the user could be presented with a ranking of all good answers accompanied by veracity scores, where low scores would warn her not to completely trust the answer or to doublecheck it. Figure 2 presents an excerpt of an example from the Qatar Living forum, with one question ( q) and three plausible answers ( a1‚àía3) selected from a longer thread. According to the SemEval2016 Task 3 annotation instructions [Nakov et al.2016], all three answers are considered Good since they address the question. Nevertheless, a1contains false information, while a2anda3are true,13as can be checked on an official governmental website.14 3.1 Data We use the CQAQLFACT dataset, which stresses the difference between (a) distinguishing a good vs. a bad answer, and (b) distinguishing between a factually true vs. a factually false one. We added the factuality annotations on top of the CQAQL2016 dataset from the SemEval2016 Task 3 on community Question Answering [Nakov et al .2016]. In CQAQL2016, the data is organized in question‚Äìanswer threads extracted from the Qatar Living forum. Each question has a subject, a body, and metadata: ID, category (e.g., Computers and Internet ,Education , and Moving to Qatar ), date and time of posting, and user name. 13One could also guess that answers a2anda3are more likely to be true from the fact that the 6 months answer fragment appears many times in the current thread (it also happens to appear more often in related threads as well). While these observations serve as the basis for useful features for classification, the real verification for a gold standard annotation requires finding support from a reliable external information source: in this case, an official government information portal. 14https://www.moi.gov.qa/site/english/departments/PassportDept/news/2011/01/03/23385.html Manuscript submitted to ACMAutomatic FactChecking Using Context and Discourse Information 13 Label #Questions Example Factual 373 What is Ooredoo customer service number? Opinion 689 Can anyone recommend a good Vet in Doha? Socializing 295 What was your first car? Table 7. Distribution of factuality labels in the annotated questions (1,357 in total). First, we annotated the questions using the following labels: ‚Ä¢Factual : The question is asking for factual information, which can be answered by checking various information sources, and it is not ambiguous. ‚Ä¢Opinion : The question asks for an opinion or an advice, not for a fact. ‚Ä¢Socializing : Not a real question, but rather socializing/chatting. This can also mean expressing an opinion or sharing some information without really asking anything of general interest. We annotated 1,982 questions, with the above factuality labels. We ended up with 625 instances that contain multiple questions, which we excluded from further analysis. Table 7 shows the annotation results for the remaining 1,357 questions, including examples. Next, we annotated for veracity the answers to the factual questions. We only annotated the originally judged as Good answers (ignoring both Bad andPotentially Useful ), and we used the following labels: ‚Ä¢Factual  True : The answer is True and this can be verified using an external resource. ( q: ‚ÄúI wanted to know if there were any specific shots and vaccinations I should get before coming over [to Doha]. ‚Äù; a: ‚ÄúYes there are; though it varies depending on which country you come from. In the UK; the doctor has a list of all countries and the vaccinations needed for each. ‚Äù ).15 ‚Ä¢Factual  False : The answer gives a factual response, but it is false. ( q: ‚ÄúCan I bring my pitbulls to Qatar?‚Äù, a: ‚ÄúYes you can bring it but be careful this kind of dog is very dangerous. ‚Äù ).16 ‚Ä¢Factual  Partially True : We could only verify part of the answer. ( q: ‚ÄúI will be relocating from the UK to Qatar [. . . ] is there a league or TT clubs / nights in Doha?‚Äù, a: ‚ÄúVisit Qatar Bowling Center during thursday and friday and you‚Äôll find people playing TT there. ‚Äù ).17 ‚Ä¢Factual  Conditionally True : The answer is True in some cases, and False in others, depending on some conditions that the answer does not mention. ( q: ‚ÄúMy wife does not have NOC from Qatar Airways; but we are married now so can i bring her legally on my family visa as her husband?‚Äù, a: ‚ÄúYes you can. ‚Äù ).18 ‚Ä¢Factual  Responder Unsure : The person giving the answer is not sure about the veracity of his/her statement. (e.g., ‚Äú Possible only if government employed. That‚Äôs what I heard. ‚Äù) ‚Ä¢NonFactual : The answer is not factual. It could be an opinion, an advice, etc. that cannot be verified. (e.g., ‚Äú Its better to buy a new one. ‚Äù) We further discarded items whose factuality was very timesensitive (e.g., ‚Äú It is Friday tomorrow. ‚Äù, ‚ÄúIt was raining last week. ‚Äù)19, or for which the annotators were unsure. 15This can be verified at https://wwwnc.cdc.gov/travel/destinations/traveler/none/qatar 16The answer is not true because pitbulls are included in the list of banned breeds in Qatar: http://canvethospital.com/petrelocation/ banneddogbreedlistqatar2015/ 17The place has table tennis, but we do not know on which days: https://www.qatarbowlingfederation.com/bowlingcenter/ 18This answer can be true, but this depends upon some conditions: http://www.onlineqatar.com/info/dependentfamilyvisa.aspx 19Arguably, many answers are somewhat timesensitive, e.g., ‚Äú There is an IKEA in Doha. ‚Äù is true only after IKEA opened, but not before that. In such cases, we just used the present situation as a point of reference. Manuscript submitted to ACM14 Atanasova et al. CoarseGrained Label Answers FineGrained Label Answers +Positive 128 +Factual  True 128 ‚àíNegative 121‚àíFactual  False 22 ‚àíFactual  Partially True 38 ‚àíFactual  Conditionally True 16 ‚àíFactual  Responder Unsure 26 ‚àíNonFactual 19 Table 8. Distribution of the positive and the negative answers (i.e., the two classes we predict) and of the finegrained labels. We considered all questions from the Dev and the Test partitions of the CQAQL2016 dataset. We targeted very high quality, and thus we did not crowdsource the annotation, as pilot annotations showed that the task was very difficult and that it was not possible to guarantee that Turkers would do all the necessary verification, e.g., gather evidence from trusted sources. Instead, all examples were first annotated independently by four annotators, and then they discussed each example in detail to come up with a final label. We ended up with 249 Good answers20to 71 different questions, which we annotated for factuality: 128 Positive and 121 Negative examples. See Table 8 for details. 3.2 Modeling Context and Discourse We model the context of an answer with respect to the entire answer thread in which it occurs, and with respect to other highquality posts from the entire Qatar Living forum. We further use discourse features as in Section 2.2.8. 3.2.1 Support from the current thread ( 5 features ).We use the cosine similarity between an answer and a thread vector of all Good answers using Qatar Living embeddings. For this purpose, we use 100dimensional indomain word embeddings [Mihaylov and Nakov 2016b], which were trained using word2vec [Mikolov et al .2013b] on a large dump of Qatar Living data (2M answers).21The idea is that if an answer is similar to other answers in the thread, it is more likely to be true. To this, we add threadlevel features related to the rank of the answer in the thread: ( i) the reciprocal rank of the answer in the thread and ( ii) percentile of answer‚Äôs rank in the thread. As there are exactly ten answers per thread in the dataset, the first answer gets the score of 1.0, the second one gets 0.9, the next one gets 0.8, and so on. We calculate these two ranking features twice: once for the full list of answers, and once for the list of good answers only. 3.2.2 Support from all of Qatar Living ( 60 features ).We further collect supporting evidence from all threads in the Qatar Living forum. To do this, we query a search engine, limiting the search to the forum only. See Section 3.3.3 for more detail about how the search for evidence on the Web is performed and what features are calculated. 3.2.3 Support from highquality posts in Qatar Living. Among the 60kactive users of the Qatar Living forum, there is a community of 38 trusted users, who have written 5.2khighquality articles on topics that attract a lot of interest, e.g., issues related to visas, work legislation, etc. We try to verify the answers against these highquality posts. ( i) Since an answer can combine both relevant and irrelevant information with respect to its question, we first generate a query against a search engine for each Q&A. ( ii) We then compute cosines between the query and the sentences in the highquality posts, and we select the kbest matches. ( iii) Finally, we compute textual entailment scores [Kouylekov and Negri 2010] for the answer given the kbest matches, which we then use as features. An example is shown in Table 9. 3.2.4 Discourse features. We use the same discourse features as for the claim identification task (cf. Section 2.2.8). 20This is comparable in size to other factchecking datasets, e.g., Ma et al. [2015] used 226 rumors, and Popat et al. [2016] had 100 Wiki hoaxes. 21Available at http://alt.qcri.org/semeval2016/task3/data/uploads/QLunannotateddatasubtaskA.xml.zip Manuscript submitted to ACMAutomatic FactChecking Using Context and Discourse Information 15 Question : does anyone know if there is a french speaking nursery in doha? Answer : there is a french school here. don‚Äôt know the ages but my neighbor‚Äôs 3 yr old goes there. . . Best Matched Sentence for Q&A: there is a french school here. Post Id sNo R1 R2 Sentence 35639076 15 1 10 the preschool follows the english program but also gives french and arabic lessons. 32448901 4 2 11 france bought the property in 1952 and since 1981 it has been home to the french institute. 31704366 7 3 1 they include one indian school, two french, seven following the british curriculum. . . 27971261 6 4 4 the new schools include six qatari, four indian, two british, two american and a finnish. . . Table 9. Sample of sentences from highquality posts automatically extracted to support the answer A.sNois the sentence‚Äôs sequential number in the post, R1andR2are the ranks of the target sentences based on entailment and similarity, respectively. Question: Hi; Just wanted to confirm Qatar‚Äôs National Day. Is it 18th of December? Thanks. Answer: yes; it is 18th Dec. Query generated from Q&A: ""National Day"" ""Qatar"" National December Day confirm wanted Qatar Source URL related? type Snippet qppstudio.net No Other Public holidays and national . . . the world‚Äôs source of Public holidays information dohanews.co Yes Reputed culture and more in and around Qatar ...The documentary features human interest pieces that incorporate the daytoday lives of Qatar residents iloveqatar.net Yes Forum Qatar National Day  Short Info ...the date of December 18 is celebrated each year as the National Day of Qatar. . . cnn.com No Reputed The 2022 World Cup final in Qatar will be held on December 18 ...Qatar will be held on December 18 ‚Äì the Gulf state‚Äôs national day. Confirm. U.S . . . icassociat No Other In partnership with ProEvent Qatar, ICA can confirm that the World Stars ion.co.uk will be led on the 17 December, World Stars vs. Qatar Stars  Qatar National Day. Table 10. Sample snippets returned by a search engine for a given query generated from a Q&A pair. 3.3 Other Features 3.3.1 Linguistic bias, subjectivity and sentiment. Forum users, consciously or not, often put linguistic markers in their answers, which can signal the degree of the user‚Äôs certainty in the veracity of what they say. We thus use the linguistic features from the previous task (see above). 3.3.2 Credibility ( 31 features ).We use features that have been previously proposed for credibility detection [Castillo et al.2011]: number of URLs/images/emails/phone numbers; number of tokens/sentences; average number of tokens; number of positive/negative smileys; number of single/double/triple exclamation/interrogation symbols. To this set, we further add number of interrogative sentences; number of nouns/verbs/adjectives/adverbs/pronouns; and number of words that are not in word2vec‚Äôs Google News vocabulary (such OOV words could signal slang, foreign language, etc.) We also use the number of 1st, 2nd, 3rd person pronouns in the comments: ( i) in absolute number, and also (ii) normalized by the total number of pronouns in the comment. The latter is also a feature. 3.3.3 Support from the Web ( 60 features ).We tried to verify whether an answer‚Äôs claim is factually true by searching for supporting information on the Web. We started with the concatenation of an answer to the question that heads the respective thread. Then, following [Potthast et al .2013], we extracted nouns, verbs and adjectives, sorted by TFIDF (we computed IDF on the Qatar Living dump). We further extracted and added the named entities from the text and we generated a query of 510 words. If we did not obtain ten results, we dropped some terms and we tried again. Manuscript submitted to ACM16 Atanasova et al. We automatically queried Bing and Google, and we extracted features from the resulting pages, considering Qatar related websites only. An example is shown in Table 10. Based on the results, we calculated similarities: ( i) cosine with TFIDF vectors, ( ii) cosine using Qatar Living embeddings, and ( iii) containment [Lyon et al .2001]. We calculated these similarities between, on the one side, ( i) the question or ( ii) the answer or ( iii) the question‚Äìanswer pair, vs. on the other side, ( i) the snippets or ( ii) the web pages. To calculate the similarity to a webpage, we first converted the page to a list of rolling sentence triplets, then we calculated the score of the Q/A/QA vs. this triplet, and finally we took the average and also the maximum similarity over these triplets. Now, as we had up to ten Web results, we further took the maximum and the average over all the above features over the returned Qatarrelated pages. We created three copies of each feature, depending on whether it came from a ( i) reputed source (e.g., news, government websites, official sites of companies, etc.), from a ( ii) forum type site (forums, reviews, social media), or ( iii) from some other type of websites. 3.3.4 Embeddings. (260 features ) Finally, we used as features the embeddings of the claim (i.e., the answer), of the bestscoring snippet, and of the bestscoring sentence triplet from a webpage. We calculated these embeddings using long shortterm memory (LSTM) representations, which we trained for the task as part of a deep neural network (NN). We also used a taskspecific embedding of the question and of the answer together with all the above evidence about it, which comes from the last hidden layer of the neural network. 3.4 Classification Model Our model combines an LSTMbased neural network with kernelbased support vector machines. In particular, we use a biLSTM recurrent neural network to train abstract feature representations of the examples. We then feed these representations into a kernelbased SVM, together with other features. The architecture is shown in Figure 3a. We have five LSTM subnetworks, one for each of the text sources from two search engines: Claim ,Google Web page ,Google snippet ,Bing Web page , and Bing snippet . We feed the claim (i.e., the answer) into the neural network asis. As we can have multiple snippets, we only use the bestmatching one as described above. Similarly, we only use a single bestmatching triple of consecutive sentences from a Web page. We further feed the neural network with the similarity features described above. All these vectors are concatenated and fully connected to a much more compact hidden layer that captures the taskspecific embeddings. This layer is connected to a softmax output unit that classifies the claim as true or false. Figure 3b shows the general architecture of each of the LSTM components. The input text is transformed into a sequence of word embeddings, which are then passed to the bidirectional LSTM layer to obtain a representation for the input text. Next, we extract the last three layers of the neural network ‚Äî( i) the concatenation layer, ( ii) the embedding layer, and ( iii) the classification node‚Äî and we feed them into an SVM with a radial basis function kernel (RBF). In this way, we use the neural network to train taskspecific embeddings of the input text fragments, and also of the entire input example. Ultimately, this yields a combination of deep learning and taskspecific embeddings with RBF kernels. 3.5 Experiments 3.5.1 Question Classification. Table 11 shows the results of our run for classification of the three question categories (Factual ,Opinion ,Socializing ), using an SVM with bagofwords and some other features. We can see a 10point absolute improvement over the baseline, which means the task is feasible. This also leaves plenty of space for further improvement, which is beyond the scope of this work. Instead, below we focus on the more interesting task of checking the factuality of Good answers to Factual questions. Manuscript submitted to ACMAutomatic FactChecking Using Context and Discourse Information 17 (a) General overview of the architecture. (b) Detailed LSTM representation. Fig. 3. Our NN architecture for factchecking in cQA. Each green box in 3a consists of the biLSTM structure in 3b. System Accuracy Baseline: All Opinion (majority class) 50.7 Our pilot: SVM, bagofwords 62.0 Our pilot: SVM, text features 60.3 Table 11. Baseline vs. our pilot SVM, predicting one of three classes of the questions (factual vs. opinion vs. just socializing). 3.5.2 Answer Classification. Setting and Evaluation. We perform leaveonethreadout cross validation, where each time we exclude and use for testing one of the 71 questions together with all its answers. This is done in order to respect the structure of the threads when splitting the data. We report Accuracy, Precision, Recall, and F 1for the classification setting. We used a bidirectional LSTM with 25 units and a hardsigmoid activation, which we trained using an RMSprop optimizer with 0.001 initial learning rate, L2 regularization with Œª=0.1, and 0.5 dropout after the LSTM layers. The size of the hidden layer was 60 with tanh activations. We used a batch of 32 and we trained for 400 epochs. Similarly to the biLSTM layers, we used an l2regularizer with Œª= 0.01 and dropout with a probability of 0.3. For the SVM, we used grid search to find the best parameters for the parameters cand Œ≥. We optimized the SVM for classification Accuracy. Manuscript submitted to ACM18 Atanasova et al. Our System Accuracy Precision Recall F 1 All information sources 0.683 0.693 0.688 0.690 All\discourse 0.659 0.675 0.648 0.661 All\context 0.574 0.583 0.602 0.592 All\discourse and context 0.542 0.554 0.563 0.558 Only context+discourse 0.635 0.621 0.742 0.676 Baseline All positive (majority class) 0.514 0.514 1.000 0.679 Table 12. Factchecking the answers in a cQA forum, focusing on the impact of the contextual and discourse features. (a) Clinton: They‚Äôre doing it to try to influence the election for Donald Trump .(b) Clinton: In the days after the first debate, you sent out a series of tweets from 3 a.m. to 5 a.m., including one that told people to check out a sex tape. Clinton: Is that the discipline of a good leader? Trump No, there wasn‚Äôt check out a sex tape. Fig. 4. Examples of the impact of context in debate instances. Results. Table 12 shows the results from our experiments for several feature combinations and for two baselines. First, we can see that our system with all features performs better than the baseline for Accuracy. The ablation study shows the importance of the context and of the discourse features. When we exclude the discourse and the contextual features, the accuracy drops from 0.683 to 0.659 and 0.574, respectively. When both the context and the discourse features are excluded, the accuracy drops even further, to 0.542. The F 1results are consistent with this trend. This is similar to the trend for checkworthiness estimation (cf. Table 4). Finally, using the discourse and the contextual features, without any other features, yields an accuracy of 0.635, which is quite competitive. Overall, these results show the importance of the contextual and of the discourse features for the factchecking task, with the former being more important than the latter. 4 DISCUSSION Here we look at some examples that illustrate how context and discourse help for our two tasks. 4.1 Impact of Context First, we give some examples where the use of contextual information yields the correct prediction for the check worthiness task (Section 2). In each of these examples, there is a particular contextual feature type that turned out to be critical for making the correct prediction, namely that these are checkworthy sentences (they were all misclassified as not checkworthy when excluding that feature type): Metadata  using opponent‚Äôs name. According to our explanation in Section 2.2, the target sentence in Figure 4(a) mentions the name of the opponent, and this turned out to be the critical feature for correctly predicting that these are checkworthy claims. Contradiction. Sometimes, an important claim contains a contradiction to what has been said earlier, e.g., the bold sentence in Figure 4(b). We model the contradiction as explained in Section 2.2 to extract such checkworthy claims. Similarity of the sentence to known positive/negative examples. The sentence ‚ÄúFor the last sevenandahalf years, we‚Äôve seen America‚Äôs place in the world weakened. ‚Äù is similar to the already factchecked sentence ‚ÄúWe‚Äôve weakened America‚Äôs place in the world. ‚Äù Thus, the latter is to be classified as checkworthy. Manuscript submitted to ACMAutomatic FactChecking Using Context and Discourse Information 19 (a)q:what is qtel customer service number? a1:Call 111 . . . and hold the line for at least 30 minutes before being answered. Enjoy Qtel music. a2: call 111 a3: 111  Customer service a4: 111(b)q: I have visiting visa for work; so can I drive? I have egyptian license a:If you are on a visiting Visa and and you have an international driver license you can use it for 6 month I guess. Evidence :[. . . ] A valid international driving license can be used from the day you arrive into the country until six months. [. . . ] (c)q: Smoke after dark during ramadan? a: Yes! You can smoke in public after sunset till dawn. Evidence :Bars and pubs will generally remain open but will only serve alcohol after dark. [. . . ] Don‚Äôt smoke, drink, chew gum or eat in public during the hours of sunrise to sunset.(d)q:I am in the process of coming over to work in Doha. I wanted to know if their were any specific shots and vaccinations I should get before coming over. I want to try and get these things completed before I leave the US. a:Yes there are; though it varies depending on which country you come from. In the UK; the doctor has a list of all countries and the vaccinations needed for each. I‚Äôll imagine they have the same in the US. Fig. 5. Examples of the impact of context and discourse in cQA instances. Following, there are some examples for the cQA factchecking task, where the use of particular contextual features allowed the system to predict correctly the factuality of the answers (they were all misclassified when the corresponding contextual feature was turned off): Support from the current thread. The example in Figure 5(a) shows how the thread information (e.g., similarity of one answer to the other answers in the thread) helps to predict the answer‚Äôs factuality. The question has four answers that should all be True , but they had been misclassified without the support from the current thread. Support from highquality posts in Qatar Living. The example in Figure 5(b) was correctly classified as True when using the highquality posts, and misclassified as False otherwise. The highquality posts in the QL forum contain verified information about common topics discussed by people living in Qatar such as visas, driving regulations, customs, etc. The example shows one piece of relevant evidence selected by our method from the highquality posts, which possibly helps in making the right classification. Support from all of Qatar Living .The example in Figure 5(c) shows the evidence found in the search results in the entire Qatar Living forum. It was classified correctly as True when using the support from all of the Qatar Living forum, and it was misclassified without it. 4.2 Impact of Discourse As the evaluation results have shown, discourse also played an important role. Let us take the checkworthiness task as an example. In the sentence ‚ÄúBut what President Clinton did, he was impeached, he lost his license to practice law.‚Äù , the discourse parser identified the fragment ‚Äú But what President Clinton did ‚Äù asBackground referring to the text for facilitating understanding; the segment ‚Äú he was impeached ‚Äù isElaboration referring to additional information and ‚Äú. . .to practice law ‚Äù isEnablement referring to the action. These relations are associated with factuallytrue claims. Similarly, for cQA factchecking using discourse information yielded correct classification as True for the example in Figure 5(d). The question and the answer were parsed together and the segment containing the answer was identified asElaboration . The answer further contains a Background segment (‚Äú In the UK; the doctor has a list of all countries and the vaccinations needed for each. ‚Äù) and an Attribution segment (‚Äú they have the same in the US ‚Äù). These discourse relations are also associated with factuallytrue answers (as we have seen also in the Figure 5(c)). Manuscript submitted to ACM20 Atanasova et al. 5 RELATED WORK "
227,Geometric Image Correspondence Verification by Dense Pixel Matching.txt,"This paper addresses the problem of determining dense pixel correspondences
between two images and its application to geometric correspondence verification
in image retrieval. The main contribution is a geometric correspondence
verification approach for re-ranking a shortlist of retrieved database images
based on their dense pair-wise matching with the query image at a pixel level.
We determine a set of cyclically consistent dense pixel matches between the
pair of images and evaluate local similarity of matched pixels using neural
network based image descriptors. Final re-ranking is based on a novel
similarity function, which fuses the local similarity metric with a global
similarity metric and a geometric consistency measure computed for the matched
pixels. For dense matching our approach utilizes a modified version of a
recently proposed dense geometric correspondence network (DGC-Net), which we
also improve by optimizing the architecture. The proposed model and similarity
metric compare favourably to the state-of-the-art image retrieval methods. In
addition, we apply our method to the problem of long-term visual localization
demonstrating promising results and generalization across datasets.","Image retrieval is a well studied problem in the Ô¨Åeld of computer vision and robotics with applications in place recognition [5, 13, 37], localization [21, 37, 42], au tonomous driving [25], and virtual reality [28] among many others. Given a query image, the image retrieval pipeline re turns a ranked list of database images according to its mea sure of relevance to the query image. As raw pixels are not a good representation, extensive research has gone into Ô¨Ånding discriminative and efÔ¨Åcient image representations. The seminal work of Sivic and Zisserman [40] proposed BagofWords based image representation using SIFT [22]. Later, more advanced and efÔ¨Åcient representations were proposed in the form of VLAD [18] descriptors and Fisher Equal contribution: firstname.lastname@aalto.fi Figure 1: Qualitative results of the proposed method for the task of image retrieval. The Ô¨Årst row is a query taken at nighttime with a mobile phone camera and the last row is a list of top4 retrieved database images obtained by our method. All 4 are correct matches. vectors [32]. More recently, offtheshelf [3, 19, 20] and Ô¨Ånetuned [1, 12, 29] convolutional neural network (CNN) representations have demonstrated great success in image retrieval. The models encode an input image to a global vector representation which leads to efÔ¨Åcient retrieval al lowing to use just a dot product as a similarity measure to obtain relevant database images. Once Ô¨Ånetuned on auxil iary datasets with similar distribution as the target one, those methods have achieved stateoftheart image retrieval per formance [1, 12, 29]. However, the main limitation of such Ô¨Ånetuned CNN representations are their generalization ca pabilities which is crucial in the context of cityscale lo calization where the database images can be quite similar in structure and appearance. Moreover, variations in illu mination ( e.g. night time queries) or occlusion can signiÔ¨Å cantly affect the encoded global representations degrading retrieval performance due to lack of spatial information. In this paper we leverage the advances of spatial geomarXiv:1904.06882v3  [cs.CV]  17 Aug 2020etry to obtain better ranking of the database images. To this end, we revisit the geometric veriÔ¨Åcation problem in the context of image retrieval. That is, given an initial ranked list,Lof database images returned by a CNN model ( e.g. NetVLAD), we seek to rerank a shortlist L02Lof im ages by using dense pixel correspondences [27] which are veriÔ¨Åed by the proposed similarity functions. Previously, DGCNet [27] has been successfully applied only to posi tive image pairs i.e. pairs with overlapping Ô¨Åeld of view. In this work we extend its applicability to verify positive and negative image pairs in the framework of geometric veriÔ¨Å cation. That is, we demonstrate how dense pixel correspon dence methods such as DGCNet can be used to improve image retrieval by geometric veriÔ¨Åcation. In summary, the contributions of this work are threefold. First, we improve the baseline DGCNet by constraining the matching layer to be locally and globally consistent. Sec ond, we replace multiple decoders of the original DGCNet architecture by the proposed universal decoder, which can be shared for feature maps in different layers of the feature pyramid of DGCNet. Third, we formulate two similarity functions, which Ô¨Årst rank the shortlisted database images based on structural similarity and then rerank them using appearance based similarity. 2. Related work "
254,TinySiamese Network for Biometric Analysis.txt,"Biometric recognition is the process of verifying or classifying human
characteristics in images or videos. It is a complex task that requires machine
learning algorithms, including convolutional neural networks (CNNs) and Siamese
networks. Besides, there are several limitations to consider when using these
algorithms for image verification and classification tasks. In fact, training
may be computationally intensive, requiring specialized hardware and
significant computational resources to train and deploy. Moreover, it
necessitates a large amount of labeled data, which can be time-consuming and
costly to obtain. The main advantage of the proposed TinySiamese compared to
the standard Siamese is that it does not require the whole CNN for training. In
fact, using a pre-trained CNN as a feature extractor and the TinySiamese to
learn the extracted features gave almost the same performance and efficiency as
the standard Siamese for biometric verification. In this way, the TinySiamese
solves the problems of memory and computational time with a small number of
layers which did not exceed 7. It can be run under low-power machines which
possess a normal GPU and cannot allocate a large RAM space. Using TinySiamese
with only 8 GO of memory, the matching time decreased by 76.78% on the B2F
(Biometric images of Fingerprints and Faces), FVC2000, FVC2002 and FVC2004
while the training time for 10 epochs went down by approximately 93.14% on the
B2F, FVC2002, THDD-part1 and CASIA-B datasets. The accuracy of the fingerprint,
gait (NM-angle 180 degree) and face verification tasks was better than the
accuracy of a standard Siamese by 0.87%, 20.24% and 3.85% respectively.
TinySiamese achieved comparable accuracy with related works for the fingerprint
and gait classification tasks.","Deep learning has been successfully used to achieve good performances in a variety of applications such as recognition applications including im age, activity and voice recognition. However, most of these algorithms often perform well when the predictions are made using a bit of information or data. In fact, in the modern deep learning tasks, neural networks are almost effective, but these networks require training on a huge number of samples. Nevertheless, a large number of samples is not available in some problems. For certain tasks including fingerprint or signature verification, data is not abundantly available. The lack of data can be solved using such procedures as data augmentation which has drawbacks, among which changing the right direction of learning or falling into too much data. As a result, systems that incorporate these procedures tend to excel in similar cases, but sometimes fail to offer robust solutions. A particularly interesting task when there are a few examples for training from scratch of each class before making a prediction is verification. This is called oneshot learning [1], which attempts to solve such problems and construct a trained model using a small number of samples. Oneshot algo rithms can use few training samples for each class and generalize a model for unfamiliar categories without the need for extensive retraining. Therefore, the objective is to achieve new samples for each epoch and get high recogni tion accuracy with limited data. For oneshot learning, approaches such as deep Siamese networks [2] were proposed in several works [3, 4, 5]. Deep Siamese networks solve this type of tasks using only few images to get better predictions. The capacity to learn from little data has made Siamese networks popular in recent years. These networks are composed of two twin networks for image similarity computa tion. In fact, the Siamese network integrates CNN neural networks such as 2ResNet, VGG and MobileNet. It tries to learn the similarity between given images using distance measures. Despite the effectiveness of the Siamese Networks, they possess some weak nesses. Since they require pairs to learn, these networks need more training memory and time than normal CNN networks. In fact, they are slower than the normal learning types. In addition, the Siamese networks always require a lot of running time for the prediction. This work aims to address these highlevel problems without requiring expensive learning which may be impossible due to limited data, lowpower machines or the demand for fast prediction in terms of execution time. The present work work relies on the deep learning framework, which uses a small number of layers with relevant features to avoid learning failure. The proposed model is able to learn from little data although the cost of the learning algorithm in terms of execution time, running memory, and number of layers cannot be high. In fact, this paper introduces the TinySiamese network which has a small number of layers and allows a small model to successfully learn from few examples with a short learning time. TinySiamese is very useful under lowpower machines with a normal GPU which cannot allocate a large RAM space. The most important contributions of our work are the following: ‚Ä¢Proposing the TinySiamese for verification using a few number of layers and without the need for a huge dataset for training. ‚Ä¢Proving that the proposed TinySiamese could get a competitive per formance with the standard Siamese Network. In the experiments, the efficiency of TinySiamese was demonstrated for verification and classi fication with the shorted matching and training time. ‚Ä¢Showing through experimental studies that TinySiamese achieved a competitive performance with related works for classification. Here is how the remaining part of the paper is organized: related works are presented in section 2. However, the used Siamese and the proposed TinySiamese are described in Section 3 and Section 4 respectively. Section 5 is devoted to the presentation of used datasets, whereas Section 6 focuses on the experimental study. Section 7 covers the discussion. The conclusion of this paper is drawn in Section 8. 32. Related Works "
394,Probabilistic Conformance for Cyber-Physical Systems.txt,"In system analysis, conformance indicates that two systems simultaneously
satisfy the same set of specifications of interest; thus, the results from
analyzing one system automatically transfer to the other, or one system can
safely replace the other in practice. In this work, we study the probabilistic
conformance of cyber-physical systems (CPS). We propose a notion of
(approximate) probabilistic conformance for sets of complex specifications
expressed by the Signal Temporal Logic (STL). Based on a novel statistical
test, we develop the first statistical verification methods for the
probabilistic conformance of a wide class of CPS. Using this method, we verify
the conformance of the startup time of the widely-used full and simplified
model of Toyota powertrain systems, the settling time of
model-predictive-control-based and neural-network-based automotive lane-keeping
controllers, as well as the maximal voltage deviation of full and simplified
power grid systems.","Conformance is an important concept in the analysis of cyber physical systems (CPS) [ 13,18,21,23,32,34]. It indicates that two systems satisfy the same set of given specifications (e.g., reacha bility or inputoutput relation). Thus the analysis results for one system can transfer to the other system, or one system can safely replace the other in practice. The term ‚Äúconformance‚Äù may also refer to the consistency between a system and a design specification (e.g., [14, 22]); this is out of the scope of this work. For CPS, complex specifications for their dynamics are mathemat ically expressible by temporal logics, such as the Signal Temporal Logic (STL) [ 24]. Following the line of work [ 1,9], we focus on the conformance of CPS for temporal logics specifications. This Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for thirdparty components of this work must be honored. For all other uses, contact the owner/author(s). ICCPS ‚Äô21, May 19‚Äì21, 2021, Nashville, TN, USA ¬©2021 Copyright held by the owner/author(s). ACM ISBN 9781450383530/21/05. https://doi.org/10.1145/3450267.3450534notion of conformance generalizes the conformance for reachabil ity [21, 32], since reachability is expressible by temporal logic. Conformance can be used for two different models derived from the same system under two conditions, implying that the system executes in the same way under the conditions (e.g., two inputs). A wellknown example of nonconformity is the Volkswagen emissions scandal [ 4], where the emission control software deliberately per forms differently in the lab testing and driving conditions to bypass the emission test without actually reducing the pollution generated from the cars while driving. Similar undesirable nonconformity exists in printers [ 5], where the software drivers deliberately work differently in favor of certain cartridge brands. To prevent such soft ware doping [31], one needs to verify the conformance of a system under different conditions/settings. The conformance also applies to two models derived from two systems operating under the same conditions, implying that they are interchangeable for the application. For instance, there has been recently significant interest in replacing precise but computation ally expensive controllers based on model predictive control (MPC) with ones based on neural network (NN) for applications such as lanekeeping systems in autonomous vehicles [ 29]. To migrate from an MPC controller to an NN controller without significantly chang ing the responsiveness, we need to check the conformance of the closedloop system under the two controllers for their settling time, especially considering the fragility of AIbased controllers. While we focus on the conformance of two different systems operating under the same conditions in our case studies, our approach also applies to a system‚Äôs conformance under two conditions. Since CPS, such as autonomous vehicles, are frequently subject to randomness (e.g., system/network/environment noise), we propose aprobabilistic notion of conformance for these systems. We use the definition of probabilistic uncertain systems (PUSs) from [ 40] to capture CPS dynamics. Roughly speaking, they are greybox probabilistic dynamical systems with unknown dynamics in known state space. The PUSs capture the system nondeterminism as the input and probabilism as the parameters. The input and parameters can be time functions of general types, including real, integer, or categorical/Boolean. Given the input and parameters‚Äô value, a time dependent sample path of general types can be generated. The PUSs subsume commonly used dynamical models such as continuous time Markov chains and hybrid I/O automata [ 15] with probabilistic parameters (used to capture the Toyota Powertrain [33]). We define the notion of conformance through a parameterized signal temporal logic (STL) formula [ 3] as illustrated in Figure 1.arXiv:2008.01135v2  [eess.SY]  2 Mar 2021ICCPS ‚Äô21, May 19‚Äì21, 2021, Nashville, TN, USA Yu Wang, Mojtaba Zarei, Borzoo Bonakdarpoor, and Miroslav Pajic Figure 1: Overview of our statistical conformance test. Specifically, we require that the satisfaction probabilities are approx imately equal for all values of the STL parameters. For example, for the probabilistic conformance of two models M1andM2of reach ing the same setD, one can consider the parameterized formula 3[0,ùë°]Dand require that for a given ùëê>0, it holds that ‚àÄùë°‚àà[0,‚àû).Prùúé1‚àºM 1(ùúé1|=3[0,ùë°]D) ‚àíPrùúé2‚àºM 2(ùúé2|=3[0,ùë°]D)<ùëê; here,ùúé1andùúé2are two random signals from the models M1and M2, respectively, as illustrated in Figure 2. This implies that both systemsM1andM2reachDwith approximately equal probability for any time horizon. Our notion of conformance only requires these probabilities to be approximately equal instead of exactly equal, since the former is usually sufficient in practice (more examples are provided in Section 6). Since the PUSs may have complex or even unknown dynam ics, we adopt a statistical verification approach, as it scales better than modelbased verification approaches and can handle unknown dynamics [ 2,19]. From the conformance definition, we need to simultaneously handle the approximately equal satisfaction prob ability of infinitely many STL specifications since the parameters of the parameterized STL formula can take infinitely many values; this is very challenging since existing statistical verification meth ods can only handle a single (nonparametrized) temporal logic formula [2, 20] or a hyper temporal logic formula [38, 40]. We show that statistically verifying conformance is feasible when the STL formula is monotonically parameterized, i.e., the formula‚Äôs satisfaction probability changes monotonically with the parameters. Such a property holds for many cases as discussed in detail in Section 3 and the case studies in Section 6. To the best of our knowledge, this work is the first to enable statistical verification for infinitely many formulas. Due to monotonicity, the satisfaction probabilities over the val ues of its parameters on the two PUSs form two probability distri butions. Accordingly, the conformance of two PUSs requires the two distributions to be approximately equal. To this end, we de velop a new statistical test to check the approximate equality of two distributions with provable confidence levels. Our test is based on the classic KolmogorovSmirnov (KS) test [ 10] and its multivariate generalization [ 30] for checking the exact equality of two distribu tions. Based on this, we develop a statistical verification method for the probabilistic (non)conformance of two PUSs for any desired confidence level (lower than 1). We apply the proposed statistical verification method to check the probabilistic conformance for three case studies to show itsùë°Prùúé1‚àºM 1(ùúé1|=3[0,ùë°]D) Prùúé2‚àºM 2(ùúé2|=3[0,ùë°]D)1 Figure 2: Reachability probabilities for some set Dv.s. time horizonùë°. The two models conform (for reachability) if the black line stays within the blue tube. applicability. First, we study the probabilistic conformance of the widely used full and simplified models of the Toyota powertrain system [ 16,33] for the startup time for their air to fuel ratio to reach a working region. Our results show the nonconformity of the two models, suggesting the simplified model may not capture certain important aspects of the system. Second, we check the probabilistic conformance of the settling time of an MPCbased lane keeping controller and several NNbased lanekeeping controllers of different sizes for an autonomous car [ 26]. We show that NN based controllers conform to the MPCbased controller, as their size increases; however, a small NN design may result in nonconformity. It suggests that an MPCbased controller can be replaced with a sufficientlylarge NNbased controller to satisfyingly control the settling time. Finally, we check the probabilistic conformance of the maximal deviation of DC voltage between the full model and a simplified model of a power grid system [ 27]. Our results show that the two models do not probabilistically conform ‚Äì i.e., the simplified model again may not capture certain important aspects of the system. This paper is organized as follows. After preliminaries in Sec tion 2, in Section 3 we formalize the problem and our definition of probabilistic conformance for a parameterized STL formula. We present a new statistical test in Section 4 and the verification method for the probabilistic conformance in Section 5. In Section 6, we ap ply our method to three realworld casestudies, before discussing related work in Section 7, and concluding in Section 8. Notation. We denote the sets of natural, real, and nonnegative real numbers by N,R, andR‚â•0, respectively. We define R‚àû= R‚à™{‚àí‚àû,‚àû}, and[ùëõ]={1,...,ùëõ}, forùëõ‚ààN. The cardinality and the power set of a set ùëÜare denoted by|ùëÜ|and2ùëÜ. 2 PROBLEM FORMULATION We use a general system model for CPS called probabilistic uncertain systems (PUSs) [ 40]. They capture continuoustime probabilistic dynamics on a hybrid statespace of discrete and continuous val ues, as well as generalize common probabilistic models such as continuoustime Markov chains (CTMC) and probabilistic hybrid I/O automata [ 40]. Since we adopt a statistical approach, we mainly view a PUS as a greybox that generates random samples (Figure 3). Definition 1. A probabilistic uncertain system (PUS) is a tuple M=(X,ùëãinit,I,D,{ùê∑(ùë°)}ùë°‚ààR‚â•0,T), where ‚Ä¢X=X1√ó...√óXùëõis the state space with eachXùëñbeing either Ror a discrete set[ùëõXùëñ];Probabilistic Conformance for CyberPhysical Systems ICCPS ‚Äô21, May 19‚Äì21, 2021, Nashville, TN, USA Xùëã(ùë°) ùë°‚ààR‚â•0XPUSM Input ùêº(ùë°)‚ààI Figure 3: Probabilistic Uncertain System (PUS). ‚Ä¢ùëãinit‚ààX is the initial state ; ‚Ä¢I=I1√ó...√óIùëöis the range of inputs with eachIùëñbeing eitherRor a discrete set[ùëõIùëñ]; ‚Ä¢D=D1√ó...√óDùëôis the range of parameters with eachDùëñ being either Ror a discrete set[ùëõDùëñ]; ‚Ä¢{ùê∑(ùë°)}ùë°‚ààR‚â•0is a random process on D(for a properly de fined probability space), defining the random change of the parameter over time; ‚Ä¢T :(R‚â•0‚ÜíI)√ó( R‚â•0‚ÜíD)‚Üí( R‚â•0‚ÜíX) defines thetransition of the system ‚Äì i.e., given the (timedependent) value of the input and parameter, the system deterministically generates a path. Given the value of the (timedependent) inputùêº:R‚â•0‚ÜíI , the PUS can generate a random signalùúé(ùë°)=T(ùêº(ùë°),ùê∑(ùë°)), where the randomness comes from the parameter ùê∑(ùë°). We denote by ùúé‚àºMùêº when the signal ùúéis randomly generated from the system Mfor the given input ùêº. We also write ùúé‚àºM ifùêºis clear from the context. There is no assumption on the dynamics of a PUS, such as Markovian, causal, etc. Common probabilistic models such as the discretetime or continuoustime Markov chains [ 36], and proba bilistic hybrid I/O automata [ 35,42] are subsumed by the notion of PUS (see [40] for details). Example 1. A simple example of PUS is a bouncing ball with random gravitational acceleration, as shown in Figure 4. Its state is the height and velocity (ùë•,ùë£). Forùë•>0, the state evolves by ¬§ùë•=ùë£,¬§ùë£=ùëî; forùë•=0, it jumps by ùë•‚Ü¶‚Üíùë•,ùë£‚Ü¶‚Üí‚àíùë£. The parameter ùëî is randomly drawn from a normal distribution ùëÅ(ùëî0,ùúé2)for some ùëî0,ùúé>0. The initial state is (ùë•0,0). The input set is empty. Finally, note that although by Definition 1, a PUS has a unique initial state, it allows for defining conformance of paths from dif ferent initial states ùëã1andùëã2of the PUS. This is done by adding a new initial state ùëã0to the PUS, and model the transition from ùëã0 toùëã1andùëã2as part of the input. Signal Temporal Logic. We use the signal temporal logic (STL) [ 24] to capture the temporal specifications of interest for the random signals of the PUS. STL can be viewed as the counterpart of lin ear temporal logic (LTL) in the realtime domain with realvalued constraints. An STL formula is defined inductively by the syntax ùúëFùëì>0|¬¨ùúë|ùúë‚àßùúë|ùúëU[ùë°1,ùë°2]ùúë, (1) whereùëì:Rùëõ‚ÜíRis a given function. To simplify further discus sion, we let ùë°1,ùë°2‚ààR‚àû, instead of taking values in nonnegative rational numbers. We call ùëì>0anatomic proposition andU[ùë°1,ùë°2] the ‚Äúuntil‚Äù operator. Other temporal and logic operators are defined as usual; for example, Figure 4: Stochastic bouncing ball. ‚Ä¢(false/true) F=ùúë‚àß(¬¨ùúë)andT=¬¨F, ‚Ä¢(finally) 3[ùë°1,ùë°2]ùúë=TU[ùë°1,ùë°2]ùúë, and ‚Ä¢(always) 2[ùë°1,ùë°2]ùúë=¬¨(3[ùë°1,ùë°2]¬¨ùúë). For a concrete signalùúé:R‚â•0‚ÜíRùëõof the PUS, the satisfaction relation for STL formulas is defined recursively by the semantics ùúé|=ùëì>0 iffùëì(ùúé(0))>0 ùúé|=¬¨ùúë iffùúéÃ∏|=ùúë ùúé|=ùúë1‚àßùúë2 iffùúé|=ùúë1andùúé|=ùúë2 ùúé|=ùúë1U[ùë°1,ùë°2]ùúë2iff there exists ùë°‚àà[ùë°1,ùë°2]such that ùúé(ùë°)|=ùúë2and for any 0‚â§ùë°‚Ä≤<ùë°, it holds that ùúé(ùë°‚Ä≤)|=ùúë1; here,ùúé(ùë°)denotes the ùë°shift of the signal, defined by ùúé(ùë°)(ùë°‚Ä≤)= ùúé(ùë°+ùë°‚Ä≤)for anyùë°‚Ä≤‚ààR‚â•0. We make the convention that a formula ùúë1U[ùë°1,ùë°2]ùúë2is equiv alent to F, ifùë°2<ùë°1,ùë°1<0, orùë°2<0. Example 2. The following STL formula requires that if |ùë•|>0.5, then within 0.6time units|ùë•|settles under the value 0.5for the 1.5long time interval ùúë=2 |ùë•|>0.5‚áí3[0,.6](2[0,1.5]|ùë•|<0.5) . 3 PROBABILISTIC CONFORMANCE We focus on a class of conformance properties for CPS for an (in finite) set of STL formulas . Mathematically, we say that two PUSs probabilistically conform if for any STL formula from the set, the satisfaction probabilities are approximately equal for two random signals drawn respectively from the two PUSs. This can be viewed as a probabilistic generalization of [1, 9]. Definition 2 (Conformance). LetŒ¶be an infinite set of STL formulas. For two PUSs M1andM2, and a given ùëê>0, we say that M1andM2ùëêapproximately probabilistically conform for Œ¶(for the same given input), if for any STL formula ùúô‚ààŒ¶, it holds that Prùúé1‚àºM 1(ùúé1|=ùúô)‚àíPrùúé2‚àºM 2(ùúé2|=ùúô)<ùëê, whereùúéùëñ‚àºMùëñis a random path from the PUS Mùëñ, forùëñ‚àà{1,2}. In Definition 2, we only require the satisfaction probabilities to beapproximately equal for the STL formulas of interest instead of exactly equal; the latter is usually unnecessary in applications (see e.g. the case studies presented in Section 6). Besides, the confor mance from Definition 2 cannot be expressed by single formulas in any common temporal logic since a parameterized formula effec tively captures an infinite number of STL formulas. For any fixed values of the employed parameters, the property can be expressed in HyperPSTL [40].ICCPS ‚Äô21, May 19‚Äì21, 2021, Nashville, TN, USA Yu Wang, Mojtaba Zarei, Borzoo Bonakdarpoor, and Miroslav Pajic Depending on the choice of the class (i.e., set) of temporal proper tiesŒ¶, different notions for the conformance of PUS are derived, in cluding probabilistic reachset conformance and probabilistic trace conformance. Commonly, an STL formula set Œ¶can be derived by parametrizing a single STL formula ùúôby [3] Œ¶={ùúôùëë:ùëë‚ààRùêæ}. (2) Effectively, ùúôùëërepresents infinitely many STL formulas, as the parameterùëëcan take infinitely many values. For example, the STL formula set Œ¶1={3[0,1](ùúé>ùëé):ùëé‚ààR} (3) is derived by parametrizing the threshold ùëé. It contains an infinite set of reachability specifications for the parametrized threshold ùëé within the fixed timeinterval [0,1]. The conformance of the two PUSsM1andM2for the set Œ¶1means that, for any threshold ùëé the probability of reaching the threshold should be approximately equal for two random signals respectively from M1andM2. Similarly, the STL formula set Œ¶2={3[0,ùë°](ùúé>0):ùë°‚ààR} (4) is derived by parametrizing the time horizon ùë°. It contains an infinite set of reachability specifications for the fixed threshold 0, within a parameterized time interval [0,ùë°]. The conformance of the two PUSsM1andM2for the set Œ¶2means that the probability of reaching the threshold 0 (i.e., >0) within any time interval [0,ùë°] should be approximately equal for two random signals respectively fromM1andM2. Considering that the PUSs can have complex dynamics that may be even unknown in practice, in this work we propose to statis tically verify the conformance of PUSs from Definition 2; such method exhibits better scalability than the exhaustive approaches and can handle unknown dynamics [ 2,19]. There are infinitely many STL formulas of interest in (2), so the proposed statistical verification method should be able to handle an infinite set of STL specifications. This is very challenging since all existing statistical verification techniques can only handle single STL specifications [2,20]. To solve this, we focus on the conformance for monoton ically parameterized STL formulas, which are commonly used in system analysis [3]. Generally, the parametrized formula ùúôùëë(whereùëëcaptures the vector of parameters) is monotone if the satisfaction probability on a model is preserved for the order of the parameters ‚Äì i.e., the satisfaction probability changes monotonically with the parame ter. While statistically verifying the probabilistic conformance for an arbitrary STL formula set is very difficult, handling a mono tonically parameterized formula set can be done by exploiting the formula‚Äôs monotonicity. Definition 3 (Monotonically Parameterized Formula). A parameterized formula ùúôùëëwithùëë‚ààRùêæismonotone for a PUSMif for any given path ùúéfromMandùëñ‚àà[ùêæ], and ‚Ä¢for anyùëë,ùëë‚Ä≤such thatùëë‚™Øùëñùëë‚Ä≤, it holds that ùúé|=ùúôùëëimplies ùúé|=ùúôùëë‚Ä≤, OR ‚Ä¢for anyùëë,ùëë‚Ä≤such thatùëë‚™Øùëñùëë‚Ä≤, it holds that ùúé|=ùúôùëë‚Ä≤implies ùúé|=ùúôùëë;here,ùëë‚™Øùëñùëë‚Ä≤denotes that the entries of ùëëandùëë‚Ä≤are equal except for ùëëùëñ‚â§ùëë‚Ä≤ ùëñ. Following Definition 3, the parameter alternation preserves the parametrized STL formula‚Äôs monotonicity. Definition 4 (Alternation). The function ùúã(ùëë)=ùëë‚Ä≤is called an alternation, if for all ùëñ‚àà[ùêæ],ùëë‚Ä≤ ùëñ=ùëëùëñorùëë‚Ä≤ ùëñ=‚àíùëëùëñ. The set of all ùêædimensional alternations in Rùêæis denoted by Œ†ùêæ. From the previous definitions, the following directly holds. Lemma 1. Ifùúôùëëis a monotonically parameterized STL formula, then so isùúôùúã(ùëë), whereùúãis an alternation.1 4 STATISTICAL TEST FOR APPROXIMATE EQUALITY OF DISTRIBUTIONS Before introducing a statistical verification algorithm for probabilis tic conformance, we propose a new statistical test for the equiv alence of two (unknown) probability distributions, based on the classic KolmogorovSmirnov test [ 10,30]. We start from the scalar case and then extend to the multidimensional case. Consider two ùêædimensional random vectors ùëã=(ùëã1,...,ùëãùêæ) andùëå=(ùëå1,...,ùëåùêæ). For eachùêædimensional alternation ùúã‚ààŒ†ùêæ, we define ùêπùúã(ùëé)=Prùëã"
131,Fast Falsification of Neural Networks using Property Directed Testing.txt,"Neural networks are now extensively used in perception, prediction and
control of autonomous systems. Their deployment in safety-critical systems
brings forth the need for verification techniques for such networks. As an
alternative to exhaustive and costly verification algorithms, lightweight
falsification algorithms have been heavily used to search for an input to the
system that produces an unsafe output, i.e., a counterexample to the safety of
the system. In this work, we propose a falsification algorithm for neural
networks that directs the search for a counterexample, guided by a safety
property specification. Our algorithm uses a derivative-free sampling-based
optimization method. We evaluate our algorithm on 45 trained neural network
benchmarks of the ACAS Xu system against 10 safety properties. We show that our
falsification procedure detects all the unsafe instances that other
verification tools also report as unsafe. Moreover, in terms of performance,
our falsification procedure identifies most of the unsafe instances faster, in
comparison to the state-of-the-art verification tools for feed-forward neural
networks such as NNENUM and Neurify and in many instances, by orders of
magnitude.","From simple daytoday tools like text prediction in emails and messages, to sophisticated autopilot systems in modern planes, almost every aspect of our life today involves systems that learn automatically from data for synthesizing optimal control policies. Indeed, recent advances in Machine Learning (ML) and in particu lar, in the areas of Reinforcement Learning (RL) and Deep Neural Networks (DNN), has made it possible to achieve exceptional sophis tication and performance in a wide variety of domains including chip design, image classification, software product lines, resource allocation, scheduling, and controller synthesis. In recent times, both the software and hardware design industry are seriously con sidering the possibility of including neural components inside their design artifacts, even inside critical system software and hardware, replacing their ageold handcoded counterparts. However, in spite of phenomenal research advances and hardware sophistication, these components still pose a plethora of risks towards widespreaddeployment. These range from privacy concerns, algorithmic bias and black box decision making, to broader questions of hardware alignment, selfimprovement, and risk from unexplainable intelli gence. Correctness of these systems is thus of paramount concern and needs to be rigorously verified. Given the scale and complexity of today‚Äôs system designs and applications, guaranteeing satisfac tion of safety objectives for ML designs under all possible input scenarios is a difficult challenge, due to factors such as nonlinearity and nonconvexity of the model, high dimensional input spaces, realvalued weights etc. As a result, the problem of ML safety veri fication has been at the forefront of verification research in recent times [2][6][8][9][10][11][14][15][22][25][24][27][29][32]. In this paper, we address the verification problem of feedforward neural networks with general activation functions. In particular, given a feedforward neural network and a property, we propose an efficient falsification algorithm that attempts to search for an input to the network that violates the property and thereby proving the network to be unsafe. Our algorithm uses a derivative free sampling based optimization method to direct the search for a falsifying input based on the safety property. We refer to a property refuting input as acounterexample . This kind of a procedure is an archetype of thefalsification method of testing a system, which has been heavily used in system verification as an alternative to exhaustive and costly verification algorithms that rather attempt to prove the safety of the system at hand [ 17][26]. Naive falsification techniques such as random testing [ 23][20] do not generally learn and infer knowledge from the earlier failed test trials on the system. As a result, a large part of the inputspace may have to be explored to find a coun terexample. In contrast, falsification procedures for software and hardware that are either property directed [ 4,18] or that explore the inputspace systematically have been shown to be considerably effective and efficient in comparison to random testing [ 12]. In this work, we propose a falsification algorithm for neural networks that not only learns from the failed test executions of the neural network but also efficiently directs the search for a counterexample towards the inputspace of interest based on the property at hand. The core of our falsification procedure is a derivativefree samplingbased optimization method [ 33] that we tailor to our needs. Since our procedure is samplingbased, it is applicable to neural networks with any type of activation function. Our proposed falsification algorithm is sound but not complete. When a falsifying input hasarXiv:2104.12418v1  [cs.AI]  26 Apr 2021Conference‚Äô17, July 2017, Washington, DC, USA Moumita Das, Rajarshi Ray, Swarup Kumar Mohalik, and Ansuman Banerjee been found by our algorithm, it terminates by declaring the net work as unsafe and the reported counterexample indeed violates the safety property of the network. However, when it terminates before finding any falsifying input, one cannot guarantee the ab sence of any falsifying input and consequently, the safety of the network with respect to the property. We evaluate our algorithm on 45 trained neural network bench marks of the ACAS Xu system against 10 safety properties. Em pirically, we show that our falsification procedure detects all the unsafe instances that other verification tools also report as unsafe. In terms of performance, our falsification procedure identifies the unsafe instances orders of magnitude faster in comparison to the stateoftheart verification tools for neural networks. Therefore, we believe that our falsification algorithm can complement the pro cess of neural network verification by rapidly detecting the unsafe instances and henceforth directing the effort of verification on the rest of the instances with sound and complete algorithms. As a result, the overall time to verify a set of instances can be drastically reduced by adopting our method. The rest of the paper is organized as follows. Section 2 presents some related work on neural network verification. Section 3 presents the problem definition for this work. The detailed method and algo rithms of this work are explained in Section 4. Section 5 discusses the performance comparison of our method with other existing tools, while Section 6 concludes this work. 2 RELATED WORK "
522,Program Enhanced Fact Verification with Verbalization and Graph Attention Network.txt,"Performing fact verification based on structured data is important for many
real-life applications and is a challenging research problem, particularly when
it involves both symbolic operations and informal inference based on language
understanding. In this paper, we present a Program-enhanced Verbalization and
Graph Attention Network (ProgVGAT) to integrate programs and execution into
textual inference models. Specifically, a verbalization with program execution
model is proposed to accumulate evidences that are embedded in operations over
the tables. Built on that, we construct the graph attention verification
networks, which are designed to fuse different sources of evidences from
verbalized program execution, program structures, and the original statements
and tables, to make the final verification decision. To support the above
framework, we propose a program selection module optimized with a new training
strategy based on margin loss, to produce more accurate programs, which is
shown to be effective in enhancing the final verification results. Experimental
results show that the proposed framework achieves the new state-of-the-art
performance, a 74.4% accuracy, on the benchmark dataset TABFACT.","With the overwhelming information available on the Internet, fact veriÔ¨Åcation has become crucial for many applications such as detecting fake news, ru mors, and political deception (Rashkin et al., 2017; Thorne et al., 2018; Goodrich et al., 2019; Vaibhav et al., 2019; Kry ¬¥sci¬¥nski et al., 2019), among others. Existing research has mainly focused on collecting *Equal contribution to this work. The work was done during the second author‚Äôs visiting to Queen‚Äôs University. YearTournaments PlayedAvg.ScoreScoring Rank20072272.468120082971.652220092571.903420101873.429220111174.42125Table with title ‚ÄòJiyoung Oh‚Äô  Statement LabelProgramJiyoung Oh played more tournament in 2008 than any other year.ENTAILEDeq { max { all_rows ; tournaments played }  ; hop { filter_eq { all_rows ; year ; 2008 }  ; tournaments played }  }   = TrueFigure 1: An example of fact veriÔ¨Åcation over tables. and processing evidences from unstructured text data (Liu et al., 2020; Nie et al., 2019; Hanselowski et al., 2018; Yoneda et al., 2018), which is only one type of data where important facts exist. Structured and semistructured data, e.g., tables in relational databases or in the HTML format is also ubiquitous. Performing fact validation based on structured data is important yet challenging and further study is highly desirable. Fig. 1 depicts a simpliÔ¨Åed ex ample in which systems are expected to decide whether the facts in the table support the natural language statement. In addition to its importance in applications, the task presents research challenges of fundamental interests‚Äîthe problem inherently involves both in formal inference based on language understand ing (Dagan et al., 2005; MacCartney and Man ning, 2009, 2008; Bowman et al., 2015, 2016) and symbolic operations such as mathematical opera tions (e.g., count andmax). Recently, pretrained language models such as BERT (Devlin et al., 2019) have shown superior performances in nat ural language inference by leveraging knowledge from large text datasets and can capture compli cated semantic and syntactic information among premises and hypotheses (Radford, 2018; Radford et al., 2019; Liu et al., 2019; Dong et al., 2019b).arXiv:2010.03084v6  [cs.AI]  12 Sep 2021However, such methods tend to fail when veriÔ¨Åca tion requires the joint modelling of both symbolic operations and language inference (Gupta et al., 2020) such as the case depicted in Fig. 1. To effectively enable symbolic operations and in tegrate them into languagebased inference models, we propose a framework centered around programs, i.e., logical forms that can be executed to Ô¨Ånd evi dences from structured data. Our model starts with aprogram selection module, for which we propose a new training strategy based on margin loss to Ô¨Ånd programs that can accurately extract support ing facts from tables. To bridge the semantic gap between structured programs and tables as well as to leverage the structures of programs, we propose a novel model based on verbalization with program execution . The verbalization algorithm interweaves with program execution in order to accumulate evi dences inherently embedded in operations, and the algorithm recursively converts executed operations in programs into natural language sentences. Built on that, we propose graphbased veriÔ¨Åcation net work to fuse different sources of evidences from verbalized program execution, together with the original statements and tables, to support the Ô¨Ånal veriÔ¨Åcation decision. We conduct experiments on the recently proposed large scale benchmark dataset TAB FACT (Chen et al., 2020). Experimental results show that our proposed framework achieves new stateoftheart performance, an accuracy of 74.4%, substantially improving the previously reported best performance with the accuracy of 71.7%. Our detailed analysis shows the effectiveness of verbal ization and graphbased veriÔ¨Åcation network in uti lizing programs to achieve the improvement. The analysis also demonstrates that the program selec tion optimized with the proposed training strategy based on margin loss effectively improves the Ô¨Ånal veriÔ¨Åcation results. 2 Related Work "
263,Deep Network Guided Proof Search.txt,"Deep learning techniques lie at the heart of several significant AI advances
in recent years including object recognition and detection, image captioning,
machine translation, speech recognition and synthesis, and playing the game of
Go. Automated first-order theorem provers can aid in the formalization and
verification of mathematical theorems and play a crucial role in program
analysis, theory reasoning, security, interpolation, and system verification.
Here we suggest deep learning based guidance in the proof search of the theorem
prover E. We train and compare several deep neural network models on the traces
of existing ATP proofs of Mizar statements and use them to select processed
clauses during proof search. We give experimental evidence that with a hybrid,
two-phase approach, deep learning based guidance can significantly reduce the
average number of proof search steps while increasing the number of theorems
proved. Using a few proof guidance strategies that leverage deep neural
networks, we have found first-order proofs of 7.36% of the first-order logic
translations of the Mizar Mathematical Library theorems that did not previously
have ATP generated proofs. This increases the ratio of statements in the corpus
with ATP generated proofs from 56% to 59%.","1.1 Motivation Inthepasttwentyyears, variouslargecorporaofcomputerunderstandablereasoningknowledge have been developed (Harrison et al., 2014). Apart from axioms, deÔ¨Ånitions, and conjectures, such corpora include proofs derived in the selected logical foundation with suÔ¨Écient detail to be machinecheckable. This is either given in the form of premisesconclusion pairs (SutcliÔ¨Äe, 2009) or as procedures and intermediate steps (Wenzel, 1999). The development of many of these formal proofs required dozens of personyears, their sizes are measured in tens of thousands of humannamed theorems and the complete proofs contain billions of lowlevel inference steps. These formal proof libraries are also interesting for AIbased methods, with tasks such as concept matching, theory exploration, and structure formation (Autexier & Hutter, 2015). Furthermore, the AI methods can be augmented by automated reasoning: progress in the "
514,Set Distribution Networks: a Generative Model for Sets of Images.txt,"Images with shared characteristics naturally form sets. For example, in a
face verification benchmark, images of the same identity form sets. For
generative models, the standard way of dealing with sets is to represent each
as a one hot vector, and learn a conditional generative model
$p(\mathbf{x}|\mathbf{y})$. This representation assumes that the number of sets
is limited and known, such that the distribution over sets reduces to a simple
multinomial distribution. In contrast, we study a more generic problem where
the number of sets is large and unknown. We introduce Set Distribution Networks
(SDNs), a novel framework that learns to autoencode and freely generate sets.
We achieve this by jointly learning a set encoder, set discriminator, set
generator, and set prior. We show that SDNs are able to reconstruct image sets
that preserve salient attributes of the inputs in our benchmark datasets, and
are also able to generate novel objects/identities. We examine the sets
generated by SDN with a pre-trained 3D reconstruction network and a face
verification network, respectively, as a novel way to evaluate the quality of
generated sets of images.","Generative modeling of natural images has seen great advances in recent years. State of the art models such as GANs [ 3], EBMs [ 9] and V AEs [ 19] can generate single images with high perceptual quality. In many applications, however, images often come in sets with shared characteristics. For example, a set might be constructed from images that belong to the same semantic category, or those that share the same attribute. When the number of sets is limited and known, one is able to easily extend a generative model to its conditional version by representing the set information as a one hot vector [ 15,17]. We refer to these models as class conditional generative models (CCGMs). CCGMs are fundamentally limited by the predeÔ¨Åned enumeration of all possible sets in their encoding, which prevents recognizing or generating sets that are not speciÔ¨Åcally encoded from the training distribution. Also, the number of parameters needed for a CCGM grows linearly w.r.t the number of sets (classes) during training, which limits its scalability. In this paper, we study the problem of generative modeling of sets of images with a generic approach. We propose Set Distribution Networks (SDNs), a probabilistic model that is capable of learning to stochastically reconstruct a given set and generate novel sets at the same time. Stochastic reconstruc tion of a set means that the individual images in the input set will not be reproduced exactly, but the generated images will share setdeÔ¨Åning attributes with the input images. We achieve this by jointly training a set encoder, a set discriminator, a set generator, and a set prior. We train an SDN by following the MLE objective, which results in an adversarial game where the encoder, discriminator and prior are trained against the generator. We evaluate SDNs on two benchmarks: 1. ShapeNet [ 5], which consists of objects in various viewpoints; 2. VGGFace2 [ 4], which consists of various faces of human identities. We show that Preprint. Under review.arXiv:2006.10705v1  [cs.LG]  18 Jun 2020the same SDN architecture can be successfully trained on the two datasets, and can learn to both reconstruct an unseen set, and generate a novel set. We measure the quality of the set generative model by examining the generated samples with a pretrained 3D reconstruction network, and face veriÔ¨Åcation network, respectively, and show that SDNs learn to generate faithful and coherent sets. 2 Methodology "
410,Constrained Feedforward Neural Network Training via Reachability Analysis.txt,"Neural networks have recently become popular for a wide variety of uses, but
have seen limited application in safety-critical domains such as robotics near
and around humans. This is because it remains an open challenge to train a
neural network to obey safety constraints. Most existing safety-related methods
only seek to verify that already-trained networks obey constraints, requiring
alternating training and verification. Instead, this work proposes a
constrained method to simultaneously train and verify a feedforward neural
network with rectified linear unit (ReLU) nonlinearities. Constraints are
enforced by computing the network's output-space reachable set and ensuring
that it does not intersect with unsafe sets; training is achieved by
formulating a novel collision-check loss function between the reachable set and
unsafe portions of the output space. The reachable and unsafe sets are
represented by constrained zonotopes, a convex polytope representation that
enables differentiable collision checking. The proposed method is demonstrated
successfully on a network with one nonlinearity layer and approximately 50
parameters.","Neural networks are a popular method for approximating nonlinear functions, with increasing applications in the Ô¨Åeld of humanrobot interactions. For example, the kinematics of many eldercare robots [1], [2], rehabilitation robots [3], [4], industrial robot manipulators [5], and automated driving systems [6], [7] are controlled by neural networks. Thus, verifying the safety of the neural networks in these systems, before deployment near humans, is crucial in avoid ing injuries and accidents. However, it remains an active area of research to ensure the output of a neural network satisÔ¨Åes userspeciÔ¨Åed constraints and requirements. In this short paper, we take preliminary steps towards safety via constrained training by representing constraints as a collision check between the reachable set of a neural network and unsafe sets in its output space. A. Related Work Many different solutions have been proposed for the veriÔ¨Åcation problem, with setbased reachability analysis being the most common for an uncertain set of inputs [8]. Depending on one‚Äôs choice of representation, the predicted output is either exact (e.g. star set [6], [9], ImageStar [10]) or an overapproximation (e.g. zonotope [11]) of the actual output set. Reachability is most commonly computed layer bylayer, though methods have been proposed that speed up * indicates equal contribution. All authors are with Stanford University, Stanford, CA. L.K. Chung is with the Department of Mechanical Engineer ing. A. Dai is with the Department of Electrical Engineering. D. Knowles, S. Kousik, and G.X. Gao are with the Department of Aeronautics and Astronautics. Corresponding author: gracegao@stanford.edu .veriÔ¨Åcation by, e.g., using an anytime algorithm to return unsafe cells while enumerating polyhedral cells in the input space [12], or recursively partitioning the input set via shadow prices [13]. VeriÔ¨Åcation techniques have several drawbacks. First, they do not provide feedback about constraints during training, so one must alternate training and veriÔ¨Åcation until desired properties have been achieved. Furthermore, veriÔ¨Åcation by overapproximation can often be inconclusive, while exact veriÔ¨Åcation can be expensive to compute. Several alternative approaches have therefore been pro posed. For example, [14] employs a constrained optimiza tion layer to use the output of the network as a poten tial function for optimization while enforcing constraints. Similarly, [15], [16] adds a constraint violation penalty to the objective loss function and penalizes violation of the constraint. These methods augment their networks with con strained optimization, but are unable to guarantee constraint satisfaction upon convergence of the training. Alternatively, [17] uses a systematic process of small changes to con form a ‚Äúmostlycorrect‚Äù network to constraints. However the method only works for networks with a TwoLevel Lattice (TLL) architecture, requires an alreadytrained net work, and again does not guarantee a provably safe solution. Finally, [18] attempts to learn the optimal costtogo for the Hamilton‚ÄìJacobi‚ÄìBellman (HJB) equation, while subjected to constraints on the output of the neural network controller. Yet, it does not actually involve any network training and is unable to handle uncertain input sets. Recently, constrained zonotopes have been introduced as a setbased representation that is closed under linear transformations and can exactly represent any convex poly tope [19], [20]. Importantly, these sets are wellsuited for reachability analysis due to analytical, efÔ¨Åcient methods for computing Minkowski sums, intersections, and collision checks; in particular, collisionchecking only requires solving a linear program. We leverage these properties to enable our contributions. B. Contributions We propose a method to compute the output of a neu ral network with rectiÔ¨Åed linear unit (ReLU) activations given an input set represented as constrained zonotopes. We then enforce performance by training under a differentiable zonotope intersection constraint, which guarantees safety upon convergence. Our method is demonstrated on a small numerical example, and illustrated in Fig. 1. 1arXiv:2107.07696v1  [cs.LG]  16 Jul 2021Fig. 1. An example safe training result with the proposed method. The color gradient illustrates corresponding input and output points. With our method, the trained output does not intersect the unsafe set (red box). II. P RELIMINARIES We now introduce our notation for neural networks and deÔ¨Åne constrained zonotopes. In this work, we consider a fullyconnected, ReLU activated feedforward neural network n():X(0)!Rn(d), with output x(d)=n x(0) given an input x(0)2X(0)Rn(0). We call X(0)the input set. We denote by d2Nthedepth of the network and by n(i)thewidth of the ithlayer. For each layer k=1;;d"
169,Provably Bounding Neural Network Preimages.txt,"Most work on the formal verification of neural networks has focused on
bounding forward images of neural networks, i.e., the set of outputs of a
neural network that correspond to a given set of inputs (for example, bounded
perturbations of a nominal input). However, many use cases of neural network
verification require solving the inverse problem, i.e, over-approximating the
set of inputs that lead to certain outputs. In this work, we present the first
efficient bound propagation algorithm, INVPROP, for verifying properties over
the preimage of a linearly constrained output set of a neural network, which
can be combined with branch-and-bound to achieve completeness. Our efficient
algorithm allows multiple passes of intermediate bound refinements, which are
crucial for tight inverse verification because the bounds of an intermediate
layer depend on relaxations both before and after this layer. We demonstrate
our algorithm on applications related to quantifying safe control regions for a
dynamical system and detecting out-of-distribution inputs to a neural network.
Our results show that in certain settings, we can find over-approximations that
are over 2500 times tighter than prior work while being 2.5 times faster on the
same hardware.","Applications of neural networks to safetycritical settings often require reasoning about the set of inputs that will produce a particular set of outputs. For example, for a physical system controlled by a policy parameterized as a neural network, it is of interest to understand the states that would cause the policy to choose control actions that are outside acceptable limits (for example torques that are beyond the safe operating range of a motor), or that would result in a future state that violates safety constraints. Another example is quantifying the outofdistribution (OOD) detection behavior of a neural network: here, it is of interest to bound the set of inputs that leads to a classiÔ¨Åer making a conÔ¨Ådent prediction, i.e, where the highest scoring logit exceeds the second highest scoring logit by a large margin. Given this set, one can assess whether there are inputs far from the training data that are assigned high conÔ¨Ådence predictions, which would be an undesirable property. Formal veriÔ¨Åcation of neural networks seeks to provide provable guarantees demonstrating that networks satisfy formal speciÔ¨Åcations on their inputs and outputs. Practical algorithms often rephrase the above as Ô¨Ånding provably correct bounds on the inputs or outputs of a neural network subject to speciÔ¨Åc constraints. Most work to date has focused on developing algorithms that can bound the outputs of a neural network given constraints on the inputs, which is challenging due to high *Equal contribution Code is available at https://github.com/kothasuhas/verifyinput Preprint.arXiv:2302.01404v2  [cs.LG]  7 Feb 2023dimensionality and nonconvexity. For example, to analyze the robustness of a neural network to perturbations of a given input, these algorithms compute bounds on the outputs of the network given that the inputs are bounded perturbations of a nominal input [Wong and Kolter, 2018, Dvijotham et al., 2018, Zhang et al., 2018, Raghunathan et al., 2018, Gehr et al., 2018]. In this work, we address the inverse problem, motivated by the usecases outlined above. Our goal is to Ô¨Ånd bounds on the preimage of a neural network: given a set of outputs Sout(described by linear constraints on the output of a neural network), we seek to Ô¨Ånd a set that provably contains all inputs that lead to such outputs. The veriÔ¨Åcation problem is already challenging due to nonconvexity and high dimensionality. This new problem is increasingly difÔ¨Åcult since neural networks are not invertible. SpeciÔ¨Åcally, representative efÔ¨Åcient veriÔ¨Åers (such as state of the art boundpropagationbased methods [Zhang et al., 2022]) can only compute bounds in the forward direction, and the tightness of the linear programming relaxations they rely on to perform formal veriÔ¨Åcation critically depends on having tight bounds on intermediate activations. In the setting of this paper, however, the bounds available on the intermediate activations derived from the input constraints are weak, since the only constraints on the input are that it should be from the valid input domain (for example, normalized pixels from an image lie between 0and1). In fact, in some applications like control, the input domain may be unbounded. Given this, the bounds on intermediate activations derived from the input constraints may be vacuous or very loose, impacting the tightness of the intermediate activation relaxations. We efÔ¨Åciently solve this problem by signiÔ¨Åcantly generalizing the existing bound propagationbased veriÔ¨Åcation framework. Our contributions are as follows: ‚Ä¢We formulate the inverse veriÔ¨Åcation problem for neural networks, i.e, the problem of over approximating the set of inputs that leads to a given set of outputs, with a mixed integer linear programming formulation. This motivates our development of an efÔ¨Åcient bound propagation method. ‚Ä¢We develop an effective bound propagation framework, Inverse Propagation for Neural Network VeriÔ¨Åcation ( INVPROP ), which computes provable overapproximations of neural network preim ages. We study the convex outer approximation of this problem which leads to a novel inverse bound propagation method for veriÔ¨Åcation. We also unify INVPROP and forward veriÔ¨Åcation bound propagation into a more general veriÔ¨Åcation framework, allowing us to connect our method to standard tools and beneÔ¨Åt from prior progress in the veriÔ¨Åcation community, such as efÔ¨Åcient GPU acceleration. ‚Ä¢We demonstrate that tight inverse veriÔ¨Åcation requires multiple reÔ¨Ånement passes of intermediate bounds. This is unique to the inverse veriÔ¨Åcation problem because bounds for an intermediate layer depend on not only intermediate bounds before this layer, but also constraints imposed on downstream layers or the output of the network. In other words, bounds cannot be simply propagated in a single forward pass Ô¨Årst tightening all neurons in a given layer and then tightening the next layer based on the previous layer bounds. Instead, inverse veriÔ¨Åcation requires an iterative process where, in each pass, all bounds are tightened based on previous bounds (including output constraints), and the iterative process continues until bounds converge. ‚Ä¢We improve the stateoftheart on a control benchmark Rober et al. [2022a,b] by providing 2500 tighter bounds with 2:5faster computation. We also demonstrate applicability in OOD detection. 2 Setup 2.1 Notation Throughout this paper, we will use [L]forL2Nto refer to the setf1;2;:::;Lg,W(i) :;jto refer to columnjof the matrix W(i),[]+to refer to max(0;), and []"
432,Enabling certification of verification-agnostic networks via memory-efficient semidefinite programming.txt,"Convex relaxations have emerged as a promising approach for verifying
desirable properties of neural networks like robustness to adversarial
perturbations. Widely used Linear Programming (LP) relaxations only work well
when networks are trained to facilitate verification. This precludes
applications that involve verification-agnostic networks, i.e., networks not
specially trained for verification. On the other hand, semidefinite programming
(SDP) relaxations have successfully be applied to verification-agnostic
networks, but do not currently scale beyond small networks due to poor time and
space asymptotics. In this work, we propose a first-order dual SDP algorithm
that (1) requires memory only linear in the total number of network
activations, (2) only requires a fixed number of forward/backward passes
through the network per iteration. By exploiting iterative eigenvector methods,
we express all solver operations in terms of forward and backward passes
through the network, enabling efficient use of hardware like GPUs/TPUs. For two
verification-agnostic networks on MNIST and CIFAR-10, we significantly improve
L-inf verified robust accuracy from 1% to 88% and 6% to 40% respectively. We
also demonstrate tight verification of a quadratic stability specification for
the decoder of a variational autoencoder.","Applications of neural networks to safetycritical domains requires ensuring that they behave as expected under all circumstances [ 32]. One way to achieve this is to ensure that neural networks conform with a list of speciÔ¨Åcations , i.e., relationships between the inputs and outputs of a neural network that ought to be satisÔ¨Åed. SpeciÔ¨Åcations can come from safety constraints (a robot should never enter certain unsafe states [ 40,29,12]), prior knowledge (a learned physical dynamics model should be consistent with the laws of physics [ 49]), or stability considerations (certain transformations of the network inputs should not signiÔ¨Åcantly change its outputs [57, 7]). Evaluating whether a network satisÔ¨Åes a given speciÔ¨Åcation is a challenging task, due to the difÔ¨Åculty of searching for violations over the high dimensional input spaces. Due to this, several techniques that claimed to enhance neural network robustness were later shown to break under stronger attacks [61,5]. This has motivated the search for veriÔ¨Åcation algorithms that can provide provable guarantees on neural networks satisfying inputoutput speciÔ¨Åcations. Popular approaches based on linear programming (LP) relaxations of neural networks are compu tationally efÔ¨Åcient and have enabled successful veriÔ¨Åcation for many speciÔ¨Åcations [ 37,18,30,21]. LP relaxations are sound (they would never incorrectly conclude that a speciÔ¨Åcation is satisÔ¨Åed) but Equal contribution. Alphabetical order. :Code available at https://github.com/deepmind/jax_verify . 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.arXiv:2010.11645v2  [cs.LG]  3 Nov 2020incomplete (they may fail to verify a speciÔ¨Åcation even if it is actually satisÔ¨Åed). Consequently, these approaches tend to give poor or vacuous results when used in isolation, though can achieve strong results when combined with speciÔ¨Åc training approaches to aid veriÔ¨Åcation [22, 51, 67, 21, 54, 6]. In contrast, we focus on veriÔ¨Åcationagnostic models, which are trained in a manner agnostic to the veriÔ¨Åcation algorithm. This would enable applying veriÔ¨Åcation to all neural networks, and not just those trained to be veriÔ¨Åable. First, this means training procedures need not be constrained by the need to verify, thus allowing techniques which produce empirically robust networks, which may not be easily veriÔ¨Åed [ 38]. Second, ML training algorithms are often not easily modiÔ¨Åable, e.g. productionscale ML models with highly speciÔ¨Åc pipelines. Third, for many tasks, deÔ¨Åning formal speciÔ¨Åcations is difÔ¨Åcult, thus motivating the need to learn speciÔ¨Åcations from data. In particular, in recent work [ 24,50,66], natural perturbations to images like changes in lighting conditions or changes in the skin tone of a person, have been modeled using perturbations in the latent space of a generative model. In these cases, the speciÔ¨Åcation itself is a veriÔ¨Åcationagnostic network which the veriÔ¨Åcation must handle even if the prediction network is trained with the veriÔ¨Åcation in mind. In contrast to LPbased approaches, the semideÔ¨Ånite programming (SDP) relaxation [ 52] has enabled robustness certiÔ¨Åcation of veriÔ¨Åcationagnostic networks. However, the interior point methods commonly used for SDP solving are computationally expensive with Opn6qruntime and Opn4q memory requirements, where nis the number of neurons in the network [ 41,60]. This limits applicability of SDPs to small fully connected neural networks. Within the SDP literature, a natural approach is to turn to Ô¨Årstorder methods, exchanging precision for scalability [ 63,53]. Because veriÔ¨Åcation only needs a bound on the optimal value of the relaxation (and not the optimal solution), we need not design a generalpurpose SDP solver, and can instead operate directly in the dual. A key beneÔ¨Åt is that the dual problem can be cast as minimizing the maximum eigenvalue of an afÔ¨Åne function, subject only to nonnegativity constraints. This is a standard technique used in the SDP literature [ 25,42] and removes the need for an expensive projection operation onto the positive semideÔ¨Ånite cone. Further, since any set of feasible dual variables provides a valid upper bound, we do not need to solve the SDP to optimality as done previously [ 52], and can instead stop once a sufÔ¨Åciently tight upper bound is attained. In this paper, we show that applying these ideas to neural network veriÔ¨Åcation results in an efÔ¨Åcient implementation both in theory and practice. Our solver requires Opnqmemory rather than Opn4q for interior point methods, and each iteration involves a constant number of forward and backward passes through the network. Our contributions. The key contributions of our paper are as follows: 1.By adapting ideas from the Ô¨Årstorder SDP literature [ 25,42], we observe that the dual of the SDP formulation for neural network veriÔ¨Åcation can be expressed as a maximum eigenvalue problem with only interval bound constraints. This formulation generalizes [ 52] without loss of tightness, and applies to any quadraticallyconstrained quadratic program (QCQP), including the standard adversarial robustness speciÔ¨Åcation and a variety of network architectures. Crucially, when applied to neural networks, we show that subgradient computations are expressible purely in terms of forward or backward passes through layers of the neural network. Consequently, applying a subgradient algorithm to this formulation achieves periteration complexity comparable to a constant number of forward and backward passes through the neural network. 2.We demonstrate the applicability of Ô¨Årstorder SDP techniques to neural network veriÔ¨Åcation. We Ô¨Årst evaluate our solver by verifying `8robustness of a variety of veriÔ¨Åcationagnostic networks on MNIST andCIFAR 10. We show that our approach can verify large networks beyond the scope of existing techniques. For these veriÔ¨Åcationagnostic networks, we obtain bounds an order of magni tude tighter than previous approaches (Figure 1). For an adversarially trained convolutional neural network (CNN) with no additional regularization on MNIST ( 0:1), compared to LP relaxations, we improve the veriÔ¨Åed robust accuracy from 1%to88%. For the same training and architecture on C IFAR 10 (2{255), the corresponding improvement is from 6%to40%(Table 1). 3.To demonstrate the generality of our approach, we verify a different quadratic speciÔ¨Åcation on the stability of the output of the decoder for a variational autoencoder (V AE). The upper bound on speciÔ¨Åcation violation computed by our solver closely matches the lower bound on speciÔ¨Åcation violation (from PGD attacks) across a wide range of inputs (Section 6.2). 22 Related work "
73,Validation of Image-Based Neural Network Controllers through Adaptive Stress Testing.txt,"Neural networks have become state-of-the-art for computer vision problems
because of their ability to efficiently model complex functions from large
amounts of data. While neural networks can be shown to perform well empirically
for a variety of tasks, their performance is difficult to guarantee. Neural
network verification tools have been developed that can certify robustness with
respect to a given input image; however, for neural network systems used in
closed-loop controllers, robustness with respect to individual images does not
address multi-step properties of the neural network controller and its
environment. Furthermore, neural network systems interacting in the physical
world and using natural images are operating in a black-box environment, making
formal verification intractable. This work combines the adaptive stress testing
(AST) framework with neural network verification tools to search for the most
likely sequence of image disturbances that cause the neural network controlled
system to reach a failure. An autonomous aircraft taxi application is
presented, and results show that the AST method finds failures with more likely
image disturbances than baseline methods. Further analysis of AST results
revealed an explainable cause of the failure, giving insight into the
problematic scenarios that should be addressed.","Many autonomous systems interact in complex environ ments and operate with highdimensional data, such as images. Recent work has shown that neural networks can be trained efÔ¨Åciently to make decisions for imagebased problems. Mnih et al. use deep reinforcement learning to train neural network controllers that map Atari screen images to controller commands to create gameplaying agents that outperform humans [1]. Additional work has shown that neural networks can play chess [2], classify objects [3], and recognize digits [4]. In addition, neural networks can be used to control vehicles, such as steering cars [5], [6], guiding aircraft to waypoints [7], and controlling quadrotors [8]. Although misclassifying a cat image is undesirable, steer ing vehicles off roads or into other vehicles can be catas trophic. Recently, tools have been developed that can verify inputoutput properties of neural networks, such as those representing aircraft collision avoidance policies [9]. These This material is based upon work supported by the National Science Foundation Graduate Research Fellowship under Grant No. DGE1656518, AFRL and DARPA under contract FA875018C0099, and a NASA Ames Research Center summer internship. Any opinions, Ô¨Åndings, or recommen dations expressed in this material are those of the authors and do not necessarily reÔ¨Çect the views of the U.S. Government. 1Kyle D. Julian and Mykel J. Kochenderfer are with Aeronautics and As tronautics, Stanford University, Stanford, CA 94305, USA fkjulian3, mykel g@stanford.edu 2Ritchie Lee is with KBR Inc. at NASA Ames Research Park, Moffett Field, CA 94035, USA ritchie.lee@nasa.govtools use the simplex method [9], [10], mixed integer linear programming [11], symbolic interval analysis with linear relaxation [12], and other approaches [13]. However, verifying inputoutput properties of systems acting as closedloop controllers is insufÔ¨Åcient to verify safety. Additional work has focused on veriÔ¨Åcation of multistep properties of neural network controllers acting within their environment [14]‚Äì[17]. Existing closedloop veriÔ¨Åcation work is applicable when the network input is lowdimensional and adequate environmental models exist; however, when the network input is highdimensional and the environment is complex, veriÔ¨Åcation approaches are intractable. As a result, many imagebased neural network veriÔ¨Åcation approaches focus on local robustness around validation images [18], [19]. However, local robustness is an inputoutput property and does not address closedloop safety. This work focuses on validation of imagebased neural network controllers. Existing work on validation of complex systems has led to the development of adaptive stress testing (AST), which uses reinforcement learning to Ô¨Ånd the most likely ways systems fail [20], [21]. However, existing work with AST has only considered lowdimensional problems. Our method combines ideas from local robustness veriÔ¨Å cation with AST black box validation to efÔ¨Åciently search for sequences of image disturbances that lead to failure. Using neural network veriÔ¨Åcation tools allows the algorithm to search for multistep sequences in a lowerdimensional space than the size of the image. As a result, this method scales well to neural networks with hundreds of input variables without making any assumptions about the environment, al lowing the tool to be easily integrated with any existing sim ulator. An example aircraft taxiway application is presented that uses the XPlane 11 photorealistic Ô¨Çight simulator [22]. The method is able to Ô¨Ånd sequences of image disturbances that cause the neural network to guide the aircraft off the taxiway, and further analysis reveals explainable weaknesses of the neural network that were exploited to cause failures. II. B ACKGROUND This work combines ideas from reinforcement learning and neural network veriÔ¨Åcation, which are described in this section. A. Markov Decision Process A Markov decision process (MDP) is a general framework for modeling sequential decisionmaking problems and is described by the tuple (S;A;R;T )[23]. An agent in statearXiv:2003.02381v1  [cs.RO]  5 Mar 2020s2S takes action a2A, transitions to s0with probability T(s0js;a), and receives reward r=R(s;a;s0). The action value function Q(s;a)gives the expected value of taking actionafrom statesand following the policy a=(s)for all future states, computed as Q(s;a) =E""X t=0 trtjs0=s;a0=a;a0=(s)# ;(1) where discount factor  is set to = 1 for Ô¨Ånite horizon problems and 0<  < 1for inÔ¨Ånite horizon problems. The goal with an MDP to compute (s)that maximizes Q(s;a), denoted as(s)andQ(s;a)respectively. If the transition function is known, then optimization algorithms can compute (s); however, when the transition function is unknown or difÔ¨Åcult to model, such as with imagebased navigation, alternative methods are needed. Reinforcement learning is a modelfree method that uses sim ulations to estimate Q(s;a). The following two subsections describe reinforcement learning algorithms used in this work. B. Monte Carlo Tree Search Monte Carlo tree search (MCTS) begins with a root node with initial state, s0. New states s0are added to the tree as leaf nodes from an existing node svia the action aused to arrive ats0froms. At each node, the algorithm keeps track ofN(s), the number of times the node with state shas been visited,N(s;a), the number of times action a2A(s)has been taken from s, andQ(s;a), the value estimate of taking actionafrom states. MCTS follows three basic steps: 1)Search . Beginning at the root node with state sand actionsA(s)already added to the tree, new actions are added to the tree if kA(s)k< kN (s), where kandare hyperparameters that balance exploration with exploitation. If a new action is not added, then an existing action is taken to maximize Q(s;a) +cs logN(s) N(s;a)(2) wherecis also a hyperparameter. The search process repeats from s0until a new action is selected. 2)Expansion . The tree is expanded with the new action by simulating the action to compute s0, which is added as a new leaf node to the tree with an empty A(s0). This work assumes that transitions are deterministic, although other versions of MCTS can incorporate stochastic actions [20]. 3)Rollout . Once a new state s0has been added to the tree, a random rollout simulation is used to initialize Q(s;a). The rollout uses a default policy 0(s)to determine actions taken, and the rollout continues until a predetermined depth or terminal state is reached. Q(s;a)is computed from the rollout simulation using Eq. (1) with  = 1since the rollout has a Ô¨Ånite depth. The estimated Q(s;a)is then propagated up throughall parent nodes according to N(s;a) N(s;a) + 1 (3) q R(s;a;s0) + Q(s0;a0) (4) Q(s;a) Q(s;a) +q"
147,A Safety Framework for Critical Systems Utilising Deep Neural Networks.txt,"Increasingly sophisticated mathematical modelling processes from Machine
Learning are being used to analyse complex data. However, the performance and
explainability of these models within practical critical systems requires a
rigorous and continuous verification of their safe utilisation. Working towards
addressing this challenge, this paper presents a principled novel safety
argument framework for critical systems that utilise deep neural networks. The
approach allows various forms of predictions, e.g., future reliability of
passing some demands, or confidence on a required reliability level. It is
supported by a Bayesian analysis using operational data and the recent
verification and validation techniques for deep learning. The prediction is
conservative -- it starts with partial prior knowledge obtained from lifecycle
activities and then determines the worst-case prediction. Open challenges are
also identified.","Deep learning (DL) has been applied broadly in industrial sectors including au tomotive, healthcare, aviation and nance. To fully exploit the potential oered by DL, there is an urgent need to develop approaches to their certication in safety critical applications. For traditional systems, safety analysis has aided en gineers in arguing that the system is suciently safe. However, the deployment of DL in critical systems requires a thorough revisit of that analysis to re ect the novel characteristics of Machine Learning (ML) in general [10,2,29]. Compared with traditional systems, the behaviour of learningenabled sys tems is much harder to predict, due to, inter alia , their \blackbox"" nature and the lack of traceable functional requirements of their DL components. The \blackbox"" nature hinders the human operators in understanding the DL andA preprint accepted by SafeComp2020. To appear in Springer LNCS series.arXiv:2003.05311v3  [cs.LG]  6 Jun 20202 X. Zhao et al. makes it hard to predict the system behaviour when faced with new data. The lack of explicit requirement traceability through to code implementation is only partially oset by learning from a dataset, which at best provides an incom plete description of the problem. These characteristics of DL increase apparent nondeterminism [26], which on the one hand emphasises the role of probabilistic measures in capturing uncertainty, but on the other hand makes it notoriously hard to estimate the probabilities (and also the consequences) of critical failures. Recent progress has been made to support the Verication and Validation (V&V) of DL, e.g., [24,61]. Although these methods may provide evidence to sup port lowlevel claims, e.g., the local robustness of a deep neural network (DNN) on a given input, they are insucient by themselves to justify overall system safety claims. Here, we present a safety case framework for DL models which may in turn support higherlevel system safety arguments. We focus on DNNs that have been widely deployed as, e.g., perception/control units of autonomous systems. Due to the page limit, we also conne the framework to DNNs that are xed in the operation; this can be extended for online learning DNNs in future. We consider safetyrelated properties including reliability, robustness, inter pretability, fairness [6], and privacy [1]. In particular, we emphasise the assess ment of DNN generalisation error (in terms of inaccuracy), as a major reliability measure, throughout our safety case. We build arguments in two steps. The rst is to provide initial condence that the DNN's generalisation error is bounded, through the assurance activities conducted at each stage of its lifecycle, e.g., formal verication on the DNN robustness. The second step is to adopt proven inuse/eldtesting arguments to boost the condence and check whether the DNN is indeed suciently safe for the risk associated with its use in the system. The second step above is done in a statistically principled way via Conser vative Bayesian Inference (CBI) [8,58,68]. CBI requires only limited and partial prior knowledge of reliability, which diers from normal Bayesian analysis that usually assumes a complete prior distribution on the failure rate. This has a unique advantage: partial prior knowledge is more convincing (i.e. constitutes a more realistic claim) and easier to obtain, while complete prior distributions usu ally require extra assumptions and introduces optimistic bias. CBI allows many forms of prediction, e.g., posterior expected failure rate [8], future reliability of passing some demands [58] or a posterior condence on a required reliabil ity bound [68]. Importantly, CBI guarantees conservative outcomes: it nds the worstcase prior distribution yielding, say, a maximised posterior expected fail ure rate, and satisfying the partial knowledge. We are aware that there are other extant dangerous pitfalls in safety arguments [29,26], thus we also identify open challenges in our proposed framework and map them onto ongoing research. The key contributions of this work are: a)A very rst safety case framework for DNNs that mainly concerns quan titative claims based on structured heterogeneous safety arguments. b)An initial idea of mapping DNN lifecycle activities to the reduction of decomposed DNN generalisation error that used as a primary reliability measure.A Safety Framework for Deep Neural Networks 3 c)Identication of open challenges in building safety arguments for quanti tative claims, and mapping them onto ongoing research of potential solutions. Next, we present preliminaries. Sec. 3 provides toplevel argument, and Sec. 4 presents how CBI approach assures reliability. Other safety related properties are discussed in Sec. 5. We discuss related work in Sec. 6 and conclude in Sec. 7. 2 Preliminaries 2.1 Safety cases A safety case is a comprehensive, defensible, and valid justication of the safety of a system for a given application in a dened operating environment, thus it is a means to provide the grounds for condence and to assist decision making in certication [12]. Early research in safety cases mainly focus on their formula tion in terms of claims, arguments and evidence elements based on fundamental argumentation theories like the Toulmin model [52]. The two most popular no tations are CAE [12] and GSN [28]. In this paper, we choose the latter to present our safety case framework. Fig. 1: The GSN core elements and an example of using GSN. Fig. 1 shows the core GSN elements and a quick GSN example. Essentially, the GSN safety case starts with a top goal (claim) which then is decomposed through an argument strategy into subgoals (subclaims), and subgoals can be further decomposed until being supported by solutions (evidence). A claim may be subject to some context orassumption . An away goal repeats a claim presented in another argument module. A description on all GSN elements used here can be found in [28].4 X. Zhao et al. 2.2 Deep neural networks and lifecycle models Let (X;Y ) be the training data, where Xis a vector of inputs and Yis a vector of outputs such that jXj=jYj. Let Xbe the input domain and Ybe the set of labels. Hence, XX. We may use xandyto range over XandY, respectively. LetNbe a DNN of a given architecture. A network N:X!D (Y) can be seen as a function mapping from Xto probabilistic distributions over Y. That is, N(x) is a probabilistic distribution, which assigns for each possible label y2Y a probability value ( N(x))y. We letfN:X!Ybe a function such that for anyx2X,fN(x) = arg max y2Yf(N(x))yg, i.e.fN(x) returns the classication label. The network is trained with a parameterised learning algorithm, in which there are (implicit) parameters representing e.g., the number of epochs, the loss function, the learning rate, the optimisation algorithm, etc. A comprehensive ML Lifecycle Model can be found in [4], which identies assurance desiderata for each stage, and reviews existing methods that con tribute to achieving these desiderata. In this paper, we refer to a simpler lifecycle model that includes several phases: initiation, data collection, model construc tion, model training, analysis of the trained model, and runtime enforcement. 2.3 Generalisation error Generalisability requires that a neural network works well on all possible inputs inX, although it is only trained on the training dataset ( X;Y ). Denition 1. Assume that there is a ground truth function f:X!Yand a probability function Op:X![0;1]representing the operational prole. A networkNtrained on (X;Y )has a generalisation error: G0"
68,Improving seasonal forecast using probabilistic deep learning.txt,"The path toward realizing the potential of seasonal forecasting and its
socioeconomic benefits depends heavily on improving general circulation model
based dynamical forecasting systems. To improve dynamical seasonal forecast, it
is crucial to set up forecast benchmarks, and clarify forecast limitations
posed by model initialization errors, formulation deficiencies, and internal
climate variability. With huge cost in generating large forecast ensembles, and
limited observations for forecast verification, the seasonal forecast
benchmarking and diagnosing task proves challenging. In this study, we develop
a probabilistic deep neural network model, drawing on a wealth of existing
climate simulations to enhance seasonal forecast capability and forecast
diagnosis. By leveraging complex physical relationships encoded in climate
simulations, our probabilistic forecast model demonstrates favorable
deterministic and probabilistic skill compared to state-of-the-art dynamical
forecast systems in quasi-global seasonal forecast of precipitation and
near-surface temperature. We apply this probabilistic forecast methodology to
quantify the impacts of initialization errors and model formulation
deficiencies in a dynamical seasonal forecasting system. We introduce the
saliency analysis approach to efficiently identify the key predictors that
influence seasonal variability. Furthermore, by explicitly modeling uncertainty
using variational Bayes, we give a more definitive answer to how the El
Nino/Southern Oscillation, the dominant mode of seasonal variability, modulates
global seasonal predictability.","1.1 Dynamical seasonal forecast and its three barriers Global atmosphereoceanland coupled general circulation models (GCMs) that simulate the dynamics and interac tions of various climate subsystems are the workhorses for predictions on weather to climate scales. Over the past seven decades, advances in computation, observation, modeling, and data assimilation have gradually extended the range of useful deterministic forecasts toward the predictability limit [1]. This limit of range, set by the chaotic nature of the atmosphere, is estimated to be around two weeks [2]. Moving beyond this range, subseasonal to seasonal fore casts seek prediction sources from lowfrequency climate signals, which give rise to predictability by constraining the climate variability through the forecasting period. By better characterizing the key prediction sources and their impacts, GCMbased seasonal forecasts have demon strated markedly improved skill, offering crucial beneÔ¨Åts to a wide range of societal sectors [3]. Despite the achieve ments, we highlight the following three barriers that hinder the improvement of dynamical seasonal forecast. The Ô¨Årst barrier is model initialization. Accurate initialization is a prerequisite for dynamical forecasts. However, ex isting initialization strategies often fail to constrain a model‚Äôs state to faithfully match observations without introducing state shocks [4, 5]. Furthermore, when compared to the atmosphere, the assimilation methods and observation net works for the ocean, cryosphere, and land are typically underdeveloped [6], inhibiting the full utilization of prediction sources from these climate subsystems.arXiv:2010.14610v1  [physics.geoph]  27 Oct 2020APREPRINT  OCTOBER 29, 2020 The second barrier is model formulation deÔ¨Åciencies. GCMs are simpliÔ¨Åed representations of the climate system. Their backbones are dynamical cores that compute the atmosphere and ocean dynamics in discrete geogrids. Besides the resolved dynamics, a suite of empirical parameterization schemes is used to account for the effects of unresolved processes. The considerable structural and parametric errors in parameterization can severely impair a model‚Äôs forecast through multiscale interactions. The third barrier concerns the insufÔ¨Åcient sampling of forecast spread. In dynamical forecasts, uncertainties in ini tialization and model formulation can quickly grow and yield distinct, but possible results. To estimate this forecast spread, we usually create forecast ensembles by sampling plausible initial states and plausible model formulations. A key question is: how many ensemble members are required to accurately infer the forecast spread? There has been a growing recognition that initial states accommodating different climate signals can yield distinct forecast spreads, resulting in variations of predictability [7, 8] and requirement on ensemble size. Currently, we can not always af ford large ensemble forecasts to accurately estimate forecast uncertainties. Also, the dependency of predictability on the initial climate state is not wellconsidered in deploying forecast ensembles or guiding forecastrelated decision makings. The difÔ¨Åculties in surmounting the outlined barriers have considerably slowed the pace toward more skillful seasonal forecasts. To accelerate forecast system development, we should set up reasonable forecast benchmarks [9], thereafter apply these benchmarks to clarify the limitations imposed by each aspect of the forecasting barriers [10]. Unfortu nately, given the huge cost to initialize and run largeensemble forecasts, and short history of climate observations for forecast veriÔ¨Åcation, the seasonal forecast benchmarking and diagnosing task remains challenging. 1.2 Learning from climate simulations for seasonal forecast Two recent studies suggest that we can turn to the datarich climate simulation ‚Äúmodel world‚Äù to seek implications for seasonal forecasts [11, 12, 13]. For instance, Ding et al. [12] drew analog from existing climate simulations that resemble observed ocean status as forecast ensembles, and found those analog forecasts match dynamical forecast systems in seasonal prediction for sea surface temperature and precipitation. This method could be interpreted as a knearest neighbour approach [14] from a machine learning viewpoint. In the second study, Ham et al. [13] trained a deep neural network to predict the El Ni√±o/Southern Oscillation (ENSO) in climate simulations, and found that, with moderate modiÔ¨Åcations and using relatively few observational records, the neural network model applies well in realworld forecast of ENSO, outperforming dynamical forecasting for lead time of up to one and a half years. The rationale behind these approaches is that, seasonal forecasts are conducted with identical or similar GCMs used in climate simulations. One can build analogical models using machine learning techniques to simulate the seasonal variability signal in climate simulations, and thereafter apply this GCMrevealed relationship for practical forecast. While these attempts open the opportunity of employing largescale statistical models (i.e., deep neural networks) to learn from climate simulation big data for seasonal forecasts, we notice the following three gaps along this novel line of research. First, existing research focuses on limited regions or phenomena, and have not fully exploited the wealth of climate simulation information to improve seasonal forecast for a broad range of regions. Second, forecast uncertainty, which is indispensable in seasonal forecast and crucial in supporting forecastrelated decision making, has not been rigorously represented. Finally, any solid progress toward improving seasonal forecast should contribute to tackling the three aforementioned forecast barriers noted in Sect. 1a. However, it is unclear how the analog seasonal forecast practices inform the identiÔ¨Åcation or conquering of these forecast barriers. To address these deÔ¨Åciencies, we develop a probabilistic deep learning model that leverages the rich information from climate model simulations to enhance seasonal forecast capability and foster forecast diagnosis. SpeciÔ¨Åcally, we summarize how key prediction sources regulate seasonal variability in climate simulations by learning a generative model that samples possible seasonalahead climate status conditioned on the current state of the predictors. By benchmarking dynamical seasonal forecasts with the proposed model, we demonstrate that current dynamical seasonal forecast systems have not fully exploited the forecast capability of existing GCMs. The impact of initialization error, GCM formulation deÔ¨Åciency, and internal climate variability are revealed. The results help answer the following questions: 1. Can we extend the datadriven seasonal forecasting paradigm to quasiglobal scale? 2. How to represent uncertainty in a datadriven seasonal forecast? 3. How does this methodology inform potential improvement of dynamical seasonal forecasts? We organize the rest of the paper as follows. Section 2 introduces the probabilistic modeling framework. Section 3 describes the data and experimental design. Section 4 compares our model with dynamical forecast systems in 2APREPRINT  OCTOBER 29, 2020 retrospective forecast experiments. We discuss the implications for diagnosing and understanding dynamical seasonal forecast in Section 5. Conclusions are drawn in Section 6. 2 Methodology "
344,Abstraction and Refinement: Towards Scalable and Exact Verification of Neural Networks.txt,"As a new programming paradigm, deep neural networks (DNNs) have been
increasingly deployed in practice, but the lack of robustness hinders their
applications in safety-critical domains. While there are techniques for
verifying DNNs with formal guarantees, they are limited in scalability and
accuracy. In this paper, we present a novel abstraction-refinement approach for
scalable and exact DNN verification. Specifically, we propose a novel
abstraction to break down the size of DNNs by over-approximation. The result of
verifying the abstract DNN is always conclusive if no spurious counterexample
is reported. To eliminate spurious counterexamples introduced by abstraction,
we propose a novel counterexample-guided refinement that refines the abstract
DNN to exclude a given spurious counterexample while still over-approximating
the original one. Our approach is orthogonal to and can be integrated with many
existing verification techniques. For demonstration, we implement our approach
using two promising and exact tools Marabou and Planet as the underlying
verification engines, and evaluate on widely-used benchmarks ACAS Xu, MNIST and
CIFAR-10. The results show that our approach can boost their performance by
solving more problems and reducing up to 86.3% and 78.0% verification time,
respectively. Compared to the most relevant abstraction-refinement approach,
our approach is 11.6-26.6 times faster.","Due to surprising breakthroughs in many challenging tasks such as image recognition [Russakovsky et al.2015] and natural language processing [Hinton et al .2012], deep learning has arguably become a new programming paradigm that takes over traditional software programs in many areas. For instance, deep neural networks (DNNs) are increasingly being deployed in safetycritical applications, e.g., autonomous driving [Urmson and Whittaker 2008] and medical systems [Litjens et al.2017]. However, DNNs are fragile to small perturbations due to the lack of robustness [Carlini and Wagner 2017; Dalvi et al .2004; Goodfellow et al .2015; Kurakin et al .2017; Papernot et al .2016; Szegedy et al .2014]. Therefore, it is important to formally guarantee the robustness of DNNs before to deploy them in safetycritical applications. Many efforts have been made to verify DNNs [Bunel et al .2017; Ehlers 2017; Elboher et al .2020; Huang et al .2017; Katz et al .2017, 2019; Lin et al .2019; Pulina and Tacchella 2010; Wong and Kolter 2018]. Early work relies on using constraint solvers, often providing soundness and completeness guarantees. However, their scalability is limited due to the intrinsic computational complexity, e.g., NPcomplete even for simple neural networks and properties [Katz et al .2017]. Another line of work is based on abstract interpretation to improve the scalability at the cost of precision [Gehr et al.2018; Singh et al .2018, 2019; Tran et al .2019; Wang et al .2018; Yang et al .2021]. Although few of them incorporate refinement strategies to improve accuracy [Singh et al .2019; Wang et al . 2018; Yang et al .2021], it remains a great challenge to efficiently and precisely verify largescale DNNs. One of the most promising techniques used in formal verification to improve the efficiency is counterexampleguided abstraction refinement (CEGAR ) framework [Clarke et al .2000]. The essential idea of CEGAR is that, when given a target system ùëÜto verify, an overapproximation, smallsized system ¬ØùëÜis constructed by abstraction and verified by an offtheshelf tool. The result is always conclusive if no spurious counterexample is reported. Otherwise, to regain precision, the abstract Authors‚Äô addresses: Jiaxiang Liu, jiaxiang0924@gmail.com; Yunhan Xing, xingyunhan@email.szu.edu.cn; Xiaomu Shi, xshi0811@gmail.com, Shenzhen University, Shenzhen, China; Fu Song, ShanghaiTech University, Shanghai, China, songfu@ shanghaitech.edu.cn; Zhiwu Xu, xuzhiwu@szu.edu.cn; Zhong Ming, Shenzhen University, Shenzhen, China.arXiv:2207.00759v1  [cs.SE]  2 Jul 20222 Liu et al. system ¬ØùëÜis refined guided by the spurious counterexample to exclude it. The verification process is repeated on the refined system until the original system is proved or a genuine counterexample is found. To instantiate the CEGAR framework, one needs to address the following two questions: (1) how to abstract a target system and (2) how to refine an abstract system. When instantiating CEGAR in DNN verification, there are four technical challenges: C1:The abstraction should guarantee soundness , i.e., if an abstract DNN ¬ØùëÅis proved robust, the target DNN ùëÅmust be robust. C2:The abstraction should reduce the network size as much as possible while preserving accuracy as much as possible, because coarsegrained abstract DNNs may result in plenty of spurious counterexamples, thus requiring more refinement steps. C3:The refinement must preserve soundness as well, similar to C1, and also excludes a given counterexample. C4:The refinement should regain the accuracy as much as possible, meanwhile enlarging the network size as little as possible. In this paper, addressing the above challenges, we present a scalable and exact CEGARbased approach for DNN verification by proposing novel procedures for abstraction and refinement. We define the abstraction procedure as a synergistic integration of two novel abstraction prim itives : one is to merge neurons and the other is to remove neurons, both of which are able to reduce network size. To address C1, these primitives are welldesigned according to the weights and bounds of neurons, thus provide soundness guarantees. To address C2, the iterative application of abstraction primitives is guided by a strategy that selects a primitive aimed at minimizing the loss of accuracy during each iteration, thus can abstract out more neurons when sacrificing the same accuracy. The refinement procedure is defined as a synergistic integration of two novel refinement primitives : one splits a single neuron into two neurons and the other recovers a removed neuron. To address C3, the iterative application of refinement primitives is restricted by a dependency graph , a novel notion proposed to characterize the dependency between refinement steps. Under the restriction of the dependency graph, the refinement procedure is proved sound, otherwise may not be sound. Last but not least, the refinement procedure is also guided by a strategy to address C4 which selects a refinement primitive to regain the most accuracy, thus can keep the network size smaller when restoring the same amount of accuracy. Our approach is orthogonal to and can be integrated with many existing approaches. For evaluation, we implement our approach as a tool NARv using two promising and exact tools Marabou [Katz et al .2019] and Planet [Ehlers 2017] as backend verification engines. The experi mental results show that our approach can improve their scalability and boost their performance by reducing up to 86.3% and 78.0% verification time, respectively. Moreover, our approach is illus trated to significantly outperform the only tool that supports structureoriented CEGARbased verification [Elboher et al. 2020], 11.6‚Äì26.6 times faster. To sum up, the main contributions of this work are as follows: ‚Ä¢We propose a novel abstraction procedure that synergistically integrates two abstraction primitives using a novel abstraction strategy, allowing to soundly and maximally reduce the network size when sacrificing the same accuracy. ‚Ä¢We propose a novel refinement procedure consisting of two refinement primitives, a notion of dependency graphs and a strategy for their synergistic integration, allowing to soundly refine the network and keep the network size as small as possible when restoring the same amount of accuracy.Abstraction and Refinement: Towards Scalable and Exact Verification of Neural Networks 3 ‚Ä¢We implement our approach as a tool NARv with two promising DNN verification engines Marabou andPlanet and conduct an extensive evaluation, demonstrating the efficacy of our approach. Outline. Section 2 defines basic notations. Section 3 presents the overview of our approach. We propose our abstraction procedure and refinement procedure in Section 4 and Section 5, respectively. Section 6 reports experimental results. Finally, after discussing related work in Section 7, we conclude the paper in Section 8. To foster further research, benchmarks and experimental data are released at https://github.com/ NARv22/data. The source code is available at https://github.com/formes20/narv. 2 PRELIMINARIES 2.1 Deep Neural Networks Afully connected feedforward deep neural network (DNN ) with‚Ñì+1layers is an acyclic graph structured in layers, where 0th and‚Ñìth layers are input layer andoutput layer , respectively and the other layers are hidden layers . The nodes in each layer are neurons . We useùë£ùëñ,ùëóto denote the value of the ùëóth neuron in layer ùëñ, and ùíóùëñ=(ùë£ùëñ,1,...,ùë£ùëñ,ùëõ)ùëáthe output vector of layer ùëñcontaining ùëõneurons. Sometimes, ùë£ùëñ,ùëóalso denotes the neuron itself. Each neuron ùë£ùëñ,ùëóin layerùëñ(1‚â§ùëñ‚â§‚Ñì) is associated with a biasùëè(ùë£ùëñ,ùëó), and is connected by the weighted edges ùë§(ùë£ùëñ‚àí1,ùëò,ùë£ùëñ,ùëó)from the neuronsùë£ùëñ‚àí1,ùëòin layerùëñ‚àí1. A DNN computes the output of a given input by propagating it through the network, where the value of each neuron is calculated by applying an activation function to the weighted sum of the neuron values from the preceding layer. Formally, a DNN is a function ùëÅ(ùíô)defined by: ùëÅ(ùíô)=ùëä‚Ñìùíó‚Ñì‚àí1+ùíÉ‚Ñì, where ùíó0=ùíô,ùíóùëñ=ùúé(ùëäùëñùíóùëñ‚àí1+ùíÉùëñ)for1‚â§ùëñ<‚Ñì,ùëäùëñandùíÉùëñare respectively the weight matrix and bias vector associated with layer ùëñ, andùúéis an activation function applied in an elementwise manner. In this paper, we focus on the most commonly used ReLU activation function ùëÖùëíùêøùëà(ùë•)=max(ùë•,0). The notation ubùëÅ(ùë£ùëñ,ùëó)(resp., lbùëÅ(ùë£ùëñ,ùëó)) denotes an upper (resp., lower )bound ofùë£ùëñ,ùëóinùëÅ, that is, lbùëÅ(ùë£ùëñ,ùëó)‚â§ùë£ùëñ,ùëó‚â§ubùëÅ(ùë£ùëñ,ùëó), w.r.t. a given input space. 2.2 Formal Verification of DNNs Given a DNN ùëÅ, a property ùëÉover the inputs ùíôand a property ùëÑover outputs ùíö=ùëÅ(ùíô), a verification problem ùúë=‚ü®ùëÅ,ùëÉ,ùëÑ‚ü©is to check whether any input ùíôthat fulfilsùëÉwill result in an output ùíö=ùëÅ(ùíô)that satisfies ùëÑ, whereùëÉforms the input space of interests. As usual, we consider input properties in conjunctions of linear constraints. W.l.o.g., we assume that the output layer only contains a single neuron ùë¶, and the output property is of the form ùë¶‚â§ùëêfor a given constant ùëê[Elboher et al. 2020]. Given a verification problem ùúë=‚ü®ùëÅ,ùëÉ,ùëÑ‚ü©, a DNN ¬ØùëÅis an overapproximation ofùëÅifùëÅ(ùíô)‚â§ ¬ØùëÅ(ùíô)for every ùíôthat fulfilsùëÉ. Note thatùëÅ(ùíô)‚â§ ¬ØùëÅ(ùíô)implies that ¬ØùëÅ(ùíô)‚â§ùëê‚áíùëÅ(ùíô)‚â§ùëê. An input ùíôis acounterexample ofùëÅifùíôfulfilsùëÉbutùëÅ(ùíô)>ùëê. A counterexample ùíôof¬ØùëÅisspurious onùëÅifùëÅ(ùíô)‚â§ùëê. 3 OVERVIEW OF OUR APPROACH Our CEGARbased approach is described in Algorithm 1, which invokes two vital components: the abstraction procedure Abstract and the refinement procedure Refine . Given a verification problem ‚ü®ùëÅ,ùëÉ,ùëÑ‚ü©, Algorithm 1 returns either YES indicating that the problem holds or a counterexample cexas the witness of the violation.4 Liu et al. Algorithm 1 CEGARBased Framework of Our Approach Input: A verification problem ‚ü®ùëÅ,ùëÉ,ùëÑ‚ü© Output: YES if the problem holds; otherwise a counterexample 1:Build an abstract DNN ¬ØùëÅ‚ÜêAbstract(ùëÅ,ùëÉ) 2:while Verify (‚ü®¬ØùëÅ,ùëÉ,ùëÑ‚ü©) = NO do 3: Extract a counterexample cex 4: ifcexis a counterexample of ‚ü®ùëÅ,ùëÉ,ùëÑ‚ü©then 5: return cex 6: else ¬ØùëÅ‚ÜêRefine(¬ØùëÅ,cex) 7:return YES To solve a verification problem ‚ü®ùëÅ,ùëÉ,ùëÑ‚ü©, we first build an overapproximation ¬ØùëÅofùëÅby invoking Abstract (line 1). Abstract first transforms ùëÅinto an equivalent DNN ùëÅ‚Ä≤such that increasing the value of each single hidden neuron in ùëÅ‚Ä≤either increases or decreases the network output, thus establishing monotonicity between the value of each hidden neuron and the network‚Äôs output. Then, we build the overapproximation ¬ØùëÅfrom the DNN ùëÅ‚Ä≤by a synergistic integration of two novel abstraction primitives: Merge andFreeze , where Merge merges two neurons with the same monotonicity into a single one while Freeze deletes a neuron from the network. Both Merge andFreeze build an overapproximation of a given DNN, thus provide soundness guarantees (i.e., challenge C1). To address C2, abstraction primitives are iteratively applied according to a strategy until a given accuracy threshold is reached, where the strategy is designed to minimize the loss of accuracy during each iteration, thus reduces the network size as much as possible when sacrificing the same accuracy. To achieve this, we measure the loss of accuracy induced by applying abstraction primitives. Next, we check if the verification problem ‚ü®¬ØùëÅ,ùëÉ,ùëÑ‚ü©holds or not by invoking a verification engine Verify (line 2). If‚ü®¬ØùëÅ,ùëÉ,ùëÑ‚ü©holds, we can conclude that the original verification problem ‚ü®ùëÅ,ùëÉ,ùëÑ‚ü© holds as well, because ¬ØùëÅoverapproximates ùëÅ. Otherwise, a counterexample cexis extracted from ¬ØùëÅ. Ifcexis a genuine counterexample of ‚ü®ùëÅ,ùëÉ,ùëÑ‚ü©,cexis reported as the witness of the violation to the property ùëÑ(line 5). If cexis a spurious counterexample of ‚ü®ùëÅ,ùëÉ,ùëÑ‚ü©,¬ØùëÅis refined to exclude cex by invoking Refine (line 6). Refine is also a synergistic integration of two novel refinement primitives: Split andRecover , where Split splits an abstract neuron into two while Recover gets back a deleted neuron. However, applying Split orRecover without any restriction does not necessarily yield an overapproximation of the original DNN ùëÅ(i.e., challenge C3). To solve this issue, Split andRecover are applied according to a dependency graph, a novel notion proposed to characterize their dependency. To address C4, refinement primitives are iteratively applied according to a strategy until the spurious counterexample cexis excluded, where the strategy is designed to regain the most accuracy during each iteration, thus keeps the network size as small as possible when restoring the same amount of accuracy. To achieve this, we introduce a profit function parameterized by the counterexample cex to measure the accuracy that can be restored via refinement primitives on different neurons. 4 NETWORK ABSTRACTION In this section, we present our abstraction procedure Abstract . 4.1 Preprocessing Before to abstract a given DNN, all hidden neurons should be classified into incordec, indicating their monotonic effect on the network‚Äôs output. A neuron is incif increasing its value, whileAbstraction and Refinement: Towards Scalable and Exact Verification of Neural Networks 5 ùë•1 ùë•2ùë£1,1 ùë£1,2ùë£+ 2,1 ùë£‚àí 2,2 ùë£+ 2,3ùë¶1 4 22 4 12 1 3 (a) Initial Networkùë•1 ùë•2ùë£+ 1,1 ùë£‚àí 1,1 ùë£1,2ùë£+ 2,1 ùë£‚àí 2,2 ùë£+ 2,3ùë¶1 14 4 2 22 4 12 1 3 (b) After Preprocessing ùë£1,1 Fig. 1. Example for Preprocessing keeping all the inputs unchanged, increases the network‚Äôs output. Symmetrically, a neuron is decif decreasing its value increases the network‚Äôs output. However, not all hidden neurons in an arbitrary DNN can be simply classified. To achieve this, we transform the given DNN ùëÅinto an equivalent DNNùëÅ‚Ä≤, namely,ùëÅ(ùíô)=ùëÅ‚Ä≤(ùíô)for any input ùíô, during which the classification is performed on ùëÅ‚Ä≤. The preprocessing procedure starts with setting the single output ùë¶asinc, and proceeds back wards layer by layer. Suppose that neurons in layer ùëñ+1have been classified as incordec. A hidden neuron ùë£ùëñ,ùëóin layerùëñwill be split into two new neurons ùë£+ ùëñ,ùëóandùë£‚àí ùëñ,ùëóby copying all incoming edges ofùë£ùëñ,ùëó. As for the outgoing edges, ùë£+ ùëñ,ùëóonly keeps positiveweighted ones pointing from ùë£ùëñ,ùëó toincneurons and negativeweighted ones pointing from ùë£ùëñ,ùëótodecneurons. Similarly, ùë£‚àí ùëñ,ùëóonly keeps positiveweighted ones from ùë£ùëñ,ùëótodecneurons and negativeweighted ones from ùë£ùëñ,ùëótoinc neurons. The new neurons ùë£+ ùëñ,ùëóandùë£‚àí ùëñ,ùëóare now respectively incanddecneurons. Formally, for every neuron ùë£ùëñ‚àí1,ùëòin layerùëñ‚àí1, we set: ùë§(ùë£ùëñ‚àí1,ùëò,ùë£+ ùëñ,ùëó)=ùë§(ùë£ùëñ‚àí1,ùëò,ùë£‚àí ùëñ,ùëó)=ùë§(ùë£ùëñ‚àí1,ùëò,ùë£ùëñ,ùëó). And for every neuron ùë£ùëñ+1,ùëòin layerùëñ+1ofùëÅ‚Ä≤, we set: ùë§(ùë£+ ùëñ,ùëó,ùë£ùëñ+1,ùëò)=ùë§(ùë£ùëñ,ùëó,ùë£ùëñ+1,ùëò),ifùë§(ùë£ùëñ,ùëó,ùë£ùëñ+1,ùëò)¬∑ùë†(ùë£ùëñ+1,ùëò)>0; 0, otherwise ùë§(ùë£‚àí ùëñ,ùëó,ùë£ùëñ+1,ùëò)=ùë§(ùë£ùëñ,ùëó,ùë£ùëñ+1,ùëò),ifùë§(ùë£ùëñ,ùëó,ùë£ùëñ+1,ùëò)¬∑ùë†(ùë£ùëñ+1,ùëò)<0; 0, otherwise whereùë†(ùë£)=1ifùë£is an incneuron and ùë†(ùë£)=‚àí1ifùë£is adecneuron. Furthermore, the biases of new neurons are copied from ùë£ùëñ,ùëó, i.e.,ùëè(ùë£+ ùëñ,ùëó)=ùëè(ùë£‚àí ùëñ,ùëó)=ùëè(ùë£ùëñ,ùëó). Intuitively, when the neuron ùë£+ ùëñ,ùëóincreases, all the inc(resp., dec) neurons in layer ùëñ+1increase (resp., decrease) since they connect to ùë£+ ùëñ,ùëóby positive (resp., negative) weights. Both the increment ofincneurons and decrement of decneurons in layer ùëñ+1will increase the network‚Äôs output by definition. Hence the neuron ùë£+ ùëñ,ùëóisinc. The case of ùë£‚àí ùëñ,ùëófollows similarly. Example 4.1. Consider the DNN shown in Figure 1(a), where the last two layers have been preprocessed. Consider neuron ùë£1,1whose bias is‚àí1and the related weights are shown. The DNN after preprocessing ùë£1,1is depicted in Figure 1(b), where: ùë£1,1is split into two neurons ùë£+ 1,1andùë£‚àí 1,1 that have the same incoming edges and biases as ùë£1,1,ùë£+ 1,1keeps the outgoing edge of weight 2 pointing to the incneuronùë£+ 2,1,ùë£‚àí 1,1keeps the outgoing edge of weight 4pointing to the decneuron ùë£‚àí 2,2and the outgoing edge of weight ‚àí1pointing to the incneuronùë£+ 2,3. The neurons ùë£+ 1,1andùë£‚àí 1,1 are now respectively incanddec.6 Liu et al. After the preprocessing of all the hidden neurons, we obtain a new DNN ùëÅ‚Ä≤that is equivalent to ùëÅ, in which each hidden neuron is classified into either incordec. Thus, we have: Lemma 4.2. Any DNNùëÅcan be transformed into an equivalent DNN ùëÅ‚Ä≤where each hidden neuron is classified into either incordec, by increasing the network size by a factor of at most 2. By Lemma 4.2, we hereafter assume that each given DNN has been preprocessed and all its hidden neurons have been classified into inc/dec. 4.2 Abstraction Primitives As aforementioned, we propose two novel abstraction primitives: Merge andFreeze , to construct overapproximations of DNNs. TheMerge primitive is to merge a pair of hidden neurons with same label inc/decin the same layer into a single one. We seek to increase the values of incneurons and decrease the values of decneurons, ensuring that the network‚Äôs output always increases. Suppose we are constructing an overapproximation ¬ØùëÅofùëÅ. Let ¬Øùë§and ¬Øùëèdenote respectively the weights and biases in the constructed network ¬ØùëÅ. The Merge primitive merges two hidden incneuronsùë£ùëñ,ùëóandùë£ùëñ,ùëòinto a new incneuronùë£ùëñ,ùë°via the following steps: (1) all edges connecting to ùë£ùëñ,ùëóorùë£ùëñ,ùëòare removed; (2) neurons ùë£ùëñ,ùëóandùë£ùëñ,ùëòare replaced by a new neuron ùë£ùëñ,ùë°; (3) from each neuron ùë£ùëñ‚àí1,ùëùin the preceding layer, an incoming edge to ùë£ùëñ,ùë°is added as ¬Øùë§(ùë£ùëñ‚àí1,ùëù,ùë£ùëñ,ùë°)=max{ùë§(ùë£ùëñ‚àí1,ùëù,ùë£ùëñ,ùëó), ùë§(ùë£ùëñ‚àí1,ùëù,ùë£ùëñ,ùëò)}; (4) to each neuron ùë£ùëñ+1,ùëûin the succeeding layer, an outgoing edge from ùë£ùëñ,ùë°is added as ¬Øùë§(ùë£ùëñ,ùë°,ùë£ùëñ+1,ùëû)=ùë§(ùë£ùëñ,ùëó,ùë£ùëñ+1,ùëû)+ùë§(ùë£ùëñ,ùëò,ùë£ùëñ+1,ùëû); (5) the bias of ùë£ùëñ,ùë°is¬Øùëè(ùë£ùëñ,ùë°)=max{ùëè(ùë£ùëñ,ùëó), ùëè(ùë£ùëñ,ùëò)}. Intuitively, the max operation in steps (3) and (5) guarantees that ùë£ùëñ,ùë°is no less than the original neuronsùë£ùëñ,ùëóandùë£ùëñ,ùëò. By the definition of outgoing edges, this amounts to increasing or keeping ùë£ùëñ,ùëó andùë£ùëñ,ùëòinùëÅ. Sinceùë£ùëñ,ùëóandùë£ùëñ,ùëòare both inc, it ensures that the output either does not change or is increased by Merge . Similarly, the Merge primitive for decneurons is defined except that max is replaced by min. A neuron produced by Merge is called an abstract neuron , otherwise an atomic neuron . Example 4.3. Consider the incneuronsùë£1andùë£2of the DNN ùëÅshown in Figure 2(a). After mergingùë£1andùë£2, we obtain the DNN ¬ØùëÅ1shown in Figure 2(b), where for the abstract neuron of(ùë£1,ùë£2), the weight of its incoming edge from ùë•1is4=max{1,4}, its bias is 2=max{1,2}, and the weight of its outgoing edge to ùë¶is3=2+1. Given an input ùíô0=(1,1)ùëá, we have ¬ØùëÅ1(ùíô0)=15>5=ùëÅ(ùíô0). The following lemma justifies the soundness of Merge . Lemma 4.4. Let¬ØùëÅbe the DNN constructed from ùëÅby a single application of Merge . It holds that ¬ØùëÅ(ùíô)‚â•ùëÅ(ùíô)for each input ùíô. One application of Merge reduces the network size by 1, but may decrease the network‚Äôs accuracy. The induced inaccuracy sometimes can be considerable, for instance, when the two weights in the max operation have a big difference as in Example 4.3. To avoid this issue, we introduce another abstraction primitive Freeze , to freeze hidden neurons using constants. Consider a hidden neuron ùë£ùëñ,ùëóand a constant ùëé. Ifùëéis an upper bound of ùë£ùëñ,ùëó, then freezing ùë£ùëñ,ùëóbyùëéamounts to increasing or keeping ùë£ùëñ,ùëó. Thus, the network‚Äôs output is guaranteed to non decrease when ùë£ùëñ,ùëóisinc. Similarly, if ùëéis a lower bound of the decneuronùë£ùëñ,ùëó, the network‚ÄôsAbstraction and Refinement: Towards Scalable and Exact Verification of Neural Networks 7 ùë•1 ùë•2ùë£1 ùë£2 ùë£3ùë¶1 2 001 4 2 1 3 22 1 1 (a) Initial Network ùëÅùë•1 ùë•2ùë£1 ùë£2 ùë£3ùë¶2 004 2 1 23 1 (b)¬ØùëÅ1:Mergeùë£1andùë£2inùëÅ ùë•1 ùë•2ùë£1 ùë£2 ùë£3ùë¶2 2 00 4 2 3 22 1 1 (c)¬ØùëÅ2:Freezeùë£1inùëÅùë•1 ùë•2ùë£2 ùë£3ùë¶2 04 4 2 3 21 1 (d)¬ØùëÅ‚Ä≤ 2:Propagateùë£1in¬ØùëÅ2 Fig. 2. Example for Abstraction Primitives output is also guaranteed to nondecrease by applying Freeze . Formally, Freeze constructs an overapproximation ¬ØùëÅofùëÅas follows: for a hidden neuron ùë£ùëñ,ùëó, (1) all incoming edges to ùë£ùëñ,ùëóare removed, i.e., ¬Øùë§(ùë£ùëñ‚àí1,ùëù,ùë£ùëñ,ùëó)=0,for eachùë£ùëñ‚àí1,ùëùin layerùëñ‚àí1; (2) the value of the neuron ùë£ùëñ,ùëóis replaced by a constant as ¬Øùëè(ùë£ùëñ,ùëó)=ubùëÅ(ùë£ùëñ,ùëó),ifùë£ùëñ,ùëóisinc; lbùëÅ(ùë£ùëñ,ùëó),ifùë£ùëñ,ùëóisdec. Intuitively, Freeze produces neurons whose all incoming edges are weighted by 0and their values are indeed their biases ¬Øùëè(ùë£ùëñ,ùëó). Neurons introduced by Freeze are called constant neurons . Example 4.5. Assume that the range of the incneuronùë£1in Figure 2(a) is[0,2]. Then the network ¬ØùëÅ2constructed from ùëÅbyFreeze onùë£1is shown in Figure 2(c). All the incoming edges toùë£1are removed. Its bias is replaced with its upper bound 2. Given the input ùíô0=(1,1)ùëá, ¬ØùëÅ2(ùíô0)=7<15=¬ØùëÅ1(ùíô0)shows that Freeze can be more accurate than Merge in some situations. The following lemma provides the soundness of Freeze . Lemma 4.6. Let¬ØùëÅbe the DNN constructed from ùëÅby a single application of Freeze . It holds that ¬ØùëÅ(ùíô)‚â•ùëÅ(ùíô)for each input ùíô. One may notice that currently Freeze does not reduce the network size. To eliminate constant neurons introduced by Freeze , we propose a new procedure Propagate . Consider a constant neuronùë£ùëñ,ùëóin the DNN ùëÅ,Propagate works as follows: (1)to propagate the value of ùë£ùëñ,ùëóto the succeeding layer ùëñ+1, for each neuron ùë£ùëñ+1,ùëûin layerùëñ+1, we set: ùëè‚Ä≤(ùë£ùëñ+1,ùëû)=ùëè(ùë£ùëñ+1,ùëû)+ùë§(ùë£ùëñ,ùëó,ùë£ùëñ+1,ùëû)¬∑ùëè(ùë£ùëñ,ùëó); (2) the constant neuron ùë£ùëñ,ùëóand related edges are removed.8 Liu et al. Example 4.7. Consider the constant neuron ùë£1in the DNN ¬ØùëÅ2shown in Figure 2(c). By applying Propagate toùë£1,ùë£1is removed and its value 2is propagated to the neuron ùë¶, resulting in the DNN shown in Figure 2(d). By definition, the obtained DNN ùëÅ‚Ä≤after Propagate is equivalent to ùëÅ. Thus, we get: Lemma 4.8. LetùëÅ‚Ä≤be the DNN constructed from ùëÅby a single application of Propagate on a constant neuron. It holds that ùëÅ‚Ä≤(ùíô)=ùëÅ(ùíô)for each input ùíô. Freeze andPropagate can cooperate to delete hidden neurons, hence reducing network size. We design Propagate as an individual procedure instead of merging with Freeze due to the following reasons: (i) to improve abstraction efficiency, Propagate is invoked only once before invoking the verification engine Verify ; (ii) to keep Freeze local, i.e., without affecting the succeeding layer, as locality makes abstraction steps less dependent on each other, thus allows us to extend abstraction primitives further in Section 4.3. Following Lemmas 4.4, 4.6 and 4.8, we conclude that our two abstraction primitives Merge and Freeze (followed by Propagate ) do construct overapproximations. Corollary 4.9. Let¬ØùëÅbe the DNN obtained from ùëÅby iteratively applying abstraction primitives: Merge and/or Freeze (followed by Propagate ). It holds that ¬ØùëÅ(ùíô)‚â•ùëÅ(ùíô)for each input ùíô. Given a DNN ùëÅto verify, after iteratively applying our abstraction primitives, we get an abstract DNN ¬ØùëÅ. Corollary 4.9 ensures that ¬ØùëÅis an overapproximation of ùëÅ, namely, if the specified property holds for ¬ØùëÅ, it holds as well for ùëÅ. Therefore, we solve the challenge C1. 4.3 Generalizing the Freeze Primitive Starting from a DNN ùëÅ0, iterating the application of abstraction primitives derives a sequence of DNNsùëÅ1,ùëÅ2,¬∑¬∑¬∑,ùëÅùëò. Corollary 4.9 guarantees that ùëÅùëóis an overapproximation of ùëÅùëñfor any 0‚â§ùëñ‚â§ùëó‚â§ùëò. Recall that when applying Freeze on some neuron in ùëÅùëñ, its bounds with respect to current DNN ùëÅùëñis required by definition. Since the structures of DNNs change along the sequence of DNNs due to abstraction, the bounds in ùëÅùëñmay be different from those in ùëÅùëóifùëñ‚â†ùëó. To apply the abstraction primitive Freeze , a naive approach is to calculate the bounds each time before applying Freeze . The calculation is no doubt a considerable overhead. To mitigate this issue, we generalize the abstraction primitive Freeze based on the following observation. Observe that an abstraction primitive applied to layer ùëñdoes not change the values of neurons in layersùëó<ùëñ, thus their bounds. A more efficient way is to calculate the bounds only once in the initial network ùëÅ0, and all abstraction primitives are applied backwards layer by layer. That is, an abstraction primitive to layer ùëñmust be applied after the applications of primitives to layers ùëó>ùëñ. This constrained order enables all Freeze primitives to make use of the bounds calculated in the DNN ùëÅ0, thus avoids the considerable calculation overhead, at the cost of flexibility when performing abstraction. However, it is sometimes too restricted to achieve a good abstraction. To gain more flexibility while preserving the efficiency, we generalize the primitive Freeze as follows. A generalized primitive FreezeùëÄ +ofFreeze is defined to freeze a neuron w.r.t. a given DNN ùëÄ. We emphasize that FreezeùëÄ +is parameterized by the given DNN ùëÄ. To construct a network ¬ØùëÅfrom ùëÅby applying FreezeùëÄ +on a hidden neuron ùë£ùëñ,ùëóofùëÅ,FreezeùëÄ +works almost the same as Freeze except that FreezeùëÄ +leverages bounds w.r.t. the given DNN ùëÄinstead ofùëÅ. More specifically, FreezeùëÄ +works as follows: (1) all incoming edges to ùë£ùëñ,ùëóare removed, i.e., ¬Øùë§(ùë£ùëñ‚àí1,ùëù,ùë£ùëñ,ùëó)=0,for eachùë£ùëñ‚àí1,ùëùin layerùëñ‚àí1;Abstraction and Refinement: Towards Scalable and Exact Verification of Neural Networks 9 (2) the value of the neuron ùë£ùëñ,ùëóis replaced by a constant as ¬Øùëè(ùë£ùëñ,ùëó)=ubùëÄ(ùë£ùëñ,ùëó),ifùë£ùëñ,ùëóisinc; lbùëÄ(ùë£ùëñ,ùëó),ifùë£ùëñ,ùëóisdec. Compared to Freeze , the bounds ubùëÄ(ùë£ùëñ,ùëó)and lbùëÄ(ùë£ùëñ,ùëó)are used instead of ubùëÅ(ùë£ùëñ,ùëó)and lbùëÅ(ùë£ùëñ,ùëó). As a result, Lemma 4.6 cannot be generalized to the new primitive FreezeùëÄ +. That is, the con structed ¬ØùëÅdoes not necessarily overapproximate ùëÅ. Nevertheless, we can show that Lemma 4.6 can be generalized to FreezeùëÄ +ifFreezeùëÄ +conforms to the definition of Freeze , i.e., ubùëÄ(ùë£ùëñ,ùëó) (resp., lbùëÄ(ùë£ùëñ,ùëó)) is also an upper (resp., lower) bound of ùë£ùëñ,ùëóinùëÅ. Thus, we have: Lemma 4.10. Given two DNNs ùëÅandùëÄ, let ¬ØùëÅbe the constructed network from ùëÅbyFreezeùëÄ +on neuronùë£.¬ØùëÅ(ùíô)‚â•ùëÅ(ùíô)holds for each input ùíô, if the upper bound ubùëÄ(ùë£)(resp., lower bound lbùëÄ(ùë£)) is also an upper (resp., lower) bound of ùë£inùëÅ. Given a DNN ùëÄ,FreezeùëÄ +is called a quasiabstraction primitive w.r.t. ùëÄ, where the prefix ""quasi"" indicates that it is not yet ready to be used as an abstraction primitive, since it does not have a strong property like Lemma 4.6. To leverage FreezeùëÄ +in the abstraction procedure, we define an abstraction step as the instance of applying an abstraction primitive on one or two specific neurons. Abstraction steps thus relate abstraction primitives to their target neurons. We denote abstraction steps by abstract steps. Similarly, we have Merge ,Freeze andFreezeùëÄ +steps. We refer to Merge andFreezeùëÄ +steps together as quasiabstraction steps w.r.t. ùëÄ, denoted by qabstractùëÄsteps. The qabstractùëÄ steps have the following important property: Lemma 4.11. Given two DNNs ùëÅandùëÄ, let ¬ØùëÅbe the network constructed from ùëÅvia iteratively applying the sequence ùúèofqabstractùëÄsteps. A permutation ùúè‚Ä≤ofùúècan be constructed such that (i) each FreezeùëÄ +step precedes all Merge steps inùúè‚Ä≤; (ii) all FreezeùëÄ +steps inùúè‚Ä≤are applied backwards layer by layer; (iii) the subsequence of Merge steps inùúè‚Ä≤is identical to that in ùúè; (iv) the network ¬ØùëÅ‚Ä≤obtained by applying ùúè‚Ä≤onùëÅis identical to the network ¬ØùëÅ. We callùúè‚Ä≤animplicit order orimplicit sequence ofùúè. Lemma 4.11 indicates that a series of qabstractùëÄsteps can be reordered, such that all FreezeùëÄ + steps are firstly performed backwards layer by layer, and then the Merge steps are performed. Moreover, the reordering does not change the resulting network. Selecting the initial target DNN ùëÅasùëÄused for the generalized primitive FreezeùëÄ +, each FreezeùëÅ +step in the implicit sequence builds an overapproximation by Lemma 4.10. The following theorem justifies that qabstractùëÅ steps, therefore FreezeùëÅ +, can be leveraged to perform abstraction: Theorem 4.12. Let¬ØùëÅbe the DNN constructed from ùëÅby a series of qabstractùëÅsteps. It holds that ¬ØùëÅ(ùíô)‚â•ùëÅ(ùíô)for each input ùíô. To abstract a given DNN ùëÅ, Theorem 4.12 guarantees that we only need to calculate the bounds of neurons once on the initial ùëÅ. The quasiabstraction primitive FreezeùëÅ +can be used for abstraction instead of Freeze . In the abstraction procedure, primitives Merge andFreezeùëÅ +can be applied to any neuron in any order to construct overapproximations. The soundness still holds by Theorem 4.12. In the rest of paper, since we will always use the initial network ùëÅfor the generalized primitive FreezeùëÅ +and the calculation of bounds, for the sake of simplicity, we use the notation Freeze+for FreezeùëÅ +. And when referring to abstraction steps/primitives , we now mean Merge andFreeze+, thanks to Theorem 4.12.10 Liu et al. 4.4 Abstraction Strategy Having only abstraction primitives is not enough to accomplish the abstraction procedure due to challenge C2, i.e., reducing the network size as much as possible while preserving accuracy as much as possible. To build an initial abstraction addressing challenge C2, two questions have to be answered: what should be done for a single abstraction step andhow many steps should be performed? The objective for the first question is to introduce less inaccuracy at each abstraction step, thus admitting more abstraction steps and reducing the size more, when sacrificing the same accuracy. For this purpose, we propose to first locate a less important neuron and then abstract it, where a neuron is less important if it contributes less to the network‚Äôs output. We measure the importance of neurons by their values, where the value ùëâ(ùë£ùëñ,ùëó)of a hidden neuron ùë£ùëñ,ùëóis estimated using the mean of its upper and lower bounds, i.e., ùëâ(ùë£ùëñ,ùëó)=1 2(ub(ùë£ùëñ,ùëó)+lb(ùë£ùëñ,ùëó)). After a neuron ùë£ùëñ,ùëówith the minimum estimated value ùëâ(ùë£ùëñ,ùëó)is found, we need decide which abstraction primitive‚Äì Merge orFreeze+‚Äìshould be applied to minimize the loss of accuracy. Therefore, we measure the loss of accuracy induced by abstraction primitives, based on which abstraction primitive is chosen. The lossùêøf(ùë£ùëñ,ùëó)of accuracy by applying Freeze+on a neuron ùë£ùëñ,ùëóis measured by the difference between the estimated value ùëâ(ùë£ùëñ,ùëó)ofùë£ùëñ,ùëóand the constant ¬Øùëè(ùë£ùëñ,ùëó)used for freezing ùë£ùëñ,ùëó: ùêøf(ùë£ùëñ,ùëó)=|¬Øùëè(ùë£ùëñ,ùëó)‚àíùëâ(ùë£ùëñ,ùëó)|. As applying Merge on two neurons ùë£ùëñ,ùëóandùë£ùëñ,ùëòproduces an abstract neuron ùë£ùëñ,ùë°, the loss ùêøm(ùë£ùëñ,ùëó,ùë£ùëñ,ùëò)of accuracy by applying Merge onùë£ùëñ,ùëóandùë£ùëñ,ùëòshould depend on the changes on weights as well as the values of both neurons. Thus, a linear combination of the estimated values is used to estimate ùêøm(ùë£ùëñ,ùëó,ùë£ùëñ,ùëò): ùêøm(ùë£ùëñ,ùëó,ùë£ùëñ,ùëò)=ùëÖ(ùë£ùëñ,ùëó,ùë£ùëñ,ùë°)¬∑ùëâ(ùë£ùëñ,ùëó)+ùëÖ(ùë£ùëñ,ùëò,ùë£ùëñ,ùë°)¬∑ùëâ(ùë£ùëñ,ùëò) where each coefficient ùëÖ(¬∑)is a ratio characterizing changes on the weights of incoming edges to ùë£ùëñ,ùë°: ùëÖ(ùë£ùëñ,ùëó,ùë£ùëñ,ùë°)=√ç ùëù|¬Øùë§(ùë£ùëñ‚àí1,ùëù,ùë£ùëñ,ùë°)‚àíùë§(ùë£ùëñ‚àí1,ùëù,ùë£ùëñ,ùëó)| √ç ùëù|ùë§(ùë£ùëñ‚àí1,ùëù,ùë£ùëñ,ùëó)|. Based on the above loss measurements, we propose a valueguided abstraction strategy, described in Algorithm 2, to synergistically apply abstraction primitives. It determines which abstraction step should be chosen at the current iteration. It starts by selecting the neuron with the minimum estimated value ùëâ(ùë£ùëñ,ùëó)as the target neuron (line 1). Then it chooses among all available abstraction steps the one that loses the least accuracy (lines 3‚Äì7). At the end, this optimum abstraction step is applied to the network ùëÅresulting in an overapproximation ¬ØùëÅ(line 8). Furthermore, the mapping ùëâ(¬∑)is updated accordingly for next use. For the second question in generating the initial abstraction, we adopt the terminating condition proposed in [Elboher et al .2020]. A set ùëãof inputs satisfying the input property ùëÉis sampled before applying abstraction. The Abstract procedure iteratively applies abstraction steps to build a sequence of overapproximations ùëÅ1,ùëÅ2,¬∑¬∑¬∑,ùëÅùëòaccording to the valueguided abstraction strategy (i.e., Algorithm 2) until ùëÅùëò(ùíô)for some input ùíô‚ààùëãviolates the output property ùëÑ. Remark that the valueguided abstraction strategy together with the terminating condition is a tradeoff for the challenge C2.Abstraction and Refinement: Towards Scalable and Exact Verification of Neural Networks 11 Algorithm 2 ValueGuided Abstraction Strategy Input: A DNNùëÅ, a mapping ùëâestimating values Output: An overapproximation ¬ØùëÅofùëÅ, updatedùëâ 1:Selectùë£ùëñ,ùëówith the minimum estimated value ùëâ(ùë£ùëñ,ùëó) 2:minLoss‚Üê‚àû ,bestStep‚Üê‚ä• 3:foreach hidden neuron ùë£ùëñ,ùëòof same label as ùë£ùëñ,ùëódo 4: ifùêøm(ùë£ùëñ,ùëó,ùë£ùëñ,ùëò)<minLoss then 5: minLoss‚Üêùêøm(ùë£ùëñ,ùëó,ùë£ùëñ,ùëò),bestStep‚ÜêMerge(ùë£ùëñ,ùëó,ùë£ùëñ,ùëò) 6:ifùêøf(ùë£ùëñ,ùëó)<minLoss then 7: minLoss‚Üêùêøf(ùë£ùëñ,ùëó),bestStep‚ÜêFreeze+(ùë£ùëñ,ùëó) 8:Apply bestStep onùëÅto construct ¬ØùëÅ 9:Updateùëâaccording to bestStep 10:return ¬ØùëÅ,ùëâ 5 NETWORK REFINEMENT In this section, we present our refinement procedure Refine . 5.1 Refinement Primitives Given a verification problem ‚ü®ùëÅ,ùëÉ,ùëÑ‚ü©and a counterexample cexof¬ØùëÅwhich is spurious on ùëÅ, to address challenge C3, the goal of refining an overapproximation ¬ØùëÅof the DNN ùëÅis defined to construct a network ¬ØùëÅ‚Ä≤satisfying the following condition: ¬ØùëÅ(ùíô)‚â• ¬ØùëÅ‚Ä≤(ùíô)‚â•ùëÅ(ùíô)for each ùíôand ¬ØùëÅ‚Ä≤(cex)satisfiesùëÑ. That means refinement primitives should construct a DNN ¬ØùëÅ‚Ä≤overapproximating ùëÅ, while ¬ØùëÅ‚Ä≤is itself overapproximated by ¬ØùëÅto exclude the spurious counterexample cexofùëÅ. We define refinement primitives as the inverses of abstraction primitives. Particularly, refinement steps , the instances of refinement primitives, are the inverses of abstraction steps. Therefore, we introduce two refinement primitives: Split andRecover , corresponding to the abstraction primitives Merge andFreeze+, respectively. The Split primitive splits an abstract neuron back into two neurons that were merged by Merge during abstraction and the Recover primitive recovers a constant neuron into the status before Freeze+. Now the question is, can we freely choose any abstract or constant neuron in ¬ØùëÅto apply a refinement step without damaging soundness (i.e., challenge C3), like what we do when applying an abstraction step? Unfortunately, the answer is negative. Example 5.1. Let us consider the DNN ùëÅ0shown in Figure 3, where all neurons are inc. Assume all biases are 0. By iteratively applying the abstraction steps Merge(ùë£3,ùë£4)andMerge(ùë£1,ùë£2)(resp. Merge(ùë£1,ùë£2)andMerge(ùë£3,ùë£4)) onùëÅ0, we obtain the DNN ¬ØùëÅ2(resp. ¬ØùëÅ4) as depicted. It is easy to see that ¬ØùëÅ2and ¬ØùëÅ4are different. Example 5.1 shows that different orders of abstraction steps may result in different over approximations. Conversely, to reverse the effects of the abstraction steps, the refinement steps must follow some specific order as well. Recall that given a sequence ùúèof abstraction steps, Lemma 4.11 enables it to be permutated into an implicit sequence ùúè‚Ä≤. When applied, ùúè‚Ä≤produces the same overapproximation as ùúè. Nevertheless, Example 5.1 indicates that the order of refinement steps should be constrained by the order of abstraction steps. This motivates us to introduce a dependency relation between abstraction steps, which restricts the order of refinement steps.12 Liu et al. (ùëÅ0)ùë•1ùë£1 ùë£2ùë£3 ùë£4ùë¶1 13 1 121 1 Merge(ùë£3,ùë£4) Merge(ùë£1,ùë£2) (¬ØùëÅ1)ùë•1ùë£1 ùë£2ùë£3 ùë£4ùë¶1 13 22 (¬ØùëÅ3)ùë•1ùë£1 ùë£2ùë£3 ùë£4ùë¶14 31 1 Merge(ùë£1,ùë£2) Merge(ùë£3,ùë£4) (¬ØùëÅ2)ùë•1ùë£1 ùë£2ùë£3 ùë£4ùë¶1 5 2 (¬ØùëÅ4)ùë•1ùë£1 ùë£2ùë£3 ùë£4ùë¶1 4 2 Fig. 3. Different Orders of Applying Same Merge Steps A straightforward dependency relation can be established on the implicit sequence: each step depends on all steps applied before it. Based on this dependency, refinement steps can be performed backwards along the implicit sequence of abstraction steps, ensuring soundness by Lemmas 4.4 and 4.10. We define the following dependency relation which provides more flexibility for refine ment. Definition 5.2. Given an implicit sequence of abstraction steps ùúè=ùõΩ1ùõΩ2¬∑¬∑¬∑ùõΩùëö. The dependency relation is defined as follows: (i)each stepùõΩùëñapplied in layer ùëòùëñdepends on the Freeze+stepùõΩùëóthat happens in layer ùëòùëó, if ùëó<ùëñandùëòùëó>ùëòùëñ; (ii)theMerge stepùõΩùëñthat merges ùë£andùë£‚Ä≤in layerùëò, depends on (a) all Merge steps producing ùë£andùë£‚Ä≤(if any), and (b) all Merge stepsùõΩùëóat both layers ùëò‚àí1andùëò+1ifùëó<ùëñ. Intuitively, Item (i) ensures that all Freeze+steps at layer ùëòùëóhappen before any abstraction step at layerùëòùëñ<ùëòùëó, so that Lemma 4.10 is applicable. Item (ii) guarantees welldefinedness of the Merge step onùë£andùë£‚Ä≤, because it requires information provided by both Merge steps producing ùë£andùë£‚Ä≤as well as all Merge steps that happened at adjacent layers. Adependency graphGofùúèis a directed acyclic graph derived by the dependency relation, where the vertices are abstraction steps and an edge from ùõΩùëñtoùõΩùëóexists ifùõΩùëñdepends on ùõΩùëó. Thus, we get: Theorem 5.3. Let¬ØùëÅbe the DNN constructed from ùëÅby applying a sequence ùúèof abstraction steps, Gthe dependency graph of the implicit order ùúè‚Ä≤forùúè, and ¬ØùëÅ‚Ä≤the DNN refined from ¬ØùëÅby a refinement stepùõæ. It holds that ¬ØùëÅ(ùíô)‚â• ¬ØùëÅ‚Ä≤(ùíô)‚â•ùëÅ(ùíô)for each input ùíô, ifùõæis the inverse of an abstraction step ùõΩinGthat has no incoming edges. In summary, to refine an overapproximation ¬ØùëÅ, we first construct the implicit sequence ùúè‚Ä≤and the corresponding dependency graph G, respectively. We pick any abstraction step in Gwith no incoming edges, i.e. not depended by others, and perform a corresponding refinement step. By Theorem 5.3, the refined DNN ¬ØùëÅ‚Ä≤in such a way ensures soundness, thus, partially solving challenge C3. Example 5.4. Recall Example 5.1 for the left part in Figure 3. ¬ØùëÅ2is obtained from ùëÅ0by sequence ùúè=[Merge(ùë£3,ùë£4),Merge(ùë£1,ùë£2)], whose implicit sequence ùúè‚Ä≤=ùúèby Lemma 4.11. The corre sponding dependency graph Gcontains only two vertices Merge(ùë£3,ùë£4)andMerge(ùë£1,ùë£2)and anAbstraction and Refinement: Towards Scalable and Exact Verification of Neural Networks 13 Algorithm 3 CounterexampleGuided Refinement Strategy Input:ùëÅ, abstraction ¬ØùëÅ, dependency graph G, counterexample cex Output: Refined network ¬ØùëÅ‚Ä≤, updatedG 1:Extract the set ùê∂of applied abstraction steps from G 2:maxGain‚Üê0,bestStep‚Üê‚ä• 3:foreach candidate step ùë†inùê∂do 4: ifùëÉcex(ùë†)>maxGain then 5: maxGain‚ÜêùëÉcex(ùë†),bestStep‚Üêrefinement step for ùë† 6:Build ¬ØùëÅ‚Ä≤from ¬ØùëÅby applying the refinement step bestStep 7:Update dependency graph G 8:return ¬ØùëÅ‚Ä≤,G edge from Merge(ùë£1,ùë£2)toMerge(ùë£3,ùë£4). To soundly refine ¬ØùëÅ2, only Merge(ùë£1,ùë£2)can be picked to reverse. 5.2 CounterexampleGuided Refinement Similar as the abstraction procedure, to address challenge C4, the following two questions should be considered in the refinement procedure: which available refinement step should be chosen , and how many steps should be performed ? According to Theorem 5.3, any abstraction step in the dependency graph without incoming edges can be chosen for refinement. Thus, there may exist several applicable refinement steps during an iteration of the refinement procedure. Contrary to the abstraction strategy, we expect a refinement step to restore more accuracy, which corresponds to the candidate abstraction step that induced more inaccuracy. Therefore, we estimate the gain of accuracy for reversing a candidate abstraction step ùë†via the following profit function ùëÉcex(¬∑)w.r.t. the spurious counterexample cex, ùëÉcex(ùë†)= |√ç ùëòùë£(ùëò)(cex)‚àí¬Øùë£(cex)|,ifùë†isMerge onùë£(ùëò)‚Äôs producing ¬Øùë£; |ùë£(cex)‚àí¬Øùëè(¬Øùë£)|, ifùë†isFreeze+onùë£producing ¬Øùë£; whereùë£(ùëò)‚Äôs denote the atomic neurons merged to ¬Øùë£,ùë£(cex)denotes the exact value of a neuron ùë£ under the input cex. Based onùëÉcex(¬∑), we propose a counterexampleguided refinement strategy (cf. Algorithm 3), which chooses a candidate refinement step, by which we can regain the most accuracy. However, the strategy in Algorithm 3 does not guarantee that the counterexample cexis ruled out by a single refinement step, i.e., cexis still a counterexample of the refined DNN ¬ØùëÅ‚Ä≤. To solve the second question for the refinement procedure, the routine in Algorithm 3 is repeated until cex is ruled out from the refined DNN. The counterexampleguided refinement strategy, coupled with the terminating condition and refinement primitives, solves challenges C3 and C4. 6 EVALUATION We implement our approach in a tool NARv (Network Abstraction Refinement for verification). NARv utilizes the promising symbolic interval analysis tool ReluVal [Wang et al .2018] for computing the bounds of neurons, while the backend verification engine can be configured with any sound tool that can produce a counterexample when the verification problem does not hold. To evaluate NARv , two promising tools Marabou [Katz et al .2019] and Planet [Ehlers 2017] are integrated as the backend verification engines. Both Marabou andPlanet are sound and complete, thus NARv is sound and complete. Marabou is chosen as the backend verification engine, because14 Liu et al. it is the most efficient tool among 13 tools participating in the 2nd International Verification of Neural Networks Competition (VNNCOMP‚Äô21) [vnn 2021] (cf. Table 5 in the summary and results of VNNCOMP‚Äô21 [Bak et al .2021]). Planet is comparable to Marabou (even better on some benchmarks) [Katz et al. 2019]. The experiments are designed to answer the following research questions: RQ1: Effectiveness . Can NARv boost the sound and complete verification tools Marabou and Planet ? RQ2: Performance . Does NARv outperform CEGARNN [Elboher et al .2020], the only work that supports structureoriented CEGAR? We evaluate NARv on three widelyused benchmarks and datasets: the DNNs from ACAS Xu [Julian et al.2019], the DNNs trained by datasets MNIST [LeCun 1998] and CIFAR10 [Krizhevsky et al . 2009]. The DNNs trained by MNIST andCIFAR10 are relatively large. Not all of complete methods are effective to solve useful verification problems in acceptable time for them [Urban and Min√© 2021]. ACAS Xu , is a collision avoidance system built for unmanned aircrafts. The system consists of 45 realworld DNNs, each of which has 310 neurons including 5 inputs, 6 hidden layers and 5 outputs. The inputs take normalized data from airborne sensors, representing the relative position and speed of intruders. The outputs provide 5 kinds of turning advisories to prevent the aircraft from collision. MNIST , is a standard dataset for handwritten digit recognition. The DNN used in our evaluation is provided by VNNCOMP‚Äô21. It contains 1306 neurons, including 2 hidden layers with 256 neurons per layer. Due to the 28√ó28format of the images, the input layer takes 784 pixels in greyscale and the output layer has 10 neurons producing the classification scores for the 10 possible digits. CIFAR10 , is a colored image dataset that consists of 60000, 32√ó32RGB images in 10 classes (e.g., cat or dog). The DNN used in our evaluation is collected from the benchmarks of the ERAN toolset [Lab 2022]. The size of its hidden layers is 6√ó100. The DNN has 3072 input neurons representing the pixel values of the 3 color channels and 10 outputs as the classification results. The total size is 3682. The properties to be verified are the robustness of DNNs against adversarial examples. We verify whether the classification result for each input on a target DNN remains the same after adding small perturbations onto that input, where the perturbations are limited within a given threshold ùõø using theùêø‚àûnorm [Carlini and Wagner 2017]. All experiments are run on a Linux server with two Intel Xeon Sliver4214 CPUs and 64 GB memory. The timeout is set to 1 hour for each ACAS Xu verification problem as in VNNCOMP‚Äô21, whereas 10 hours for each verification problem on MNIST andCIFAR10 DNNs. The experimental results show that our approach is able to significantly boost the performance and scalability of both Marabou andPlanet and significantly outperforms CEGARNN , the only work that supports structureoriented CEGAR for DNN verification. 6.1 RQ1: Effectiveness Evaluation Setup. To answer RQ1 , we evaluate the effectiveness of NARv on the relatively large networks trained by MNIST andCIFAR10 . Two NARv configurations NARv[M] andNARv[P] are set up respectively with Marabou andPlanet as their backend verification engines. NARv[M] and NARv[P] are then compared with Marabou andPlanet , respectively, on both the MNIST and the CIFAR10 networks. For each network, we verify robustness against 4 perturbation thresholds ùõøranging: from 0.02to0.05for the MNIST network, and from 0.001to0.004for the CIFAR10 network. These thresholds are selected since the robustness threshold is close to 0.06for the MNISTAbstraction and Refinement: Towards Scalable and Exact Verification of Neural Networks 15 Table 1. Effectiveness Evaluation of our Approach on Marabou andPlanet Avg. time (s) #Verified Avg. time (s) #Verified Dataset ùõø NARv[M] Marabou MNIST0.02 99.54 ( ‚ñ≥65.0%) 25 (  ) 60.34 25 0.03 971.70 ( ‚ñº86.3%) 25 (‚ñ≤12%) 7084.99 22 0.04 2458.05 ( ‚ñº85.6%) 25 (‚ñ≤40%) 17063.42 15 0.05 8056.73 ( ‚ñº71.7%) 20 (‚ñ≤52%) 28465.46 7 CIFAR100.001 1581.66 ( ‚ñº82.1%) 12 (  ) 8824.25 12 0.002 12545.33 ( ‚ñº56.0%) 8 (‚ñ≤33%) 28515.69 4 0.003 15241.70 ( ‚ñº57.7%) 7 (‚ñ≤58%) 36000.00 0 0.004 15200.91 ( ‚ñº57.8%) 7 (‚ñ≤58%) 36000.00 0 Dataset ùõø NARv[P] Planet MNIST0.02 118.91 ( ‚ñº67.5%) 25 (  ) 366.39 25 0.03 259.54 ( ‚ñº78.0%) 25 (  ) 1182.32 25 0.04 454.14 ( ‚ñº60.3%) 25 (  ) 1143.16 25 0.05 585.59 ( ‚ñº54.1%) 25 (  ) 1275.57 25 CIFAR100.001 12682.02 ( ‚ñº63.4%) 8 (‚ñ≤58%) 34641.92 1 0.002 19097.04 ( ‚ñº47.0%) 7 (‚ñ≤58%) 36000.00 0 0.003 15249.89 ( ‚ñº57.6%) 3 (‚ñ≤25%) 36000.00 0 0.004 21187.41 ( ‚ñº41.1%) 3 (‚ñ≤25%) 36000.00 0 network, and 0.005forCIFAR10 network, thus yielding interesting yet hard robustness verification problems. There are 25 and 12 verification problems for each perturbation threshold ùõørespectively forMNIST andCIFAR10 . Results on the MNIST network. Table 1 (upper part) reports the results on the MNIST network, where the average verification time in seconds (""Avg. time"") and the numbers of successfully verified problems (""#Verified"") by each tool are depicted. We can observe that NARv[M] andNARv[P] can solve more problems and in general are much faster than Marabou andPlanet , in particular on hard verification problems. This indicates that our approach is able to significantly boost the performance of both Marabou andPlanet in most cases on the MNIST network. The best improvements appear when ùõø=0.03, reducing 86.3%and 78.0%verification time respectively for Marabou andPlanet . In detail, Marabou appears to have a good performance when the perturbation threshold ùõøis small, as the solving space of the verification problem is small. It begins to time out (10 hours) when ùõø‚â•0.03, and the numbers of solved problems become less and less with the increase of ùõø. When ùõø=0.05, it only successfully solves 7 ( 28%) problems out of all the 25 verification problems. In contrast, NARv[M] is able to solve most of the problems for all perturbation thresholds except for ùõø=0.05. Whenùõø=0.05, it solves 20 problems, namely 52%(=(20‚àí7)/25) more than Marabou . In addition, NARv[M] spends 71.7%(‚âà(28465.46‚àí8056.73)/28465.46) less verification time on average when ùõø=0.05. Compared over Planet which is able to solve all the MNIST verification problems as depicted in Table 1, NARv[P] also solves all the problems, meanwhile spends less time on average for all the perturbation thresholds, reducing at least 54.1% verification time. Finally, we should emphasize that verified robustness with large perturbation threshold ùõøis more interesting in practice. Results on the CIFAR10 network. The experimental results on the CIFAR10 network are de picted in Figure 4, where Figure 4(a) (resp. Figure 4(b)) compares the verification time required16 Liu et al. /s49/s48/s48 /s49/s48/s49 /s49/s48/s50 /s49/s48/s51 /s49/s48/s52/s49/s48/s48/s49/s48/s49/s49/s48/s50/s49/s48/s51/s49/s48/s52 /s32/s102/s105/s110/s105/s115/s104/s101/s100 /s32/s116/s105/s109/s101/s111/s117/s116/s32/s32 /s32/s121/s61/s120/s77/s97/s114/s97/s98/s111/s117/s32/s40/s115/s101/s99/s41 /s78/s65/s82/s118/s91/s77/s93/s32/s40/s115/s101/s99/s41 (a)NARv[M] vs.Marabou /s49/s48/s48 /s49/s48/s49 /s49/s48/s50 /s49/s48/s51 /s49/s48/s52/s49/s48/s48/s49/s48/s49/s49/s48/s50/s49/s48/s51/s49/s48/s52 /s32/s102/s105/s110/s105/s115/s104/s101/s100 /s32/s116/s105/s109/s101/s111/s117/s116/s32/s32 /s32/s121/s61/s120/s80/s108/s97/s110/s101/s116/s32/s40/s115/s101/s99/s41 /s78/s65/s82/s118/s91/s80/s93/s32/s40/s115/s101/s99/s41 (b)NARv[P] vs.Planet Fig. 4. Verification Time on CIFAR10 Network (logscale), with Marabou ,Planet and their Boosted Versions byNARv[M] andMarabou (resp. NARv[P] andPlanet ) for each verification problem, and the xaxis and yaxis refer to the time (in seconds, logscale) spent by NARv[M] andMarabou (resp. NARv[P] andPlanet ). The blue dots represent the solved problems and the red crosses on the top and right borders are the cases where Marabou (resp. Planet ) and NARv[M] (resp. NARv[P] ) run out of time. Therefore, the dots and crosses distributed above the green line indicate the cases where NARv[M] (resp. NARv[P] ) is faster. It is easy to observe that most of the dots and crosses are situated strictly above the green line in both Figures 4(a) and 4(b), indicating that our approach can significantly boost Marabou and Planet in most cases. We should point out that Planet can hardly solve any verification problems in the CIFAR10 network. Nevertheless, boosted by our approach, NARv[P] is still able to solve many verification problems within the time limit (10 hours). Table 1 (lower part) gives the detailed results. It shows that Planet fails to solve any problems before timing out when ùõø‚â•0.002. It successfully solves only 1 ( 2.1%) problem out of all 48 problems for 4 different perturbation thresholds. Boosted by our approach, NARv[P] is able to solve 7 ( 58%) and 3 ( 25%) problems respectively when ùõø=0.002andùõø‚â•0.003, succeeding in 41.7% (‚âà(8+7+3+3‚àí1)/48) more in total. On the other hand, NARv[M] is able to solve 37.5%more problems in total than Marabou . Answer to RQ1: NARv can significantly boost the performance of two promising tools Marabou andPlanet . 6.2 RQ2: Performance Evaluation Setup. To answer RQ2 , we compare NARv over CEGARNN , both of which use the same backend verification engine Marabou .CEGARNN provides two abstraction strategies, named indicator guided abstraction andabstraction to saturation , where the former iteratively merges two neurons until some presampled input violates the given property and the latter aggressively and iteratively merges two neurons producing the smallest overapproximation. We refer to CEGARNN with those abstraction strategies as CEGARNN[I] andCEGARNN[S] , respectively. NARv is then compared with both of them using the same benchmark ACAS Xu as adopted in [Elboher et al .2020]. The perturbation threshold ùõøis set from 0.01to0.04. Results. Figure 5 depicts the comparison of the verification time between NARv andCEGARNN[I] for each problem. We observe that most of the dots and crosses are located above the green line for all perturbation thresholds, indicating that NARv is significantly more efficient than CEGARNN[I] on most verification problems. The comparison of the verification time between NARv andCEGARNN[S] is illustrated in Figure 6, where a similar conclusion can be drawn.Abstraction and Refinement: Towards Scalable and Exact Verification of Neural Networks 17 /s32/s102/s105/s110/s105/s115/s104/s101/s100 /s32/s116/s105/s109/s101/s111/s117/s116/s32/s32 /s32/s121/s61/s120/s67/s69/s71/s65/s82/s45/s78/s78/s91/s73/s93/s32/s40/s115/s101/s99/s41 /s78/s65/s82/s118/s32/s40/s115/s101/s99/s41 (a)ùõø=0.01 /s32/s102/s105/s110/s105/s115/s104/s101/s100 /s32/s116/s105/s109/s101/s111/s117/s116/s32/s32 /s32/s121/s61/s120/s67/s69/s71/s65/s82/s45/s78/s78/s91/s73/s93/s32/s40/s115/s101/s99/s41 /s78/s65/s82/s118/s32/s40/s115/s101/s99/s41 (b)ùõø=0.02 /s32/s102/s105/s110/s105/s115/s104/s101/s100 /s32/s116/s105/s109/s101/s111/s117/s116/s32/s32 /s32/s121/s61/s120/s67/s69/s71/s65/s82/s45/s78/s78/s91/s73/s93/s32/s40/s115/s101/s99/s41 /s78/s65/s82/s118/s32/s40/s115/s101/s99/s41 (c)ùõø=0.03 /s32/s102/s105/s110/s105/s115/s104/s101/s100 /s32/s116/s105/s109/s101/s111/s117/s116/s32/s32 /s32/s121/s61/s120/s67/s69/s71/s65/s82/s45/s78/s78/s91/s73/s93/s32/s40/s115/s101/s99/s41 /s78/s65/s82/s118/s32/s40/s115/s101/s99/s41 (d)ùõø=0.04 Fig. 5. Comparison to CEGARNN[I] onACAS Xu (logscale) /s32/s102/s105/s110/s105/s115/s104/s101/s100 /s32/s116/s105/s109/s101/s111/s117/s116/s32/s32 /s32/s121/s61/s120/s67/s69/s71/s65/s82/s45/s78/s78/s91/s83/s93/s32/s40/s115/s101/s99/s41 /s78/s65/s82/s118/s32/s40/s115/s101/s99/s41 (a)ùõø=0.01 /s32/s102/s105/s110/s105/s115/s104/s101/s100 /s32/s116/s105/s109/s101/s111/s117/s116/s32/s32 /s32/s121/s61/s120/s67/s69/s71/s65/s82/s45/s78/s78/s91/s83/s93/s32/s40/s115/s101/s99/s41 /s78/s65/s82/s118/s32/s40/s115/s101/s99/s41 (b)ùõø=0.02 /s32/s102/s105/s110/s105/s115/s104/s101/s100 /s32/s116/s105/s109/s101/s111/s117/s116/s32/s32 /s32/s121/s61/s120/s67/s69/s71/s65/s82/s45/s78/s78/s91/s83/s93/s32/s40/s115/s101/s99/s41 /s78/s65/s82/s118/s32/s40/s115/s101/s99/s41 (c)ùõø=0.03 /s32/s102/s105/s110/s105/s115/s104/s101/s100 /s32/s116/s105/s109/s101/s111/s117/s116/s32/s32 /s32/s121/s61/s120/s67/s69/s71/s65/s82/s45/s78/s78/s91/s83/s93/s32/s40/s115/s101/s99/s41 /s78/s65/s82/s118/s32/s40/s115/s101/s99/s41 (d)ùõø=0.04 Fig. 6. Comparison to CEGARNN[S] onACAS Xu (logscale) Table 2 reports the details of all the results, where columns (""Avg. time"") and (""#Verified"") are the same as above, and columns (""Avg. size"") give the average sizes of hidden neurons in the abstract networks when the tools successfully verify the problems.18 Liu et al. Table 2. Abstraction and Verification Results for ACAS Xu Networks NARv CEGARNN[I] CEGARNN[S] ùõø Avg. time (s) 0.01 49.82 629.16 (12.6√ó) 1373.35 (27.6√ó) 0.02 88.10 1184.92 (13.4√ó) 1980.36 (22.5√ó) 0.03 105.04 2331.45 (22.2√ó) 2835.72 (27.0√ó) 0.04 169.46 2742.36 (16.2√ó) 3034.63 (17.9√ó) ùõø #Verified 0.01 888 (98.7%) 892 (99.1%) 884 (98.2%) 0.02 881 (97.9%) 815 (90.6%) 731 (81.2%) 0.03 893 (99.2%) 497 (55.2%) 368 (40.9%) 0.04 886 (98.4%) 327 (36.3%) 233 (25.9%) ùõø Avg. size 0.01 271(‚ñº10%) 860 ( ‚ñ≥187%) 828 ( ‚ñ≥176%) 0.02 210(‚ñº30%) 882 ( ‚ñ≥194%) 824 ( ‚ñ≥175%) 0.03 212(‚ñº29%) 887 ( ‚ñ≥196%) 784 ( ‚ñ≥161%) 0.04 229(‚ñº24%) 884 ( ‚ñ≥195%) 684 ( ‚ñ≥128%) Table 2 shows that NARv is much faster than both CEGARNN[I] andCEGARNN[S] . Partic ularly, when ùõø=0.01,NARv is on average 11.6(‚âà (629.16‚àí49.82)/49.82) times faster than CEGARNN[I] , and 26.6(‚âà (1373.35‚àí49.82)/49.82) times faster than CEGARNN[S] . For the network sizes, recall that there are 300 hidden neurons in each given ACAS Xu network. NARv succeeds in reducing the sizes of hidden neurons for all perturbation thresholds, the best reduction being 30%(=(300‚àí210)/300) on average when ùõø=0.02. However, neither of the two abstraction strategies of CEGARNN has progress in size reduction. One of the main reasons is that CEGARNN preprocesses the target DNN by first quadrupling the size, leading to a heavy load for the abstraction procedure. As a structureoriented abstraction approach, the abstraction of CEGARNN appears less practical. A welldesigned abstraction procedure leads to a better verification performance. As a result, NARv is able to solve the most problems in a reasonable time among the three tools whenùõø‚â•0.02, and is comparable to the other two when ùõø=0.01. In particular, NARv successfully verifies 72.6%(‚âà(886‚àí233)/900) more problems than CEGARNN[S] whenùõø=0.04, spending only 5.6%(‚âà169.46/3034.63) of time on average. Answer to RQ2: NARv significantly outperforms CEGARNN , the only work that supports structureoriented CEGAR. 6.3 Threats to Validity Our approach is designed for fully connected feedforward deep neural networks with the ReLU activation function. It could cope with any monotonic activation functions such as sigmoid and tanh [Paulsen and Wang 2022], but we have not yet evaluated the effectiveness. There are deep neural networks such as convolutional and recurrent ones. The former could be verified by equivalently transforming into fully connected ones [Ma and Lu 2017], but utilizing the particular properties of convolutional constructs to build abstraction is certainly an interesting future work. The feasibility has been shown in the concurrent work [Ostrovsky et al .2022]. However, it remains an open problem for recurrent neural networks. The verification engines Marabou andPlanet adopted in the experiments are primarily based on SMT solving and thus complete but computational expensive. Our structureoriented CEGAR approach is proposed to boost them. We have not evaluated with the abstract interpretationAbstraction and Refinement: Towards Scalable and Exact Verification of Neural Networks 19 approaches, which can be seen as computationoriented abstraction, thus are incomplete, e.g., [Gehr et al.2018; Singh et al .2019]. Although refinement techniques also have been proposed, e.g., input refinement [Wang et al .2018], such computationoriented abstractionrefinement frameworks are orthogonal to our structureoriented one. Investigating the synergy between them is left for future work, for instance, using them at a backend verification engine in our approach. To reduce this threat, we use the most efficient one in VNNCOMP‚Äô21 (i.e., Marabou ) and another comparable toolPlanet . Our approach may fail to boost DNN verification when the verification problems are very easy. More effective heuristics should be added to improve the efficiency for such verification problems. For instance, abstract interpretation based approaches could be leveraged before applying our approach. Nevertheless, our approach can significantly boost the verification of hard problems which are arguably more interesting and important in practice. 7 RELATED WORK "
27,Towards a Theoretical Understanding of Hashing-Based Neural Nets.txt,"Parameter reduction has been an important topic in deep learning due to the
ever-increasing size of deep neural network models and the need to train and
run them on resource limited machines. Despite many efforts in this area, there
were no rigorous theoretical guarantees on why existing neural net compression
methods should work. In this paper, we provide provable guarantees on some
hashing-based parameter reduction methods in neural nets. First, we introduce a
neural net compression scheme based on random linear sketching (which is
usually implemented efficiently via hashing), and show that the sketched
(smaller) network is able to approximate the original network on all input data
coming from any smooth and well-conditioned low-dimensional manifold. The
sketched network can also be trained directly via back-propagation. Next, we
study the previously proposed HashedNets architecture and show that the
optimization landscape of one-hidden-layer HashedNets has a local strong
convexity property similar to a normal fully connected neural network. We
complement our theoretical results with empirical verifications.","In the past decade, deep neural networks have become the new standards for many machine learning appli cations, including computer vision Krizhevsky et al. (2012); He et al. (2016), natural language processing Zaremba et al. (2014); Gehring et al. (2017), speech Proceedings of the 22ndInternational Conference on Ar tiÔ¨Åcial Intelligence and Statistics (AISTATS) 2019, Naha, Okinawa, Japan. PMLR: Volume 89. Copyright 2019 by the author(s).recognition Graves et al. (2013); Amodei et al. (2016), robotics Lillicrap et al. (2015), game playing Silver etal.(2016,2017),etc. Suchmodelusuallycontainsan enormous number of parameters, which is often much larger than the number of available training samples. Therefore, these networks are usually trained on mod ern computer clusters which have a huge amount of memory and computation power. On the other hand, there is an increasing need to train and run personal ized machine learning models on mobile and embed ded devices instead of transferring mobile data to a remote computation center on which all the computa tions are performed. This is because realtime process ing of deep learning models on mobile devices brings the beneÔ¨Åts of better privacy and less Internet band width. However, mobile devices like smart phones do not have the memory or computation capability of training large neural networks or even storing these models. These trends motivate the study of neural network compression , with the goal of reducing the memory overhead required to train, store and run neural net works. There is a recent line of research in this di rection, for example Chen et al. (2015); Iandola et al. (2016); Han et al. (2016). Despite their empirical ef fectiveness, there is little theoretical understanding on why these methods perform well. Thegoalofthispaperistobridgethegapbetweenthe ory and practice in neural network compression. Our focus is on hashingbased methods , which have been studied empirically in e.g. Chen et al. (2015, 2016), with the hope that the randomness in hash functions helps preserve the properties of neural networks de spite a reduction in the number of eÔ¨Äective parame ters. We make this intuition formal by giving theoret ical guarantees on the approximation power and the parameter recovery of such networks. First, we propose a neural net compression scheme based on random linear sketching, which can be ef Ô¨Åciently implemented using a hash function. Simi lar idea has been proposed in Kasiviswanathan et al. (2017) and demonstrated high performance empiriarXiv:1812.10244v2  [cs.LG]  25 Feb 2019Towards a Theoretical Understanding of HashingBased Neural Nets cally, but no formal theoretical guarantee was known. We show that such compression has strong approxima tion power. Namely, the small network obtained after sketching can approximate the original network on all input data coming from any lowdimensional manifold withsomeregularityproperties. Thesketchednetwork is also directly trainable via backpropagation. In fact, sketching is a principled technique for dimensionality reduction,whichhasbeenshowntobeverypowerfulin solving various problems arising in statistics Raskutti and Mahoney (2016); Wang et al. (2017) and numeri cal linear algebra WoodruÔ¨Ä (2014). Given its theoret ical success, it is natural to ask whether sketching can be applied to the context of neural net compression with theoretical guarantees. Our result makes partial progresses on this question. Next we study HashedNets, a simple method proposed in Chen et al. (2015) which appears to perform well in practice. HashedNets directly applies a random hash function on the connection weights in a neural net and to enforce all the weights mapped to the same hash bucket to take the same value. In this way the number of trainable parameters is reduced to be the number of diÔ¨Äerent hash buckets, and training can still be per formed via backpropagation while taking the weight sharing structure into account. From the perspective of optimization, we show that the training objective for a onehiddenlayer hashed neural net has a local strong convexity property, similar to that of a normal fully connected network Zhong et al. (2017b). Addi tionally, we can apply the initialization algorithm in Zhong et al. (2017b) to obtain a good initialization for training. Therefore it implies that the parameters in onehiddenlayer HashedNets can be provably recov ered under milde assumptions. Below we describe our contributions in more detail. Approximation Power Our result on the approx imation power of sketched nets is based on a classi cal concept, ‚Äúsubspace embedding‚Äù, which originally appears in numerical linear algebra Sarl√≥s (2006). Roughly speaking, it says that there exist a wide family of random matrices S2Rsn, such that for anyddimensional subspace URn, with probability 1"
231,How to Improve Your Speaker Embeddings Extractor in Generic Toolkits.txt,"Recently, speaker embeddings extracted with deep neural networks became the
state-of-the-art method for speaker verification. In this paper we aim to
facilitate its implementation on a more generic toolkit than Kaldi, which we
anticipate to enable further improvements on the method. We examine several
tricks in training, such as the effects of normalizing input features and
pooled statistics, different methods for preventing overfitting as well as
alternative non-linearities that can be used instead of Rectifier Linear Units.
In addition, we investigate the difference in performance between TDNN and CNN,
and between two types of attention mechanism. Experimental results on Speaker
in the Wild, SRE 2016 and SRE 2018 datasets demonstrate the effectiveness of
the proposed implementation.","For several years, ivector representation of a variable le ngth speech signal alongside with Probabilistic Linear Discriminant A nalysis (PLDA) has been the stateoftheart in textindependent s peaker veriÔ¨Åcation (TISV) [1, 2], yielding very good results in ot her tasks too, such as language identiÔ¨Åcation [3], textdependent SV [4, 5] and even in nonspeech task such as online signature veriÔ¨Åcatio n [6]. In recent years, novel deep learning approaches have emerged w hich outperform the traditional ivector/PLDA framework. Deep learning methods for speaker recognition can be summa rized into four categories: (a) methods applied to Ô¨Åxed utte rance level representations (typically ivectors) such as nonl inear map pings and backend classiÔ¨Åers [7, 8], (b) ivectors with Baum Welch statistics or framelevel features (e.g. bottleneck) extr acted with Deep Neural Networks (DNNs) trained for ASR (i.e. with pho netic recognition units as targets) [9, 10, 11], (c) fully en dtoend DNN approaches, where siamese DNNs learn directly to approx i mate the posterior probability of two or more utterances bel onging to the same speaker [12], and (d) semi endtoend approaches , where DNNs with either a closedset speaker identiÔ¨Åcation archit ecture (us ing a softmax over a large number of training speakers) or wit h a siamese architecture are trained, and utterancelevel rep resentations (embeddings) are extracted and fed to a trainable backend c lassiÔ¨Åer (typically PLDA) [13, 14]. To the best of our knowledge, the p erfor mance of the latter category is the current stateofthear t in most (if not all) speaker recognition benchmarks [13]. In this paper, we demonstrate how to train a speaker embed ding system in a generalpurpose deep learning framework an d attain comparable (or even better) performance compared to the ori ginalKaldi version [13]. Developing new ideas and combining othe r pro posed method with the xvector topology is easier in such too lkits, and this is the main motivation for sharing our experience wi th other researchers. Several papers have been published to show how to train speaker embedding systems in terms of different data augmen tation methods and also the amount of required training data [15, 16 ], but the aim of this paper is to show how to implement an xvector to pol ogy in TensorÔ¨Çow toolkit, proposing several tricks to impro ve the performance of speaker embeddings, and empirically evalua te the effectiveness of each trick. 2. SYSTEM SETUP In this paper, we focus on speaker embedding training part of the xvector pipeline and Kaldi toolkit is used for other parts o f the pipeline. Our features are 23dimensional MFCC features, w hich are extracted from 25 ms windows with short time mean normali za tion. Unvoiced frames are eliminated using an Energy based V AD. For creating training archives1for TensorÔ¨Çow, we use our imple mentation which produces pretty similar archives like Kald i except we save minibatches in numpy arrays which saved to tar Ô¨Åles. F or a fair comparison, all conÔ¨Åguration and number of training a rchives are the same for both Kaldi and TensorÔ¨Çow and also same Kaldi backend is used for both implementations. For training the network we use Adam [17] optimizer in almost all cases. The initial learning rate is set to 0.001 and linea rly reduced to 0.0001. We use 3 epochs for network training. We checked 6 epochs for some systems, but almost all of them overÔ¨Åtted mor e to the training speakers. In [15], it was mentioned 6 epochs is b etter for Kaldi and our experiments also prove it, but this is not the ca se for our TensorÔ¨Çow implementation. 2.1. Training data and augmentation The training data we use in this paper is the list prepared for NIST SRE 2018 close condition and consists of: 1) SREs 48 and SRE1 2, 2) Telephony part of Mixer6, 3) Fisher English, 4) All switch board data and 5) V oxceleb 1 and 2. For both V oxceleb the concatenat ed version of each session is used. The following data augmentation methods are used in this pa per. Apart from the four augmentation methods used in [13], w e also include audio compression using ogg and mp3 codecs. Fin ally, training data consists of 3fold augmentation that combine sclean data with 2 copies of augmented data, which are selected rand omly. ‚Ä¢Reverberation : ArtiÔ¨Åcially reverberated data using convolu tion with simulated RIRs. 1In Kaldi, the network training examples are split to several Ô¨Åles which called archive.‚Ä¢Babble : Several speakers are randomly selected from MU SAN [18] speech and the summation of them is added to the original signal with SNR between 1320dB. ‚Ä¢Music : Adding a random music Ô¨Åle from MUSAN to the original signal with random SNR between 515dB. ‚Ä¢Noise : MUSAN noises are added at one second intervals throughout the recording with random SNR between 015dB. ‚Ä¢Compression : The original signal is randomly compressed (using ogg or mp3 methods) and it is subsequently converted "
320,Carbide: Highly Reliable Networks Through Real-Time Multiple Control Plane Composition.txt,"Achieving highly reliable networks is essential for network operators to
ensure proper packet delivery in the event of software errors or hardware
failures. Networks must ensure reachability and routing correctness, such as
subnet isolation and waypoint traversal. Existing work in network verification
relies on centralized computation at the cost of fault tolerance, while other
approaches either build an over-engineered, complex control plane, or compose
multiple control planes without providing any guarantee on correctness. This
paper presents Carbide, a novel system to achieve high reliability in networks
through distributed verification and multiple control plane composition. The
core of Carbide is a simple, generic, efficient distributed verification
framework that transforms a generic network verification problem to a
reachability verification problem on a directed acyclic graph (DAG), and solves
the latter via an efficient distributed verification protocol (DV-protocol).
Equipped with verification results, Carbide allows the systematic composition
of multiple control planes and realization of operator-specified consistency.
Carbide is fully implemented. Extensive experiments show that (1) Carbide
reduces downtime by 43% over the most reliable individual underlying control
plane, while enforcing correctness requirements on all traffic; and (2) by
systematically decomposing computation to devices and pruning unnecessary
messaging between devices during verification, Carbide scales to a production
data center network.","The expectation for network availability is increasingly de manding. For example, Google increased its service level objectives (SLOs) from 99% availability in 2013 to 99.99% in 2018 [23,26]. This is because businesscritical applications are increasingly reliant on networks, and the cost of infras tructure downtime can now reach $7 million per hour [41]. Given its importance, substantial efforts have been devoted to increasing network reliability [12, 21, 22, 27, 29 ‚Äì31, 33, 48, 52, 56]. A major advance to improve reliability is to use net work veriÔ¨Åcation. Many veriÔ¨Åcation methods [24, 29 ‚Äì31, 54] model all possible forwarding behaviors and compute possible violations of network requirements. Other approaches con vert network state and requirements into systems of boolean constraints and utilize SAT or SMT solvers to compute cor rectness [12, 21]. Complementary to veriÔ¨Åcation, active test ing [22, 56] or control plane emulation [37, 38] are used to catch bugs after the deployment. On the other hand, network synthesis [13, 18, 25, 47] tries to avoid problems by systemati cally generating conÔ¨Ågurations. Despite considerable progress, existing approaches still suffer major limitations. First, most veriÔ¨Åcation tools rely on a centralized veriÔ¨Åcation server to collect snapshots of the 1This technical report includes Dennis Duan‚Äôs undergraduate thesis.network states or conÔ¨Åguration Ô¨Åles from all of the network de vices, which requires reliable connections between the server and network devices, resulting in a bottleneck and a single point of failure. Azure [27] proposed to have devices ver ify its forwarding behaviors using local contracts. However, they only support veriÔ¨Åcations of the shortest path reacha bility and fault tolerance property. Secondly, the attempt of building a single, infallible control plane often results in over engineered, complex control plane. Third, existing work in multiple control plane composition supports only a limited number of properties ( e.g., reachability, domain backup) and fail to provide generic routing correctness guarantees ( e.g., waypoint routing, subnet isolation) [34]. This paper systematically investigates and tackles the afore mentioned limitations of existing approaches to improve net work reliability, and presents Carbide , a novel system to achieve high reliability in networks through distributed veriÔ¨Å cation and multiple control plane composition. SpeciÔ¨Åcally, the core of Carbide isCPCheck , asimple, generic, efÔ¨Åcient distributed veriÔ¨Åcation framework that lets ingress devices verify which packet space can be forwarded by a given CP without violating requirements speciÔ¨Åed by the operators. CPCheck has two key insights: (1) A generic veri Ô¨Åcation problem ( e.g., reachability, loopfree, waypoint and faulttolerance) on a generic network can be transformed to a reachability veriÔ¨Åcation problem on a directed acyclic graph (DAG), and (2) the latter can be solved via a novel, efÔ¨Åcient distributed veriÔ¨Åcation protocol (DVprotocol). By systemati cally decomposing computation to each device and pruning unnecessary messaging between devices, CPCheck scales to a production data center network. Rigorous analysis proves the convergence and correctness of CPCheck . It also shows that the previous published Azure local veriÔ¨Åcation [27] can be easily supported as a specialized case of verifying shortest path reachability and faulttolerance requirement in CPCheck . Next, to allow systematic multiple control plane composi tion, Carbide provides (1) CPSpec , a Ô¨Çexible grammar that allows operators to specify correctness requirements for each CP on different packet space, the preference relation between CPs, and the desired consistency model, and (2) CPComposer , a module that uses the veriÔ¨Åcation results of CPCheck , select different CPs to use for different packet spaces, and sched ules the hotswapping of the corresponding data plane to guarantee the consistency requirement speciÔ¨Åed in CPSpec . Moreover, by constructing virtual CPs to preveriÔ¨Åed alterna tive nexthops, tunnels and the mix of different CPs, Carbide provides the veriÔ¨Åed fastreroute (VFRR) capability to the network, which substantially reduces the network downtime while guaranteeing routing correctness. A switch OS software suite called Multijet is implemented to deploy Carbide on real whitebox switches. Extensive ex periments show that (1) Carbide reduces downtime by over an order of magnitude compared to SDN, and by up to 43% when compared to OSPF. Even in the presence of network 1partitions, Carbide correctly enforces network requirements (e.g., on security, waypoint) on all packets, and (2) by sys tematically decomposing computation to devices and pruning unnecessary messaging between devices during veriÔ¨Åcation, Carbide scales to a production data center network with little overhead. This work does not raise any ethical issues. 2 Motivation Problems with centralized veriÔ¨Åcation. Always ensuring the network functions as desired, even in face of failure, is challenging. Existing veriÔ¨Åcation [24,29 ‚Äì31,54] fails to meet this requirement. Although differing in details, these work em ploy a common centralized architecture: a centralized server is used to collect data from each network device and verify the invariant compliance. This architecture has two major pitfalls to satisfy the ""always correct"" requirement. First, it heavily re lies on the network connection between the veriÔ¨Åcation server and the devices. The network connection, however, is possibly congested or broken during outage, especially catastrophic failure. Second, the server becomes the bottleneck and single point of failure. Fundamentally, it violates the fate sharing principle [16]: the network control and data path should share the same fate, they either fail together, or not at all. The fate sharing principle naturally motivates the dis tributed veriÔ¨Åcation design. VeriÔ¨Åcation messages should Ô¨Çow on the same path as trafÔ¨Åc. The sender of the path shares the same fate as its trafÔ¨Åc, thus, the source/ingress device should be responsible for veriÔ¨Åcation rather than an offpath cen tralized server. A naive approach is for all devices to send relevant information ( e.g., FIB entries) to the source so that it can run various veriÔ¨Åcation on its own trafÔ¨Åc. Yet, Ô¨Çooding FIB to all devices certainly is not scalable nor necessary. Our key idea is to distribute the veriÔ¨Åcation and systemati cally prune the messages to eliminate most of the unnecessary communications. Each device can make local veriÔ¨Åcation and propagates messages to source only when its local veriÔ¨Åcation results change. The communication is limited to the small set of switches according to the data plane path and requirements. Problems with a single control plane. While distributed ver iÔ¨Åcation provides better correctness guarantee during failure, high availability is still not satisÔ¨Åed because of a single control plane. One may argue that a single control plane can survive failure by setting up multipaths or fast reroute capabilities. However, it often results in an overengineered, complex con trol plane. More importantly, these data plane bandaids cannot handle control plane bugs and misconÔ¨Ågurations. High availability requirements call for multiple control plane coexistence. Internet is a great example of running multiple control plane to tolerate failure, rather than relying on a single ‚Äúneverfailed"" control plane. At the macro level, each Autonomous System controls its own network indepen dently so that the failure‚Äôs impact can be constrained within the domain. Within a single network, it is not uncommon Figure 1: Carbide architecture. to have multiple control planes in production. For example, multiple controllers are used to control different planes of a backbone [4, 26]. At the micro level, multiple routing proto cols ( e.g., OpenR, BGP) can run together on each switch [15]. These designs use multicontrol plane to ensure high avail ability. Naively running multiple control planes simultaneously does not work since different control plane may make con Ô¨Çicting decisions and result in violation of network policy. Thus, we use distributed veriÔ¨Åcation results to compose con trol planes to guarantee correctness and resilience. 3Carbide Overview Carbide is a thin layer between CP and switches (Figure 1). SpeciÔ¨Åcally, each network device runs (1) a control plane layer, (2) a novel online composition layer, and (3) a uniÔ¨Åed data plane layer. 3.1 Control Plane Layer The control plane layer consists of a set of control plane (CP) instances CP=fCPigi,i=1;2;:::, running in parallel. A control plane instance may be centralized ( e.g., SDN) or distributed ( e.g., OSPF and BGP). For example, a device may run three control plane instances: CP1as an SDN control plane receiving OpenFlow messages from a new release of an SDN controller, CP2as an SDN control plane receiving OpenFlow messages from a stable release of an SDN controller, and CP3as a traditional distributed routing protocol such as OSPF. Carbide treats every control plane instance as a blackbox and only depends on the output ( e.g., forwarding information base) of each control plane instance. This design decision allows Carbide to use any existing implementation (open source or commercial) for each control plane instance. 23.2 Online Composition Layer This novel layer dynamically composes the information from the control plane instances to satisfy the requirements. It contains four components. CPSpec . A global speciÔ¨Åcation allows operators to spec ify correctness requirements for each CP of different traf Ô¨Åc types, and the preference order between control plane instances. SpeciÔ¨Åcally, a CPSpec is speciÔ¨Åed as a tuple of (ps,f(reqi;CPi)gi,option ).psis the packet space of interests expressed as a predicate of packet headers. Given a ps, a set of packet ingestion points (ingress of packets in ps) will be identiÔ¨Åed. A CP composer will be started at each such source. f(reqi;CPi)giis a sequence of (requirement, CP) pairs in descending order of CP preference. Because different CPs may have different desired behavior, CPSpec allows operators to specify different requirements for each CP. As such, if a CP cannot satisfy its desired requirement, it will not be used. A requirement reqiis expressed as a predicate of regular expressions, which describes a set of paths in the network (e.g., reachability, waypoint, and loopfreeness). Section 4.2 gives the details of the requirement grammar. option allows an operator to specify the consistency model to enforce. Carbide guarantees the eventual consistency by default, and can achieve a stronger consistency ( e.g., transientloopfree consistency) with a tradeoff on perfor mance. (¬ß 5.1) vFIB : Each switch running a CP is associated with a virtual forwarding information base that collects and stores the for warding information computed by the CP ( e.g., FIB and ACL). vFIB does not need an internal forwarding state of a device (e.g., counter). For the same packet, a CP may have multiple nexthops in its forwarding information ( e.g., load balancing, robustness, and multicast). vFIB puts all these nexthops as a group action, and does not need the underlying hardware realization. CPCheck (Section 4) : Each device running CPiis associated with CPCheck , a simple, efÔ¨Åcient distributed veriÔ¨Åcation com ponent. The goal of CPCheck is to let each source identiÔ¨Åed byCPSpec to verify which packets can be forwarded by CPi without violating related requirements speciÔ¨Åed by the CP Spec. The core idea of CPCheck consists of (1) transformation of a generic requirement veriÔ¨Åcation on a generic network to a reachability veriÔ¨Åcation on a DAG, and (2) a novel, efÔ¨Åcient DVprotocol to verify reachability on the DAG. The root of the DAG is the source (see Section 4.4). CP composer (Section 5) : The CP composer takes as inputs the forwarding rules from the vFIBs, the veriÔ¨Åcation results from the CPCheck modules, and the consistency model to compute the CP assignments of packets to enforce at the data plane layer. In the general case, when trafÔ¨Åc in the same packet space enters the network from multiple ingress points, these devices run a consensus protocol to let one decide and announce the CP assignments. See Section 4.4 for examples SABWCD10.0.1.0/2410.0.2.0/24Figure 2: An example network. of the complete workÔ¨Çow. Resource control. To improve performance, Carbide devel ops a resource control component on each device to allo cate shared resources ( e.g., CPU, memory and bandwidth) among different running processes ( e.g., control plane in stances, CPCheck modules, CP composer). SpeciÔ¨Åcally, this component proactively limits the resource consumption of each process ( e.g., CPU and bandwidth usage), to prevent a process using up all of the resources on a device and starv ing all other process. It also adaptively adjusts the resources allocated to different processes in response to the behaviors of CPs. For example, a CP may oscillate between various routes, Carbide develops a BGPinspired damping mecha nism to control the resources allocated to the corresponding CPCheck process, to go from passive veriÔ¨Åcation to more active Ô¨Åltering. 3.3 Data Plane Layer Despite multiple CP instances running, each device in Car bide has a single uniÔ¨Åed data plane that processes data packets at the line rate based on rules installed by the CP composer in the device‚Äôs physical FIB (pFIB). Conceptually, the pFIB at the data plane is comprised of the rules from different CPs. A challenge is that different CPs may overlap and conÔ¨Çict, but a packet should only match the rules from one CP. To this end, Carbide leverages the multitable structure in commod ity switches ( e.g., [14, 20]) and stores forwarding rules from different CPs in different tables. The CP composer generates an extra CP selection table to safely direct the trafÔ¨Åc in the data plane using the corresponding rules. 4CPCheck : A Distributed VeriÔ¨Åcation Frame work CPCheck is a core component of Carbide . At the same time, it can be a generic distributed veriÔ¨Åcation technique used sep arately in other settings ( e.g., trouble shooting [22]). Assume a stable data plane, CPCheck allows ingress devices to ver ify which packet space can be forwarded without violating requirements speciÔ¨Åed by the operators. The key insight of CPCheck is to transform a generic veriÔ¨Åcation problem into a simple DVNetwork problem, and solve it with a novel, ef Ô¨Åcient DVprotocol. In the following, we Ô¨Årst introduce the data plane model, the language to deÔ¨Åne requirements and present our detailed algorithm. 4.1 Data Plane Model CPCheck uses a generic data plane model that abstracts dif ferent FIB heterogeneity, e.g., destinationbased FIB, Open 3h2 packet headers f2 header fields v2 header field values label2 device labels packetspace := (h.f [=,6=] v) j (packetspace [ \,[] packetspace) RegExr := ... extended with: ‚Äò[‚Äô (ÀÜ)label ‚Äò]‚Äô pathset := RegExr j (pathset [\,[] pathset) sources := ‚Äò[‚Äô (ÀÜ)label ‚Äò]‚Äô requirement := (sources:) packetspace !pathset Figure 3: A simplified grammar of CPCheck ReqLang . Flow table. Each entry in the table maps a disjoint packet space [29] to an action. The action includes modiÔ¨Åcation of packet header as well as a group of nexthops [27]. If an ac tion sends a matched packet to all nexthops in this group, it is annotated with a keyword ALL. If it sends to only one nexthop of the group, it is annotated with a keyword ANY . This representation allows modeling of different forward ing behaviors at a network device. For example, drop is mod eled by an empty nexthop group. Packet encapsulation and decapsulation are modeled by modiÔ¨Åcation functions. Mul ticast is modeled by an ALL nexthop group. Anycast, load balancing and faulttolerance [27] is modeled by an ANY next hop group. Given an action, however, CPCheck is oblivious of its hardware realization ( e.g., how to select one nexthop from an ANY nexthop group). Another important concept at the data plane is path seg ments. The global data plane DPifor a given control plane CPiis composed of a set of FIBs, fFIBj igj,i.e., the FIBs of all network devices j. Each FIB indicating nexthop constructs 1hop segments. Together, they construct path segments start ing from source devices or other devices. A path segments is a sequence of network devices. When a device appears twice, it forms a loop. 4.2 VeriÔ¨Åcation Requirements SpeciÔ¨Åcation Next, we deÔ¨Åne a grammar to specify global requirements. A wide range of common, important veriÔ¨Åcation requirements (e.g., reachability, waypoint, loop free and fault tolerance) can be expressed using grammar shown in Figure 3. At the high level, a requirement is speciÔ¨Åed as a pathset for a pair ofsources andpacketspace . The sources optionally refers to devices responsible to verify the requirement. The packet space is deÔ¨Åned by predicates of header Ô¨Åelds, which is passed byCPSpec . A pair of sources andpacketspace speciÔ¨Åes packets within packetspace originated from sources . The pathset is deÔ¨Åned by (dis)conjunction of regular expressions (Figure 3). By default, CPCheck assumes loopfree and only considers correctness requirement. The correctness is deÔ¨Åned as path segments starting from source should belong to the pathset . For example, the data plane must construct path segments ending with the destinations if the pathset consists of pathsreachable to the destination. More general requirements are tackled in Section 4.5. The grammar of regular expression is mostly standard, but includes [label]as a syntax sugar. It refers to any device with thelabel and[ÀÜlabel]refers to any device without that label . A device can have multiple labels ( e.g., identiÔ¨Åer, ip address, functionality) and can share a label with others. Example . Consider a network in Figure 2. S,Aand so on are the identiÔ¨Åer labels of network devices. SandDeach has an IP label 10.0.1.0/24 and 10.0.2.0/24, respectively, denoting to the subnet each one is connected to. The following requirements assigned to source device S. They require the trafÔ¨Åc from source IP 10.0.1.0/24 to destination IP 10.0.2.0/24 is always delivered ( i.e., reachability) after passing W(i.e., waypoint), without any loop ( i.e., loopfree). 1.packetspace = (srcIp = 10.0.1.0/24) \(dstIp = 10.0.2.0/24) 2. loopfree =T device x(([ÀÜx]*)[([ÀÜx]*[x][ÀÜx]*)) 3. reachability = [10.0.1.0/24].*[10.0.1.0/24] 4. waypoint = .*[W].* 5. pathset = reachability \waypoint\loopfree 6. requirement = ( [S]: packetspace)!pathset SpeciÔ¨Åcally, the Ô¨Årst line deÔ¨Ånes packetspace to be the space of packets with source IP 10.0.1.0/24 and destination IP 10.0.2.0/24. Next, it uses regular expressions to deÔ¨Åne the set of paths satisfying reachability, waypoint and loopfree requirements, respectively. In line 5, the pathset takes inter section of those sets, which means satisfying all the require ments. At the end, the veriÔ¨Åcation requirement is assigned to the source device with identiÔ¨Åer label S. 4.3 Distributed VeriÔ¨Åcation for DVNetwork Given the preceding requirements, a straightforward approach is to have every node send each FIB entry to the veriÔ¨Åer (source in this case). This, however, is unnecessary and unde sirable, as it leads to less distributed load. A key novelty of CPCheck is its ability to distribute the veriÔ¨Åcation. DVNetwork veriÔ¨Åcation problem. Instead of starting with generic network veriÔ¨Åcation, we Ô¨Årst study the DVNetwork (distributed veriÔ¨Åcation network) veriÔ¨Åcation problem. The problem may look special, but it actually is not. We will show in Section 4.4 how to convert a generic network veriÔ¨Åcation problem to this problem. But for now, we focus on this prob lem. SpeciÔ¨Åcally, a DVNetwork is a directedacyclicgraph (DAG) with only a source and only destinations as sinks. Each node in the network has an FIB to look up the next hop for each packet. The FIB may return an outgoing edge in the 4DAG from the node or offpath. The network is veriÔ¨Åed for a destination if the FIBs construct a path from the source to the destination. Intuitionbuilding example. To build intuition, consider an example DVNetwork veriÔ¨Åcation problem shown in Figure 4. Note that the example has only a single destination and hence we just consider this destination. Observe that at a given state, the FIBs of the nodes in the DVNetwork form a set of path segments. For example, there exists a path segment src!sw1!sw3!sw5!dst. The FIBs also set up a path segment from sw2!sw4!dst. One might think that to verify dst, the source needs to know each FIB state at alltime. This, however, is unnecessary. To appreciate it, consider some changes to FIBs and observe whether the source needs to know about the change. ‚Ä¢Case1: sw2updates its nexthop to somewhere outside the network (shown in red line). From a purely local view, it is a violation so sw2attempts to report it to src. However, from a global view, this change has no effect on the path segment chosen by srcand hence does not need to be reported. To approximate the global view, sw2should report the change to its upstream sw1. Since sw1is not using sw2as next hop, sw1can locally decide that there is no need to propagate this change further. This example shows one insight of eliminating unnecessary propagation: if the node is not on the current path from srctodst, its change does not need to be propagated. ‚Ä¢Case2: sw5updates its nexthop to point to sw4. This change does not need to report to srceither, because sw5‚Äôs new change still satisÔ¨Åes the requirement. This illustrates our second insight of reducing propagation: only propagate if the local veriÔ¨Åcation result changes. VeriÔ¨Åcation function. To ground the above intuitive exam ples, formally, we introduce a Boolean veriÔ¨Åcation function d(x): whether the requirement is satisÔ¨Åed at switch x, from the global view. One can see that the goal of veriÔ¨Åcation is to compute veriÔ¨Åcation function d(src), which can be computed cumulatively from the d(x)along the path. SpeciÔ¨Åcally, de note the next hop of switch x(searched using its FIB) as n(x). If the next hop is off network, it is a special switch nil. We have: d(x) =d(n(x)): (1) As the boundary, d(dst) =True andd(nil) =False . One can compute Equation (1)using a distributed algo rithm, and a natural design is a push based design: each switch xowns its value of d(x)and pushes the value up stream. One can see that it is sufÔ¨Åcient for xto follow a simple local update rule: switch xwill propagate d(x)only if its value changes . Let us go back to our example to illus trate the beneÔ¨Åts of this rule. For Case1, initially, we have d(src) =d(sw1) =d(sw3) =d(sw5) =d(dst) =True . Upon sw2making the change of its nexthop, d(sw2) =False .sw2 srcsw1sw3sw5sw4sw2dst(sink)Case1Case2Figure 4: Two cases of update for DVNetwork. propagates its change to sw1, however, because d(sw1)‚Äôs com putation does not rely on sw2,d(sw1)remains True . Then sw1 will not propagate the change further. Similarly, for Case2, d(sw5) =True before and after the change, so sw5will not even trigger the propagation. Consider a general case of DV Network of an nbyn grid, with the source at the upper left, destination at the lower right, and each node can go only right or down inside the grid. Assume that each node has computed a next hop (right or down) to the destination. Consider any Ô¨Çip between right and down, there will be no message generated. At this point, one might make an observation that the al gorithm has a structure similar to traditional distance vector routing. Observing this similarity can help understand our design. One may consider veriÔ¨Åcation as computing distances in a domain with only two values: Ô¨Ånite (reachable or veriÔ¨Åed) and inÔ¨Ånite (unreachable or unveriÔ¨Åed). Note that traditional distance vector routing can have churns during convergence. A DVNetwork, on the other hand, is a DAG and the propaga tion follows the reverse links of the DAG; hence there are no loops, and hence no churns. Single destination to packet space. The above cases con sider an individual destination. Now consider a DVNetwork with multiple destinations. It is more efÔ¨Åcient to consider all destinations together than consider them one by one. With multiple destinations, the FIB at node xmay choose differ ent nexthops for different destinations (or more Ô¨Ånegrained packet space determined by both destination and port number). We extend n(x)function to np(x), representing the nexthop for packet pin node x‚Äôs FIB. As a result, dp(x)is extended to consider different destination space p. dp(x) =dp(np(x)): (2) From equation to DV protocol. While Equation (2) is a compact model, it requires efÔ¨Åcient implementation. DeÔ¨Åne x:H=fpjdp(x) =Falsegas a headerspace [30], com pact [29, 55] representation for dp(x). Protocol 1 gives the basic protocol using headerspace operations ( \;[;"
206,Neural Network Pruning as Spectrum Preserving Process.txt,"Neural networks have achieved remarkable performance in various application
domains. Nevertheless, a large number of weights in pre-trained deep neural
networks prohibit them from being deployed on smartphones and embedded systems.
It is highly desirable to obtain lightweight versions of neural networks for
inference in edge devices. Many cost-effective approaches were proposed to
prune dense and convolutional layers that are common in deep neural networks
and dominant in the parameter space. However, a unified theoretical foundation
for the problem mostly is missing. In this paper, we identify the close
connection between matrix spectrum learning and neural network training for
dense and convolutional layers and argue that weight pruning is essentially a
matrix sparsification process to preserve the spectrum. Based on the analysis,
we also propose a matrix sparsification algorithm tailored for neural network
pruning that yields better pruning result. We carefully design and conduct
experiments to support our arguments. Hence we provide a consolidated viewpoint
for neural network pruning and enhance the interpretability of deep neural
networks by identifying and preserving the critical neural weights.","Deep neural network pruning[ 17] [20] [19] [29] has been an essential topic in recent years due to the emerging desire of efficiently deploying pretrained models on lightweight devices, for example, smartphones, edge devices (Nvidia Jetson and Raspberry Pi), and Internet of Things (IoTs). Neural network pruning dates back to last century when the initial attempts were made by optimal brain damage [28] and optimal brain surgeon [21], and have achieved impressive results. A larger body of work, namely, neural network compression [ 9][23][11][26], aims at removing a large number of parameters without significantly deteriorating the performance while benefiting from the reduced storage footprints for pretrained networks and computing power. Because the 1Preprint. Authors‚Äô addresses: Shibo Yao, New Jersey Institute of Technology, Newark, NJ, USA, espoyao@gmail.com; Dantong Yu, New Jersey Institute of Technology, Newark, NJ, USA, dtyu@njit.edu; Ioannis Koutis, New Jersey Institute of Technology, Newark, NJ, USA, ikoutis@njit.edu. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. ¬©2018 Association for Computing Machinery. 15564681/2022/8ART111 $15.00 https://doi.org/10.1145/1122445.1122456 ACM Trans. Knowl. Discov. Data., Vol. 37, No. 4, Article 111. Publication date: August 2022.arXiv:2307.08982v1  [cs.LG]  18 Jul 2023111:2 Shibo Yao, Dantong Yu, and Ioannis Koutis dense layers and convolutional layers usually dominate the space and time complexity in neural networks, multiple approaches have been proposed to compress these two types of network. These approaches demonstrated surprising simplicity and superior efficacy in many situations of neural network pruning. Nonetheless, existing works mostly are experimentoriented and fall into distinct categories. Thoroughly studying these related work revealed several questions. Can the same approaches be applied to both dense layers and convolutional layers? What are the theory and mechanisms justifying the chosen pruning operations and providing the performance guarantee of the pruned networks? And can we gain a better insight to interpret deep learning models [ 35][13] from studying the topics of neural network pruning? In this paper, we employ spectral theory and matrix sparsification techniques to provide an alternative perspective for neural network pruning and attempt to answer the questions mentioned above. Our contributions are as follows: ‚Ä¢We discover the relationship between neural network training and the spectrum learning process of weight matrices. By tracking the evolution of matrix spectrum, we formalize neural network pruning as a spectrum preserving process. ‚Ä¢We illustrate in detail the resemblance between dense layer and convolutional layer and essentially they both are matrix multiplication. Consequently, a unified viewpoint, namely matrix sparsification, is proposed to prune both types of layer. ‚Ä¢Based on our analysis, we show the potential of customizing matrix sparsification algorithm for better neural network pruning by proposing a tailored sparsification algorithm. ‚Ä¢We thoroughly conduct experimental tasks, each of which targets a specific argument to provide appropriate and solid empirical support. The outline of this paper is as follows: Section 2 briefly reviews related literature. In section 3, we formulate the problem of neural network pruning and explain how we tackle it from spectral theory perspective; Section 4 provides matrix sparsification techniques that are suitable for neural network pruning. In section 5, we generalize the analysis schema to convolutional layers. Section 6 presents detailed empirical study; and finally the conclusions are offered. 2 RELATED WORK "
454,Table-based Fact Verification with Self-adaptive Mixture of Experts.txt,"The table-based fact verification task has recently gained widespread
attention and yet remains to be a very challenging problem. It inherently
requires informative reasoning over natural language together with different
numerical and logical reasoning on tables (e.g., count, superlative,
comparative). Considering that, we exploit mixture-of-experts and present in
this paper a new method: Self-adaptive Mixture-of-Experts Network (SaMoE).
Specifically, we have developed a mixture-of-experts neural network to
recognize and execute different types of reasoning -- the network is composed
of multiple experts, each handling a specific part of the semantics for
reasoning, whereas a management module is applied to decide the contribution of
each expert network to the verification result. A self-adaptive method is
developed to teach the management module combining results of different experts
more efficiently without external knowledge. The experimental results
illustrate that our framework achieves 85.1% accuracy on the benchmark dataset
TabFact, comparable with the previous state-of-the-art models. We hope our
framework can serve as a new baseline for table-based verification. Our code is
available at https://github.com/THUMLP/SaMoE.","Fact VeriÔ¨Åcation, aiming to determine the consis tency between a statement and given evidence, has become a crucial part of various applications such as fake news detection, rumor detection (Rashkin et al., 2017; Thorne et al., 2018; Goodrich et al., 2019; Vaibhav et al., 2019; Kryscinski et al., 2020). While most existing research focuses on veriÔ¨Åca tion based on unstructured text, a new trend is ex tending the scope to structured evidence (e.g., ta bles), which is informative and ubiquitous in our daily lives. Tablebased veriÔ¨Åcation faces different challenges than unstructuredtextbased due to thecomplexity of the requirements, including sophis ticated textual, numerical, and logical reasoning across evidence tables; even for some statements, multiple types of reasoning are indispensable to complete the veriÔ¨Åcation. An example is presented in Figure 1. Figure 1: An Example of tablebased fact veriÔ¨Åcation. To tackle the challenges above, previous work established two kinds of methods: (1) program enhanced methods (Chen et al., 2020; Zhong et al., 2020; Shi et al., 2020; Yang et al., 2020) and (2) tablebased pretrained models (Eisenschlos et al., 2020; Liu et al., 2021). The programenhanced methods mainly leverage programs generated by the semantic parser. SpeciÔ¨Åcally, statements are parsed into executable programs to extract the logi cal/numerical semantics, which is further be lever aged together with contextual semantics learned by a language model (e.g., BERT) in inference. How ever, the semantic parsers that generate semantic consistent programs must be trained in a weak su pervision setting, which brings difÔ¨Åculties in train ing. Furthermore, generalizing this method to other datasets is almost impossible without the API set modiÔ¨Åcation according to the reasoning require ments on the new datasets. The tablebased pretrained models leverage elaborate model structure (Herzig et al., 2020) and pretraining tasks (Eisenschlos et al., 2020; Liu et al., 2021) to enhance the reasoning skills on struc tured data. Nevertheless, two signiÔ¨Åcant shortcom ings remain. Firstly, the process is demanding duearXiv:2204.08753v1  [cs.AI]  19 Apr 2022Figure 2: An overview of Selfadaptive Mixture ofExperts Network ( SaMoE ) for tablebased fact veriÔ¨Åcation. to the tremendous computing resources required by pretraining. Moreover, the effectiveness of pre training to its downstream tasks mainly depends on the adaptability between these two tasks. Therefore, implementing pretraining tasks may fail to meet the requirements when facing the unseen reasoning types demanded by new datasets. In this paper, we introduce an innovative frame work, Selfadaptive Mixture ofExperts (SaMoE), to address the previously mentioned problems. The entire framework is illustrated in Figure 2. SaMoE consists of 3 components: feature extractor ,ex perts , and management module , which is the combination of manager andsupervisor networks. Each expert initially takes the same feature as input and then learns to deal with different parts of the reasoning types (e.g., contextual/logical/numerical) required by tablebased veriÔ¨Åcation. A manage ment module is designed to guide the training of experts and combine experts‚Äô veriÔ¨Åcation results effectively. The manager network in this module assigns each expert a unique attention score, al lowing each individual to focus on different kinds of reasoning types and summarizes experts‚Äô en tire outputs as the Ô¨Ånal veriÔ¨Åcation result. How ever, managers failed to allocate the highest atten tion score to the expert who performs best on the current reasoning type in most circumstances. To alleviate this problem, we introduce a supervisor network to adjust the attention score given by the manager. The supervisor network is trained self adaptively (i.e., it learns directly from experts‚Äô per formance on the train set) without prior knowledge of the task or dataset. Extensive experiments areconducted to show that our proposed framework, implemented with a general pretrained language model RoBERTa (Liu et al., 2019), outperforms previous stateoftheart methods, including table based pretrained models. The main contributions of this work are as follows: ‚Ä¢We innovatively implement mixtureof experts for tablebased veriÔ¨Åcation, aiming to arrange each expert to different types of reasoning. This method can also be easily generalized to other datasets. ‚Ä¢We investigate a selfadaptive method to ad just suitable attention score to each expert ac cording to its performance on different reason ing types, achieving more efÔ¨Åcient coopera tion across experts. ‚Ä¢Our framework achieves better performance on the TABFACT dataset without the assis tance of tablebased pretrained models. 2 Research Question The tablebased veriÔ¨Åcation task expects one to de termine whether a statement Sis entailed or refuted by an evidence table T. The process above can be regarded as a binary classiÔ¨Åcation task and thus de noted asf(S;T) = ^y, wherefis the veriÔ¨Åcation model and ^y2f0;1gits prediction. 3 Methods "
391,G2SAT: Learning to Generate SAT Formulas.txt,"The Boolean Satisfiability (SAT) problem is the canonical NP-complete problem
and is fundamental to computer science, with a wide array of applications in
planning, verification, and theorem proving. Developing and evaluating
practical SAT solvers relies on extensive empirical testing on a set of
real-world benchmark formulas. However, the availability of such real-world SAT
formulas is limited. While these benchmark formulas can be augmented with
synthetically generated ones, existing approaches for doing so are heavily
hand-crafted and fail to simultaneously capture a wide range of characteristics
exhibited by real-world SAT instances. In this work, we present G2SAT, the
first deep generative framework that learns to generate SAT formulas from a
given set of input formulas. Our key insight is that SAT formulas can be
transformed into latent bipartite graph representations which we model using a
specialized deep generative neural network. We show that G2SAT can generate SAT
formulas that closely resemble given real-world SAT instances, as measured by
both graph metrics and SAT solver behavior. Further, we show that our synthetic
SAT formulas could be used to improve SAT solver performance on real-world
benchmarks, which opens up new opportunities for the continued development of
SAT solvers and a deeper understanding of their performance.","TheBoolean SatisÔ¨Åability (SAT) problem is central to computer science, and Ô¨Ånds many applications across ArtiÔ¨Åcial Intelligence, including planning [ 26], veriÔ¨Åcation [ 9], and theorem proving [ 16]. SAT was the Ô¨Årst problem to be shown to be NPcomplete [ 11], and there is believed to be no general procedure for solving arbitrary SAT instances efÔ¨Åciently. Nevertheless, modern solvers are able to routinely decide large SAT instances in practice, with different algorithms proving to be more successful than others on particular problem instances. For example, incomplete search methods such as WalkSAT [ 37] and survey propagation [ 8] are more effective at solving large, randomly generated formulas, while complete solvers leveraging conÔ¨Çictdriven clause learning (CDCL) [ 32] fare better on large structured SAT formulas that commonly arise in industrial settings. Understanding, developing and evaluating modern SAT solvers relies heavily on extensive empirical testing on a suite of benchmark SAT formulas. Unfortunately, in many domains, availability of The two Ô¨Årst authors made equal contributions. 33rd Conference on Neural Information Processing Systems (NeurIPS 2019), Vancouver, Canada.arXiv:1910.13445v1  [cs.LG]  29 Oct 2019!ÃÖ!!ÃÖ!###!ÃÖ!!ÃÖ!####!ÃÖ!!ÃÖ!#####!ÃÖ!!ÃÖ!#########Node split Bipartite Graph!ÃÖ!###!ÃÖ!###GCNPositive pair!ÃÖ!###!ÃÖ!###PredictNode splitting sequence Node merging sequence$%$&$'$(Modeling )(+,|+,./)with GCN Set of TreesNode proposalphaseNode mergingphase#Merged clause#Split clauseEdgeÃÖ!Negative literal!Positive literal Extra messagepassing pathIntermediategraph$1Bipartite GraphSet of Trees ###Node mergeGCNNegative pairPredictLegend#ClauseFigure 1: An overview of the proposed G2SAT model. Top left : A given bipartite graph can be decomposed into a set of disjoint trees by applying a sequence of node splitting operations. Orange nodecin graphGiis split into two blue cnodes in graph Gi"
456,Learning regression and verification networks for long-term visual tracking.txt,"Compared with short-term tracking, the long-term tracking task requires
determining the tracked object is present or absent, and then estimating the
accurate bounding box if present or conducting image-wide re-detection if
absent. Until now, few attempts have been done although this task is much
closer to designing practical tracking systems. In this work, we propose a
novel long-term tracking framework based on deep regression and verification
networks. The offline-trained regression model is designed using the
object-aware feature fusion and region proposal networks to generate a series
of candidates and estimate their similarity scores effectively. The
verification network evaluates these candidates to output the optimal one as
the tracked object with its classification score, which is online updated to
adapt to the appearance variations based on newly reliable observations. The
similarity and classification scores are combined to obtain a final confidence
value, based on which our tracker can determine the absence of the target
accurately and conduct image-wide re-detection to capture the target
successfully when it reappears. Extensive experiments show that our tracker
achieves the best performance on the VOT2018 long-term challenge and
state-of-the-art results on the OxUvA long-term dataset.","Visual tracking is a fundamental problem in computer vi sion, which has many practical applications including video surveillance, vehicle navigation, to name a few. The track ing algorithms can be roughly divided into two branches: shortterm tracking and longterm tracking. For the former one, the tracked object is almost always in the camera‚Äôs Ô¨Åeld of view but not necessarily fully visible. The tracking al gorithm focuses on estimating the accurate positions and scales of the target in shortterm sequences. In recent years, numerous trackers [4, 6, 21, 29, 28, 15] have achieved very promising results in shortterm tracking benchmarks (such as OTB [34] and VOT2017 [13]). However, the experi #0001present #0634present #0643absent #1034absent #1035present #1323present #1328absent#1487absent#1552   presentFigure 1. Visual results of our tracker in representative frames. Table 1. Comparisons between recent longterm tracking bench marks and popular shortterm ones. LTB35 [19] OxUvA [31] OTB100 [34] VOT2017 [14] Avg frames 4196 4235 590 350 Max frames 29700 37440 3870 1494 Min frames 1389 900 72 36 absent labels 12% 52% 0% 0% Avg absent labels 503 2.2 0 0 ments on these benchmarks cannot well evaluate the long term tracking performance of different trackers, and cannot provide valid references for the realistic tracking systems. Recently, the importance of longterm tracking has been emphasized and some largescale datasets have been well constructed to address this issue (such as VOT2018 LTB35 [19] and OxUvA [31]). Besides common challenges in shortterm scenarios, in the longterm tracking task, the tracked object requires to be captured in longterm se quences, and also disappears and reappears very frequently. Thus, this task provides more challenges than shortterm tracking. Table 1 reports some statistics on the frame length and the number of absent labels in popular and recent short term (OTB, VOT2017) and longterm (VOT2018 LTB35 and OxUvA) benchmarks. First, the frame length in long term benchmarks is almost ten times longer than that in shortterm benchmarks. In addition, there exist a large amount of absent labels in longterm tracking scenarios. 1arXiv:1809.04320v2  [cs.CV]  19 Nov 2018Thus, it is vital for longterm trackers to provide a valid conÔ¨Ådence score indicating the tracked object is present or absent and have the capability of imagewide redetection. Figure 1 provides visual results of our tracker in one rep resentative sequence, which shows that our tracker can ef fectively identify the tracked object is present orabsent and estimate the accurate bounding box when it is present . Up to now, few works have been done to deal with long term challenges [18, 20, 7, 10, 22], The LCT [20] and PTA V [7] trackers just track and redetect the target in a local search region, and cannot recapture the target suc cessfully after the target moves out of view and reappears again. The CMT [22] and FCLT [18] methods merely ex ploit a single matching or classiÔ¨Åcation model for the entire tracking process, which makes the tracker easily drift due to online variations. The MUSTer algorithm [10] exploits ensemble models to treat shortterm and longterm scenar ios separately; however, its performance is not satisfactory mainly due to the adopted handcrafted features. To deal with challenges in the longterm scenarios, we attempt to develop a deeplearningbased longterm tracker with an integration of regression and veriÔ¨Åcation networks (Figure 2). The regression network Rlearns a generic matching function offline to robustly handle the common appearance variations of the tracked object during the track ing process. The veriÔ¨Åcation network Vfurther equips the tracker with a strong discriminative power by online learn ing. In each frame, Rregresses a series of candidate bound ing boxes in a local search region, with their scores measur ing the similarities between candidates and the object tem plate. Then,Vlearns a classiÔ¨Åcation boundary online to further decide whether the most similar candidate is the true target or a distractor. The Ô¨Ånal conÔ¨Ådence score is outputted by the integration of the scores from both RandV, and in dicates the tracked object is present orabsent in the current frame. This score will be used to invoke the imagewide redetection scheme if necessary. To summarize, the main contributions of this work are presented as follows : i) A novel longterm tracking frame work is developed to combine an ofÔ¨Çinelearned regression network with an onlineupdated veriÔ¨Åcation network. The regression model aims to candidate proposal, while the ver iÔ¨Åcation one is for target identiÔ¨Åcation. ii) A novel object speciÔ¨Åc regression network is proposed to generate a series of candidates being similar with the tracked object, which is ofÔ¨Çine learned effectively and handles intrinsic appearance variations robustly. iii) A valid conÔ¨Ådence score is designed to determine the target is present or not, and to make the tracker dynamically switch between local search and global search. iv) Extensive evaluations on the VOT2018 LTB35 and OxUvA longterm benchmarks demonstrate that our tracker achieves the best performance in comparisons with other competing methods.2. Related Work "
100,Improved Branch and Bound for Neural Network Verification via Lagrangian Decomposition.txt,"We improve the scalability of Branch and Bound (BaB) algorithms for formally
proving input-output properties of neural networks. First, we propose novel
bounding algorithms based on Lagrangian Decomposition. Previous works have used
off-the-shelf solvers to solve relaxations at each node of the BaB tree, or
constructed weaker relaxations that can be solved efficiently, but lead to
unnecessarily weak bounds. Our formulation restricts the optimization to a
subspace of the dual domain that is guaranteed to contain the optimum,
resulting in accelerated convergence. Furthermore, it allows for a massively
parallel implementation, which is amenable to GPU acceleration via modern deep
learning frameworks. Second, we present a novel activation-based branching
strategy. By coupling an inexpensive heuristic with fast dual bounding, our
branching scheme greatly reduces the size of the BaB tree compared to previous
heuristic methods. Moreover, it performs competitively with a recent strategy
based on learning algorithms, without its large offline training cost. Finally,
we design a BaB framework, named Branch and Dual Network Bound (BaDNB), based
on our novel bounding and branching algorithms. We show that BaDNB outperforms
previous complete verification systems by a large margin, cutting average
verification times by factors up to 50 on adversarial robustness properties.","As deep learning powered systems become more and more common, the lack of robustness of neural networks and their reputation for being \black boxes"" has become increasingly worrisome. In order to deploy them in critical scenarios where safety and robustness would be a prerequisite, techniques that can prove formal guarantees for neural network behavior are needed. A particularly desirable property is resistance to adversarial examples (Good ¬©2021 Alessandro De Palma, Rudy Bunel, Alban Desmaison, Krishnamurthy Dvijotham, Pushmeet Kohli, Philip H.S. Torr and M. Pawan Kumar.arXiv:2104.06718v1  [cs.LG]  14 Apr 2021De Palma, Bunel, Desmaison, Dvijotham, Kohli, Torr, and Kumar fellow et al., 2015; Szegedy et al., 2014): perturbations maliciously crafted with the intent of fooling even extremely well performing models. After several defenses were proposed and subsequently broken (Athalye et al., 2018; Uesato et al., 2018), some progress has been made in being able to formally verify whether there exist any adversarial examples in the neighborhood of a data point (Tjeng et al., 2019; Wong and Kolter, 2018). Verication algorithms fall into three categories: unsound (some false properties are proven false), incomplete (some true properties are proven true), and complete (all prop erties are correctly veried as either true or false). Unsound verication, which relies on approximate nonconvex optimization, is not related to the topic of this work. Instead, we focus on incomplete verication and its role in complete verication. An incomplete verier can be obtained via the computation of lower and upper bounds on the output of neu ral networks. Many complete veriers can be seen as branch and bound algorithms (Bunel et al., 2018), which operate by dividing the property into subproblems (branching) for which incomplete veriers are more likely to provide a denite answer (bounding). Bunel et al. (2020b) have recently proposed a branch and bound framework that scales to medium sized convolutional networks, outperforming stateoftheart complete veriers (Katz et al., 2017; Wang et al., 2018b; Tjeng et al., 2019). The aim of this work is to signicantly improve their design choices, in order to scale up the applicability of complete veriers to larger networks. In the remainder of this section, we provide a highlevel overview of our proposed improvements. Bounding Most previous algorithms for computing bounds are either computationally expensive (Ehlers, 2017) or sacrice tightness in order to scale (Gowal et al., 2018; Mir man et al., 2018; Wong and Kolter, 2018; Singh et al., 2018; Zhang et al., 2018). Within complete verication Bunel et al. (2018, 2020b) chose tightness over scalability, employing otheshelf solvers (Gurobi Optimization, 2020) to solve a network relaxation obtained by replacing activation functions by their convex hull (Ehlers, 2017). In the context of incom plete verication, better speedaccuracy tradeos were achieved by designing specialized solvers for such relaxation (Dvijotham et al., 2018). In this work, we design a novel dual formulation for the bounding problem and two corresponding solvers, which we employ as a branch and bound subroutine. Our approach oers the following advantages: ‚Ä¢While previous bounding algorithms operating on the same network relaxation (Dvi jotham et al., 2018) are based on Lagrangian relaxations, we derive a new family of optimization problems for neural network bounds through Lagrangian Decomposition, which in general yields duals at least as strong as those obtained through Lagrangian relaxation (Guignard and Kim, 1987). For our bounding problem, the optimal solu tions of both the Lagrangian Decomposition and Lagrangian relaxation will match. However we prove that, in the context of ReLU networks, for any dual bound from the approach by Dvijotham et al. (2018) obtained in the process of dual optimization, the corresponding bounds obtained by our dual are at least as tight. Geometrically, our dual corresponds to a reduction of the dual space of the Lagrangian relaxation that always contains the optimum. We demonstrate empirically that our derivation com putes tighter bounds in the same time when using supergradient methods, improving the quality of incomplete verication. We further rene performance by devising a proximal solver for the problem, which decomposes the task into a series of strongly 2Improved Branch and Bound for NN Verification convex subproblems. For each subproblem, we use an iterative method that lends itself to analytical optimal step sizes, thereby resulting in faster convergence. ‚Ä¢Both the supergradient and the proximal method hinge on linear operations similar to those used during network forward/backward passes. As a consequence, we can leverage the convolutional structure when necessary, while standard solvers are often restricted to treating it as a general linear operation. Moreover, both methods are easily parallelizable: when computing bounds on the activations at layer k, we need to solve two problems for each hidden unit of the network (for the upper and lower bounds). These can all be solved in parallel. Within branch and bound, we need to compute bounds for several dierent problem domains at once: we solve these problems in parallel as well. Our GPU implementation thus allows us to solve several hundreds of linear programs at once on a single GPU, a level of parallelism that would be hard to match on CPUbased systems. Branching While bounding is often the computational bottleneck within each branch and bound iteration, a high quality branching strategy is crucial to reduce the branch and bound search tree (Achterberg and Wunderling, 2013). Strategies used for neural network verication typically split the domain on a coordinate of the network input (Wang et al., 2018a; Bunel et al., 2018; Royo et al., 2019), or on a given network activation (Ehlers, 2017; Katz et al., 2017; Wang et al., 2018b). It was recently shown (Bunel et al., 2020b) that, for convolutional networks with around one thousand neurons, it is preferable to split on the network activations (activation splitting). As this search space is signicantly larger, the bestperforming heuristic strategy favors computational eciency over accuracy (Bunel et al., 2020b). In order to improve performance without signicantly increasing branching costs, strategies based on learning algorithms were proposed recently (Lu and Kumar, 2020). We present a novel branching strategy that, by coupling an inexpensive heuristic with fast dual bounds, greatly improves upon previous approaches strategies (Bunel et al., 2020b) and performs competitively with learning algorithms without incurring large training costs. BaDNB We design a massively parallel, GPUaccelerated, branch and bound framework around our bounding and branching algorithms. We conduct detailed ablation studies over the various components of the framework, named BaDNB, and show that it yields substantial complete verication speedups over the stateoftheart algorithms. A preliminary version of this work, centered around the novel bounding algorithms, appeared in the proceedings of the 36th Conference on Uncertainty in Articial Intelli gence (Bunel et al., 2020a). The present article signicantly extends it by (i) presenting a new heuristic branching scheme for activation splitting ( x4); (ii) improving on various com ponents of the branch and bound framework employed in the preliminary version ( x5.1), resulting in large complete verication improvements; (iii) rening the analysis linking our dual problem to previous dual approaches ( x2.2,x3.4), which now includes initialization via any propagationbased algorithm and a geometric explanation of the eectiveness of our dual compared to the one by Dvijotham et al. (2018); and (iv) expanding the experimental analysis to include both new benchmarks, and new baselines such as CROWN (Zhang et al., 2018), ERAN (Singh et al., 2020), nnenum (Bak et al., 2020) and VeriNet (Henriksen and Lomuscio, 2020). 3De Palma, Bunel, Desmaison, Dvijotham, Kohli, Torr, and Kumar The paper is organized as follows: in section 2, we state the neural network verica tion problem and describe the technical background necessary for the understanding of our approach. Section 3 presents our novel formulation for neural network bounding, yield ing ecient incomplete veriers. Section 4 presents our branching scheme, to be used within branch and bound for complete verication. Technical and implementation details of BaDNB are outlined in section 5. In section 6, we discuss related work in the context of our contributions. Finally, sections 7 and 8 present an experimental evaluation of both our bounding algorithms and the branch and bound framework. 2. Neural Network Verication Throughout this paper, we will use bold lower case letters (for example, x) to represent vectors and upper case letters (for example, W) to represent matrices. Brackets are used to indicate intervals ([ ^lk;^uk]) and vector or matrix entries ( x[i] orW[i;j]). Moreover, we usefor the Hadamard product, J;Kfor integer ranges, 1afor the indicator vector on condition a. Finally, we write Conv( f;a;b) and Conv( S) respectively for the convex hull of function fdened in [ a;b], and for the convex hull of set S. We begin by formally introducing the problem of neural network verication ( x2.1), followed by an outline of two popular solution strategies ( x2.2,x2.3). 2.1 Problem Specication Given adlayer feedforward neural network f:Rn0!Rnd, an input domain C, and a propertyP, verication problem ( f;C;P) is dened as follows: x02C ^ xd=f(x0) =)P(xd): Under the assumption that Pis a Boolean formula over linear inequalities (for instance, robustness to adversarial examples), we can represent both fandPas annlayer neu ral network fP:Rn0!R, which is said to be in canonical form if, for any x02Rn0, P(f(x0)) =)fP(x0)0 (Bunel et al., 2018, 2020b). Verifying ( f;C;P) then reduces to nding the sign of the minimum of the following optimization problem: min x;^ x^xn s.t. x02C; (1a) ^ xk+1=Wk+1xk+bk+1k2J0;n"
429,Fusion of Global-Local Features for Image Quality Inspection of Shipping Label.txt,"The demands of automated shipping address recognition and verification have
increased to handle a large number of packages and to save costs associated
with misdelivery. A previous study proposed a deep learning system where the
shipping address is recognized and verified based on a camera image capturing
the shipping address and barcode area. Because the system performance depends
on the input image quality, inspection of input image quality is necessary for
image preprocessing. In this paper, we propose an input image quality
verification method combining global and local features. Object detection and
scale-invariant feature transform in different feature spaces are developed to
extract global and local features from several independent convolutional neural
networks. The conditions of shipping label images are classified by fully
connected fusion layers with concatenated global and local features. The
experimental results regarding real captured and generated images show that the
proposed method achieves better performance than other methods. These results
are expected to improve the shipping address recognition and verification
system by applying different image preprocessing steps based on the classified
conditions.","With the rapid rise of the logistics delivery market, the annual cost associated with failed delivery has also increased. In 2015, this annual cost was estimated to be approximately 1.5 billion dollars for the postal service and 20 billion dollars for the mailing industry in United States of America [1]. One of the main causes of misdelivery is incorrect shipping labels, which may contain falsely given addresses or may be damaged during the logistics process. Packages with problematic labels lead to not only cost loss during unnecessary delivery to undeliverables and return but also damage to the manufacturers and sellers reputations. A process for screening undeliverable addresses and errorcontaining barcodes in the shipping label that is used for identifying packages and their destinations is required. To verify the information in the shipping label, the com monly used approaches are optical character veriÔ¨Åcation (OCV) and optical character recognition (OCR). These ap proaches capture an image using a vision system or smart phone, detect regions of interest (ROIs), and recognize optical characters in the ROIs. Several traditional image processing methodologies have been applied for OCV and OCR, but deep learningbased approaches have been shown to be effective for these tasks [2], [3], [4], [5], [6]. Previous studies adoptinga deep neural network framework provided high accuracy of veriÔ¨Åcation and recognition of expiration dates in a food package or address in a shipping label [7], [8], [9]. However, the performance of OCR engines and text detec tion engines is sensitive to image quality and defects on target objects. The quality of the captured image can be affected by many degradations caused during image acquisition. Further, during the packaging and delivery processes, the shipping label can be damaged. Thus, proper assessment and classiÔ¨Åcation of the captured image and object are required to improve the text detection and recognition processes. Four poor conditions of captured images are deÔ¨Åned, and example images of generated and collected datasets are shown in Fig. 1 and Fig. 2. 1) Unreadable: Blurring is the most common issue in real world applications, occurring because of defocusing or camera motion [10], and an image acquired at the wrong positioning leads to missing the ROI. By detecting the blur degradation and incorrect positioning, the user reacquires the image and the OCR accuracy can be improved. 2) Contaminated: Shipping labels are often contaminated in the delivery process, or some part of the address area in the shipping label can be occluded by a pen mark. By processing with methods such as document image enhancement and binarization [11], [12], the address in the contaminated or occluded label can be recognized better. 3) Handwritten: The shipping label sometimes contains handwritten addresses. Because recognition engines for machineprinted characters and handwritten characters are different, the two types of characters must be clas siÔ¨Åed differently. 4) Damaged: The shipping label can be torn or occluded by another shipping label in the processes of packaging and delivery. By detecting damaged shipping labels, misdelivery can be reduced and the performance of the text recognition process can be improved. In this paper, we propose an input image quality veriÔ¨Åca tion method using convolutional neural networks (CNNs) for shipping label inspection. The proposed method classiÔ¨Åes the mentioned previously Ô¨Åve image types: normal, contaminatedarXiv:2008.11440v1  [cs.CV]  26 Aug 2020(a) Normal  (b) Contaminated  (c) Unreadable  (d) Handwritten  (e) Damaged Fig. 1. Examples of the annotated real dataset of the shipping label. (a) Normal  (b) Contaminated  (c) Unreadable  (d) Handwritten  (e) Damaged Fig. 2. Examples of the annotated generated dataset of the shipping label. address, unreadable image, handwritten address, and damaged shipping label. However, classiÔ¨Åcation methods based on CNNs are not suitable for direct use for input image quality veriÔ¨Åcation because of two problems. One problem is the varying aspect ratios and sizes of shipping label images. The varying aspect ratios make it difÔ¨Åcult to design a CNN with a Ô¨Åxed image size as input. Another problem is that it is difÔ¨Åcult to distinguish between contaminants in the address area and contaminants in other areas. In general, there are two methods for handling input images of different sizes: (1) resizing the input image while maintaining the aspect ratio in the padding space and (2) using patches as inputs to the CNN to extract discrimi native features. However, resizing the input images leads to increasing the ambiguity between normal and blurred images because of the loss of detailed features, making it difÔ¨Åcult to detect defects in ROIs. Conversely, dividing an input image into patches can lead to the loss of global features, degrading the classiÔ¨Åcation performance. We integrate local and global features from different CNNs. To localize the local features, we detect the barcode and address areas using the deeplearning object detection algo rithm You Only Look Once (YOLO) [13], [14]. Then, we localize and crop regions with strong features using one of the famous feature extraction methods, features from accelerated segment test (FAST) [15]. The global features are extracted from the global CNNs with a resized input image, and the local features are extracted from independent local CNNs with the detected address and barcode area and the localized regions using FAST. We concatenate the global and local features together into fully connected fusion layers to classify the shipping label image conditions. The contribution of thispaper can be summarized into two points. (1) We detect and localize the ROIs using YOLO and FAST and extract the local features using independent local CNNs. (2) By constructing the variant global and local images to combine the global and local features, we propose a novel CNN modelbased stacked generalization ensemble method [16] for image quality veriÔ¨Åcation. The rest of the paper is organized as follows. Section II summarizes related works. Section III describes the details of the proposed algorithm, and Section IV presents the experi mental results. Finally, Section V concludes the paper with discussion of the results. II. R ELATED WORK "
6,Structure Learning of Deep Neural Networks with Q-Learning.txt,"Recently, with convolutional neural networks gaining significant achievements
in many challenging machine learning fields, hand-crafted neural networks no
longer satisfy our requirements as designing a network will cost a lot, and
automatically generating architectures has attracted increasingly more
attention and focus. Some research on auto-generated networks has achieved
promising results. However, they mainly aim at picking a series of single
layers such as convolution or pooling layers one by one. There are many elegant
and creative designs in the carefully hand-crafted neural networks, such as
Inception-block in GoogLeNet, residual block in residual network and dense
block in dense convolutional network. Based on reinforcement learning and
taking advantages of the superiority of these networks, we propose a novel
automatic process to design a multi-block neural network, whose architecture
contains multiple types of blocks mentioned above, with the purpose to do
structure learning of deep neural networks and explore the possibility whether
different blocks can be composed together to form a well-behaved neural
network. The optimal network is created by the Q-learning agent who is trained
to sequentially pick different types of blocks. To verify the validity of our
proposed method, we use the auto-generated multi-block neural network to
conduct experiments on image benchmark datasets MNIST, SVHN and CIFAR-10 image
classification task with restricted computational resources. The results
demonstrate that our method is very effective, achieving comparable or better
performance than hand-crafted networks and advanced auto-generated neural
networks.","During the last few years, deep learning has been play ing an increasingly important role in the Ô¨Åeld of computervision, such as image classiÔ¨Åcation and object recognition, especially with the convolutional neural networks (CNNs) making great achievements. CNNs architectures evolving from traditional layerstacking in a plain way like Alexnet [15], VGG Net [21], to multibranch Inception modules in GoogleNet [24], shortcut connection in Residual Network (ResNet) [8] and dense connection in Dense Convolutional Network (DenseNet) [10], have achieved increasingly high performance. However, designing network architectures of ten not only needs a great many number of possible conÔ¨Ågu rations, for example, the number of layers of each type and hyperparameters for each type of layer, but also requires a lot of expert experience, knowledge and plenty of time. Hence there is a growing trend from handcrafted archi tecture designing to automated network generating. Some research work [27, 1, 26, 4] has been done to automati cally learn wellbehaved neural network architectures and made promising results. Despite the learned networks have yielded nice results, the work in [27] and [1] are just di rectly generate the entire plain network by stacking single layers one by one, while in [26], it aims at automatically generating block structure. Starting from 2014, deeper and wider networks are uti lized to signiÔ¨Åcantly improve the performance of network architecture, emerging a number of networks that are no longer stacked layer by layer, among which the represen tative architectures include Inception network [24], ResNet [8] and DenseNet [10]. These networks have many excel lences that are deserved us to learn from and are crucial for learning good feature representations. For instance, the inception architecture is based on multiscale processing; the residual unit in ResNet elementwisely adds the input features to the output by adopting skip connection to en able feature reusage, while the dense block in DenseNet concatenates the input features with the output features to enable new feature exploration. Moreover, the architec tures of these networks are mostly assembled as the stack 1arXiv:1810.13155v1  [cs.LG]  31 Oct 2018of respective block units, which can been seen in Figure 1. In this paper, unlike other methods [27, 1, 26, 4], we are Figure 1: (a) Inception block unit of GoogLeNet (except for the dotted line). (b) Residual block unit of ResNet. (c) Dense block unit in DenseNet. The input shown in block units refers to the output from the last block, and the output would be the input of the next block. And more, a complete GoogLeNet, ResNet, DenseNet are stacked by their respec tive block units. willing to make use of the beneÔ¨Åts of these stateoftheart blocks mentioned above and explore the possibility whether different blocks can be composed together to form a well behaved neural network, so that we specify several differ ent types of block modules and propose a novel automatic process to stack them to generate a multiblock neural net work. We regard a block module as a layer of a CNN model to construct the whole network. And we learn the struc tures of deep networks based on these autogenerated and diverse multiblock neural networks. Moreover, we employ the wellknown Qlearning [25] as an agent to sequentially select block modules of a CNN model with greedy strat egy [18]. The validation accuracy on the given machine learning task would be viewed as the reward feedback to the agent to pick an architecture. By utilizing experience replay technique [16], the goal of Qlearning agent is to Ô¨Ånd the optimal network architectures that behave well without manual intervention. Our model generation method can be summarized in Figure 2. We conduct experiments on standard image benchmark datasets: CIFAR10, SVHN and MNIST for image clas siÔ¨Åcation tasks. The automatically constructed network ar chitectures present competitive performance compared with those handcrafted networks as well as autogenerated net works, achieving the best result on CIFAR10, SVHN and MNIST with 4.68%, 1.96%, 0.34% test error rate respec tively. In addition to obtaining wellbehaved multiblock neural networks via reinforcement learning (RL), we have some interesting Ô¨Åndings from our replay memory which stores a lot of data about structure information of multi block networks. Figure 2: The overall model generation process: The Q learning agent Ô¨Årstly samples block codes (the description of our blocks, introduced in detail later) and store them in replay memory, then according to a set of picked block codes to automatically stack blocks to construct a network and train it on speciÔ¨Åc tasks. Via training the newlybuilt network, we can receive a validation accuracy which can be regarded as the reward feedback to the Qlearning agent to update its Qvalue. Consequently, the agent would be prompted to select a betterperforming model in the next iteration. 2. Related Work "
183,Reluplex: An Efficient SMT Solver for Verifying Deep Neural Networks.txt,"Deep neural networks have emerged as a widely used and effective means for
tackling complex, real-world problems. However, a major obstacle in applying
them to safety-critical systems is the great difficulty in providing formal
guarantees about their behavior. We present a novel, scalable, and efficient
technique for verifying properties of deep neural networks (or providing
counter-examples). The technique is based on the simplex method, extended to
handle the non-convex Rectified Linear Unit (ReLU) activation function, which
is a crucial ingredient in many modern neural networks. The verification
procedure tackles neural networks as a whole, without making any simplifying
assumptions. We evaluated our technique on a prototype deep neural network
implementation of the next-generation airborne collision avoidance system for
unmanned aircraft (ACAS Xu). Results show that our technique can successfully
prove properties of networks that are an order of magnitude larger than the
largest networks verified using existing methods.","Articial neural networks [7,31] have emerged as a promising approach for cre ating scalable and robust systems. Applications include speech recognition [9], image classication [22], game playing [32], and many others. It is now clear that software that may be extremely dicult for humans to implement can instead be created by training deep neural networks (DNN s), and that the performance of these DNNs is often comparable to, or even surpasses, the performance of manually crafted software. DNNs are becoming widespread, and this trend is likely to continue and intensify. Great eort is now being put into using DNNs as controllers for safetycritical systems such as autonomous vehicles [4] and airborne collision avoidance systems for unmanned aircraft (ACAS Xu) [13]. DNNs are trained over a nite set of in puts and outputs and are expected to generalize , i.e. to behave correctly for previouslyunseen inputs. However, it has been observed that DNNs can react in unexpected and incorrect ways to even slight perturbations of their inputs [33]. This unexpected behavior of DNNs is likely to result in unsafe systems, or re strict the usage of DNNs in safetycritical applications. Hence, there is an urgent ?This is the extended version of a paper with the same title that appeared at CAV 2017.arXiv:1702.01135v2  [cs.AI]  19 May 2017need for methods that can provide formal guarantees about DNN behavior. Un fortunately, manual reasoning about large DNNs is impossible, as their structure renders them incomprehensible to humans. Automatic verication techniques are thus sorely needed, but here, the state of the art is a severely limiting factor. Verifying DNNs is a dicult problem. DNNs are large, nonlinear, and non convex, and verifying even simple properties about them is an NPcomplete problem (see Section I of the appendix). DNN verication is experimentally beyond the reach of generalpurpose tools such as linear programming (LP) solvers or existing satisability modulo theories (SMT ) solvers [3, 10, 30], and thus far, dedicated tools have only been able to handle very small networks (e.g. a single hidden layer with only 10 to 20 hidden nodes [29,30]). The diculty in proving properties about DNNs is caused by the presence ofactivation functions . A DNN is comprised of a set of layers of nodes, and the value of each node is determined by computing a linear combination of values from nodes in the preceding layer and then applying an activation function to the result. These activation functions are nonlinear and render the problem nonconvex. We focus here on DNNs with a specic kind of activation func tion, called a Rectied Linear Unit (ReLU ) [26]. When the ReLU function is applied to a node with a positive value, it returns the value unchanged (the active case), but when the value is negative, the ReLU function returns 0 (the inactive case). ReLUs are very widely used [22, 24], and it has been suggested that their piecewise linearity allows DNNs to generalize well to previously un seen inputs [6,7,11,26]. Past eorts at verifying properties of DNNs with ReLUs have had to make signicant simplifying assumptions [3, 10] | for instance, by considering only small input regions in which all ReLUs are xed at either the active or inactive state [3], hence making the problem convex but at the cost of being able to verify only an approximation of the desired property. We propose a novel, scalable, and ecient algorithm for verifying properties of DNNs with ReLUs. We address the issue of the activation functions head on, by extending the simplex algorithm | a standard algorithm for solving LP instances | to support ReLU constraints. This is achieved by leveraging the piecewise linear nature of ReLUs and attempting to gradually satisfy the constraints that they impose as the algorithm searches for a feasible solution. We call the algorithm Reluplex , for \ReLU with Simplex"". The problem's NPcompleteness means that we must expect the worstcase performance of the algorithm to be poor. However, as is often the case with SAT and SMT solvers, the performance in practice can be quite reasonable; in particular, our experiments show that during the search for a solution, many of the ReLUs can be ignored or even discarded altogether, reducing the search space by an order of magnitude or more. Occasionally, Reluplex will still need tosplit on a specic ReLU constraint | i.e., guess that it is either active or inactive, and possibly backtrack later if the choice leads to a contradiction. We evaluated Reluplex on a family of 45 realworld DNNs, developed as an early prototype for the nextgeneration airborne collision avoidance system for unmanned aircraft ACAS Xu [13]. These fully connected DNNs have 8 layersand 300 ReLU nodes each, and are intended to be run onboard aircraft. They take in sensor data indicating the speed and present course of the aircraft (the ownship ) and that of any nearby intruder aircraft, and issue appropriate naviga tion advisories. These advisories indicate whether the aircraft is clearofcon ict, in which case the present course can be maintained, or whether it should turn to avoid collision. We successfully proved several properties of these networks, e.g. that a clearofcon ict advisory will always be issued if the intruder is su ciently far away or that it will never be issued if the intruder is suciently close and on a collision course with the ownship. Additionally, we were able to prove certain robustness properties [3] of the networks, meaning that small adversarial perturbations do not change the advisories produced for certain inputs. Our contributions can be summarized as follows. We (i) present Reluplex, an SMT solver for a theory of linear real arithmetic with ReLU constraints; (ii) show how DNNs and properties of interest can be encoded as inputs to Reluplex; (iii) discuss several implementation details that are crucial to performance and scalability, such as the use of  oatingpoint arithmetic, bound derivation for ReLU variables, and con ict analysis; and (iv) conduct a thorough evaluation on the DNN implementation of the prototype ACAS Xu system, demonstrating the ability of Reluplex to scale to DNNs that are an order of magnitude larger than those that can be analyzed using existing techniques. The rest of the paper is organized as follows. We begin with some background on DNNs, SMT, and simplex in Section 2. The abstract Reluplex algorithm is described in Section 3, with key implementation details highlighted in Section 4. We then describe the ACAS Xu system and its prototype DNN implementation that we used as a casestudy in Section 5, followed by experimental results in Section 6. Related work is discussed in Section 7, and we conclude in Section 8. "
74,Learning Speaker Representations with Mutual Information.txt,"Learning good representations is of crucial importance in deep learning.
Mutual Information (MI) or similar measures of statistical dependence are
promising tools for learning these representations in an unsupervised way. Even
though the mutual information between two random variables is hard to measure
directly in high dimensional spaces, some recent studies have shown that an
implicit optimization of MI can be achieved with an encoder-discriminator
architecture similar to that of Generative Adversarial Networks (GANs). In this
work, we learn representations that capture speaker identities by maximizing
the mutual information between the encoded representations of chunks of speech
randomly sampled from the same sentence. The proposed encoder relies on the
SincNet architecture and transforms raw speech waveform into a compact feature
vector. The discriminator is fed by either positive samples (of the joint
distribution of encoded chunks) or negative samples (from the product of the
marginals) and is trained to separate them. We report experiments showing that
this approach effectively learns useful speaker representations, leading to
promising results on speaker identification and verification tasks. Our
experiments consider both unsupervised and semi-supervised settings and compare
the performance achieved with different objective functions.","Deep learning has shown remarkable success in numerous speech tasks, including speech recognition [1‚Äì4] and speaker recognition [5, 6]. The deep learning paradigm aims to de scribe data by means of a hierarchy of representations, that are progressively combined to model higher level abstractions [7]. Most commonly, deep neural networks are trained in a super vised way, while learning meaningful representations in an un supervised fashion is more challenging but could be useful es pecially in semisupervised settings. Several approaches have been proposed for deep unsuper vised learning in the last decade. Notable examples are deep autoencoders [8], Restricted Boltzmann Machines (RBMs) [9], variational autoencoders [10] and, more recently, Generative Adversarial Networks (GANs) [11]. GANs are often used in the context of generative modeling, where they attempt to mini mize a measure of discrepancy between a distribution generated by a neural network and the data distribution. Beyond genera tive modeling, some works have extended this framework to learn features that are invariant to different domains [12] or to noise conditions [13]. Moreover, we recently witnessed some remarkable attempts to learn unsupervised representations by minimizing or maximizing Mutual Information (MI) [14‚Äì17]. This measure is a fundamental quantity for estimating the sta tistical dependence between random variables and is deÔ¨Ånedas the KullbackLeibler (KL) divergence between the joint dis tribution over these random variables and the product of their marginal distributions [18]. As opposed to other metrics, such as correlation, MI can capture complex nonlinear relationships between random variables [19]. MI, however, is difÔ¨Åcult to compute directly, especially in high dimensional spaces [20]. The aforementioned works found that it is possible to maximize or minimize the MI within a framework that closely resembles that of GANs. Additionally, [15] has further proved that it is even possible to explicitly compute it by exploiting its Donsker Varadhan bound. Here we attempt to learn good speaker representations by maximizing the mutual information between two encoded ran dom chunks of speech sampled from the same sentence. Our ar chitecture employs both an encoder, that transforms raw speech samples into a compact feature vector, and a discriminator. The latter is alternatively fed by samples from the joint distribution (i.e. two local encoded vectors randomly drawn from the same speech sentence) and from the product of marginal distributions (i.e, two local encoder vectors coming different utterances). The discriminator is jointly trained with the encoder to maximize the separability of the two distributions. We called our approach Local Info Max (LIM) to highlight the fact that it is simply based on randomly sampled local speech chunks. Our encoder is based on SincNet [21,22], which efÔ¨Åciently processes the raw input waveforms with learnable bandpass Ô¨Ålters based on sinc functions. The experimental results show that our approach learns use ful speaker features, leading to promising results on speaker identiÔ¨Åcation and veriÔ¨Åcation tasks. Our experiments are con ducted in both unsupervised and semisupervised settings and compare different objective functions for the discriminator. We release the code of LIM within the PyTorchKaldi toolkit [23]. 2. Speaker Representations based on MI The mutual information between two random variables z1and z2is deÔ¨Åned as follows: MI(z1;z2) =Z z1Z z2p(z1;z2)logp(z1;z2) p(z1)p(z2) dz1dz2 =DKL"
96,Neural Network Verification using Residual Reasoning.txt,"With the increasing integration of neural networks as components in
mission-critical systems, there is an increasing need to ensure that they
satisfy various safety and liveness requirements. In recent years, numerous
sound and complete verification methods have been proposed towards that end,
but these typically suffer from severe scalability limitations. Recent work has
proposed enhancing such verification techniques with abstraction-refinement
capabilities, which have been shown to boost scalability: instead of verifying
a large and complex network, the verifier constructs and then verifies a much
smaller network, whose correctness implies the correctness of the original
network. A shortcoming of such a scheme is that if verifying the smaller
network fails, the verifier needs to perform a refinement step that increases
the size of the network being verified, and then start verifying the new
network from scratch - effectively ""wasting"" its earlier work on verifying the
smaller network. In this paper, we present an enhancement to abstraction-based
verification of neural networks, by using residual reasoning: the process of
utilizing information acquired when verifying an abstract network, in order to
expedite the verification of a refined network. In essence, the method allows
the verifier to store information about parts of the search space in which the
refined network is guaranteed to behave correctly, and allows it to focus on
areas where bugs might be discovered. We implemented our approach as an
extension to the Marabou verifier, and obtained promising results.","In recent years, the use of deep neural networks (DNNs) [15] in critical compo nents of diverse systems has been gaining momentum. A few notable examples include the elds of speech recognition [10], image recognition [16], autonomous driving [6], and many others. The reason for this unprecedented success is the ability of DNNs to generalize from a small set of training data, and then correctly handle previously unseen inputs.arXiv:2208.03083v2  [cs.NE]  27 Aug 2022Still, despite their success, neural networks suer from various reliability is sues. First, they are completely dependent on the training process, which may include data that is anecdotal, partial, noisy, or biased [21,27]; further, the train ing process has inherent overtting limitations [33]; and nally, trained networks suer from susceptibility to adversarial attacks, as well as from obscurity and lack of explainability [1]. Unless addressed, these concerns, and others, are likely to limit the applicability of DNNs in the coming years. A promising approach for improving the reliability of DNN models is to apply formal verication techniques: automated and rigorous techniques that can ensure that a DNN model adheres to a given specication, in all possible corner cases [14,17,19,29]. While sound and complete formal verication methods can certify that DNNs are reliable, these methods can typically only tackle small or mediumsized DNNs; and despite signicant strides in recent years, scalability remains a major issue [4]. In order to improve the scalability of DNN verication, recent studies have demonstrated the great potential of enhancing it with abstractionrenement techniques [2,8,13,25]. The idea is to use a blackbox DNN verier, and feed it a series of abstract networks | i.e., DNNs that are signicantly smaller than the original network being veried. Because the complexity of DNN verication is exponential in the size of the DNN in question [19], these queries can be solved relatively quickly; and the abstract networks are constructed so that their cor rectness implies the correctness of the original, larger network. The downside of abstraction is that sometimes, verifying the smaller network returns an incon clusive result | in which case, the abstract network is rened and made slightly larger, and the process is repeated. Is it well known that the heuristics used for performing the abstraction and renement steps can have a signicant impact on performance [8,13], and that poor heuristics can cause the abstractionrenement sequence of queries to take longer to dispatch than the original query. In this paper, we propose an extension that can improve the performance of an abstractionrenement verication scheme. The idea is to use residual rea soning [3]: an approach for reusing information obtained in an early verication query, in order to expedite a subsequent query. Presently, a verier might verify an abstract network N1, obtain an inconclusive answer, and then verify a rened network,N2; and it will verify N2from scratch, as if it had never veried N1. Using residual reasoning, we seek to leverage the similarities between N1andN2 in order to identify large portions of the verication search space that need not be explored, because we are guaranteed apriori that they contain no violations of the property being checked. More specically, modern veriers can be regarded as traversing a large search tree. Each branching in the tree is caused by an activation function within the neural network, which can take on multiple linear phases; and each branch cor responds to one of these phases. We show that when a verier traverses a branch of the search tree and determines that no property violations occur therein, that information can be used to deduce that no violation can exist in some of the branches of the search tree traversed when verifying a rened network. The advantages of this approach are clear: by curtailing the search space, the verication process can be expedited signicantly. The disadvantage is that, unlike in other abstractionrenement based techniques, the verier needs to be instrumented, and cannot be used as a black box. Our contributions in this paper are as follows: (i) we formally dene our residual reasoning scheme, in a general way that preserves the soundness and completeness of the underlying verier; (ii) we specify how our approach can be used to extend the stateoftheart Marabou DNN verication engine [20]; and (iii) we implement our approach, and evaluate it on the ACAS Xu set of benchmarks [18]. We regard this work as a step towards tapping into the great potential of abstractionrenement methods in the context of DNN verication. The rest of the paper is organized as follows. In Section 2 we recap the necessary background on DNNs and their verication. Next, in Section 3 we describe our general method for residual reasoning; followed by a discussion of how our technique can enhance a specic abstractionrenement method, in Section 4. Sections 5 is then dedicated to explaining how our method can be applied using the Marabou DNN verier as a backend, followed by our evaluation of the approach in Section 6. Related work is covered in Section 7, and we "
191,Improving Embedding Extraction for Speaker Verification with Ladder Network.txt,"Speaker verification is an established yet challenging task in speech
processing and a very vibrant research area. Recent speaker verification (SV)
systems rely on deep neural networks to extract high-level embeddings which are
able to characterize the users' voices. Most of the studies have investigated
on improving the discriminability of the networks to extract better embeddings
for performances improvement. However, only few research focus on improving the
generalization. In this paper, we propose to apply the ladder network framework
in the SV systems, which combines the supervised and unsupervised learning
fashions. The ladder network can make the system to have better high-level
embedding by balancing the trade-off to keep/discard as much useful/useless
information as possible. We evaluated the framework on two state-of-the-art SV
systems, d-vector and x-vector, which can be used for different use cases. The
experiments showed that the proposed approach relatively improved the
performance by 10% at most without adding parameters and augmented data.","Speaker veriÔ¨Åcation (SV) aims to verify a speaker using the speech signal. As an open set recognition problem, speaker veriÔ¨Åcation performs the task where testing labels are not seen during training, and most probably, there is large mismatch be tween testing and training data (different environments, lan guages, and devices) [1, 2, 3, 4, 5, 6, 7]. A standard pipeline is extracting a speaker embedding relying on some trained model and comparing the similarity between the registered and test ing embeddings. One key problem in this task is extracting a good embedding which can capture characteristics of the input voice to discriminate speakers. Recently, the deep neural net work (DNN) approaches are widely used since they were proved to be able to extract better highlevel embeddings [4, 5, 6, 7]. The DNN approaches don‚Äôt have presumption of the data dis tribution, in contrast, they can learn the data distribution in a datadriven fashion in manifold space [8, 9, 10]. Research has also been done to improve the capability of DNN to output better embeddings. Previous work has either focused on improving the capability of modeling the hidden representation from the input, e.g. convolutional neural net work (CNN), timedelay neural network (TDNN), or focused on designing more discriminative loss functions for classiÔ¨Åca tion task during the neural networking training, e.g. siamese neural network (SNN) and triplet loss. Only few efforts have investigated training strategies to maintain more original infor mation in inputs. This is important, because supervised learning essentially discards input information regarding the targeting task within the DNN framework. We don‚Äôt know what information will affect the performance on testing data during training in the open set recognition problem, like SV , it is necessary to keep input information as much as possible when we train the embedding extraction model in supervised learning fashion. In this paper, we propose to apply ladder network framework to the SV system training. Ladder networks combine supervised and unsupervised learning fashions together. On one hand, super vised learning makes the network discard useless information regarding the classiÔ¨Åcation task (capture the speaker‚Äôs charac teristics); on the other hand, unsupervised learning makes the network keep useful information regarding the reconstruction task (improve the system generalization). Ladder network per forms these two learning fashions simultaneously during train ing, so it guarantees to keep balance in the tradeoff of keeping and discarding information. The remaining of the paper is organized in this way: Section 2 reviews previous related work; Section 3 describes the details of our proposed SV system; Section 4.1 introduces the corpus we used and the features we extracted in this study; Section 4 introduce our experiments and the results; at last, we will draw conclusions in Section 5. 2. Related Work "
523,Towards Reliable Neural Specifications.txt,"Having reliable specifications is an unavoidable challenge in achieving
verifiable correctness, robustness, and interpretability of AI systems.
Existing specifications for neural networks are in the paradigm of data as
specification. That is, the local neighborhood centering around a reference
input is considered to be correct (or robust). While existing specifications
contribute to verifying adversarial robustness, a significant problem in many
research domains, our empirical study shows that those verified regions are
somewhat tight, and thus fail to allow verification of test set inputs, making
them impractical for some real-world applications. To this end, we propose a
new family of specifications called neural representation as specification,
which uses the intrinsic information of neural networks - neural activation
patterns (NAPs), rather than input data to specify the correctness and/or
robustness of neural network predictions. We present a simple statistical
approach to mining neural activation patterns. To show the effectiveness of
discovered NAPs, we formally verify several important properties, such as
various types of misclassifications will never happen for a given NAP, and
there is no ambiguity between different NAPs. We show that by using NAP, we can
verify a significant region of the input space, while still recalling 84% of
the data on MNIST. Moreover, we can push the verifiable bound to 10 times
larger on the CIFAR10 benchmark. Thus, we argue that NAPs can potentially be
used as a more reliable and extensible specification for neural network
verification.","The advances in deep neural networks (DNNs) have brought a wide societal impact in many domains such as transportation, healthcare, Ô¨Ånance, ecommerce, and education. This growing societalscale impact has also raised some risks and concerns about errors in AI software, their susceptibility to cyberattacks, and AI system safety (Dietterich & Horvitz, 2015). Therefore, the challenge of veriÔ¨Åcation and validation of AI systems, as well as, achieving trustworthy AI (Wing, 2021), has attracted much attention of the research community. Existing works approach this challenge by building on formal methods ‚Äì a Ô¨Åeld of computer science and engineering that involves verifying properties of systems using rigorous mathematical speciÔ¨Åcations and proofs (Wing, 1990). Having a formal speciÔ¨Åcation ‚Äî a precise, mathematical statement of what AI system is supposed to do is critical for formal veriÔ¨Åcation. Most works (Katz et al., 2017; 2019; Huang et al., 2017; 2020; Wang et al., 2021) use the speciÔ¨Åcation of adversarial robustness for classiÔ¨Åcation tasks that states that the NN correctly classiÔ¨Åes an image as a given adversarial label under perturbations with a speciÔ¨Åc norm (usually L8). Generally speaking, existing works use a paradigm of data as speciÔ¨Åcation ‚Äî the robustness of local neighborhoods of reference data points with groundtruth labels is the only speciÔ¨Åcation of correct behaviors. However, from a learning perspective, this would lead to overÔ¨Åtted speciÔ¨Åcation, since only local neighborhoods of reference inputs get certiÔ¨Åed. As a concrete example, Figure 1 illustrates the fundamental limitation of such overÔ¨Åtted speciÔ¨Åca tions. SpeciÔ¨Åcally, a testing input like the one shown in Fig. 1a can hardly be veriÔ¨Åed even if all *These authors contributed equally to this work. 1arXiv:2210.16114v5  [cs.LG]  17 Mar 2023(a) A testing image from MNIST, classiÔ¨Åed as 1 (b) The closest training image in MNIST, whose L8distance to Fig. 1a is 0.5294 (c) An adversarial exam ple misclassiÔ¨Åed as 8, whoseL8distance to Fig. 1b is 0.2 (d) A testing image, on which our veriÔ¨Åed NAP (for digit 1) disagrees with the ground truth (i.e., 7) Figure 1: The limitation of ‚ÄúdataasspeciÔ¨Åcation‚Äù: First three images show that a test input can be much further away (in L8) from its closest train input compared to adversarial examples (the upper bound of a veriÔ¨Åable local region). The last image shows that even data itself can be imperfect. local neighborhoods of all training images have been certiÔ¨Åed using the L8norm. This is because adversarial examples like Fig. 1c fall into a much closer region compared to testing inputs (e.g., Fig. 1a), as a result, the truly veriÔ¨Åable region for a given reference input like Fig. 1b can only be smaller. All neural network veriÔ¨Åcation approaches following such dataasspeciÔ¨Åcation paradigm inherit this limitation regardless of their underlying veriÔ¨Åcation techniques. In order to avoid such a limitation, a new paradigm for specifying what is correct or wrong is necessary. The intrinsic challenge is that manually giving a proper speciÔ¨Åcation on the input space is no easier than directly programming a solution to the machine learning problem itself. We envision that a promising way to address this challenge is developing speciÔ¨Åcations directly on top of, instead of being agnostic to, the learned model. We propose a new family of speciÔ¨Åcations, neural representation as speciÔ¨Åcation , where neural activation patterns form speciÔ¨Åcations. The key observation is that inputs from the same class often share a neural activation pattern (NAP) ‚Äì a carefully chosen subset of neurons that are expected to be activated (or not activated) for the majority of inputs in a class. Although two inputs are distant in a certain norm in the input space, the neural activations exhibited when the same prediction is made are very close. For instance, we can Ô¨Ånd a single NAP that is shared by nearly all training and testing images (including Fig. 1a and Fig. 1b) in the same class but not the adversarial example like Fig. 1c. We can further formally verify thatall possible inputs following this particular NAP can never be misclassiÔ¨Åed. SpeciÔ¨Åcations based on NAP enable successful veriÔ¨Åcation of a broad region of inputs, which would not be possible if the dataasspeciÔ¨Åcation paradigm were used. For the MNIST dataset, a veriÔ¨Åable NAP mined from the training images could cover up to 84% testing images, a signiÔ¨Åcant improvement in contrast to 0% when using neighborhoods of training images as the speciÔ¨Åcation. To our best knowledge, this is the Ô¨Årst time that a signiÔ¨Åcant fraction of unseen testing images have been formally veriÔ¨Åed. This unique advantage of using NAPs as speciÔ¨Åcation is enabled by the intrinsic information (or neural representation) embedded in the neural network model. Furthermore, such information is a simple byproduct of a prediction and can be collected easily and efÔ¨Åciently. Besides serving as reliable speciÔ¨Åcations for neural networks, we foresee other important applications of NAPs. For instance, veriÔ¨Åed NAPs may serve as proofs of correctness or certiÔ¨Åcates for predictions. We hope our initial Ô¨Åndings shared in this paper would inspire new interesting applications. We summarize our contribution as follows: ‚Ä¢ We propose a new family of formal speciÔ¨Åcations for neural networks, neural represen tation as speciÔ¨Åcation , which use activation patterns (NAPs) as speciÔ¨Åcations. We also introduce a tunable parameter to specify the level of abstraction of NAPs. ‚Ä¢ We propose a simple yet effective approximate method to mine NAPs from neural networks and training datasets. 2‚Ä¢ We show that NAPs can be easily checked by outofthebox neural network veriÔ¨Åcation tools used in VNNCOMP ‚Äì the annual neural network veriÔ¨Åcation competition, such as Marabou. ‚Ä¢ We conduct thorough experimental evaluations from both statistical and formal veriÔ¨Åca tion perspectives. Particularly, we show that a single NAP is sufÔ¨Åcient for certifying a signiÔ¨Åcant fraction of unseen inputs. 2 B ACKGROUND 2.1 N EURAL NETWORKS FOR CLASSIFICATION TASKS In this paper, we focus on feedforward neural networks for classiÔ¨Åcation (including convolutional neural nets). A neural network NofLlayers is a settpWi;biq|1¬§i¬§Lu, where Wiandbi are the weight matrix and the bias for layer i, respectively. The neural network NdeÔ¨Åned a function FN:Rd0√ëRdL(d0anddLrepresent the input and output dimension, respectively), deÔ¨Åned as FNpxqzLpxq, wherez0pxqx,zipxqWipzi1pxqq"
13,Learning based Facial Image Compression with Semantic Fidelity Metric.txt,"Surveillance and security scenarios usually require high efficient facial
image compression scheme for face recognition and identification. While either
traditional general image codecs or special facial image compression schemes
only heuristically refine codec separately according to face verification
accuracy metric. We propose a Learning based Facial Image Compression (LFIC)
framework with a novel Regionally Adaptive Pooling (RAP) module whose
parameters can be automatically optimized according to gradient feedback from
an integrated hybrid semantic fidelity metric, including a successfully
exploration to apply Generative Adversarial Network (GAN) as metric directly in
image compression scheme. The experimental results verify the framework's
efficiency by demonstrating performance improvement of 71.41%, 48.28% and
52.67% bitrate saving separately over JPEG2000, WebP and neural network-based
codecs under the same face verification accuracy distortion metric. We also
evaluate LFIC's superior performance gain compared with latest specific facial
image codecs. Visual experiments also show some interesting insight on how LFIC
can automatically capture the information in critical areas based on semantic
distortion metrics for optimized compression, which is quite different from the
heuristic way of optimization in traditional image compression algorithms.","Face veriÔ¨Åcation /recognition has been developing rapidly in recent years, which facilitates a wide range of intelligent applications such as surveillance video anal ysis, mobile authentication, etc. Since these frequently used applications generate a huge amount of data that requires to be transmitted or stored, a highly e cient facial image compression is broadly required as illus trated in Fig. 1. Basically, facial image compression can be regarded as a special application of general image compression technology. While evolution of general image /video compression techniques has been focused on continu ously improving Rate Distortion performance, viz. re ducing the compressed bit rate under the same distortion between the reconstructed pixels and original pixels or reducing the distortion under the same bit rate. The ap parent question is how to deÔ¨Åne the distortion metric, especially for speciÔ¨Åc application scenario such as face Email address: chenzhibo@ustc.edu.cn (Zhibo Chen) Figure 1: A highly e cient facial image compression is broadly re quired (located in blue arrow) in a wide range of intelligent applica tions. recognition in surveillance. Usually we can classify the distortion into three levels of distortion metrics: Pixel Fidelity ,Perceptual Fidelity , and Semantic Fidelity , according to di erent levels of human cognition on im age/video signals. The most common metric is Pixel Fidelity , which measures the pixel level di erence between the orig inal image and compressed image, e.g., MSE (Mean Square Error) has been widely adopted in many ex isted image and video coding techniques and standards (e.g., MPEG2, H.264, HEVC, etc.). It can be easily integrated into image /video hybrid compression frame Preprint submitted to Neurocomputing March 8, 2019arXiv:1812.10067v2  [cs.MM]  7 Mar 2019(a)  (b) Figure 2: The visualization of gradient feedback from (a) MSE; (b) the integrated face veriÔ¨Åcation metric, which shows that more focus is on the distinguishable regions ( e.g., eye, nose) according to such semantic distortion metric. work as an inloop metric for ratedistortion optimized compression. However, it‚Äôs obvious that pixel Ô¨Ådelity metric cannot fully reÔ¨Çect human perceptual viewing experience [1]. Therefore, many researchers have de veloped Perceptual Fidelity metrics to investigate ob jective metrics measuring human subjective viewing experience [2]. With the development of aforemen tioned intelligent applications, image /video signals will be captured and processed for semantic analysis. Con sequently, there will be increasingly more requirements on research for Semantic Fidelity metric to study the semantic di erence ( e.g., dierence of veriÔ¨Åcation ac curacy) between the original image and compressed im age. There are few research work on this area [3, 4] and usually are taskspeciÔ¨Åc. The aforementioned various distortion metrics pro vide a criteria to measure the quality of reconstructed content. However, the ultimate target of image quality assessment is not only to measure the quality of images with di erent level of distortion, but also to apply these metrics to optimize image compression schemes. While it‚Äôs a contradictory that most complicated quality met rics with high performance are not able to be integrated easily into an image compression loop. Some research works tried to do this by adjusting image compression parameters ( e.g., Quantization parameters) heuristically according to embedded quality metrics [5, 6], but they are still not fully automaticoptimized endtoend image encoder with integration of complicated distortion met rics. In this paper, we are trying to solve this problem by developing a Learning based Facial Image Compression (LFIC) framework, to make it feasible to automaticallyoptimize coding parameters according to gradient feed back from the integrated hybrid facial image distortion metric calculation module. Di erent from traditional hybrid coding framework with prediction, transform, quantization and entropy coding modules, we separate these di erent modules inside or outside the endtoend loop according to their derivable property. We demon strated the e ciency of this framework with the sim plest prediction, quantization and entropy coding mod ule. We propose a new module called Regionally Adap tive Pooling (RAP) inside the endtoend loop to im prove the ability to conÔ¨Ågure compression performance. RAP has advantages of being able to control bit alloca tion according to distortion metrics‚Äô feedback under a given bit budget. Face veriÔ¨Åcation accuracy is adopted as one semantic distortion metric to be integrated into LFIC framework. Although we adopt the simplest prediction, quanti zation and entropy coding module, the LFIC frame work has shown great improvement over traditional codec like JPEG2000, WebP and neural networkbased codecs, and also demonstrates much better performance compared with existing speciÔ¨Åc facial image compres sion schemes. The visualization as illustrated in Fig. 2 shows that more focus is on the distinguishable re gions ( e.g., eye, nose) according to face veriÔ¨Åcation metric. Also, it demonstrates that our LFIC framework can automatically capture the information in critical ar eas based on semantic distortion metric. In general, our contributions are fourfolds: 1) a Learning based Facial Image Compression framework; 2) a novel pooling strategy called RAP; 3) a successful exploration to apply Generative Adversarial Network (GAN) as metric to compression directly; 4) a starting exploration for semantic based image compression. 2. Related Work "
303,Learning Features for Offline Handwritten Signature Verification using Deep Convolutional Neural Networks.txt,"Verifying the identity of a person using handwritten signatures is
challenging in the presence of skilled forgeries, where a forger has access to
a person's signature and deliberately attempt to imitate it. In offline
(static) signature verification, the dynamic information of the signature
writing process is lost, and it is difficult to design good feature extractors
that can distinguish genuine signatures and skilled forgeries. This reflects in
a relatively poor performance, with verification errors around 7% in the best
systems in the literature. To address both the difficulty of obtaining good
features, as well as improve system performance, we propose learning the
representations from signature images, in a Writer-Independent format, using
Convolutional Neural Networks. In particular, we propose a novel formulation of
the problem that includes knowledge of skilled forgeries from a subset of users
in the feature learning process, that aims to capture visual cues that
distinguish genuine signatures and forgeries regardless of the user. Extensive
experiments were conducted on four datasets: GPDS, MCYT, CEDAR and Brazilian
PUC-PR datasets. On GPDS-160, we obtained a large improvement in
state-of-the-art performance, achieving 1.72% Equal Error Rate, compared to
6.97% in the literature. We also verified that the features generalize beyond
the GPDS dataset, surpassing the state-of-the-art performance in the other
datasets, without requiring the representation to be fine-tuned to each
particular dataset.","Signature veriÔ¨Åcation systems aim to verify the identity of individuals by recognizing their handwritten signature. They rely on recognizing a speciÔ¨Åc, welllearned gesture, in order to iden tify a person. This is in contrast with systems based on the possession of an object (e.g. key, smartcard) or the knowledge of something (e.g. password), and also differ from other biometric systems, such as Ô¨Ångerprint, since the signature remains the most socially and legally accepted means for identiÔ¨Åcation [1]. In ofÔ¨Çine (static) signature veriÔ¨Åcation, the signature is acquired after the writing process is completed, by scanning a document containing the signature, and representing it as a digital im age [2]. Therefore, the dynamic information about the signature generation process is lost (e.g. position and velocity of the pen over time), which makes the problem very challenging. DeÔ¨Åning discriminative feature extractors for ofÔ¨Çine signatures is a hard task. The question ‚ÄúWhat characterizes a signature‚Äù is a difÔ¨Åcult concept to implement as a feature descriptor, as illustrated in Figure 1. This can be observed in the literature, where most of the research efforts on this Ô¨Åeld have been devoted to Ô¨Ånding a good representation for signatures, that is, designing feature extractors tailored for signature veriÔ¨Åcation, as well as using feature extractors created for other purposes [3]. Recent work uses texture features, such as Local Binary Patterns (LBP) [4], [5] and GrayLevel Cooccurrence Matrix (GLCM) [5]; directionalbased features such as Histogram of Oriented Gradients (HOG) [4] and DirectionalPDF [6], [7]; feature extractors speciÔ¨Åcally de signed for signatures, such as the estimation of strokes by Ô¨Åtting Bezier curves [8]; among others. No feature extractor has emerged as particularly suitable for signature veriÔ¨Åcation, and most recent work uses a combination of many such techniques. The difÔ¨Åculty of Ô¨Ånding a good representation for signatures reÔ¨Çects on the classiÔ¨Åcation per formance of signature veriÔ¨Åcation systems, in particular to distinguish genuine signatures and skilled forgeries  forgeries that are made targeting a particular individual. When we consider ex periments conducted on large public datasets, such as GPDS [9], the best reported results achieve 2(a)  (b)  (c)  (d) Figure 1: Examples of challenges in designing feature extractors for ofÔ¨Çine signatures, and the challenge of classifying skilled forgeries. Each column shows two genuine signatures from the same user in the GPDS dataset, and a skilled forgery created for the user. We notice that skilled forgeries resemble genuine signatures to a large extent. Since we do not have examples from the forgery class for training, the problem is even more challenging. We also note the challenges of creating feature extractors for these genuine signatures: (a)The shape of the Ô¨Årst name is very different among the two genuine samples. A feature descriptor based on grid features would have very different vectors for the two samples. (b)The shape of the characters in the Ô¨Årst name (‚ÄúPaula‚Äù) is very different. An analysis based on the design of individual letters would perform poorly for this user. (c)Large variation in Ô¨Çourishes may impact directionalbased descriptors (such as HOG or DPDF). (d)For some users, it is difÔ¨Åcult to pinpoint the common attributes of two signatures even after carefully analyzing the samples. Equal Error Rates around 7%, even when the number of samples for training is around 1015, with worse results using fewer samples per user. To address both the issue of obtaining a good feature representation for signatures, as well as improving classiÔ¨Åcation performance, we propose a framework for learning the representations directly from the signature images, using convolutional neural networks. In particular, we propose a novel formulation of the problem, that incorporates knowledge of skilled forgeries from a subset of users, using a multitask learning strategy. The hypothesis is that the model can learn visual cues present in the signature images, that are discriminative between genuine signatures and forgeries in general (i.e. not speciÔ¨Åc to a particular individual). We then evaluate if this feature representation generalizes for other users, for whom we do not have skilled forgeries available. Our main contributions are as follows: 1) we present formulations to learn features for ofÔ¨Çine signature veriÔ¨Åcation in a WriterIndependent format. We introduce a novel formulation that uses skilled forgeries from a subset of users to guide the feature learning process, using a multitask framework to jointly optimize the model to discriminate between users (addressing random forg 3eries), and to discriminate between genuine signatures and skilled forgeries; 2) we propose a strict experimental protocol, in which all design decisions are made using a validation set composed of a separate set of users. Generalization performance is estimated in a disjoint set of users, from whom we do not use any forgeries for training; 3) we present a visual analysis of the learned representations, which shows that genuine signatures and skilled forgeries get better separated in different parts of the feature space; 4) lastly, we are making two trained models available for the research community1, so that other researchers can use them as specialized feature extractors for the task. Experiments were conducted on four datasets, including the largest publicly available signature veriÔ¨Åcation dataset (GPDS), achieving a large performance improvement in the stateoftheart, reducing Equal Error Rates from 6.97% to 1.72% in GPDS160. We used the features learned on this dataset to train classiÔ¨Åers for users in the MCYT, CEDAR and Brazilian PUCPR datasets, also surpassing the stateoftheart performance, and showing that the learned feature space not only generalizes to other users in the GPDS set, but also to other datasets. Preliminary results, using only genuine signatures for learning the features, were published as two conference papers. In [10], we introduced the formulation to learn features from genuine signatures from a development dataset, using them to train WriterDependent classiÔ¨Åers to another set of users. In [11], we analyzed the learned feature space and optimized the CNN architecture, obtaining stateoftheart results on GPDS. The present work includes this formulation of the prob lem for completeness, with additional experiments on two other datasets (MCYT and CEDAR), a clearer explanation of the method and the experimental protocol, as well as the novel formulation that leverages knowledge of skilled forgeries for feature learning. The remaining of this paper is organized as follows: Section 2 reviews the related work on signature veriÔ¨Åcation and on feature learning techniques. Section 3 details the formulation and methodology to learn features for ofÔ¨Çine signature veriÔ¨Åcation, and section 4 describes our exper imental protocol. Section 5 presents and discusses the results of our experiments. Lastly, section 6 concludes the paper. 1https://www.etsmtl.ca/Unitesderecherche/LIVIA/Rechercheetinnovation/ Projets 42. Related works "
388,Quantitative Verification of Neural Networks And its Security Applications.txt,"Neural networks are increasingly employed in safety-critical domains. This
has prompted interest in verifying or certifying logically encoded properties
of neural networks. Prior work has largely focused on checking existential
properties, wherein the goal is to check whether there exists any input that
violates a given property of interest. However, neural network training is a
stochastic process, and many questions arising in their analysis require
probabilistic and quantitative reasoning, i.e., estimating how many inputs
satisfy a given property. To this end, our paper proposes a novel and
principled framework to quantitative verification of logical properties
specified over neural networks. Our framework is the first to provide PAC-style
soundness guarantees, in that its quantitative estimates are within a
controllable and bounded error from the true count. We instantiate our
algorithmic framework by building a prototype tool called NPAQ that enables
checking rich properties over binarized neural networks. We show how emerging
security analyses can utilize our framework in 3 concrete point applications:
quantifying robustness to adversarial inputs, efficacy of trojan attacks, and
fairness/bias of given neural networks.","Neural networks are witnessing widescale adoption, including in domains with the potential for a longterm impact on human society. Examples of these domains include criminal sentencing [ 1], drug discovery [ 102,103], selfdriving cars [ 16], aircraft collision avoidance systems [ 59], robots [ 13], and drones [ 48]. While neural networks achieve humanlevel accuracy in several challenging tasks such as image recognition [ 54,63,95] and machine translation [ 11, 65, 94], studies show that these systems may behave erratically in the wild [9, 14, 17, 18, 36, 39, 40, 76‚Äì78, 87, 98, 100]. Consequently, there has been a surge of interest in the design of methodological approaches to verification and testing of neural networks. Early efforts focused on qualitative verification wherein, given a neural network Nand property P, one is concerned with determining whether there exists an input ItoNsuch that Pis violated [ 25,29,32,56,60,61,73,80,82,88,93]. While such certi fiability techniques provide value, for instance in demonstrating the existence of adversarial examples [ 50,77], it is worth recalling that the designers of neural networkbased systems often make a statistical claim of their behavior, i.e., a given system is claimed to satisfy properties of interest with high probability but not always. ‚àóPart of the research done while working at National University of Singapore.Therefore, many analyses of neural networks require quantitative reasoning, which determines how many inputs satisfy P. It is natural to encode properties as well as conditions on inputs or outputs as logical formulae. We focus on the following formu lation of quantitative verification : Given a set of neural networks Nand a property of interest Pdefined over the union of inputs and outputs of neural networks in N, we are interested in estima tion of how often Pis satisfied. In many critical domains, client analyses often require guarantees that the computed estimates be reasonably close to the ground truth. We are not aware of any prior approaches that provide such formal guarantees, though the need for quantitative verification has recently been recognized [ 86,105]. Security Applications. Quantitative verification enables many applications in security analysis (and beyond) for neural networks. We present 3point applications in which the following analysis questions can be quantitatively answered: ‚Ä¢Robustness : How many adversarial samples does a given neural network have? Does one neural network have more adversarial inputs compared to another one? ‚Ä¢Trojan Attacks : A neural network can be trained to classify certain inputs with ‚Äútrojan trigger‚Äù patterns to the desired label. How wellpoisoned is a trojaned model, i.e., how many such trojan inputs does the attack successfully work for? ‚Ä¢Fairness : Does a neural network change its predictions significantly when certain input features are present (e.g., when the input record has gender attribute set to ‚Äúfemale‚Äù vs. ‚Äúmale‚Äù)? Note that such analysis questions boil down to estimating how often some property over inputs and outputs is satisfied. Estimating counts is fundamentally different from checking whether a satisfi able input exists. Since neural networks are stochastically trained, the mere existence of certain satisfiable inputs is not unexpected. The questions above checks whether their counts are sufficiently large to draw statistically significant inferences. Section 3 formu lates these analysis questions as logical specifications. Our Approach. The primary contribution of this paper is a new analysis framework, which models the given set of neural networks NandPas set of logical constraints, œÜ, such that the problem of quantifying how often Nsatisfies Preduces to model counting over œÜ. We then show that the quantitative verification is #Phard. Given the computational intractability of #P, we seek to compute rigorous estimates and introduce the notion of approximate quantitativearXiv:1906.10395v1  [cs.CR]  25 Jun 2019verification : given a prescribed tolerance factor Œµand confidence parameter Œ¥, we estimate how often Pis satisfied with PACstyle guarantees, i.e., computed result is within a multiplicative (1+Œµ) factor of the ground truth with confidence at least 1‚àíŒ¥. Our approach works by encoding the neural network into a logical formula in CNF form. The key to achieving soundness guar antees is our new notion of equiwitnessability, which defines a principled way of encoding neural networks into a CNF formula F, such that quantitative verification reduces to counting the satisfy ing assignments of Fprojected to a subset of the support of F. We then use approximate model counting on F, which has seen rapid advancement in practical tools that provide PACstyle guarantees on counts for F. The end result is a quantitative verification proce dure for neural networks with soundness and precision guarantees . While our framework is more general, we instantiate our analy sis framework with a subclass of neural networks called binarized neural networks (or BNNs) [ 57]. BNNs are multilayered percep trons with +/1weights and step activation functions. They have been demonstrated to achieve high accuracy for a wide variety of applications [ 64,70,84]. Due to their small memory footprint and fast inference time, they have been deployed in constrained environments such as embedded devices [ 64,70]. We observe that specific existing encodings for BNNs adhere to our notion of equi witnessability and implement these in a new tool called NPAQ1. We provide proofs of key correctness and composability properties of our general approach, as well as of our specific encodings. Our encodings are linear in the size of NandP. Empirical Results. We show that NPAQ scales to BNNs with 1‚àí3internal layers and 50‚àí200units per layer. We use 2standard datasets namely MNIST and UCI Adult Census Income dataset. We encode a total of 84models, each with 6,280‚àí51,410parameters, into 1,056formulae and quantitatively verify them. NPAQ encodes properties in less than a minute and solves 97.1% formulae in a 24 hour timeout. Encodings scale linearly in the size of the models, and its running time is not dependent on the true counts. We showcase how NPAQ can be used in diverse security applications with case studies. First, we quantify the model robustness by measuring how many adversarially perturbed inputs are misclassified, and then the effectiveness of 2defenses for model hardening with adversar ial training. Next, we evaluate the effectiveness of trojan attacks outside the chosen test set. Lastly, we measure the influence of 3 sensitive features on the output and check if the model is biased towards a particular value of the sensitive feature. Contributions. We make the following contributions: ‚Ä¢New Notion. We introduce the notion of approximate quan titative verification to estimate how often a property Pis satisfied by the neural net Nwith theoretically rigorous PACstyle guarantees. ‚Ä¢Algorithmic Approach, Tool, & Security Applications. We pro pose a principled algorithmic approach for encoding neu ral networks to CNF formula that preserve model counts. We build an endtoend tool called NPAQ that can handle BNNs. We demonstrate security applications of NPAQ in quantifying robustness, trojan attacks, and fairness. 1The name stands for Neural Property Approximate Quantifier. The tool will be released as opensource postpublication.‚Ä¢Results. We evaluate NPAQ on1,056formulae derived from properties over BNNs trained on two datasets. We show that NPAQ presently scales to BNNs of over 50,000 parameters, and evaluate its performance characteristics with respect to different userchosen parameters. 2 PROBLEM DEFINITION Definition 2.1 (Specification ( œÜ)).LetN={f1,f2, . . . , fm}be a set of mneural nets, where each neural net fitakes a vector of inputs xiand outputs a vector yi, such that yi=fi(xi). Let P:{x‚à™y}‚Üí{ 0,1}denote the property Pover the inputs x=m√ê i=1xi and outputs y=m√ê i=1yi. We define the specification of property P overNasœÜ(x,y)=(m√ì i=1(yi=fi(xi))‚àßP(x,y)). We show several motivating property specifications in Section 3. For the sake of illustration here, consider N={f1,f2}be a set of two neural networks that take as input a vector of three integers and output a 0/1, i.e., f1:Z3‚Üí{0,1}andf2:Z3‚Üí{0,1}. We want to encode a property to check the dissimilarity between f1 andf2, i.e., counting for how many inputs (over all possible inputs) dof1andf2produce differing outputs. The specification is defined over the inputs x=[x1,x2,x3], outputsy1=f1(x)andy2=f2(x) asœÜ(x1,x2,x3,y1,y2)=(f1(x)=y1‚àßf2(x)=y2‚àßy1,y2). Given a specification œÜfor a property Pover the set of neural netsN, a verification procedure returns r=1(SAT) if there exists a satisfying assignment œÑsuch thatœÑ|=œÜ, otherwise it returns r=0 (UNSAT). A satisfying assignment for œÜis defined as œÑ:{x‚à™y}‚Üí {0,1}such thatœÜevaluates to true, i.e., œÜ(œÑ)=1orœÑ|=œÜ. While the problem of standard (qualitative) verification asks whether there exists a satisfying assignment to œÜ, the problem of quantitative verification asks how many satisfying assignments or models does œÜadmit. We denote the set of satisfying assignments for the specification œÜasR(œÜ)={œÑ:œÑ|=œÜ}. Definition 2.2 (Neural Quantitative Verification ( NQV )).Given a specification œÜfor a property Pover the set of neural nets N, a quantitative verification procedure, NQV(œÜ), returns the number of satisfying assignments of œÜ,r=|R(œÜ)|. It is worth noting that |R(œÜ)|may be intractably large to compute via na√Øve enumeration. For instance, we consider neural networks with hundreds of bits as inputs for which the unconditioned input space is 2|x|. In fact, we prove that quantitative verification is #P hard, as stated below. Theorem 2.3. NQV(œÜ)is #Phard, where œÜis a specification for a property P over binarized neural nets. Our proof is a parsimonious reduction of model counting of CNF formulas, #CNF, to quantitative verification of binarized neural networks. We show how an arbitrary CNF formula Fcan be trans formed into a binarized neural net fiand a property Psuch that for a specification œÜforPoverN={fi}, it holds true that R(F)=R(œÜ). See Appendix 10.2 for the full proof. Remark 1. The parsimonious reduction from #CNF to NQV im plies that fully polynomial time randomized approximation schemes, including those based on Monte Carlo, cannot exist unless NP=RP.The computational intractability of #P necessitates a search for relaxations of NQV . To this end, we introduce the notion of an ap proximate quantitative verifier that outputs an approximate count withinœµof the true count with a probability greater than 1‚àíŒ¥. Definition 2.4 (Approximate NQV ((œµ,Œ¥)NQV )).Given a specifi cationœÜfor a property Pover a set of neural nets N,0<œµ‚â§1 and0<Œ¥‚â§1, an approximate quantitative verification procedure (œµ,Œ¥)NQV(œÜ,œµ,Œ¥)computes rsuch that Pr[(1+œµ)‚àí1|R(œÜ)|‚â§r‚â§ (1+œµ)|R(œÜ)|]‚â• 1‚àíŒ¥. The security analyst can set the ‚Äúconfidence‚Äù parameter Œ¥and the precision or ‚Äúerror tolerance‚Äù œµas desired. The(œµ,Œ¥)NQV defi nition specifies the end guarantee of producing estimates that are statistically sound with respect to chosen parameters (œµ,Œ¥). Connection to computing probabilities. Readers can naturally interpret|R(œÜ)|as a measure of probability. Consider Nto be a set of functions defined over input random variables x. The property specification œÜdefines an event that conditions inputs and outputs to certain values, which the user can specify as desired. The mea sure|R(œÜ)|counts how often the event occurs under all possible values of x. Therefore,|R(œÜ)| 2|x|is the probability of the event defined byœÜoccurring. Our formulation presented here computes |R(œÜ)| weighting all possible values of xequally, which implicitly assumes a uniform distribution over all random variables x. Our framework can be extended to weighted counting [ 20,33‚Äì35], assigning differ ent userdefined weights to different values of x, which is akin to specifying a desired probability distributions over x. However, we consider this extension as a promising future work. 3 SECURITY APPLICATIONS We present three concrete application contexts which highlight how quantitative verification is useful to diverse security analyses. The specific property specifications presented here derived directly from recent works, highlighting that NPAQ is broadly applicable to analysis problems actively being investigated. Robustness. An adversarial example for a neural network is an in put which under a small perturbation is classified differently [ 50,96]. The lower the number of adversarial examples, the more ‚Äúrobust‚Äù the neural network. Early work on verifying robustness aimed at checking whether adversarial inputs exist. However, recent works suggest that adversarial inputs are statistically ‚Äúnot surprising‚Äù [ 9, 38,100] as they are a consequence of normal error in statistical classification [ 26,46,47,69]. This highlights the importance of an alyzing whether a statistically significant number of adversarial examples exist, not just whether they exist at all, under desired input distributions. Our framework allows the analyst to specify a logical property of adversarial inputs and quantitatively verify it. Specifically, one can estimate how many inputs are misclassified by the net ( f) and within some small perturbation distance kfrom a benign sample ( xb) [19,76,77], by encoding the property P1 in our framework as: P1(x,y,xb,k)=|x|√ï j=1(xb[j]‚äïx[j])‚â§k‚àßyb,y (P1) As a concrete usage scenario, our evaluation reports on BNNs for image classification (Section 6.2). Even for a small given input(saymbits), the space of all inputs within a perturbation of kbits is"
479,Population-Induced Phase Transitions and the Verification of Chemical Reaction Networks.txt,"We show that very simple molecular systems, modeled as chemical reaction
networks, can have behaviors that exhibit dramatic phase transitions at certain
population thresholds. Moreover, the magnitudes of these thresholds can thwart
attempts to use simulation, model checking, or approximation by differential
equations to formally verify the behaviors of such systems at realistic
populations. We show how formal theorem provers can successfully verify some
such systems at populations where other verification methods fail.","Chemical reaction networks, mathematical abstractions similar to Petri nets, are used as a programming language to specify the dynamic behaviors of en gineered molecular systems. Existing software can compile chemical reaction networks into DNA strand displacement systems that simulate them with growing generality and precision [50, 15, 6, 51]. Programming is a chal lenging discipline in any case, but this is especially true of molecular pro gramming, because chemical reaction networks‚Äîin addition to being Turing ‚àóThis research was supported in part by National Science Foundation grants 1545028 and 1900716. 1arXiv:1909.05390v2  [cs.ET]  1 Jun 2020universal [49, 19, 23] and hence subject to all the uncomputable aspects of sequential, imperative programs‚Äìare, like the systems that they specify, distributed, asynchronous, and probabilistic. Since many envisioned applica tions of molecular programming will be safety critical [52, 53, 21, 35, 34, 48, 20], programmers thus seek to create chemical reaction networks that can be veriÔ¨Åedto correctly carry out their design intent. One principle that is sometimes used in chemical reaction network design is thesmall population heuristic [33, 11, 22]. The idea here is to verify various stages of a design by model checking or software simulation to ferret out bugs in the design prior to laboratory experimentation or deployment. Since the number of states of a molecular system is typically much larger than its population (the number of molecules present), and since molecular systems typically have very large populations, this model checking or simulation can usually only be carried out on populations that are far smaller than those of the intended molecular systems. It is nevertheless reasonable to hope that, if a system is going to consist of a very large number of ‚Äúdevices‚Äù of various sorts, then any unforeseen errors in these devices‚Äô interactions will manifest themselves even with very small populations of each device. It is this reasonable hope that is the underlying premise of the small population heuristic. (Note that the small population heuristic can be regarded as a molecular version of the small scope hypothesis [26].) The question that we address here is whether real molecular systems can thwart the small population heuristic. That is, can a real molecular system behave very diÔ¨Äerently at large populations than at small populations? If so,how sensitive can its behavior be to its population, and how simple a mechanism can achieve such sensitivity? In order to ensure that we are only investigating population eÔ¨Äects, we focus our attention on chemical reaction networks that are population pro tocolsin the sense that their populations remain constant throughout their operations. If we have such a chemical reaction network, and if we vary its initial population and nothing else , then we are assured that any resulting variations of behavior are due solely to the diÔ¨Äering populations. In this paper we show that very simple chemical reaction networks can be very sensitive to their own populations. In fact, they can exhibit population induced phase transitions , behaving one way below a threshold population and behaving very diÔ¨Äerently above that threshold. After reviewing chemi cal reaction networks in Section 2, we present in Section 3 a chemical reac tion network N1, and we prove that N1exhibits a populationinduced phase 2transition in the following sense. There are two parameters, mandn, in the construction. For this discussion, we may take m= 34andn= 67, but the construction is general. There are n+ 1reactions among n+ 2species (molecule types) in N1. A species Z0is given an initial population of p, and all other species counts are initially 0. Each reaction of N1has two reactants and two products, so the total population of N1ispat all times. There are inN1two distinguished species, BandR. These ‚Äúblue‚Äù and ‚Äúred‚Äù species are abstract standins for two diÔ¨Äerent behaviors of N1. Our construction ex ploits the inherent nonlinearity of chemical kinetics to ensure that, if p<2m, thenN1terminates with essentially all its population blue, while if p2m, thenN1terminates with essentially all its population red. Thus N1exhibits a sharp phase transition at the population threshold p= 2m. Our construction is very simple. The chemical reaction network N1 changes its behavior at the threshold p= 2mby merely computing suc cessive bits of p, starting at the least signiÔ¨Åcant bit. This mechanism is so simple that it could be hidden, by accident or by malice, in a larger chemical reaction network. Moreover, for suitable values of m(e.g.,m= 34, so that the threshold p= 2mis roughly 1:71010), 1. any attempt to modelcheck or simulate N1will perforce use a popu lation much less than the threshold and conclude that N1will always turn blue; while 2. any realistic wetlab molecular implementation of N1will have a pop ulation greater than the threshold and thus turn red. If the behaviors represented by blue and red here are a desired, ‚Äúgood‚Äù behav ior of N1(or of a network containing N1) and an undesired, ‚Äúbad‚Äù behavior of this network, respectively, then the possibility of such a phase transition is a serious challenge to verifying the correct behavior of the chemical reac tion network. Simply put, this is a context in which the small population heuristic can lead us astray. Thereisadual large population heuristic thatisusedevenmoreoftenthan thesmallpopulationheuristic. AtheoremofKurtz[29,2,3]tellsusthateach stochastic chemical reaction network (the type of chemical reaction network used in our work here and in most of molecular programming) behaves, at suÔ¨Éciently large populations, like the corresponding deterministic chemical reactionnetwork. Sincethebehaviorofadeterministicchemicalreactionnet work is exactly described by a system of ordinary diÔ¨Äerential equations, this 3population 0 1 realistic nanoexperiments and applicationsmodel checking works simulation worksODEs work Figure 1: Scales at which diÔ¨Äerent veriÔ¨Åcation methods (simulation, model checking, and ODE‚Äôs) work. The gap in the middle shows the scale at which none of these methods will catch the ‚Äúproduce blue‚Äù behavior of the system design. Thisgapisproblematicbecauseitisthescaleofrealisticprogrammed molecular systems. We show in Section 5.4 how such systems can be veriÔ¨Åed using automated theorem proving. means that we can use a mathematical software package to numerically solve this system and thereby understand the behavior of the original stochastic chemical reaction network at suÔ¨Éciently large populations. In Section 4 we add a single reaction to the chemical reaction network N1, creating a chemical reaction network N2that we prove (in Theorem 4.6) to exhibit two coupled populationinduced phase transitions in the following sense. Ifp < 2morp2n, then N2terminates with essentially all its population blue, while if 2mp <2n, then N2terminates with essentially all its population red. Thus N2exhibits sharp phase transitions at the two population thresholds, p= 2mandp= 2n. These phase transitions are coupledin that exceeding the second threshold returns the behavior of N2to its behavior below the Ô¨Årst threshold. For suitable values of mandn(e.g. m= 34andn= 67as above, so that the thresholds p= 2mandp= 2nare roughly 1:71010and1:51020), this implies (see Figure 1) that 1. any attempt to modelcheck or simulate N2will perforce use a popu lation much less than the smaller threshold and conclude that N2will always turn blue, and 2. any use of ordinary diÔ¨Äerential equations to analyze the behavior of N2 will also conclude that N2will always turn blue, a conclusion that is only valid for populations greater than the larger threshold, while 3. any realistic wetlab molecular implementation of N2will have a pop ulation between the two thresholds and thus turn red. 4The chemical reaction network N2thus exempliÔ¨Åes a class of contexts in which the small population heuristic and the large population heuristic can both lead us astray. We emphasize that the phase transitions in the chemical reaction net works N1andN2occur at thresholds in their absolute populations . In con trast, phase transitions in chemical reaction networks for approximate ma jority [4, 10, 18] occur at threshold ratios between subpopulations , and phase transitions in bacterial quorum sensing [38] occur at threshold population densities . Section 5 discusses the consequences of our results for the veriÔ¨Åcation of programmed molecular systems in some detail. Here we summarize these consequences brieÔ¨Çy. Phase transitions are ubiquitous in natural and engi neered systems [44, 45, 9]. Our results are thus cautionary, but they should not be daunting. Fifteen years after Turing proved the undecidability of the halting problem, Rice [46, 47] proved his famous generalization stating that everynontrivial input/output property of programs is undecidable. Rice‚Äôs theorem saves valuable time, but it has never prevented computer scientists from developing speciÔ¨Åc programs in disciplined ways that enable them to be veriÔ¨Åed. Similarly, Sections 3 and 4 give mathematical proofsthat the chemical reaction networks N1andN2have the properties described above, and Section 5 describes how we have implemented such proofs in the Isabelle proof assistant [41, 42]. As molecular programming develops, simulators, model checkers, theorem provers, and other tools will evolve with it, as will disciplined scientiÔ¨Åc judgment about how and when to use such tools. 2 Chemical Reaction Networks Chemical reaction networks (CRNs) are abstract models of molecular pro cesses in wellmixed solutions. They are roughly equivalent to three models used in distributed computing, namely, Petri nets, population protocols, and vector addition systems [19]. This paper uses stochastic chemical reaction networks. For our purposes, a ( stochastic )chemical reaction network Nconsists of Ô¨Ånitely many reactions , each of which has the form A+B!C+D; (2.1) whereA,B,C, andD(not necessarily distinct) are species, i.e., abstract 5types of molecules. Intuitively, if this reaction occurs in a solution at some time, then one Aand oneBdisappear from the solution and are replaced by oneCand oneD, these things happening instantaneously. A stateof the chemical reaction network Nwith species A1;:::;A nat a particular moment of time is the vector (a1;:::;a s), where each aiis the nonnegative integer count of the molecules of species Aiin solution at that moment. Note that we are using the so called ‚Äúlowercase convention‚Äù for denoting species counts. In the full stochastic chemical reaction network model, each reaction also has a positive real rate constant , and the random behavior of Nobeys a continuoustime Markov chain derived from these rate constants. However, our results here are so robust that they hold for anyassignment of rate con stants, so we need not concern ourselves with rate constants or continuous time Markov chains. In fact, for this paper, we can consider the reaction (2.1) to be the ifstatement ifa>0andb>0thena;b;c;d :=a"
484,Few Shot Text-Independent speaker verification using 3D-CNN.txt,"Facial recognition system is one of the major successes of Artificial
intelligence and has been used a lot over the last years. But, images are not
the only biometric present: audio is another possible biometric that can be
used as an alternative to the existing recognition systems. However, the
text-independent audio data is not always available for tasks like speaker
verification and also no work has been done in the past for text-independent
speaker verification assuming very little training data. Therefore, In this
paper, we have proposed a novel method to verify the identity of the claimed
speaker using very few training data. To achieve this we are using a Siamese
neural network with center loss and speaker bias loss. Experiments conducted on
the VoxCeleb1 dataset show that the proposed model accuracy even on training
with very few data is near to the state of the art model on text-independent
speaker verification","¬† Every speaker has their own acoustic and behavioral features. This uniqueness in                         speech data makes it useful for the task like speaker verification. TextIndependent                         speaker verification is the task of verifying the claimed identity of the speaker where                             the spoken utterances are different.   In past years, many approaches have been proposed for textindependent speaker                       verification but they assume the availability of large amounts of training data [1,2].                           There has also been work done on speaker verification with few training data [3,4] but                               they assume that the spoken utterances should be the same in both enrollment and                             evaluation phase ( Which is referred to as textdependent speaker verification ). There                           has been no work done in the past on the task of textindependent speaker verification                               by assuming very little training data. To this end, we will make use of the siamese                                 neural network as a base network with the raw waveform as input and for learning the                                 feature embeddings we are using 3DCNN's. Input to the model is very important for                             making a good verification model and in past, many researchers have experimented                         their speaker verification model by inputting different forms of audio data like raw                          waveforms, spectrogram, MFCC features, etc. and among all of those experimented                       models, those which uses raw waveforms as input have shown comparatively good                         result. Using Raw waveforms as model input has other advantages as well since they                             are timevariant audio signals directly collected from the source they require no time                           and resource for feature extraction. Works by Lee ‚Äã et al. ‚Äã and Muckenhirn ‚Äã et al. ‚Äã show                               how raw waveforms on direct input to CNN can be used for audio classification ‚Äã [5,6].                               Another important study carried out by Jung ‚Äã et al. [2] shows that extraction of                             multiple frequencies from audio by the kernel of each layer can only be obtained                             when we process it with a raw waveform.   RawNet proposed by Jung ‚Äã et al. ‚Äã [2] is the current state of the art algorithm for                                 textindependent speaker verification but it also assumes a large training data. In this                           paper, we focus on the textindependent speaker verification assuming that we have                         little data for training. We have also experimented with our proposed model to                           achieve near to state of the art performance with very little data so that we can replace                                   the existing face verification system with a textindependent speaker verification                     system. Our proposed model is the first of its kind that will unravel this problem and                                 thus will provide possibilities for many researchers to implement new procedures by                         using very little training data. ¬† 2   Related Works "
25,Anisotropic Diffusion-based Kernel Matrix Model for Face Liveness Detection.txt,"Facial recognition and verification is a widely used biometric technology in
security system. Unfortunately, face biometrics is vulnerable to spoofing
attacks using photographs or videos. In this paper, we present an anisotropic
diffusion-based kernel matrix model (ADKMM) for face liveness detection to
prevent face spoofing attacks. We use the anisotropic diffusion to enhance the
edges and boundary locations of a face image, and the kernel matrix model to
extract face image features which we call the diffusion-kernel (D-K) features.
The D-K features reflect the inner correlation of the face image sequence. We
introduce convolution neural networks to extract the deep features, and then,
employ a generalized multiple kernel learning method to fuse the D-K features
and the deep features to achieve better performance. Our experimental
evaluation on the two publicly available datasets shows that the proposed
method outperforms the state-of-art face liveness detection methods.","Face recognition and veriÔ¨Åcation [21, 23] has become the most popular technology in highlevel security systems due to the natural, intuitive, and less humaninvasive face biometrics. Unfortunately, face biometrics is vulnerable to spooÔ¨Ång attacks using photographs or videos of the actual user. Attackers can attempt to hack the security system by using printed photos, mimic masks, or screenshots, and they can also use the captured or downloaded video sequences containing facial gestures like eye blink ing of the valid user to invade the security system. In or der to mitigate this problem, many researchers have made much effort to face liveness detection based on image quality [24, 29], spectrum [10, 30], and motion informa tion like eye blinking [18], mouth movement [11], and head pose [3]. Recently, Diffusion methods have been ap plied to face liveness detection [9, 1], which can estimate the difference in surface properties between live and fake faces and achieve spectacular performance. However, it still remains a big challenge to detect face liveness against spooÔ¨Ång attacks. In this paper, we present an anisotropic diffusionbased kernel matrix model (ADKMM) for face liveness detec tion to prevent face spooÔ¨Ång attacks. The ADKMM can accurately estimate the difference in surface properties and inner correlation between live and fake face images. Figure 1 illustrates the overview of our method. The anisotropic diffusion is used to enhance the edges and boundary locations of a face image sequence, and the kernel matrix model is used to extract face features from the sequence which reÔ¨Çect the inner correlation of the se quence. We call these features the diffusionkernel (D K) features. To achieve better performance against the spooÔ¨Ång attack, we also extract the deep features using deep convolution neural networks, and then utilize a gen eralized multiple kernel learning method to fuse the D K features and the deep features. The deep features can work well with DK features by providing complemen tary information. Synthetical considering these two kinds 1arXiv:1707.02692v1  [cs.CV]  10 Jul 2017Input video/images Anisotropic  DiffusionKernel Matrix Model Convolution  Neural NetworkAnisotropic Diffusion based Kernel Matrix Model ( ADKMM ) GMKL DK features deep featuresFigure 1: An illustration of the proposed method. We diffuse the input video or images by anisotropic diffusion method Ô¨Årst, next we use kernel matrix model to extract the diffusionkernel (DK) features. Then, we extract deep features from the diffused images by deep convolution neural networks. Finally, the DK features and deep features are fused by a generalized multiple kernel learning (GMKL) method for face liveness detection to prevent face spooÔ¨Ång attacks. of feature relationships, we can capture the differences ef fectively in both sides of illumination characteristics and inner correlation of face images. The experimental re sults on various publicly available datasets demonstrate that our method provides a reliable performance of face liveness detection. The main contributions of this paper can be summa rized as follows: We present an anisotropic diffusionbased kernel ma trix model (ADKMM) that can accurately estimate the difference in surface properties and inner correlation be tween live and fake face images to extract diffusionkernel (DK) features for face liveness detection. We utilize a generalized multiple kernel learning method to fuse the DK features and the deep features ex tracted by deep convolution neural networks to get better performance against the spooÔ¨Ång attack. Our method achieves an impressive accuracy on the publicly available datasets and outperforms the stateof art face liveness detection methods. 2 Related Work "
318,Neural Networks Reduction via Lumping.txt,"The increasing size of recently proposed Neural Networks makes it hard to
implement them on embedded devices, where memory, battery and computational
power are a non-trivial bottleneck. For this reason during the last years
network compression literature has been thriving and a large number of
solutions has been been published to reduce both the number of operations and
the parameters involved with the models. Unfortunately, most of these reducing
techniques are actually heuristic methods and usually require at least one
re-training step to recover the accuracy. The need of procedures for model
reduction is well-known also in the fields of Verification and Performances
Evaluation, where large efforts have been devoted to the definition of
quotients that preserve the observable underlying behaviour. In this paper we
try to bridge the gap between the most popular and very effective network
reduction strategies and formal notions, such as lumpability, introduced for
verification and evaluation of Markov Chains. Elaborating on lumpability we
propose a pruning approach that reduces the number of neurons in a network
without using any data or fine-tuning, while completely preserving the exact
behaviour. Relaxing the constraints on the exact definition of the quotienting
method we can give a formal explanation of some of the most common reduction
techniques.","Since 2012, when AlexNet [26] won the famous ImageNet Large Scale Visual Recognition Challenge (ILSVRC), the number of proposed Articial Neural Net work (ANN orNN) architectures has increased exponentially. Their intrinsic  exibility, together with the superior performance they can achieve, made neu ral networks the tool of choice to solve a wide variety of tasks. As these models have evolved to process large amount of data or to solve complicated tasks, their complexity has also increased at same pace [10]. Such elaborate and deep net works are the foundation of Deep Learning (DL) and they stand out both for the large number of layers they are made of and for the higher level of accuracy they can reach on dicult tasks [53].arXiv:2209.07475v1  [cs.LG]  15 Sep 20222 Dalila Ressi, Riccardo Romanello , Carla Piazza, and Sabina Rossi While the academic community mostly focused their eorts in training large and deep models [25,8,54], being able to adopt such networks in embedded de vices resulted to be a problem. Physical constraints such as battery, memory and computational power greatly limit both the number of parameters used to the dene the architecture and the number of Floating Point Operations (FLOPs) required to be computed at inference time. A commonly used strategy to address this problem is called Network Compression . Compression literature has had a substantial growth during the last years, and for this reason there are many dierent ways to group together methods reducing a model in similar ways. Methods focusing on nding the best possible structure to solve a particular tasks can be grouped together as Architecturerelated strategies. These kind of methods usually require to train the network from scratch each time the struc ture is modied. In particular, Neural Architecture Search (NAS) techniques aim to nd the best possible architecture for a certain task with minimal human in tervention [41,12,32]. This is usually made possible by modelling the search as an optimization problem and applying Reinforcement Learning (LR) based meth ods to nd the best architecture [57,3]. In this group we can also nd Tensor Decomposition , where matrix decomposition/factorization principles are applied to theddimensional tensors in neural networks. Tensor decomposition general izes the widely used Principal Component Analysis (PCA) and Singular Value Decomposition (SVD) to an arbitrary number of dimensions [6,16,51]. The goal of these techniques is to reduce the rank of tensors in order to eciently de compose them into smaller ones and drastically reduce the number of operations [10]. As the rank of a tensor is usually far from being small, the most common solutions are to either to force the network to learn lters with small rank either to use an approximated decomposition [11]. Using a similar approach Lightweight orCompact Networks focus on modi fying the design of the architecture such that it performs less operations while maintaining the same capability. It is the case of the MobileNet series [21,43,20], ShueNet series [56,34], and EcientNet series [49,50]. They exploit the idea of using 11 lters introduced by Network in Network [29] and GoogLeNet [46,47] in their inception modules. A similar concept is explored by the SqueezeNet [23] architecture in their Fire module , where they substitute the classical con volutional layers such that they can achieve the same accuracy of AlexNet on ImageNet dataset but with a model 510 times smaller. A dierent methodology consists in training a big model from the start, and then Pruning super uous parameters. In particular, Weight Pruning consists in zeroing connections or parameters already close to zero [27], but more elaborated methods can also take into consideration the impact of the single weights on the nal results [15]. Even if weight pruning is a very powerful tool to reduce the network parameters [13], its major drawback is that it does not actually reduce the number of FLOPs at inference time. A more eective solution consists instead in skipping completely some of the operations. It is the case of Filter Pruning , where whole nodes or lters (in case of convolutional layers) are removed from the architecture. Pruning usuallyNNs Reduction via Lumping 3 requires some degree of retraining to recover the lost accuracy due to the reduced network capability, but an interesting phenomena that happens in the early stages of pruning is that most of the times the test accuracy actually increases, due to the regularization eect that pruning unnecessary parameters has on the network. While weight pruning allows more control on what parameters to remove, lter pruning is usually the best solution compressionwise as it allows to drastically reduce the network parameters such that the models can be actually implemented in small embedded devices [42]. Another technique often used in conjunction with pruning is called quantiza tion [14]. While pruning aims to reduce the number of parameters, quantization instead targets their precision. As the weights are usually represented by  oating point numbers, it is possible to reduce the bits used for the number representa tion down to single bits [40], without aecting the network accuracy. In the context of performance evaluation of computer systems, stochastic models whose underlying stochastic processes are Markov chains, play a key role providing a sound highlevel framework for the analysis of software and hard ware architectures. Although the use of highlevel modelling formalism greatly simplies the specication of quantitative models (e.g., by exploiting the compo sitionality properties [18]), the stochastic process underlying even a very compact model may have a number of states that makes its analysis a dicult, sometimes computationally impossible, task. In order to study models with a large state space without using approximations or resorting to simulations, one can attempt to reduce the state space of the underlying Markov chain by aggregating states with equivalent behaviours. Lumpability is an aggregation technique used to cope with the state space explosion problem inherent to the computation of the stationary performance indices of large stochastic models. The lumpability method turns out to be useful on Markov chains exhibiting some structural reg ularity. Moreover, it allows one to eciently compute the exact values of the performance indices when the model is actually lumpable. In the literature, sev eral notions of lumping have been introduced: ordinary and weak lumping [24], exact lumping [44], and strict lumping [5]. With this paper we aim to link together the work of two dierent communi ties, the rst one focusing on machine learning and network compression and the second one focusing on lumpingbased aggregation techniques for performance evaluation. Even if a large number of possible ecient compression techniques has already been published, we aim instead to give a formal demonstration on how it is possible to deterministically remove some of the network parameters to obtain a smaller network with the same performance. Our method condenses many dierent concepts together, such as some of the ideas exploited by tensor decomposition methods, lter pruning and the lumpability used to evaluate the performance of complex systems. The paper is structured as follows. In Section 2 we provide a literature re view. Section 3 gives the necessary background. Section 4 formally describes our technique exploiting exact lumpability for quotienting NN. Section 5 presents some experimental results. Finally, Section 6 concludes the paper.4 Dalila Ressi, Riccardo Romanello , Carla Piazza, and Sabina Rossi 2 Related Work "
343,Normalization of Neural Networks using Analytic Variance Propagation.txt,"We address the problem of estimating statistics of hidden units in a neural
network using a method of analytic moment propagation. These statistics are
useful for approximate whitening of the inputs in front of saturating
non-linearities such as a sigmoid function. This is important for
initialization of training and for reducing the accumulated scale and bias
dependencies (compensating covariate shift), which presumably eases the
learning. In batch normalization, which is currently a very widely applied
technique, sample estimates of statistics of hidden units over a batch are
used. The proposed estimation uses an analytic propagation of mean and variance
of the training set through the network. The result depends on the network
structure and its current weights but not on the specific batch input. The
estimates are suitable for initialization and normalization, efficient to
compute and independent of the batch size. The experimental verification well
supports these claims. However, the method does not share the generalization
properties of BN, to which our experiments give some additional insight.","Batch normalization (BN) [5] is a widely applied method which is known to improve learning speed and performance of difÔ¨Åcult networks. It is based on a whitening normalization that requires comput ing the mean and variance statistics of all activations over the training set. In [5] these statistics are ap proximated by those over a batch. Since [5], there have appeared a number of dif ferent normalization methods. A good overview is given in [2] who categorize current methods in three groups: methods based on sample statistics over dif ferent groups of hidden units [7, 17, 11], modiÔ¨Åca tions of BN [12, 3, 4, 8] and methods normalizing weights instead of activations [13, 1, 19].The proposed technique is a followup applica tion of the work [16], where a feedforward propaga tion of uncertainties (variances) in neural networks (NNs) is proposed, making NNs and Bayesian net works more alike. In this work we apply the idea of variance propagation to analyze standard networks. Namely, we are interested in estimating means and variances of activations in a given network provided basic statistics of the dataset. We show that the method [16] is suitable for this task, can be imple mented very efÔ¨Åciently for CNNs and conduct a de tailed experimental study. The method is also related to normalization prop agation [1] and deep information propagation [15] as will be discussed in x3. 1.1. Background Normalization Methods Ioffe and Szegedy [5] proposed the following transformation to be applied infront of saturating nonlinearities (such as logistic sigmoid): X0=X"
130,ActiveGuard: An Active DNN IP Protection Technique via Adversarial Examples.txt,"The training of Deep Neural Networks (DNN) is costly, thus DNN can be
considered as the intellectual properties (IP) of model owners. To date, most
of the existing protection works focus on verifying the ownership after the DNN
model is stolen, which cannot resist piracy in advance. To this end, we propose
an active DNN IP protection method based on adversarial examples against DNN
piracy, named ActiveGuard. ActiveGuard aims to achieve authorization control
and users' fingerprints management through adversarial examples, and can
provide ownership verification. Specifically, ActiveGuard exploits the
elaborate adversarial examples as users' fingerprints to distinguish authorized
users from unauthorized users. Legitimate users can enter fingerprints into DNN
for identity authentication and authorized usage, while unauthorized users will
obtain poor model performance due to an additional control layer. In addition,
ActiveGuard enables the model owner to embed a watermark into the weights of
DNN. When the DNN is illegally pirated, the model owner can extract the
embedded watermark and perform ownership verification. Experimental results
show that, for authorized users, the test accuracy of LeNet-5 and Wide Residual
Network (WRN) models are 99.15% and 91.46%, respectively, while for
unauthorized users, the test accuracy of the two DNNs are only 8.92% (LeNet-5)
and 10% (WRN), respectively. Besides, each authorized user can pass the
fingerprint authentication with a high success rate (up to 100%). For ownership
verification, the embedded watermark can be successfully extracted, while the
normal performance of the DNN model will not be affected. Further, ActiveGuard
is demonstrated to be robust against fingerprint forgery attack, model
fine-tuning attack and pruning attack.","DEEP learning techniques, especially Deep Neural Net works (DNNs), have been widely used in various Ô¨Åelds, such as biometric authentication, speech recognition, and autonomous driving, etc. However, training a high performance DNN faces the following challenges [1]‚Äì[4]: M. Xue, S. Sun, C. He, Y . Zhang and J. Wang are with the College of Computer Science and Technology, Nanjing Univer sity of Aeronautics and Astronautics, Nanjing 211106, China (email: mingfu.xue@nuaa.edu.cn; sunshichang@nuaa.edu.cn; hecan@nuaa.edu.cn; yushu@nuaa.edu.cn; wangjian@nuaa.edu.cn). W. Liu is with the College of Electronic and Information Engineering, Nanjing University of Aeronautics and Astronautics, Nanjing 211106, China (email: liuweiqiang@nuaa.edu.cn).(i) timeconsuming and requiring a large amount of train ing data; (ii) expensive hardware computing resources; (iii) requiring human experts. Therefore, machine learning as a service (MLaaS) [5] has emerged as a new and popular business paradigm, i.e., pretrained DNNs are used to provide services to users. Since the cost of stealing a pretrained DNN model is much smaller than training a highperformance DNN model from scratch, malicious users have strong incentives to illegally copy or tamper with the DNN models [3], [6]. An adversary can easily duplicate or pirate DNN models with little prior knowledge. Recently, the copyright protection for DNN has attracted more and more concerns. DNN watermarking method is Ô¨Årst proposed to protect the intellectual property (IP) of DNN. Similar to digital water marking in the multimedia Ô¨Åeld [7], [8], DNN watermarking is a technique that embeds the watermarks into DNN models, and extracts the watermarks for ownership veriÔ¨Åcation when copyright infringement occurs. To date, most of the existing works protect the copyright of DNN using watermarks, which can be divided into two types, whitebox watermarking meth ods [1], [2], [9] and blackbox watermarking methods [10]‚Äì [13]. However, the DNN watermarking is a passive veriÔ¨Åcation method that only works after the DNN is pirated or stolen, which cannot prevent piracy in advance. Besides, it cannot provide commercial digital rights management capabilities (i.e., it can neither prevent unauthorized users from illegally accessing the DNN nor track users‚Äô identities). To date, few works [3], [14], [15] proposed active autho rization control methods to protect the copyright of DNN models, in which the authorized users can obtain a high accuracy when using DNN, while illegal users will obtain a poor accuracy. However, the work [3] requires to train another antipiracy DNN from scratch to verify whether a user is legal or not. Besides, to use the DNN normally, an authorized user requires to preprocess each input data by a transform module, which introduces massive computational overheads. Lastly, the DNN model in work [3] is trained using adversarial examples. As a result, the model only maintains high accuracy for the input adversarial examples (from authorized users), but produces low accuracy for the original clean images (from unauthorized users). However, in practice, users generally expect high accuracy on clean images. The work [14] adds a passport layer after each convolutional layer, which requires massive training time to embed the digital passport layers into the DNN. Moreover, once an attacker obtains the original training data, he can conduct the tampering attack to modify the embedded passports, or implement reverseengineering attacks to obtain the hidden parameters. The hardwareassistedarXiv:2103.01527v1  [cs.CR]  2 Mar 20212 method in [15] relies on the trusted hardware devices (as a rootoftrust) to store the key for each user, which is costly for commercial applications. Further, these existing active authorization control methods [3], [14], [15] all lack the function of users‚Äô Ô¨Ångerprints management, which makes these works unsuitable for commercial digital right management applications. In this paper, we propose an active DNN IP protection method ( ActivaGuard ) via adversarial examples. The proposed method consists of three parts, i.e., active authorization con trol, users‚Äô Ô¨Ångerprints management, and ownership veriÔ¨Å cation. To achieve authorization control, ActivaGuard adds a control layer to DNN. The control layer can constrain the usage of the unauthorized users on a protected DNN model, i.e., make the DNN dysfunctional to unauthorized users. To realize users‚Äô Ô¨Ångerprints management, ActivaGuard treats adversarial examples as users‚Äô Ô¨Ångerprints, and assigns the Ô¨Ångerprints to authorized users (each authorized user is assigned with an adversarial example as his Ô¨Ångerprint). Each authorized user can input an adversarial example into the DNN to verify his identity. In order to realize ownership veriÔ¨Åcation, ActivaGuard embeds a numerical watermark into DNN‚Äôs weights with a parameter regularizer. When the DNN is suspected to be pirated or stolen, the model owner can extract the embedded watermark for ownership veriÔ¨Åcation. The contributions of this paper are fourfolds: Active IP protection for DNN. We propose an active DNN IP protection method ( ActivaGuard ) based on ad versarial examples. The key idea behind ActivaGuard is that, it regards adversarial examples with speciÔ¨Åc classes and conÔ¨Ådences as users‚Äô Ô¨Ångerprints, and achieves au thorization control based on the uniqueness of each user‚Äôs Ô¨Ångerprint. The experiments on MNIST [16] and CIFAR10 [17] datasets show that, for authorized users, the test accuracy of LeNet5 [18] and Wide Residual Network (WRN) [19] models are 99.15% and 91.46%, respectively. For unauthorized users, the test accuracy of the two models are only 8.92% (LeNet5 [18]) and 10% (WRN [19]), respectively. Users‚Äô Ô¨Ångerprints management. We provide a users‚Äô Ô¨Ångerprints management scheme, including users‚Äô Ô¨Ånger prints generation, users‚Äô Ô¨Ångerprints allocation and users‚Äô Ô¨Ångerprints authentication. The Ô¨Ångerprint authentication success rates among the allocated 30 authorized users range from 96% to 100% on MNIST [16] dataset, and range from 99% to 100% on CIFAR10 [17] dataset. Enabling ownership veriÔ¨Åcation. We embed a water mark into the weights of DNN by leveraging a regularizer. The embedded watermark can be applied for ownership veriÔ¨Åcation without affecting the normal usage of DNN models. The accuracy drop of two watermarked DNNs is only 0.03% (LeNet5 [18]) and 0.08% (WRN [19]), respectively. This indicates that the proposed ActiveGuard method will not degrade the performance of DNN mod els. Compared with existing watermarking method [1], the proposed watermark embedding method can provide larger capacity (09, rather than 0/1) and is more stealthy (can be embedded discretely).Antiattack capability. We evaluate the robustness of the proposed ActiveGuard method against three common attacks. For Ô¨Ångerprint forgery attack, the success rate of 10,000 forged Ô¨Ångerprints is between 0.01% and 0.1%. Even the Ô¨Ånetuning attack has been performed on the two DNNs (LeNet5 [18] and WRN [19]) for 50 epochs, the embedded watermark can still be extracted correctly. For pruning attack, when 90% parameters of the DNN are pruned, the watermark embedded by the proposed ActiveGuard method can still be successfully extracted. This paper is organized as follows. The related works are reviewed in Section II. The proposed method ( ActiveGuard ), including authorization control, users‚Äô Ô¨Ångerprints manage ment and copyright veriÔ¨Åcation, is elaborated in Section III. The effectiveness and robustness of the proposed method are evaluated in Section IV. This paper is concluded in Section V. II. R ELATED WORK "
355,From Model Checking to Runtime Verification and Back.txt,"We describe a novel approach for adapting an existing software model checker
to perform precise runtime verification. The software under test is allowed to
communicate with the wider environment (including the file system and network).
The modifications to the model checker are small and self-contained, making
this a viable strategy for re-using existing model checking tools in a new
context.
  Additionally, from the data that is gathered during a single execution in the
runtime verification mode, we automatically re-construct a description of the
execution environment which can then be used in the standard, full-blown model
checker. This additional verification step can further improve coverage,
especially in the case of parallel programs, without introducing substantial
overhead into the process of runtime verification.","While model checking is a powerful technique for software verication, it also has certain limitations and deciencies. Many of those limitations are related to the fact that a model checker must, by design, fully isolate the program from any outside eects. Therefore, for verication purposes, the program under test is placed into an articial environment, which gives nondeterministic (but fully reproducible) responses to the program. The existence of this model environ ment immediately requires tradeos to be made. If the environment model is too coarse, errors may be missed, or spurious errors may be introduced. Creat ing a detailed model is, however, more costly, and the result is not guaranteed to exactly match the behaviour of the actual environment either. Moreover, a detailed model may be too rigid: programs are often executed in conditions that have not been fully anticipated, and a certain amount of coarseness in the model of the environment can highlight such unwarranted assumptions. Many of those challenges are, however, not unique to model checking. In the context of automated testing, the test environment plays a prominent role, and a large body of work deals with related problems. Unfortunately, adapting ?This work has been partially supported by the Czech Science Foundation grant No. 1508772S and by Red Hat, Inc.arXiv:1805.12428v1  [cs.SE]  31 May 2018the methods used in automated testing to the context of model checking is far from straightforward. Making existing testbased setups easier to use with model checking tools is a core contribution of this paper. Both manual and automated testing are established, core techniques which play an important role in virtually every software development project. In a certain sense, then, testing provides an excellent opportunity to integrate rig orous tools into the software development process. A number of verication tools specically tailored for this mode of operation have seen great success in the software development community, for instance the memcheck tool from the valgrind suite. We show that it is possible to tap into this potential also with a traditionallydesigned software model checker: we hope that this will help put powerful verication technology into the hands of software developers in a natu ral and seamless fashion. The second important contribution of this paper, then, is an approach to build a runtime verication tool out of an existing software model checker. Our main motivating application is extending our existing software model checker, DIVINE [1], with a runtime verication mode. In its latest version, DI VINE has been split into a number of welldened, reusable components [11] and this presented an opportunity to explore the contexts in which the new com ponents could be used. Based on this motivation, our primary goal is to bring traditional (software) model checking and runtime verication closer together. As outlined above, there are two sides to this coin. One is to make model check ing t better into existing software development practice, the second is to derive powerful runtime verication tools from existing model checkers. To ensure that the proposed approach is viable in practice, we have built a prototype implemen tation, which allowed us to execute simple C and C++ programs in the resulting runtime verier. The rest of the paper is organised as follows: Section 2 describes prior art and related work, while Section 3 lays out our assumptions about the model checker and its host environment. Section 4 describes adapting a model checker to also work as a runtime verier and Section 5 focuses on how to make use of data gathered by the runtime verier in the context of model checking. Section 6 describes our prototype implementation based on DIVINE (including evaluation) and nally, Section 7 summarises and concludes the paper. 2 Related Work "
295,Photometric redshift analysis in the Dark Energy Survey Science Verification data.txt,"We present results from a study of the photometric redshift performance of
the Dark Energy Survey (DES), using the early data from a Science Verification
(SV) period of observations in late 2012 and early 2013 that provided
science-quality images for almost 200 sq.~deg.~at the nominal depth of the
survey. We assess the photometric redshift performance using about 15000
galaxies with spectroscopic redshifts available from other surveys. These
galaxies are used, in different configurations, as a calibration sample, and
photo-$z$'s are obtained and studied using most of the existing photo-$z$
codes. A weighting method in a multi-dimensional color-magnitude space is
applied to the spectroscopic sample in order to evaluate the photo-$z$
performance with sets that mimic the full DES photometric sample, which is on
average significantly deeper than the calibration sample due to the limited
depth of spectroscopic surveys. Empirical photo-$z$ methods using, for
instance, Artificial Neural Networks or Random Forests, yield the best
performance in the tests, achieving core photo-$z$ resolutions $\sigma_{68}
\sim 0.08$. Moreover, the results from most of the codes, including template
fitting methods, comfortably meet the DES requirements on photo-$z$
performance, therefore, providing an excellent precedent for future DES data
sets.","Large galaxy surveys provide detailed information on the large scale structure of the Universe, which, in turn, helps under stand its geometry, composition, evolution and fate. On one hand, spectroscopic surveys like 2dF (Colless et al. 2001), c 0000 RASarXiv:1406.4407v2  [astroph.IM]  14 Oct 20142 C. S anchez et al. VVDS (Le F evre et al. 2005), WiggleZ (Drinkwater et al. 2010) or BOSS (Dawson et al. 2013) provide a threedimensional pic ture of the galaxy distribution, but they are costly in time and resources, and may suer from limited depth, incompleteness and selection eects. On the other hand, photometric surveys such as SDSS (York et al. 2000), PanSTARRS (Kaiser, Tonry & Luppino 2000), KiDS (de Jong et al. 2013), HSC1or LSST (Tyson et al. 2003) are more ecient and usually deeper, more complete and nearly unbiased, but do not provide a complete 3D view of the Universe, due to their limited resolution in the galaxy positions along the line of sight, which are computed by measuring the photometric redshift (photo z) of each galaxy from the  uxes measured through a set of broadband lters. Even with their limited resolution along the line of sight, pho tometric surveys, because of their larger volume, are extremely useful for cosmology and, furthermore, uniquely provide some of the most stringent probes of dark energy, such as weak lens ing. There are two main approaches for measuring photomet ric redshifts: template tting methods (e.g. Hyperz , Bolzonella, Miralles & Pell (2000); BPZ, Benitez (2000); Coe et al. (2006); LePhare , Arnouts et al. (2002); Ilbert et al. (2006); EAZY, Brammer, van Dokkum & Coppi (2008)), in which the mea sured broadband galaxy spectral energy distribution (SED) obtained from the  uxes is compared to a set of redshifted galaxy templates until a best match is found, thereby deter mining both the galaxy spectral type and its redshift; and training methods (e.g. ANNz, Collister & Lahav (2004); ArborZ , Gerdes et al. (2010); TPZ, Carrasco Kind & Brunner (2013)), in which a set of galaxies with known spectroscopic redshifts is used to train a machinelearning algorithm (an artitial neural network, for example), which is then applied over the galaxy set of interest. Each technique has its own advantages and dis advantages, as we will discuss in this paper, and a combination of them can fully exploit this fact (Carrasco Kind & Brunner 2014). In order for photo z's to be useful for cosmological stud ies, it is necessary to calibrate them, by understanding the statistical properties of the distribution of the dierences be tween the true galaxy redshifts and their photo zestimates: its mean value (for the bias), its width (for the resolution), and its tails (for the fraction of outliers, with grossly mises timated photo z's). To accomplish this, a sample of galaxies with spectroscopic redshifts is required, ideally with a galaxy population that reproduces the population in the photometric survey. The Dark Energy Survey (DES, Flaugher (2005)) is one such photometric redshift survey, and will cover about one eighth of the sky (5000 sq. deg.) to an unprecedented depth (iAB<24), imaging about 300 million galaxies in 5 broadband lters (grizY ) up to redshift z= 1:4. The DES camera (DE Cam, Flaugher et al. (2012); Diehl et al. (2012)) was installed and commissioned in the second semester of 2012, and a Sci ence Verication (SV) period of observations followed, lasting from November 2012 to February 2013. The survey ocially started in late August 2013. The SV observations provided sciencequality data for al most 200 sq. deg. at close to the nominal depth of the survey. The SV footprint was chosen to contain areas already cov ered by several deep spectroscopic galaxy surveys, including VVDS (Le F evre et al. (2005)), ACES (Cooper et al. (2012)), 1http://www.naoj.org/Projects/HSC/index.htmland zCOSMOS (Lilly et al. (2007)), which together provide a suitable calibration sample for the DES photometric redshifts. This paper presents a study of the photo zprecision achieved by DES during the SV period, by taking advantage of the avail able spectroscopic data in its footprint, and by using a large number of photo zalgorithms of dierent nature. It has been pointed out (Cunha et al. 2012a) that cosmic variance in the spectroscopic samples used for photo zcali bration may bias the results of an analysis such as the one we present here, which uses spectra in four relatively small (1 sq. deg. each) patches of sky. A robust photo zcalibra tion requires galaxy spectra distributed all over the photo metric survey's footprint, calling for as many as O(50{100) patches (Cunha et al. 2012a) . While the plan for the ultimate photozcalibration of the whole DES data will need such a spectroscopic calibration sample, and steps are being taken to wards the acquisition of the relevant data, the currently avail able spectroscopic data set is good enough for a rst analysis of the photo zprecision that can be achieved with the early DES data. Analogously, the ultimate DES photo zcalibration will have to worry about the eects of the possible incomplete ness of the spectroscopic calibration samples, eects that we can safely ignore here, given the scope of this rst study. Many studies have been performed in the past comparing in detail several photo zcodes over the same, real or simulated, data set (Hogg et al. 1998; Abdalla et al. 2011; Hildebrandt, Wolf & Ben tez 2008; Hildebrandt et al. 2010; Dahlen et al. 2013). Particularly comprehensive is the work by Hildebrandt et al. (2010), which compares the performance of 19 photo z codes both over simulated and real (including HST) observa tions taken in 18 optical and nearinfrared bands. Similarly, Dahlen et al. (2013) compares 11 codes over real data in 14 bands, including also some HST data. On the other hand, Ab dalla et al. (2011), analyzed the performance of six photoz algorithms on the MegaZ Luminous Red Galaxy sample ex tracted from the SDSS Data Release 7 veband photome try, with a magnitude limit around iAB= 20. This paper dif fers from these previous studies in that, on the one hand, it uses solely DECam veband photometry ( grizY ), and on the other, it studies all kinds of galaxies up to the DES nomi nal limiting magnitude iAB= 24. Furthermore, in the present study, rather than trying to carry out a thorough comparison of all the photo zcodes available in the literature, we con centrate on assessing the performance of the early DES data with respect to the photometric redshift determination, and, in order to do so, we try the codes in which members of the DES collaboration have a certain degree of expertise, with out attempting to be complete or even necessarily fair in the comparison. Beyond providing a snapshot of the quality of the DESSV data regarding photo zestimation and accuracy, a secondary goal of this work is to tune these photo zcodes to the particular characteristics of the DES data: lter set, depth, etc, in preparation for the upcoming larger data sets. Since even the deep spectroscopic samples mentioned above fail to reproduce exactly the depth and colors of the DESSV photometric galaxy sample, a multidimensional weighting technique (Lima et al. (2008); Cunha et al. (2009)) was used in order to bring the spectroscopic and photometric samples into better agreement. Matching the galaxies in the spectroscopic samples with those in the DESSV photometric sample and comparing their spectroscopic redshifts with the DES photo z's, we will show that, even at this early stage, the DESSV data fulll the set of photoz requirements on bias, c 0000 RAS, MNRAS 000, 1{25Photometric redshift analysis in the Dark Energy Survey Science Verication data 3 resolution and outlier fraction that were dened prior to the start of the survey. The outline of the paper is as follows. Section 2 describes the DESSV photometric galaxy sample, whereas the spec troscopic galaxy samples are presented in Section 3, together with the weighting technique that has been used to match their depth and colors to those of the DESSV sample. Section 4 de scribes brie y the conditions in which the 13 dierent photo z codes studied were run, and contains the bulk of the results of the paper, including the comparison between the results ob tained with the dierent photo zcodes, the dependence of the results on both the depth of the DESSV data and the spe cic spectroscopic calibration samples used, and an indepth presentation of the results obtained with four representative photozcodes, in particular with respect to the set of require ments of the DES survey, which we set up at the beginning of Section 4. A discussion of the main results in the paper can be found in Section 5. Finally, we present our conclusions in Sec tion 6, while we conne to an appendix the detailed description of the metrics used to characterize the photo zdistributions. 2 DESSV PHOTOMETRIC SAMPLE DECam imaging on elds overlapping those from deep spec troscopic redshift surveys were obtained for the following four DES elds: SNX3, SNC3, VVDS F14, and COSMOS, whose positions in the sky are shown in Fig. 1. SNX3 and SNC3 are the two deep elds in the DES supernova survey, and dithered observations of these elds were obtained routinely during the DES SV period. The SNX3 eld includes the VVDS02hr eld of the VVDS Deep survey (Le F evre et al. 2005, 2013), while SNC3 overlaps with the CDFS (Chandra Deep Field South) area of the ACES survey (Cooper et al. 2012). The VVDS F14 eld was centered on the VVDSWide redshift survey 14hr eld (Garilli et al. 2008), and dithered imaging to DES main survey depth of this eld was likewise obtained during DES SV. Deep dithered imaging data for the COSMOS eld, centered on the Cosmological Evolution Survey (COSMOS) area (Lilly et al. 2007, 2009) were obtained during February 2013 by a DECam community program.2Each one of the four elds covers about the area of a single DECam pointing, or about 3 deg2. See Section 3 for a detailed description of the spectroscopic data matched in each of the elds. All elds include imaging in the 5 DES lters grizY , and additionally in the uband, which is part of DECam but not used by the DES survey. The data have been processed to two imaging depths: Main, corresponding to approximately DES main survey exposure times, and Deep, corresponding to about 3 times the exposure of a single visit to a DES supernova deep eld (for SNX3 and SNC3) or deeper (for COSMOS). Dierences in S/N between the Main and Deep samples can be appreciated in Fig 2; details of the data, the exposure times used and the magnitude depths are given in Table 1. Similar to DES science requirements convention, the 10 magnitude limit is dened to be the MAGAUTO value (see denition below in this section) at which the  ux in a 2arcsec diameter aperture is measured at 10 . Note that for the SNX3 and SNC3 elds, we selected those SV observations that approximately met DES 2Proposal 2013A0351 Made available for DES photo zcalibration use by arrangement with PI Arjun Dey. 21.522.523.524.5 gmagnitude0102030405060S/N 21.522.523.524.5 rmagnitudeDeep sample Main sample 21.522.523.524.5 imagnitude0102030405060S/N 21.522.523.524.5 zmagnitudeFigure 2. S/N vs. magnitude for g;r;i andzDES bands, and for Main (red dots) and Deep (black dots) samples. main survey sky background and seeing criteria in constructing the processed data used for this paper. The data were processed using the same routines used by DES Data Management (DESDM) in their processing pipeline (Mohr et al. 2012; Desai et al. 2012), in particular for image detrending, astrometric calibration (SCAMP, Bertin (2006)), image remapping and coaddition (SWarp, Bertin et al. (2002)), point spread function modeling (PSFEx, Bertin (2011)), and object detection and photometry (SExtractor, Bertin & Arnouts (1996)). The data were processed by run ning these codes in standalone mode at Fermilab, rather than by running them within the DESDM processing framework at NCSA. Running standalone was needed as the DESDM frame work was not yet fully setup at the time (Spring 2013) to pro cess and calibrate the data for these isolated elds all the way through to image coaddition. Though we basically used the DESDM codes, there were some detailed dierences in processing and photometric cali bration that we highlight here. For image detrending we did not include corrections for CCD nonlinearity, pupil ghost, and illumination that are now used by DESDM, as these correc tions were not available at the time. Image coaddition was done using a median coadd rather than by using a weighted mean as in DESDM. Photometric calibration in the ugriz l ters for the SNX3, VVDS F14, and COSMOS elds was done by matching against overlapping bright stars from the SDSS Data Release 9 database (Ahn et al. 2012). This was done to calibrate each individual CCD on each separate DECam expo sure, before image coaddition. In the Yband for all elds, and in all lters for the SNC3 eld (which did not overlap SDSS), we picked a ducial exposure for each eld, adopted the typical DECam CCDbyCCD photometric zeropoints as determined from DES SV data, and then tied the photometry for subse c 0000 RAS, MNRAS 000, 1{254 C. S anchez et al. 30‚ó¶60‚ó¶90‚ó¶120‚ó¶150‚ó¶180‚ó¶210‚ó¶240‚ó¶270‚ó¶300‚ó¶330‚ó¶ RA ‚àí75‚ó¶‚àí60‚ó¶‚àí45‚ó¶‚àí30‚ó¶‚àí15‚ó¶0‚ó¶15‚ó¶30‚ó¶45‚ó¶60‚ó¶75‚ó¶DECDES objects Spectroscopic matched objects 208.65 209.22 209.79 210.37 210.944.014.585.165.73VVDS F14 149.06 149.63 150.21 150.78 151.350.861.151.431.722.01COSMOS 51.66 52.23 52.80 53.38 53.9529.2228.6528.0727.5026.93SNC3 35.61 36.19 36.76 37.33 37.915.735.164.584.013.44SNX3 Figure 1. Positions in the sky of the four calibration elds. In the zoomedin inset panels it is possible to observe the spectroscopic matched galaxies, in red, in front of all the DES galaxies detected in the elds, in black. quent exposures/CCDs to the ducial exposure by matching overlapping bright objects. In addition, we also applied a fur ther relative photometric calibration step, by selecting bright r= 18{22 galaxies in each eld and osetting the zeropoints in the other 5 lters so that the median galaxy colors relative tor(i.e.,g"
14,Model Distillation with Knowledge Transfer from Face Classification to Alignment and Verification.txt,"Knowledge distillation is a potential solution for model compression. The
idea is to make a small student network imitate the target of a large teacher
network, then the student network can be competitive to the teacher one. Most
previous studies focus on model distillation in the classification task, where
they propose different architects and initializations for the student network.
However, only the classification task is not enough, and other related tasks
such as regression and retrieval are barely considered. To solve the problem,
in this paper, we take face recognition as a breaking point and propose model
distillation with knowledge transfer from face classification to alignment and
verification. By selecting appropriate initializations and targets in the
knowledge transfer, the distillation can be easier in non-classification tasks.
Experiments on the CelebA and CASIA-WebFace datasets demonstrate that the
student network can be competitive to the teacher one in alignment and
verification, and even surpasses the teacher network under specific compression
rates. In addition, to achieve stronger knowledge transfer, we also use a
common initialization trick to improve the distillation performance of
classification. Evaluations on the CASIA-Webface and large-scale MS-Celeb-1M
datasets show the effectiveness of this simple trick.","Since the emergence of Alexnet[ 13], larger and deeper networks have shown to be more powerful[ 23, 24,8]. However, as the network going larger and deeper, it becomes difÔ¨Åcult to use it in mobile devices. Therefore, model compression has become necessary in compressing the large network into a small one. In recent years, many compression methods have been proposed, including knowledge distillation[ 1,9,20], weight quantization[ 5,18], weight pruning[ 7,25] and weight decomposition[ 3,17]. In this paper, we focus on the knowledge distillation, which is a potential approach for model compression. In knowledge distillation, there is usually a large teacher network and a small student one, and the objective is to make the student network competitive to the teacher one by learning speciÔ¨Åc targets of the teacher network. Previous studies mainly consider the selection of targets in the classiÔ¨Åcation task, e.g., hidden layers[ 16], logits[ 1,26,21] or soft predictions[ 9,20]. However, only the distillation of the classiÔ¨Åcation task is not enough, and some common tasks such as regression and retrieval should also be considered. In this paper, we take face recognition as a breaking point that we start with the knowledge distillation in face classiÔ¨Åcation, and consider the distillation on two domainsimilar tasks, including face alignment and veriÔ¨Åcation. The objective of face alignment is to locate the keypoint locations in each image; while in face veriÔ¨Åcation, we have to determine if two images belong to the same identity. Chong Wang is the corresponding author and Xipeng Lan has equal contribution.arXiv:1709.02929v2  [cs.CV]  23 Oct 2017For distillation on nonclassiÔ¨Åcation tasks, one intuitive idea is to adopt a similar method as in face classiÔ¨Åcation that trains teacher and student networks from scratch. In this way, the distillation on all tasks will be independent, and this is a possible solution. However, this independence cannot give the best distillation performance. There has been strong evidence that in object detection[ 19], object segmentation[ 4] and image retrieval[ 31], they all used the pretrained classiÔ¨Åcation model(on ImageNet) as initialization to boost performance. This success comes from the fact that their domains are similar, which makes them transfer a lot from lowlevel to highlevel representation[ 30]. Similarly, face classiÔ¨Åcation, alignment and veriÔ¨Åcation also share the similar domain, thus we transfer the distilled knowledge of classiÔ¨Åcation by taking its teacher and student networks to initialize corresponding networks in alignment and veriÔ¨Åcation. Another problem in knowledge transfer is what targets should be used for distillation? In face classiÔ¨Åcation, the knowledge is distilled from the teacher network by learning its softprediction, which has been proved to work well[ 9,20]. However, in face alignment[ 28] and veriÔ¨Åcation[ 28], they have additional taskspeciÔ¨Åc targets. As a result, selecting the classiÔ¨Åcation or taskspeciÔ¨Åc target for distillation remains a problem. One intuitive idea is to measure the relevance of objectives between nonclassiÔ¨Åcation and classiÔ¨Åcation tasks. For example, it is not obvious to see the relation between face classiÔ¨Åcation and alignment, but the classiÔ¨Åcation can help a lot in veriÔ¨Åcation. Therefore, it seems reasonable that if the tasks are highly related, the classiÔ¨Åcation target is preferred, or the taskspeciÔ¨Åc target is better. Inspired by the above thoughts, in this paper, we propose the model distillation in face alignment and veriÔ¨Åcation by transferring the distilled knowledge from face classiÔ¨Åcation. With appropriate selection of initializations and targets, we show that the distillation performance of alignment and veriÔ¨Åcation on the CelebA[ 15] and CASIAWebFace[ 29] datasets can be largely improved, and the student network can even exceed the teacher network under speciÔ¨Åc compression rates. This knowledge transfer is our main contribution. In addition, we realize that in the proposed method, the knowledge transfer depends on the distillation of classiÔ¨Åcation, thus we use a common initialization trick to further boost the distillation performance of classiÔ¨Åcation. Evaluations on the CASIAWebFace and largescale MSCeleb1M[6] datasets show that this simple trick can give the best distillation results in the classiÔ¨Åcation task. 2 Related Work "
452,Verifying Quantized Neural Networks using SMT-Based Model Checking.txt,"Artificial Neural Networks (ANNs) are being deployed for an increasing number
of safety-critical applications, including autonomous cars and medical
diagnosis. However, concerns about their reliability have been raised due to
their black-box nature and apparent fragility to adversarial attacks. These
concerns are amplified when ANNs are deployed on restricted system, which limit
the precision of mathematical operations and thus introduce additional
quantization errors. Here, we develop and evaluate a novel symbolic
verification framework using software model checking (SMC) and satisfiability
modulo theories (SMT) to check for vulnerabilities in ANNs. More specifically,
we propose several ANN-related optimizations for SMC, including invariant
inference via interval analysis, slicing, expression simplifications, and
discretization of non-linear activation functions. With this verification
framework, we can provide formal guarantees on the safe behavior of ANNs
implemented both in floating- and fixed-point arithmetic. In this regard, our
verification approach was able to verify and produce adversarial examples for
$52$ test cases spanning image classification and general machine learning
applications. Furthermore, for small- to medium-sized ANN, our approach
completes most of its verification runs in minutes. Moreover, in contrast to
most state-of-the-art methods, our approach is not restricted to specific
choices regarding activation functions and non-quantized representations. Our
experiments show that our approach can analyze larger ANN implementations and
substantially reduce the verification time compared to state-of-the-art
techniques that use SMT solving.","Artificial neural networks (ANNs) are soft computing models usually employed for regression, machine learning, decisionmaking, and pattern recognition problems [ 13], which have been recently used to perform various safetycritical tasks. For instance, ANNs are employed for Covid 19 diagnosis [ 76], and for performing steering commands in selfdriving cars [ 98]. Unfortunately, in such contexts, incorrect classifications can cause serious problems. Indeed, adversarial disturbances can make ANNs misclassify objects, thus causing severe damage to users of safetycritical systems. For instance, Eykholt et al. [33] showed that noise and disturbances, such as graffiti on traffic signals, could result in target misclassification during the operation of computer vision systems. Moreover, given that ANNs are notorious for being difficult to interpret and debug, the whole scenario becomes even more problematic [ 68], which then claims for techniques able to assess their structures and verify results and behaviors. For this reason, there is a growing interest in verification methods for ensuring safety, accuracy, and robustness for neural networks. The approaches for ANN verification may be divided into three groups: optimization [ 34,48,84,93], reachability [49, 54, 62, 92, 96, 100, 100], and satisfiability [47, 51, 61, 75]. On the one hand, optimizationbased algorithms pose the safety verification problem as an optimization one, in which safety properties are usually treated as constraints, as described by Tjeng et al. [91]. The main difficulty of optimization methods, such as mixedinteger linear pro gramming [ 15,91,93], branch and bound [ 84], and semidefinite programming [ 34], is to deal with constraints that are nonlinear and nonconvex due to a network‚Äôs complex structure and its activation functions. Indeed, it is still possible to employ dual optimization for simplifying those constraints and then obtain a convex problem [ 32]; however, completeness tends to be lost due to relaxations. On the other hand, reachabilitybased approaches aim at computing the reachable set of an ANN by propagating input sets through it, layerbylayer, while checking whether some unsafe state (violation) belongs or not to that same reachable set. The main advantage of those methods is that they are usually sound, i.e., if the algorithm indicates that a network is unsafe, its safety property is violated. However, the computational cost to compute exact reachable sets becomes unreasonable for more complex ANNs and more extensive input spaces. In order to avoid such a problem, a reachable set is overapproximated by using symbolic [ 61,62,96] and/or settheoretic methods [ 92,100]. Although those tools effectively reduce the computational cost of reachability sets, it is still challenging to overapproximate ANN‚Äôs nonlinear elements, particularly their activa tion functions. There are some symbolic techniques suitable for dealing with overapproximation of activation functions [ 49,54]; however, most of the approaches available in literature are only able to approximate piecewiselinear and rectified linear unit (ReLU) activation functions. Finally, satisfiability modulo theories (SMT) encode both ANN and desired safety property into a single logic formula using a decidable fragment of firstorder logic, and then check whether a counterexample exists. In this regard, only binarized neural networks [ 52,81] can be encoded into boolean logic and verified with existing SAT solvers [ 20,75]. More complex ANNs, whether implemented in floating or fixedpoint [ 63,66], the latter aiming at efficiency and simplicity, require the use of firstorder logic instead of propositional logic to exploit more abstract and less expensive techniques to solve the problem at hand. For example, SMT solvers often integrate a simplifier, which applies standard algebraic reduction rules and contextual simplification to simplify the logical formula. Regarding these, several SMTbased approaches have been proposed [ 5,39,47,51, 61,62,80]. While SMT background theories allow those approaches to model the semantic of neural operations exactly using wordlevel theories, the resulting verification problem is challenging to solve [ 80]. In this respect, quantization, i.e., a representation with a lower number of bits, has been proven to make this problem even computationally harder [ 47]. As a consequence, most ACM Trans. Embedd. Comput. Syst., Vol. 1, No. 1, Article . Publication date: September 2021.Verifying Quantized Neural Networks using SMTBased Model Checking 3 existing approaches specialize in simple piecewiselinear activation functions [ 5,39,61], focus on the floatingpoint scenario only [62], or require domainspecific abstractions [51]. Against this background, we propose a novel approach to verify both fixed and floatingpoint ANN implementations. Our main idea is to look at the source code of an ANN rather than the abstract mathematical model behind it. By doing so, we can then leverage many recent advances in software verification that can dramatically increase the computational efficiency of verification processes, as observed in our experimental evaluation. More specifically, in this paper, we make the following original contributions: ‚Ä¢We cast the ANN verification problem into a software verification one. On the one hand, we propose a method to represent ANN safety properties as pairs of assume andassert instruc tions. On the other hand, we explain how to represent fixed and floatingpoint operations in a quantized ANN, using direct implementations of their behavior, i.e., representations that consider a target precision. ‚Ä¢We introduce several preprocessing steps to increase the efficiency of downstream software verification tools. Namely, we give a principled method to discretize nonlinear activation functions and replace them with lookup tables. Furthermore, we show how to bound the feasible range of each variable with interval analysis and how to represent those bounds with additional assume instructions. ‚Ä¢We detail which existing techniques for searchspace reduction can be borrowed from the software verification literature, and we empirically evaluate their individual and cumulative effects. ‚Ä¢We evaluate our approach on fixed and floatingpoint ANNs and give empirical evidence on its computational efficiency. In particular, we show that we can verify ANNs with hundreds of neurons in less than an hour. ‚Ä¢We compare our approach with stateoftheart (SOTA) techniques, including quantized and floatingpoint tools. According to the comparison, since our method applies various optimization techniques before invoking the SMT solver, we have better performance than other SMTbased verification tools. Outline . In Section 2, we introduce the ANN verification problem and present existing satisfiability modulo theories. In Section 3, we detail all the steps involved in our codelevel verification approach for ANNs. In Section 4, we empirically test our approach on ANN classifiers trained on the classic Iris dataset and an image recognition dataset. In Section 5, we give a broader review of the recent trends in verifying ANNs. In Section 6, we conclude and outline possible future work. 2 PRELIMINARIES Before introducing the details of our verification approach, let us review some important concepts related to the verification of artificial neural networks. 2.1 Artificial Neural Networks (ANNs) Modern ANNs are universal function approximators built by composing multiple copies of the same basic building block, called neuron [ 13]. In other words, they provide a way of constructing system models with a set of sample observations, in such a way that the joint behavior of existing neurons is correctly adjusted. In their most common form, each neuron ùëòis itself the composition of two functions, as illustrated in Fig. 1. The first one is an affine projection of the ùëölocal inputs, often referred to as the activation potential ùë¢ùëò. The second one is a nonlinear transformation of the resulting potential, often referred to as activation function Nùëò. Together, they define the following mappingùëõùëò: Rùëö‚Üí R: ACM Trans. Embedd. Comput. Syst., Vol. 1, No. 1, Article . Publication date: September 2021.4 Luiz Sena, Xidan Song, Erickson Alves, Iury Bessa, Edoardo Manino, Lucas Cordeiro, and Eddie de Lima Filho ùë¶ùëò=Nùëò(ùë¢ùëò), (1) where ùë¢ùëò(ùë•)=ùëö‚àëÔ∏Å ùëó=1ùë§ùëó,ùëòùë•ùëó+ùëèùëò. (2) Finally,ùëèùëòprovides a way of directly shifting a given activation function. ùë•ùëó Œ£Nùëò(ùë¢ùëò)Activation function ùë¶ùëòOutputùë•1 ùë•ùëöBias ùëèùëò ... ...ùë§1,ùëò ùë§ùëó,ùëò ùë§ùëö,ùëòùë¢ùëò WeightsInputs Fig. 1. The detailed view of a single neuron ùëõùëò. The behavior of the basic neuron in Fig. 1 depends on the values of its weights ùë§ùëòand also on the chosen activation function Nùëò. In this regard, researchers have experimented with a wide range of functions, including nonmonotonic [ 78,88], noncontinuous [ 13], and unbounded ones [ 46,74]. In our experiments, which are available in Section 4, we cover the most popular activation functions: namely, ReLU, sigmoid (Sigm), and the rescaled version of the latter known as hyperbolic tangent (TanH): NReLU(ùë¢ùëò)=max(0,ùë¢ùëò) (3) NSigm(ùë¢ùëò)="
106,Boosting Robustness Verification of Semantic Feature Neighborhoods.txt,"Deep neural networks have been shown to be vulnerable to adversarial attacks
that perturb inputs based on semantic features. Existing robustness analyzers
can reason about semantic feature neighborhoods to increase the networks'
reliability. However, despite the significant progress in these techniques,
they still struggle to scale to deep networks and large neighborhoods. In this
work, we introduce VeeP, an active learning approach that splits the
verification process into a series of smaller verification steps, each is
submitted to an existing robustness analyzer. The key idea is to build on prior
steps to predict the next optimal step. The optimal step is predicted by
estimating the certification velocity and sensitivity via parametric
regression. We evaluate VeeP on MNIST, Fashion-MNIST, CIFAR-10 and ImageNet and
show that it can analyze neighborhoods of various features: brightness,
contrast, hue, saturation, and lightness. We show that, on average, given a 90
minute timeout, VeeP verifies 96% of the maximally certifiable neighborhoods
within 29 minutes, while existing splitting approaches verify, on average, 73%
of the maximally certifiable neighborhoods within 58 minutes.","The reliability of deep neural networks (DNNs) has been undermined by adversar ial examples: perturbations to inputs that deceive the network. Many adversarial attacks perturb an input image by perturbing each pixel independently by up to a small constant [14,44,26,35,45]. To understand the local robustness of a DNN inballs around given images, many analysis techniques have been pro posed [ 51,12,23,47,33,37,53,16,41,13,46]. In parallel, semantic adversarial attacks have been introduced, such as HSV transformations [ 21] and colorization and texture attacks [ 5]. Figure 1 illustrates some of these transformations. Unlike ball adversarial attacks which are not visible, feature adversarial attacks can be visible, because the assumption is that humans and networks should not misclassify an image due to perturbations of semantic features. Reasoning about networks' robustness to semantic feature perturbations introduces new challenges to robustness analyzers. The main challenge is that unlike ball attacks, where pixels can be perturbed independently, feature attacks impose dependencies on the pixels. Abstracting a feature neighborhood to its smallest bounding ball will lead to too many false alarms. Thus, existing robustness analyzers designed forball neighborhoods perform very poorly on feature neighborhoods.arXiv:2209.05446v1  [cs.LG]  12 Sep 20222 A. Kabaha and D. DrachslerCohen This gave rise to several works on analyzing the robustness of feature neigh borhoods [ 31,3,41]. These works rely on existing ball robustness analyzers and employ two main techniques to reduce the loss of precision. First, they encode the pixels' dependencies imposed by the features by adding layers to the network [ 31] or by computing a tight linear abstraction of the feature neighborhood [ 3]. Second, they split the input range into smaller parts, each is veried independently, e.g., using uniform splitting [ 31,3,41]. Despite of these techniques, for deep networks and large neighborhoods, existing works either lose too much precision and fail to verify or split the neighborhoods into too many parts. In the latter case, ap proaches must choose between a very long execution time (several hours for deep networks and a single neighborhood) or forcing the analysis to terminate within a certain timeout, leading to certication of neighborhoods that are signicantly smaller than the maximal certiable neighborhoods. These inherent limitations diminish the ability to understand how vulnerable a network is to feature attacks. Our work: splitting of feature neighborhoods via active learning We address the following problem: given a set of features, each with a target perturbation diame ter, nd a maximally robust neighborhood dened by these features. We propose a dynamic closetooptimal input splitting to boost the robustness certication of feature neighborhoods. Unlike previous splitting techniques, which perform uniform splitting [ 31,3] or branchandbound [ 7,47,6,34,51,29,19], our splitting relies on active learning: the success or failure of previous splits determines the size of future splits. The key idea is to phrase the verication task as a process, where each step picks an unproven part of the neighborhood and submits it to a robustness analyzer. The analyzer either succeeds in proving robustness or fails. Our goal is to compute the optimal split. An optimal split is one where the number of failed steps is minimal, the size of each proven part is maximal, and the execution time is minimal. Predicting an optimal split requires estimating the exact robustness boundary of the neighborhood, which is challenging. Splitting by predicting the analyzer's velocity and sensitivity We present VeeP (for verication predictor), a learning algorithm, treating the robustness analyzer as the oracle, which dynamically denes the splitting. VeeP denes the next step by predicting the next optimal diameters. To this end, it approximates the analyzer's sensitivity and velocity for the unproven part. Informally, the sensitivity is a function of the diameters quantifying how certain the robustness analyzer is that the neighborhood is robust. A positive sensitivity means the analyzer determines the neighborhood is robust, while a nonpositive sensitivity means the analyzer fails. The velocity is a function of the diameters quantifying the speed of the robustness analyzer. VeeP predicts the diameters of the next step by solving a constrained optimization problem: it looks for the diameters maximizing the velocity such that its sensitivity is positive. VeeP relies on parametric regression to approximate the velocity and sensitivity functions of the current step. It terminates either when it succeeds verifying robustness for the given target diameters or when it fails to prove robustness for too small parts. It is thus a sound and precise verier, up to a tunable precision level.Boosting Robustness Verication of Semantic Feature Neighborhoods 3 Hue Saturation Lightness  Fig. 1: Examples of ImageNet images and maximally perturbed images in the neighborhoods that VeeP veried robust, for an AlexNet model. We implemented VeeP in a system, which relies on GPUPoly [ 33] as the robustness analyzer (the oracle). We evaluate VeeP on dierent kinds of architec tures, including ResNet models for CIFAR10 and AlexNet models for ImageNet. Our experiments focus on several semantic features: brightness, contrast, and HSL (hue, saturation, lightness). Results show that, when given a 90 minute timeout, VeeP almost perfectly closes the gap between the maximal certied feature neighborhoods and the minimal feature adversarial examples: the veried diameters that VeeP computes are, on average, at least 96% of the maximal certiable diameter. On average, VeeP completes in 29 minutes. We compare to branchandbound, which computes 74% of the maximal diameters in 54 minutes, and to uniform splitting, which computes 73% of the maximal diameters in 62 minutes. We study the acceleration rate of VeeP over branchandbound and uniform splitting by running an experiment without a timeout. Results show that VeeP reduces the execution time of branchandbound by 4.4x and of uniform splitting by 10.2x. We also compare to the theoretical optimal greedy baseline that \knows"" the optimal diameter of every step. We show that VeeP's time overhead is only 1.2x more than this theoretical optimal baseline. Figure 1 illustrates how large the neighborhoods that VeeP veries. It shows pairs of original ImageNet images and the maximally perturbed image in the neighborhood that VeeP veried robust, for an AlexNet model. In these examples, every neighborhood is dened by a dierent feature (hue, saturation, and lightness), and the target diameter submitted to VeeP is determined by computing a minimal adversarial feature example along the corresponding feature. To conclude, our main contributions are: {A learning algorithm, called VeeP, to verify robustness of feature neighbor hoods. VeeP computes an optimal split of the neighborhood, each part is veried by a robustness analyzer. To predict the next split, VeeP approximates the analyzer's velocity and sensitivity using parametric regression. {An evaluation of VeeP on MNIST, Fashion MNIST, CIFAR10 and Im ageNet over fullyconnected, convolutional, ResNet, and AlexNet models. Our evaluation focuses on neighborhoods dened using brightness, contrast, and HSL. Results show that VeeP provides a signicant acceleration over branchandbound and uniform splitting.4 A. Kabaha and D. DrachslerCohen 2 Preliminaries In this section, we provide the background on neural network classiers, verica tion of feature neighborhoods, and existing splitting approaches. Neural network classiers Given an input domain Rdand a set of classes C= f1;:::;cg, a classier is a function mapping inputs to a score vector over the possible classes D:Rd!Rc. A fullyconnected network consists of Llayers. The rst layer takes as input a vector from Rd, denotedi, and it passes the input as is to the next layer. The last layer outputs a vector, denoted oD(i), consisting of a score for each class in C. The classication of the network for inputiis the class with the highest score, c0=argmax (oD(i)). When it is clear from the context, we omit the superscript D. The layers are functions, denoted h1;h2;:::;hL, each takes as input the output of the preceding layer. The network's function is the composition of the layers: o(i) =D(i) =hL(hL"
437,Environmental Sound Recognition using Masked Conditional Neural Networks.txt,"Neural network based architectures used for sound recognition are usually
adapted from other application domains, which may not harness sound related
properties. The ConditionaL Neural Network (CLNN) is designed to consider the
relational properties across frames in a temporal signal, and its extension the
Masked ConditionaL Neural Network (MCLNN) embeds a filterbank behavior within
the network, which enforces the network to learn in frequency bands rather than
bins. Additionally, it automates the exploration of different feature
combinations analogous to handcrafting the optimum combination of features for
a recognition task. We applied the MCLNN to the environmental sounds of the
ESC-10 dataset. The MCLNN achieved competitive accuracies compared to
state-of-the-art convolutional neural networks and hand-crafted attempts.","Hand crafting the features required for the sound recognit ion problem has been inves tigated for decades. It is still an open area of research that consumes a lot of effort in  an attempt to design the best features to be fed to a recognition system. Deep architec tures of neural networks are currently being conside red to be a replacement to the  feature hand crafting stage. There is an endeavor  to use these deep architectures  that  achieved wide  success  for images [1] , on signals like sound to extract features auto matically that can be further classifi ed using a conventional classifier such as a  Support Vector Machine (SVM ) [2]. Hand crafted features still hold their position, but                                                           1 Code: https://github.com/fadymedhat/MCLNN   ‚Ä†This work is funded by the European Union‚Äôs Seventh Framework  Programme for research,  technological development and demonstration under grant agreement no. 608014  (CAPACITIE).    2             Fady Medhat, David Chesmore, John Robinson   the performance gap between them and the use of  the deep neural architectures as  automatic feature extractors is getting narrower.   The work by Soltau et al. [3] marks an early attempt in using neural  networks   based architectures  for feature extraction in sound recognition. In their work, they  used a three stage recognition system . The first stage is an event detection phas e to  extract musical events, where they dropped the output nodes  of a neural network  and  used the hidden node s as features for the succeeding stages . A more recent attempt by  Lee et al. [4 ] used Convolutional Deep Belie f Networks [5]  for several audio recogni tion tasks. Hamel et al. [6] introduced another attempt t o extract features using a Deep  Belief Network (DBN) architecture , where the features extracted with the DBN were   further classified using an SVM , a similar  attempt  was in [ 7]. Hinton e t al. [8] pro posed the use of deep neural network architectures to replace the Gaussian Mixture  Model (GMM) in a GMMHMM combination for speech recognition. G raves et al.  [9] used a deep recurrent neural network for speech recognition. An overlapping us age to music genre classification was in the work of Oord et  al. [10], where they used  Convolutional Neural Network (CNN) [11 ] for automatic music recommendation.  Dieleman et al. [12 ] aimed to bypass the need for an intermediate signal  representation  like spectrograms  by using a CNN over the raw signal , where their  findings show ed that spectrograms  provided better performance .  Several neural based architectures were proposed  for the sound recognition prob lem in music, speech and environmental sound, but they are usually adapted to the  sound problem after they gain wide  acceptance by the research community in other  applications especially  image recognition . Despite  these successful attempts, they  may not har ness the full properties of the sound signal  represented in a spectrogram .   For example , recent effor ts [13, 14] proposed  the need to restructure the widely u sed  Convolutional Neural Network (CNN) to fit the sound recognition problem. This need  is attributed to the inability of the vanilla CNN to preserve the spatial locality of the  learned features across the frequency domain in a time frequency representation . Sim ilarly, DBN s have  a shortcoming in ignoring the interframes  relation, where it treats  each frame as an isolated entity.    The ConditionaL  Neural Network (CLNN) [15] is designed to exploit the time  frequency representation of the sound signals. The model structure also extends its  application to other multidimensional temporal representations . The CLNN takes  into consideration the influence the successive frames, in a  temporal signal, have on  each other. The Masked Conditional Neural Network (MCLNN) [15]  extends the  functionality of the CLNN to include a binary masking operation using a systematic  sparseness to automate the  exploration of different feature combinations concurrently,  which is usually a manual mix andmatch process of various  features combinations.  Additionally, the MCLNN embeds  a filterbank  behavior , which lends  filterbank ‚Äôs  properties such as the freque ncy s hiftinvariance to the neural network structure.  In  this work, we extend the work in [16]  with an analysis  of the masking effect in the  MCLNN compared to the CLNN.   Environmental Sound Recognition using Masked Conditional Neural Networks             3  2 Related Work   "
127,MobileFaceNets: Efficient CNNs for Accurate Real-Time Face Verification on Mobile Devices.txt,"We present a class of extremely efficient CNN models, MobileFaceNets, which
use less than 1 million parameters and are specifically tailored for
high-accuracy real-time face verification on mobile and embedded devices. We
first make a simple analysis on the weakness of common mobile networks for face
verification. The weakness has been well overcome by our specifically designed
MobileFaceNets. Under the same experimental conditions, our MobileFaceNets
achieve significantly superior accuracy as well as more than 2 times actual
speedup over MobileNetV2. After trained by ArcFace loss on the refined
MS-Celeb-1M, our single MobileFaceNet of 4.0MB size achieves 99.55% accuracy on
LFW and 92.59% TAR@FAR1e-6 on MegaFace, which is even comparable to
state-of-the-art big CNN models of hundreds MB size. The fastest one of
MobileFaceNets has an actual inference time of 18 milliseconds on a mobile
phone. For face verification, MobileFaceNets achieve significantly improved
efficiency over previous state-of-the-art mobile CNNs.","Face verification is an important identity authentication technology used in more and  more mobile and embedded applications suc h as device unlock, application login,  mobile payment and so on. Some mobile applications equipped with face verification  technology, for example, smartphone unlock, need to run offline. To achieve user  friendliness with limited computation resources, the face verification models  deployed locally on mobile devices are expected to be not only accurate but also  small and fast. However, modern high accuracy face verification models are built  upon deep and big convolutional neural networks (CNNs) which are supe rvised by  novel loss functions during training stage. The big CNN models requiring high  computational resources are not suitable for many mobile and embedded applications.  Several highly efficient neural network architectures, for example, MobileNetV1 [1],  ShuffleNet [2], and MobileNetV2 [3], have been proposed for common visual  recognition tasks rather than face verification in recent years. It is a straight forward  way to use these common CNNs unchanged for face verification, which only achieves  very infe rior accuracy compared with state oftheart results according to our  experiments (see Table 2 ).    Fig. 1. A typical face feature embedding CNN and the receptive field (RF). The last 7x7 feature  map is denoted as FMap end. RF1 and RF2 correspond to the corner unit and the center unit in  FMap end respectively. The corner unit should be of less importance than the center unit.  When a global depthwise convolution (GDConv) is used as the global operator, for a fixed  spatia l position, the norm of the weight vector consisted of GDConv weights in all channels can  be considered as the spatial importance. We show that GDConv learns very different  importances at different spatial position s after training.   In this paper, we make a simple analysis on common mobile networks‚Äô weakness  for face verification. The weakness has been well overcome by our specifically  designed MobileFaceNets, which is a class of extremely efficient CNN models  tailored for high accura cy real time face verification on mobile and embedded  devices. Our MobileFaceNets use less than 1 million parameters. Under the same  experimental conditions, our MobileFaceNets achieve significantly superior accuracy  as well as more than 2 times actual spe edup over MobileNetV2. After trained on the  refined MS Celeb 1M [4] by ArcFace [5] loss from scratch, our single  MobileFaceNet model of 4.0MB size achieves 99.55% face verification accuracy (see  Table 3) on LFW [6] and 92.59% TAR@FAR10 6 (see Table 4) on M egaFace  Challenge 1 [7], which is even comparable to state oftheart big CNN models of  hundreds MB size. Note that many existing techniques such as pruning [37], low bit  quantization [29], and knowledge distillation [16] are able to improve  MobileFaceNets ‚Äô efficiency additionally, but these are not included in the scope of  this paper.   The major contributions of this paper are summarized as follows: (1) After the last  (nonglobal) convolutional layer of a face feature embedding CNN, we use a global  depthwis e convolution layer rather than a global average pooling layer or a fully  connected layer to output a discriminative feature vector. The advantage of this choice  is also analyzed in both theory and experiment. (2) We carefully design a class of face  featur e embedding CNNs, namely MobileFaceNets, with extreme efficiency on  mobile and embedded devices. (3) Our experiments on LFW, AgeDB ([8]), and  MegaFace show that our MobileFaceNets achieve significantly improved efficiency  over previous stateoftheart mobile CNNs for face verification.   2   Related Work   "
440,Verification of Very Low-Resolution Faces Using An Identity-Preserving Deep Face Super-Resolution Network.txt,"Face super-resolution methods usually aim at producing visually appealing
results rather than preserving distinctive features for further face
identification. In this work, we propose a deep learning method for face
verification on very low-resolution face images that involves
identity-preserving face super-resolution. Our framework includes a
super-resolution network and a feature extraction network. We train a VGG-based
deep face recognition network (Parkhi et al. 2015) to be used as feature
extractor. Our super-resolution network is trained to minimize the feature
distance between the high resolution ground truth image and the super-resolved
image, where features are extracted using our pre-trained feature extraction
network. We carry out experiments on FRGC, Multi-PIE, LFW-a, and MegaFace
datasets to evaluate our method in controlled and uncontrolled settings. The
results show that the presented method outperforms conventional
super-resolution methods in low-resolution face verification.","Face images appear in various platforms and are vital for many applications ranging from forensics to health monitoring. In most cases, these images are in lowresolution, making face identication dicult. Although many algorithms have been developed for face recognition from highquality images, few studies focus on the problem of very lowresolution face recognition. The performance of the traditional face recognition algorithms developed for high quality images, degrades considerably on lowresolution faces. There exists a tremendous amount of work in image enhancement and up sampling. Recently, high magnication factors greater than 4 times have gained more attention for targeted objects such as faces with the rise in deep learning methods. Existing methods provide an upsampling of the image that is as close as possible to \ aface image"". Since resulting upsampled images are meant to be used in face identication task, recovering \ theface"" is essential. We present a face superresolution method that preserves the identity of the person during arXiv:1903.10974v1  [cs.CV]  26 Mar 20192 Cansizoglu, Jones, Zhang, Sullivan VGGSR  Network IL JH IH JH G(IL)||f(G (IL))f(JH)||<Œ≥ ||f(IH)f(JH)||<Œ≥Same  person Different personSame  person Different personGallery Probe Gallery ProbeY NSuperresolved NYVGG VGG VGG Fig. 1. System overview for (top) lowresolution and (bottom) highresolution resolution face verication. Dashed lines indicate weight sharing between networks. superresolution by minimizing the distance in feature space as opposed to the traditional face superresolution methods designed to minimize the distance in highresolution image space. The goal of this paper is to verify whether a given lowresolution face im age is the same person as in a highresolution gallery image. Our focus is very lowresolution face images with a tiny visible facial area (as low as 6 6 pixels). We represent a face image with its VGG face descriptor. Since our goal is veri cation, the face descriptor of a superresolved face image should be as close as possible to the face descriptor of its ground truth highresolution version. Thus, we train a superresolution network by minimizing the feature distance between them. Contrary to the conventional face hallucination methods, we consider face descriptor similarity instead of appearance similarity during superresolution. Moreover, we also perform detailed experiments in order to investigate the eect of various losses in training superresolution for the task of lowresolution face verication. The performance of superresolution methods are evaluated by using image quality assessment measures such as peak signaltonoise ratio (PSNR). These measures account for the visual similarity of two images by equally paying at tention to every pixel in intensity domain. However, face identication relies on discriminative features. In this work, we present face descriptor similarity as an evaluation measure to assess the capacity of a method in preserving identity. The main contributions of our study include: (1) a novel loss term to be used for face superresolution in order to preserve identity for aggressive scaling factors as big as 8, (2) an evaluation measure to account for identity preservation on the superresolved faces, and (3) a thorough analysis of various loss terms in training a face superresolution network for lowresolution face verication. 1.1 Related Work "
160,Unconstrained Face Verification using Deep CNN Features.txt,"In this paper, we present an algorithm for unconstrained face verification
based on deep convolutional features and evaluate it on the newly released
IARPA Janus Benchmark A (IJB-A) dataset. The IJB-A dataset includes real-world
unconstrained faces from 500 subjects with full pose and illumination
variations which are much harder than the traditional Labeled Face in the Wild
(LFW) and Youtube Face (YTF) datasets. The deep convolutional neural network
(DCNN) is trained using the CASIA-WebFace dataset. Extensive experiments on the
IJB-A dataset are provided.","Face veriÔ¨Åcation is one of the core problems in com puter vision and has been actively researched for over two decades [40]. In face veriÔ¨Åcation, given two videos or im ages, the objective is to determine whether they belong to the same person. Many algorithms have been shown to work well on images that are collected in controlled set tings. However, the performance of these algorithms often degrades signiÔ¨Åcantly on images that have large variations in pose, illumination, expression, aging, cosmetics, and oc clusion. To deal with this problem, many methods have focused on learning invariant and discriminative representation from face images and videos. One approach is to extract over complete and highdimensional feature representation fol lowed by a learned metric to project the feature vector into a lowdimensional space and to compute the similar ity score. For instance, the highdimensional multiscale Local Binary Pattern (LBP)[5] features extracted from lo cal patches around facial landmarks is reasonably effective for face recognition. Face representation based on Fisher vector (FV) has also shown to be effective for face recog nition problems [26][23], [9]. However, deep convolu tional neural networks (DCNN) have demonstrated impres sive performances on different tasks such as object recognition [21][31], object detection [14], and face veriÔ¨Åcation [25]. It has been shown that a DCNN model can not only characterize large data variations but also learn a compact and discriminative feature representation when the size of the training data is sufÔ¨Åciently large. Once the model is learned, it is possible to generalize it to other tasks by Ô¨Åne tuning the learned model on target datasets [13]. In this work, we train a DCNN model using a relatively small face dataset, the CASIAWebFace [38], and compare the perfor mance of our method with other commercial offtheshelf face matchers on the challenging IJBA dataset which con tains signiÔ¨Åcant variations in pose, illumination, expression, resolution and occlusion. We also evaluate the performance of the proposed method on the LFW dataset. The rest of the paper is organized as follows. We brieÔ¨Çy review some related works in Section 2. Details of the dif ferent components of the proposed method including the DCNN representation and joint Bayesian metric learning are given in Section 3. The protocol and the experimen tal results are presented in Section 4. Finally, we conclude the paper in Section 5 with a brief summary and discussion. 2. Related Work "
81,Neural Network Verification in Control.txt,"Learning-based methods could provide solutions to many of the long-standing
challenges in control. However, the neural networks (NNs) commonly used in
modern learning approaches present substantial challenges for analyzing the
resulting control systems' safety properties. Fortunately, a new body of
literature could provide tractable methods for analysis and verification of
these high dimensional, highly nonlinear representations. This tutorial first
introduces and unifies recent techniques (many of which originated in the
computer vision and machine learning communities) for verifying robustness
properties of NNs. The techniques are then extended to provide formal
guarantees of neural feedback loops (e.g., closed-loop system with NN control
policy). The provided tools are shown to enable closed-loop reachability
analysis and robust deep reinforcement learning.","Datadriven (or learningbased) methods offer many com pelling advantages for addressing longstanding issues in the Ô¨Åeld of controls. For instance, real environments are often highly dynamic, nonlinear, uncertain, and highdimensional, each of which present major challenges for the design, veriÔ¨Åcation and deployment of control systems. [1] identiÔ¨Åes opportunities to reduce the costs of modeling complicated systems and improve the control of largescale networked systems through learning: ‚ÄúIn order to maintain veriÔ¨Åable high performance, future engineering systems will need to be equipped with online capabilities for active model learning and adaptation, and for model accuracy assessment.‚Äù Despite the potential advantages of learningbased control, this tutorial focuses on a fundamental open question: how can we certify the safety, performance, and robustness properties of learning machines? Autonomous vehicles, passenger aircraft, and surgical robots are examples of con trol systems that need safety guarantees, while robots that explore oceans or other planets require assurances that an ex pensive, onetime experiment will succeed. There are many challenges with solving these NN veriÔ¨Åcation problems. For instance, realworld uncertainties (e.g., from sensor noise, imperfect state estimates, unknown initial conditions, adversarial attacks [2]) often appear at the NN input and must be mapped through the NN to make a formal statement about the set of possible NN outputs. The high dimensionality and nonlinear nature of NNs introduces technical challenges for quickly and accurately propagating uncertainty sets through the NN. Fortunately, there is a growing body of literature on this topic, much of which began in the computer vision and The author is with the Aerospace Controls Laboratory at the Mas sachusetts Institute of Technology, mfe@mit.edu . This work was sup ported by Ford Motor Company. Fig. 1: Neural Networks are a key component of many promising learningbased approaches for challenging con trols problems. This tutorial introduces frameworks for the veriÔ¨Åcation of robustness, safety, and performance proper ties, which is a critical step toward bringing learningbased methods to realworld control systems. machine learning communities. Section III introduces and uniÔ¨Åes the literature into a framework that can be tailored for speciÔ¨Åc applications. While NNs are difÔ¨Åcult to analyze in isolation, the analysis is even more challenging for neural feedback loops (NFLs) ‚Äì closedloop systems with NN components, depicted in Fig. 1. A fundamental challenge in NFLs is that NN outputs can inÔ¨Çuence the NN inputs at the next step. Thus, conservatism about NN outputs compounds as time advances, which must be handled to verify meaningful properties. Section IV introduces the literature and describes a linear programming based approach to estimate an NFL‚Äôs forward reachable sets ‚Äì the set of all states the closedloop system could enter in some time interval. The reachable sets could then be used to guarantee the control system will avoid undesirable states and terminate in a goal set. In addition to verifying properties, NN analysis tools can be leveraged to address the socalled ‚Äúsimtoreal gap‚Äù that plagues learning methods, and reinforcement learning in particular. [3]‚Äì[12] provide examples where the performance of learned control policies can be degraded substantially by introducing a small uncertainties that were not present during training. To address this issue with analysis tools, Section VI introduces a method for robust reinforcement learning that considers the worstcase outcomes of its actions, with respect to knowntobeimperfect state observations. This tutorial is based on material in [13]‚Äì[16] and pro vides further exposition and connections between the key problems. II. L ITERATURE REVIEW A. Neural Networks in Control Early work on NNs in control systems dates back to the 1960s [17], [18], with substantial interest in the 1980s andarXiv:2110.01388v1  [cs.LG]  30 Sep 20211990s, especially for the control of nonlinear systems [19]‚Äì [21]. Many of the NN architectures used today were devel oped in this era, including the convolutional neural network (CNN) [22] and long shortterm memory (LSTM) [23]. So why are NNs a big deal again? What has changed? One massive improvement is the ecosystem of tools: new computer hardware categories for faster training/inference (e.g., GPUs [24], TPUs [25]), opensource software pack ages (e.g., Caffe [26], TensorFlow [27], PyTorch [28]), massive curated datasets (e.g., ImageNet [29]), and well established benchmark simulation tasks (e.g., Atari [30], [31], Gym [32]). In parallel, substantial algorithmic advances (e.g., dropout [33]), novel architectures (generative adversar ial networks [34], autoencoders [35]), and latency reductions (e.g., MobileNet [36]) expand what can be learned from data. Another paradigm shift is the idea of deep NNs (NNs with many hidden layers), as they unlock the ability to deal with highdimensional inputs from modern perception systems (e.g., cameras). Going far beyond the classical notions of state estimates from 1D sensors, DNNs provide a way to extract semantic knowledge and context clues in realtime from onboard sensing. A body of work on endtoend learning takes this idea to an extreme by learning a mapping from raw sensor data to control. Building on these advances, recent work demonstrates that NNs are a powerful representation for various control problems, including: learning a control policy [37]‚Äì[39] learning the system‚Äôs model from data [40], possibly using physical constraints [41]‚Äì[44] online estimation of states or parameters [45], [46] learning a representation for veriÔ¨Åcation [47]‚Äì[50] Despite this progress, NNs still present many challenges for control systems. For example, deep learning algorithms typically require massive amounts of training data, which can be expensive or dangerous to acquire and annotate. NNs‚Äô lack of interpretability and possible overconÔ¨Ådence in unsupported predictions are common concerns, as well. The combination of physicsbased models with data is a promising approach, but there is not yet a consensus in the community on what should be modeled versus learned. This tutorial focuses on the challenges of verifying systems that employ NNs. B. VeriÔ¨Åcation in Controls Control design is primarily concerned with stability, per formance, and robustness. While there are many mathemat ical tools to aid the design of controllers and proof of these properties, there is usually still a gap between the models used for control design and the real, deployed systems. Thus, formal veriÔ¨Åcation techniques provide assurances that the real system will meet speciÔ¨Åcations. [51] provides a recent surveys on the topic in the context of robotics. [52] and [53] provide further depth in verifying the software and hybrid nature of real control system implementations, respectively. [54] provides a survey on practitioners‚Äô perception of the stateoftheart for these methods.A main focus of this tutorial is reachability analysis , which is a standard component of safety veriÔ¨Åcation. Informally, these methods compute the set of all states the system could ever reach, which can be used to provide guarantees that the system will, for example, reach the desired state and avoid dangerous regions of the state space. Modern methods include HamiltonJacobi Reachability methods [40], [55], SpaceEx [56], Flow* [57], CORA [58], and C2E2 [59], [60]. Orthogonal approaches that do not explicitly estimate the system‚Äôs forward reachable set, but provide other notions of safety that assist in veriÔ¨Åcation, include Lyapunov func tion search [61] and control barrier functions (CBFs) [62]. Several recent methods learn a representation that aids in veriÔ¨Åcation [47]‚Äì[50]. Some of the key open issues include scalability to high dimensional systems, computation time required for veriÔ¨Åca tion, and overconservatism that can lead to arbitrarily loose performance bounds. Moreover, a relatively small subset of the literature focuses on NN control policies, which present additional challenges as described next. C. VeriÔ¨Åcation of Neural Feedback Loops Despite the importance of analyzing closedloop behavior, much of the recent work on formal NN analysis has focused on NNs in isolation (e.g., for image classiÔ¨Åcation) [63]‚Äì [68], with an emphasis on efÔ¨Åciently relaxing NN nonlineari ties [69]‚Äì[75]. [76] provides an excellent software repository for general computation graphs. When NNs are embedded in feedback loops, a new set of challenges arise for veriÔ¨Åcation, surveyed in [77], [78]. To verify stability properties, [79] uses linear differential inclusions (LDI), and [80] uses interval constraint programming (ICP). A handful of recent works [81]‚Äì[86] propose methods that compute forward reachable sets of closedloop systems with NN controllers. A key challenge is in maintaining computational efÔ¨Åciency while still providing tight bounds on the reachable sets. [81]‚Äì[83] use polynomial approximations of NNs to make the analysis tractable. Most works consider NNs with ReLU approximations, whereas [84] considers sigmoidal activations. [85], [87] introduce conservatism by assuming the NN controller could output its extreme values at every state. [88] developed a method for ReLU NNs that also computes backward reachable sets, and [86] recently ap proached the problem with semideÔ¨Ånite programming (SDP). Key open issues include the analysis of NFLs with high dimensional, nonlinear, or stochastic plants and accounting for realistic perception systems (e.g., camera, lidar data). Additionally, veriÔ¨Åcation methods are rarely embedded in the learning process, which could be a path toward synthesizing knowntobesafe NFLs, building on ideas from work on isolated NNs [89]. III. A NALYZING NN S IN ISOLATION This tutorial begins by introducing tools for formally analyzing NNs (in isolation). While empirical performance statistics can indicate that a NN has learned a useful input output mapping, there are still concerns about how muchProblem Reachability VeriÔ¨Åcation Minimal Adversarial Example Graphic Problem Compute NN‚Äôs reachable set from Sin(xnom), known formally as ‚Äúthe image ofSin(xnom)under the DNN f‚Äù, written as f[Sin(xnom)] =ff(x)jx2Sin(xnom)gWill NN classiÔ¨Åer output same label for every x(0)2Sin(xnom)? Recall that in classiÔ¨Åcation, NN predicts an input‚Äôs label, i= argmaxjfj(xnom).Unknown Sin(xnom). For classiÔ¨Åcation, minimal adv. example is result of apply ing smallest perturbation to nominal input xnomto cause nonnominal predicted label. Answer Output Set Yes/No/Unsure Perturbed Input Algorithm SketchFor`1ball output set, solve (2) for 2nL+1objectives, ci(z(L)) = sign( i)eT i z(L) 8i2f"
16,Output Reachable Set Estimation and Verification for Multi-Layer Neural Networks.txt,"In this paper, the output reachable estimation and safety verification
problems for multi-layer perceptron neural networks are addressed. First, a
conception called maximum sensitivity in introduced and, for a class of
multi-layer perceptrons whose activation functions are monotonic functions, the
maximum sensitivity can be computed via solving convex optimization problems.
Then, using a simulation-based method, the output reachable set estimation
problem for neural networks is formulated into a chain of optimization
problems. Finally, an automated safety verification is developed based on the
output reachable set estimation result. An application to the safety
verification for a robotic arm model with two joints is presented to show the
effectiveness of proposed approaches.","ArtiÔ¨Åcial neural networks have been widely used in machine learning systems. Applications include adaptive control [ 1]‚Äì [4], pattern recognition [5], [6], game playing [7], autono mous vehicles [8], and many others. Though neural networks have been showing the effectiveness and powerful ability in deal ing with complex problems, they are conÔ¨Åned to systems which comply only to the lowest safety integrity levels since, in most of the time, a neural network is viewed as a black box without effective methods to assure safety speciÔ¨Åcations f or its outputs. Verifying neural networks is a hard problem, ev en simple properties about them have been proven NPcomplete problems [9]. The difÔ¨Åculties mainly come from the presence of activation functions and the complex structures, making neural networks largescale, nonlinear, nonconvex and th us incomprehensible to humans. Until now, only few results hav e been reported for verifying neural networks. The veriÔ¨Åcati on for feedforward multilayer neural networks is investiga ted based on SatisÔ¨Åability Modulo Theory (SMT) in [10], [11]. In [12] an AbstractionReÔ¨Ånement approach is proposed. In [9] , [13], a speciÔ¨Åc kind of activation functions called RectiÔ¨Åed Linear Unit is considered for veriÔ¨Åcation of neural networks. The material presented in this paper is based upon work suppo rted by the National Science Foundation (NSF) under grant numbers CNS 1 464311 and 1713253, and SHF 1527398 and 1736323, and the Air Force OfÔ¨Åce of Scien tiÔ¨Åc Research (AFOSR) under contract numbers FA9550151 0258, FA9550 1610246, and FA95501810122. The U.S. government is au thorized to reproduce and distribute reprints for Governmental purpos es notwithstanding any copyright notation thereon. Any opinions, Ô¨Åndings, and conclusions or recommendations expressed in this publication are those of the authors and do not necessarily reÔ¨Çect the views of AFOSR or NSF. Authors are with the Department of Electrical Engineering a nd Com puter Science, Vanderbilt University, Nashville, TN 37212 USA. Email: Weiming Xiang (xiangwming@gmail.com), HoangDung Tran (t rhoang dung@gmail.com), Taylor T. Johnson (taylor.johnson@gmai l.com).Additionally, some recent reachable set estimation result s are reported for neural networks [14]‚Äì[16], these results that are based on Lyapunov functions analogous to stability [17]‚Äì[2 0] and reachability analysis of dynamical systems [21], [22], have potentials to be further extended to safety veriÔ¨Åcation. In this work, we shall focus on a class of neural networks called MultiLayer Perceptron (MLP). Due to the complex structure, manual reasoning for an MLP is impossible. Inspi red by some simulationbased ideas for veriÔ¨Åcation [23]‚Äì[25], the information collected from a Ô¨Ånitely many simulations will be exploited to estimate the output reachable set of an MLP and, furthermore, to do safety veriÔ¨Åcation. To bridge th e gap between the Ô¨Ånitely many simulations and the output set generated from a bounded input set which essentially includ es inÔ¨Ånite number of inputs, a conception called maximum sensi  tivity is introduced to characterize the maximum deviation of the output subject to a bounded disturbance around a nominal input. By formulating a chain of optimizations, the maximum sensitivity for an MLP can be computed in a layerbylayer manner. Then, an exhaustive search of the input set is enable d by a discretization of input space to achieve an estimation o f output reachable set which consists of a union of reachtubes . Finally, by the merit of reachable set estimation, the safet y veriÔ¨Åcation for an MLP can be done via checking the existence of intersections between the estimated reachable set and un safe regions. The main beneÔ¨Åts of our approach are that there are very few restrictions on the activation functions except fo r the monotonicity which is satisÔ¨Åed by a variety of activatio n functions, and also no requirement on the bounded input sets . All these advantages are coming from the simulationbased nature of our approach. The remainder of this paper is organized as follows. Prelim inaries and problem formulation are given in Section II. The maximum sensitivity analysis for an MLP is studied in Sectio n III. Output reachable set estimation and safety veriÔ¨Åcatio n results are given in Section IV . An application to robotic ar ms is provided in Section V and Conclusions are presented in Section VI. II. P RELIMINARIES AND PROBLEM FORMULATION A. MultiLayer Neural Networks A neural network consists of a number of interconnected neurons. Each neuron is a simple processing element that responds to the weighted inputs it received from other neuro ns. In this paper, we consider the most popular and general feed forward neural networks called the MultiLayer Perceptron (MLP). Generally, an MLP consists of three typical classesIEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. XX, NO. XX, XX XXXX 2 of layers: An input layer, that serves to pass the input vecto r to the network, hidden layers of computation neurons, and an output layer composed of at least a computation neuron to produce the output vector. The action of a neuron depends on its activation function, which is described as yi=f/parenleftBig/summationdisplayn j=1œâijxj+Œ∏i/parenrightBig (1) wherexjis thejth input of the ith neuron, œâijis the weight from the jth input to the ith neuron, Œ∏iis called the bias of theith neuron, yiis the output of the ith neuron, f(¬∑)is the activation function. The activation function is a nonli near function describing the reaction of ith neuron with inputs xj(t),j= 1,¬∑¬∑¬∑,n. Typical activation functions include rectiÔ¨Åed linear unit, logistic, tanh, exponential linear u nit, linear functions, for instance. In this work, our approach a ims at dealing with the most of activation functions regardless of their speciÔ¨Åc forms, only the following monotonic assumpti on needs to be satisÔ¨Åed. Assumption 1: For any x1‚â§x2, the activation function satisÔ¨Åesf(x1)‚â§f(x2). Remark 1: Assumption 1 is a common property that can be satisÔ¨Åed by a variety of activation functions. For example, it is easy to verify that the most commonly used logistic function f(x) = 1/(1+e‚àíx)satisÔ¨Åes Assumption 1. An MLP has multiple layers, each layer ‚Ñì,1‚â§‚Ñì‚â§L, has n[‚Ñì]neurons. In particular, layer ‚Ñì= 0 is used to denote the input layer and n[0]stands for the number of inputs in the rest of this paper, and n[L]stands for the last layer, that is the output layer. For a neuron i,1‚â§i‚â§n[‚Ñì]in layer‚Ñì, the corresponding input vector is denoted by x[‚Ñì]and the weight matrix is W[‚Ñì]= [œâ[‚Ñì] 1,...,œâ[‚Ñì] n[‚Ñì]]‚ä§, whereœâ[‚Ñì] iis the weight vector. The bias vector for layer ‚ÑìisŒ∏[‚Ñì]= [Œ∏[‚Ñì] 1,...,Œ∏[‚Ñì] n[‚Ñì]]‚ä§. The output vector of layer ‚Ñìcan be expressed as y[‚Ñì]=f‚Ñì(W[‚Ñì]x[‚Ñì]+Œ∏[‚Ñì]) wheref‚Ñì(¬∑)is the activation function for layer ‚Ñì. For an MLP, the output of ‚Ñì‚àí1layer is the input of ‚Ñìlayer. The mapping from the input x[0]of input layer to the output y[L]of output layer stands for the inputoutput relation of the MLP, denoted by y[L]=F(x[0]) (2) whereF(¬∑)/definesfL‚ó¶fL‚àí1‚ó¶¬∑¬∑¬∑‚ó¶f1(¬∑). According to the Universal Approximation Theorem [26], it guarantees that, in principle, such an MLP in the form of (2), namely the function F(¬∑), is able to approximate any nonlinear realvalued function. Despite the impressive ab ility of approximating functions, much complexities represent i n predicting the output behaviors of an MLP. In most of real applications, an MLP is usually viewed as a black box to generate a desirable output with respect to a given input. However, regarding property veriÔ¨Åcations such as safety ve ri Ô¨Åcation, it has been observed that even a welltrained neura l network can react in unexpected and incorrect ways to even slight perturbations of their inputs, which could result in unsafe systems. Thus, the output reachable set estimation o f an MLP, which is able to cover all possible values of outputs,is necessary for the safety veriÔ¨Åcation of an MLP and draw a safe or unsafe conclusion for an MLP. B. Problem Formulation Given an input set X, the output reachable set of neural network (2) is stated by the following deÔ¨Ånition. DeÔ¨Ånition 1: Given an MLP in the form of (2) and an input setX, the output reachable set of (2) is deÔ¨Åned as Y/defines{y[L]|y[L]=F(x[0]),x[0]‚ààX}. (3) Since MLPs are often large, nonlinear, and nonconvex, it is extremely difÔ¨Åcult to compute the exact output reachable setYfor an MLP. Rather than directly computing the exact output reachable set for an MLP, a more practical and feasibl e way is to derive an overapproximation of Y, which is called output reachable set estimation. DeÔ¨Ånition 2: A setÀúYis called an output reachable set estimation of MLP (2), if Y‚äÜÀúYholds, whereYis the output reachable set of MLP (2). Based on DeÔ¨Ånition 2, the problem of output reachable set estimation for an MLP is given as below. Problem 1: Given a bounded input set Xand an MLP described by (2), how to Ô¨Ånd a set ÀúYsuch thatY‚äÜÀúY, and make the estimation set ÀúYas small as possible1? In this work, we will focus on the safety veriÔ¨Åcation for neural networks. The safety speciÔ¨Åcation for outputs is expressed by a set deÔ¨Åned in the output space, describing the safety requirement. DeÔ¨Ånition 3: Safety speciÔ¨Åcation Sof an MLP formalizes the safety requirements for output y[L]of MLP y[L]= F(x[0]), and is a predicate over output y[L]of MLP. The MLP is safe if and only if the following condition is satisÔ¨Åed: Y‚à©¬¨S=‚àÖ (4) where¬¨is the symbol for logical negation. Therefore, the safety veriÔ¨Åcation problem for an MLP is stated as follows. Problem 2: Given a bounded input set X, an MLP in the form of (2) and a safety speciÔ¨Åcation S, how to check if condition (4) is satisÔ¨Åed? Before ending this section, a lemma is presented to show that the safety veriÔ¨Åcation of an MLP can be relaxed by checking with the overapproximation of the output reachab le set. Lemma 1: Consider an MLP in the form of (2), an output reachable set estimation Y‚äÜÀúYand a safety speciÔ¨Åcation S, the MLP is safe if the following condition is satisÔ¨Åed ÀúY‚à©¬¨S=‚àÖ. (5) Proof: SinceY‚äÜÀúY, (5) directly leads to Y‚à©¬¨S=‚àÖ. The proof is complete. Lemma 1 implies that it is sufÔ¨Åcient to use the estimated output reachable set for the safety veriÔ¨Åcation of an MLP, th us the solution of Problem 1 is also the key to solve Problem 2. 1For a set Y, its overapproximation ÀúY1is smaller than another over approximation ÀúY2ifdH(ÀúY1,Y)< dH(ÀúY2,Y)holds, where dHstands for the Hausdorff distance.IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. XX, NO. XX, XX XXXX 3 III. M AXIMUM SENSITIVITY FOR NEURAL NETWORKS Due to the complex structure and nonlinearities in activa tion functions, estimating the output reachable sets of MLP s represents much difÔ¨Åculties if only using analytical metho ds. One possible way to circumvent those difÔ¨Åculties is to emplo y the information produced by a Ô¨Ånite number of simulations. As well known, the Ô¨Ånitely many simulations generated from input setXare incomplete to characterize output set Y, a conception called maximum sensitivity is introduced to bridge the gap between simulations and output reachable set estimations of MLPs. DeÔ¨Ånition 4: Given an MLP y[L]=F(x[0]), an input x[0] and disturbances ‚àÜx[0]satisfying/vextenddouble/vextenddouble‚àÜx[0]/vextenddouble/vextenddouble‚â§Œ¥, the maximum sensitivity of the MLP with input error Œ¥atx[0]is deÔ¨Åned by «´F(x[0],Œ¥)/definesinf{«´:/vextenddouble/vextenddouble/vextenddouble‚àÜy[L]/vextenddouble/vextenddouble/vextenddouble‚â§«´, wherey[L]=F(x[0]) and/vextenddouble/vextenddouble/vextenddouble‚àÜx[0]/vextenddouble/vextenddouble/vextenddouble‚â§Œ¥}(6) Remark 2: In some previous articles as [27], [28], the sensitivity for neural networks is deÔ¨Åned as the mathematic al expectation of output deviations due to input and weight deviations with respect to overall input and weight values in a given continuous interval. The sensitivity in the avera ge point of view works well for learning algorithm improvement [29], weight selection [30], architecture construction [3 1], for instance. However, it cannot be used for safety veriÔ¨Åcation due to the concern of soundness. In this paper, the maximum sensitivity is introduced to measure the maximum deviation of outputs, which is caused by the bounded disturbances around the nominal input x[0]. Due to the multiple layer structure, we are going to develop a layerbylayer method to compute the maximum sensitivity deÔ¨Åned by (6). First, we consider a single layer ‚Ñì. According to DeÔ¨Ånition 4, the maximum sensitivity for layer ‚Ñì, which is denoted by «´(x[‚Ñì],Œ¥[‚Ñì])atx[‚Ñì], can be computed by max«´(x[‚Ñì],Œ¥[‚Ñì]) s.t. «´(x[‚Ñì],Œ¥[‚Ñì]) =/vextenddouble/vextenddouble/vextenddoublef‚Ñì(W[‚Ñì](x[‚Ñì]+‚àÜx[‚Ñì])+Œ∏[‚Ñì])‚àíy[‚Ñì]/vextenddouble/vextenddouble/vextenddouble y[‚Ñì]=f‚Ñì(W[‚Ñì]x[‚Ñì]+Œ∏[‚Ñì])/vextenddouble/vextenddouble/vextenddouble‚àÜx[‚Ñì]/vextenddouble/vextenddouble/vextenddouble‚â§Œ¥[‚Ñì]. (7) In the rest of paper, the norm /bar‚åàbl¬∑/bar‚åàblis considered the inÔ¨Ånity norm, that is/bar‚åàbl¬∑/bar‚åàbl‚àû. By the deÔ¨Ånition of /bar‚åàbl¬∑/bar‚åàbl‚àûand monotonicity assumption in Assumption 1, the optimal solution ‚àÜx[‚Ñì] optof (7) can be found by running the following set of optimization problems. To Ô¨Ånd the optimal solution of (7) for layer ‚Ñì, we start from the neuron iin layer‚Ñì, the following two convex optimizations can be set up maxŒ≤[‚Ñì] i s.t. Œ≤[‚Ñì] i= (œâ[‚Ñì] i)‚ä§(x[‚Ñì]+‚àÜx[‚Ñì])+Œ∏[‚Ñì] /vextenddouble/vextenddouble/vextenddouble‚àÜx[‚Ñì]/vextenddouble/vextenddouble/vextenddouble ‚àû‚â§Œ¥[‚Ñì](8)and minŒ≤[‚Ñì] i s.t. Œ≤[‚Ñì] i= (œâ[‚Ñì] i)‚ä§(x[‚Ñì]+‚àÜx[‚Ñì])+Œ∏[‚Ñì] /vextenddouble/vextenddouble/vextenddouble‚àÜx[‚Ñì]/vextenddouble/vextenddouble/vextenddouble ‚àû‚â§Œ¥[‚Ñì]. (9) Then, due to the monotonicity, the following optimization problem deÔ¨Åned over a Ô¨Ånite set consisting of Œ≤[‚Ñì] i,max and Œ≤[‚Ñì] i,minobtained in (8) and (9) is formulated to compute the maximum absolute value of output of neuron iin layer‚Ñì maxŒ≥[‚Ñì] i s.t. Œ≥[‚Ñì] i=/vextendsingle/vextendsingle/vextendsinglef‚Ñì(Œ≤[‚Ñì] i)‚àíf‚Ñì((œâ[‚Ñì] i)‚ä§(x[‚Ñì])+Œ∏[‚Ñì])/vextendsingle/vextendsingle/vextendsingle Œ≤[‚Ñì] i‚àà{Œ≤[‚Ñì] i,min, Œ≤[‚Ñì] i,max}. (10) Finally, based on the maximum absolute value of the output of neuron iand because of the deÔ¨Ånition of inÔ¨Ånity norm, we are ready to compute the maximum sensitivity of layer ‚Ñìby picking out the largest value of Œ≥[‚Ñì] iin layer‚Ñì, that is max«´(x[‚Ñì],Œ¥[‚Ñì]) s.t. «´(x[‚Ñì],Œ¥[‚Ñì])‚àà{Œ≥[‚Ñì] 1,...,Œ≥[‚Ñì] n[‚Ñì]}. (11) In summary, the maximum sensitivity of a single layer ‚Ñìcan be computed through solving optimizations (8)‚Äì(11) sequentially. Proposition 1: Given a single layer ‚Ñì, the maximum sensi tivity«´(x[‚Ñì],Œ¥[‚Ñì])is the solution of (11) in which Œ≥[‚Ñì] 1,...,Œ≥[‚Ñì] n[‚Ñì] are solutions of (10) with Œ≤[‚Ñì] i,min, Œ≤[‚Ñì] i,maxbeing solutions of (8) and (9). The above optimizations (8)‚Äì(11) provide a way to compute the maximum sensitivity for one layer. Then, for an MLP, we have x[‚Ñì]=y[‚Ñì‚àí1],‚Ñì= 1,...,L , so the output of each layer can be computed by iterating above optimizations with updated input x[‚Ñì]=y[‚Ñì‚àí1],Œ¥[‚Ñì]=«´(x[‚Ñì‚àí1],Œ¥[‚Ñì‚àí1]), ‚Ñì= 1,...,L . The maximum sensitivity of neural network y[L]=F(x[0])is the outcome of optimization (11) for output layerL, namely, «´F(x[0],Œ¥) =«´(x[L],Œ¥[L]). The layerbylayer idea is illustrated in Fig. 1, which shows the general idea of the computation process for multiple layer neural networks . In conclusion, the computation for the maximal sensitivity of an MLP is converted to a chain of optimization problems. Furthermore, the optimization problems (8), (9) are convex optimization problems which can be efÔ¨Åciently solved by existing tools such as cvx,linprog in Matlab. To be more efÔ¨Åcient in computation without evaluating the object ive function repeatedly, we can even pregenerate the expressi on of optimal solutions given the weight and bias of the neural network. Optimizations (10), (11) only have Ô¨Ånite elements to search for the optimum, which can be also computed efÔ¨Å ciently. The algorithm for computing the maximum sensitivi ty of an MLP is given in Algorithm 1. IV. R EACHABLE SETESTIMATION AND VERIFICATION In previous section, the maximum sensitivity for an MLP can be computed via a chain of optimizations. The computa tion result actually can be viewed as a reachtube for the inputsIEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. XX, NO. XX, XX XXXX 4    Œ¥        Œ¥ Œµ Œ¥ = =             Œ¥ Œµ Œ¥ = =    	  	       Œ¥ Œµ Œ¥ = =       	                     Œ¥ Œµ Œ¥ ‚àí ‚àí ‚àí = =        Fig. 1. Illustration for computing maximum sensitivity for an MLP. Algorithm 1 Maximum Sensitivity Computation Function for MLP Require: MLPF, inputx[0]and disturbance error Œ¥. Ensure: Maximum Sensitivity «´F(x[0],Œ¥). 1:function MAXSENSITIVITY (F,x[0],Œ¥) 2:x[1]‚Üêx[0];Œ¥[1]‚ÜêŒ¥ 3: for‚Ñì= 1 : 1 :L‚àí1do 4: Solve (8), (9) to obtain Œ≤[‚Ñì] i,min,Œ≤[‚Ñì] i,max 5: WithŒ≤[‚Ñì] i,min,Œ≤[‚Ñì] i,max, solve (10) to obtain Œ≥[‚Ñì] i 6: WithŒ≥[‚Ñì] i, solve (11) to obtain «´(x[‚Ñì],Œ¥[‚Ñì]) 7: x[‚Ñì+1]‚Üêf‚Ñì(W[‚Ñì]x[‚Ñì]+Œ∏[‚Ñì]);Œ¥[‚Ñì+1]‚Üê«´(x[‚Ñì],Œ¥[‚Ñì]) 8: end for 9: Withx[L],Œ¥[L], solve (8)‚Äì(11) to obtain «´(x[L],Œ¥[L]) 10:«´F(x[0],Œ¥)‚Üê«´(x[L],Œ¥[L]) 11: return«´F(x[0],Œ¥) 12:end function around nominal input x[0], that are the inputs bounded in the tube/vextenddouble/vextenddouble‚àÜx[0]/vextenddouble/vextenddouble ‚àû‚â§Œ¥. This allows us to relate the individual simulation outputs to the output reachable set of an MLP. First, the input space is discretized into lattices, which a re described by Li/defines{x[0]|/vextenddouble/vextenddouble/vextenddoublex[0]‚àíx[0] i/vextenddouble/vextenddouble/vextenddouble ‚àû‚â§Œ¥} (12) wherex[0] iandŒ¥are called the center and the radius of Li, respectively. The sets LisatisfyLi‚à©Lj={x[0]| /vextenddouble/vextenddouble/vextenddoublex[0]‚àíx[0] i/vextenddouble/vextenddouble/vextenddouble ‚àû=Œ¥‚àß/vextenddouble/vextenddouble/vextenddoublex[0]‚àíx[0] j/vextenddouble/vextenddouble/vextenddouble ‚àû=Œ¥}and/uniontext‚àû i=1Li= Rn√ón. Obviously, for any bounded set X, we can Ô¨Ånd a Ô¨Ånite number ofLisuch thatLi/intersectiontextX/n‚åâ}ationslash=‚àÖ. The index set for all Li satisfyingLi‚à©X/n‚åâ}ationslash=‚àÖis denoted byI, so it can be obtained thatX‚äÜ/uniontext i‚ààILi. Explicitly, the lattices with a smaller radius Œ¥are able to achieve a preciser approximation of bounded set Xand, moreover,/uniontext i‚ààILiwill exactly beXif radiusŒ¥‚Üí0. The number of lattices is closely related to the dimension ofthe input space and radius chosen for discretization. Takin g a unit box{x‚ààRn|/bar‚åàblx/bar‚åàbl‚â§1}for example, the number of lattices with radius Œ¥is‚åà1/2Œ¥‚åân. The Ô¨Årst step is to derive all the lattices Li,i‚ààI for the input setXsuch thatLi‚à©X/n‚åâ}ationslash=‚àÖ,‚àÄi‚ààI. Then, based on the maximum sensitivity computation result, the output reacht ube for each latticeLican be obtained by using Algorithm 1. SinceX ‚äÜ/uniontext i‚ààILi, the union of output reachtubes of Li, i‚ààIincludes all the possible outputs generated by the neural network with input set X. The following proposition is the main result in this work. Proposition 2: Given an MLP y[L]=F(x[0]), input setX and latticesLi,i‚ààI with centers x[0] iand radius Œ¥, and all the lattices satisfy Li‚à©X/n‚åâ}ationslash=‚àÖ,‚àÄi‚ààI, the output reachable setYsatisÔ¨ÅesY‚äÜÀúY/defines/uniontext i‚ààIÀúYi, where ÀúYi/defines{y[L]|/vextenddouble/vextenddouble/vextenddoubley[L]‚àíy[L] i/vextenddouble/vextenddouble/vextenddouble ‚àû‚â§«´F(x[0] i,Œ¥),y[L] i=F(x[0] i)} (13) where«´F(x[0] i,Œ¥)is computed by Algorithm 1. Proof: Using Algorithm 1 for inputs within lattice Li,ÀúYi is the reachtube for Livia the given MLP. Thus, the union ofÀúYi, that is/uniontext i‚ààIÀúYi, is the output reachable set of/uniontext i‚ààILi. Moreover, due to X ‚äÜ/uniontext i‚ààILi, it directly implies that the output reachable set of Xis a subset of/uniontext i‚ààIÀúYi, that isY‚äÜ ÀúY/defines/uniontext i‚ààIÀúYi. The proof is complete. Based on Proposition 2, the output reachable set estimation involves the following two key steps: (1) Execute a Ô¨Ånite number of simulations for MLP to get individual outputs y[L] iwith respect to individual inputsx[0] i. This can be done by simply generating the outputs with a Ô¨Ånite number of inputs through the MLP asy[L] i=F(x[0] i). That is the main reason that our approach is called simulationbased. (2) Compute the maximum sensitivity for a Ô¨Ånite number of lattices centered at x[0] i, which can be solved by the MaxSensitivity function proposed in Algorithm 1. This step is to produce the reachtubes based on the simulation results, and combine them for the reachable set estimation of outputs. The complete algorithm to perform the output reachable set estimation for an MLP is summarized in Algorithm 2, and Example 1 is provided to validate our approach. Algorithm 2 Output Reachable Set Estimation for MLP Require: MLFF, input setX. Ensure: Estimated output set ÀúY. 1:function OUTPUT REACH (F,X) 2: InitializeLi,i‚ààI,x[0] i,Œ¥;ÀúY‚Üê‚àÖ 3: for‚Ñì= 1 : 1 :|I|do 4: y[L] i‚ÜêF(x[0] i) 5: «´F(x[0] i,Œ¥)‚ÜêMAXSENSITIVITY (F,x[0] i,Œ¥) 6: ÀúYi‚Üê{y[L]|/vextenddouble/vextenddouble/vextenddoubley[L]‚àíy[L] i/vextenddouble/vextenddouble/vextenddouble ‚àû‚â§«´F(x[0] i,Œ¥)} 7: ÀúY‚ÜêÀúY‚à™ÀúYi 8: end for 9: returnÀúY 10:end functionIEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. XX, NO. XX, XX XXXX 5      Fig. 2. Input sets X1and25lattices with radius of Œ¥= 0.1. Example 1: A neural network with 2 inputs, 2 outputs and 1 hidden layer consisting of 5 neurons is considered. The activation function for the hidden layer is choosen as tanh function and purelin function is for the output layer. The weight matrices and bias vectors are randomly generated as below: W[1]=Ô£Æ Ô£ØÔ£ØÔ£ØÔ£ØÔ£∞‚àí0.9507‚àí0.7680 0.9707 0 .0270 ‚àí0.6876‚àí0.0626 0.4301 0 .1724 0.7408‚àí0.7948Ô£π Ô£∫Ô£∫Ô£∫Ô£∫Ô£ª,Œ∏[1]=Ô£Æ Ô£ØÔ£ØÔ£ØÔ£ØÔ£∞1.1836 ‚àí0.9087 ‚àí0.3463 0.2626 ‚àí0.6768Ô£π Ô£∫Ô£∫Ô£∫Ô£∫Ô£ª W[2]=/bracketleftbigg 0.8280 0.6839 1.0645‚àí0.0302 1 .7372 1.4436 0.0824 0.8721 0 .1490‚àí1.9154/bracketrightbigg Œ∏[2]=/bracketleftbigg ‚àí1.4048 ‚àí0.4827/bracketrightbigg . The input set is considered as X1={[x1x2]‚ä§| |x1‚àí0.5| ‚â§0.5‚àß|x2‚àí0.5| ‚â§0.5}. In order to execute functionOutputReach described in Algorithm 2, the Ô¨Årst step is to initialize the lattices Liwith centers x[0] iand radius Œ¥. In this example, the radius is chosen to be 0.1and25lattices are generated as in Fig. 2 shown in gray, which means there are in total25simulations to be executed for the output reachable set estimation. Executing function OutputReach forX1, the estimated output reachable set is given in Fig. 3, in which 25 reachtube s are obtained and the union of them is an overapproximation o f reachable setY. To validate the result, 10000 random outputs are generated, it is clear to see that all the outputs are incl uded in the estimated reachable set, showing the effectiveness o f the proposed approach. Moreover, we choose different radius for discretizing stat e space to show how the choice of radius affects the estima tion outcome. As mentioned before, a smaller radius implies a tighter approximation of input sets and is supposed to achieve a preciser estimation. Here, we select the radius as Œ¥‚àà{0.1,0.05,0.025,0.0125}. With Ô¨Åner discretizations, more simulations are required for running function OutputReach , but tighter estimations for the output reachable set can be obtained. The output reachable set estimations are shown in Fig. 4. Comparing those results, it can be observed that a smaller radius can lead to a better estimation result at the Fig. 3. Output reachable set estimation with input set X1andŒ¥= 0.1. 25 reachtubes are computed and 10000 random outputs are all included in the estimated reachable set. Fig. 4. Output reachable set estimations with input set X1andŒ¥= 0.1(blue),0.05(green) ,0.025(yellow) ,0.0125(cyan) . Tighter estimations are obtained with smaller radius. TABLE I COMPARISON OF OUTPUT REACHABLE SET ESTIMATIONS WITH DIFFERENT RADIUS Radius 0.1 0 .05 0 .025 0 .0125 Computation time 0.044 s0.053 s0.086 s0.251 s Simulations 25 100 400 1600 expense of more simulations and computation time, as shown in Table I. Algorithm 2 is sufÔ¨Åcient to solve the output reachable set estimation problem for an MLP, that is Problem 1. Then, we can move forward to Problem 2, the safety veriÔ¨Åcation problem for an MLP with a given safety speciÔ¨Åcation S. Proposition 3: Consider an MLP in the form of (2), an output reachable set estimation and a safety speciÔ¨Åcation S, the MLP is safe if ÀúY‚à©¬¨S =‚àÖ, where ÀúYis the estimated output reachable set obtained by Algorithm 2. Proof: By Algorithm 2, we have Y‚äÜÀúY, whereYis theIEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. XX, NO. XX, XX XXXX 6 actual output reachable set of the MLP. Using Lemma 1, the safety can be guaranteed. The proof is complete. The simulationbased safety veriÔ¨Åcation algorithm is pre sented in Algorithm 3. Algorithm 3 Safety VeriÔ¨Åcation for MLP Require: MLPF, input setX, safety requirement S. Ensure: Safe or unsafe property. 1:function SAFETY VERI(F,X,S) 2: InitializeLi,i‚ààI,x[0] i,Œ¥ 3: for‚Ñì= 1 : 1 :|I|do 4: y[L] i‚ÜêF(x[0] i) 5: ify[L] i‚à©¬¨S/n‚åâ}ationslash=‚àÖandx[0] i‚ààX then 6: return UNSAFE 7: end if 8: end for 9:ÀúY‚Üê OUTPUT REACH (F,X) 10: ifÀúY‚à©¬¨S=‚àÖthen 11: return SAFE 12: else 13: return UNCERTAIN 14: end if 15:end function Remark 3: The Algorithm 3 is sound for the cases of SAFE and UNSAFE, that is, if it returns SAFE then the system is safe; when it returns UNSAFE there exists at least one output from input set is unsafe since the existence of one simulatio n that is unsafe is sufÔ¨Åcient to claim unsafeness. Additional ly, if it returns UNCERTAIN, caused by the fact ÀúY‚à©¬¨S/n‚åâ}ationslash=‚àÖ, that means the safety property is unclear for this case. Example 2: The same MLP as in Example 1 is considered, and the input set is considered to be X2={[x1x2]‚ä§| |x1‚àí0.5|‚â§1.5‚àß|x2‚àí0.5|‚â§0.1}. Furthermore, the safe speciÔ¨ÅcationSis assumed asS={[x1x2]‚ä§|‚àí3.7‚â§x1‚â§ ‚àí1.5}. To do safety veriÔ¨Åcation, the Ô¨Årst step of using function SafetyVeri in Algorithm 3 is to initialize the lattices Li with two radius Œ¥1= 0.1andŒ¥2= 0.05. Since two radius are used, the veriÔ¨Åcation results could be different due to diff erent precisions selected. The veriÔ¨Åcation results are shown in F igs. 5 and 6, and compared in Table II. TABLE II COMPARISON OF SAFETY VERIFICATIONS WITH DIFFERENT RADIUS Radius Œ¥1= 0.1Œ¥2= 0.05 Safety UNCERTAIN SAFE Simulations 15 60 The safety property is uncertain when the radius is chosen as0.1. However, we can conclude the safeness of the MLP when a smaller radius Œ¥= 0.05is chosen at the expense of increasing the number of simulations from 15to60. V. A PPLICATION IN SAFETY VERIFICATION FOR ROBOTIC ARMMODELS In this section, our study focuses on learning forward kinematics of a robotic arm model with two joints, see Fig. 7. The learning task of the MLP is to predict the position‚àí4‚àí3.7‚àí3.5 ‚àí3 ‚àí2.5 ‚àí2 ‚àí1.5 ‚àí1‚àí4‚àí3‚àí2‚àí101234 y1y2Safe Region UncertainUncertain Fig. 5. Safety veriÔ¨Åcation for input belonging to X2. With radius Œ¥= 0.1, the MLP cannot be concluded to be safe or not, since there exis t intersections between the estimated reachable set and the unsafe region. ‚àí4‚àí3.7‚àí3.5 ‚àí3 ‚àí2.5 ‚àí2 ‚àí1.5 ‚àí1‚àí4‚àí3‚àí2‚àí101234 y1y2Safe Region Fig. 6. Safety veriÔ¨Åcation for input belonging to X2. WithŒ¥= 0.05, the safety can be conÔ¨Årmed, since the estimated reachable set is in the safe region. (x,y)of the end with knowing the joint angles (Œ∏1,Œ∏2). For the robotic arm, the input space [0,2œÄ]√ó[0,2œÄ]for(Œ∏1,Œ∏2) is classiÔ¨Åed into three zones for its operations: (1)Normal working zone: The normal working zone is the working region that the robotic arm works most of the time in, and the inputoutput training data is all collected from this region to train the MLP model. This zone is assumed to be Œ∏1,Œ∏2‚àà[5œÄ 12,7œÄ 12]. (2)Forbidden zone: The forbidden zone speciÔ¨Åes the region that the robotic arm will never operate in due to physical constraints or safety considerations in design. This zone is assumed as Œ∏1,Œ∏2‚àà[0,œÄ 3]‚à™[2œÄ 3,2œÄ]. (3)Buffering zone: The buffering zone is between the nor mal working zone and the forbidden zone. Some occa sional operations may occur out of normal working zone, but it remains in the buffering zone, not reaching theIEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. XX, NO. XX, XX XXXX 7 Œ∏Œ∏  ==      Fig. 7. Robotic arm with two joints. The normal working zone o f(Œ∏1,Œ∏2) is colored in green and the buffering zone is in yellow. forbidden zone. This zone is Œ∏1,Œ∏2‚àà[œÄ 3,5œÄ 12]‚à™[7œÄ 12,2œÄ 3]. The safety speciÔ¨Åcation for the position (x,y)is considered asS={(x,y)| ‚àí14‚â§x‚â§3‚àß1‚â§y‚â§17}. In the safety point of view, the MLP needs to be veriÔ¨Åed that all the outputs produced by the inputs in the normal working zone and buffering zone will satisfy safety speciÔ¨Åcation S. One point needs to emphasize is that the MLP is trained by the data in normal working zone, but the safety speciÔ¨Åcation is deÔ¨Åned on both normal working zone and buffering zone. Using the data from normal working zone, the learning process is standard by using train function in the neural network toolbox in Matlab. The MLP considered for this example is with 2 inputs, 2 outputs and 1 hidden layer consisting of 5 neurons. The activation functions tanh and purelin are for hidden layer and output layer, respectively. However, for the trained MLP, there is no safety assurance for any manipulations, especially for the ones in the buffer ing zone where no inputoutput data is used to train the MLP. To verify the safety speciÔ¨Åcation of the trained MLP, our functionSafetyVeri presented in Algorithm 3 is used for this example. First, we train the MLP with inputs (Œ∏1,Œ∏2)‚àà[5œÄ 12,7œÄ 12]√ó [5œÄ 12,7œÄ 12]along with their corresponding outputs. Then, to use function SafetyVeri for the inputs in both normal working zone and buffering zone, we discretize input space [œÄ 3,2œÄ 3]√ó[œÄ 3,2œÄ 3]with radius Œ¥= 0.05. The safety veriÔ¨Åcation result is shown in Fig. 8. It can be observed that the safety property of the MLP is uncertain since the estimated reachab le set reaches out of the safe region S. Then, 5000 random simulations are executed, and it shows that no output is unsa fe. However, 5000 simulations or any Ô¨Ånite number of simulation s are not sufÔ¨Åcient to say the MLP is safe. Therefore, to soundl y claim that the MLP trained with the data collected in normal working zone is safe with regard to both normal working and buffering zones, a smaller radius Œ¥= 0.02has to be adopted. The veriÔ¨Åcation result with Œ¥= 0.02is shown in Fig. 9. It can be seen that the reachable set of the MLP is contained in the safe region, which is sufÔ¨Åcient to claim the safety of the robotic arm MLP model. VI. R ELATED WORK "
171,Double Retrieval and Ranking for Accurate Question Answering.txt,"Recent work has shown that an answer verification step introduced in
Transformer-based answer selection models can significantly improve the state
of the art in Question Answering. This step is performed by aggregating the
embeddings of top $k$ answer candidates to support the verification of a target
answer. Although the approach is intuitive and sound still shows two
limitations: (i) the supporting candidates are ranked only according to the
relevancy with the question and not with the answer, and (ii) the support
provided by the other answer candidates is suboptimal as these are retrieved
independently of the target answer. In this paper, we address both drawbacks by
proposing (i) a double reranking model, which, for each target answer, selects
the best support; and (ii) a second neural retrieval stage designed to encode
question and answer pair as the query, which finds more specific verification
information. The results on three well-known datasets for AS2 show consistent
and significant improvement of the state of the art.","In recent years, automated Question Answering (QA) research has received a renewed attention thanks to the diffusion of Virtual Assistants. For example, Google Home, Siri and Alexa provide general information inquiry services, while many other systems serve customer requests in different application domains. QA is enabled by two main tasks: (i) Answer Sentence Selection (AS2), which, given a question and a set of answersentence can didates, consists in selecting sentences (e.g., re trieved by a search engine) that correctly answer the question; and (ii) Machine Reading (MR), e.g., (Chen et al., 2017), which, given a question and a reference text, Ô¨Ånds an exact text span that an swers the question. Deploying MR systems in Work done while the author was an intern at Amazon Alexa AI.q:What causes heart disease? c1:Cardiovascular disease (also called heart disease) is a class of diseases that involve the heart or blood vessels (arteries, capillaries, and veins). c2:The causes of cardiovascular disease are diverse but atherosclerosis and/or hypertension are the most com mon. c3:Cardiovascular disease refers to any disease that affects the cardiovascular system , principally cardiac disease, vascular diseases of the brain and kidney , and peripheral arterial disease. Table 1: A question with answer candidates. production is challenging for efÔ¨Åciency reasons, while AS2 models can efÔ¨Åciently target large text databases. Indeed, they originated from TREC QA tracks (V oorhees and Tice, 1999), which dealt with realworld retrieval systems since the Ô¨Årst edi tion. Another limitation of MR is the focus on factoid answers: although it can in principle pro vide longer answers, the datasets developed for the task mainly contains short answers and in particu lar named entities. In contrast, as AS2 processes entire sentences, its inference steps always involve sentences/paragraphs, which make the approach agnostic to both factoid and not factoid classes. Garg et al. (2020) proposed the T AND A ap proach based on pretrained Transformer models, obtaining impressive improvement over the state of the art for AS2, measured on the two most used datasets, WikiQA (Yang et al., 2015) and TREC QA (Wang et al., 2007). The approach above, based on pointwise rerankers, was signiÔ¨Åcantly improved by the Answer Supportbased Reranker (ASR) (Zhang et al., 2021), which adds an answer veriÔ¨Åcation step similar to the one operated by fact checking systems, e.g., see the FEVER challenge (Thorne et al., 2018). More speciÔ¨Åcally, given a question q, and a tar get answer to be veriÔ¨Åed, t, taken from a set of answer candidates Ck=fc1;::;c kg, ASR concate nates transformerbased embeddings of ( q;ci) with the maxpooling vector produced by the top kem 1arXiv:2201.05981v1  [cs.CL]  16 Jan 2022beddings of ( t;ci), where the ciare selected by an initial answer reranking model (e.g., TANDA). For example, Table 1 reports a question, q=What causes heart disease? , with some candidate an swers,c1,c2, andc3. Selecting the correct answer c2is difÔ¨Åcult, without the information: cardiovas cular disease is also called heart disease . Interest ingly, this information is provided by c1. Thus, to compute the probability of correctness of c1, they exploit the representation of c2, similarly to the way claims are supported in the fact veriÔ¨Åcation. ASR reduced the error of T AND A by 10% (rel ative), both on WikiQA and TRECQA datasets. However, it shows two important limitations: Ô¨Årst, when attempting the veriÔ¨Åcation step of t, thek candidates used in the maxpoling operation are ranked only considering the question, i.e., inde pendently of t. Second, the support for each tis provided by other answer candidates, which again were retrieved independently of the need of acquir ing information for verifying t. In this paper, we provide new answer veriÔ¨Åca tion models, which are more efÔ¨Åcient and accu rate than ASR. We introduce a new architecture, Double Answer Reranking (DAR), which uses two reranking models both for target answers and sup porting candidates. To verify t, the Ô¨Årst, support answer reranker (SR), sorts (q;t;c i)for Ô¨Ånding the best support st, while the second, answer reranker (AR), orders (q;t;s t)triplets, providing the rank of all target answers t. Additionally, we improve the veriÔ¨Åcation step, introducing a second retrieval stage, which searches for passage relevant to (q;t). This is im portant as the information relevant to only qun luckily provides useful context for assessing t. As building an effective query for a pair of text can be challenging, we exploit deep passage retrieval (DPR) (Karpukhin et al., 2020) encoding (q;t)as the target query. As our DAR is efÔ¨Åcient, it can process many candidates retrieved by DPR, making Double Retrieval (DR) effective. The results derived on three wellknown AS2 datasets, WikiQA (Yang et al., 2015), TREC (Wang et al., 2007), and SelQA (Jurczyk et al., 2016) show consistent and signiÔ¨Åcant improvement over the state of the art. For example, DCR im proves TANDA by 13.6% (relative error reduction), achieving the same accuracy of the computational expensive ASR veriÔ¨Åcation approach (84.36%). Additionally, DARDR improves the absolute stateof the art, reducing the error by an additional 8%. We will release the datasets augmented with DPR retrieval (support candidates) for each (q;a) of each of the datasets above. 2 Related work "
125,Performance Evaluation of Low-Cost Machine Vision Cameras for Image-Based Grasp Verification.txt,"Grasp verification is advantageous for autonomous manipulation robots as they
provide the feedback required for higher level planning components about
successful task completion. However, a major obstacle in doing grasp
verification is sensor selection. In this paper, we propose a vision based
grasp verification system using machine vision cameras, with the verification
problem formulated as an image classification task. Machine vision cameras
consist of a camera and a processing unit capable of on-board deep learning
inference. The inference in these low-power hardware are done near the data
source, reducing the robot's dependence on a centralized server, leading to
reduced latency, and improved reliability. Machine vision cameras provide the
deep learning inference capabilities using different neural accelerators.
Although, it is not clear from the documentation of these cameras what is the
effect of these neural accelerators on performance metrics such as latency and
throughput. To systematically benchmark these machine vision cameras, we
propose a parameterized model generator that generates end to end models of
Convolutional Neural Networks(CNN). Using these generated models we benchmark
latency and throughput of two machine vision cameras, JeVois A33 and Sipeed
Maix Bit. Our experiments demonstrate that the selected machine vision camera
and the deep learning models can robustly verify grasp with 97% per frame
accuracy.","Grasp veriÔ¨Åcation is a necessitate for autonomous robots to determine the state of the grasp while performing object manipulation. Normally robots need to perform a series of operations that depend on each other. If a task is not done correctly then the robot should rebuild the operation sequence based on the occurred failure. So the robot needs to verify its action to update its knowledge about the current state. Grasp veriÔ¨Åcation in robots, generally, are done using sensor‚Äôs in the gripper but this becomes challenging in the new Ô¨Çexible grippers. For example, in the KUKA youBot(see Ô¨Åg 1) we have added a parallel adaptive gripper Ô¨Ångers by Festo. The adaptive nature of the gripper Ô¨Ånger makes it difÔ¨Åcult for placing traditional sensors and to robustly determine the state of the grasp. In this paper, we propose a machine vision camera sensor based grasp veriÔ¨Åcation that works by capturing images of the gripper and verifying if the grasp is successful using deep learning inference. A machine vision camera consists of an image sensor, a processor and a neural processing unit, this makes it possible to perform edge computing on the captured image. Performing inference near the data source reduces the load 1Deebul Nair, Amirhossein Pakdaman and Prof. Dr. Paul G. Pl¬®oger are with the Dept. of Computer Science, BonnRheinSieg University of Applied Sciences, Germany. deebul.nair@hbrs.de, amirhossein.pakdaman@smail.inf.hbrs.de, paul.ploeger@hbrs.de Fig. 1: youBot gripper with machine vision camera JeV ois A33 along with the camera view. to transfer and process images on the centralized server. This helps in reducing the latency in processing the data and improves reliability of the overall system. Recently, deep neural networks had great improvements in solving image classiÔ¨Åcation problems. This was achieved by the advent of convolutional neural networks (CNNs). Successful CNN approaches are able to solve image classiÔ¨Åcation problems with an accuracy near to human [1]. However, CNNs need considerable resources of computation and memory. The idea of executing a deep learning algorithm into an embedded device has been discussed widely and solutions such as compression are provided [2], [3]. In this paper, we formu late the grasp veriÔ¨Åcation problem as deep learning based image classiÔ¨Åcation task. However, the two main challenges with performing deep learning inference in machine vision cameras are (i) lack of literature on the performance of these cameras and (ii) establishing a deep learning architecture that is capable to fulÔ¨Åll the visual classiÔ¨Åcation task with satis fying accuracy reckoning the limitations of the embedded device. In this paper, we benchmark the performance of machine vision cameras by creating a parameterized model gener ator which generates CNN models of varying parameters, executing them and recording performance metrics. Based on the hardwaresoftware limitation of the machine visionarXiv:2003.10167v1  [cs.RO]  23 Mar 2020cameras, the benchmarking results and the grasp veriÔ¨Åcation task we select corresponding deep learning models. Finally all the grasp veriÔ¨Åcation system is integrated which includes dataset collection, training and deployment of machine vision camera compatible deep learning models. To summarize, the main contributions of the paper are the performance eval uation of lowcost machine vision cameras and integration of machine vision camera with a real world robot for grasp veriÔ¨Åcation tasks. We hope that the performance evaluation will drive the robotic community to apply machine vision cameras in other robotics applications. II. RELATED WORK "
401,Verified Probabilistic Policies for Deep Reinforcement Learning.txt,"Deep reinforcement learning is an increasingly popular technique for
synthesising policies to control an agent's interaction with its environment.
There is also growing interest in formally verifying that such policies are
correct and execute safely. Progress has been made in this area by building on
existing work for verification of deep neural networks and of continuous-state
dynamical systems. In this paper, we tackle the problem of verifying
probabilistic policies for deep reinforcement learning, which are used to, for
example, tackle adversarial environments, break symmetries and manage
trade-offs. We propose an abstraction approach, based on interval Markov
decision processes, that yields probabilistic guarantees on a policy's
execution, and present techniques to build and solve these models using
abstract interpretation, mixed-integer linear programming, entropy-based
refinement and probabilistic model checking. We implement our approach and
illustrate its effectiveness on a selection of reinforcement learning
benchmarks.","Reinforcement learning (RL) is a technique for training a policy used to govern the interaction between an agent and an environment. It is based on repeated explorations of the environment, which yield rewards that the agent should aim to maximise. Deep reinforcement learning combines RL and deep learning, by using neural networks to store a representation of a learnt reward function or optimal policy. These methods have been increasingly successful across a wide range of challenging application domains, including for example, autonomous driving [30], robotics [19] and healthcare [49]. In safety critical domains, it is particularly important to assure that policies learnt via RL will be executed safely, which makes the application of formal verication to this problem appealing. This is challenging, especially for deep RL, since it requires reasoning about multidimensional, continuous state spaces and complex policies encoded as deep neural networks. There are several approaches to assuring safety in reinforcement learning, often leveraging ideas from formal verication, such as the use of temporal logic to specify safety conditions, or the use of abstract interpretation to build dis cretised models. One approach is shielding (e.g., [1]), which synthesises override mechanisms to prevent the RL agent from acting upon bad decisions; another isarXiv:2201.03698v2  [cs.AI]  1 Jun 2022constrained orsafe RL (e.g. [17]), which generates provably safe policies, typi cally by restricting the training process to safe explorations. An alternative approach, which we take in this paper, is to verify an RL policy's correctness after it has been learnt, rather than placing restrictions on the learning process or on its deployment. Progress has been made in the formal verication of policies for RL [6] and also for the specic case of deep RL [28,3,4], in the latter case by building on advances in abstraction and verication tech niques for neural networks; [3] also exploits the development of ecient abstract domains such as template polyhedra [42], previously applied to the verication of continuousspace and hybrid systems [7,16]. A useful tool in reinforcement learning is the notion of a probabilistic pol icy(orstochastic policy ), which chooses randomly between available actions in each state, according to a probability distribution specied by the policy. This brings a number of advantages (similarly to mixed strategies [39] in game the ory and contextual bandits [34]), such as balancing the explorationexploitation tradeo [18], dealing with partial observability of the environment [40], handling multiple objectives [47] or learning continuous actions [38]. In this paper, we tackle the problem of verifying the safety of probabilistic policies for deep reinforcement learning. We dene a formal model of their exe cution using (continuousstate, nitebranching) discretetime Markov processes . We then build and solve sound abstractions of these models. This approach was also taken in earlier work [4], which used Markov decision process abstractions to verify deep RL policies in which actions may exhibit failures. However, a particular challenge for probabilistic policies, as generated by deep RL, is that policies tend to specify very dierent action distributions across states. We thus propose a novel abstraction based on interval Markov decision processes (IMDPs), in which transitions are labelled with intervals of probabil ities, representing the range of possible events that can occur. We solve these IMDPs, over a nite time horizon, which we show yields probabilistic guarantees , in the form of upper bounds on the actual probability of the RL policy leading the agent to a state designated to be unsafe. We present methods to construct IMDP abstractions using template poly hedra as an abstract domain, and mixedinteger linear programming (MILP) to reason symbolically about the neural network policy encoding and a model of the RL agent's environment. We extend existing MILPbased methods for neu ral networks to cope with the softmax encoding used for probabilistic policies. Naive approaches to constructing these IMDPs yield abstractions that are too coarse, i.e., where the probability intervals are too wide and the resulting safety probability bounds are too high be useful. So, we present an iterative rene ment approach based on sampling which splits abstract states via crossentropy minimisation based on the uncertainty of the overapproximation. We implement our techniques, building on an extension of the probabilistic model checker PRISM [32] to solve IMDPs. We show that our approach suc cessfully veries probabilistic policies trained for several reinforcement learning benchmarks and explore tradeos in precision and computational eciency. 2Related work. As discussed above, other approaches to assuring safety in re "
59,Experimental Analysis of Legendre Decomposition in Machine Learning.txt,"In this technical report, we analyze Legendre decomposition for non-negative
tensor in theory and application. In theory, the properties of dual parameters
and dually flat manifold in Legendre decomposition are reviewed, and the
process of tensor projection and parameter updating is analyzed. In
application, a series of verification experiments and clustering experiments
with parameters on submanifold were carried out, hoping to find an effective
lower dimensional representation of the input tensor. The experimental results
show that the parameters on submanifold have no ability to be directly used as
low-rank representations. Combined with analysis, we connect Legendre
decomposition with neural networks and low-rank representation applications,
and put forward some promising prospects.","Matrix and tensor decomposition is the multiplication of a n umber of smaller matrices or tensors that are approximately disassembled by matrix and tensor. Up to now, the main matrix decomposition techniques have been widely used in computer vision, recommendation system, signal processin g and other Ô¨Åelds. Currently, standard methods for third order nonnegative tensor decomposition include CP decomp osition[ 1] and Tucker decomposition[ 2]. It‚Äôs well known the normal nonnegative Tucker and CP tensor decomposition include nonconvex optimization and that the global convergence is not guaranteed. One directio n is to apply additional assumptions on data, such as a bounded variance, to transform the nonconvex optimizatio n problem into a convex one[ 3,4]. Legendre decomposition[ 5] is a new nonnegative tensor decomposition method propose d by Mahito Sugiyama et al. Compared with the existing nonnegative tensor decompo sition methods, the greatest contribution of Legendre decomposition lies in the transformation of the nonconvex optimization problem onto a convex submanifold space without additional assumptions, which ensures global conv ergence, and the use of gradient descent can Ô¨Ånd a unique reconstructed tensor satisfying and the minimum Kullback Leibler (KL) divergence from the input matrix. In this paper, we analyze Legendre tensor decomposition in b oth theory and application. From the perspective of theory, we aim to analyze the properties of dual parameters a nd dually Ô¨Çat manifold introduced in Legendre tensor decomposition. From the perspective of application, we aim to verify the ability of parameters on submanifold to ‚àóCorresponding authorAPREPRINT  SEPTEMBER 22, 2020 represent the semantics of the input tensor and discuss whet her there is a connection between Legendre decomposition technique and classical neural network structures and low rank representations. 2 Related Work "
202,AMSS-Net: Audio Manipulation on User-Specified Sources with Textual Queries.txt,"This paper proposes a neural network that performs audio transformations to
user-specified sources (e.g., vocals) of a given audio track according to a
given description while preserving other sources not mentioned in the
description. Audio Manipulation on a Specific Source (AMSS) is challenging
because a sound object (i.e., a waveform sample or frequency bin) is
`transparent'; it usually carries information from multiple sources, in
contrast to a pixel in an image. To address this challenging problem, we
propose AMSS-Net, which extracts latent sources and selectively manipulates
them while preserving irrelevant sources. We also propose an evaluation
benchmark for several AMSS tasks, and we show that AMSS-Net outperforms
baselines on several AMSS tasks via objective metrics and empirical
verification.","In recent days, social media applications have attracted many users to create, edit, and share their audio, audiovisual, or other types of multimedia content. However, it is usually hard for nonexperts to manipulate them, especially when they want to edit only the desired objects. For image manipulation, fortunately, recently proposed methods such as image inpainting [ 36], style transfer [ 38], and text guided image manipulation [ 10,12] enables nonexpert users to edit the desired objects while leaving other contents intact. These machine learnedbased methods can reduce human labor for image editing and enable nonexperts to manipulate their image without prior knowledge of tools that are often complicated to use. On the other hand, little attention has been given to machine learning methods for automatic audio editing. It is challenging to edit specific sound objects (e.g., decrease the volume of cicada buzzing noise ) with limited tools in the given audio. Considering that audio editing usually requires expert knowledge of audio engi neering or signal processing, we explore a deep learning approach in conjunction with textual queries to lessen audio editing difficulty. This paper addresses Audio Manipulation on Specific Sources (AMSS), which aims to edit only desired objects that correspond to specific sources, such as vocals and drums, according to a given description while preserving the content of sources that are not mentioned in the description. We formally define AMSS and a structured query language for AMSS in ¬ß2. AMSS can be used for many applications such as video creation tools making audio editing easy for nonexperts. For example, users can decrease the volume of drums by typing simple textual instructions instead of timeconsuming interactions with digital audio workstations. Although many machine learning approaches have been pro posed for audio processing [ 3,8,13,14,18,19,23,24,28,32,33], to the best of our knowledge, there is no existing method that can directly address AMSS (see ¬ß3). This paper proposes a novel end toend neural network that performs AMSS according to the given textual query. Designing a neural network for AMSS is straight forward if the sources of a given mixture track are observable. However, we assume that they are not observable because mostarXiv:2104.13553v1  [eess.AS]  28 Apr 2021XXXX21, XX, XX Woosung Choi, et al. Figure 1: Sound objects are transparent audio data does not provide them in general. In the assumed en vironment, modeling AMSS is very challenging because a sound object (e.g., a sample in a wave, a frequency bin in a spectrogram) is ‚Äòtransparent‚Äô([ 34]); a pixel in an image usually corresponds to only a single visual object, whereas a sound object carries information of multiple sources, as shown in Figure 1. Thus, we need differ ent approaches for AMSS from the existing image manipulation techniques. To address this challenge, we propose a neural network called AMSSNet that extracts a feature map containing latent sources (see ¬ß5.4.1) from the given mixture audio and selectively manipulates them while preserving irrelevant latent sources. We describe the AMSSNet architecture in ¬ß5. Another challenge is that existing datasets cannot be directly used for supervised training AMSSNet. If a training dataset of triples{(ùê¥(ùëñ),ùê¥‚Ä≤(ùëñ),ùëÜ(ùëñ))}ùëÅ ùëñ=1, whereùëÜ(ùëñ)is an AMSS description, ùê¥(ùëñ)is a mixture, and ùê¥‚Ä≤(ùëñ)is the manipulated audio according to ùëÜ(ùëñ)is provided, we can train a neural network ùëõùëíùë°in a supervised manner by minimizing√çùëÅ ùëñ=1ùëôùëúùë†ùë†(ùëõùëíùë°(ùê¥(ùëñ),ùëÜ(ùëñ)),ùê¥‚Ä≤(ùëñ)), whereùëôùëúùë†ùë† is a distance metric such as ùêø2. Unfortunately, there were no datasets currently available that directly target AMSS. To address this issue, we propose a training framework for AMSS (see ¬ß4) that uses a ‚Äòsource observable multitrack dataset‚Äô such as Musdb18 [ 22]. To generate an AMSS triple onthefly, we apply audio transformations onto specific sources of a given multitrack using common methods from Digital Signal Processing (DSP) libraries. We summarize our contributions as follows: ‚Ä¢Our work is a pioneer study on selective audio manipulation. ‚Ä¢We propose a supervised training framework for AMSS based on source observable multitrack datasets and DSP libraries together with evaluation benchmarks for AMSS. ‚Ä¢We propose AMSSNet, which performs multiple tasks and outperforms baselines on several tasks. 2 TASK DEFINITION 2.1 Audio Manipulation on Specific Sources We define Audio Manipulation on Specific Sources (AMSS) as fol lows: for a given audio track ùê¥and a given description ùëÜ, AMSS aims to generate a manipulated audio track ùê¥‚Ä≤that semantically matchesùëÜwhile preserving contents in ùê¥that are not described in ùëÜ.ùê¥contains multiple sources, and ùëÜdescribes the desired audio transformation and the targets, which we want to manipulate. ùëÜ can be represented as a onehot encoding or a textual query. In this paper, we assume that ùëÜis a textual query written in the Audio Manipulation Language described in ¬ß2.2. As a proofofconcept, this paper aims to verify that it is possi ble to train a neural network for AMSS. Specifically, we focus onclass task DSP operations volume controlseparate masking the others mute masking targets increase vol rescaling (increase) decrease vol rescaling (decrease) volume control (multi channel)pan left rescaling (left > mean > right) pan right rescaling (left < mean < right) filterlowpasss Lowpass Filter highpass Highpass Filter delay dereverb reverb‚àó Table 1: List of AMSS tasks modeled in this paper: ( ‚àó) denotes reversed generation process (the line 5 in Algorithm 1) modifying specified sources‚Äô sonic characteristics (e.g., loudness, panning, frequency content, and dereverberation). This paper does not address more complex manipulations such as distortion (see ¬ß6.7). Throughout the rest of the paper, we define an AMSS task to be a set of instructions dealing with the same manipulation method. Table 1 lists nine AMSS tasks we try to model in this paper. We also define an AMSS task class as a set of similar AMSS tasks. 2.2 Audio Manipulation Language We assume that ùëÜis given as a textual query, such as ‚Äúapply light lowpass to drums‚Äù. We make this assumption because textual query ing enables us to naturally describe any pair of a transformation function and its target sources with detailed options. For exam ple, we can control the level of audio effects (which corresponds to the parameter settings of DSP functions) by simply inserting adjectives such as light,medium , orheavy into the query. It also can provide easy extensibility to natural language interfaces, which will be addressed in future works. To this end, we propose an Audio Manipulation Language based on a probabilistic ContextFree Grammar (CFG) [ 5] for AMSS. Due to the page limit, we only present a subset of production rules (i.e., Rules (1a)(1f)) that define the query language‚Äôs syntax for the filter class. The Full CFG is available online1. <ùëëùëíùë†ùëê>‚Üí<ùëêùëôùë†ùëì> (1a) <ùëêùëôùë†ùëì>‚Üíapply <ùëúùëùùë°‚àíùëìùëñùëôùë°ùëíùëü >to<ùë†ùëüùëêùë†> (1b) <ùëúùëùùë°‚àíùëìùëñùëôùë°ùëíùëü >‚Üí<ùëúùëùùë°> <ùëìùëñùëôùë°ùëíùëü >|<ùëìùëñùëôùë°ùëíùëü > (1c) <ùëúùëùùë°>‚Üílight|medium|heavy (1d) <ùëìùëñùëôùë°ùëíùëü >‚Üílowpass|highpass (1e) <ùë†ùëüùëêùë†>‚Üívocals|drums|bass|vocal, drums|...(1f) In the above rules, bold strings are terminal symbols, and strings enclosed in angle brackets are nonterminal symbols. Each rule is of the formùê¥‚Üíùõº|ùõΩ|..., which means that ùê¥can be replaced with ùõºor ùõΩ. In a CFG, we apply a rule to replace a single nonterminal symbol with one of the expressions. Starting from the first symbol <ùëëùëíùë†ùëê>, we can generate a valid query string by recursively applying rules until there is no nonterminal symbol. 1https://kuielab.github.io/AMSSNet/aml.htmlAMSSNet: Audio Manipulation on UserSpecified Sources with Textual Queries XXXX21, XX, XX For example, ‚Äú apply medium lowpass to vocals, drums ‚Äù can derived from <ùëëùëíùë†ùëê >by Rules (1a)(1f). We can also produce ‚Äúapply lowpass to vocals, drums ‚Äù if we choose <ùëìùëñùëôùë°ùëíùëü >instead of<ùëúùëùùë°><ùëìùëñùëôùë°ùëíùëü >. Since we set a default option for lowpass level to be medium , those two queries have the same meaning. Rules (1b)(1e) are dependant on a AMSS task class, and Rule (1f) is dependant on a given multitrack audio. In this work, we use four AMSS task classes as shown in Table 1. Since we use in the experiment Musdb18[ 22] dataset of which track contains three named instruments (i.e., vocals, drums, bass), we set the righthand side of Rule (1f) to have all the possible permutations (13 expressions in total) 3 RELATED WORK "
143,L2-constrained Softmax Loss for Discriminative Face Verification.txt,"In recent years, the performance of face verification systems has
significantly improved using deep convolutional neural networks (DCNNs). A
typical pipeline for face verification includes training a deep network for
subject classification with softmax loss, using the penultimate layer output as
the feature descriptor, and generating a cosine similarity score given a pair
of face images. The softmax loss function does not optimize the features to
have higher similarity score for positive pairs and lower similarity score for
negative pairs, which leads to a performance gap. In this paper, we add an
L2-constraint to the feature descriptors which restricts them to lie on a
hypersphere of a fixed radius. This module can be easily implemented using
existing deep learning frameworks. We show that integrating this simple step in
the training pipeline significantly boosts the performance of face
verification. Specifically, we achieve state-of-the-art results on the
challenging IJB-A dataset, achieving True Accept Rate of 0.909 at False Accept
Rate 0.0001 on the face verification protocol. Additionally, we achieve
state-of-the-art performance on LFW dataset with an accuracy of 99.78%, and
competing performance on YTF dataset with accuracy of 96.08%.","Face veriÔ¨Åcation in unconstrained settings is a challeng ing problem. Despite the excellent performance of recent face veriÔ¨Åcation systems on curated datasets like Labeled Faces in the Wild (LFW) [14], it is still difÔ¨Åcult to achieve similar accuracy on faces with extreme variations in view points, resolution, occlusion and image quality. This is ev ident from the performance of the traditional algorithms on the publicly available IJBA [16] dataset. Data quality im balance in the training set is one of the reason for this perfor mance gap. Existing face recognition training datasets con tain large amount of high quality and frontal faces, whereas the unconstrained and difÔ¨Åcult faces occur rarely. Most of the DCNNbased methods trained with softmax loss for classiÔ¨Åcation tend to overÔ¨Åt to the high quality data and failto correctly classify faces acquired in difÔ¨Åcult conditions. Using softmax loss function for training face veriÔ¨Åcation system has its own pros and cons. On the one hand, it can be easily implemented using inbuilt functions from the pub licly available deep leaning toolboxes such as Caffe [15], Torch [7] and TensorFlow [1]. Unlike triplet loss [28], it does not have any restrictions on the input batch size and converges quickly. The learned features are discrimina tive enough for efÔ¨Åcient face veriÔ¨Åcation without any metric learning. On the other hand, the softmax loss is biased to the sam ple distribution. Unlike contrastive loss [29] and triplet loss [28] which speciÔ¨Åcally attend to hard samples, the soft max loss maximizes the conditional probability of all the samples in a given minibatch. Hence, it Ô¨Åts well to the high quality faces, ignoring the rare difÔ¨Åcult faces from a train ing minibatch. We observe that the L2norm of features learned using softmax loss is informative of the quality of the face [23]. Features for good quality frontal faces have a highL2norm while blurry faces with extreme pose have lowL2norm (see Figure 1(b)). Moreover, the softmax loss does not optimize the veriÔ¨Åcation requirement of keeping positive pairs closer and negative pairs far from each other. Due to this reason, many methods either apply metric learn ing on top of softmax features [27, 3, 24] or train an auxil iary loss [33, 29, 32] along with the softmax loss to achieve better veriÔ¨Åcation performance. In this paper, we provide a symptomatic treatment to is sues associated with the softmax loss. We propose an L2 softmax loss that adds a constraint on the features during training such that their L2norm remain constant. In other words, we restrict the features to lie on a hypersphere of a Ô¨Åxed radius. The proposed L2softmax loss has a dual ad vantage. Firstly, it provides similar attention to both good and bad quality faces since all the features have the same L2norm now, which is essential for better performance in unconstrained settings. Secondly, it strengthens the veri Ô¨Åcation signal by forcing the same subject features to be closer and different subject features to be far from each other in the normalized space. Thus, it maximizes the mar gin for the normalized L2distance or cosine similarity score between negative and positive pairs. Thus, it overcomes the 1arXiv:1703.09507v3  [cs.CV]  7 Jun 2017main disadvantages of the regular softmax loss. TheL2softmax loss also retains the advantages of the regular softmax loss. Similar to the softmax loss, it is a one network, one loss system. It doesn‚Äôt necessarily re quire any joint supervision as used by many recent meth ods [33, 24, 32, 29]. It can be easily implemented using inbuilt functions from Caffe [15], Torch [7] and Tensor Flow [1], and converges very fast. It introduces just a sin gle scaling parameter to the network. Compared to the reg ular softmax loss, the L2softmax loss gains a signiÔ¨Åcant boost in the performance. It achieves new stateoftheart results on IJBA dataset, and competing results on LFW and YouTube Face datasets. It surpasses the performance of several stateoftheart systems, which use multiple net works or multiple loss functions or both. In summary, this paper contributes to the following aspects: 1. We propose a simple, novel and effective L2softmax loss for face veriÔ¨Åcation that restricts the L2norm of the feature descriptor to a constant value . 2. We study the variations in the performance with re spect to the scaling parameter and provide suitable bounds on its value for achieving consistently high per formance. 3. The proposed method yields a consistent and signif icant boost on all the three challenging face veriÔ¨Åca tion datasets namely LFW [14], YouTube Face [19] and IJBA [16] Moreover, the gains from L2softmax loss are comple mentary to metric learning (eg: TPE [27], jointBayes [3]) or auxiliary loss functions (eg: center loss [33], contrastive loss [29]). We show that applying these techniques on top of theL2softmax loss can further improve the veriÔ¨Åcation performance. Combining with TPE [27], L2softmax loss achieves a record True Accept Rate (TAR) of 0.909 at False Accept Rate (FAR) of 0.0001 on the challenging IJBA [16] dataset. 2. Related Work "
392,Input Validation for Neural Networks via Runtime Local Robustness Verification.txt,"Local robustness verification can verify that a neural network is robust wrt.
any perturbation to a specific input within a certain distance. We call this
distance Robustness Radius. We observe that the robustness radii of correctly
classified inputs are much larger than that of misclassified inputs which
include adversarial examples, especially those from strong adversarial attacks.
Another observation is that the robustness radii of correctly classified inputs
often follow a normal distribution. Based on these two observations, we propose
to validate inputs for neural networks via runtime local robustness
verification. Experiments show that our approach can protect neural networks
from adversarial examples and improve their accuracies.","Despite the tremendous success ( LeCun et al. ,2015 ) of deep neural networks in recent years, their applications in safety critical areas are still concerning. Can we trust neural networks? This question arose when people found it hard to explain or interpret neural networks ( Castelvecchi ,2016 ) and drew more attention since the discovery of adversarial examples ( Szegedy et al. , 2014 ). An adversarial example is an input that is obtained by adding a small, imperceptible perturbation to a valid in put (i.e., correctly classiÔ¨Åed input), and that is designed to be misclassiÔ¨Åed. Recent studies ( Ilyas et al. ,2019 ) demon strate that adversarial examples are features that widely e x ist in common datasets, thus can hardly be avoided. This means neural networks inherently lack robustness and are vulnerable to malicious attacks. 1National University of Defense Technology, Changsha, Chin a 2Sorbonne Universit¬¥ e, CNRS, LIP6, F75005, Paris, France 3Institut universitaire de France. Correspondence to: Jian gchao Liu<jiangchaoliu@nudt.edu.cn >.Considerable amount ( Yuan et al. ,2019 ) of works have been proposed to improve the robustness of neural net works against adversarial examples. One method is ad versarial training (Goodfellow et al. ,2014 ;Kurakin et al. , 2016 ) which feeds adversarial examples to neural networks in the training stage. Adversarial training works well on the types of adversarial examples considered in the trainin g dataset, but provides no guarantee on other types. Some works ( Bradshaw et al. ,2017 ;Abbasi & Gagn¬¥ e ,2017 ) fo cus on designing robust architectures of neural networks. However, similarly to adversarial training, these methods do not guarantee robustness on all adversarial examples. One promising solution is formal veriÔ¨Åcation , which can prove that a network satisÔ¨Åes some formally deÔ¨Åned speci Ô¨Åcations. To give a formal speciÔ¨Åcation on robustness, we Ô¨Årst deÔ¨Åne a network as f:Rm‚ÜíC, whereRmis a vector space of input (e.g., images) and Cis a set of class labels. Then we deÔ¨Åne robustness radius (Wang et al. ,2017 ) of a network on an input /vector x‚ààRmas R(f,/vector x) =max{Œ∑| ‚àÄ/vector y‚ààRm,/bardbl/vector y‚àí/vector x/bardblp‚â§Œ∑‚áíf(/vector x) =f(/vector y)} where/bardbl¬∑/bardblpmeansLpnorm distance. Robustness radius measures the region in which a network is robust against perturbations. Another equivalent deÔ¨Ånition is minimal dis tortion (Weng et al. ,2018 ) (i.e., the minimal distance re quired to craft an adversarial example). We prefer to use the term robustness radius since it is deÔ¨Åned from a de fensive perspective. With robustness radius, we can deÔ¨Åne global robustness property of a network fas ‚àÄ/vector x‚ààRm,H(/vector x) =f(/vector x)‚áí R(f,/vector x)‚â•Œ¥ whereŒ¥is a userprovided threshold and H:Rm‚ÜíC‚à™{œÜ} denotes the oracle on the classiÔ¨Åcation of Rm. Note that H outputsœÜif an input in Rmis not classiÔ¨Åed into any class in C. This property ensures that for any input that can be rec ognized by human and correctly classiÔ¨Åed, the neural net work is robust to any perturbation to some extent (i.e., Œ¥in Lpnormal distance). Unfortunately, the global robustness property following this deÔ¨Ånition can hardly be veriÔ¨Åed be cause of the huge input space and absence of the oracle H. Some researchers tried to verify global robustness propert y of a weaker deÔ¨Ånition ( Katz et al. ,2017 ) (without H), butInput Validation for Deep Neural Networks via Runtime Local Robustness VeriÔ¨Åcation only succeeded on very small networks (i.e., consisting of a few dozens of neurons). Given the difÔ¨Åculties in verifying global robustness prop erties, many researchers turned to local robustness proper ties, i.e.,‚àÄ/vector x‚ààX‚äÜRm,H(/vector x) =f(/vector x)‚áí R(f,/vector x)‚â•Œ¥. Instead of the whole input space, local robustness prop erty only considers a set of inputs (denoted as Xin the formula), for instance, the training dataset. Various tech  niques ( Huang et al. ,2017 ;Gehr et al. ,2018 ;Singh et al. , 2018b ;Ehlers ,2017 ) have been successfully applied in this kind of veriÔ¨Åcation. However, local robustness properties are currently only used to evaluate the robustness of a given network or a defense technique, since they do not provide guarantee for robustness on inputs outside of the set X. Can we trust neural networks on a speciÔ¨Åc runtime input? Although this question is a compromise to the sad fact that the global robustness properties can hardly be guaranteed, it is still practically useful if we can know whether a neu ral network gives the expected output on an input at run time. Adversarial detection (Lu et al. ,2017 ;Grosse et al. , 2017 ) rejects inputs that are suspected of being adversarial examples based on the characteristics observed on known adversarial attacks. Input reconstruction (Meng & Chen , 2017 ) tries to transform adversarial examples to the in puts that can be correctly classiÔ¨Åed. Runtime veriÔ¨Åca tion(Desai et al. ,2018 ) checks whether an output satisÔ¨Åes some safety speciÔ¨Åcations at runtime and drops the output if not (traditional software is used as backup). This method , however, needs to know the constraints on outputs, which is not the case in tasks like image classiÔ¨Åcation. In this paper, we propose to validate inputs at runtime in a new way, i.e., via local robustness veriÔ¨Åcation, which can compute the robustness radius of any input (as opposed to correctly classiÔ¨Åed inputs only). We utilize robustness ra  dius as the characterics of inputs to distinguish correctly classiÔ¨Åed inputs and misclassiÔ¨Åed (possibly adversarial) in puts. Although it is known that adversarial examples them selves are often not robust to small perturbations ( Luo et al. , 2018 ;Wang et al. ,2018a ), to the best of our knowledge, we are the Ô¨Årst to validate inputs by observing robustness radius. To be speciÔ¨Åc, we have two observations. The Ô¨Årst is that the average robustness radius of valid inputs (i.e., correctly classiÔ¨Åed inputs) is much larger than that of misclassiÔ¨Åed inputs, no matter whether adversarial or not. To be formal, given a neural network f, and a set of inputs X‚äÜRmat runtime (which may include adver sarial examples), let Xc={/vector x‚ààX|f(/vector x) =H(/vector x)}and Xw={/vector x‚ààX|H(/vector x)‚ààC‚àßf(/vector x)/ne}ationslash=H(/vector x)}, then we have /summationtext /vector x‚ààXcR(f,/vector x) |Xc|‚â´/summationtext /vector x‚ààXwR(f,/vector x) |Xw|(1)where| ¬∑ |denotes cardinality and ‚â´denotes ‚Äúmuch larger than‚Äù. Note that we only consider inputs that can be clas siÔ¨Åed into labels, which exclude randomly generated in puts mapping to no label (i.e., mapped by HtoœÜ). We believe that this assumption is practical. Our experiments show that Equation 1holds on adversarial examples from all attacks we have tried, especially on those strong attack s which seek the smallest perturbations. Another observation is that the robustness radii of valid in  puts (i.e.,{R(f,/vector x)|/vector x‚ààXc}) follow a normal distribution. Based on these two observations, we propose a new way of validating inputs for neural networks. It can reject both ad  versarial examples and misclassiÔ¨Åed clean data (i.e., with  out crafted adversarial examples). Thus it not only protect s neural networks from adversarial attacks, but also improve s their accuracies. More importantly, this way does not need knowledge of the classiÔ¨Åcation scenario and is not speciÔ¨Åc to any attack. We have conducted experiments on Feed forward Neural Networks (FNN) and Convolutional Neu ral networks (CNN) with three representative attacks, i.e. , FGSM (fast, whitebox) ( Goodfellow et al. ,2014 ), C&W (strong, whitebox) ( Carlini & Wagner ,2017 ), and HOP (i.e., Hopskipjump, blackbox) ( Chen et al. ,2019 ). The re sults demonstrate the effectiveness of our method. To be more speciÔ¨Åc, on a random CNN for MNIST ( LeCun et al. , 1998 ), our method can reject 75% misclassiÔ¨Åed natural in puts, 95% and 100% FGSM adversarial examples with dif ferent parameters respectively, 100% C&W adversarial ex amples and 100% HOP adversarial examples, with only 3% false alarm rate. It is worth mentioning that the two observations are valid not only on exact robustness radius computed by complete veriÔ¨Åcation, but also on underapproximated robustness ra  dius computed by incomplete veriÔ¨Åcation, which is fast enough to be deployed at runtime. We make the following contributions: ‚Ä¢We observed that, on FNNs and CNNs, the average ro bustness radius of the valid inputs is much larger than that of the misclassiÔ¨Åed inputs (no matter whether ad versarial or not); ‚Ä¢We observed that, on most FNNs and CNNs, the ro bustness radii of the valid inputs follow a normal dis tribution; ‚Ä¢Based on these two observations, we propose a new input validation method based on local robustness ver iÔ¨Åcation (which currently is only used to evaluate the robustness of a given network in existing work, as opposed to validate inputs), which can protect neural networks from adversarial examples, especially fromInput Validation for Deep Neural Networks via Runtime Local Robustness VeriÔ¨Åcation strong attacks, and improve their accuracies on clean data. 2. Observation on Robustness Radii of Inputs from Different Categories In this section, we show our observation on the robustness radii of valid (i.e., correctly classiÔ¨Åed) data, misclassi Ô¨Åed clean data and adversarial examples. 2.1. Background and Experimental Setup Local Robustness VeriÔ¨Åcation . Local robustness properties ensure that, a neural network is immune to adversarial ex amples on a set of inputs within Œ¥inLpnorm distance. To prove it, we only need to prove that, for given /vector x‚ààXandŒ¥, ‚àÄ/vector y‚ààRm,/bardbl/vector y‚àí/vector x/bardblp‚â§Œ¥‚áíf(/vector x) =f(/vector y) (2) In this paper, we only consider the case p=‚àû. Current veriÔ¨Åers for this property can be categorized as complete andincomplete . Complete veriÔ¨Åers can give an exact an swer on whether the property is satisÔ¨Åed. Most complete veriÔ¨Åers are based on Mixed Integer Linear Programming (MILP) ( Dutta et al. ,2018 ;Fischetti & Jo ,2018 ) or SatisÔ¨Å ability Modulo Theories (SMT) ( Ehlers ,2017 ;Katz et al. , 2017 ). These methods are NPhard, thus can hardly be ap plied to large networks. Incomplete veriÔ¨Åers only provide conservative answers, that is, they could return unknown even if the property holds. Thus incomplete veriÔ¨Åers usually can only verify an underapproximation of robustness radius. Typical incom plete veriÔ¨Åcation methods on neural networks include sym bolic intervals ( Wang et al. ,2018b ) and abstract interpreta tion ( Singh et al. ,2019 ). These methods are much more scalable than complete ones. Experimental Setup . We take MNIST ( LeCun et al. , 1998 ) and CIFAR10 ( Krizhevsky et al. ,2009 ) as our in put datasets and use IBM‚Äôs Adversarial Robustness Tool box ( Nicolae et al. ,2018 ) to generate FGSM, C&W, and HOP adversarial examples with default parame ters, except for FGSM where we set «´(i.e., a parame ter (Goodfellow et al. ,2014 )) as 0.1 (by default) and 0.05 (which is stronger) respectively. We use ERAN ( Singh et al. ,2018a ) as the veriÔ¨Åer which supports both complete and incomplete robustness veriÔ¨Åca tions. ERAN does not compute robustness radius directly, but can judge whether the robustness radius is larger than a givenŒ¥(i.e., the network fis robust on all inputs that are withinŒ¥inL‚àûnorm distance with /vector x, as Equation 2). We denote it as isrobust (f,/vector x,Œ¥). Note that, ERAN supports two versions of isrobust : the complete one and the in complete one. Applying binary search on complete (resp.Algorithm 1 Computation of robustness radius Input: networkf, input/vector x, big value up, tolerance e Initialize low= 0 repeat mid= (up+low)/2 ifisrobust (f,/vector x,mid)then low=mid else up=mid end if untilup‚àílow < e Output: low incomplete) isrobust , we can Ô¨Ånd a value close enough to the robustness radius (resp. an underapproximation of the robustness radius). This algorithm is described in Al gorithm 1. In the following, we will call the computed value with complete veriÔ¨Åcation the (asymptotically) exact robustness radius , and that with incomplete veriÔ¨Åcation the approximate robustness radius . All experiments are con ducted on an Ubuntu 18.04 running on a desktop with an Intel i99900K CPU, 32GB Memory. 2.2. Observation on Exact Robustness Radius ERAN combines abstract interpretation, linear program ming and MILP to completely verify a network. To make the veriÔ¨Åcation terminate in a reasonable time, we trained a small FNN (denoted as FNNMNIST) on MNIST (with 95.82% accuracy), which consists of 5 layers: the input layer, three fully connected layers, each with 30 neurons and one output layer. We run ERAN with ReÔ¨ÅneZono ( Singh et al. ,2018b ) do main, and set upas 0.256 and eas 0.001 in Algorithm 1. We computed the robustness radii of the Ô¨Årst 100 samples from each of following six categories in the MNIST test dataset: ‚Ä¢samples that can be correctly classiÔ¨Åed by the network ‚Ä¢samples that are misclassifed by the network ‚Ä¢adversarial examples from successful FGSM attack with«´= 0.1 ‚Ä¢adversarial examples from successful FGSM attack with«´= 0.05 ‚Ä¢adversarial examples from successful C&W attack ‚Ä¢adversarial examples from successful HOP attack Figure 1(a) shows the number of inputs, the exact robust ness radii of which are above a given value (i.e., the xaxis) . We can see that the robustness radii of valid inputs are much larger than that of the other categories of data, especially the adversarial examples from the strong whitebox C&W attack and blackbox HOP attack. The robustness radii of adversarial examples from FGSM attack with «´= 0.1areInput Validation for Deep Neural Networks via Runtime Local Robustness VeriÔ¨Åcation (a) Exact robustness radius on FNNMNIST  (b) Approximate robustness radius on FNNMNIST (c) Approximate robustness radius on CNNMNIST  (d) Approximate robustness radius on CNNCIFAR Figure 1. The numbers of inputs which have a larger robustness radius t han a given value signiÔ¨Åcantly larger than those with «´= 0.05. Our experiments suggest that we can use robustness radius to evaluate to what extent we should trust the output of a neural network on a given input. By setting a threshold to reject any input the robustness radius of which is lower, we can protect the neural network from adversarial examples and improve its accuracy. However, complete veriÔ¨Åcation is timeconsuming. In our experiments, each call to func tionisrobust takes 11s on average, even though our net work contains only 100 neurons. It seems that complete veriÔ¨Åcation can hardly be deployed at runtime, especially considering that the running time of complete veriÔ¨Åcation increases exponentially with the number of neurons. 2.3. Observation on Approximate Robustness Radius Incomplete veriÔ¨Åcation usually runs much faster than com plete veriÔ¨Åcation and has the potential to be deployed at runtime. However, Algorithm 1with incomplete veriÔ¨Åca tion can only give an approximate robustness radius. We would like to know (1) whether approximate robustness ra dius from incomplete veriÔ¨Åcation is close to the exact ro bustness radius; (2) whether the approximate robustnessradii of valid inputs are signiÔ¨Åcantly larger than that of th e misclassiÔ¨Åed inputs. Actually the second question is more important since it decides whether we can use incomplete veriÔ¨Åcation to validate inputs. Observation on FNN . We utilize ERAN with DeepZono do main ( Singh et al. ,2018a ) (which is incomplete) to com pute the approximate robustness radii of the same inputs on the network FNNMNIST. The results are shown in Figure 1(b). Comparing Figure 1(a) and Figure 1(b), we can see that the values of approximate and exact robust ness radii of the same inputs are very close (comparing the xaxis). In fact, the approximate robustness radii (ex cept those equal to 0) of all inputs are between 44% and 100% of their exact robustness radii. Moreover, we can see that, similar to exact robustness radii, the approximate ro  bustness radii of valid inputs are signiÔ¨Åcantly larger than that of misclassiÔ¨Åed inputs. This means, we can utilize approximate robustness radius to protect neural networks. Moreover, each call to isrobust in incomplete veriÔ¨Åcation costs less than 1s on the given network, and has polynomial time complexity wrt. the number of neurons, which means it has potential to be deployed at runtime. Observation on CNN . We have also conducted experiInput Validation for Deep Neural Networks via Runtime Local Robustness VeriÔ¨Åcation ments on Convolutional Neural Networks. They are sig niÔ¨Åcantly larger than the network FNNMNIST, and com plete veriÔ¨Åcation methods can hardly compute robustness radius in a reasonable time. Thus we only tried incom plete veriÔ¨Åcation. Our experiments on CNN are conducted on two datasets: MNIST ( LeCun et al. ,1998 ) and CI FAR10 ( Krizhevsky et al. ,2009 ). We trained a CNN (denoted as CNNMNIST) on MNIST of 7 layers: the input layer, a convolutional layer with 6 Ô¨Ålter s of size3√ó3, a maxpooling layer of (2,2), a convolutional layer with 16 Ô¨Ålters of size 3√ó3, a maxpooling layer of (2,2), a fully connected layer of 128 neurons and an output layer with 10 labels. The accuracy is 98.62%. As in Section 2.2, we utilize ERAN with DeepZono do main ( Singh et al. ,2018a ) to compute the approximate ro bustness radii of the Ô¨Årst 100 inputs from each of the six categories. Figure 1(c) shows the results on CNNMNIST. We can see that the computed approximate robustness radii of all inputs are much smaller (i.e., ‚â§0.04) than those com puted on the small network FNNMNIST. We do not know whether the approximate robustness radii are close to the exact robustness radii, which we cannot get even after sev eral days of computation. However, most importantly, the characteristics of approximate robustness radii of inputs of different categories are the same as exact robustness radii . That is the approximate robustness radii of valid inputs (i. e., the red line) are much larger than that of other inputs. In fact, if we set the threshold as 0.01, we can reject 75% misclassiÔ¨Åed clean data, 95% FGSM adversarial examples where«´= 0.1,100% FGSM adversarial examples where «´= 0.05,100% C&W adversarial examples, and 100% HOP adversarial examples, and only 3%valid inputs. We trained a LeNet5 ( LeCun et al. ,1998 ) CNN (denoted as CNNCIFAR in this paper) on CIFAR10 of 8 layers: the input layer, a convolutional layer with 6 Ô¨Ålters of size 5√ó5, a maxpooling layer of (2,2), a convolutional layer with 16 Ô¨Ålters of size 5√ó5, a maxpooling layer of (2,2), two fully connected layers of 120 and 84 neurons respectively, an output layer with 10 labels. The accuracy is 73.66%. Figure 1(d) shows the results of the Ô¨Årst 100 inputs of each category in CIFAR10 test database. Even the approximate robustness radii of the valid inputs are signiÔ¨Åcantly large r than those of misclassiÔ¨Åed inputs and adversarial examples from C&W and HOP attacks, but are almost indistinguish able from FGSM attacks. We believe that the reason is the accuracy of the network is too low such that it leaves big ‚Äúholes‚Äù for adversarial examples in the input space. To validate our observations, we trained more FNNs and CNNs of various structures and conducted the same mea sure. Table 1shows the results. In the table, on each net work, we show its training dataset (column Dataset), network structure (column Network), where ( 3√ó30,101) de scribes FNNMNIST, ( 6(3,3),16(3,3),128,101) describes CNNMNIST and ( 6(5,5),16(5,5),120,84,10) describes CNNCIFAR. For each network structure, we adopted dif ferent activation functions (column Activation). The tabl e also shows the accuracy on the test dataset (column Acc.) and the average approximate robustness radii of the Ô¨Årst 10 inputs (we chose 10 because we believe that 10 is enough to compare the average values and generating adversarial attacks e.g., HOP can be very timeconsuming) in the test dataset of six categories: correctly classiÔ¨Åed inputs (col  umn Valid), misclassiÔ¨Åed inputs (column Mis.), adversaria l examples from FGSM attacks with «´= 0.1, FGSM attacks with«´= 0.05, C&W attacks and HOP attacks. The aver age running time of each call to isrobust is also recorded in column Time(s). The column Pvalue will be explained later (see Section 4). From the table, we can see that our ob servation is valid on all trained networks. Our experiments can be easily reproduced since we only use open source tools with a little modiÔ¨Åcation (e.g., Algorithm 1). The modiÔ¨Åed code and all trained networks in this paper have been uploaded to an online repository1. Even though we believe that people can easily reproduce our experiments with their own trained networks. There are CNNs ( Hu et al. ,2018 ;Xie et al. ,2017 ) that have high accuracies on CIFAR10. But these networks usually adopt layers other than fullyconnected, convolutional an d maxpooling layers and are out of the scope of this pa per and beyond the ability of current local robustness ver iÔ¨Åers ( Katz et al. ,2017 ;Ehlers ,2017 ;Wang et al. ,2018b ; Dutta et al. ,2018 ;Singh et al. ,2018a ). (a) FNNMNIST  (b) CNNMNIST Figure 2. The numbers of inputs which have a larger minimal dis tortion than a given value We also tried another tool CLEVER ( Weng et al. ,2018 ) which estimates the minimal distortion to craft adversar ial examples (which should be equal to robustness radius). Figure 2illustrates the robustness radii on the Ô¨Årst 100 in puts of the six categories on the networks FNNMNIST and CNNMNIST. We can see that, the difference of min imal distortions of valid inputs and other categories is les s signiÔ¨Åcant than that of robustness radii in Figure 1. Fig ure3shows the histogram of the density of the minimal 1https://www.github.com/jiangchaoliu/eran.gitInput Validation for Deep Neural Networks via Runtime Local Robustness VeriÔ¨Åcation Table 1. The average robustness radius and pvalue of different netw orks DATASET NETWORK ACIVATION ACC. V ALID MIS. FGSM( 0.1) FGSM( 0.05) C&W HOP P VALUE TIME(S) MNIST 3√ó30,101 RELU 95.82 0.0227 0.0056 0.0091 0.0066 0.0020 0.0009 0.033 0.2 42 MNIST 3√ó30,102 RELU 96.49 0.0183 0.0069 0.0087 0.0065 0.0020 0.0009 0.026 0.2 39 MNIST 3√ó30,103 RELU 96.55 0.0194 0.0069 0.0078 0.0048 0.0027 0.0007 <0.001 0.241 MNIST 3√ó50,10 RELU 96.80 0.0176 0.0047 0.0090 0.0068 0.0013 0.0009 0.140 0.1 43 MNIST 3√ó100,10 RELU 97.49 0.0162 0.0070 0.0080 0.0054 0.0023 0.0010 0.916 0.3 57 MNIST 4√ó100,10 RELU 97.37 0.0143 0.0076 0.0057 0.0051 0.0019 0.0010 0.091 0.4 41 MNIST 5√ó100,10 RELU 97.61 0.0127 0.0057 0.0047 0.0043 0.0013 0.0011 0.082 0.5 17 MNIST 5√ó200,10 RELU 97.70 0.0101 0.0054 0.0038 0.0041 0.0027 0.0010 <0.001 1.746 MNIST 3√ó30,10 SIGMOID 95.26 0.0145 0.0071 0.0074 0.0050 0.0020 0.0011 <0.001 0.251 MNIST 3√ó50,10 SIGMOID 96.15 0.0130 0.0053 0.0071 0.0050 0.0015 0.0010 0.003 0.156 MNIST 3√ó100,10 SIGMOID 97.11 0.0115 0.0057 0.0047 0.0043 0.0017 0.0008 0.142 0.408 MNIST 4√ó100,10 SIGMOID 96.86 0.0101 0.0057 0.0041 0.0042 0.0007 0.0008 0.126 0.551 MNIST 5√ó100,10 SIGMOID 96.30 0.0102 0.0023 0.0050 0.0024 0.0011 0.0008 0.492 0.670 MNIST 5√ó200,10 SIGMOID 96.90 0.0086 0.0052 0.0042 0.0033 0.0018 0.0007 0.034 2.720 MNIST 3√ó30,10 TANH 96.25 0.0081 0.0046 0.0030 0.0020 0.0016 0.0008 <0.001 0.255 MNIST 3√ó50,10 TANH 96.98 0.0070 0.0032 0.0034 0.0034 0.0008 0.0007 <0.001 0.156 MNIST 3√ó100,10 TANH 97.42 0.0059 0.0024 0.0034 0.0026 0.0011 0.0007 0.713 0.408 MNIST 4√ó100,10 TANH 97.80 0.0046 0.0026 0.0017 0.0021 0.0013 0.0008 0.307 0.550 MNIST 5√ó100,10 TANH 97.62 0.0035 0.0020 0.0024 0.0016 0.0008 0.0007 0.022 0.681 MNIST 5√ó200,10 TANH 97.52 0.0028 0.0015 0.0015 0.0010 0.0007 0.0007 0.142 2.736 MNIST 6(3,3),16(3,3),128,101 RELU 98.62 0.0175 0.0064 0.0055 0.0032 0.0021 0.0011 0.828 0.2 32 MNIST 6(3,3),16(3,3),128,102 RELU 98.29 0.0188 0.0061 0.0049 0.0040 0.0034 0.0019 0.492 0.2 53 MNIST 6(3,3),16(3,3),128,103 RELU 98.45 0.0174 0.0065 0.0051 0.0029 0.0030 0.0019 0.622 0.2 13 MNIST 3(3,3),8(3,3),128,10 RELU 97.45 0.0239 0.0092 0.0089 0.0080 0.0025 0.0021 <0.001 0.073 MNIST 12(3,3),32(3,3),128,10 RELU 98.99 0.0170 0.0059 0.0051 0.0032 0.0027 0.0019 0.333 0.7 54 MNIST 6(3,3),16(3,3),128,10 SIGMOID 98.45 0.0178 0.0045 0.0053 0.0045 0.0017 0.0018 0.773 0.344 MNIST 3(3,3),8(3,3),128,10 SIGMOID 97.78 0.0249 0.0081 0.0102 0.0060 0.0037 0.0022 0.068 0.119 MNIST 12(3,3),32(3,3),128,10 SIGMOID 98.85 0.0172 0.0061 0.0038 0.0059 0.0016 0.0019 0.522 1.318 MNIST 6(3,3),16(3,3),128,10 TANH 98.73 0.0039 0.0013 0.0022 0.0015 0.0006 0.0006 0.188 0.369 MNIST 3(3,3),8(3,3),128,10 TANH 98.56 0.0103 0.0036 0.0042 0.0024 0.0014 0.0012 0.314 0.124 MNIST 12(3,3),32(3,3),128,10 TANH 99.11 0.0037 0.0017 0.0024 0.0013 0.0004 0.0006 0.001 1.488 CIFAR10 6(5,5),16(5,5),120,84,10 RELU 73.66 0.0017 0.0009 0.0017 0.0016 0.0003 0.0002 0.005 1.6 80 CIFAR10 6(5,5),16(5,5),120,84,10 SIGMOID 65.30 0.0025 0.0014 0.0029 0.0022 0.0005 0.0004 0.839 2.418 CIFAR10 6(5,5),16(5,5),120,84,10 TANH 70.68 0.0008 0.0005 0.0009 0.0007 0.0002 0.0002 0.390 2.443 Figure 3. Minimal distortion from CLEVER and exact/approximate robu stness radius from ERAN distortion from CLEVER and exact/approximate robust ness radii from ERAN of the Ô¨Årst 100 valid inputs on the network FNNMNIST. Compared with approximate robust ness radii, both the values and distribution of minimal dis tortions are much farther from the exact robustness radii. 3. Input Validation with Observation I Based on our Ô¨Årst observation, we can design an algorithm to validate the inputs of a neural network at runtime to pro tect it from adversarial examples and improve its accuracy. A naive idea is to set a threshold and reject all inputs the approximate robustness radii of which are below it. How ever, it is nontrivial to choose the threshold. One solutio n is to set the threshold according to the maximal false alarmrate that can be tolerated, which depends on the applica tion. ROC curve plots the true alarm rate against the false alarm rate at various threshold settings. Figure 4shows the ROC curves of the network CNNMNIST and CNN CIFAR on the Ô¨Årst 100 inputs from each category. The re sult on MNIST is good on all kinds of adversarial examples. However, on CIFAR10, our method is not very helpful on FGSM attacks. The reason, we believe, is that the accuracy of our CNN on CIFAR10 is not high enough. Until now, we have only studied the Ô¨Årst 100 inputs in each category. In Table 2, we show the effect of different choices of thresholds on the network CNNMNIST on the Ô¨Årst 100 and random 100 inputs in each category. To be more spe ciÔ¨Åc, we show with different thresholds (column Th.), the percentage of rejected valid inputs (column Vic.), the perInput Validation for Deep Neural Networks via Runtime Local Robustness VeriÔ¨Åcation Table 2. The rejection rates with different thresholds TH. V IC. W F ( 0.1) F (0.05) C&W HOP 0.002 0/0 14/14 17/13 27/24 48/47 91/99 0.004 0/0 28/29 42/38 57/56 77/79 100/100 0.006 0/0 49/48 62/59 87/79 89/89 100/100 0.008 2/1 66/69 88/79 100/95 96/99 100/100 0.010 3/4 75/80 95/97 100/99 100/100 100/100 0.012 8/7 89/90 99/100 100/100 100/100 100/100 0.014 13/16 97/95 100/100 100/100 100/100 100/100 0.016 24/28 100/100 100/100 100/100 100/100 100/100 centage of rejected misclassiÔ¨Åed inputs (column W.), and the rejected adversarial examples from FGSM attack with «´= 0.1(column F ( 0.1)), FGSM attack with «´= 0.05(col umn F (0.05)), C&W attack and HOP attack. The result of the Ô¨Årst 100 inputs and random 100 inputs are on the left and right sides of ‚Äù/‚Äù respectively in each cell. This table shows that the observation of the Ô¨Årst 100 inputs of each category are also valid in the whole test database. (a) ROC curve on MNIST  (b) ROC curve on CIFAR Figure 4. ROC curves on MNIST and CIFAR The beneÔ¨Åt of validation by threshold is that once the threshold is decided, we just need to call isrobust once to test whether the approximate robustness radius of an input is above the threshold. 4. Distribution of The Approximate Robustness Radius of Valid Inputs One thing concerns us: if the attackers have the knowledge of our neural network and our detection method, they can generate adversarial examples with large approximate ro bustness radii on purpose (even though we believe that such adversarial examples can be hardly found on a neural net work with high accuracy). To avoid this, we study further whether the approximate robustness radii of valid inputs follow a certain distribution. If they do, then the attacker s not only need to generate adversarial examples with large enough robustness radii, but also need to make sure that such robustness radii follow a certain distribution, which is much harder. Observing Figure 3, one thought is that the exact/approximate robustness radii follow a normal distri  bution. To test that, we compute the approximate robustAlgorithm 2 Validation by distribution Input: networkf, input/vector x Q=a queue (the size of which is s) of valid inputs repeat Input: input/vector x Q.append(/vector x) iftest(Q)then delQ[0] else delQ[s] end if until END OF INPUT ness radii of the Ô¨Årst 100 valid inputs for all networks in Table 1. We test whether they follow a normal distribution by D‚ÄôAgostino and Pearson‚Äôs test ( D‚ÄôAgostino & Pearson , 1973 ), which returns a pvalue2(shown in column Pvalue). If the pvalue is larger than 0.05, then they are believed to follow a normal distribution. We can see that 25 net works follow normal distributions, but 9 not. We cannot give a conclusion on what factors make the difference, but it seems that a medium size network with high accuracy usually enjoys this property. It is worth mentioning that th e exact robustness radii of the FNNMNIST network do not pass the D‚ÄôAgostino and Pearson‚Äôs test either, the same as its approximate robustness radii, even though they look lik e a normal distribution in Figure 3. 5. Input Validation with Observation II If the approximate robustness radii of the valid inputs on a network follow a normal distribution, we can utilize this to improve our input validation method. The new algorithm is shown in Algorithm 2. It maintains a sliding window ( Rebbapragada et al. ,2009 ) of sizescon taining the inputs believed to be valid. When a new input comes, the algorithm checks whether it breaks the original normal distribution by function test . If it does, then this new input is deleted ( delQ[s]), otherwise the Ô¨Årst element is deleted ( delQ[0]), thus the window slides. The design of function test is heuristic, and we propose the one below Q[s]‚â•œÉ0‚à®pvalue(Q[0 :s‚àí1])‚àípvalue(Q[1 :s])‚â§œÉ1 This function combines our two observations. It returns true if the approximate robustness radius of the last input is larger than a threshold œÉ0(from Observation I) or the p value of the new sliding window pvalue(Q[1 :s])does not drop sharply from the last one pvalue(Q[0 :s‚àí1]) 2In statistics, pvalue (or probability value) is the probab ility of obtaining the observed results of a test, assuming that th e null hypothesis is correct.Input Validation for Deep Neural Networks via Runtime Local Robustness VeriÔ¨Åcation (from Observation II). However, we do not have a method to decide the two parameters œÉ0andœÉ1. On the network CNNMNIST, we set s= 50 ,œÉ0= 0.014andœÉ1= 0.001. To test this algorithm, we take 100 valid inputs, 1 misclas siÔ¨Åed input (because the accuracy is 98.62% ), and 100 ad versarial examples from each of the four types of attacks (which totally makes 400) as the inputs. If all the inputs come in sequence, our algorithm can reject all adversarial examples and the misclassiÔ¨Åed input, with only 3 valid in puts rejected. However, if we shufÔ¨Çe the inputs randomly, the average rejected valid inputs are 5 and adversarial ex amples are 28 respectively (by 10 times experiments). Ac tually, in both cases, the Ô¨Årst condition ( Q[s]‚â•œÉ0) accepts 87 valid inputs and rejects all invalid inputs. The second condition accounts for other accepted valid inputs and fals e positives. The disadvantage of validation by distribution is that it needs to compute the approximate robustness radius with Algorithm 1which needs several iterative calls to isrobust , which takes more time. However, the time com plexity of isrobust for incomplete veriÔ¨Åcation is polyno mial wrt. the number of neurons, and the potential of its speed is far from fully explored (e.g., GPU is not utilized). 6. Related Work "
33,The DKU-DukeECE System for the Self-Supervision Speaker Verification Task of the 2021 VoxCeleb Speaker Recognition Challenge.txt,"This report describes the submission of the DKU-DukeECE team to the
self-supervision speaker verification task of the 2021 VoxCeleb Speaker
Recognition Challenge (VoxSRC). Our method employs an iterative labeling
framework to learn self-supervised speaker representation based on a deep
neural network (DNN). The framework starts with training a self-supervision
speaker embedding network by maximizing agreement between different segments
within an utterance via a contrastive loss. Taking advantage of DNN's ability
to learn from data with label noise, we propose to cluster the speaker
embedding obtained from the previous speaker network and use the subsequent
class assignments as pseudo labels to train a new DNN. Moreover, we iteratively
train the speaker network with pseudo labels generated from the previous step
to bootstrap the discriminative power of a DNN. Also, visual modal data is
incorporated in this self-labeling framework. The visual pseudo label and the
audio pseudo label are fused with a cluster ensemble algorithm to generate a
robust supervisory signal for representation learning. Our submission achieves
an equal error rate (EER) of 5.58% and 5.59% on the challenge development and
test set, respectively.","This report describes the submission of the DKUDukeECE team to the selfsupervision speaker veriÔ¨Åcation task of the 2021 V oxCeleb Speaker Recognition Challenge (V oxSRC). In our previous work on selfsupervised speaker represen tation learning [1], we proposed a twostage iterative labeling framework. In the Ô¨Årst stage, contrastive selfsupervised learn ing is used to pretraining the speaker embedding network. This allows the network to learn a meaningful feature representa tion for the Ô¨Årst round of clustering instead of random initial ization. In the second stage, a clustering algorithm iteratively generates pseudo labels of the training data with the learned representation, and the network is trained with these labels in a supervised manner. The clustering algorithm can discover the intrinsic structure of the representation of the unlabeled data, providing meaningful supervisory signals comparing to con trastive learning which draws negative samples uniformly from the training data without label information. The idea behind the proposed framework is to take advantage of the DNN‚Äôs ability to learn from data with label noise and bootstrap its discrimina tive power. In this work, we extend this iterative labeling framework to multimodal audiovisual data, considering that complemen tary information from different modalities can help the cluster ing algorithm generate more meaningful supervisory signals.SpeciÔ¨Åcally, we train a visual representation network to en code face information using the pseudo labels generated by au dio data. With the resulted visual representations, clustering is performed to generate pseudo labels for visual data. Then, we employ a cluster ensemble algorithm to fuse pseudolabels gen erated by different modalities. This fused pseudolabel is then used to train speaker and face representation networks. With the clustering ensemble algorithm, information in one modal ity can Ô¨Çow to the other modality, providing more robust and faulttolerant supervisory signals. 2. Methods "
261,Actor-Based Model Checking for SDN Networks.txt,"Software-Defined Networking (SDN) is a networking paradigm that has become
increasingly popular in the last decade. The unprecedented control over the
global behavior of the network it provides opens a range of new opportunities
for formal methods and much work has appeared in the last few years on
providing bridges between SDN and verification. This article advances this
research line and provides a link between SDN and traditional work on formal
methods for verification of concurrent and distributed software---actor-based
modelling. We show how SDN programs can be seamlessly modelled using
\emph{actors}, and thus existing advanced model checking techniques developed
for actors can be directly applied to verify a range of properties of SDN
networks, including consistency of flow tables, violation of safety policies,
and forwarding loops. Our model checker for SDN networks is available through
an online web interface, that also provides the SDN actor-models for a number
of well-known SDN benchmarks.","SDN is a relatively recent networking paradigm which is now widely used in industry, with many companies|such as Google and Facebook|using SDN to control their backbone networks and datacenters. The core principle in SDN is the separation of control and data planes|there is a centralized controller which operates a collection of distributed interconnected switches. The controller can dynamically update switches' policies depending on the observed  ow of packets, which is a simple but powerful way to react to unexpected events in the network. Corresponding author: Miguel Isabel, Department of Sistemas Inform aticos y Com putaci on , C/ Profesor Jos e Garc a Santesmases, s/n Complutense University of Madrid, E28040  Madrid (Spain). Phone/Fax +34 91 3947641 / +34 91 3947529. Email addresses: elvira@sip.ucm.es (Elvira Albert), mzamalloa@ucm.es (Miguel G omezZamalloa), miguelis@ucm.es (Miguel Isabel ), albert@cs.upc.edu ( Albert Rubio), m.sammartino@ucl.ac.uk ( Matteo Sammartino), alexandra.silva@ucl.ac.uk ( Alexandra Silva) Preprint submitted to Elsevier January 29, 2020arXiv:2001.10022v1  [cs.NI]  27 Jan 2020Network verication has gained an extra boost since SDN was introduced, as in this new paradigm the amount of detailed information available about network events is rich enough and can be centrally gathered to check for properties, both statically and dynamically, of the network behavior. Moreover, the controller itself is a program which can be analyzed and veried before deployment. The distributed and concurrent nature of network behavior makes program ming and verication tasks challenging. Some of the bugs that can be found in existing (programmable) networks are reminiscent of faults that have appeared in distributed and concurrent systems, and which have inspired much research in the verication and formal methods communities. With this observation as a starting point, this article provides a new bridge between SDN and a strand of formal methods|actorbased modelling [1]| which was originally developed to analyze concurrent systems. Actors, entities equipped with a private mem ory, form the basic unit of computation in such framework and can interact with each other through asynchronous messages. This setup enables reasoning about local properties of the system without knowledge of the whole program, which gives rise to more compositional and thus scalable methods. Actors provide the foundations for the concurrency model of languages used in industry, e.g., Erlang and Scala , and libraries used in mainstream languages, e.g., Akka . 1.1. Summary of contributions This article makes ve main contributions: 1. SDNsemantics: A formalization of the semantics of SDN networks which allows us to dene the transitions that occur in the network and formalize the concept of execution trace needed to prove soundness of our modelling. 2. SDNActors: An encoding of all basic components of an SDN network (switches, hosts, controller) into the actorbased language ABS [2] and a soundness proof of our encoding using the semantics of SDN networks in point 1. 3. Barriers: One of the most challenging aspects to encode are the OpenFlow barrier messages, special instructions that the controller can use to force switches to execute all their queued tasks. We provide an implementation of barriers using conditional synchronization and a soundness result. 4. Model checker: A model checker for our SDN models built on top of the SYCO tool [3] that incorporates several dynamic partialorder reduction (DPOR) algorithms. 5. Case studies: Several case studies of SDN and properties to illustrate the versatility and potential of the approach. We were able to nd bugs related to programming errors in the controller, forwarding loops, and violation of safety policies, and scale to larger networks than related techniques. This article extends and improves the conference paper that appeared in the FM'18 proceedings [4] as follows. On the theoretical side, we have formalized 2the semantics of SDN networks and used it to prove soundness of the basic encoding of SDNActors, ensuring thus the correctness of our models. On the practical side, we have carried out a new experimental evaluation using the Constrained DPOR algorithm [5]. This DPOR algorithm can take advantage of independence conditions that we have dened specically for the SDN domain and that allow us to treat larger networks than by using related techniques and than in our FM'18 paper. We have also extended the SYCO tool with a mechanism to detect the violation of the property under check that stops the exploration, while before SYCO was restricted to full exploration. 1.2. Organization of the article Section 2 gives an intuition of the main ideas in the article by means of a simple example. In Section 3 we present the semantics of SDN programs and of actor systems, in two parts. First, Section 3.1 introduces a semantics for SDN networks that describes the communication patterns in this kind of networks and that allows us to formalize the notion of execution trace in the SDN network. Next, we recall the semantics of actor systems from [2] which will constitute the semantics of our models. Section 4 introduces the concept ofSDNActor by providing the encoding of all components in an SDN network as actors. We formally prove the soundness of the encoding by relying on the semantics introduced in Section 3.1. Section 5 extends both the SDN semantics and our models to handle barriers and formalizes the soundness of this extension. Section 6 describes our DPORbased model checker which instantiates an o theshelf model checker for actor systems with tailored independence conditions to eciently verify SDNActor models. Section 7 describes the experimental evaluation of the tool. Related work and conclusions appear in Section 8. 2. Overview This section contains an overview of the technical contributions via an ex tended example, which we also use to introduces basic concepts and notations. 2.1. Concurrency errors in SDN networks SDN is a networking architecture where a central software controller can dynamically change how network switches forward packets by monitoring the trac. Switches can be connected to hosts and to other switches via bidirec tional channels that may reorder packets. Each switch has a  ow table , that is a collection of guarded forwarding rules to determine the route of incoming packets. Whenever a switch receives a packet, it checks if one of the  ow table rules applies. If no rule applies, the switch sends a message to the controller via a dedicated link, and the packet is buered until instructions arrive. Depending on its policy, the controller instructs the switch, and possibly other switches in the network, on how to update their  ow tables. Such control messages between the controller and the switches can be processed in arbitrary order. We now show how a simple loadbalancer can be implemented in SDN (exam ple taken from [6]) and how potential bugs can easily arise due to the concurrent 3S1CS2S3H0R2R10211001loadbalancer1201001 S2S3CS1Ô¨Årst round(R1 is chosen)second round(R2 is chosen){{456Figure 1: Example SDN loadbalancer. On the left: structure of the SDN. On the right: messages exchanged in a possible execution of a naive controller program. Coloured arrows stand for control messages to switches, indicating which  ow rule to install (colours specify the link to be used for the forwarding). Grey boxes and arrows among them represent packet forwardings. Dashed arrows indicate messages to the controller. behavior and asynchrony of message passing. Suppose we want to balance the trac to a server by using two replicas R1and R2to which the controller alter nates the trac in a roundrobin fashion. The structure of the SDN is shown in Figure 1, on the left: H0is any host that wants to communicate with the server and S1,S2and S3are switches (numbers on endpoints stand for port numbers). Even in this simple network, an incorrect implementation of the controller can lead to serious problems. In Figure 1, on the right, we show an execution of a naive controller, which simply instructs switches to forward packets along the shortest path to the chosen replica. This implementation ignores the potential concurrency in actions taken by switches and controller, leading to a forwarding loop between S1and S2. In the rst round, when S1queries the controller, R1is chosen. The gure shows S1forwarding the packet to S2before the end of the rst round, i.e., before a rule is installed on S2(green arrow). This causes S2 to query the controller, which triggers the second round in which the controller chooses R2. Thus, it sends instructions to install rules on S2,S1and S3to forward the packet to S1,S3and R2, respectively. When the controller rules arrive at S1, it will have two contradictory instructions, telling to forward the packet either to S2or to S3. In the former case, the loop at the bottom of the gure occurs. This issue can be avoided if the implementation uses barriers|the controller will then guarantee that S2receives and processes control messages before taking any other action. 2.2. Actorbased modelling of SDN networks We now explain how we can automatically detect the above problem using actors and model checking. We use the objectoriented actor language ABS [2, 7], where each actor type is specied as a class, consisting of a set of elds and methods. Actors are instances of actor classes. For instance, the instructions: Controller ctrl = new Controller(); Switch s1 = new Switch(""S1"",ctrl); Host h0 = 4new Host(""H0"",s1,0); create 3 actors: a controller ctrl; a switch s1with name ""S1"" and a reference to ctrl; a host h0, with name ""H0"" , connected to the switch s1via the port 0. The SDN in Figure 1 can be modeled using one actor per component (additional data structures for network links will be shown later). The execution model of actors is asynchronous . Each actor can be thought of as a processor, with a queue of pending tasks and a local memory. Actors are executed in parallel and, at each actor, one task is nondeterministically selected among all the pending ones and executed. The syntax Fut<type> f=a!m(x)spawns an asynchronous task m(x), that is added to the queue of pending tasks of a,type is the type of the data returned by morUnit if no data is returned. This task consists in executing the method mofawith arguments x. The variable fis afuture variable [8] that will allow us to check if such task has been completed. Lefthand side of the assignment can be omitted in case the future variable is not needed. A partial trace of execution of our SDN actor model computed by the model checker is (the code that the tasks below execute will be given in Section 4): 1:h0!sendIn1"
167,"Towards a Formal Framework for Mobile, Service-Oriented Sensor-Actuator Networks.txt","Service-oriented sensor-actuator networks (SOSANETs) are deployed in
health-critical applications like patient monitoring and have to fulfill strong
safety requirements. However, a framework for the rigorous formal modeling and
analysis of SOSANETs does not exist. In particular, there is currently no
support for the verification of correct network behavior after node failure or
loss/addition of communication links. To overcome this problem, we propose a
formal framework for SOSANETs. The main idea is to base our framework on the
\pi-calculus, a formally defined, compositional and well-established formalism.
We choose KLAIM, an existing formal language based on the \pi-calculus as the
foundation for our framework. With that, we are able to formally model SOSANETs
with possible topology changes and network failures. This provides the basis
for our future work on prediction, analysis and verification of the network
behavior of these systems. Furthermore, we illustrate the real-life
applicability of this approach by modeling and extending a use case scenario
from the medical domain.","Mobility and independence are some of the major factors dening the quality of life. With rising age people often develop physical and mental diseases of dierent degree in uencing their options for an independent and mobile life style. Serviceoriented sensoractuator networks (SOSANETs) [25] employed as assistant systems at home and en route can support the user by securing their everyday life. These networks are highly dynamic. New communication channels are built ad hoc, connecting the system with other previously unknown SOSANETs. These systems are healthcritical and have to fulll strong safety requirements. Up to now there exists no formal design framework for the verication and analysis of SOSANETs. The common approach is to evaluate network behavior by running test scenarios on prototypes or simulations. These tests do not cover the whole state space of the network and cannot ensure correct system behavior. In this paper, we address the problem of modeling dynamic SOSANETs. We require a formal modeling framework which oers techniques to model topology changes like the establishing of new connections or the sudden disappearance of a component. Especially the interaction with components, which were unknown at design level, has to be representable. Furthermore, we re quire the framework to oer features for modeling basic functionalities of serviceoriented archi tectures like service publishing. Additionally, the framework needs to be platformindependent to allow the representation of all kinds of nodes. Our idea is to base our framework on the pcalculus [20]. The pcalculus is a wellestablished formalism for the modeling of compositional and concurrent systems. It provides primitives for the description and analysis of distributed infrastructures. Furthermore, it oers the modeling50 Design Framework for SOSANETs foundation for the verication of correct network behavior after topology changes. We choose KLAIM [3], a formal language based on the pcalculus, as a foundation for our ap proach. It enriches the formalism by providing concrete actions for the manipulation of data within the network. In this paper we evaluate the applicability of KLAIM, which was de veloped for Wide Area Networks (WAN), for the modeling of SOSANETs. We consider the usability of the privileged node coordinator processes provided within KLAIM for the modeling of anticipated and unexpected topology changes in serviceoriented sensoractuator networks. Additionally, we assess the language to judge its ability to represent basic functions of a service oriented network. These are the service publishing, the service discover and the service request. Furthermore, we validate our observations by modeling an use case from the medical domain. The mentioned case study is a driver assistant system for the support of elderly driver. We extend the existing closed system to an open network to match our requirements. The open net is capable of interacting dynamically with expected new network components, e.g. portable medical devices like a pulse meter, and completely unknown networks, e.g. driver assistant sys tems installed in cars of dierent brands. The remainer of this paper is structured as follows. In Section 2 we discuss related work in the area of formal modeling and verication of sensoractuator networks and other distributed systems. This is followed by an introduction to SOSANETs, the pcalculus and KLAIM, the basis of our design framework, in Section 3. Section 4 illustrates our use case scenario and its proposed extension to an open network. We present a model of the driver assistant system and show the possibilities and limitations of KLAIM as a modeling language for SOSANETs in its current version. Afterwards, Section 5 concludes this paper and gives an outlook on future work. 2 Related work "
158,Towards Formal XAI: Formally Approximate Minimal Explanations of Neural Networks.txt,"With the rapid growth of machine learning, deep neural networks (DNNs) are
now being used in numerous domains. Unfortunately, DNNs are ""black-boxes"", and
cannot be interpreted by humans, which is a substantial concern in
safety-critical systems. To mitigate this issue, researchers have begun working
on explainable AI (XAI) methods, which can identify a subset of input features
that are the cause of a DNN's decision for a given input. Most existing
techniques are heuristic, and cannot guarantee the correctness of the
explanation provided. In contrast, recent and exciting attempts have shown that
formal methods can be used to generate provably correct explanations. Although
these methods are sound, the computational complexity of the underlying
verification problem limits their scalability; and the explanations they
produce might sometimes be overly complex. Here, we propose a novel approach to
tackle these limitations. We (1) suggest an efficient, verification-based
method for finding minimal explanations, which constitute a provable
approximation of the global, minimum explanation; (2) show how DNN verification
can assist in calculating lower and upper bounds on the optimal explanation;
(3) propose heuristics that significantly improve the scalability of the
verification process; and (4) suggest the use of bundles, which allows us to
arrive at more succinct and interpretable explanations. Our evaluation shows
that our approach significantly outperforms state-of-the-art techniques, and
produces explanations that are more useful to humans. We thus regard this work
as a step toward leveraging verification technology in producing DNNs that are
more reliable and comprehensible.","Machine learning (ML) is a rapidly growing eld with a wide range of applica tions, including safetycritical, highrisk systems in the elds of health care [19], aviation [39] and autonomous driving [12]. Despite their success, ML models, and especially deep neural networks (DNNs), remain \blackboxes"" | they are incomprehensible to humans and are prone to unexpected behaviour and errors. This issue can result in major catastrophes [13, 74], and also in poor decision making due to brittleness or bias [8,25]. In order to render DNNs more comprehensible to humans, researchers have been working on explainable AI (XAI), where we seek to construct models forarXiv:2210.13915v2  [cs.LG]  9 Feb 2023explaining and interpreting the decisions of DNNs [51,56{58]. Work to date has focused on heuristic approaches, which provide explanations, but do not provide guarantees about the correctness or succinctness of these explanations [14,33,45]. Although these approaches are an important step, their limitations might result in skewed results, possibly failing to meet the regulatory guidelines of institu tions and organizations such as the European Union, the US government, and the OECD [52]. Thus, producing DNN explanations that are provably accurate remains of utmost importance. More recently, the formal verication community has proposed approaches for providing formal and rigorous explanations for DNN decision making [28,32, 52,60]. Many of these approaches rely on the recent and rapid developments in DNN verication [1, 9, 10, 40]. These approaches typically produce an abductive explanation (also known as a prime implicant , or PIexplanation ) [32, 59, 60]: a minimum subset of input features, which by themselves already determine the classication produced by the DNN, regardless of any other input features. These explanations aord formal guarantees, and can be computed via DNN verication [32]. Abductive explanations are highly useful, but there are two major dicul ties in computing them. First, there is the issue of scalability: computing locally minimal explanations might require a polynomial number of costly invocations of the underlying DNN verier, and computing a globally minimal explanation is even more challenging [ ?,32,49]. The second diculty is that users may some times prefer \highlevel"" explanations, not based solely on input features, as these may be easier to grasp and interpret compared to \lowlevel"", complex, featurebased explanations. To tackle the rst diculty, we propose here new approaches for more e ciently producing vericationbased abductive explanations. More concretely, we propose a method for provably approximating minimum explanations, allowing stakeholders to use slightly larger explanations that can be discovered much more quickly. To accomplish this, we leverage the recently discovered dual relationship between explanations and contrastive examples [31]; and also take advantage of the sensitivity of DNNs to small adversarial perturbations [65], to compute both lower and upper bounds for the minimum explanation. In addition, we propose novel heuristics for signicantly expediting the underlying verication process. In addressing the second diculty, i.e. the interpretability limitations of \low level"" explanations, we propose to construct explanations in terms of bundles , which are sets of related features. We empirically show that using our method to produce bundle explanations can signicantly improve the interpretability of the results, and even the scalability of the approach, while still maintaining the soundness of the resulting explanations. To summarize, our contributions include the following: (i) We are the rst to suggest a method that formally produces sound and minimal abductive ex planations that provably approximate the globalminimum explanation. (ii) Our three suggested novel heuristics expedite the search for minimal abductive ex planations, signicantly outperforming the state of the art. (iii) We suggest anovel approach for using bundles to eciently produce sound and provable ex planations that are more interpretable and succinct. For evaluation purposes, we implemented our approach as a proofofconcept tool. Although our method can be applied to any ML model, we focused here on DNNs, where the verication process is known to be NPcomplete [40], and the scalable generation of explanations is known to be challenging [32, 59]. We used our tool to test the approach on DNNs trained for digit and clothing classi cation, and also compared it to stateoftheart approaches [32,33]. Our results indicate that our approach was successful in quickly producing meaningful ex planations, often running 40% faster than existing tools. We believe that these promising results showcase the potential of this line of work. The rest of the paper is organized as follows. Sec. 2 contains background on DNNs and their verication, as well as on formal, minimal explanations. Sec. 3 covers the main method for calculating approximations of minimum explana tions, and Sec. 4 covers methods for improving the eciency of calculating these approximations. Sec. 5 covers the use of bundles in constructing \highlevel"", provable explanations. Next, we present our evaluation in Sec. 6. Related work "
486,An Inductive Synthesis Framework for Verifiable Reinforcement Learning.txt,"Despite the tremendous advances that have been made in the last decade on
developing useful machine-learning applications, their wider adoption has been
hindered by the lack of strong assurance guarantees that can be made about
their behavior. In this paper, we consider how formal verification techniques
developed for traditional software systems can be repurposed for verification
of reinforcement learning-enabled ones, a particularly important class of
machine learning systems. Rather than enforcing safety by examining and
altering the structure of a complex neural network implementation, our
technique uses blackbox methods to synthesizes deterministic programs, simpler,
more interpretable, approximations of the network that can nonetheless
guarantee desired safety properties are preserved, even when the network is
deployed in unanticipated or previously unobserved environments. Our
methodology frames the problem of neural network verification in terms of a
counterexample and syntax-guided inductive synthesis procedure over these
programs. The synthesis procedure searches for both a deterministic program and
an inductive invariant over an infinite state transition system that represents
a specification of an application's control logic. Additional specifications
defining environment-based constraints can also be provided to further refine
the search space. Synthesized programs deployed in conjunction with a neural
network implementation dynamically enforce safety conditions by monitoring and
preventing potentially unsafe actions proposed by neural policies. Experimental
results over a wide range of cyber-physical applications demonstrate that
software-inspired formal verification techniques can be used to realize
trustworthy reinforcement learning systems with low overhead.","Neural networks have proven to be a promising software ar chitecture for expressing a variety of machine learning appli cations. However, nonlinearity and stochasticity inherent in their design greatly complicate reasoning about their behav ior. Many existing approaches to verifying [ 17,23,31,37] and testing [ 43,45,48] these systems typically attempt to tackle implementations headon, reasoning directly over the struc ture of activation functions, hidden layers, weights, biases, and other kinds of lowlevel artifacts that are farremovedfrom the specifications they are intended to satisfy. Moreover, the notion of safety verification that is typically considered in these efforts ignore effects induced by the actual envi ronment in which the network is deployed, significantly weakening the utility of any safety claims that are actually proven. Consequently, effective verification methodologies in this important domain still remains an open problem. To overcome these difficulties, we define a new verification toolchain that reasons about correctness extensionally, using a syntaxguided synthesis framework [ 5] that generates a simpler and more malleable deterministic program guaran teed to represent a safe control policy of a reinforcement learning (RL)based neural network, an important class of machine learning systems, commonly used to govern cyber physical systems such as autonomous vehicles, where high assurance is particularly important. Our synthesis procedure is designed with verification in mind, and is thus structured to incorporate formal safety constraints drawn from a logical specification of the control system the network purports to implement, along with additional salient environment prop erties relevant to the deployment context. Our synthesis procedure treats the neural network as an oracle, extract ing a deterministic program Pintended to approximate the policy actions implemented by the network. Moreover, our procedure ensures that a synthesized program Pis formally verified safe. To this end, we realize our synthesis proce dure via a counterexample guided inductive synthesis (CEGIS) loop [ 5] that eliminates any counterexamples to safety of P. More importantly, rather than repairing the network directly to satisfy the constraints governing P, we instead treatPas a safety shield that operates in tandem with the network, over riding networkproposed actions whenever such actions can be shown to lead to a potentially unsafe state. Our shielding mechanism thus retains performance, provided by the neural policy, while maintaining safety, provided by the program. Our approach naturally generalizes to infinite state systems with a continuous underlying action space. Taken together, these properties enable safety enforcement of RLbased neu ral networks without having to suffer a loss in performance to achieve high assurance. We show that over a range of cyberphysical applications defining various kinds of control systems, the overhead of runtime assurance is nominal, less than a few percent, compared to running an unproven, andarXiv:1907.07273v1  [cs.LG]  16 Jul 2019thus potentially unsafe, network with no shield support. This paper makes the following contributions: 1.We present a verification toolchain for ensuring that the control policies learned by an RLbased neural net work are safe. Our notion of safety is defined in terms of a specification of an infinite state transition system that captures, for example, the system dynamics of a cyberphysical controller. 2.We develop a counterexampleguided inductive syn thesis framework that treats the neural control policy as an oracle to guide the search for a simpler deter ministic program that approximates the behavior of the network but which is more amenable for verifi cation. The synthesis procedure differs from prior ef forts [ 9,47] because the search procedure is bounded by safety constraints defined by the specification (i.e., state transition system) as well as a characterization of specific environment conditions defining the appli cation‚Äôs deployment context. 3.We use a verification procedure that guarantees ac tions proposed by the synthesized program always lead to a state consistent with an inductive invariant of the original specification and deployed environment context. This invariant defines an inductive property that separates all reachable (safe) and unreachable (un safe) states expressible in the transition system. 4.We develop a runtime monitoring framework that treats the synthesized program as a safety shield [ 4], overriding proposed actions of the network whenever such actions can cause the system to enter into an unsafe region. We present a detailed experimental study over a wide range of cyberphysical control systems that justify the util ity of our approach. These results indicate that the cost of ensuring verification is low, typically on the order of a few percent. The remainder of the paper is structured as follows. In the next section, we present a detailed overview of our approach. Sec. 3 formalizes the problem and the context. De tails about the synthesis and verification procedure are given in Sec. 4. A detailed evaluation study is provided in Sec. 5. Related work and conclusions are given in Secs. 6 and 7, resp. 2 Motivation and Overview To motivate the problem and to provide an overview of our approach, consider the definition of a learningenabled con troller that operates an inverted pendulum. While the spec ification of this system is simple, it is nonetheless repre sentative of a number of practical control systems, such as Segway transporters and autonomous drones, that have thus far proven difficult to verify, but for which high assurance is very desirable. Figure 1. Inverted Pendulum State Transition System. The pendulum has mass mand length l. A system state is s= [Œ∑,œâ]TwhereŒ∑is the its angle and œâis its angular velocity. A continuous control action amaintains the pendulum upright. 2.1 State Transition System We model an inverted pendulum system as an infinite state transition system with continuous actions in Fig. 1. Here, the pendulum has mass mand length l. A system state is s= [Œ∑,œâ]TwhereŒ∑is the pendulum‚Äôs angle and œâis its angular velocity. A controller can use a 1dimensional continuous control action ato maintain the pendulum upright. Since modern controllers are typically implemented digi tally (using digitaltoanalog converters for interfacing be tween the analog system and a digital controller), we as sume that the pendulum is controlled in discrete time in stants ktwhere k=0,1,2,¬∑¬∑¬∑,i.e., the controller uses the system dynamics, the change of rate of s, denoted as√õs, to transition every ttime period, with the conjecture that the control action ais a constant during each discrete time in terval. Using Euler‚Äôs method, for example, a transition from state sk=s(kt)at time ktto time kt+tis approximated as s(kt+t)=s(kt)+√õs(kt)√ót. We specify the change of rate √õs using the differential equation shown in Fig. 1.1Intuitively, the control action ais allowed to affect the change of rate of Œ∑andœâto balance a pendulum. Thus, small values of aresult in small swing and velocity changes of the pendulum, ac tions that are useful when the pendulum is upright (or nearly so), while large values of acontribute to larger changes in swing and velocity, actions that are necessary when the pen dulum enters a state where it may risk losing balance. In case the system dynamics are unknown, we can use known algorithms to infer dynamics from online experiments [1]. Assume the state transition system of the inverted pendu lum starts from a set of initial states S0: S0:{(Œ∑,œâ)|‚àí 20‚ó¶‚â§Œ∑‚â§20‚ó¶‚àß‚àí20‚ó¶‚â§œâ‚â§20‚ó¶} The global safety property we wish to preserve is that the pendulum never falls down. We define a set of unsafe states Suof the transition system (colored in yellow in Fig. 1): Su:{(Œ∑,œâ)|¬¨(‚àí 90‚ó¶<Œ∑<90‚ó¶‚àß‚àí90‚ó¶<œâ<90‚ó¶)} 1We derive the control dynamics equations assuming that an inverted pendulum satisfies general Lagrangian mechanics and approximate non polynomial expressions with their Taylor expansions. 2Figure 2. The Framework of Our Approach. We assume the existence of a neural network control pol icyœÄw:R2‚ÜíRthat executes actions over the pendu lum, whose weight values of ware learned from training episodes. This policy is a statedependent function, mapping a2dimensional state s(Œ∑andœâ) to a control action a. At each transition, the policy mitigates uncertainty through feedback over state variables in s. Environment Context . An environment context C[¬∑] de fines the behavior of the application, where [¬∑]is left open to deploy a reasonable neural controller œÄw. The actions of the controller are dictated by constraints imposed by the en vironment. In its simplest form, the environment is simply a state transition system. In the pendulum example, this would be the equations given in Fig. 1, parameterized by pendulum mass and length. In general, however, the environment may include additional constraints ( e.g., a constraining bounding box that restricts the motion of the pendulum beyond the specification given by the transition system in Fig. 1). 2.2 Synthesis, Verification and Shielding In this paper, we assume that a neural network is trained using a stateoftheart reinforcement learning strategy [ 28, 40]. Even though the resulting neural policy may appear to work well in practice, the complexity of its implementation makes it difficult to assert any strong and provable claims about its correctness since the neurons, layers, weights and biases are farremoved from the intent of the actual controller. We found that stateoftheart neural network verifiers [ 17, 23] are ineffective for verification of a neural controller over an infinite time horizon with complex system dynamics. Framework. We construct a policy interpretation mecha nism to enable verification, inspired by prior work on im itation learning [ 36,38] and interpretable machine learn ing [ 9,47]. Fig. 2 depicts the highlevel framework of our approach. Our idea is to synthesize a deterministic policy program from a neural policy œÄw, approximating œÄw(which we call an oracle ) with a simpler structural program P. Like œÄw,Ptakes as input a system state and generates a control action a. To this end,Pis simulated in the environment used to train the neural policy œÄw, to collect feasible states. Guided byœÄw‚Äôs actions on such collected states, Pis further improved to resemble œÄw.The goal of the synthesis procedure is to search for a de terministic program P‚àósatisfying both (1) a quantitative specification such that it bears reasonably close resemblance to its oracle so that allowing it to serve as a potential sub stitute is a sensible notion, and (2) a desired logical safety property such that when in operation the unsafe states de fined in the environment Ccannot be reached. Formally, P‚àó=arg max P‚ààSafe(C,JHK)d(œÄw,P,C) (1) where d(œÄw,P,C)measures proximity of Pwith its neural oracle in an environment C;JHKdefines a search space for Pwith prior knowledge on the shape of target deterministic programs; and, Safe(C,JHK)restricts the solution space to a set of safe programs. A program Pis safe if the safety of the transition system C[P] , the deployment of Pin the environmentC, can be formally verified . The novelty of our approach against prior work on neural policy interpretation [9, 47] is thus twofold: 1.We bake in the concept of safety and formal safety verifi cation into the synthesis of a deterministic program from a neural policy as depicted in Fig. 2. If a candidate program is not safe, we rely on a counterexampleguided inductive synthesis loop to improve our synthesis outcome to en force the safety conditions imposed by the environment. 2.We allowPto operate in tandem with the highperforming neural policy.Pcan be viewed as capturing an inductive invariant of the state transition system, which can be used as a shield to describe a boundary of safe states within which the neural policy is free to make optimal control de cisions. If the system is about to be driven out of this safety boundary, the synthesized program is used to take an ac tion that is guaranteed to stay within the space subsumed by the invariant. By allowing the synthesis procedure to treat the neural policy as an oracle, we constrain the search space of feasible programs to be those whose ac tions reside within a proximate neighborhood of actions undertaken by the neural policy. Synthesis. Reducing a complex neural policy to a simpler yet safe deterministic program is possible because we do not require other properties from the oracle; specifically, we do not require that the deterministic program precisely mirrors the performance of the neural policy. For example, experiments described in [ 35] show that while a linearpolicy controlled robot can effectively stand up, it is unable to learn an efficient walking gait, unlike a sufficientlytrained neural policy. However, if we just care about the safety of the neural network, we posit that a linear reduction can be sufficiently expressive to describe necessary safety constraints. Based on this hypothesis, for our inverted pendulum example, we can explore a linear program space from which a deterministic programPŒ∏can be drawn expressed in terms of the following program sketch: 3defP[Œ∏1,Œ∏2](Œ∑,œâ): return Œ∏1Œ∑+Œ∏2œâ Here,Œ∏=[Œ∏1,Œ∏2]are unknown parameters that need to be synthesized. Intuitively, the program weights the importance ofŒ∑andœâat a particular state to provide a feedback control action to mitigate the deviation of the inverted pendulum from(Œ∑=0‚ó¶,œâ=0‚ó¶). Our searchbased synthesis sets Œ∏to0initially. It runs the deterministic program PŒ∏instead of the oracle neural policyœÄwwithin the environment Cdefined in Fig. 1 (in this case, the state transition system represents the differential equation specification of the controller) to collect a batch of trajectories. A run of the state transition system of C[PŒ∏] produces a finite trajectory s0,s1,¬∑¬∑¬∑,sT. We findŒ∏from the following optimization task that realizes (1): max Œ∏‚ààR2E[Œ£T t=0d(œÄw,PŒ∏,st)] (2) where d(œÄw,PŒ∏,st)‚â°( ‚àí(PŒ∏(st)‚àíœÄw(st))2st<Su ‚àíMAX s t‚ààSu. This equation aims to search for a program PŒ∏at minimal distance from the neural oracle œÄwalong sampled trajectories, while simultaneously maximizing the likelihood that PŒ∏is safe. Our synthesis procedure described in Sec. 4.1 is a random searchbased optimization algorithm [ 30]. We sample a new position of Œ∏iteratively from its hypersphere of a given small radius surrounding the current position of Œ∏and move to the new position ( w.r.t. a learning rate) as dictated by Equation (2). For the running example, our search synthesizes: defP(Œ∑,œâ): return‚àí12.05Œ∑+‚àí5.87œâ The synthesized program can be used to intuitively interpret how the neural oracle works. For example, if a pendulum with a positive angle Œ∑>0leans towards the right ( œâ>0), the controller will need to generate a large negative control action to force the pendulum to move left. Verification. Since our method synthesizes a deterministic programP, we can leverage offtheshelf formal verification algorithms to verify its safety with respect to the state transi tion systemCdefined in Fig. 1. To ensure that Pis safe, we must ascertain that it can never transition to an unsafe state, i.e., a state that causes the pendulum to fall. When framed as a formal verification problem, answering such a question is tantamount to discovering an inductive invariant œÜthat represents all safe states over the state transition system: 1.Safe:œÜis disjoint with all unsafe states Su, 2.Init:œÜincludes all initial states S0, 3.Induction: Any state in œÜtransitions to another state inœÜand hence cannot reach an unsafe state. Inspired by templatebased constraint solving approaches on inductive invariant inference [ 19,20,24,34], the verification algorithm described in Sec. 4.2 uses a constraint solver to look for an inductive invariant in the form of a convex barrier certificate [34]E(s)‚â§0that maps all the states in the (safe)reachable set to nonpositive reals and all the states in the unsafe set to positive reals. The basic idea is to identify a polynomial function E:Rn‚ÜíRsuch that 1) E(s)>0for any state s‚ààS u, 2)E(s)‚â§0for any state s‚ààS 0, and 3) E(s‚Ä≤)‚àíE(s)‚â§0for any state sthat transitions to s‚Ä≤in the state transition system C[P] . The second and third condition collectively guarantee that E(s)‚â§0for any state sin the reachable set, thus implying that an unsafe state in Sucan never be reached. Fig. 3(a) draws the discovered invariant in blue for C[P] given the initial and unsafe states where Pis the synthesized program for the inverted pendulum system. We can conclude that the safety property is satisfied by the Pcontrolled sys tem as all reachable states do not overlap with unsafe states. In case verification fails, our approach conducts a counterex ample guided loop (Sec. 4.2) to iteratively synthesize safe deterministic programs until verification succeeds. Shielding. Keep in mind that a safety proof of a reduced deterministic program of a neural network does not auto matically lift to a safety argument of the neural network from which it was derived since the network may exhibit behaviors not fully captured by the simpler deterministic program. To bridge this divide, we propose to recover sound ness at runtime by monitoring system behaviors of a neural network in its actual environment (deployment) context. Fig. 4 depicts our runtime shielding approach with more details given in Sec. 4.3. The inductive invariant œÜlearnt for a deterministic program Pof a neural network œÄwcan serve as ashield to protectœÄwat runtime under the environment context and safety property used to synthesize P. An obser vation about a current state is sent to both œÄwand the shield. A highperforming neural network is allowed to take any ac tions it feels are optimal as long as the next state it proposes is still within the safety boundary formally characterized by the inductive invariant of C[P] . Whenever a neural policy proposes an action that steers its controlled system out of the state space defined by the inductive invariant we have learned as part of deterministic program synthesis, our shield can instead take a safe action proposed by the deterministic programP. The action given by Pis guaranteed safe be causeœÜdefines an inductive invariant of C[P] ; taking the action allows the system to stay within the provably safe re gion identified by œÜ. Our shielding mechanism is sound due to formal verification. Because the deterministic program was synthesized using œÄwas an oracle, it is expected that the shield derived from the program will not frequently inter rupt the neural network‚Äôs decision, allowing the combined system to perform (closeto) optimally. In the inverted pendulum example, since the 90‚ó¶bound given as a safety constraint is rather conservative, we do not expect a welltrained neural network to violate this boundary. Indeed, in Fig. 3(a), even though the inductive invariant of the synthesized program defines a substantially smaller state space than what is permissible, in our simulation results, 4Figure 3. Invariant Inference on Inverted Pendulum. Figure 4. The Framework of Neural Network Shielding. we find that the neural policy is never interrupted by the deterministic program when governing the pendulum. Note that the nonshaded areas in Fig. 3(a), while appearing safe, presumably define states from which the trajectory of the system can be led to an unsafe state, and would thus not be inductive. Our synthesis approach is critical to ensuring safety when the neural policy is used to predict actions in an environment different from the one used during training. Consider a neu ral network suitably protected by a shield that now operates safely. The effectiveness of this shield would be greatly di minished if the network had to be completely retrained from scratch whenever it was deployed in a new environment which imposes different safety constraints. In our running example, suppose we wish to operate the inverted pendulum in an environment such as a Segway transporter in which the model is prohibited from swinging significantly and whose angular velocity must be suitably restricted. We might specify the following new constraints on state parameters to enforce these conditions: Su:{(Œ∑,œâ)|¬¨(‚àí 30‚ó¶<Œ∑<30‚ó¶‚àß‚àí30‚ó¶<œâ<30‚ó¶)} Because of the dependence of a neural network to the quality of training data used to build it, environment changes that deviate from assumptions made at trainingtime could result in a costly retraining exercise because the network must learn a new way to penalize unsafe actions that were previ ously safe. However, training a neural network from scratch requires substantial nontrivial effort, involving finegrained tuning of training parameters or even network structures. In our framework, the existing network provides a reason able approximation to the desired behavior. To incorporate the additional constraints defined by the new environmentC‚Ä≤, we attempt to synthesize a new deterministic program P‚Ä≤forC‚Ä≤, a task based on our experience is substantially easier to achieve than training a new neural network policy from scratch. This new program can be used to protect the original network provided that we can use the aforemen tioned verification approach to formally verify that C‚Ä≤[P‚Ä≤]is safe by identifying a new inductive invariant œÜ‚Ä≤. As depicted in Fig. 4, we simply build a new shield S‚Ä≤that is composed of the programP‚Ä≤and the safety boundary captured by œÜ‚Ä≤. The shieldS‚Ä≤can ensure the safety of the neural network in the environment context C‚Ä≤with a strengthened safety con dition, despite the fact that the neural network was trained in a different environment context C. Fig. 3(b) depicts the new unsafe states in C‚Ä≤(colored in red). It extends the unsafe range draw in Fig. 3(a) so the inductive invariant learned there is unsafe for the new one. Our approach synthesizes a new deterministic program for which we learn a more restricted inductive invariant de picted in green in Fig. 3(b). To characterize the effectiveness of our shielding approach, we examined 1000 simulation trajectories of this restricted version of the inverted pendu lum system, each of which is comprised of 5000 simulation steps with the safety constraints defined by C‚Ä≤. Without the shieldS‚Ä≤, the pendulum entered the unsafe region Su41 times. All of these violations were prevented by S‚Ä≤. Notably, the intervention rate of S‚Ä≤to interrupt the neural network‚Äôs decision was extremely low. Out of a total of 5000 √ó1000 de cisions, we only observed 414 instances (0.00828%) where the shield interfered with (i.e., overrode) the decision made by the network. 3 Problem Setup We model the context Cof a control policy as an environment state transition system C[¬∑] =(X,A,S,S0,Su,Tt[¬∑],f,r). Note that¬∑is intentionally left open to deploy neural control policies. Here, Xis a finite set of variables interpreted over the reals RandS=RXis the set of all valuations of the variables X. We denote s‚ààSto be an ndimensional envi ronment state and a‚ààA to be a control action where A is an infinite set of mdimensional continuous actions that a learningenabled controller can perform. We use S0‚ààS to specify a set of initial environment states and Su‚ààSto specify a set of unsafe environment states that a safe con troller should avoid. The transition relation Tt[¬∑]defines how one state transitions to another given an action by an un known policy. We assume that Tt[¬∑]is governed by a standard differential equation fdefining the relationship between a continuously varying state s(t)and action a(t)and its rate of change√õs(t)over time t: √õs(t)=f(s(t),a(t)) We assume fis defined by equations of the form: Rn√óRm‚Üí Rnsuch as the example in Fig. 1. In the following, we often omit the time variable tfor simplicity. A deterministic neural 5network control policy œÄw:Rn‚ÜíRmparameterized by a set of weight values wis a function mapping an environment state sto a control action awhere a=œÄw(s) By providing a feedback action, a policy can alter the rate of change of state variables to realize optimal system control. The transition relation Tt[¬∑]is parameterized by a con trol policy œÄthat is deployed in C. We explicitly model this deployment as Tt[œÄ]. Given a control policy œÄw, we useTt[œÄw]:S√óS to specify all possible state transitions allowed by the policy. We assume that a system transitions in discrete time instants ktwhere k=0,1,2,¬∑¬∑¬∑andtis a fixed time step ( t>0). A state stransitions to a next state s‚Ä≤ after time twith the assumption that a control action a(œÑ)at timeœÑis a constant between the time period œÑ‚àà[0,t). Us ing Euler‚Äôs method2, we discretize the continuous dynamics fwith finite difference approximation so it can be used in the discretized transition relation Tt[œÄw]. ThenTt[œÄw]can compute these estimates by the following difference equation : Tt[œÄw]:={(s,s‚Ä≤)|s‚Ä≤=s+f(s,œÄw(s))√ót} Environment Disturbance . Our model allows bounded external properties ( e.g., additional environmentimposed constraints) by extending the definition of change of rate: √õs= f(s,a)+dwhere dis a vector of random disturbances. We use dto encode environment disturbances in terms of bounded nondeterministic values. We assume that tight upper and lower bounds of dcan be accurately estimated at runtime using multivariate normal distribution fitting methods. Trajectory. A trajectory hof a state transition system C[œÄw] which we denote as h‚àà C[œÄw]is a sequence of states s0,¬∑¬∑¬∑,si,si+1,¬∑¬∑¬∑where s0‚ààS 0and(si,si+1)‚ààT t[œÄw]for alli‚â•0. We use C‚äÜC[œÄw]to denote a set of trajectories. The reward that a control policy receives on performing an action ain a state sis given by the reward function r(s,a). Reinforcement Learning. The goal of reinforcement learn ing is to maximize the reward that can be collected by a neu ral control policy in a given environment context C. Such problems can be abstractly formulated as max w‚ààRnJ(w) J(w)=E[r(œÄw)](3) Assume that s0,s1, . . . , sTis a trajectory of length Tof the state transition system and r(œÄw)=lim T‚Üí‚àûŒ£T k=0r(sk,œÄw(sk)) is the cumulative reward achieved by the policy œÄwfrom this trajectory. Thus this formulation uses simulations of the transition system with finite length rollouts to estimate the expected cumulative reward collected over Ttime steps and aim to maximize this reward. Reinforcement learning 2Euler‚Äôs method may sometimes poorly approximate the true system tran sition function when fis highly nonlinear. More precise higherorder ap proaches such as RungeKutta methods exist to compensate for loss of precision in this case.assumes polices are expressible in some executable structure (e.g.a neural network) and allows samples generated from one policy to influence the estimates made for others. The two main approaches for reinforcement learning are value function estimation and direct policy search. We refer readers to [27] for an overview. Safety Verification. Since reinforcement learning only con siders finite length rollouts, we wish to determine if a control policy is safe to use under an infinite time horizon. Given a state transition system, the safety verification problem is concerned with verifying that no trajectories contained in S starting from an initial state in S0reach an unsafe state in Su. However, a neural network is a representative of a class of deep and sophisticated models that challenges the capability of the stateoftheart verification techniques. This level of complexity is exacerbated in our work because we consider the long term safety of a neural policy deployed within a nontrivial environment context Cthat in turn is described by a complex infinitestate transition system. 4 Verification Procedure To verify a neural network control policy œÄwwith respect to an environment context C, we first synthesize a deterministic policy programPfrom the neural policy. We require that P both ( a) broadly resembles its neural oracle and ( b) addition ally satisfies a desired safety property when it is deployed inC. We conjecture that a safety proof of C[P] is easier to construct than that of C[œÄw]. More importantly, we leverage the safety proof of C[P] to ensure the safety of C[œÄw]. 4.1 Synthesis Fig. 5 defines a search space for a deterministic policy pro gramPwhere EandœÜrepresent the basic syntax of (polyno mial) program expressions and inductive invariants, respec tively. Here vranges over a universe of numerical constants, xrepresents variables, and ‚äïis a basic operator including + and√ó. A deterministic program Palso features conditional statements using œÜas branching predicates. We allow the user to define a sketch [ 41,42] to describe the shape of target policy programs using the grammar in Fig. 5. We useP[Œ∏]to represent a sketch where Œ∏represents unknowns that need to be filledin by the synthesis proce dure. We usePŒ∏to represent a synthesized program with known values of Œ∏. Similarly, the user can define a sketch of an inductive invariant œÜ[¬∑]that is used (in Sec. 4.2) to learn a safety proof to verify a synthesized program PŒ∏. We do not require the user to explicitly define conditional statements in a program sketch. Our synthesis algorithm uses verification counterexamples to lazily add branch predicates œÜunder which a program performs different computations depending on whether œÜevaluates to true or false. The end user simply writes a sketch over basic expressions. For ex ample, a sketch that defines a family of linear function over 6E::=v|x| ‚äï( E1, . . . , Ek) œÜ::=E‚â§0 P::=return E|ifœÜthen return EelseP Figure 5. Syntax of the Policy Programming Language. Algorithm 1: Synthesize ( œÄw,P[Œ∏],C[¬∑]) 1Œ∏‚Üê0; 2do 3 SampleŒ¥from a zero mean Gaussian vector; 4 Sample a set of trajectories C1usingC[PŒ∏+ŒΩŒ¥]; 5 Sample a set of trajectories C2usingC[PŒ∏‚àíŒΩŒ¥]; 6Œ∏‚ÜêŒ∏+Œ±[d(œÄw,PŒ∏+ŒΩ Œ¥ ,C1)‚àíd(œÄw,PŒ∏‚àíŒΩ Œ¥ ,C2) ŒΩ]Œ¥; 7whileŒ∏is not converged ; 8returnPŒ∏ a collection of variables can be expressed as: P[Œ∏](X)::=returnŒ∏1x1+Œ∏2x2+¬∑¬∑¬∑+Œ∏nxn+Œ∏n+1(4) Here X=(x1,x2,¬∑¬∑¬∑) are system variables in which the coefficient constants Œ∏=(Œ∏1,Œ∏2,¬∑¬∑¬∑) are unknown. The goal of our synthesis algorithm is to find unknown values ofŒ∏that maximize the likelihood that PŒ∏resembles the neural oracle œÄwwhile still being a safe program with respect to the environment context C: Œ∏‚àó=arg max Œ∏‚ààRn+1d(œÄw,PŒ∏,C) (5) where dmeasures the distance between the outputs of the estimate program PŒ∏and the neural policy œÄwsubject to safety constraints. To avoid the computational complexity that arises if we consider a solution to this equation analyti cally as an optimization problem, we instead approximate d(œÄw,PŒ∏,C)by randomly sampling a set of trajectories C that are encountered by PŒ∏in the environment state transi tion systemC[PŒ∏]: d(œÄw,PŒ∏,C)‚âà d(œÄw,PŒ∏,C)s.t.C‚äÜC[PŒ∏] We estimate Œ∏‚àóusing these sampled trajectories Cand define: d(œÄw,PŒ∏,C)=√ï h‚ààCd(œÄw,PŒ∏,h) Since each trajectory h‚ààCis a finite rollout s0, . . . , sTof length T, we have: d(œÄw,PŒ∏,h)=T√ï t=0( ‚àí‚à•(PŒ∏(st)‚àíœÄw(st))‚à•st<Su ‚àíMAX s t‚ààSu where‚à•¬∑‚à•is a suitable norm. As illustrated in Sec. 2.2, we aim to minimize the distance between a synthesized program PŒ∏from a sketch space and its neural oracle along sampled trajectories encountered by PŒ∏in the environment context but put a large penalty on states that are unsafe.Random Search. We implement the idea encoded in equa tion (5)in Algorithm 1 that depicts the pseudocode of our policy interpretation approach. It take as inputs a neural policy, a policy program sketch parameterized by Œ∏, and an environment state transition system and outputs a synthe sized policy program PŒ∏. An efficient way to solve equation (5)is to directly perturb Œ∏in the search space by adding random noise and then updateŒ∏based on the effect on this perturbation [ 30]. We choose a direction uniformly at random on the sphere in parameter space, and then optimize the goal function along this direction. To this end, in line 3 of Algorithm 1, we sample Gaussian noise Œ¥to be added to policy parameters Œ∏in both directions where ŒΩis a small positive real number. In line 4 and line 5, we sample trajectories C1andC2from the state transition systems obtained by running the perturbed policy programPŒ∏+ŒΩŒ¥andPŒ∏‚àíŒΩŒ¥in the environment context C. We evaluate the proximity of these two policy programs to the neural oracle and, in line 6 of Algorithm 1, to improve the policy program, we also optimize equation (5)by updating Œ∏ with a finite difference approximation along the direction: Œ∏‚ÜêŒ∏+Œ±[d(PŒ∏+ŒΩŒ¥,œÄw,C1)‚àíd(PŒ∏‚àíŒΩŒ¥,œÄw,C2) ŒΩ]Œ¥ (6) whereŒ±is a predefined learning rate. Such an update incre ment corresponds to an unbiased estimator of the gradient of Œ∏[29,33] for equation (5). The algorithm iteratively updates Œ∏until convergence. 4.2 Verification A synthesized policy program Pis verified with respect to an environment context given as an infinite state transition sys tem defined in Sec. 3: C[P] =(X,A,S,S0,Su,Tt[P],f,r). Our verification algorithm learns an inductive invariant œÜ over the transition relation Tt[P]formally proving that all possible system behaviors are encapsulated in œÜandœÜis required to be disjoint with all unsafe states Su. We follow templatebased constraint solving approaches for inductive invariant inference [ 19,20,24,34] to discover this invariant. The basic idea is to identify a function E: Rn‚ÜíRthat serves as a ""barrier"" [ 20,24,34] between reach able system states (evaluated to be nonpositive by E), and unsafe states (evaluated positive by E). Using the invariant syntax in Fig. 5, the user can define an invariant sketch œÜ[c](X)::=E[c](X)‚â§0 (7) over variables Xandcunknown coefficients intended to be synthesized. Fig. 5 carefully restricts that an invariant sketch E[c]can only be postulated as a polynomial function as there exist efficient SMT solvers [ 13] and constraint solvers [ 26] for nonlinear polynomial reals. Formally, assume real coef ficients c=(c0,¬∑¬∑¬∑,cp)are used to parameterize E[c]in an affine manner: E[c](X)=Œ£p i=0cibi(X) 7where the bi(X)‚Äôs are some monomials in variables X. As a heuristic, the user can simply determine an upper bound on the degree of E[c], and then include all monomials whose degrees are no greater than the bound in the sketch. Large values of the bound enable verification of more complex safety conditions, but impose greater demands on the con straint solver; small values capture coarser safety properties, but are easier to solve. Example 4.1. Consider the inverted pendulum system in Sec. 2.2. To discover an inductive invariant for the transition system, the user might choose to define an upper bound of 4, which results in the following polynomial invariant sketch: œÜ[c](Œ∑,œâ)::=E[c](Œ∑,œâ)‚â§0where E[c](Œ∑,œâ)=c0Œ∑4+c1Œ∑3œâ+c2Œ∑2œâ2+c3Œ∑œâ3+c4œâ4+c5Œ∑3+¬∑¬∑¬∑+cp The sketch includes all monomials over Œ∑andœâ, whose de grees are no greater than 4. The coefficients c=[c0,¬∑¬∑¬∑,cp] are unknown and need to be synthesized. To synthesize these unknowns, we require that E[c]must satisfy the following verification conditions: ‚àÄ(s)‚ààS u E[c](s)>0 (8) ‚àÄ(s)‚ààS 0 E[c](s)‚â§0 (9) ‚àÄ(s,s‚Ä≤)‚ààT t[P] E[c](s‚Ä≤)‚àíE[c](s)‚â§0. (10) We claim that œÜ::=E[c](x) ‚â§ 0defines an inductive in variant because verification condition (9)ensures that any initial state s0‚ààS0satisfiesœÜsince E[c](s0)‚â§0; verification condition (10)asserts that along the transition from a state s‚ààœÜ(soE[c](s)‚â§ 0) to a resulting state s‚Ä≤,E[c]cannot become positive so s‚Ä≤satisfiesœÜas well. Finally, according to verification condition (8),œÜdoes not include any unsafe state su‚ààSuasE[c](su)is positive. Verification conditions (8) (9) (10) are polynomials over re als. Synthesizing unknown coefficients can be left to an SMT solver [ 13] after universal quantifiers are eliminated using a variant of Farkas Lemma as in [ 20]. However, observe that E[c]is convex.3We can gain efficiency by finding unknown coefficients cusing offtheshelf convex constraint solvers following [ 34]. Encoding verification conditions (8) (9) (10) as polynomial inequalities, we search cthat can prove non negativity of these constraints via an efficient and convex sum of squares programming solver [ 26]. Additional techni cal details are provided in the supplementary material [49]. Counterexampleguided Inductive Synthesis (CEGIS) . Given the environment state transition system C[P] de ployed with a synthesized program P, the verification ap proach above can compute an inductive invariant over the state transition system or tell if there is no feasible solution in the given set of candidates. Note however that the latter does not necessarily imply that the system is unsafe. 3For arbitrary E1(x)andE2(x)satisfying the verification conditions and Œ±‚àà[0,1],E(x)=Œ±E1(x)+(1‚àíŒ±)E2(x)satisfies the conditions as well.Algorithm 2: CEGIS (œÄw,P[Œ∏],C[¬∑]) 1policies‚Üê‚àÖ; 2covers‚Üê‚àÖ; 3whileC.S0‚äàcovers do 4 search s0such that s0‚ààC.S0‚àßs0<covers ; 5 r‚àó‚ÜêDiameter(C.S0); 6 do 7œïbound‚Üê{s|s‚àà{s0‚àír‚àó,s0+r‚àó}}; 8 ÀúC‚ÜêC where ÀúC.S0=(C.S0‚à©œïbound); 9Œ∏‚ÜêSynthesize( œÄw,P[Œ∏],ÀúC[¬∑]); 10 œÜ‚ÜêVerify( ÀúC[PŒ∏]); 11 ifœÜis False then 12 r‚àó‚Üêr‚àó/2; 13 else 14 covers‚Üêcovers‚à™{s|œÜ(s)}; 15 policies‚Üêpolicies‚à™(PŒ∏,œÜ); 16 break; 17 while True; 18end 19return policies Since our goal is to learn a safe deterministic program from a neural network, we develop a counterexample guided inductive program synthesis approach. A CEGIS algorithm in our context is challenging because safety verification is necessarily incomplete, and may not be able to produce a counterexample that serves as an explanation for why a verification attempt is unsuccessful. We solve the incompleteness challenge by leveraging the fact that we can simultaneously synthesize and verify a program. Our CEGIS approach is given in Algorithm 2. A counterexample is an initial state on which our synthesized program is not yet proved safe. Driven by these counterex amples, our algorithm synthesizes a set of programs from a sketch along with the conditions under which we can switch from from one synthesized program to another. Algorithm 2 takes as input a neural policy œÄw, a program sketchP[Œ∏]and an environment context C. It maintains syn thesized policy programs in policies in line 1, each of which is inductively verified safe in a partition of the universe state space that is maintained in covers in line 2. For soundness, the state space covered by such partitions must be able to include all initial states, checked in line 3 of Algorithm 2 by an SMT solver. In the algorithm, we use C.S0to access a field ofCsuch as its initial state space. The algorithm iteratively samples a counterexample initial state s0that is currently not covered by covers in line 4. Since covers is empty at the beginning, this choice is uniformly random initially; we synthesize a presumably safe policy program in line 9 of Algorithm 2 that resembles the neural policyœÄwconsidering all possible initial states S0of the given environment model C, using Algorithm 1. 8Figure 6. CEGIS for Verifiable Reinforcement Learning. If verification fails in line 11, our approach simply reduces the initial state space, hoping that a safe policy program is easier to synthesize if only a subset of initial states are con sidered. The algorithm in line 12 gradually shrinks the radius r‚àóof the initial state space around the sampled initial state s0. The synthesis algorithm in the next iteration synthesizes and verifies a candidate using the reduced initial state space. The main idea is that if the initial state space is shrunk to a restricted area around s0but a safety policy program still cannot be found, it is quite possible that either s0points to an unsafe initial state of the neural oracle or the sketch is not sufficiently expressive. If verification at this stage succeeds with an inductive invariantœÜ, a new policy program PŒ∏is synthesized that can be verified safe in the state space covered by œÜ. We add the inductive invariant and the policy program into covers andpolicies in line 14 and 15 respectively and then move to another iteration of counterexampleguided synthesis. This iterative synthesizeandverify process continues until the entire initial state space is covered (line 3 to 18). The output of Algorithm 2 is[(PŒ∏1,œÜ1),(PŒ∏2,œÜ2),¬∑¬∑¬∑] that essentially defines conditional statements in a synthesized program per forming different actions depending on whether a specified invariant condition evaluates to true or false. Theorem 4.2. IfCEGIS(œÄw,P[Œ∏],C[¬∑]) =[(PŒ∏1,œÜ1),(PŒ∏2, œÜ2),¬∑¬∑¬∑] (as defined in Algorithm 2), then the deterministic programP: ŒªX.ifœÜ1(X): returnPŒ∏1(X)else ifœÜ2(X): returnPŒ∏2(X) ¬∑¬∑¬∑ is safe in the environment Cmeaning that œÜ1‚à®œÜ2‚à®¬∑¬∑¬∑ is an inductive invariant of C[P] proving thatC.Suis unreachable. Example 4.3. We illustrate the proposed counterexample guided inductive synthesis method by means of a simple ex ample, the Duffing oscillator [ 22], a nonlinear secondorder environment. The transition relation of the environment systemCis described with the differential equation: √õx=y √õy=‚àí0.6y‚àíx‚àíx3+awhere x,yare the state variables and athe continuous con trol action given by a welltrained neural feedback control policyœÄsuch that a=œÄ(x,y). The control objective is to regulate the state to the origin from a set of initial states C.S0:{x,y|‚àí2.5‚â§x‚â§2.5‚àß‚àí2‚â§y‚â§2}. To be safe, the controller must be able to avoid a set of unsafe statesC.Su:{x,y|¬¨(‚àí 5‚â§x‚â§5‚àß‚àí5‚â§y‚â§5)}. Given a program sketch as in the pendulum example, that is P[Œ∏](x,y)::=Œ∏1x+Œ∏2y, the user can ask the constraint solver to reason over a small (say 4) order polynomial invariant sketch for a synthesized program as in Example 4.1. Algorithm 2 initially samples an initial state sas{x= ‚àí0.46,y=‚àí0.36}fromS0. The inner dowhile loop of the algorithm can discover a subregion of initial states in the dotted box of Fig. 6(a) that can be leveraged to synthesize a verified deterministic policy P1(x,y)::=0.39x‚àí1.41yfrom the sketch. We also obtain an inductive invariant showing that the synthesized policy can always maintain the con troller within the invariant set drawn in purple in Fig. 6(a): œÜ1‚â°20.9x4+2.9x3y+1.4x2y2+0.4xy3+29.6x3+20.1x2y+ 11.3xy2+1.6y3+25.2x2+39.2xy+53.7y2‚àí680‚â§0. This invariant explains why the initial state space used for verification does not include the entire C.S0: a coun terexample initial state s‚Ä≤={x=2.249,y=2}is not cov ered by the invariant for which the synthesized policy pro gram above is not verified safe. The CEGIS loop in line 3 of Algorithm 2 uses s‚Ä≤to synthesize another deterministic policyP2(x,y)::=0.88x‚àí2.34yfrom the sketch whose learned inductive invariant is depicted in blue in Fig. 2(b): œÜ2‚â°12.8x4+0.9x3y‚àí0.2x2y2‚àí5.9x3‚àí1.5xy2‚àí0.3y3+ 2.2x2+4.7xy+40.4y2‚àí619‚â§0. Algorithm 2 then termi nates because œÜ1‚à®œÜ2coversC.S0. Our system interprets the two synthesized deterministic policies as the following deterministic program Poscillator using the syntax in Fig. 5: defPoscillator(x,y): if20.9x4+2.9x3y+1.4x2y2+¬∑¬∑¬∑+53.7y2‚àí680‚â§0: #œÜ1 return 0.39x‚àí1.41y else if 12.8x4+0.9x3y‚àí0.2x2y2+¬∑¬∑¬∑+40.4y2‚àí619‚â§0: #œÜ2 return 0.88x‚àí2.34y else abort # unsafe Neither of the two deterministic policies enforce safety by themselves on all initial states but do guarantee safety when combined together because by construction, œÜ=œÜ1‚à®œÜ2is an inductive invariant of Poscillator in the environment C. Although Algorithm 2 is sound, it may not terminate as r‚àóin the algorithm can become arbitrarily small and there is also no restriction on the size of potential counterexam ples. Nonetheless, our experimental results indicate that the algorithm performs well in practice. 4.3 Shielding A safety proof of a synthesized deterministic program of a neural network does not automatically lift to a safety ar gument of the neural network from which it was derived 9Algorithm 3: Shield ( s,C[œÄw],P,œÜ) 1Predict s‚Ä≤such that(s,s‚Ä≤)‚ààC[œÄw].Tt(s); 2ifœÜ(s‚Ä≤)then return œÄw(s); 3else returnP(s); since the network may exhibit behaviors not captured by the simpler deterministic program. To bridge this divide, we recover soundness at runtime by monitoring system behav iors of a neural network in its environment context by using the synthesized policy program and its inductive invariant as a shield. The pseudocode for using a shield is given in Algorithm 3. In line 1 of Algorithm 3, for a current state s, we use the state transition system of our environment context model to predict the next state s‚Ä≤. Ifs‚Ä≤is not within œÜ, we are unsure whether entering s‚Ä≤would inevitably make the system unsafe as we lack a proof that the neural oracle is safe. However, we do have a guarantee that if we follow the synthesized program P, the system would stay within the safety boundary defined by œÜthat Algorithm 2 has formally proved. We do so in line 3 of Algorithm 3, using PandœÜ as shields, intervening only if necessary so as to restrict the shield from unnecessarily intervening the neural policy.4 5 Experimental Results We have applied our framework on a number of challenging control and cyberphysicalsystem benchmarks. We consider the utility of our approach for verifying the safety of trained neural network controllers. We use the deep policy gradi ent algorithm [ 28] for neural network training, the Z3 SMT solver [ 13] to check convergence of the CEGIS loop, and the Mosek constraint solver [ 6] to generate inductive in variants of synthesized programs from a sketch. All of our benchmarks are verified using the program sketch defined in equation (4)and the invariant sketch defined in equation (7). We report simulation results on our benchmarks over 1000 runs (each run consists of 5000 simulation steps). Each simu lation time step is fixed 0.01 second. Our experiments were conducted on a standard desktop machine consisting of In tel(R) Core(TM) i78700 CPU cores and 64GB memory. Case Study on Inverted Pendulum. We first give more de tails on the evaluation result of our running example, the inverted pendulum. Here we consider a more restricted safety condition that deems the system to be unsafe when the pen dulum‚Äôs angle is more than 23‚ó¶from the origin ( i.e.,signif icant swings are further prohibited). The controller is a 2 hiddenlayer neural model ( 240√ó200). Our tool interprets the neural network as a program containing three conditional branches: defP (Œ∑,œâ): 4We also extended our approach to synthesize deterministic programs which can guarantee stability in the supplementary material [49].if17533Œ∑4+13732Œ∑3œâ+3831Œ∑2œâ2‚àí5472Œ∑œâ3+8579œâ4+6813Œ∑3+ 9634Œ∑2œâ+3947Œ∑œâ2‚àí120œâ3+1928Œ∑2+1915Œ∑œâ+1104œâ2‚àí313‚â§0: return‚àí17.28176866Œ∑‚àí10.09441768œâ else if 2485Œ∑4+826Œ∑3œâ‚àí351Œ∑2œâ2+581Œ∑œâ3+2579œâ4+591Œ∑3+ 9Œ∑2œâ+243Œ∑œâ2‚àí189œâ3+484Œ∑2+170Œ∑œâ+287œâ2‚àí82‚â§0: return‚àí17.34281984 x‚àí10.73944835y else if 115496Œ∑4+64763Œ∑3œâ+85376Œ∑2œâ2+21365Œ∑œâ3+7661œâ4‚àí 111271Œ∑3‚àí54416Œ∑2œâ‚àí66684Œ∑œâ2‚àí8742œâ3+33701Œ∑2+ 11736Œ∑œâ+12503œâ2‚àí1185‚â§0: return‚àí25.78835525Œ∑‚àí16.25056971œâ else abort Over 1000 simulation runs, we found 60 unsafe cases when running the neural controller alone. Importantly, running the neural controller in tandem with the above verified and synthesized program can prevent all unsafe neural decisions. There were only with 65 interventions from the program on the neural network. Our results demonstrate that CEGIS is important to ensure a synthesized program is safe to use. We report more details including synthesis times below. One may ask why we do not directly learn a deterministic program to control the device (without appealing to the neu ral policy at all), using reinforcement learning to synthesize its unknown parameters. Even for an example as simple as the inverted pendulum, our discussion above shows that it is difficult (if not impossible) to derive a single straightline (linear) program that is safe to control the system. Even for scenarios in which a straightline program suffices, using ex isting RL methods to directly learn unknown parameters in our sketches may still fail to obtain a safe program. For exam ple, we considered if a linear control policy can be learned to (1) prevent the pendulum from falling down (2) and require a pendulum control action to be strictly within the range [‚àí1,1](e.g., operating the controller in an environment with low power constraints). We found that despite many experi ments on tuning learning rates and rewards, directly training a linear control program to conform to this restriction with either reinforcement learning (e.g. policy gradient) or ran dom search [ 29] was unsuccessful because of undesirable overfitting. In contrast, neural networks work much better for these RL algorithms and can be used to guide the syn thesis of a deterministic program policy. Indeed, by treating the neural policy as an oracle, we were able to quickly dis cover a straightline linear deterministic program that in fact satisfies this additional motion constraint. Safety Verification. Our verification results are given in Table 1. In the table, Vars represents the number of variables in a control system  this number serves as a proxy for ap plication complexity; Size the number of neurons in hidden layers of the network; the Training time for the network; and, its Failures , the number of times the network failed to satisfy the safety property in simulation. The table also gives theSize of a synthesized program in term of the number of polices found by Algorithm 2 (used to generate condi tional statements in the program); its Synthesis time; the Overhead of our approach in terms of the additional cost 10Table 1. Experimental Results on Deterministic Program Synthesis, Verification, and Shielding. Neural Network Deterministic Program as Shield PerformanceBenchmarks VarsSize Training Failures Size Synthesis Overhead Interventions NN Program Satellite 2 240√ó200 957s 0 1 160s 3.37% 0 5.7 9.7 DCMotor 3 240√ó200 944s 0 1 68s 2.03% 0 11.9 12.2 Tape 3 240√ó200 980s 0 1 42s 2.63% 0 3.0 3.6 Magnetic Pointer 3 240√ó200 992s 0 1 85s 2.92% 0 8.3 8.8 Suspension 4 240√ó200 960s 0 1 41s 8.71% 0 4.7 6.1 Biology 3 240√ó200 978s 0 1 168s 5.23% 0 2464 2599 DataCenter Cooling 3 240√ó200 968s 0 1 168s 4.69% 0 14.6 40.1 Quadcopter 2 300√ó200 990s 182 2 67s 6.41% 185 7.2 9.8 Pendulum 2 240√ó200 962s 60 3 1107s 9.65% 65 44.2 58.6 CartPole 4 300√ó200 990s 47 4 998s 5.62% 1799 681.3 1912.6 SelfDriving 4 300√ó200 990s 61 1 185s 4.66% 236 145.9 513.6 Lane Keeping 4 240√ó200 895s 36 1 183s 8.65% 64 375.3 643.5 4Car platoon 8 500√ó400√ó300 1160s 8 4 609s 3.17% 8 7.6 9.6 8Car platoon 16 500√ó400√ó300 1165s 40 1 1217s 6.05% 1080 38.5 55.4 Oscillator 18 240√ó200 1023s 371 1 618s 21.31% 93703 693.5 1135.3 (compared to the nonshielded variant) in running time to use a shield; and, the number of Interventions , the number of times the shield was invoked across all simulation runs. We also report performance gap between of a shield neural policy ( NN) and a purely programmatic policy ( Program ), in terms of the number of steps on average that a controlled system spends in reaching a steady state of the system ( i.e., a convergence state). The first five benchmarks are linear timeinvariant control systems adapted from [ 15]. The safety property is that the reach set has to be within a safe rectangle. Benchmark Biol ogydefines a minimal model of glycemic control in diabetic patients such that the dynamics of glucose and insulin inter action in the blood system are defined by polynomials [ 10]. For safety, we verify that the neural controller ensures that the level of plasma glucose concentration is above a certain threshold. Benchmark DataCenter Cooling is a model of a collection of three server racks each with their own cooling devices and they also shed heat to their neighbors. The safety property is that a learned controller must keep the data cen ter below a certain temperature. In these benchmarks, the cost to query the network oracle constitutes the dominant time for generating the safety shield in these benchmarks. Given the simplicity of these benchmarks, the neural net work controllers did not violate the safety condition in our trials, and moreover there were no interventions from the safety shields that affected performance. The next three benchmarks Quadcopter ,(Inverted) Pen dulum andCartpole are selected from classic control appli cations and have more sophisticated safety conditions. We have discussed the inverted pendulum example at length earlier. The Quadcopter environment tests whether a con trolled quadcopter can realize stable flight. The environment ofCartpole consists of a pole attached to an unactuated jointconnected to a cart that moves along a frictionless track. The system is unsafe when the pole‚Äôs angle is more than 30‚ó¶from being upright or the cart moves by more than 0.3 meters from the origin. We observed safety violations in each of these benchmarks that were eliminated using our verifi cation methodology. Notably, the number of interventions is remarkably low, as a percentage of the overall number of simulation steps. Benchmark Selfdriving defines a single car navigation problem. The neural controller is responsible for prevent ing the car from veering into canals found on either side of the road. Benchmark Lane Keeping models another safety related cardriving problem. The neural controller aims to maintain a vehicle between lane markers and keep it cen tered in a possibly curved lane. The curvature of the road is considered as a disturbance input. Environment disturbances of such kind can be conservatively specified in our model, accounting for noise and unmodeled dynamics. Our verifi cation approach supports these disturbances (verification condition (10)). Benchmarks nCar platoon model multiple (n) vehicles forming a platoon, maintaining a safe relative distance among one another [ 39]. Each of these benchmarks exhibited some number of violations that were remediated by our verification methodology. Benchmark Oscillator con sists of a twodimensional switched oscillator plus a 16order filter. The filter smoothens the input signals and has a sin gle output signal. We verify that the output signal is below a safe threshold. Because of the model complexity of this benchmark, it exhibited significantly more violations than the others. Indeed, the neuralnetwork controlled system often oscillated between the safe and unsafe boundary in many runs. Consequently, the overhead in this benchmark is high because a large number of shield interventions was required to ensure safety. In other words, the synthesized 11shield trades performance for safety to guarantee that the threshold boundary is never violated. For all benchmarks, our tool successfully generated safe interpretable deterministic programs and inductive invari ants as shields. When a neural controller takes an unsafe action, the synthesized shield correctly prevents this action from executing by providing an alternative provable safe action proposed by the verified deterministic program. In term of performance, Table 1 shows that a shielded neural policy is a feasible approach to drive a controlled system into a steady state. For each of the benchmarks studied, the pro grammatic policy is less performant than the shielded neural policy, sometimes by a factor of two or more (e.g., Cartpole , SelfDriving , and Oscillator ). Our result demonstrates that executing a neural policy in tandem with a program distilled from it can retain performance, provided by the neural policy, while maintaining safety, provided by the verified program. Although our synthesis algorithm does not guarantee con vergence to the global minimum when applied to nonconvex RL problems, the results given in Table 1 indicate that our algorithm can often produce highquality control programs, with respect to a provided sketch, that converge reasonably fast. In some of our benchmarks, however, the number of interventions are significantly higher than the number of neural controller failures, e.g.,8Car platoon andOscillator . However, the high number of interventions is not primar ily because of nonoptimality of the synthesized program matic controller. Instead, inherent safety issues in the neural network models are the main culprit that triggers shield interventions. In 8Car platoon , after corrections made by our deterministic program, the neural model again takes an unsafe action in the next execution step so that the deter ministic program has to make another correction. It is only after applying a number of such shield interventions that the system navigates into a part of the state space that can be safely operated on by the neural model. For this benchmark, all system states where there occur shield interventions are indeed unsafe. We also examined the unsafe simulation runs made by executing the neural controller alone in Oscillator . Among the large number of shield interventions (as reflected in Table 1), 74% of them are effective and indeed prevent an unsafe neural decision. Ineffective interventions in Oscillator are due to the fact that, when optimizing equation (5), a large penalty is given to unsafe states, causing the synthesized programmatic policy to weigh safety more than proximity when there exist a large number of unsafe neural decisions. Suitable Sketches. Providing a suitable sketch may need domain knowledge. To help the user more easily tune the shape of a sketch, our approach provides algorithmic support by not requiring conditional statements in a program sketch and syntactic sugar, i.e.,the user can simply provide an upper bound on the degree of an invariant sketch.Table 2. Experimental Results on Tuning Invariant Degrees. TO means that an adequate inductive invariant cannot be found within 2 hours. Benchmarks Degree Verification Interventions Overhead Pendulum2 TO   4 22.6s 40542 7.82% 8 23.6s 30787 8.79% SelfDriving2 TO   4 24s 128851 6.97% 8 25.1s 123671 26.85% 8Carplatoon2 172.9s 43952 8.36% 4 540.2s 37990 9.19% 8 TO   Our experimental results are collected using the invari ant sketch defined in equation (7)and we chose an upper bound of 4 on the degree of all monomials included in the sketch. Recall that invariants may also be used as conditional predicates as part of a synthesized program. We adjust the invariant degree upper bound to evaluate its effect in our synthesis procedure. The results are given in Table 2. Generally, highdegree invariants lead to fewer interven tions because they tend to be more permissive than low degree ones. However, highdegree invariants take more time to synthesize and verify. This is particularly true for highdimension models such as 8Car platoon . Moreover, although highdegree invariants tend to have fewer inter ventions, they have larger overhead. For example, using a shield of degree 8 in the SelfDriving benchmark caused an overhead of 26.85%. This is because highdegree polyno mial computations are timeconsuming. On the other hand, an insufficient degree upper bound may not be permissive enough to obtain a valid invariant. It is, therefore, essential to consider the tradeoff between overhead and permissiveness when choosing the degree of an invariant. Handling Environment Changes. We consider the effec tiveness of our tool when previously trained neural network controllers are deployed in environment contexts different from the environment used for training. Here we consider neural network controllers of larger size (two hidden layers with 1200√ó900neurons) than in the above experiments. This is because we want to ensure that a neural policy is trained to be near optimal in the environment context used for training. These larger networks were in general more difficult to train, requiring at least 1500 seconds to converge. Our results are summarized in Table 3. When the under lying environment sightly changes, learning a new safety shield takes substantially shorter time than training a new network. For Cartpole , we simulated the trained controller in a new environment by increasing the length of the pole by 0.15 meters. The neural controller failed 3 times in our 1000 episode simulation; the shield interfered with the network operation only 8 times to prevent these unsafe behaviors. 12Table 3. Experimental Results on Handling Environment Changes. Neural Network Deterministic Program as ShieldBenchmarks Environment ChangeSize Failures Size Synthesis Overhead Shield Interventions Cartpole Increased Pole length by 0.15m 1200√ó900 3 1 239s 2.91% 8 Pendulum Increased Pendulum mass by 0.3kg 1200√ó900 77 1 581s 8.11% 8748 Pendulum Increased Pendulum length by 0.15m 1200√ó900 76 1 483s 6.53% 7060 Selfdriving Added an obstacle that must be avoided 1200√ó900 203 1 392s 8.42% 108320 The new shield was synthesized in 239s significantly faster than retraining a new neural network for the new environ ment. For (Inverted) Pendulum , we deployed the trained neural network in an environment in which the pendulum‚Äôs mass is increased by 0.3kg. The neural controller exhibits noticeably higher failure rates than in the previous experi ment; we were able to synthesize a safety shield adapted to this new environment in 581 seconds that prevented these violations. The shield intervened with the operation of the network only 8.7 number of times per episode. Similar results were observed when we increased the pendulum‚Äôs length by 0.15m. For Selfdriving , we additionally required the car to avoid an obstacle. The synthesized shield provided safe actions to ensure collisionfree motion. 6 Related Work "
56,Large age-gap face verification by feature injection in deep networks.txt,"This paper introduces a new method for face verification across large age
gaps and also a dataset containing variations of age in the wild, the Large
Age-Gap (LAG) dataset, with images ranging from child/young to adult/old. The
proposed method exploits a deep convolutional neural network (DCNN) pre-trained
for the face recognition task on a large dataset and then fine-tuned for the
large age-gap face verification task. Finetuning is performed in a Siamese
architecture using a contrastive loss function. A feature injection layer is
introduced to boost verification accuracy, showing the ability of the DCNN to
learn a similarity metric leveraging external features. Experimental results on
the LAG dataset show that our method is able to outperform the face
verification solutions in the state of the art considered.","Face veriÔ¨Åcation is an important topic in both computer vision, imaging and multimedia. VeriÔ¨Åcation accuracy mainly depends on four elements: face pose, facial expression, illu mination, and aging [1]. The greatest part of the works in the state of the art studied the face veriÔ¨Åcation problem in constrained scenarios, controlling and Ô¨Åxing one or more of these four elements. Recently many researchers achieved or even surpassed humanlevel performance [14], [15] on face veriÔ¨Åcation bench mark taken in unconstrained environments such as the Labeled Faces in the Wild dataset (LFW) [2]. These results have been made possible thanks to the improvement in facial landmark detection and to the increase of the computational power available to train deep models. However, the LFW dataset Ô¨Åxes the aging element: it contains large variations in pose, facial expression, and illumination, but contains very little variation in aging. As people grow, face appearance can be very different, which makes it difÔ¨Åcult to recognize people across age. The problem is even harder when large age gaps are considered. To address this problem, in this work a new approach is proposed. Differently from other approaches in the state of the art, the proposed method does not rely on parametric models nor tries to model age progression. The idea is to use deep learning to jointly learn face features that matching faces share, and a similarity metric on top of these features. This is done coupling two deep convolutional neural networks (DCNN) with shared parameters in a Siamese network [32], [33] ended with a contrastive loss function. The discriminative S. Bianco is with the Dipartment of Informatics, Systems and Communi cation (DISCo), University of MilanoBicocca, 20126 Milano, Italy email: simone.bianco@disco.unimib.it.power of the network is further improved including a feature injection layer, which fuses externally computed features with the activations of the deepest layers of the DCNN. The idea of deep feature fusion has been mainly explored in the video categorization task. One of the earliest work is from Simonyan and Zisserman [3] where they proposed a twostream ConvNet architecture which incorporated a spatial and a temporal network. Perhaps the most similar work is [4] where multimodal video features are combined (e.g. frame based features computed by a convolutional neural network, trajectorybased motion descriptors and audio descriptors). Wang et al. [5] integrate the advantages of handcrafted and deeplearned features: they utilize deep architectures to learn multiscale convolutional feature maps, and introduce the strategies of trajectoryconstrained sampling and pooling to encode deep features into effective descriptors. Zha et al. [6] propose a late fusion approach between CNN features (taken at different layers) and Fisher Vectors [7]. The features are fused using an external classiÔ¨Åer and thus not in an endtoend training, excluding the possibility of backward feedbacks on feature extraction. Ng et al. [8] investigated the combination of Long Short Term Memory (LSTM) networks [9] with optical Ô¨Çow. Park et al. [10] propose a multiplicative fusion method for combining multiple CNNs trained on different sources. The contributions of this work are summarized as follows:  A new largescale Large AgeGap (LAG) dataset is collected, that includes images in the wild of 1,010 international celebrities spanning large age gaps.  A new DCNN architecture is proposed, including a feature injection layer that fuses external features with the activations of the deepest DCNN layers.  Extensive experiments are conducted on LAG and show that the proposed DCNN architecture can outperform stateoftheart methods. The remaining sections are organized as follows: Section II reviews the related works on face recognition, ageinvariant face recognition and existing face datasets. Section III de scribes the proposed method, while Section IV introduces the Large AgeGap (LAG) dataset. Experiments are presented in Section V. Finally, Section VI draws the conclusions and discusses future works. II. R ELATED WORKS "
203,Shared Certificates for Neural Network Verification.txt,"Existing neural network verifiers compute a proof that each input is handled
correctly under a given perturbation by propagating a symbolic abstraction of
reachable values at each layer. This process is repeated from scratch
independently for each input (e.g., image) and perturbation (e.g., rotation),
leading to an expensive overall proof effort when handling an entire dataset.
In this work, we introduce a new method for reducing this verification cost
without losing precision based on a key insight that abstractions obtained at
intermediate layers for different inputs and perturbations can overlap or
contain each other. Leveraging our insight, we introduce the general concept of
shared certificates, enabling proof effort reuse across multiple inputs to
reduce overall verification costs. We perform an extensive experimental
evaluation to demonstrate the effectiveness of shared certificates in reducing
the verification cost on a range of datasets and attack specifications on image
classifiers including the popular patch and geometric perturbations. We release
our implementation at https://github.com/eth-sri/proof-sharing.","The success of neural networks across a wide range of application domains [22,32] has led to their widespread application and study. Despite this success, neural networks remain vulnerable to adversarial attacks [9,24] which raises concerns over their trustworthiness in safetycritical settings such as autonomous driving and medical devices. To overcome this barrier, formal verication of neural net works has been proposed as a key technology in the literature [43]. As a result, yExtended version of our CAV'22 paper. First published in TODO. ?equal contribution zwork performed while at ETH ZuricharXiv:2109.00542v3  [cs.LG]  20 Dec 2022recent years have witnessed a growing interest in verifying critical safety proper ties of neural networks (e.g., fairness, robustness) [15,18,19,33,34,44,46] specied using pre and post conditions over network inputs and outputs respectively. Con ceptually, existing veriers propagate sets of inputs in the precondition captured in symbolic form (e.g., convex sets) through the network, an expensive process that produces overapproximations of all possible values at intermediate layers. The nal abstraction of the output can then be used to check postconditions. The key technical challenge all existing veriers aim to address is speeding up and scaling the certication process, i.e, faster and more ecient propagation of symbolic shapes while reducing the overapproximation error. This work: accelerating certication via proof sharing. In this work, we propose a new, complementary method for accelerating neural network verication based on the key observation that instead of treating each certication attempt in isolation as existing veriers do, we can reuse proof eort among multiple such attempts, thus obtaining signicant overall speedups without losing precision. Fig. 1 illustrates both, standard verication and the concept of proof sharing. In standard verication an input region I1(x) (orange square) is propagated from left to right, obtaining intermediate shapes at each intermediate layer (here the goal is to verify all points in the input region are classied as \cat"" by the neural network N). We observe that the abstraction obtained for a new regionI2(x) (e.g., blue shapes) can be contained inside existing abstractions fromI1(x), an eect we term proof subsumption . This eect can be observed both between abstractions obtained from dierent specications (e.g., `1and adversarial patches) for the same data point and between proofs for the same property but dierent, yet semantically similar inputs. Building on this obser vation, we introduce the notion of proof sharing via templates. Proof sharing works in two steps: rst, we leverage abstractions from existing proofs in order to create templates, and second, we augment the verier with these templates, stopping the expensive propagation at an intermediate layer as soon as the newly generated abstraction is included inside an existing template. Key technical in gredients to the eectiveness of our approach are fast template generation and inclusion checking techniques. We experimentally demonstrate that proof shar ing can achieve signicant speedups in challenging scenarios including proving robustness to adversarial patches [11] and geometric perturbations [4] across dierent neural network architectures. Main Contributions Our key contributions are: {An introduction and formalization of the concept of proof sharing in neural network verication: the idea that some proofs capture others ( ¬ß3). {A general framework leveraging the above concept, enabling proof eort reuse via proof templates ( ¬ß4). {A thorough experimental evaluation involving verication of neural network robustness against challenging adversarial patch and geometric perturba tions, demonstrating that our methods can achieve proof match rates of up 95% as well as provide nontrivial endtoend certication speedups ( ¬ß5).Fig. 1: Visualization of neural network verication. The input regions I1(x);I2(x) are propagated layer by layer through a neural network N. The high dimensional convex shapes are visualized in 2d. While initially I1(x) andI2(x) only slightly overlap, at layer k,N1:k(I2(x)) is fully contained in N1:k(I1(x)). 2 Background Here we formally introduce the necessary background for proof sharing. Neural Network A neural network Nis a function N:Rdin!Rdout, commonly built from individual layers N=NLNL"
133,Tools for Verifying Neural Models' Training Data.txt,"It is important that consumers and regulators can verify the provenance of
large neural models to evaluate their capabilities and risks. We introduce the
concept of a ""Proof-of-Training-Data"": any protocol that allows a model trainer
to convince a Verifier of the training data that produced a set of model
weights. Such protocols could verify the amount and kind of data and compute
used to train the model, including whether it was trained on specific harmful
or beneficial data sources. We explore efficient verification strategies for
Proof-of-Training-Data that are compatible with most current large-model
training procedures. These include a method for the model-trainer to verifiably
pre-commit to a random seed used in training, and a method that exploits
models' tendency to temporarily overfit to training data in order to detect
whether a given data-point was included in training. We show experimentally
that our verification procedures can catch a wide variety of attacks, including
all known attacks from the Proof-of-Learning literature.","How can we verify the capabilities of large machine learning models? Today, such claims are based on trust and reputation: customers and regulators believe that wellknown companies building AI models wouldn‚Äôt lie about the training data used in their models. However, as the ability to build new AI models proliferates, users need to trust an everlarger array of model providers at their word, and regulators may increasingly face malicious AI developers who may lie to appear compliant with standards and regulations. Worse, countries developing militarilysignificant AI systems may not trust each others‚Äô claims about these systems‚Äô capabilities, making it hard to coordinate on limits. AI developers can enable greater trust by having a third party verify the developer‚Äôs claims about their system, much as the iOS App Store checks apps for malicious code. Current blackbox approaches to model auditing allow some probing of capabilities [ Cen23 ], but these audits‚Äô utility is limited and a model‚Äôs capabilities can be hidden [ GTB22 ,GKVZ22 ]. An auditor can more effectively target their examination if they also know the model‚Äôs training data, including the total quantity, inclusion of data likely to enable specific harmful capabilities (such as texts on cyberexploit generation), and inclusion of safetyenhancing data (such as instructiontuning [OWJ+22]). However, if such data is selfreported by the AI developer, it could be falsified. This uncertainty limits the trust such audits can create. In this work, we define the problem of ProofofTrainingData (PoTD): a protocol by which a thirdparty auditor (the ‚ÄúVerifier‚Äù) can verify which data was used to train a model. Our verifica tion procedures assume that the Verifier can be given access to sensitive information and IP (e.g., training data, model weights) and is trusted to keep it secure; we leave the additional challenge of simultaneously preserving the confidentiality of the training data and model weights to future work. In principle, one could solve PoTD by cryptographically attesting to the results of training on a dataset using delegated computation [ CKV10 ]. However, in practice such delegation methods are impractically slow, forcing us to turn to heuristic verification approaches. Preprint. Under review. *First two authors contributed equally.arXiv:2307.00682v1  [cs.LG]  2 Jul 2023Inspired by the related literature on ‚ÄúProofofLearning‚Äù (PoL)[ JYCC+21], we propose that model trainers disclose a training transcript to the Verifier, including training data, training code, and intermediate checkpoints. In Section 4, we provide several verification strategies for a Verifier to confirm a training transcript‚Äôs authenticity, including new methods that address all published attacks in the ProofofLearning literature. We demonstrate the practical effectiveness of our defenses via experiments on two language models (Section 6). Our methods can be run cheaply, adding as little as 1.3% of the original training run‚Äôs compute. Further, we require no change to the training pipeline other than fixing the data ordering and initialization seeds, and storing the training process seeds for reproducibility. Still, like PoL, they sometimes require rerunning a small fraction of training steps to produce strong guarantees. The verification strategies we describe are not provably robust, but are intended as an opening proposal which we hope motivates further work in the ML security community to investigate new attacks and defenses that eventually build public confidence in the training data used to build advanced machine learning models. 2 Related Work "
497,Ensemble Deep Learning on Time-Series Representation of Tweets for Rumor Detection in Social Media.txt,"Social media is a popular platform for timely information sharing. One of the
important challenges for social media platforms like Twitter is whether to
trust news shared on them when there is no systematic news verification
process. On the other hand, timely detection of rumors is a non-trivial task,
given the fast-paced social media environment. In this work, we proposed an
ensemble model, which performs majority-voting on a collection of predictions
by deep neural networks using time-series vector representation of Twitter data
for timely detection of rumors. By combining the proposed data pre-processing
method with the ensemble model, better performance of rumor detection has been
demonstrated in the experiments using PHEME dataset. Experimental results show
that the classification performance has been improved by 7.9% in terms of micro
F1 score compared to the baselines.","Over the past few decades social media have emerged out as the primary means for news creation as well as for news consumption. Given the speed at which information travels on social media it is very easy to propagate any type of news and it can be consumed instantly across the globe at the early stages of its propagation process. However, the biggest challenge for news spreading on social media is how to verify whether that news is correct or not. Even though social media outperforms traditional media in many aspects, the key difference between them is that the news is veriÔ¨Åed for its truthfulness before it gets proliferated in traditional media, while it is not the case for social media. Thus, any piece of information can be easily spread on social media regardless of its truthfulness. Furthermore, information shared on social media propagates rapidly and increases the difÔ¨Åculty in verifying its credibility in near real time. A rumor is deÔ¨Åned as a ‚Äúcirculating story of questionable veracity, which seems credible but hard to verify [1], and produces sufÔ¨Åcient skepticism and anxiety‚Äù, and it could have truth values such as true, false or unveriÔ¨Åed [2]. Detection of rumors in social media has a lot of importance among research communities because unveriÔ¨Åed information may be easily disseminated over a large network, and rumorsmay spread misinformation or disinformation1, which are forms of false information [3], [4]. If the spread of false information is not stopped early it may cause turmoil in the society. In case of time critical events, the effects may be dreadful. So detecting rumors in social media must be done in a timely fashion. Recently machine learning and deep learning gained huge popularity in addressing rumor detection in social media [5], and they typically applies trained classiÔ¨Åcation models to predict new data samples as rumors or nonrumors [6]. One of the main concerns for applying these techniques is to Ô¨Ånd a dataset with good quality. On the other hand, performing extensive feature engineering on the dataset to extract a variety of useful features for the rumor identiÔ¨Åcation problem may help in improving a classiÔ¨Åcation model‚Äôs performance. However, it will signiÔ¨Åcantly slow down the training procedure since employing complex features in training process is cumbersome in terms of computational complexity and availability of hardware resources to deal with extremely large sized feature set [7]. Hence, extensive feature engineering may not be suitable for timely rumor detection. In this paper, we explore the temporal features of Twitter data for timely detection of rumors in social media. Tweet creation timestamp can readily be extracted from tweets, and there is no time delay to collect timestamp features and no so phisticated data preprocessing is required to convert them into useful features to train a classiÔ¨Åcation model. Based on this observation, we proposed an ensemble based multiple time series analysis model using deep learning models for timely detection of rumors in social media. SpeciÔ¨Åcally, we generated timeseries data by transforming Twitter conversations, where each conversation contains a list of tweets, into timesseries vectors that contain reaction counts as features, and fed them as input to deep learning models. The contributions of our proposed method are: With the proposed method, computational complexity can be signiÔ¨Åcantly reduced as we just need timestamps of tweets rather than their contents or user social en 1Misinformation means information that is incorrect in its nature and disinformation means information that is used to deceive its consumers.arXiv:2004.12500v1  [cs.LG]  26 Apr 2020gagements to perform feature extraction. Moreover, the extracted feature set is of numeric type, which is amicable to classiÔ¨Åcation models. Our proposed ensemble model improves the perfor mances of classiÔ¨Åcation models since it uses the majority voting scheme on multiple neural networks that are part of the ensemble model and takes advantage of their individual strengths. We validated our proposed method on the PHEME2 dataset and the performance results demonstrate the ef fectiveness of the proposed scheme. II. P ROBLEM FORMULATION A. Rumor detection Rumor detection involves identifying whether a data sample is a rumor or not. In machine learning, this kind of problem is termed as a classiÔ¨Åcation task, in which the classiÔ¨Åcation model gets trained with adequate number of training samples and tries to classify a never before seen testing sample as rumor or not. Therefore, the problem is given by ^y=f(X), where fis the classiÔ¨Åcation model and Xis a completely new data sample (a Twitter conversation sample that is transformed into a timeseries vector) to it, and ^yis the prediction of the classiÔ¨Åcation model and it has only two values since the PHEME dataset has two classes. In our work, we used 0‚Äôs and 1‚Äôs to represent nonrumor and rumor samples, respectively, i.e.,^y2f0;1g. B. General features of tweets Typically, for a classiÔ¨Åcation task using machine learning or deep learning requires extraction of useful features from the dataset. A variety of features can be extracted from Twitter data, for example, four types of features are extracted from Twitter data for the study on spread of anomalous information in social media [8]: user proÔ¨Åle features (users‚Äô friends and followers count), user network features (users‚Äô EgoNet fea tures), temporal features (retweet count), and content features (e.g. whether a tweet has question mark). However, based on the theories of rumor propagation, authors in [9] considered temporal features as one of the key properties for studying spread of rumors since according to social psychologists rumormongers have a short attention. In this work, for the fast detection of rumors on social media, we solely focused on the temporal features of Twitter data, which are the creation times tamps of tweets. These timestamps can be readily fetched, and our work strictly relies on them for generation of time series data, which involves simple calculations i.e. counting of number of tweets for given time interval limits. C. Feature extraction In general, for Twitter data we use a parser to read and extract required information from it by depending up on its data type. In our work, the Twitter data we utilized is available inJSON format and we used a suitable parser to read that 2https://Ô¨Ågshare.com/articles/PHEME dataset forRumour Detection and eracity ClassiÔ¨Åcation/6392078information and extracted our required features, which are the creation timestamps of tweets. III. E NSEMBLE LEARNING A. Overview of ensemble learning Ensemble learning is a concept in which many weak or base learners try to solve a single problem. An ensemble contains a number of base learners and its generalization ability is powerful than that of the base learners [10]. Ensemble methods work on a set of hypotheses derived from training data rather than relying on one hypothesis. Constructing ensembles is a twostep process. At Ô¨Årst, required number of base learners are produced. Secondly, all the base learners are grouped and typically majority voting is applied for classiÔ¨Åcation problems, and weighted averaging combination schemes are used for regression problems. Popular ensemble methods are boosting [11], bagging [12], and stacking [13]. Boosting method focuses on Ô¨Åtting multiple weak learners sequentially, where each model in a sequence gives more emphasis to the data samples that were badly treated by its previous model. AdaBoost [11] algorithm is a good example of boosting, which is simple and can be applied to data that is numeric, textual, etc. In bagging method, multiple bootstrap samples are generated from the training data, and an independent weak learner is Ô¨Åtted for each of these samples. Finally, all the predictions of weak learners are aggregated to determine the mostvoted class. RandomForests [14] algorithm is good example of bagging method, which is one of the most accurate learning algorithms and runs efÔ¨Åciently on large databases. In stacking method, by using different learning algorithms, multiple Ô¨Årstlevel individual learners are created, and these learners are grouped by a secondlevel learner (metalearner) to output a prediction [13]. B. Bagging learning Bagging learning has been studied extensively in the lit erature. Bagging also known as bootstrap aggregation is a popular ensemble method that is useful in reducing the high variance of machine learning algorithms. In bagging technique, several datasets are derived from the original training data set by employing sampling with replacement strategy that means some observations in the derived datasets may be repeated. These datasets are used to train classiÔ¨Åcation or regression models, and outputs of them are typically weighted averaged for regression cases or majority voted for classiÔ¨Åcation prob lems. Majority voting grouping technique is used in [15], [16]. In [15], bagging method of ensemble is used with REPTree as base classiÔ¨Åer for intrusion detection system, and compared to other traditional machine learning techniques. It is shown that ensemble bagging method achieved high classiÔ¨Åcation accuracy by employing NSL KDD dataset. Authors in [16], proposed to use dictionary learning with random subspace and bagging methods, and introduced Random Subspace Dic tionary Learning (RDL) and Bagging Dictionary Learning (BDL) algorithms. Their experimental analysis concluded thatensemble based dictionary learning methods performed better than that of single dictionary learning. Weighted averaging grouping technique is employed in [17], [18]. In [17], Neural Network Ensemble (NNE) approach is proposed to improve generalization ability of neural networks, and to reduce the calculation errors of Density Functional Theory (DFT). It is shown that both simple averaging and weighted averaging grouping techniques helped in improving DFT calculation results. Authors in [18], proposed a method for improving image classiÔ¨Åcation performance using SVM ensembles. Optimal weights for the base classiÔ¨Åers in the SVM ensemble are estimated by solving a quadratic programming problem. These weights are then used to combine the base classiÔ¨Åers to form an SVM ensemble. Optimization of a generic bagging algorithm is studied in [19]. Authors added an optimization process into the bagging algorithm that focuses on selecting better classiÔ¨Åers, which are relatively efÔ¨Åcient, and proposed a Selecting Base ClassiÔ¨Åers on Bagging (SBCB) algorithm. Experimental results proved that their SBCB algorithm performed well than generic bag ging approach. C. Deep bagging learning Because deep neural networks are nonlinear methods and have high variance, ensemble learning can combine the pre dictions of multiple neural network models in order to achieve less variance among the predictions and to decrease the gener alization error. Ensemble method is applied to neural networks mainly by (1) varying training data (data samples used to train models in the ensemble are varied), (2) varying choice of the models in the ensemble, and (3) varying the combination techniques that determine how outputs of ensemble members are combined. In [20], authors proposed a method that uses Convolutional Neural Network (CNN) and deep residual network (ResNET) ensemblebased classiÔ¨Åcation methods for Hyperspectral Im age (HSI) classiÔ¨Åcation. Their proposed method uses deep learning techniques, random feature selection, and majority voting strategy. Moreover, a transferring deep learning en semble is also proposed to make use of the learned weights of CNNs. In [21], two cooperative algorithms namely Neg Bagg (bagging is used) and NegBoost (boosting is used) are proposed for designing neural network (NN) ensembles. These algorithms use negative correlation algorithm while training NNs in the ensemble. Applying these models to well known problems in machine learning showed that with lesser number of training epochs compact NN ensembles with good generalization are produced. In [22], bagging ensemble is proposed to improve the prediction performance of artiÔ¨Åcial neural networks (ANN) to tackle bankruptcy prediction problem. Experimental re sults showed that proposed method improved performance of ANNs. Bagging technique using an ANN is proposed to address imbalance datasets on clinical prediction in [23], and experimental results showed that this method improved the prediction performance.D. Overview of the proposed model Our proposed model has two key components: data pre processing method and ensemble model. Firstly, raw Twitter conversations are processed to transform them into required data format and then the transformed data is supplied to the ensemble model to perform the classiÔ¨Åcation task. The ensemble model consists of six different neural networks (base learners) that are trained using the generated timeseries data and their predictions are grouped such that majority voting scheme is applied on them to determine the outcome as rumor or nonrumor. IV. M ETHODOLOGY The structure of our proposed model is shown in Fig. 1. The model takes Twitter conversations as input, where each conversation is a stream of tweets that contains sourcetweet and its corresponding reactions. In data preprocessing stage, we parse every tweet and extract its creation timestamp value. Once all tweets are parsed, we generate timeseries data for different time intervals and conduct data cleaning on it. Then we fed that cleaned data as input to the ensemble model. The ensemble model has nbase learners, which are ndifferent neural networks that are represented as m1; m2;; mn, where each of them yields its individual prediction results (i.e.r1; r2;; rn). Finally, we perform the majorityvoting process on all the predictions of those base learners, i.e., summing up all the prediction results and deciding the Ô¨Ånal prediction result as 0(nonrumor) if total sum is less than bn=2c+ 1or as 1(rumor) otherwise. A. Neural networks models considered The ensemble model constitutes base learners designed using Recurrent Neural Network (RNN), Long ShortTerm Memory (LSTM), Gated Recurrent Unit (GRU), and Bi directional Recurrent Neural Network (BiRNN). Six base learners are designed in this work: BiGRU, BiLSTM, GRU, LSTM, LG (a combination of LSTM and GRU layers), and RNN. 1) RNN: An RNN is a type of neural network that processes sequences by iterating through the sequence elements [24]. Typically, it consists of a hidden state h, and an optional output yfor a given variable length input sequence x= (x1;; xT). At each time t, the hidden state h(t)is given by [25]: h(t)=f(h(t"
224,Toward Neural-Network-Guided Program Synthesis and Verification.txt,"We propose a novel framework of program and invariant synthesis called neural
network-guided synthesis. We first show that, by suitably designing and
training neural networks, we can extract logical formulas over integers from
the weights and biases of the trained neural networks. Based on the idea, we
have implemented a tool to synthesize formulas from positive/negative examples
and implication constraints, and obtained promising experimental results. We
also discuss two applications of our synthesis method. One is the use of our
tool for qualifier discovery in the framework of ICE-learning-based CHC
solving, which can in turn be applied to program verification and inductive
invariant synthesis. Another application is to a new program development
framework called oracle-based programming, which is a neural-network-guided
variation of Solar-Lezama's program synthesis by sketching.","With the recent advance of machine learning techniques, there have been a lot of interests in applying them to program synthesis and verication. Garg et al. [6] have proposed the ICEframework, where the classical supervised learning based on positive and negative examples been extended to deal with \implication con straints"" to infer inductive invariants. Zhu et al. [32] proposed a novel approach to combining neural networks (NNs) and traditional software, where a NN con troller is synthesized rst, and then an ordinary program that imitates the NN's behavior; the latter is used as a shield for the neural net controller and the shield (instead of the NN) is veried by using traditional program verication techniques. There have also been various approaches to directly verifying NN components [8,30,1,21,16]. We propose yet another approach to using neural networks for program ver ication and synthesis. Unlike the previous approaches where neural networks are used either as black boxes [32,28] or white boxes [8,11], our approach treats ?An Extended Version of the Summary in the Proceedings of SAS 2021, Springer LNCS.arXiv:2103.09414v2  [cs.PL]  25 Aug 2021  input nodes output node hidden nodes x1 x2y1 y2 y8zFig. 1. A Neural Network with One Hidden Layer neural networks as gray boxes. Given training data, which typically consist of input/output examples for a (quantierfree) logical formula (as a part of a pro gram component or a program invariant) to be synthesized, we rst train a NN. We then synthesize a logical formula by using the weights and biases of the trained NN as hints. Extracting simple (or, \interpretable""), classical5program expressions from NNs has been considered dicult, especially for deep NNs; in fact, achieving \explainable AI"" [2] has been a grand challenge in the eld of machine learning. Our thesis here is, however, that if NNs are suitably designed with program or invariant synthesis in mind, and if the domain of the synthesis problems is suitably restricted to those which have reasonably simple program expressions as solutions, then it is actually often possible to extract program expressions (or logical formulas) by inspecting the weights of trained NNs. To clarify our approach, we give an example of the extraction. Let us consider the threelayer neural network shown in Figure 1. The NN is supposed to work as a binary classier for twodimensional data: it takes a pair of numbers ( x1;x2) as an input, and outputs a single number z, which is expected to be a value close to either 1 or 0. The NN has eight hidden nodes, and the sigmoid function is used as activation functions for both the hidden and output nodes.6The lefthand side of Table 1 shows a training data set, where each row consists of inputs (x1;x2) ("
336,Dynamic Kernels and Channel Attention for Low Resource Speaker Verification.txt,"State-of-the-art speaker verification frameworks have typically focused on
developing models with increasingly deeper (more layers) and wider (number of
channels) models to improve their verification performance. Instead, this paper
proposes an approach to increase the model resolution capability using
attention-based dynamic kernels in a convolutional neural network to adapt the
model parameters to be feature-conditioned. The attention weights on the
kernels are further distilled by channel attention and multi-layer feature
aggregation to learn global features from speech. This approach provides an
efficient solution to improving representation capacity with lower data
resources. This is due to the self-adaptation to inputs of the structures of
the model parameters. The proposed dynamic convolutional model achieved 1.62\%
EER and 0.18 miniDCF on the VoxCeleb1 test set and has a 17\% relative
improvement compared to the ECAPA-TDNN using the same training resources.","Speaker veriÔ¨Åcation (SV) aims to identify a speaker typically from an unlabeled sample of speech. This task involves mea suring the similarity between a test speaker‚Äôs acoustic embed ding and the already enrolled target speaker embedding. This similarity is typically evaluated using distance metrics such as cosine distance or Probabilistic Linear Discriminant Analysis (PLDA). The main objective of an SV framework is to learn generalised global characteristics from speaker acoustics. Many current approaches use combinations of deep neural networks (DNNs) trained for utterance classiÔ¨Åcation based upon learned features that correspond with the speaker‚Äôs identity. Ivectors [1] provide a Ô¨Åxed representation over the speaker acoustics; xvectors [2] became the following stateoftheart method for speaker representations as they were able to map variable length utterances to embeddings of Ô¨Åxed dimensions. The topology of these models and the embedding hierar chies are hypothesised to represent different speaker character istics. ResNet based models [3] [4] attempt to learn stronger representations with residual skip connections as this enables the composition of deeper models by learning the identity func tion and compensating for vanishing gradients. These speaker embeddings are further distilled by learning saliency regions with attention mechanisms. The DNN models using attention This work was conducted at the Liveperson Centre of Speech and Language Technology at the University of ShefÔ¨Åeldand skip connections [5] [6] proved a considerable improvement over the traditional xvectors and ivector embeddings. Both recurrent neural networks (RNN) and convolutional neural net works (CNN) have been used to learn temporal dependencies for speaker representations, noting that the CNNbased models have typically produced better performance with fewer number of parameters than RNNs [7]. The current stateoftheart SV architectures use Time De lay Neural Networks (TDNN) and attention mechanisms in the convolutional channel outputs, which further improved the per formance results [6]. However SV is still a challenging and computationally demanding task, especially in poor acoustic conditions. Large models that have been pretrained using huge datasets perform well [8]; however, training and serving these models is becoming increasingly computationally demanding. Work by [9] introduced the CNNECAPATDNN where the convolutional frontend allows the network to construct local, frequency invariant features to integrate frequency positional information. In order to enable the network to be invariant to small shifts in the frequency domain and to compensate for the potential intraspeaker variability, 2D convolutions are used to model at a higher resolution. However, this approach also uses large amounts of training data, where typically Ô¨Årst a pretrained largescale model is used to then be Ô¨Ånetuned for stateofthe art results. The ResNetbased models [3] can suffer from over Ô¨Åtting due to the increases in layer dimensionality and it can also take an excessive amount of time and computational re sources to Ô¨Ånetune the hyperparameters to improve the perfor mance. Often the performance of stateoftheart models can be difÔ¨Åcult to replicate due to optimisation and model complexity, which has increased the uptake of Ô¨Ånetuning pretrained mod els [10, 11]. The general trend for CNN based architectures has been to increase the depth and complexity of the network, while si multaneously increasing training data size for improved accu racy [12, 13]. However, considering the challenges for mod elling speech data, it is becoming necessary to make systems that are more efÔ¨Åcient with regard to size and training speed as well as more interpretable. The main contribution of this paper is to integrate attentionbased dynamic kernels for con volutions for a SV task achieving similar baselines to stateof theart approaches with lower resources, which has not yet been explored. The proposed approach uses parallel dynamic convo lutional kernels described in 2.2, which are able to adjust pa rameters dependent upon the input attention. Dynamic kernels have shown promising potential for boosting the model repre sentation capabilities without increasing the computational cost [14] and larger models have shown performance improvements for textindependent SV [15]. The proposed model builds upon the original ResNet modelarXiv:2211.02000v2  [cs.SD]  27 Feb 2023[3], which uses a 2D CNN based approach. This method can also be integrated into other CNNbased approaches, such as the CNNECAPATDNN for further improved SV performance without the requirement for larger or pretrained models. The main motivation for using this approach is to improve represen tation capacity, which is shown in the following experiments to improve veriÔ¨Åcation performance without increasing the com putation. This is possible with the dynamic convolution ap proach as the kernels share the output channels, and it is ob served to outperform similar models with increased layers, pa rameters and training data. Section 3.4 discusses the results of the experimental models with additional details regarding the average computation time of each epoch. 2. Model Topology 2.1. Related Works "
60,Temporal Action Detection by Joint Identification-Verification.txt,"Temporal action detection aims at not only recognizing action category but
also detecting start time and end time for each action instance in an untrimmed
video. The key challenge of this task is to accurately classify the action and
determine the temporal boundaries of each action instance. In temporal action
detection benchmark: THUMOS 2014, large variations exist in the same action
category while many similarities exist in different action categories, which
always limit the performance of temporal action detection. To address this
problem, we propose to use joint Identification-Verification network to reduce
the intra-action variations and enlarge inter-action differences. The joint
Identification-Verification network is a siamese network based on 3D ConvNets,
which can simultaneously predict the action categories and the similarity
scores for the input pairs of video proposal segments. Extensive experimental
results on the challenging THUMOS 2014 dataset demonstrate the effectiveness of
our proposed method compared to the existing state-of-art methods for temporal
action detection in untrimmed videos.","Temporal action detection has risen much attention in recent years because of the continuously booming of videos in the Internet. This task is a very challenging problem, given a long untrimmed video, action detection aims to predict the action categories and also localize the start and end time of actions of interest. However, actions of the same label could look much different in different poses, duration, background and so on. At the same time, actions of different classes may show many similarities. Such variations within the same action class and similarities within different action classes could make action detection more challenging, especially in untrimmed videos. There are multiple activities per video and many similarities between different action classes in the largescale video dataset THUMOS 2014 [8], like CliffDiving andDiving as shown in Fig. 1 (a) and (b). There are also large variations in pose of the same action class, like CricketBowling as shown in Fig. 1 (c) and (d). Therefore, it is an essential topic in temporal action detection task to reduce the intraaction variations while enlarge the interaction differences. Current methods [13], [14], [25], [31] for temporal ac tion detection always adopt the proposalclassiÔ¨Åcation frame work, which has been very successful in object detection. This proposalclassiÔ¨Åcation framework consists of three steps. (a) (b) (c) (d)Fig. 1. Samples from THUMOS 2014 dataset: (a) Diving. (b) CliffDiving. (c) CricketBowling. (d) CricketBowling. (a) and (b) are from different action labels, but they perform more similarities, (c) and (d) are from the same action label of CricketBowling, while they perform more variations due to different background. Firstly, action proposals are generated as candidates by tempo ral sliding windows. Secondly, the candidate segments are used to train a classiÔ¨Åer for action recognition. Finally, some post processing and nonmaximum suppression (NMS) procedures are conducted to reÔ¨Åne temporal boundaries from proposal segments to precisely localize boundaries of action instances. Instead of sliding window, [28] used a method called TAG [24] to generate proposals. SSAD [11] directly detect action instances in untrimmed videos by proposing a novel Single Shot Action Detector network to skip the proposal generation step. However, these methods ignore the problem of low clas siÔ¨Åcation accuracy which is caused by intraaction variations and interaction differences. In this work, we also adopt the proposalclassiÔ¨Åcation framework to perform temporal action detection task. How ever, our work only focuses on action classiÔ¨Åcation. For temporal action classiÔ¨Åcation, we argue that it is effective to use identiÔ¨Åcation and veriÔ¨Åcation simultaneously for reducing intraaction variations while enlarging interaction differences. Given a set of video proposal segments, identiÔ¨Åcation network can output the category of each video proposal segments, which can be treated as a multiclass recognition task [20], [23], [26]. While veriÔ¨Åcation network takes a pair of video proposal segments as input and determine whether they belong to the same action or not, which can be treated as a binary class classiÔ¨Åcation task. The veriÔ¨Åcation model ignores the relationship between the input video proposal pairs with other proposals, and the identiÔ¨Åcation model also dosen‚Äôt takearXiv:1810.08375v1  [cs.CV]  19 Oct 2018similarity between video proposal pairs into consideration. To address this problem, our work proposes to combine identiÔ¨Åcation and veriÔ¨Åcation model into a siamese network that can not only predict action categories but also estimate the similarities of the input video proposal pairs. Our contributions are twofold: (1) To the best of our knowledge, our work is the Ô¨Årst to incorporate the identiÔ¨Åcation and veriÔ¨Åcation model into tem poral action detection framework. We propose a IdentiÔ¨Åcation VeriÔ¨Åcation siamese (IVS) network that predicts action cate gories and similarity scores at the same time, thus improving temporal action detection accuracy. (2) Our proposed method signiÔ¨Åcantly outperforms the stateofart methods on the challenging action detection dataset: THUMOS 2014. The paper is organized as follows. We Ô¨Årst review some related works in Section II. In Section III, we describe our framework of IdentiÔ¨ÅcationVeriÔ¨Åcation. Section IV provides the experimental results on the largescale action detection dataset. At last, we conclude our works in Section V . II. R ELATED WORK "
277,SAVERS: SAR ATR with Verification Support Based on Convolutional Neural Network.txt,"We propose a new convolutional neural network (CNN) which performs coarse and
fine segmentation for end-to-end synthetic aperture radar (SAR) automatic
target recognition (ATR) system. In recent years, many CNNs for SAR ATR using
deep learning have been proposed, but most of them classify target classes from
fixed size target chips extracted from SAR imagery. On the other hand, we
proposed the CNN which outputs the score of the multiple target classes and a
background class for each pixel from the SAR imagery of arbitrary size and
multiple targets as fine segmentation. However, it was necessary for humans to
judge the CNN segmentation result. In this report, we propose a CNN called SAR
ATR with verification support (SAVERS), which performs region-wise (i.e.
coarse) segmentation and pixel-wise segmentation. SAVERS discriminates between
target and non-target, and classifies multiple target classes and non-target
class by coarse segmentation. This report describes the evaluation results of
SAVERS using the Moving and Stationary Target Acquisition and Recognition
(MSTAR) dataset.","In recent years, methods using convolution neural network (CNN) [1]‚Äì[4] have been successful in the classiÔ¨Åcation of image recognition. Similarly, CNNs for synthetic aperture radar (SAR) automatic target recognition (ATR) have beenproposed. On the Moving and Stationary Target Acquisition and Recognition (MSTAR) public dataset [5], the target clas siÔ¨Åcation accuracy of the CNNs [6]‚Äì[9] exceeds conventionalmethods (support vector machine, etc.). However, most of CNNs for SAR ATR classify target classes from a target chip extracted from SAR image but do not classify multiple targets or a target chip (or SAR image) of an arbitrary size.In addition, a CNN for target classiÔ¨Åcation can output scoreor probability of each class as classiÔ¨Åcation result, but it is diÔ¨Écult for a human to verify the classiÔ¨Åcation result. Figure 2a shows that the standard architecture of SAR ATR consists of three stages: detection, discrimination, and classiÔ¨Åcation. Detection: the Ô¨Årst stage of SAR ATR detectsa region of interest (ROI) from a SAR image. Discrimination: the second stage of SAR ATR discriminates whetheran ROI is a target or nontarget region, and outputs thediscriminated ROI as a target chip. ClassiÔ¨Åcation: the thirdstage of SAR ATR classiÔ¨Åes target classes from a target chip. In contrast, we proposed an architecture that performs de tection, discrimination, and classiÔ¨Åcation in a single stage (a) Input.  (b) SAVERS.  (c) Output. Fig. 1 Illustration of input and output of proposed CNN. The CNN named SAVERS performs automatic target recog nition of multiclass / multitarget in variable size SAR image. In this case, the input is a single image with twotargets of diÔ¨Äerent classes and two clutters. SAVERS out puts the position, class, and shape of each detected target. (Fig. 2b). Furthermore, we proposed a CNN which inputs a SAR image of variable sizes with multitarget and outputs aSAR ATR image. In this report, we propose a new CNN focusing on object detection by coarse segmentation and discrimination betweentarget and nontarget using clutter chips. 2. Related Work "
520,Abstraction and Symbolic Execution of Deep Neural Networks with Bayesian Approximation of Hidden Features.txt,"Intensive research has been conducted on the verification and validation of
deep neural networks (DNNs), aiming to understand if, and how, DNNs can be
applied to safety critical applications. However, existing verification and
validation techniques are limited by their scalability, over both the size of
the DNN and the size of the dataset. In this paper, we propose a novel
abstraction method which abstracts a DNN and a dataset into a Bayesian network
(BN). We make use of dimensionality reduction techniques to identify hidden
features that have been learned by hidden layers of the DNN, and associate each
hidden feature with a node of the BN. On this BN, we can conduct probabilistic
inference to understand the behaviours of the DNN processing data. More
importantly, we can derive a runtime monitoring approach to detect in
operational time rare inputs and covariate shift of the input data. We can also
adapt existing structural coverage-guided testing techniques (i.e., based on
low-level elements of the DNN such as neurons), in order to generate test cases
that better exercise hidden features. We implement and evaluate the BN
abstraction technique using our DeepConcolic tool available at
https://github.com/TrustAI/DeepConcolic.","Neural networks generally work with high precision, but recent work has shown that they are subject to weaknesses such as adversarial attacks [35], data poison ing attacks [2], Trojan attacks [22], model inversion attacks [8], etc. Given their importance and such weaknesses, the analysis of DNNs has become a popular research direction, with research on formal verication, coverageguided testing, etc. See [16] for a recent survey. The large size of DNNs, containing tens of thousands of neurons that interact with each other in intricate ways, leads to the scalability problem of these analysis methods, particularly for whitebox 1arXiv:2103.03704v1  [cs.LG]  5 Mar 2021analysis techniques, whose computational complexity is usually measured over either the number of neurons or the number of parameters. Moreover, most analysis methods { either verication or testing { work with local inputs in dividually, which easily leads to the other scalability problem when they need to work with a large dataset. The above scalability problems, due to the size of DNNs and the size of datasets, imply the need for an abstraction technique that approximates a DNN and a dataset into a simpler model { while preserving critical properties { to improve the scalability of the analysis methods. Contribution. This paper proposes a novel abstraction technique for DNNs through Bayesian approximation: we abstract the behaviour of a DNN on a dataset into a Bayesian network (BN), which is a probabilistic graphical model based on highlevel features instead of lowlevel neurons. The rst step of this abstraction is naturally to identify the relevant hidden features for each hidden layer. Standard feature extraction techniques are avail able, and while we obviously have to select some for experimental results and explore a few dierent ways of conducting feature extraction, we predominantly treat feature extraction as blackbox techniques. The features not only provide the structure of the BN, they also provide, for each input from a given dataset1, an observation of occurrences of features in neighbouring layers. This rst allows us to conduct probabilistic reasoning to understand how the appearance of some input features may statistically aect the appearance of hidden features or output labels, and how the appearance of some output label may aect the appearance probability of some input feature, etc. Such reasoning contributes to a global explainable AI method, helping the users to "
101,Writer-independent Feature Learning for Offline Signature Verification using Deep Convolutional Neural Networks.txt,"Automatic Offline Handwritten Signature Verification has been researched over
the last few decades from several perspectives, using insights from graphology,
computer vision, signal processing, among others. In spite of the advancements
on the field, building classifiers that can separate between genuine signatures
and skilled forgeries (forgeries made targeting a particular signature) is
still hard. We propose approaching the problem from a feature learning
perspective. Our hypothesis is that, in the absence of a good model of the data
generation process, it is better to learn the features from data, instead of
using hand-crafted features that have no resemblance to the signature
generation process. To this end, we use Deep Convolutional Neural Networks to
learn features in a writer-independent format, and use this model to obtain a
feature representation on another set of users, where we train writer-dependent
classifiers. We tested our method in two datasets: GPDS-960 and Brazilian
PUC-PR. Our experimental results show that the features learned in a subset of
the users are discriminative for the other users, including across different
datasets, reaching close to the state-of-the-art in the GPDS dataset, and
improving the state-of-the-art in the Brazilian PUC-PR dataset.","Biometrics technology is used in a wide variety of security applications. The aim of such systems is to recognize a person based on physiological traits (e.g Ô¨Ångerprint, iris) or behavioral traits (e.g. voice, handwritten signature) [1]. The handwritten signature is a particularly important type of biometric trait, mostly due to its widespread use to verify a person‚Äôs identity in legal, Ô¨Ånancial and administrative areas. One of the reasons for its extensive use is that the process to collect handwritten signatures is noninvasive, and people are familiar with their use in daily life [2]. Research in signature veriÔ¨Åcation is divided between online (dynamic) and ofÔ¨Çine (static) scenarios. In the online case, the signature is captured using a special input device (such as a tablet), and the dynamic information of the signature process is captured (pen‚Äôs position, inclination, among others). In this work, we focus on the OfÔ¨Çine (static) signature veriÔ¨Åcation problem, where the signature is acquired after the writing process is completed, by scanning the document containingthe signature. In this case, the signature is represented as a digital image. Most of the research effort in this area has been devoted to obtaining a good feature representation for signatures, that is, designing good feature extractors. To this end, researchers have used insights from graphology, computer vision, signal processing, among other areas [3]. As with several problems in computer vision, it is often hard to design good feature extractors, and the choice of which feature descriptors to use is problemdependent. Ideally, the features should reÔ¨Çect the process used to generate the data  for instance, neuromotor models of the hand movement. Although this approach has been explored in the context of online signature veriÔ¨Åcation [4], there is not a widely accepted ‚Äúbest‚Äù way to model the problem, specially for OfÔ¨Çine (static) signature veriÔ¨Åcation, where the dynamic information of the signature generation process is not available. In spite of the advancements in the Ô¨Åeld, systems proposed in the literature still struggle to distinguish genuine signatures and skilled forgeries. These are forgeries made by a person with access to a user‚Äôs signature, that practices imitating it (see Figure 1). Experimental results show somewhat large error rates when testing on public datasets (such as GPDS [5]), even when the number of samples for training is around 1015 (results are worse with 13 samples per user, which is a common scenario in banks and other institutions). In this work we propose using feature learning (also called representation learning) for the problem of OfÔ¨Çine Signature VeriÔ¨Åcation, in order to obtain better feature representations. Our hypothesis is that, in the absence of a good model of the data generation process, it is better to learn the features from data, rather than using handcrafted features that have no resemblance to how the signatures are created, which is the case for the best performing systems proposed in the literature. For example, recent OfÔ¨Çine Signature VeriÔ¨Åcation systems are based on texture descriptors, such as Local Binary Patterns [6], interestpointmatching such as SURF [7], among others. We base our research on recent successful applications of purely supervised learning models for computer vision (sucharXiv:1604.00974v1  [cs.CV]  4 Apr 2016Figure 1. Samples from the GPDS960 dataset. Each row contains three genuine signatures from the same user and a skilled forgery. We notice that each genuine signature is different (showing high intraclass variability), while skilled forgeries resemble the genuine signatures to a large extent (showing low interclass variability) as image recognition [8]). In particular, we use Deep Convolu tional Neural Networks (CNN) trained with a supervised cri terion, in order to learn good representations for the signature veriÔ¨Åcation problem. This type of architecture is interesting for our problem, since it scales better than fully connected models for larger input sizes, having a smaller number of trainable parameters. This is a desirable property for the problem at hand, since we cannot rescale signature images too much without risking losing the details that enable discriminating between skilled forgeries and genuine signatures. The most common formulation of the signature veriÔ¨Åcation problem is called WriterDependent classiÔ¨Åcation. In this formulation, one classiÔ¨Åer is built for each user in the system. Using a supervised feature learning approach directly in this case is not practical, since the number of samples per user is very small (usually around 114 samples). Instead, we propose a twophase approach: a WriterIndependent feature learning phase followed by WriterDependent classiÔ¨Åcation. The feature learning phase uses a surrogate classiÔ¨Åcation task for learning feature representations, where we train a CNN to discriminate between signatures from users not enrolled in the system. We then use this CNN as a feature extractor and train a Writerdependent classiÔ¨Åer for each user. Note that in this formulation, adding a new user to the system requires training only a WriterDependent classiÔ¨Åer. We tested this method using two datasets: the GPDS960 corpus ([5]) and the Brazilian PUCPR dataset [9]. The Ô¨Årst is the largest publicly available corpus for ofÔ¨Çine signature veriÔ¨Åcation, while the second is a smaller dataset that has been used for several studies in the area. Our main contributions are the following: We propose a twostage framework for ofÔ¨Çine signature veriÔ¨Åcation, where we learn features in a WriterIndependent way, and build WriterDependent classiÔ¨Åers. Our results show that we do have enough data in signature datasets to learn relevant features for the task, and the proposed method achieves stateofthe art performance. We also investigate how the features learnedin one dataset transfer to another dataset, and the impact in performance of the number of samples available for WD training. II. R ELATED WORK "
448,RoMA: a Method for Neural Network Robustness Measurement and Assessment.txt,"Neural network models have become the leading solution for a large variety of
tasks, such as classification, language processing, protein folding, and
others. However, their reliability is heavily plagued by adversarial inputs:
small input perturbations that cause the model to produce erroneous outputs.
Adversarial inputs can occur naturally when the system's environment behaves
randomly, even in the absence of a malicious adversary, and are a severe cause
for concern when attempting to deploy neural networks within critical systems.
In this paper, we present a new statistical method, called Robustness
Measurement and Assessment (RoMA), which can measure the expected robustness of
a neural network model. Specifically, RoMA determines the probability that a
random input perturbation might cause misclassification. The method allows us
to provide formal guarantees regarding the expected frequency of errors that a
trained model will encounter after deployment. Our approach can be applied to
large-scale, black-box neural networks, which is a significant advantage
compared to recently proposed verification methods. We apply our approach in
two ways: comparing the robustness of different models, and measuring how a
model's robustness is affected by the magnitude of input perturbation. One
interesting insight obtained through this work is that, in a classification
network, different output labels can exhibit very different robustness levels.
We term this phenomenon categorial robustness. Our ability to perform risk and
robustness assessments on a categorial basis opens the door to risk mitigation,
which may prove to be a significant step towards neural network certification
in safety-critical applications.","In the passing decade, deep neural networks (DNNs) have emerged as one of the most exciting developments in computer science, allowing computers to outper form humans in various classiÔ¨Åcation tasks. However, a major issue with DNNs is the existence of adversarial inputs [11]: inputs that are very close (accord ing to some metrics) to correctlyclassiÔ¨Åed inputs, but which are misclassiÔ¨Åed themselves. It has been observed that many stateoftheart DNNs are highly vulnerable to adversarial inputs [6]. As the impact of the AI revolution is becoming evident, regulatory agencies are starting to address the challenge of integrating DNNs into various auto motive and aerospace systems ‚Äî by forming workgroups to create the needed guidelines. Notable examples in the European Union include SAE G34 and EUROCAE WG114 [21,26]; and the European Union Safety Agency (EASA), which is responsible for civil aviation safety, and which has published a road map for certifying AIbased systems [9]. These eÔ¨Äorts, however, must overcome a sig niÔ¨Åcant gap: on one hand, the superior performance of DNNs makes it highlyarXiv:2110.11088v5  [cs.LG]  1 Oct 20222 N. Levy and G. Katz desirable to incorporate them into various systems, but on the other hand, the DNN‚Äôs intrinsic susceptibility to adversarial inputs could render them unsafe. This dilemma is particularly felt in safetycritical systems, such as automotive, aerospace and medical devices, where regulators and public opinion set a high bar for reliability. In this work, we seek to begin bridging this gap, by devising a framework that could allow engineers to bound and mitigate the risk introduced by a trained DNN,eÔ¨Äectivelycontainingthephenomenonofadversarialinputs.Ourapproach is inspired by common practices of regulatory agencies, which often need to certify various systems with components that might fail due to an unexpected hazard. A widely used example is the certiÔ¨Åcation of jet engines, which are known to occasionally fail. In order to mitigate this risk, manufacturers compute the engines‚Äô mean time between failures (MTBF), and then use this value in performingasafetyanalysisthatcaneventuallyjustifythesafetyofthejetengine system as a whole [17]. For example, federal agencies guide that the probability of an extremely improbable failure conditions event per operational hour should not exceed 10"
390,TRACE: A Differentiable Approach to Line-level Stroke Recovery for Offline Handwritten Text.txt,"Stroke order and velocity are helpful features in the fields of signature
verification, handwriting recognition, and handwriting synthesis. Recovering
these features from offline handwritten text is a challenging and well-studied
problem. We propose a new model called TRACE (Trajectory Recovery by an
Adaptively-trained Convolutional Encoder). TRACE is a differentiable approach
that uses a convolutional recurrent neural network (CRNN) to infer temporal
stroke information from long lines of offline handwritten text with many
characters and dynamic time warping (DTW) to align predictions and ground truth
points. TRACE is perhaps the first system to be trained end-to-end on entire
lines of text of arbitrary width and does not require the use of dynamic
exemplars. Moreover, the system does not require images to undergo any
pre-processing, nor do the predictions require any post-processing.
Consequently, the recovered trajectory is differentiable and can be used as a
loss function for other tasks, including synthesizing offline handwritten text.
  We demonstrate that temporal stroke information recovered by TRACE from
offline data can be used for handwriting synthesis and establish the first
benchmarks for a stroke trajectory recovery system trained on the IAM online
handwriting dataset.","Handwriting is prevalent in both the physical and digital world. When hand writing is captured by a digital device, such as a penbased computer screen, it is referred to as online handwriting data. At a minimum, these data include the location of the pen tip or stylus when touching the screen through time [17]. On the other hand, oine handwriting data refers to digital images of handwriting inscribed on some physical medium. While online data can be readily rendered as an image, the reverse process is much more dicult, as oine data lack a temporal component and often contain artifacts inherent to the writing medium or digitization process. Consequently,arXiv:2105.11559v1  [cs.CV]  24 May 20212 Taylor Archibald et al. (1) (2) Fig. 1: TRACE recovery and synthesis. (1) is a visualization of strokes recovered by TRACE from an oine handwriting image. Blue arrows indicate the predicted direction and orange points indicate the beginning of a new stroke. (2) is an example of a synthetically generated image that mimics the style of (1), and demonstrates how strokes recovered from oine data can be used for other tasks. online handwriting data can make many tasks easier or more accurate [16], including handwriting recognition, signature verication, writer identication, and handwriting synthesis (see Figure 1). While capturing handwriting online is becoming increasingly common, oine handwriting data collection can be easier in many instances and oine handwriting recognition remains an important challenge. We propose a novel, dierentiable model for stroke recovery called TRACE (Trajectory Recovery by an Adaptivelytrained Convolutional Encoder). Our model is based on a CRNN that outputs a series of predicted stroke points, the number of which is proportional to the width of the original image. These predictions are then aligned using a Dynamic Time Warping algorithm (DTW) and compared against the ground truth (GT) stroke points to calculate a loss, from which the network is updated. The most important contribution TRACE oers is it extends prior trajectory recovery deep learning approaches to work on arbitrarily long lines of text. We provide the rst trajectory recovery benchmarks for the IAM online handwriting database (IAMOn) [12] and the IAM oine handwriting database (IAMO) [13]. Additionally, we demonstrate that strokes recovered by TRACE can be used to synthesize handwriting in the manner of a given style. 2 Related Work "
404,Deep Speaker Embeddings for Far-Field Speaker Recognition on Short Utterances.txt,"Speaker recognition systems based on deep speaker embeddings have achieved
significant performance in controlled conditions according to the results
obtained for early NIST SRE (Speaker Recognition Evaluation) datasets. From the
practical point of view, taking into account the increased interest in virtual
assistants (such as Amazon Alexa, Google Home, AppleSiri, etc.), speaker
verification on short utterances in uncontrolled noisy environment conditions
is one of the most challenging and highly demanded tasks. This paper presents
approaches aimed to achieve two goals: a) improve the quality of far-field
speaker verification systems in the presence of environmental noise,
reverberation and b) reduce the system qualitydegradation for short utterances.
For these purposes, we considered deep neural network architectures based on
TDNN (TimeDelay Neural Network) and ResNet (Residual Neural Network) blocks. We
experimented with state-of-the-art embedding extractors and their training
procedures. Obtained results confirm that ResNet architectures outperform the
standard x-vector approach in terms of speaker verification quality for both
long-duration and short-duration utterances. We also investigate the impact of
speech activity detector, different scoring models, adaptation and score
normalization techniques. The experimental results are presented for publicly
available data and verification protocols for the VoxCeleb1, VoxCeleb2, and
VOiCES datasets.","The increasing interest in reliable means of guarding and re stricting access to informational resources requires the devel opment of new authentication methods. Biometric recognition remains one of the priority research areas in this Ô¨Åeld. Today Automatic Speaker VeriÔ¨Åcation (ASV) systems are a subject of increased interest of both state law enforcement agencies and commercial structures due to their reliability, con venience, low cost and provided security. Moreover, such sys tems can operate on different inputoutput devices and commu nication channels (landline, mobile telephone networks, IP tele phony, etc.). The latest results obtained for the telephone part of NIST SRE (National Institute of Standards and Technology Speaker Recognition Evaluation) datasets demonstrated that Speaker Recognition (SR) systems based on deep speaker embeddingshad achieved signiÔ¨Åcant results in controlled conditions [1]. However, speaker veriÔ¨Åcation on short utterances is still one of the more challenging tasks in the textindependent speaker recognition Ô¨Åeld. Taking into account the increased interest in virtual assis tants (such as Amazon Alexa, Google Home, Apple Siri, etc.), the demand for farÔ¨Åeld speaker veriÔ¨Åcation on short utterances (such as wakeup words and short commands) in uncontrolled noisy environment conditions is very high. Such factors as channel mismatch, environmental noise and room reverberation can dramatically decrease the quality of these systems. This was conÔ¨Årmed by the VOiCES from a Dis tance challenge 2019 (VOiCES 2019 challenge) [2, 3] aimed to support research in the area of speaker recognition and auto matic speech recognition with the special focus on single chan nel farÔ¨Åeld audio under noisy conditions. This paper presents approaches aimed to achieve two goals simultaneously: to improve the performance of farÔ¨Åeld speaker veriÔ¨Åcation systems in the presence of environmental noise and reverberation, and to reduce the system quality degradation for short utterances. In order to achieve these goals, we consider stateoftheart deep neural network architectures and its appli cability for speaker veriÔ¨Åcation task in uncontrolled environ mental conditions on publicly available data and veriÔ¨Åcation protocols for the V oxCeleb1, V oxCeleb2, and VOiCES datasets. We experimented with deep speaker embedding extractors based on TDNN (Time Delay Neural Network) [4] and ResNet (Residual Neural Network) [1, 5] blocks and different train ing objectives. A detailed description of the extractors is pre sented in Section 4. Special attention was paid to the impact of deep neural network speech activity detector presented in 3.2 that is more robust against noise and other distortions compared to classical energybased methods. In this paper, we also an alyzed different scoring models, adaptation and score normal ization techniques and estimated their contribution to the Ô¨Ånal system performance. All obtained experimental results and their comparison with the standard xvector approach are considered in Section 5. The proposed systems performance is presented in terms of EER (Equal Error Rate) and minDCF (Minimum Detection Cost Function).arXiv:2002.06033v1  [cs.SD]  14 Feb 20202. Related work "
109,Data Efficient Human Intention Prediction: Leveraging Neural Network Verification and Expert Guidance.txt,"Predicting human intention is critical to facilitating safe and efficient
human-robot collaboration (HRC). However, it is challenging to build
data-driven models for human intention prediction. One major challenge is due
to the diversity and noise in human motion data. It is expensive to collect a
massive motion dataset that comprehensively covers all possible scenarios,
which leads to the scarcity of human motion data in certain scenarios, and
therefore, causes difficulties in constructing robust and reliable intention
predictors. To address the challenge, this paper proposes an iterative
adversarial data augmentation (IADA) framework to learn neural network models
from an insufficient amount of training data. The method uses neural network
verification to identify the most ""confusing"" input samples and leverages
expert guidance to safely and iteratively augment the training data with these
samples. The proposed framework is applied to collected human datasets. The
experiments demonstrate that our method can achieve more robust and accurate
prediction performance compared to existing training methods.","The rapid development of humanrobot collaboration (HRC) addresses contemporary needs by enabling more efÔ¨Åcient and Ô¨Çexible production lines [ 36,51]. Due to the close physical interactions (Fig. 1(a)), any collision could lead to severe harm to the human workers. Therefore, it is essential to ensure safety while maximizing efÔ¨Åciency when facilitating HRC. One key technology to enable safe and efÔ¨Åcient HRC is to have accurate and robust human intention prediction [ 25]. Data driven methods, especially neural network (NN) models, are widely used for intention prediction [1, 43, 28, 41]. This paper mainly focuses on human upperbody motion during HRC in manufacturing settings. It is challenging to build datadriven models for intention prediction in such environments due to data scarcity. Since the prediction task varies when the HRC task changes (which happens frequently), it is expensive, if not impossible, to collect a dataset from different human subjects that comprehensively covers all possible scenarios. One reason that leads to the high cost is the diversity of human behavior. For example, in a setting where the humans are doing assembly tasks, human subjects with different habits, body structures, moods, and task proÔ¨Åciencies may exhibit different motion patterns. As shown inFig. 1(b), for the same reaching motion, the wrist can move in different ways. It is expensive (if not impossible) to collect data from all human subjects in all possible task situations. Another reason for the high cost of data collection is the existence of exogenous input disturbances. For This work is in part supported by Ford Motor Company. 36th Conference on Neural Information Processing Systems (NeurIPS 2022).arXiv:2108.06871v3  [cs.LG]  24 Sep 2022(a)  (b)  (c) Figure 1: (a) An example of HRC: Humanrobot handover [ 33,32]. (b) For the same type of motion, the human can perform in different ways as shown by the red, green and blue trajectories. (c) Noise in human motion data. Green: true wrist trajectory. Red: captured wrist trajectory. example in Fig. 1(c), due to the inevitable sensor noise and algorithm uncertainty, the captured motion trajectory (red) may deviate from the ground truth motion (green). It is expensive to generate a full distribution of these disturbances on each data point. Due to these high costs of data collection, a welldistributed and sufÔ¨Åcient human behavior dataset is usually not available. Early works [ 3,22,19,24] have shown that an insufÔ¨Åcient amount of training data would make it difÔ¨Åcult to train an NN model, as the performance of the learned model will deteriorate in testing. Therefore, the learned model is not deployable in real applications. To deal with data deÔ¨Åciency, some methods [ 31,11] use online adaptation to incrementally update the NN using the data received online, which has been shown to improve prediction accuracy. However, these methods are postdeployment measures and there is no control over the incoming data, which might lead to safety hazards during the adaptation process. This paper investigates methods that efÔ¨Åciently learn NN models before deployment with limited data. The goal is to actively and costeffectively augment the dataset (i.e., getting full control over the augmented data) so that the learned NN can perform robustly in real applications. To achieve the goal, this paper proposes an iterative adversarial data augmentation (IADA) framework to train NNs with limited data. This framework leverages neural network veriÔ¨Åcation and expert guidance for iterative data augmentation during training. The key idea of IADA is to Ô¨Ånd the most ‚Äúconfusing‚Äù samples to the NN, e.g., the samples on the decision boundary of the current NN, and add them back to the dataset to improve model accuracy. We use NN veriÔ¨Åcation to Ô¨Ånd these samples by computing the closest adversaries to existing data (called roots) in L¬•norm. These samples are called ‚Äúadversaries‚Äù since the current NN predicts that they have different labels from the labels of roots (hence they are on the decision boundary of the current NN). The IADA framework will query experts to label these samples in order to ensure the correctness of the labels of the adversaries. The sample is a true adversary if its ground truth label is the same as the label of its root; otherwise, this sample is a false adversary. This paper incorporates humanintheloop veriÔ¨Åcation as the expert guidance to label the adversaries. The labeled samples will be added back to the training dataset no matter what labels they are assigned. The true adversarial samples can improve the robustness of the network, while the false adversarial samples can help recover the ground truth decision boundary. The IADA framework iteratively expands the dataset and trains the NN model. To verify the effectiveness of IADA, we applied it to two human intention prediction tasks. We compared our training framework against several other training methods. The results demonstrate that our training method can improve the model testing accuracy by over 10%. 2 Related Work "
453,End-to-End Speaker-Dependent Voice Activity Detection.txt,"Voice activity detection (VAD) is an essential pre-processing step for tasks
such as automatic speech recognition (ASR) and speaker recognition. A basic
goal is to remove silent segments within an audio, while a more general VAD
system could remove all the irrelevant segments such as noise and even unwanted
speech from non-target speakers. We define the task, which only detects the
speech from the target speaker, as speaker-dependent voice activity detection
(SDVAD). This task is quite common in real applications and usually implemented
by performing speaker verification (SV) on audio segments extracted from VAD.
In this paper, we propose an end-to-end neural network based approach to
address this problem, which explicitly takes the speaker identity into the
modeling process. Moreover, inference can be performed in an online fashion,
which leads to low system latency. Experiments are carried out on a
conversational telephone dataset generated from the Switchboard corpus. Results
show that our proposed online approach achieves significantly better
performance than the usual VAD/SV system in terms of both frame accuracy and
F-score. We also used our previously proposed segment-level metric for a more
comprehensive analysis.","V oice activity detection (V AD) [1], one of the most crit ical techniques of speech signal processing, i s used to  separate speech from nonspeech segments within au dio. V AD is usually applied as a pr eprocessing step for  various speech processing tasks such as automatic  speech recognition (ASR), speech synthesis, speaker  recognition and voice over internet protocol (V oIP).  The quality of V AD directly affects the performance of  the subsequent tasks.   In traditional V AD systems, the non speech parts  are usually composed of silence and noises, while in  this work we also incorporate the speech from un wanted speakers. This is quite common in real applica tions, for example, voice assistants may only need to  reply to a particular speaker's commands, or in a con versational environment, speech from non target  speakers should be regarded as non speech. The prob lem addressed is termed as speaker dependent voice ac tivity detection (SDV AD), which is an extension of t he  conventional V AD task. In this setting, we only want to                                                           This work has been supported by  the National Key Research  and   Development Program of China under Grant No.2017YFB1302402 and the   China NSFC projects (No. 61603252 and No. U1736202) . Experiments have   been carried out on the PI supercomputer at Shanghai Jiao Tong University.    Yanmin Qian and Kai Yu are the corresponding authors.  detect the speech from a target speaker, so silence,  noises, or speech from a non target speaker will all be  ignored. A naive approach to this task has two steps: (1)  Generate speech segments using  an ordinary V AD sys tem (2) Perform speaker verification on the obtained  speech segments to filter out the target speaker. How ever, this approach is performed in an offline manner  and suffers from high latency.   Traditional V AD algorithms can be divided in to  two categories, feature based methods and model  based methods. Regarding feature based methods, dif ferent acoustic features are first extracted such as time  domain energy [2], zero crossing rate [3] and pitch [4],  then simple detection sch eme such as threshold com parison is applied. Regarding model based methods,  separate statistical models were trained to represent  speech and non speech segments by different probabil ity distributions, where likelihood ratio between the  two models is used a s a decision threshold. Models such  as Gaussian Mixture Model (GMM) [5] and Hidden  Markov Model (HMM) [6] were investigated in the lit erature. Instead of using likelihood ratio based methods,   directly training a binary classifier to discriminate  speech and non speech is more popular in current V AD  systems. Classifiers such as Supp ort V ector Machine  (SVM) [7] and deep neural networks are trained to out put the posteriors for each frame directly.   Recently, deep learning approaches have been  successfully applied to many tasks including V AD. For  V AD in complex environments, DNN has better mod eling capabilities than traditional methods [8], recurrent  neural ne twork (RNN) and long short term memory  (LSTM) can better model long term dependencies be tween inputs [9][10] and convolutional neural network  (CNN) can generate better features for V AD training  [11].   In order t o tackle the speaker dependent V AD  problem, we propose a neural network based system  which explicitly integrates the speaker identity infor mation into the modeling process in this paper. On top  of the normal spectral features such as filter banks  (Fbank), speaker embeddings ( ivector) from the target  speaker are also taken as input. If the current frame rep resented by the spectral feature is speech and comes  from the speaker characterized by the ivector, then the  label will be 1, else it will be 0. Compare d to the de coupled two stage V AD / SV approach, our proposed  model optimizes an end toend system directly against  the final goal. Experiments are carried out on an artifi cial conversational dataset generated from the Switch board database and results show that compared to the  offline V AD / SV approach, our proposed online ap proach could achieve better performance with negligi ble latency since the prediction is generated at each  frame.   The rest of this paper is organized as follows. In  section 2, we introduc e neural network based V AD.  Section 3 describes the details of our proposed end to end speaker dependent V AD architecture. In section 4,  experimental results and analysis are provided. Discus sion and conclusion are given in section 5.     2. Neural network  based  VAD   2.1 DNN based V AD system   As shown in [8], the DNN based V AD systems not only  outperform the traditional model based systems but  also have a low detection complex ity [12]. A typical  DNN based V AD system trains a frame based binary  classifier to classify each frame into two classes: speech and non speech. Conventionally, the f rame wise input  for the DNN is conca tenated with its context as ùêét:    ùêét=[ùê±t‚àír,‚Ä¶,ùê±t‚àí1,ùê±t,ùê±t+1,‚Ä¶,ùê±t+r]      (1)    Where ùê±t is tth frame and  r is the length of context  extension. DNN is optimized by the cross entropy cri terion. For each frame, classification is performed by a  comparison among posterior probabilities of the two  classes.     2.2 LSTM based V AD system   LSTM is capable at modeling sequ ences and capturing  longrange dependencies in a sequence of features. In  its core it is comprised of special units called memory  blocks. Each memory block contains an input gate , an  output gate  and a forget gate , which enables the model  to memorize inform ation for a short or long duration.  The LSTM structure can effectively use a context to  model the input acoustic features sequentially.   The LSTM network computes a mapping from an  input sequence ùê±=[ùê±1,ùê±2,‚Ä¶,ùê±T] to an output se quence ùê≤=[ùê≤1,ùê≤2,‚Ä¶,ùê≤T] . More details of this ar chitecture could be referred from [13].  If applied to V AD, a LSTM based system outputs  predictions frame by frame, but each predict ion of the  current frame partially depends on its history. The train ing criterion is the same as for DNN.     3. Speaker dependent VAD   3.1 Related work   "
273,Graph Structure of Neural Networks.txt,"Neural networks are often represented as graphs of connections between
neurons. However, despite their wide use, there is currently little
understanding of the relationship between the graph structure of the neural
network and its predictive performance. Here we systematically investigate how
does the graph structure of neural networks affect their predictive
performance. To this end, we develop a novel graph-based representation of
neural networks called relational graph, where layers of neural network
computation correspond to rounds of message exchange along the graph structure.
Using this representation we show that: (1) a ""sweet spot"" of relational graphs
leads to neural networks with significantly improved predictive performance;
(2) neural network's performance is approximately a smooth function of the
clustering coefficient and average path length of its relational graph; (3) our
findings are consistent across many different tasks and datasets; (4) the sweet
spot can be identified efficiently; (5) top-performing neural networks have
graph structure surprisingly similar to those of real biological neural
networks. Our work opens new directions for the design of neural architectures
and the understanding on neural networks in general.","Deep neural networks consist of neurons organized into lay ers and connections between them. Architecture of a neural network can be captured by its ‚Äúcomputational graph‚Äù where neurons are represented as nodes and directed edges link neurons in different layers. Such graphical representation demonstrates how the network passes and transforms the information from its input neurons, through hidden layers 1Department of Computer Science, Stanford University 2Facebook AI Research. Correspondence to: Jiaxuan You <ji axuan@cs.stanford.edu >, Saining Xie <s9xie@fb.com >. Proceedings of the 37thInternational Conference on Machine Learning , Online, PMLR 119, 2020. Copyright 2020 by the au thor(s).all the way to the output neurons (McClelland et al., 1986). While it has been widely observed that performance of neu ral networks depends on their architecture (LeCun et al., 1998; Krizhevsky et al., 2012; Simonyan & Zisserman, 2015; Szegedy et al., 2015; He et al., 2016), there is currently little systematic understanding on the relation between a neural network‚Äôs accuracy and its underlying graph struc ture. This is especially important for the neural architecture search, which today exhaustively searches over all possible connectivity patterns (Ying et al., 2019). From this per spective, several open questions arise: Is there a systematic link between the network structure and its predictive perfor mance? What are structural signatures of wellperforming neural networks? How do such structural signatures gener alize across tasks and datasets? Is there an efÔ¨Åcient way to check whether a given neural network is promising or not? Establishing such a relation is both scientiÔ¨Åcally and practi cally important because it would have direct consequences on designing more efÔ¨Åcient and more accurate architectures. It would also inform the design of new hardware architec tures that execute neural networks. Understanding the graph structures that underlie neural networks would also advance the science of deep learning. However, establishing the relation between network archi tecture and its accuracy is nontrivial, because it is unclear how to map a neural network to a graph (and vice versa). The natural choice would be to use computational graph rep resentation but it has many limitations: (1) lack of generality: Computational graphs are constrained by the allowed graph properties, e.g., these graphs have to be directed and acyclic (DAGs), bipartite at the layer level, and singleinsingleout at the network level (Xie et al., 2019). This limits the use of the rich tools developed for general graphs. (2) Disconnec tion with biology/neuroscience: Biological neural networks have a much richer and less templatized structure (Fornito et al., 2013). There are information exchanges, rather than just singledirectional Ô¨Çows, in the brain networks (Stringer et al., 2018). Such biological or neurological models cannot be simply represented by directed acyclic graphs. Here we systematically study the relationship between the graph structure of a neural network and its predictive per formance. We develop a new way of representing a neural network as a graph, which we call relational graph . OurarXiv:2007.06559v2  [cs.LG]  27 Aug 2020Graph Structure of Neural Networks Relational Graphs1 round of message exchange‚ü∫124343214321a b5layer MLP ‚ü∫124343214321‚ü∫124343214321Neural Networks1 layerc Complete graphWSflex graphWSflex graphNeural Net PerformanceTranslate to5layer MLP Translate toResNet34Exploring Relational GraphsRelational GraphRepresentationd Figure 1: Overview of our approach. (a) A layer of a neural network can be viewed as a relational graph where we connect nodes that exchange messages. (b)More examples of neural network layers and relational graphs. (c)We explore the design space of relational graphs according to their graph measures, including average path length and clustering coefÔ¨Åcient, where the complete graph corresponds to a fullyconnected layer. (d)We translate these relational graphs to neural networks and study how their predictive performance depends on the graph measures of their corresponding relational graphs. key insight is to focus on message exchange , rather than just on directed data Ô¨Çow. As a simple example, for a Ô¨Åxed width fullyconnected layer, we can represent one input channel andone output channel together as a single node, and an edge in the relational graph represents the message exchange between the two nodes (Figure 1(a)). Under this formulation, using appropriate message exchange deÔ¨Ånition, we show that the relational graph can represent many types of neural network layers (a fullyconnected layer, a convo lutional layer, etc.), while getting rid of many constraints of computational graphs (such as directed, acyclic, bipartite, singleinsingleout). One neural network layer corresponds to one round of message exchange over a relational graph, and to obtain deep networks, we perform message exchange over the same graph for several rounds . Our new representa tion enables us to build neural networks that are richer and more diverse and analyze them using wellestablished tools of network science (Barab ¬¥asi & Psfai, 2016). We then design a graph generator named WSÔ¨Çex that al lows us to systematically explore the design space of neural networks ( i.e., relation graphs). Based on the insights from neuroscience, we characterize neural networks by the clus tering coefÔ¨Åcient and average path length of their relational graphs (Figure 1(c)). Furthermore, our framework is Ô¨Çexible and general, as we can translate relational graphs into di verse neural architectures, including Multilayer Perceptrons (MLPs), Convolutional Neural Networks (CNNs), ResNets, etc. with controlled computational budgets (Figure 1(d)). Using standard image classiÔ¨Åcation datasets CIFAR10 and ImageNet, we conduct a systematic study on how the ar chitecture of neural networks affects their predictive perfor mance. We make several important empirical observations: ‚Ä¢A ‚Äúsweet spot‚Äù of relational graphs lead to neural networks with signiÔ¨Åcantly improved performance under controlled computational budgets (Section 5.1). ‚Ä¢Neural network‚Äôs performance is approximately a smooth function of the clustering coefÔ¨Åcient and aver age path length of its relational graph. (Section 5.2). ‚Ä¢Our Ô¨Åndings are consistent across many architec tures (MLPs, CNNs, ResNets, EfÔ¨ÅcientNet) and tasks (CIFAR10, ImageNet) (Section 5.3). ‚Ä¢The sweet spot can be identiÔ¨Åed efÔ¨Åciently. Identifying a sweet spot only requires a few samples of relational graphs and a few epochs of training (Section 5.4). ‚Ä¢Wellperforming neural networks have graph structure surprisingly similar to those of real biological neural networks (Section 5.5). Our results have implications for designing neural network architectures, advancing the science of deep learning and improving our understanding of neural networks in general1. 2. Neural Networks as Relational Graphs To explore the graph structure of neural networks, we Ô¨Årst introduce the concept of our relational graph representation and its instantiations. We demonstrate how our representa tion can capture diverse neural network architectures under a uniÔ¨Åed framework. Using the language of graph in the context of deep learning helps bring the two worlds together and establish a foundation for our study. 2.1. Message Exchange over Graphs We start by revisiting the deÔ¨Ånition of a neural network from the graph perspective. We deÔ¨Åne a graph G= 1Code for experiments and analyses are available at https: //github.com/facebookresearch/graph2nnGraph Structure of Neural Networks Fixedwidth MLP Variablewidth MLP ResNet34 ResNet34sep ResNet50 Node feature xiScalar: 1 dimension of dataVector: multiple dimensions of dataTensor: multiple channels of dataTensor: multiple channels of dataTensor: multiple channels of data Message function fi(¬∑) Scalar multiplication(Nonsquare) matrix multiplication3√ó3 Conv3√ó3 depthwise and 1√ó1 Conv3√ó3 and 1√ó1 Conv Aggregation function A GG(¬∑)œÉ(/summationtext(¬∑)) œÉ(/summationtext(¬∑)) œÉ(/summationtext(¬∑)) œÉ(/summationtext(¬∑)) œÉ(/summationtext(¬∑)) Number of rounds R 1 round per layer 1 round per layer34 rounds with residual connections34 rounds with residual connections50 rounds with residual connections Table 1: Diverse neural architectures expressed in the language of relational graphs. These architectures are usually implemented as complete relational graphs, while we systematically explore more graph structures for these architectures. Node feature:"""",%,'‚àà‚Ñù""#,""&‚àà‚Ñù"")Message: %!""$='!$""$Aggregation: ())‚ãÖ=+‚àë‚ãÖRounds: =4MLP layer 24layer 65dim MLPMLP layer 1MLP layer 4MLP layer 34node Relational GraphTranslate""""""%""&""'%""("""")%""(""&)())(‚ãÖ)%""(""%)1234123465dim65dim Figure 2: Example of translating a 4node relational graph to a 4layer 65dim MLP. We highlight the mes sage exchange for node x1. Using different deÔ¨Ånitions of xi,fi(¬∑),AGG(¬∑)andR(those deÔ¨Åned in Table 1), relational graphs can be translated to diverse neural architectures. (V,E)by its node setV={v1,...,v n}and edge set E ‚äÜ{ (vi,vj)|vi,vj‚ààV} . We assume each node vhas a node feature scalar/vector xv. We call graph Garelational graph , when it is associated with message exchanges between neurons. SpeciÔ¨Åcally, a message exchange is deÔ¨Åned by a message function, whose input is a node‚Äôs feature and output is a message, and an aggregation function, whose input is a set of messages and output is the updated node feature. At each round of mes sage exchange, each node sends messages to its neighbors, and aggregates incoming messages from its neighbors. Each message is transformed at each edge through a message functionf(¬∑), then they are aggregated at each node via an aggregation function AGG(¬∑). Suppose we conduct R rounds of message exchange, then the rth round of message exchange for a node vcan be described as x(r+1) v =AGG(r)({f(r) v(x(r) u),‚àÄu‚ààN(v)}) (1) whereu,vare nodes in G,N(v) ={u|v‚à®(u,v)‚ààE} is the neighborhood of node vwhere we assume all nodes have selfedges, x(r) vis the input node feature and x(r+1) v is the output node feature for node v. Note that this message exchange can be deÔ¨Åned over any graph G; for simplicity, we only consider undirected graphs in this paper. Equation 1 provides a general deÔ¨Ånition for message ex change. In the remainder of this section, we discuss how this general message exchange deÔ¨Ånition can be instanti ated as different neural architectures. We summarize thedifferent instantiations in Table 1, and provide a concrete example of instantiating a 4layer 65dim MLP in Figure 2. 2.2. Fixedwidth MLPs as Relational Graphs A Multilayer Perceptron (MLP) consists of layers of com putation units (neurons), where each neuron performs a weighted sum over scalar inputs and outputs, followed by some nonlinearity. Suppose the rth layer of an MLP takes x(r)as input and x(r+1)as output, then a neuron computes: x(r+1) i =œÉ(/summationdisplay jw(r) ijx(r) j) (2) wherew(r) ijis the trainable weight, x(r) jis thejth dimension of the input x(r),i.e.,x(r)= (x(r) 1,...,x(r) n),x(r+1) i is thei th dimension of the output x(r+1), andœÉis the nonlinearity. Let us consider the special case where the input and output of all the layers x(r),1‚â§r‚â§Rhave the same feature dimensions. In this scenario, a fullyconnected, Ô¨Åxedwidth MLP layer can be expressed with a complete relational graph , where each node xiconnects to all the other nodes {x1,...,x n},i.e., neighborhood set N(v) =Vfor each nodev. Additionally, a fullyconnected Ô¨Åxedwidth MLP layer has a special message exchange deÔ¨Ånition, where the message function is fi(xj) =wijxi, and the aggregation function is A GG({xi}) =œÉ(/summationtext{xi}). The above discussion reveals that a Ô¨Åxedwidth MLP can be viewed as a complete relational graph with a special message exchange function. Therefore, a Ô¨Åxedwidth MLP is a special case under a much more general model family, where the message function, aggregation function, and most importantly, the relation graph structure can vary . This insight allows us to generalize Ô¨Åxedwidth MLPs from using complete relational graph to any general relational graphG. Based on the general deÔ¨Ånition of message ex change in Equation 1, we have: x(r+1) i =œÉ(/summationdisplay j‚ààN(i)w(r) ijx(r) j) (3) wherei,jare nodes in GandN(i)is deÔ¨Åned by G.Graph Structure of Neural Networks 2.3. General Neural Networks as Relational Graphs The graph viewpoint in Equation 3 lays the foundation of representing Ô¨Åxedwidth MLPs as relational graphs. In this section, we discuss how we can further generalize relational graphs to general neural networks. Variablewidth MLPs as relational graphs . An important design consideration for general neural networks is that layer width often varies through out the network. For example, in CNNs, a common practice is to double the layer width (number of feature channels) after spatial downsampling. To represent neural networks with variable layer width, we generalize node features from scalar x(r) ito vector x(r) i which consists of some dimensions of the input x(r)for the MLP , i.e.,x(r)=CONCAT (x(r) 1,...,x(r) n), and generalize message function fi(¬∑)from scalar multiplication to matrix multiplication: x(r+1) i =œÉ(/summationdisplay j‚ààN(i)W(r) ijx(r) j) (4) where W(r) ijis the weight matrix. Additionally, we allow that: (1) the same node in different layers, x(r) iandx(r+1) i , can have different dimensions; (2) Within a layer, different nodes in the graph, x(r) iandx(r) j, can have different dimen sions. This generalized deÔ¨Ånition leads to a Ô¨Çexible graph representation of neural networks, as we can reuse the same relational graph across different layers with arbitrary width. Suppose we use an nnode relational graph to represent anmdim layer, then mmodnnodes have‚åäm/n‚åã+ 1di mensions each, remaining n‚àí(mmodn)nodes will have ‚åäm/n‚åãdimensions each. For example, if we use a 4node relational graph to represent a 2layer neural network. If the Ô¨Årst layer has width of 5 while the second layer has width of 9, then the 4 nodes have dimensions {2,1,1,1}in the Ô¨Årst layer and{3,2,2,2}in the second layer. Note that under this deÔ¨Ånition, the maximum number of nodes of a relational graph is bounded by the width of the narrowest layer in the corresponding neural network (since the feature dimension for each node must be at least 1). CNNs as relational graphs . We further make rela tional graphs applicable to CNNs where the input be comes an image tensor X(r). We generalize the deÔ¨Åni tion of node features from vector x(r) ito tensor X(r) ithat consists of some channels of the input image X(r)= CONCAT (X(r) 1,...,X(r) n). We then generalize the message exchange deÔ¨Ånition with convolutional operator. SpeciÔ¨Å cally, X(r+1) i =œÉ(/summationdisplay j‚ààN(i)W(r) ij‚àóX(r) j) (5) where‚àóis the convolutional operator and W(r) ijis the convo lutional Ô¨Ålter. Under this deÔ¨Ånition, the widely used dense convolutions are again represented as complete graphs.Modern neural architectures as relational graphs . Fi nally, we generalize relational graphs to represent modern neural architectures with more sophisticated designs. For example, to represent a ResNet (He et al., 2016), we keep the residual connections between layers unchanged. To represent neural networks with bottleneck transform (He et al., 2016), a relational graph alternatively applies mes sage exchange with 3 √ó3 and 1√ó1 convolution; similarly, in the efÔ¨Åcient computing setup, the widely used separable convolution (Howard et al., 2017; Chollet, 2017) can be viewed as alternatively applying message exchange with 3√ó3 depthwise convolution and 1 √ó1 convolution. Overall, relational graphs provide a general representation for neural networks. With proper deÔ¨Ånitions of node fea tures and message exchange, relational graphs can represent diverse neural architectures, as is summarized in Table 1. 3. Exploring Relational Graphs In this section, we describe in detail how we design and explore the space of relational graphs deÔ¨Åned in Section 2, in order to study the relationship between the graph struc ture of neural networks and their predictive performance. Three main components are needed to make progress: (1) graph measures that characterize graph structural properties, (2)graph generators that can generate diverse graphs, and (3) a way to control the computational budget , so that the differences in performance of different neural networks are due to their diverse relational graph structures. 3.1. Selection of Graph Measures Given the complex nature of graph structure, graph mea sures are often used to characterize graphs. In this paper, we focus on one global graph measure, average path length, and one local graph measure, clustering coefÔ¨Åcient. No tably, these two measures are widely used in network sci ence (Watts & Strogatz, 1998) and neuroscience (Sporns, 2003; Bassett & Bullmore, 2006). SpeciÔ¨Åcally, average path length measures the average shortest path distance between any pair of nodes; clustering coefÔ¨Åcient measures the pro portion of edges between the nodes within a given node‚Äôs neighborhood, divided by the number of edges that could possibly exist between them, averaged over all the nodes. There are other graph measures that can be used for analysis, which are included in the Appendix. 3.2. Design of Graph Generators Given selected graph measures, we aim to generate diverse graphs that can cover a large span of graph measures, using agraph generator . However, such a goal requires careful generator designs: classic graph generators can only gen erate a limited class of graphs, while recent learningbasedGraph Structure of Neural Networks graph generators are designed to imitate given exemplar graphs (Kipf & Welling, 2017; Li et al., 2018; You et al., 2018a;b; 2019a). Limitations of existing graph generators . To illustrate the limitation of existing graph generators, we investigate the following classic graph generators: (1) Erd ÀùosR ¬¥enyi (ER) model that can sample graphs with given node and edge number uniformly at random (Erd Àùos & R ¬¥enyi, 1960); (2) WattsStrogatz (WS) model that can generate graphs with smallworld properties (Watts & Strogatz, 1998); (3) Barab ¬¥asiAlbert (BA) model that can generate scalefree graphs (Albert & Barab ¬¥asi, 2002); (4) Harary model that can generate graphs with maximum connectivity (Harary, 1962); (5) regular ring lattice graphs (ring graphs); (6) complete graphs. For all types of graph generators, we control the number of nodes to be 64, enumerate all possible discrete parameters and grid search over all continuous parameters of the graph generator. We generate 30 random graphs with different random seeds under each parameter setting. In total, we generate 486,000 WS graphs, 53,000 ER graphs, 8,000 BA graphs, 1,800 Harary graphs, 54 ring graphs and 1 complete graph (more details provided in the Appendix). In Figure 3, we can observe that graphs generated by those classic graph generators have a limited span in the space of average path length and clustering coefÔ¨Åcient. WSÔ¨Çex graph generator . Here we propose the WSÔ¨Çex graph generator that can generate graphs with a wide cov erage of graph measures; notably, WSÔ¨Çex graphs almost encompass all the graphs generated by classic random gen erators mentioned above, as is shown in Figure 3. WS Ô¨Çex generator generalizes WS model by relaxing the con straint that all the nodes have the same degree before random rewiring. SpeciÔ¨Åcally, WSÔ¨Çex generator is parametrized by noden, average degree kand rewiring probability p. The number of edges is determined as e=‚åän‚àók/2‚åã. Specif ically, WSÔ¨Çex generator Ô¨Årst creates a ring graph where each node connects to ‚åäe/n‚åãneighboring nodes; then the generator randomly picks emodnnodes and connects each node to one closest neighboring node; Ô¨Ånally, all the edges are randomly rewired with probability p. We use WSÔ¨Çex generator to smoothly sample within the space of clustering coefÔ¨Åcient and average path length, then subsample 3942 graphs for our experiments, as is shown in Figure 1(c). 3.3. Controlling Computational Budget To compare the neural networks translated by these diverse graphs, it is important to ensure that all networks have ap proximately the same complexity, so that the differences in performance are due to their relational graph structures. We use FLOPS (# of multiplyadds) as the metric. We Ô¨Årst com pute the FLOPS of our baseline network instantiations ( i.e. complete relational graph), and use them as the reference Figure 3: Graphs generated by different graph gener ators. The proposed graph generator WSÔ¨Çex can cover a much larger region of graph design space. WS (Watts Strogatz), BA (Barab ¬¥asiAlbert), ER (Erd ÀùosR ¬¥enyi). complexity in each experiment. As described in Section 2.3, a relational graph structure can be instantiated as a neural network with variable width, by partitioning dimensions or channels into disjoint set of node features. Therefore, we can conveniently adjust the width of a neural network to match the reference complexity (within 0.5% of baseline FLOPS) without changing the relational graph structures. We provide more details in the Appendix. 4. Experimental Setup Considering the large number of candidate graphs (3942 in total) that we want to explore, we Ô¨Årst investigate graph structure of MLPs on the CIFAR10 dataset (Krizhevsky, 2009) which has 50K training images and 10K validation images. We then further study the larger and more complex task of ImageNet classiÔ¨Åcation (Russakovsky et al., 2015), which consists of 1K image classes, 1.28M training images and 50K validation images. 4.1. Base Architectures For CIFAR10 experiments, We use a 5layer MLP with 512 hidden units as the baseline architecture. The input of the MLP is a 3072d Ô¨Çattened vector of the ( 32√ó32√ó3) image, the output is a 10d prediction. Each MLP layer has a ReLU nonlinearity and a BatchNorm layer (Ioffe & Szegedy, 2015). We train the model for 200 epochs with batch size 128, using cosine learning rate schedule (Loshchilov & Hut ter, 2016) with an initial learning rate of 0.1 (annealed to 0, no restarting). We train all MLP models with 5 different random seeds and report the averaged results. For ImageNet experiments, we use three ResNetfamily ar chitectures, including (1) ResNet34, which only consists of basic blocks of 3 √ó3 convolutions (He et al., 2016); (2) ResNet34sep, a variant where we replace all 3 √ó3 dense convolutions in ResNet34 with 3 √ó3 separable convolu tions (Chollet, 2017); (3) ResNet50, which consists of bottleneck blocks (He et al., 2016) of 1 √ó1, 3√ó3, 1√ó1 con volutions. Additionally, we use EfÔ¨ÅcientNetB0 architec ture (Tan & Le, 2019) that achieves good performance inGraph Structure of Neural Networks Complete graph Top1 Error: 33.34¬±0.36Best graph Top1 Error: 32.05¬±0.14 Best graph: Best graph:a   5layer MLP on CIFAR10c   ResNet34 on ImageNet Complete graph Top1 Error: 25.73 ¬±0.07Best graph Top1 Error: 24.57¬±0.10b   Measures vs Performance  e   Correlation across neural architecturesd   Measures vs Performance  Complete graph: 25.73 ¬±0.07Best graph: 24.57¬±0.10ResNet34 on ImageNetResNet34sep on ImageNetResNet50 on ImageNetComplete graph: 28.39¬±0.05Best graph: 27.17¬±0.18Complete graph: 23.09¬±0.05Best graph: 22.42¬±0.095layer MLP on CIFAR10Complete graph: 33.34¬±0.36Best graph: 32.05¬±0.14EfficientNetB0 on ImageNetComplete graph: 25.59¬±0.05Best graph: 25.07¬±0.178layer CNN on ImageNetComplete graph: 48.27 ¬±0.14Best graph: 46.73¬±0.16f   Summary of all the experiments Figure 4: Key results. The computational budgets of all the experiments are rigorously controlled. Each visualized result is averaged over at least 3 random seeds. A complete graph with C= 1andL= 1(lower right corner) is regarded as the baseline. (a)(c) Graph measures vs.neural network performance. The best graphs signiÔ¨Åcantly outperform the baseline complete graphs. (b)(d) Single graph measure vs.neural network performance. Relational graphs that fall within the given range are shown as grey points. The overall smooth function is indicated by the blue regression line. (e) Consistency across architectures. Correlations of the performance of the same set of 52 relational graphs when translated to different neural architectures are shown. (f) Summary of all the experiments. Best relational graphs (the red crosses) consistently outperform the baseline complete graphs across different settings. Moreover, we highlight the ‚Äúsweet spots‚Äù (red rectangular regions), in which relational graphs are not statistically worse than the best relational graphs (bins with red crosses). Bin values of 5layer MLP on CIFAR10 are average over all the relational graphs whose CandLfall into the given bin. the small computation regime. Finally, we use a simple 8 layer CNN with 3√ó3 convolutions. The model has 3 stages with [64, 128, 256] hidden units. Stride2 convolutions are used for downsampling. The stem and head layers are the same as a ResNet. We train all the ImageNet models for 100 epochs using cosine learning rate schedule with initial learning rate of 0.1. Batch size is 256 for ResNet family models and 512 for EfÔ¨ÅcientNetB0. We train all ImageNet models with 3 random seeds and report the av eraged performance. All the baseline architectures have a complete relational graph structure. The reference computa tional complexity is 2.89e6 FLOPS for MLP, 3.66e9 FLOPS for ResNet34, 0.55e9 FLOPS for ResNet34sep, 4.09e9 FLOPS for ResNet50, 0.39e9 FLOPS for EffcientNetB0, and 0.17e9 FLOPS for 8layer CNN. Training an MLP model roughly takes 5 minutes on a NVIDIA Tesla V100 GPU, and training a ResNet model on ImageNet roughly takes a day on 8 Tesla V100 GPUs with data parallelism. We provide more details in Appendix.4.2. Exploration with Relational Graphs For all the architectures, we instantiate each sampled rela tional graph as a neural network, using the corresponding deÔ¨Ånitions outlined in Table 1. SpeciÔ¨Åcally, we replace all the dense layers (linear layers, 3 √ó3 and 1√ó1 convolution layers) with their relational graph counterparts. We leave the input and output layer unchanged and keep all the other designs (such as downsampling, skipconnections, etc.) in tact. We then match the reference computational complexity for all the models, as discussed in Section 3.3. For CIFAR10 MLP experiments, we study 3942 sampled relational graphs of 64 nodes as described in Section 3.2. For ImageNet experiments, due to high computational cost, we subsample 52 graphs uniformly from the 3942 graphs. Since EfÔ¨ÅcientNetB0 is a small model with a layer that has only 16 channels, we can not reuse the 64node graphs sampled for other setups. We resample 48 relational graphs with 16 nodes following the same procedure in Section 3.Graph Structure of Neural Networks 5. Results In this section, we summarize the results of our experiments and discuss our key Ô¨Åndings. We collect top1 errors for all the sampled relational graphs on different tasks and ar chitectures, and also record the graph measures (average path length Land clustering coefÔ¨Åcient C) for each sam pled graph. We present these results as heat maps of graph measures vs.predictive performance (Figure 4(a)(c)(f)). 5.1. A Sweet Spot for Top Neural Networks Overall, the heat maps of graph measures vs.predictive per formance (Figure 4(f)) show that there exist graph structures that can outperform the complete graph (the pixel on bottom right) baselines. The best performing relational graph can outperform the complete graph baseline by 1.4% top1 error on CIFAR10, and 0.5% to 1.2% for models on ImageNet. Notably, we discover that topperforming graphs tend to cluster into a sweet spot in the space deÔ¨Åned by CandL (red rectangles in Figure 4(f)). We follow these steps to identify a sweet spot: (1) we downsample and aggregate the 3942 graphs in Figure 4(a) into a coarse resolution of 52 bins, where each bin records the performance of graphs that fall into the bin; (2) we identify the bin with best average performance (red cross in Figure 4(f)); (3) we conduct one tailed ttest over each bin against the bestperforming bin, and record the bins that are notsigniÔ¨Åcantly worse than the bestperforming bin ( pvalue 0.05 as threshold). The minimum area rectangle that covers these bins is visualized as a sweet spot. For 5layer MLP on CIFAR10, the sweet spot isC‚àà[0.10,0.50],L‚àà[1.82,2.75]. 5.2. Neural Network Performance as a Smooth Function over Graph Measures In Figure 4(f), we observe that neural network‚Äôs predictive performance is approximately a smooth function of the clus tering coefÔ¨Åcient and average path length of its relational graph. Keeping one graph measure Ô¨Åxed in a small range (C‚àà[0.4,0.6],L‚àà[2,2.5]), we visualize network perfor mances against the other measure (shown in Figure 4(b)(d)). We use second degree polynomial regression to visualize the overall trend. We observe that both clustering coefÔ¨Åcient and average path length are indicative of neural network performance, demonstrating a smooth Ushape correlation. 5.3. Consistency across Architectures Given that relational graph deÔ¨Ånes a shared design space across various neural architectures, we observe that rela tional graphs with certain graph measures may consistently perform well regardless of how they are instantiated. correlation = 0.90correlation = 0.93 52 graphs100 epochs3 epochs 5layer MLPon CIFAR103942 graphs ResNet34 on ImageNetFigure 5: Quickly identifying a sweet spot. Left: The cor relation between sweet spots identiÔ¨Åed using fewer samples of relational graphs and using all 3942 graphs. Right: The correlation between sweet spots identiÔ¨Åed at the intermedi ate training epochs and the Ô¨Ånal epoch (100 epochs). Qualitative consistency . We visually observe in Figure 4(f) that the sweet spots are roughly consistent across dif ferent architectures. SpeciÔ¨Åcally, if we take the union of the sweet spots across architectures, we have C‚àà[0.43,0.50], L‚àà[1.82,2.28]which is the consistent sweet spot across architectures. Moreover, the Ushape trends between graph measures and corresponding neural network performance, shown in Figure 4(b)(d), are also visually consistent. Quantitative consistency . To further quantify this consis tency across tasks and architectures, we select the 52 bins in the heat map in Figure 4(f), where the bin value indicates the average performance of relational graphs whose graph measures fall into the bin range. We plot the correlation of the 52 bin values across different pairs of tasks, shown in Figure 4(e). We observe that the performance of relational graphs with certain graph measures correlates across dif ferent tasks and architectures. For example, even though a ResNet34 has much higher complexity than a 5layer MLP, and ImageNet is a much more challenging dataset than CIFAR10, a Ô¨Åxed set relational graphs would perform similarly in both settings, indicated by a Pearson correlation of 0.658 (pvalue <10‚àí8). 5.4. Quickly Identifying a Sweet Spot Training thousands of relational graphs until convergence might be computationally prohibitive. Therefore, we quanti tatively show that a sweet spot can be identiÔ¨Åed with much less computational cost, e.g., by sampling fewer graphs and training for fewer epochs. How many graphs are needed? Using the 5layer MLP on CIFAR10 as an example, we consider the heat map over 52 bins in Figure 4(f) which is computed using 3942 graph samples. We investigate if a similar heat map can beGraph Structure of Neural Networks Graph Path (L) Clustering (C) CIFAR10 Error (%) Complete graph 1.00 1.00 33.34 ¬±0.36 Cat cortex 1.81 0.55 33.01 ¬±0.22 Macaque visual cortex 1.73 0.53 32.78 ¬±0.21 Macaque whole cortex 2.38 0.46 32.77¬±0.14 Consistent sweet spot across neural architectures1.822.28 0.430.50 32.50¬±0.33 Best 5layer MLP 2.48 0.45 32.05¬±0.14 Table 2: Top artiÔ¨Åcial neural networks can be similar to biological neural networks (Bassett & Bullmore, 2006). Biological neural network:Macaque whole cortexArtificial neural network:Best 5layer MLP Figure 6: Visualizations of graph structure of biological (left) and artiÔ¨Åcial ( right ) neural networks. produced with much fewer graph samples. SpeciÔ¨Åcally, we subsample the graphs in each bin while making sure each bin has at least one graph. We then compute the correlation between the 52 bin values computed using all 3942 graphs and using subsampled fewer graphs, as is shown in Figure 5 (left). We can see that bin values computed using only 52 samples have a high 0.90Pearson correlation with the bin values computed using full 3942 graph samples. This Ô¨Ånding suggests that, in practice, much fewer graphs are needed to conduct a similar analysis. How many training epochs are needed? Using ResNet 34 on ImageNet as an example, we compute the correlation between the validation top1 error of partially trained models and the validation top1 error of models trained for full 100 epochs, over the 52 sampled relational graphs, as is visualized in Figure 5 (right). Surprisingly, models trained after 3 epochs already have a high correlation (0.93), which means that good relational graphs perform well even at the early training epochs . This Ô¨Ånding is also important as it indicates that the computation cost to determine if a relational graph is promising can be greatly reduced. 5.5. Network Science and Neuroscience Connections Network science . The average path length that we measure characterizes how well information is exchanged across the network (Latora & Marchiori, 2001), which aligns with our deÔ¨Ånition of relational graph that consists of rounds of message exchange. Therefore, the Ushape correlation in Figure 4(b)(d) might indicate a tradeoff between message exchange efÔ¨Åciency (Sengupta et al., 2013) and capability of learning distributed representations (Hinton, 1984).Neuroscience . The bestperforming relational graph that we discover surprisingly resembles biological neural net works, as is shown in Table 2 and Figure 6. The similarities are in twofold: (1) the graph measures ( LandC) of top artiÔ¨Åcial neural networks are highly similar to biological neural networks; (2) with the relational graph representation, we can translate biological neural networks to 5layer MLPs, and found that these networks also outperform the baseline complete graphs. While our Ô¨Åndings are preliminary, our approach opens up new possibilities for interdisciplinary re search in network science, neuroscience and deep learning. 6. Related Work "
156,A Security Verification Framework of Cryptographic Protocols Using Machine Learning.txt,"We propose a security verification framework for cryptographic protocols
using machine learning. In recent years, as cryptographic protocols have become
more complex, research on automatic verification techniques has been focused
on. The main technique is formal verification. However, the formal verification
has two problems: it requires a large amount of computational time and does not
guarantee decidability. We propose a method that allows security verification
with computational time on the order of linear with respect to the size of the
protocol using machine learning. In training machine learning models for
security verification of cryptographic protocols, a sufficient amount of data,
i.e., a set of protocol data with security labels, is difficult to collect from
academic papers and other sources. To overcome this issue, we propose a way to
create arbitrarily large datasets by automatically generating random protocols
and assigning security labels to them using formal verification tools.
Furthermore, to exploit structural features of protocols, we construct a neural
network that processes a protocol along its series and tree structures. We
evaluate the proposed method by applying it to verification of practical
cryptographic protocols.","Today, cryptographic protocols are used in a variety of impor tant situations and are indispensable technologies. For exam ple, TLS 1.3 is used for conÔ¨Ådentiality, tamper detection, and authentication of communication partners on the Internet [39]. Vulnerabilities in cryptographic protocols can compromise communications over the Internet and tamper with electronic transactions. The impact is serious, and therefore the secu rity of cryptographic protocols is important. However, the design of cryptographic protocols is generally complex and errorprone. To design complex and correct cryptographic protocols, designers often use computer aids such as automated ver iÔ¨Åcation tools. As we input the protocol speciÔ¨Åcation andsecurity requirements, an ideal automated veriÔ¨Åcation tool instantly outputs whether the protocol satisÔ¨Åes the security requirements or not. A typical example of such an automatic veriÔ¨Åcation tool is a formal veriÔ¨Åcation tool based on model checking. Formal veriÔ¨Åcation is a technique that describes a target using a formal language and veriÔ¨Åes whether or not the target satisÔ¨Åes certain requirements by using mathematical techniques. In particular, formal veriÔ¨Åcation tools based on model checking provide exhaustive veriÔ¨Åcation by thoroughly enumerating possible states of the target and verifying all pos sible paths to the target. There are many formal veriÔ¨Åcation tools for cryptographic protocols; ProVerif [8,10] and Tamarin prover [3, 38] are wellknown examples. These tools are used in the design of widely used cryptographic protocols and con tribute to the design of secure protocols. For example, formal veriÔ¨Åcation tools were used in the standardization process of TLS 1.3 and 5G authentication protocols, and many vulnera bilities were found by these tools [4, 5, 7, 9, 22, 24 ‚Äì27, 47]. As shown in these examples, the strength of formal veriÔ¨Åcation tools is that they can Ô¨Ånd vulnerabilities that are difÔ¨Åcult for the human eye to detect. The problem with formal veriÔ¨Åcation is the time required to perform exhaustive veriÔ¨Åcation. In addition, veriÔ¨Åcation may never be completed because the veriÔ¨Åcation tools do not have decidability [29, 43]. For example, the TLS veriÔ¨Åcation by Bhargavan et al. [7] took up to 35 hours. Therefore, the veriÔ¨Åer should devise ways to formalize the protocol and use the tools to complete the veriÔ¨Åcation within the effective time. This requires highlevel expertise. This is one reason that many excellent formal veriÔ¨Åcation tools for cryptographic protocols exist but have not received enough attention in the industry. To perform veriÔ¨Åcation in practical time, we focus on ma chine learning techniques, in particular deep learning, as a veriÔ¨Åcation tool. In general, a machine learning model makes inferences on a single input decisively in a short time. Thus, the veriÔ¨Åcation of the security of cryptographic protocols is expected to always terminate in a short period of time. We consider using deep learning, which is expected to be highly 1arXiv:2304.13249v1  [cs.CR]  26 Apr 2023101 102 11 1 2 0 0 12 1 2 0 0 I R œâT 1 œâsign 0 0 œâID 1 œâsign 0 0plain sign enc. hash plain sign enc. hash I > R : T I , ID R , sign I (T I , ID R)TLM I > R : T I , ID R , sign I (T I , ID R)0 0 2 1 12 0 I I I R[ ](a) An example of protocol conversion by the method TLM [37]. Tree LSTM I > R : T I , IDR , sign I (TI , IDR)Send I > R IDR signI TI IDRh TI IDR TIhsend I > R (T I , IDR , sign I (TI , IDR)) hsend I > R (T I , IDR , sign I (TI , IDR)) TI xTIxIDRxTIxIDRhIDRhTIhIDRhsign I (TI , IDR) xsignI (b) An example of protocol conversion by our proposed method. Figure 1: Comparison of protocol conversion between the previous method [37] and our proposed method. The previous method loses information on the hierarchical structure such as the order of application of operations such as signing and encryption during the conversion (see Section 4.3). In contrast, the proposed method enables the conversion that reÔ¨Çects the order of application of operations by using a neural network that incorporates a tree structure. accurate among machine learning methods. Deep learning has achieved great successes in a wide range of areas such as image classiÔ¨Åcation [31], image generation [32], and lan guage processing [13], particularly where abundant training data are available. The goal of this paper is to construct a veriÔ¨Åer for cryptographic protocols using machine learning that is practically fast, decidable, and accurate. To achieve this, large amounts of training data and an ap propriate model are desirable [13, 31]. At present, such a veriÔ¨Åer using machine learning has not been realized. One reason is the difÔ¨Åculty of collecting training data. The train ing data consists of pairs of cryptographic protocols and their security label. This information is usually obtained from pa pers, textbooks, and standardization documents. They are few in number, and there are not enough pairs of cryptographic protocols and their security labels for training. Therefore, a sufÔ¨Åcient amount of training data is difÔ¨Åcult to collect. There are two previous studies using machine learning to verify the security of cryptographic protocols [37, 45], but the number of training data in those studies is only 500 to 1000, which is insufÔ¨Åcient. Another issue is construction of machine learning models suitable for processing cryptographic protocols. Since cryptographic protocols can easily violate the security re quirements if the protocols are slightly changed [12], detailed information of protocols including hierarchical structures of messages in the protocols should be encoded to a vector by a machine learning model. However, this makes it difÔ¨Åcult to construct a model that can appropriately handle crypto graphic protocols. Previous studies have proposed methods for converting protocols to vectors of Ô¨Åxed length, but there is no onetoone correspondence between protocols and converted vectors, i.e., multiple different protocols are converted to the same vector (Figure 1a). Such conversion causes the loss of structural information of the cryptographic protocols, which prevents the achievement of high veriÔ¨Åcation accuracy. Therefore, for accurate protocol veriÔ¨Åcation, machine learn ing models need to be generated that reÔ¨Çect information on hierarchical structures that are ignored by existing methods. The construction of a model that adapts to the data struc ture of cryptographic protocols is expected to improve the accuracy of security veriÔ¨Åcation and lead to more advanced applications such as automatic modiÔ¨Åcation of protocols. We address the aforementioned two problems. First, we propose a method to automatically generate training data, i.e., pairs of cryptographic protocols and security labels. Specif ically, we propose a method that automatically generates a random cryptographic protocol, converts the protocol to the input format of a formal veriÔ¨Åcation tool, and obtains a secu rity label. This enables us to prepare arbitrarily large training datasets without manually collecting protocol data from the lit erature. Moreover, we propose a method to construct a model that has both a sequence structure and a tree structure as a model that can handle cryptographic protocols (Figure 1b). This is based on the idea that a cryptographic protocol is a sequence of messages, i.e., has a series structure, and each message has a syntax tree structure with encryption opera tions, etc. as nodes. The proposed model is suitable for cap turing a hierarchical structure of protocols and thus should verify the security of protocols more correctly than the pre vious methods. Furthermore, we show that the processing time of the model depends linearly on the size of protocols, which is desirable for practical use. In summary, we propose 2a novel security veriÔ¨Åcation framework of cryptographic pro tocols based on machine learning that provides practically fast, decidable, and accurate veriÔ¨Åcation. As a feasibility test, we implemented the proposed method and veriÔ¨Åed the conÔ¨Ådentiality of the key exchange protocol using practical protocols. In the results, we achieved a 79.5% veriÔ¨Åcation accuracy. The contributions of this paper are summarized as follows. To construct a protocol veriÔ¨Åer that is practically fast, decid able, and accurate, we do the following: 1.We propose a method to automatically generate a large training dataset to achieve a highly accurate security veriÔ¨Åer using machine learning for cryptographic proto cols without manually collecting protocol data from the literature. 2.We propose a model having both series and tree struc tures that is suitable for handling cryptographic proto cols. The proposed model further improves the accuracy of veriÔ¨Åcation. 3.We validate our framework for security veriÔ¨Åcation of cryptographic protocols based on the method in 1 and the model in 2 above by feasibility tests. The proposed method achieves 79.5 percent accuracy in veriÔ¨Åcation of practical protocols. The paper is organized as follows: Section 2 describes the related works, and Section 3 brieÔ¨Çy introduces cryptographic protocols, their formal veriÔ¨Åcation techniques, and neural net works. In Section 4, we introduce the proposed method. Sec tion 5 describes the implementation and experiments, and Section 6 summarizes this paper. 2 Related Work "
32,Effect of context in swipe gesture-based continuous authentication on smartphones.txt,"This work investigates how context should be taken into account when
performing continuous authentication of a smartphone user based on touchscreen
and accelerometer readings extracted from swipe gestures. The study is
conducted on the publicly available HMOG dataset consisting of 100 study
subjects performing pre-defined reading and navigation tasks while sitting and
walking. It is shown that context-specific models are needed for different
smartphone usage and human activity scenarios to minimize authentication error.
Also, the experimental results suggests that utilization of phone movement
improves swipe gesture-based verification performance only when the user is
moving.","Traditional ‚Äùobtrusive‚Äù authentication schemes, like passwords, PIN codes and biometrics, do not provide mechanisms to determine whether an act ive mobile device is being used by the same (or some other) authorized person after the initial accesshas been granted. Continuousauthentication (CA), alsoreferred to as active or implicit authentication, aims at verifying that a device is be ing used by a legitimate person after login by constantly monitoring the builtin sensor and device usage data, like (partial) face images, touchscreen ges tures, device motion, power consumption, in the background (transparently to the user) [1]. Touchscreen gesturebased user veriÔ¨Åcation has been a popular approach in CA [1]. Touchinput is directlyrelatedto the actual physicalinteract ionwith the mobile device, thus could be probably used for fast intrusion detect ion. Most of the existing works have focused on analysing singleÔ¨Ånger swipes, i.e . drag and Ô¨Çick, but also other single and multiÔ¨Ånger gestures, like tap/typing , pinch and spread, could be used for touch biometrics. Intuitively, unique pho ne motion patterns may be observed while user is using touchscreen, thus jo int analysis of touch and consequent motion signals has been proposed for CA [2]. A major limitation with prior works on touch biometrics, and CA in gener al, has been that phone usage and human activity contexts have not b een properly taken into account. It can be expected that touchscreen gestu res and phone movement patterns have signiÔ¨Åcant diÔ¨Äerences depending whethe r the user is browsing or reading (phone usage), or is stationary or moving (hum an activity), which suggests that CA systems need to be contextaware. Furt hermore, phone ‚àóThis work was partially funded by the Finnish Foundation for Technology Promotion.usage context also deÔ¨Ånes whether authentication should be perf ormed in the Ô¨Årst place. For instance, user veriÔ¨Åcation is not probably needed f or casual browsing, while it is crucial if private or conÔ¨Ådential data is being acce ssed [3]. The preliminary studies [3, 4, 5, 6] have demonstrated that applicat ion or task speciÔ¨Åc (phone usage context) modelling can indeed boost the performance of swipebased CA, while only marginal improvement has been achieve d when human activity context has been considered [6]. So far, human activ ity context based models have shown to be useful only when CA is performed bas ed on solely phone movement patterns [7] or combined with typing (tap ges tures) [8]. In this work, we investigate the role of context when CA is conducte d based on touchscreen and accelerometer readings extracted from swip e gestures. Our experimental analysis is performed on the publicly available HMOG data set [8] consisting of 100 subjects each performing predeÔ¨Åned reading a nd navigation tasks while sitting and walking. We show that both phone usage and hu man activitycontextshouldbeconsideredinswipegesturebasedCA.I naddition, our Ô¨Åndings suggest that swipebased CA should rely solely on touch sign als when the user is stationary, while inclusion of phone movement patterns im prove CA performance only when the user is moving. (a) Touch feature distribution in read (left) vs. navigation (right) phone usage scenarios. (b) Motion feature distribution in two human activities, sitting (left) vs. walking (right). Fig. 1: The Ô¨Årst two principal components and the corresponding G aussian mixture models of touch and phone movement based swipe features computed over all subjects in the HMOG dataset [8], highlighting the importance context aware modelling in diÔ¨Äerent a) phone usage and b) human activity scen arios. 2 Methodology "
287,Verifying Properties of Binarized Deep Neural Networks.txt,"Understanding properties of deep neural networks is an important challenge in
deep learning. In this paper, we take a step in this direction by proposing a
rigorous way of verifying properties of a popular class of neural networks,
Binarized Neural Networks, using the well-developed means of Boolean
satisfiability. Our main contribution is a construction that creates a
representation of a binarized neural network as a Boolean formula. Our encoding
is the first exact Boolean representation of a deep neural network. Using this
encoding, we leverage the power of modern SAT solvers along with a proposed
counterexample-guided search procedure to verify various properties of these
networks. A particular focus will be on the critical property of robustness to
adversarial perturbations. For this property, our experimental results
demonstrate that our approach scales to medium-size deep neural networks used
in image classification tasks. To the best of our knowledge, this is the first
work on verifying properties of deep neural networks using an exact Boolean
encoding of the network.","Deep neural networks have become ubiquitous in machine learning with applications ranging from computer vision to speech recognition and natural language processing. Neu ral networks demonstrate excellent performance in many practical problems, often beating specialized algorithms for these problems, which led to their rapid adoption in in dustrial applications. With such a wide adoption, important questions arise regarding our understanding of these neu ral networks: How robust are these networks to perturba tions of inputs? How critical is the choice of one archi tecture over the other? Does certain ordering of transfor mations matter? Recently, a new line of research on un derstanding neural networks has emerged that look into a wide range of such questions, from interpretability of neu ral networks to verifying their properties (Bau et al. 2017; Szegedy et al. 2014; Bastani et al. 2016; Huang et al. 2017; Katz et al. 2017). In this work we focus on an important class of neural networks: Binarized Neural Networks (BNNs) (Hubara et Copyright c 2018, Association for the Advancement of ArtiÔ¨Åcial Intelligence (www.aaai.org). All rights reserved.al. 2016). These networks have a number of important fea tures that are useful in resource constrained environments, like embedded devices or mobile phones. Firstly, these net works are memory efÔ¨Åcient, as their parameters are primar ily binary. Secondly, they are computationally efÔ¨Åcient as all activations are binary, which enables the use of specialized algorithms for fast binary matrix multiplication. These net works have been shown to achieve performance comparable to traditional deep networks that use Ô¨Çoating point precision on several standard datasets (Hubara et al. 2016). Recently, BNNs have been deployed for various embedded applica tions ranging from image classiÔ¨Åcation (McDanel, Teerapit tayanon, and Kung 2017) to object detection (Kung et al. 2017). The goal of this work is to analyze properties of bina rized neural networks through the lens of Boolean satisÔ¨Åa bility (SAT). Our main contribution is a procedure for con structing a SAT encoding of a binarized neural network. An important feature of our encoding is that it is exact and does not rely on any approximations to the network struc ture. This means that this encoding allows us to investi gate properties of BNNs by studying similar properties in the SAT domain, and the mapping of these properties back from the SAT to the neural network domain is exact. To the best of our knowledge, this is the Ô¨Årst work on verifying properties of deep neural networks using an exact Boolean encoding of a network. In our construction, we exploit at tributes of BNN‚Äôs, both functional , e.g., most parameters of these networks are binary, and structural , e.g., the modu lar structure of these networks. While these encodings could be directly handled by modern SAT solvers, we show that one can exploit the structure of these encodings to solve the resulting SAT formulas more efÔ¨Åciently based on the idea of counterexampleguided search (Clarke et al. 2000; McMillan 2005; McMillan 2003). While our encoding could be used to study many proper ties of BNNs, in this paper we focus on important properties of network robustness andequivalence . 1. Deep neural networks have been shown susceptible to crafted adversarial perturbations which force misclassi Ô¨Åcation of the inputs. Adversarial inputs can be used to subvert fraud detection, malware detection, or mislead autonomous navigation systems (Papernot et al. 2016; Grosse et al. 2016) and pose a serious security risk (e.g.,arXiv:1709.06662v2  [stat.ML]  31 May 2018consider an adversary that can fool an autonomous driv ing system into not following posted trafÔ¨Åc signs). There fore, certiÔ¨Åably verifying robustness of these networks to adversarial perturbation is a question of paramount practi cal importance. Using a SAT encoding, we can certiÔ¨Åably establish whether or not a BNN is robust to adversarial perturbation on a particular image. 2. Problems of verifying whether two networks are equiva lent in their operations regularly arise when dealing with network alterations (such as that produced by model re duction operations (Reagen et al. 2017)) and input prepro cessing. Again, with our SAT encodings, we can check for network equivalence or produce instances where the two networks differ in their operation. Experimentally, we show that our techniques can verify properties of mediumsized BNNs. In Section 8, we present a set of experiments on the MNIST dataset and its variants. For example, for a BNN with Ô¨Åve fully connected layers, we are able to prove the absence of an adversarial perturba tion or Ô¨Ånd such a perturbation for up to 95% of considered images. 2 Preliminaries Notation. We denote [m] =f1;:::;mg. Vectors are in columnwise fashion, denoted by boldface letters. For a vec torv2Rm, we use (v1;:::;vm)to denote its melements. Forp1, we usekvkpto denote the Lpnorm of v. For a Boolean CNF (Conjunctive Normal Form) formula A, let vars(A)denote the set of variables in A. We sayAisun satisÔ¨Åable if there exists no assignment to the variables in vars(A)that evaluates the formula to true, otherwise we say AissatisÔ¨Åable . LetAandBbe Boolean formulas. We de note Athe negation of A. We say that AimpliesB(A)B) iffA_Bis satisÔ¨Åable and Aisequivalent toB(A,B) iffA)BandB)A. Next, we deÔ¨Åne the supervised image classiÔ¨Åcation prob lem that we focus on. We are given a set of training images drawn from an unknown distribution overZn, wheren here represents the ‚Äúsize‚Äù of individual images. Each image is associated with a label generated by an unknown function L:Zn![s], where [s] =f1;:::;sgis a set of possible labels. During the training phase, given a labeled training set, the goal is to learn a neural network classiÔ¨Åer that can be used for inference: given a new image drawn from the same distribution , the classiÔ¨Åer should predict its true la bel. During the inference phase, the network is Ô¨Åxed . In this work, we study properties of such Ô¨Åxed networks generated post training. Properties of Neural Networks In this section, we deÔ¨Åne several important properties of neural networks, ranging from robustness to properties re lated to network structure. As the properties deÔ¨Åned in this section are not speciÔ¨Åc to BNNs, we consider a general feedforward neural network denoted by F. Let F (x)repre sent the output of F on input xand`x=L(x)be the ground truth label of x. For example, xcan be an image of a bus and `xis its ground truth label, i.e. ‚Äòbus‚Äô.Adversarial Network Robustness. Robustness is an im portant property that guards the network against adversarial tampering of its outcome by perturbing the inputs. In the past few years, modern deep networks have been shown suscep tible to crafted adversarial perturbations which force mis classiÔ¨Åcation of the inputs, especially images. Adversarial inputs enable adversaries to subvert the expected system be havior leading to undesired consequences and could pose a security risk when these systems are deployed in the real world. There are now many techniques for generating ad versarial inputs, e.g., see (Szegedy et al. 2014; Goodfellow, Shlens, and Szegedy 2015; MoosaviDezfooli, Fawzi, and Frossard 2016). Therefore, a natural question is to under stand how susceptible a network is to any form of adver sarial perturbation (Goodfellow, Shlens, and Szegedy 2015; MoosaviDezfooli, Fawzi, and Frossard 2016; Bastani et al. 2016). Informally, a network is robust on an input if small perturbations to the input does not lead to misclassiÔ¨Åcation. More formally, DeÔ¨Ånition 1 (Adversarial Robustness1).A feedforward neu ral network Fis(;p)robust for an input xif there does not exist,kkp, such that F(x+)6=`x. The case of p=1, which bounds the maximum pertur bation applied to each entry in x, is especially interesting and has been considered frequently in the literature on ad versarial attacks in deep learning (Goodfellow, Shlens, and Szegedy 2015; Bastani et al. 2016; Katz et al. 2017). Another popular deÔ¨Ånition of robustness comes from the notion of universal adversarial perturbation as deÔ¨Åned by (MoosaviDezfooli et al. 2016). Intuitively, a universal adversarial perturbation is one that leads to misclassiÔ¨Åcation on most (say, fraction) of the inputs in a set of images. Absence of such a perturbation is captured in the following deÔ¨Ånition of robustness. Let Sdenote a set of images. DeÔ¨Ånition 2 (Universal Adversarial Robustness) .A feedfor ward neural network Fis(;p; )universally robust for a set of inputs in Sif there does not exist ,kkp, such thatP xi2S1F(xi+)6=lxijSj. Network Equivalence. Similar to robustness, a property that is commonly veriÔ¨Åed is that of equivalence of networks. Informally, two networks F 1and F 2are equivalent if these networks generate same outputs on all inputs drawn from the domain. LetXdenote the domain from which inputs are drawn. In the case of images, X=Zn. DeÔ¨Ånition 3 (Network Equivalence) .Two feedforward neu ral networks F1and F2are equivalent if for all x2 X , F1(x) =F2(x). We describe two common scenarios where such equiva lence problem arises in practice. 1. Network Alteration: Consider a scenario where a part of the trained network has been altered to form a new net work. This change could arise due to model reduction operations that are commonly performed on deep net works to make them amenable for execution on resource constrained devices (Reagen et al. 2017) or they could 1The deÔ¨Ånition naturally extends to a collection of inputs.arise from other sources of noise including adversarial corruption of the network. The question now is whether the altered network is equivalent to the original network? 2. Augmentation Reordering: Consider a scenario where an input is preprocessed (augmented) before it is supplied to a network. Examples of such preprocessing include geo metrical transformations, blurring, etc. Let f:X !X andg:X!X be two transformation functions (this ex tends to more transformation functions too). We want to know how sensitive the network is to the order of applica tions offandg. For example, given a network F, let F 1be the network that applies fgon the input followed by F, and F 2be the network that applies gfon the input fol lowed by F. The question now is whether F 1is equivalent to F 2? 3 Binarized Neural Networks A binarized neural network (BNN) is a feedforward net work where weights and activations are predominantly bi nary (Hubara et al. 2016). It is convenient to describe the structure of a BNN in terms of composition of blocks of layers rather than individual layers. Each block consists of a collection of linear and nonlinear transformations. Blocks are assembled sequentially to form a BNN. Internal Block. Each internal block (denoted as B LK) in a BNN performs a collection of transformations over a binary input vector and outputs a binary vector. While the input and output of a B LKare binary vectors, the internal layers of BLKcan produce realvalued intermediate outputs. A com mon construction of an internal B LK(taken from (Hubara et al. 2016)) is composed of three main operations:2a lin ear transformation (L IN), batch normalization (B N), and bi narization (B IN). Table 1 presents the formal deÔ¨Ånition of these transformations. The Ô¨Årst step is a linear (afÔ¨Åne) trans formation of the input vector. The linear transformation can be based on a fully connected layer or a convolutional layer. The linear transformation is followed by a scaling which is performed with a batch normalization operation (Ioffe and Szegedy 2015). Finally, a binarization is performed using thesign function to obtain a binary output vector.3Figure 1 shows two B LKs connected sequentially. Output Block. The output block (denoted as O) produces the classiÔ¨Åcation decision for a given image. It consists of two layers (see Table 1). The Ô¨Årst layer applies a linear (afÔ¨Åne) transformation that maps its input to a vector of in tegers, one for each output label class. This is followed by a ARGMAX layer, which outputs the index of the largest entry in this vector as the predicted label. Network of Blocks. BNN is a deep feedforward net work formed by assembling a sequence of internal blocks 2In the training phase, there is an additional hard tanh layer after batch normalization layer that is omitted in the inference phase (Hubara et al. 2016). 3A B LKmay also contain a max pooling operation to perform dimensionality reduction, which can be simulated using a convo lutional layer with an appropriately chosen stride (Springenberg et al. 2015). LIN BN BIN x Block 1 LIN BN BIN Block 2 LIN ARGMAX OutputoFigure 1: A schematic view of a binarized neural network. The internal blocks also have an additional hard tanh layer. and an output block. Suppose we have d"
94,Deep Generation of Coq Lemma Names Using Elaborated Terms.txt,"Coding conventions for naming, spacing, and other essentially stylistic
properties are necessary for developers to effectively understand, review, and
modify source code in large software projects. Consistent conventions in
verification projects based on proof assistants, such as Coq, increase in
importance as projects grow in size and scope. While conventions can be
documented and enforced manually at high cost, emerging approaches
automatically learn and suggest idiomatic names in Java-like languages by
applying statistical language models on large code corpora. However, due to its
powerful language extension facilities and fusion of type checking and
computation, Coq is a challenging target for automated learning techniques. We
present novel generation models for learning and suggesting lemma names for Coq
projects. Our models, based on multi-input neural networks, are the first to
leverage syntactic and semantic information from Coq's lexer (tokens in lemma
statements), parser (syntax trees), and kernel (elaborated terms) for naming;
the key insight is that learning from elaborated terms can substantially boost
model performance. We implemented our models in a toolchain, dubbed Roosterize,
and applied it on a large corpus of code derived from the Mathematical
Components family of projects, known for its stringent coding conventions. Our
results show that Roosterize substantially outperforms baselines for suggesting
lemma names, highlighting the importance of using multi-input models and
elaborated terms.","Programming language source code with decient coding conventions, such as misleading function and variable names and irregular spacing, is dicult for developers to eectively understand, review, and modify [8, 52, 66]. Code with haphazard adherence to conventions may also be more bugprone [17]. The prob lem is exacerbated in large projects with many developers, where dierent source code les and components may have inconsistent and clashing conventions. Many open source software projects manually document coding conventions that contributors are expected to follow, and maintainers willingly accept xes ofarXiv:2004.07761v2  [cs.PL]  22 Apr 20202 P. Nie et al. violations to such conventions [2]. Enforcement of conventions can be performed by static analysis tools [30, 58]. However, such tools require developers to write precise checks for conventions, which are tedious to dene and often incomplete . To address this problem, researchers have proposed techniques for automatically learning coding conventions for Javalike languages from code corpora by apply ing statistical language models [4]. These models are applicable because code in these languages has high naturalness [35], i.e., statistical regularities and repet itiveness. Learned conventions can then be used to, e.g., suggest names in code. Proof assistants, such as Coq [15], are increasingly used to formalize re sults in advanced mathematics [28, 29] and develop large trustworthy software systems, e.g., compilers, operating systems, le systems, and distributed sys tems [18, 44, 72]. Such projects typically involve contributions of many partici pants over several years, and require considerable eort to maintain over time. Coding conventions are essential for evolution of large verication projects, and are thus highly emphasized in the Coq libraries HoTT [37] and Iris [39], in Lean's Mathlib [9], and in particular in the in uential Mathematical Components (MathComp) family of Coq projects [19]. Extensive changes to adhere to con ventions, e.g., on naming, are regularly requested by MathComp maintainers for proposed external contributions [50], and its conventions have been adopted, to varying degrees, by a growing number of independent Coq projects [1, 13, 24, 65]. We believe these properties make Coq code related to MathComp an attrac tive target for automated learning and suggesting of coding conventions, in par ticular, for suggesting lemma names [7]. However, serious challenges are posed by, on the one hand, Coq's powerful language extension facilities and fusion of type checking and computation [12], and on the other hand, the idiosyncratic conventions used by Coq practitioners compared to software engineers. Hence, although suggesting lemma names is similar in spirit to suggesting method names in Javalike languages [73], the former task is more challenging in that lemma names are typically much shorter than method names and tend to include heavily abbreviated terminology from logic and advanced mathematics; a single char acter can carry signicant information about a lemma's meaning. For example, the MathComp lemma names card support normedTI (\cardinality of support groups of a normed trivial intersection group"") and extprod mulgA (\associa tivity of multiplication operations in external product groups"") concisely convey information on lemma statement structure and meaning through both abbrevi ations and suxes, as when the sux Aindicates an associative property. In this paper, we present novel generation models for learning and suggest ing lemma names for Coq verication projects that address these challenges. Specically, based on our knowledge of Coq and its implementation, we devel oped multiinput encoderdecoder neural networks for generating names that use information directly from Coq's internal data structures related to lexing, parsing, and type checking. In the context of naming, our models are the rst to leverage the lemma lemma statement as well as the corresponding syntax tree and elaborated term (which we call kernel tree ) processed by Coq's kernel [53].Deep Generation of Coq Lemma Names Using Elaborated Terms 3 We implemented our models in a toolchain, dubbed Roosterize , which we used to learn from a highquality Coq corpus derived from the MathComp family. We then measured the performance of Roosterize using automatic metrics, nding that it signicantly outperforms baselines. Using our best model, we also suggested lemma names for the PCM library [56, 65], which were manually reviewed by the project maintainer with encouraging results. To allow Roosterize to use information directly from Coq's lexer, parser, and kernel, we extended the SerAPI library [26] to serialize Coq tokens, syntax trees, and kernel trees into a machinereadable format. This allowed us to achieve robustness against userdened notations and other extensions to Coq syntax. Thanks to our integration with SerAPI and its use of metaprogramming, we expect our toolchain to only require modest maintenance as Coq evolves. We make the following key contributions in this work: Models : We propose novel generation models based on multiinput neural networks to learn and suggest lemma names for Coq verication projects. A key property of our models is that they combine data from several Coq phases, including lexing, parsing, and term elaboration. Corpus : Advised by MathComp developers, we constructed a corpus of high quality Coq code for learning coding conventions, totaling over 164k LOC taken from four core projects. We believe that our corpus can enable develop ment of many novel techniques for Coq based on statistical language models. Toolchain : We implemented a toolchain, dubbed Roosterize , which sug gests lemma names for a given Coq project. We envision Roosterize being useful during the review process of proposed contributions to a Coq project. Evaluation : We performed several experiments with Roosterize to evalu ate our models using our corpus. Our results show that Roosterize performs signicantly better than several strong baselines, as measured by standard au tomatic metrics [59]. The results also reveal that our novel multiinput mod els, as well as the incorporation of kernel trees, are important for suggestion quality. Finally, we performed a manual quality analysis by suggesting lemma names for a medium sized Coq project [56], evaluated by its maintainer, who found many of the suggestions useful for improving naming consistency. The appendix describes more experiments, including an automatic evaluation on additional Coq projects. We provide artifacts related to our toolchain and corpus at: https://github.com/EngineeringSoftware/roosterize. 2 Background This section gives brief background related to Coq and the Mathematical Com ponents (MathComp) family of projects, as well as the SerAPI library. Coq and Gallina : Coq is a proof assistant based on dependent types, imple mented in the OCaml language [15, 20]. For our purposes, we view Coq as a programming language and typechecking toolchain. Specically, Coq les are sequences of sentences , with each sentence ending with a period. Sentences are4 P. Nie et al. 1 Lemma mg_eq_proof L1 L2 (N1 : mgClassifier L1) : L1 =i L2 > nerode L2 N1. 2 Proof. move => H0 u v. split => [/nerodeP H1 w|H1]. 3  by rewrite !H0. 4  apply/nerodeP => w. by rewrite !H0. 5 Qed. Fig. 1: Coq lemma on the theory of regular languages, including proof script. essentially either (a) commands for printing and other output, (b) denitions of functions, lemmas, and datatypes in the Gallina language [21], or (c) expres sions in the Ltac tactic language [22]. We will refer to denitions of lemmas as in (b) as lemma sentences . Coq internally represents a lemma sentence both as a sequence of tokens (lexing phase) and as a syntax tree (parsing phase). In the typical work ow for a Coqbased verication project, users write datatypes and functions and then interactively prove lemmas about them by ex ecuting dierent tactic expressions that may, e.g., discharge or split the current proof goal. Both statements to be proved and proofs are represented internally asterms produced during an elaboration phase [53]; we refer to elaborated terms askernel trees . Hence, as tactics are successfully executed, they gradually build a kernel tree. The Qedcommand sends the kernel tree for a tentative proof to Coq's kernel for nal certication. We call a collection of Ltac tactic sentences that build a kernel tree a proof script . Fig. 1 shows a Coq lemma and its proof script, taken verbatim from a de velopment on the theory of regular languages [24]. Line 1 contains a lemma sentence with the lemma name mg_eq_proof , followed by a lemma statement (on the same line) involving the arbitrary languages L1andL2, i.e., typed vari ables that are implicitly universally quantied. When Coq processes line 5, the kernel certies that the kernel tree generated by the proof script (lines 2 to 4) has the type (is a proof) of the kernel tree for the lemma statement on line 1. MathComp and lemma naming : The MathComp family of Coq projects, in cluding in particular the MathComp library of general mathematical denitions and results [49], grew out of Gonthier's proof of the fourcolor theorem [28], with substantial developments in the context of the landmark proof of the odd order theorem in abstract algebra [29]. The MathComp library is now used in many projects outside of the MathComp family, such as in the project containing the lemma in Fig. 1 [23]. MathComp has documented naming conventions for two kinds of entities: (1) variables and (2) functions and lemmas [19]. Variable names tend to be short and simple, while function and lemma names can be long and consist of several name components , typically separated by an underscore, but sometimes using CamelCase. Examples of denition and lemma names in Fig. 1 include mg_eq_proof ,mgClassifier ,nerode , and nerodeP . Note that lemma names sometimes have suxes to indicate their meaning, such as PinnerodeP which says that the lemma is a characteristic property . Coq functions tend to be named based on corresponding function denition bodies rather than just types (of the parameters and return value), analogously to methods in Java [47]. In contrast, MathComp lemma names tend to be based solely on the lemma state ment. Hence, a more suitable name for the lemma in Fig. 1 is mg_eq_nerode .Deep Generation of Coq Lemma Names Using Elaborated Terms 5 Lemma mg_eq_proof L1 L2 (N1 : mgClassifier L1) : L1 =i L2 > nerode L2 N1. sentence (Sentence((IDENT Lemma)(IDENT mg_eq_proof) (IDENT L1)(IDENT L2) (KEYWORD""("")(IDENT N1)(KEYWORD :)(IDENT mgClassifier) (IDENT L1)(KEYWORD"")"")(KEYWORD :)(IDENT L1)(KEYWORD =i)(IDENT L2) (KEYWORD >)(IDENT nerode)(IDENT L2)(IDENT N1)(KEYWORD .)))tokens (VernacExpr()(VernacStartTheoremProof Lemma (Id mg_eq_proof) (((CLocalAssum(Name(Id L1))(CHole()IntroAnonymous())) (CLocalAssum(Name(Id L2))(CHole()IntroAnonymous())) (CLocalAssum(Name(Id N1)) (CApp(CRef(Ser Qualid(DirPath())(Id mgClassifier)))(CRef(Ser Qualid(DirPath())(Id L1)))))) (CNotation(InConstrEntrySomeLevel"" >"") (CNotation(InConstrEntrySomeLevel"" =i"") (CRef(Ser Qualid(DirPath())(Id L1)))(CRef(Ser Qualid(DirPath())(Id L2)))) (CApp(CRef(Ser Qualid(DirPath())(Id nerode))) (CRef(Ser Qualid(DirPath())(Id L2)))(CRef(Ser Qualid(DirPath())(Id N1))))))))syntax tree (Prod (Name (Id char)) ... (Prod (Name (Id L1)) ... (Prod (Name (Id L2)) ... (Prod (Name (Id N1)) ... (Prod Anonymous (App (Ref (DirPath ((Id ssrbool) (Id ssr) (Id Coq))) (Id eq mem)) ... (Var (Id L1)) ... (Var (Id L2))) (App (Ref (DirPath ((Id myhill nerode) (Id RegLang))) (Id nerode)) ... (Var (Id L2)) ... (Var (Id N1))))))))kernel tree Fig. 2: Coq lemma sentence at the top, with sexps for, from just below to bottom: tokens, syntax tree, and kernel tree; the lemma statement in each is highlighted. SerAPI and Coq serialization : SerAPI is an OCaml library and toolchain for machine interaction with Coq [26], which provides serialization and deserializa tion of Coq internal data structures to and from Sexpressions (sexps) [51]. Ser API is implemented using OCaml's PPX metaprogramming facilities [57], which enable modifying OCaml program syntax trees at compilation time. Fig. 2 shows the lemma sentence on line 1 in Fig. 1, and below it, the corresponding (simpli ed) sexps for its tokens, syntax tree, and kernel tree, with the lemma statement highlighted in each representation. Note that the syntax tree omits the types of some quantied variables, e.g., for the types of L1and L2, as indicated by the CHole constructor. Note also that during elaboration of the syntax tree into the kernel tree by Coq, an implicit variable char is added (allquantied via Prod ), and the extensional equality operator =iis translated to its globally unique ker nel name ,Coq.ssr.ssrbool.eq_mem . Hence, a kernel tree can be much larger and contain more information than the corresponding syntax tree. 3 Models In this section, we describe our multiinput generation models for suggesting Coq lemma names. Our models consider lemma name generation with an encoder decoder mindset, i.e., we use neural architectures specically designed for trans duction tasks [67]. This family of architectures is commonly used for sequence generation, e.g., in machine translation [11] and code summarization [43], where it has been found to be much more eective than traditional probabilistic and retrievalbased approaches.6 P. Nie et al. ... ... ...Decoder EncodersFully Connected Layer<BOS> Lemma Statement Kernel Treemg nerodemg _ <EOS> L 1 . (Prod )Prod Prod Name Name CharId... ...(hd, cd) (h1, c1) (h2, c2) Fig. 3: Core architecture of our multiinput encoderdecoder models. 3.1 Core Architecture Our encoders are Recurrent Neural Networks (RNNs) that learn a deep semantic representation of a given lemma statement from its tokens, syntax tree, and kernel tree. The decoder|another RNN|generates the descriptive lemma name as a sequence. The model is trained endtoend, maximizing the probability of the generated lemma name given the input. In contrast to prior work in language code tasks that uses a single encoder [27], we design multiinput models that leverage both syntactic and semantic information from Coq's lexer, parser, and kernel. A highlevel visualization of our architecture is shown in Fig. 3. Encoding : Our multiinput encoders combine dierent kinds of syntactic and semantic information in the encoding phase. We use a dierent encoder for each input, which are: lemma statement, syntax tree, and kernel tree. Coq data structure instances can be large, with syntax trees having an av erage depth of 28.03 and kernel trees 46.51 in our corpus (we provide detailed statistics in Section 4). Therefore, we  atten the trees into sequences, which can be trained more eciently than tree encoders without performance loss [38]. We  atten the trees with preorder traversal, and we use \("" and \)"" as the bound aries of the children of a node. In later parts of this paper, we use syntax and kernel trees to refer to their  attened versions. In Section 3.2, we introduce tree chopping to reduce the length of the resulting sequences. To encode lemma statements and  attened tree sequences, we use bidirec tional LongShort Term Memory (LSTM) [36] networks. LSTMs are advanced RNNs good at capturing longrange dependencies in a sequence, and are widely used in encoders [38]. A bidirectional LSTM learns stronger representations (than a unidirectional LSTM) by encoding a sequence from both left to right and right to left [74]. Decoding : We use an LSTM (left to right direction only) as our decoder. To obtain the initial hidden and cell states ( hd;cd) of the decoder, we learn a unied representation of these separate encoders by concatenating their nal hidden and cell states (hi;ci), and then applying a fully connected layer on the concatenated states:hd=Whconcat ([hi]) +bhandcd=Wcconcat ([ci]) +bc;whereWh, Wc,bh, andbcare learnable parameters. During training, we maximize the log likelihood of the reference lemma name given all input sequences. Standard beam search is used to reduce the searchDeep Generation of Coq Lemma Names Using Elaborated Terms 7 (Prod Anonymous (App (Ref (DirPath ((Id ssrbool) (Id ssr) (Id Coq))) (Id eq_mem )) ... ((App (Ref ... )) ) ... )) (Prod Anonymous (App eq_mem ... (App (Ref ... )) ... )) Fig. 4: Kernel tree sexp before and after chopping; chopped parts are highlighted. space for the optimal sequence of tokens. With regular decoding, at each time step the decoder generates a new token relying on the preceding generated token, which can be errorprone and leads to slow convergence and instability. We mitigate this problem by performing decoding with teacher forcing [71] such that the decoder relies on the preceding reference token. At test time, the decoder still uses the proceeding generated token as input. Attention : With RNN encoders, the input sequence is compressed into the RNN's nal hidden states, which results in a loss of information, especially for longer sequences. The attention mechanism [48] grants the decoder access to the encoder hidden and cell states for all previous tokens. At each decoder time step, an attention vector is calculated as a distribution over all encoded tokens, indicating which token the decoder should \pay attention to"". To make the attention mechanism work with multiple encoders, we concatenate the hidden states of the nencoders [h1;:::;hn] and apply an attention layer on the result [69]. Initialization : Since there are no pretrained token embeddings for Coq, we initialize each unique token in the vocabulary with a random vector sampled from the uniform distribution U("
495,Intra-Variable Handwriting Inspection Reinforced with Idiosyncrasy Analysis.txt,"In this paper, we work on intra-variable handwriting, where the writing
samples of an individual can vary significantly. Such within-writer variation
throws a challenge for automatic writer inspection, where the state-of-the-art
methods do not perform well. To deal with intra-variability, we analyze the
idiosyncrasy in individual handwriting. We identify/verify the writer from
highly idiosyncratic text-patches. Such patches are detected using a deep
recurrent reinforcement learning-based architecture. An idiosyncratic score is
assigned to every patch, which is predicted by employing deep regression
analysis. For writer identification, we propose a deep neural architecture,
which makes the final decision by the idiosyncratic score-induced weighted
average of patch-based decisions. For writer verification, we propose two
algorithms for patch-fed deep feature aggregation, which assist in
authentication using a triplet network. The experiments were performed on two
databases, where we obtained encouraging results.","HANDWRITING is still considered as strong evidence in criminal courts of many countries due to its solid impact on behavioral biometrics [1], [2]. Therefore, for the last four decades, research on handwriting inspection has been of great interest in forensics. Moreover, the computational approaches are embedded in handwriting forensics owing to booming automation since the late 20thcentury. Besides, the ""9/11"" and ""2001 Anthrax"" attacks have reignited the computational handwriting forensics research [3]. From the forensic perspective, the handwritten specimen can be found mostly as an ofÔ¨Çine sample in the form of a threat letter, suicide note, forged manuscript, etc. [1]. Therefore, in this paper, we focus on ofÔ¨Çine handwriting. The ofÔ¨Çine handwriting analysis is more challenging compared to online writing due to absence of stroke trajectory, writing pressure, velocity, etc. In computational handwriting analysis, the focus during the last decade and the Ô¨Årst half of the current decade were on handcrafted features. The deep neural net derived feature based studies have thrived during the latter half of the current C. Adak is with the Centre for Data Science, JIS Institute of Advanced Studies and Research, JIS University, India700091, and also with School of Computer Science, FEIT, University of Technology Sydney, Australia2007. (email: chandra@jisiasr.org). B. B. Chaudhuri is with Dept. of CSE, Techno India University, India 700091, and also with CVPR Unit, Indian Statistical Institute, India700108. C.T. Lin and M. Blumenstein are with the Centre for AI, School of Computer Science, FEIT, University of Technology Sydney, Australia2007. This paper is a preprint version of DOI: 10.1109/TIFS.2020.2991833decade [4]. Although the past researches on writer inspection have produced some encouraging results, the major works have been performed on intervariable writing [5]. The computa tional research on intravariability of handwriting has been somewhat overlooked. However, handwriting intravariability is observed rather frequently due to some mechanical, phys ical, and psychological factors of the writers [6]. To the best of our knowledge, only one computational experiment has been performed on intravariability due to Adak et al. [6]. In that study, the authors experimentally showed that the general handcrafted and deep featurebased models did not work well on intravariable writer inspection, i.e., training/testing on disparate writing styles. At this point, our paper comes into place to identify/verify the writer from intravariable writing. Some important circumstances where our method is relevant are as follows. (i)Absent data : In forensics and biometrics [1], [7], for a writer examination system, a speciÔ¨Åc writing style/type of an individual may be absent during training. Now, the system may be required for testing on that particular type of writing. (ii)Discovered manuscript : In archival science and library science, the authorship is checked when an unpublished his torical cultural manuscript is discovered. The manuscript may contain some unknown writing styles of a claimant [7]. A system may be essential to verify such a claimant. (iii)Healthcare : Some diseases, e.g., Parkinson‚Äôs, Dyslexia, Alzheimer‚Äôs, Dysgraphia, Tourette syndrome, etc., affect the handwriting of an individual [8], [9]. Therefore, the writing of a patient changes over multiple stages of disease progression. A system that can understand such intravariability, may be needed to analyze such disease development. Our proposed system has the potential to address such realworld issues. In Fig. 1, we present some examples on intravariable and intervariable handwriting. The samples of the upper row (Fig. Fig. 1: (a), (b), (c): 3samples written by 3different writers: low inter variability ; (d), (e): 2samples written by the same writer: high intra variability .arXiv:1912.12168v2  [cs.CV]  7 May 20202 Fig. 2: Idiosyncratic writing samples in (a) English and (b) Bengali scripts, marked in red dashed boxes: (a) eccentric cursive stroke to scribble character ‚Äòd‚Äô, (b) queer penning of the Bengali character containing intermittent stroke. 1:(a)(c)) appear to be structurally similar; however, these are written by three different writers. It depicts the low inter variability which is mostly performed with the intention of writing/signatureforgery [10]. Here, writer2 (Fig. 1:(b)) and writer3 (Fig. 1:(c)) try to forge the inscription of writer1 (Fig. 1:(a)). In Fig. 1:(d), (e), two writing samples appear to be dissimilar, but both are written by the same writer, i.e., writer4. It portrays high intravariability . In this paper, we are concerned with such high intravariability in contrast with the past works [3], [5]. For intravariable handwriting inspection, the idiosyncrasy analysis [11] of handwriting may be useful, since the foren sic experts and paleographers follow quite a similar manual approach [1]. Idiosyncrasy analysis of handwriting refers to examining the eccentricity in individual writing style. The originating Greek word of idiosyncrasy is "" idiosunkrasia "", i.e. idios (own, private) + sun(with) + krasis (mixture), which denotes the ""distinctive or peculiar feature or characteristic""1 of an individual. We observe that almost every writer scribbles some charactertexts in a peculiar style, which may be useful to inspect the writer on intravariable writing. In Fig. 2:(a) and (b), we present two examples in English and Bengali scripts, where the writing idiosyncrasy is marked by red dashed boxes. Usually, to write the English character ‚Äòd‚Äô, at Ô¨Årst the lower loop is scribbled, then the vertical straight line is drawn. However, in Fig. 2:(a), to write ‚Äòd‚Äô, the vertical line is penned before the loop creation. Therefore, here, instead of the lower part (loop), the upper part (vertical line) of the ‚Äòd‚Äô creates a continuity with the previous character, which represents the individual idiosyncrasy. In Fig. 2:(b), to write the Bengali character ‚Äò  ‚Äô, an unnecessary inkstroke gap makes the character penning highly idiosyncratic (IdS). In [11], a preliminary work on idiosyncrasy analysis is performed, which did not deal with intravariable writing; however, it has provided an insight that such analysis has a positive impact on Writer IdentiÔ¨Åcation (WI). The authors modeled the idiosyncrasy analysis task into a classiÔ¨Åcation problem to classify the textpatches into multiple classes deÔ¨Åned by an IdS score. Their patch selection is mostly based on a sequential search with characterlevel information. In the current paper, we formulate the idiosyncrasy analysis task in a more sophisticated way, where we predict the score through deep regression [12], and select highly IdS patches using Reinforcement Learning (RL) [13]. In this paper, we inspect the writer from the IdS patches, instead of using all the patches that was performed in [6]. For writer inspection, a handwritten document is examined. In this paper, the examination involves the identiÔ¨Åcation and 1https://en.oxforddictionaries.com , last retrieved on 30 March 2020.veriÔ¨Åcation of a writer. In the WI task, we Ô¨Ånd the correct writerid of a questioned handwritten sample from multiple samples of different writers of a database. As a matter of fact, WI is a multiclass classiÔ¨Åcation problem, where we need to Ô¨Ånd an unknown writer class among multiple writer classes. In the Writer VeriÔ¨Åcation (WV) task, we authenticate an asked handwriting sample whether it has been written by a particular writer or not. Therefore, WV is a binary classiÔ¨Åcation problem. For WI and WV, we use some deep learningbased features. We perform the experiment on the database used in [6], which contains relatively high intravariable Bengali ofÔ¨Çine handwriting. The outcome of our method is better than that presented in [6] (refer to Section VI). The contributions of our current research are brieÔ¨Çy men tioned as follows: (i)The stateoftheart methods including [6] do not perform so well to inspect the writer on highly intravariable handwrit ing. The method proposed in this paper performs better than the past techniques. Merging the idiosyncrasy analysis with intravariable handwriting inspection is newly proposed here. (ii)We Ô¨Ånd highly IdS patches, and perform writer inspec tion on these patches only. To obtain an IdS score of a patch, we use a deepfeature induced regression analysis [12]. For highly IdS patch localization, we employ RL [13]. In RL, we propose a novel internal reward shaping function which is computed using the IdS score (refer to Section III). (iii)For WI, combining the decisions obtained from individ ual patches is a new contribution, where the overall decision is made by the IdS scorefed weighted average of the individual patchbased decisions (refer to Section IV). (iv)For WV, we propose two separate methods (MAF and XAF) for generating a combined pagelevel deep feature from multiple patchlevel features (refer to Section V). The rest of the paper is organized as follows. Section II explores the related work in the area. Section III discusses our proposed method for idiosyncrasy analysis. Then Sections IV and V describe our WI and WV methods. The following Section VI deals with the experiments and results of our proposed method. Finally, Section VII concludes this paper. II. R ELATED WORK "
506,Verifying Global Neural Network Specifications using Hyperproperties.txt,"Current approaches to neural network verification focus on specifications
that target small regions around known input data points, such as local
robustness. Thus, using these approaches, we can not obtain guarantees for
inputs that are not close to known inputs. Yet, it is highly likely that a
neural network will encounter such truly unseen inputs during its application.
We study global specifications that - when satisfied - provide guarantees for
all potential inputs. We introduce a hyperproperty formalism that allows for
expressing global specifications such as monotonicity, Lipschitz continuity,
global robustness, and dependency fairness. Our formalism enables verifying
global specifications using existing neural network verification approaches by
leveraging capabilities for verifying general computational graphs. Thereby, we
extend the scope of guarantees that can be provided using existing methods.
Recent success in verifying specific global specifications shows that attaining
strong guarantees for all potential data points is feasible.","Deeplearningisagamechangerforresearch,education,businessandbeyond[9,11]. Yet, we remain unable to provide strong guarantees on the behaviour of neu ral networks. In particular, while neural network verification in principle can provide strong guarantees, current approaches almost exclusively consider local specifications [1,14,20,25,32,38] that only apply to small regions around known input data points. This means that the currently widelyused specifications only sparsely cover the input space, providing no guarantees for inputs that are not close to known inputs. In contrast, globalspecifications cover the entire input space. We propose a specification formalism for neural networks that encompasses a rich class of global specifications while enabling verification using existing ver ifier technology. In particular, we show how monotonicity, Lipschitz continuity, two notions of global robustness [21,24], and dependency fairness [15,35] can be expressed using our formalism. As noted in [30], global specifications such as monotonicity and global ro bustness are hyperproperties [8]. In difference to regular properties that onlyarXiv:2306.12495v1  [cs.LG]  21 Jun 20232 D. Boetius, S. Leue consider one network execution at a time, hyperproperties relate executions for several inputs of the same neural network to each other. This allows us, for ex ample, to express a na√Øve notion of global robustness stating that an arbitrary input and a second input that lies close need to receive the same classification. A central aspect of our formalism is that we use auxiliary neural networks to define input sets and output sets. By leveraging capabilities for verifying general computational graphs [37], the auxiliary networks, together with self composition [8], allow for verifying hyperpropertiesusingexisting neural network verification approaches. Here, the role of the auxiliary neural networks is to make complex hyperproperty input and output sets accessible to existing verification approaches. Concretely, we design an auxiliary neural network to generate the tuples of inputs that need to be compared to determine whether a hyperprop erty is satisfied. Another auxiliary neural network detects whether the outputs a network produces for these inputs satisfy the output constraint. For the na√Øve notion of global robustness, this means that we derive a neural network that generates arbitrary pairs of inputs that are close to each other and another neu ral network that detects whether two outputs represent the same classification. Importantly, these auxiliary neural networks exactlycapture the targeted input and output constraints using standard neural network components. Recent success in verifying global robustness [36] and global individual fair ness [35] demonstrates that verifying global specifications is feasible. Our for malism is a general framework for global specifications targeting existing veri fiers[14,22,32,38].Whileourformalismdoesnotalleviatetheneedforspecialised techniques, such as the Interleaving Twin Encoding [36], it allows for 1. Comparing generalpurpose verifiers with specialised verifiers for specific global specifications and 2. Applying generalpurpose verifiers to global specifications for which no spe cialised verifier exists. 2 Preliminaries We consider verifying whether a neural network conforms to a global specifica tion. Neural networks are computational graphs [16]. Global specifications are formalised using hyperproperties [8,30]. Definition 1 (Computational Graph). Acomputational graph is a directed acyclic graph with computations (V, E, h ), where V={1, . . . , L }with L‚ààNis the set of nodes, E‚äÜV√óVis the edge relation and h= (h1, . . . , h L)is the computations tuple. Let degin : V‚ÜíNdenote the indegree. The computation of node i‚ààVishi:Rmk1√ó¬∑¬∑¬∑√ó Rmkdegin( i)‚ÜíRmi,where mi‚ààNis the output dimension of node iandk1, . . . , k degin( i)‚àà {i|(k, i)‚ààE}with k1‚â§ ¬∑¬∑¬∑ ‚â§ kdegin( i)are the direct predecessors of i. Definition 2 (Neural Network). Aneural network netŒ∏:Rn‚ÜíRm,n, m‚àà Nis a composition of affine transformations and nonaffine activation functionsVerifying Global Neural Network Specifications using Hyperproperties 3 represented by a computational graph (V, E, h )with a source iand a single sink j, such that hi:{‚àÖ} ‚Üí Rnandhj:Rmk1√ó ¬∑¬∑¬∑ √ó Rmkdegin( j)‚ÜíRm. The source i is theinputofnetŒ∏. The remaining sources of the computational graph together form the parameters Œ∏ofnetŒ∏. The sink jis theoutputofnetŒ∏. For classifica tion tasks, arg maxm j=1netŒ∏(x)is the class netŒ∏assigns to an input x‚ààRn. Figure 1 contains the computational graph of a residual unit [19] as an example. This graph defines the steps necessary for computing the output of a residual unit, given an input. It also allows for computing gradients and verifying a resid ual unit. Assume we want to compute the outputs of a neural network for an input x‚ààRn. Also, assume we have a parameter assignment Œ∏. We assign xto the network input node iand the corresponding parameter values to the remain ing sources. Now, computing the outputs corresponds to a forward walk over the computational graph, propagating the computation results of each node to its direct successors. Similarly, a backwards walk from sinks to sources allows for computing the gradients of the sink with respect to each source (backpropaga tion). Forward and backwards walks also allow for computing certified lower and upper bounds on the network output that can be used for verifying the neural network [37]. xŒ≥ Œ≤ / [‚Ä¢]+W b ‚àóŒ≥/primeŒ≤/prime / [‚Ä¢]+W/primeb/prime ‚àó + y Fig. 1. The computational graph of a residual unit [19]. In this figure, ‚àódenotes convolution, /denotes batch normalisation, [‚Ä¢]+denotes ReLU, and +denotes addi tion. We use pink nodes  for inputs, yellow  for parameters, and blue  for outputs. Verifying a neural network means that we want to automatically prove or disprove whether the neural network satisfies a specification . A specification is a set of properties. Definition 3 (Property). Aproperty œÜ= (XœÜ,YœÜ)is a tuple of an input setXœÜ‚äÜRnand anoutput set YœÜ‚äÜRm,n, m‚ààN. We write netŒ∏‚ä®œÜwhen a neural network netŒ∏:Rn‚ÜíRmsatisfiesthe property œÜ. Specifically, netŒ∏‚ä®œÜ‚áî ‚àÄx‚àà XœÜ: net Œ∏(x)‚àà YœÜ. We call an input x‚àà XœÜfor which netŒ∏(x)/‚àà YœÜacounterexample . A verifier determines whether a neural network netŒ∏satisfies a property œÜ. We require verifiers to 1.report property satisfaction if and only if the property4 D. Boetius, S. Leue is indeed satisfied ( soundness ) and2.to terminate ( completeness ). In this paper, we only require verifiers to support bounded hyperrectangles as property input sets and the nonnegative real numbers as output set. Practically, verifiers can also handle more complicated input and output sets. For formalising global specifications, we make use of hyperproperties . Hyper properties extend properties by considering multiple input variables and input dependent output sets. Definition 4 (Hyperproperty). Ahyperproperty œà= (Xœà,Yœà)is a tuple of amultivariable input set Xœà‚äÜ(Rn)vand aninputdependent output set Yœà‚äÜRn√ó ¬∑¬∑¬∑ √ó Rn |{z } vtimes√óRm√ó ¬∑¬∑¬∑ √ó Rm |{z } vtimes, where n, m, v ‚ààN. For a neural network netŒ∏:Rn‚ÜíRm, we write netŒ∏‚ä®œàif ‚àÄx(1), . . . ,x(v)‚àà Xœà: x(1), . . . ,x(v),netŒ∏ x(1) , . . . , netŒ∏ x(v) ‚àà Yœà. 3 Formalising Global Specifications using Hyperproperties Global specifications allow for expressing desired behaviour for the entire input domain of a neural network while local specifications only apply to small regions around known inputs. This property of local specifications brings with it that we have a fixed reference point for each property in a local specification. We typically do not have such a fixed reference point for global specifications, since they apply to the entire input domain. For example, a local robustness property expresses that a classifier assigns the same class to all inputs that lie within a small LpballBp(x)around a fixed input point x. Because we have this fixed input xas a reference point, we know the class that should be assigned to all the inputs in Bp(x). Knowing this class allows for judging whether an input x‚Ä≤‚àà Bp(x)is a counterexample to the local robustness property by executing the network once for x‚Ä≤. Ifwenowlookatglobalrobustness,wefindthatitdoesnotsufficetoconsider a single execution of a network to check for specification violations. As the inputs now are arbitrary inputs from the entire input domain, we can not determine whether robustness is violated by looking only at the output for one input x(1). Instead, we need to find another input x(2)‚àà Bp"
428,A Unified View of SDP-based Neural Network Verification through Completely Positive Programming.txt,"Verifying that input-output relationships of a neural network conform to
prescribed operational specifications is a key enabler towards deploying these
networks in safety-critical applications. Semidefinite programming (SDP)-based
approaches to Rectified Linear Unit (ReLU) network verification transcribe this
problem into an optimization problem, where the accuracy of any such
formulation reflects the level of fidelity in how the neural network
computation is represented, as well as the relaxations of intractable
constraints. While the literature contains much progress on improving the
tightness of SDP formulations while maintaining tractability, comparatively
little work has been devoted to the other extreme, i.e., how to most accurately
capture the original verification problem before SDP relaxation. In this work,
we develop an exact, convex formulation of verification as a completely
positive program (CPP), and provide analysis showing that our formulation is
minimal -- the removal of any constraint fundamentally misrepresents the neural
network computation. We leverage our formulation to provide a unifying view of
existing approaches, and give insight into the source of large relaxation gaps
observed in some cases.","While neural networks today empower many consumer products in image and natural language understand ing, they have been shown to fail in surprising and unexpected ways, potentially deterring broad deploy Proceedings of the 25thInternational Conference on Arti cial Intelligence and Statistics (AISTATS) 2022, Valencia, Spain. PMLR: Volume 151. Copyright 2022 by the au thor(s).ment in safety critical settings. One avenue for in spiring condence in neural networks is through the formal verication of safety rules specied as input output relationships describing limits on the expected behavior of a network. In this paper, we consider algorithms that pose verication as an optimization problem, where the objective encodes a metric of sat isfaction of the safety rule, the constraints represent the neural network computation, and the optimal ob jective value directly corresponds to conrmation or denial of the safety rule. Sound and complete, or exact, veriers must always re turn the correct decision, which inherently requires ex act representation of the neural network computations. Due to the NPcompleteness of verication Katz et al. (2017), exact veriers face a complexity barrier pro hibiting faster than exponential runtime in the worst case. This suggests that faithfully representing the for ward pass of a neural network is at odds with tractable optimization formulations. Sound but incomplete, or relaxed, veriers must never return a false assertion of safety, but may conserva tively suggest a network is unsafe when it is truly safe. The conservatism is a result of approximating the neu ral network computation, and is the tradeo for im proved tractability. In the context of optimization based verication, this is achieved by loosening ex act constraints into approximate constraints; the mis match between corresponding optimal objective values is termed the relaxation gap. In this work we aim to develop a deeper understanding of how to tune the bal ance between tightness and eciency, motivated by the central challenge of devising a systematic family of relaxations with exact representation of neural net work computations as a limiting case. Contributions. Our contributions are twofold: 1. We develop an exact, convex formulation of the verication problem as a completely positive pro gram (CPP); these are linear optimization prob lems over the cone of completely positive ma trices. While the complexity of verication is not resolved by the proposed formulation, it isarXiv:2203.03034v1  [math.OC]  6 Mar 2022A Unied View of SDPbased Neural Network Verication through Completely Positive Programming packaged entirely in the complete positivity con straint, with the neural network computation be ing exactly represented by tractable linear con straints. This gives a clean separation between the two competing desiderata of accuracy and tractability in relaxed verication, opening the door for new classes of veriers that predictably tradeo tightness and eciency. 2. We also provide analysis explaining how proper ties of the CPP formulation evolve when the com plete positivity constraint is relaxed. We nd that many of the favorable properties of the CPP for mulation are retained in SDP relaxations, show ing that it is a convenient starting point for con structing tight SDPbased veriers. Finally, we contextualize existing work in this shared frame work, clearly laying out their similarities and dif ferences with the proposed framework. 1.1 Related Work "
290,Traceable and Authenticable Image Tagging for Fake News Detection.txt,"To prevent fake news images from misleading the public, it is desirable not
only to verify the authenticity of news images but also to trace the source of
fake news, so as to provide a complete forensic chain for reliable fake news
detection. To simultaneously achieve the goals of authenticity verification and
source tracing, we propose a traceable and authenticable image tagging approach
that is based on a design of Decoupled Invertible Neural Network (DINN). The
designed DINN can simultaneously embed the dual-tags, \textit{i.e.},
authenticable tag and traceable tag, into each news image before publishing,
and then separately extract them for authenticity verification and source
tracing. Moreover, to improve the accuracy of dual-tags extraction, we design a
parallel Feature Aware Projection Model (FAPM) to help the DINN preserve
essential tag information. In addition, we define a Distance Metric-Guided
Module (DMGM) that learns asymmetric one-class representations to enable the
dual-tags to achieve different robustness performances under malicious
manipulations. Extensive experiments, on diverse datasets and unseen
manipulations, demonstrate that the proposed tagging approach achieves
excellent performance in the aspects of both authenticity verification and
source tracing for reliable fake news detection and outperforms the prior
works.","In the Wemedia era, news content with malicious ma nipulation, i.e., fake news, is easily produced and dis tributed on social media. A large amount of fake news, especially provocative fake news images, is undermining *Corresponding Author Tagged News Image  Original News Image  Authenticable Tag Traceable Tag Fake News Image Malicious  Manipulation Moderate ManipulationExtract Extract Source Tracing Authenticity  Verification Source Tracing Real News ImageFigure 1. The framework of image tagging for reliable fake news detection. Authenticable tags and traceable tags are simultane ously embedded into news images to generate tagged images. The dualtags should be correctly extracted from real news images. However, as for fake news images, authenticable tags should be fragile to malicious manipulations by extracting wrong tags to ver ify the news authenticity, and traceable tags should be robust to malicious manipulations to achieve source tracing. public credibility and inÔ¨Çuencing social stability, resulting in many serious social security issues [24]. To detect fake news images, the existing methods usually design detectors by capturing the traces of malicious manipulations such as textual information [19, 23, 32], visual features [4, 11, 31], and multimodal fusion of features [9, 27] from news im ages. Although those methods have achieved desirable per formance for verifying the authenticity of news images, they do not take source tracing into consideration. The news source traceability is essential for the public to know where the news is published to enhance the trustworthi 1arXiv:2211.10923v1  [cs.CV]  20 Nov 2022ness in news. Thus, the authenticity veriÔ¨Åcation and source traceability can jointly provide a complete forensic chain for reliable fake news detection. In the existing deep watermarking methods, robust wa termarking [8,35,41] or fragile watermarking [2,22,38] can either achieve copyright traceability or content integrity au thentication. To achieve the two purposes simultaneously, some dualwatermarking methods [6, 16, 21, 26] have been proposed to manually embed the two types of watermarks, and thus they suffer from two common issues. 1) Once the two types of watermarks are manually embedded into an image, they would affect each other, which makes them hard to decouple and extract; 2) It is hard to guarantee the two types of embedded watermarks achieve different ro bustness performances to malicious manipulations for dif ferent purposes. Therefore, it is an interesting and challenging task to achieve the goals of news authenticity veriÔ¨Åcation and source tracing simultaneously. To this end, we propose an image tagging approach based on a design of Decoupled Invertible Neural Network (DINN). In this approach, the dualtags, i.e., traceable tag and authenticable tag, can be invisibly embedded into the news images before publishing, and be separately extracted for authenticity veriÔ¨Åcation and source tracing, respectively. The framework of the proposed approach is shown in Fig. 1. In summary, the contributions of this paper include: ‚Ä¢ We propose a novel proactive image tagging scheme to achieve both news image authenticity veriÔ¨Åcation and source tracing for reliable fake news detection. ‚Ä¢ We design a Decoupled Invertible Neural Network (DINN) to simultaneously embed two types of invis ible tags, i.e., authenticable tag and traceable tag, into each news image, and extract the two tags from all ma nipulated news images separately without interfering with each other. ‚Ä¢ We design a double Feature Aware Projection Model (FAPM) and a Distance MetricGuided Module (DMGM) to improve the recovery accuracy of embed ded tags and enable the dualtags to achieve different robustness performances to malicious manipulations1. 2. Related Works "
387,Set-based Neural Network Encoding.txt,"We propose an approach to neural network weight encoding for generalization
performance prediction that utilizes set-to-set and set-to-vector functions to
efficiently encode neural network parameters. Our approach is capable of
encoding neural networks in a modelzoo of mixed architecture and different
parameter sizes as opposed to previous approaches that require custom encoding
models for different architectures. Furthermore, our \textbf{S}et-based
\textbf{N}eural network \textbf{E}ncoder (SNE) takes into consideration the
hierarchical computational structure of neural networks by utilizing a
layer-wise encoding scheme that culminates to encoding all layer-wise encodings
to obtain the neural network encoding vector. Additionally, we introduce a
\textit{pad-chunk-encode} pipeline to efficiently encode neural network layers
that is adjustable to computational and memory constraints. We also introduce
two new tasks for neural network generalization performance prediction:
cross-dataset and cross-architecture. In cross-dataset performance prediction,
we evaluate how well performance predictors generalize across modelzoos trained
on different datasets but of the same architecture. In cross-architecture
performance prediction, we evaluate how well generalization performance
predictors transfer to modelzoos of different architecture. Experimentally, we
show that SNE outperforms the relevant baselines on the cross-dataset task and
provide the first set of results on the cross-architecture task.","Recently, deep learning methods have been applied to a wide range of fields and problems. With this broad range of applications, large amounts of datasets are continually being made available in the public domain together with neural networks trained on these datasets. Given this abundance of trained neural network models, the following curiosity arises: what can we deduce about these networks with access only to the parameter values? More generally, can we predict properties of these networks such as generalization performance on a testset, the dataset on which the model was trained, the choice of optimizer and learning rate, the number of training epochs, choice of model initialization etc. through an analysis of the model parameters? The ability to infer such fundamental properties of trained neural networks using only the parameter values has the potential to open up new application and research paradigms. In this work, we tackle a specific version of this problem, namely, that of predicting the generalization performance on a testset of a neural network given access, only to the parameter values at the end of the training process. The first approach to solving this problem, proposed by Unterthiner et al. [2020], involves computing statistics such as the mean, standard deviation and quantiles, of each layer in the network, concatenating them to a single vector that represents the neural network encoding, and using this vector to predict the performance of the network. Another approach, also proposed as a baseline in Unterthiner et al. [2020], involves flattening all the parameter values of the network into a single vector which is then fed as input to layers of multilayer perceptrons(MLPs) to predict the network‚Äôs performance. An immediate consequence of this approach is that it is practical only for moderately sized neural network architectures. Additionally, this approach ignores the hierarchical Preprint. Under review.arXiv:2305.16625v1  [cs.LG]  26 May 2023Figure 1: Legend:  : Padding,  : SettoSet Function,  : SettoVector Function,  : LayerLevel Encoder, : LayerType Encoder. Concept: (left) Given the weights of a layer, SNE begins by padding and chunking the weights into chunksizes . Each chunk of the layer weight goes through a series of settoset and settovector functions to obtain the chunk representation vector. Layer level and layer type positional encodings are used to inject structural information of the network at each stage of the chunk encoding process. All chunk encoding vectors are encoded together to obtain the layer encoding. (right) All layer encodings in the neural network are encoded to obtain the neural network encoding vector again using as series of settoset and settovector functions. This vector is then used to predict the generalization performance of the neural network. computational structure of neural networks through the weight vectorization process. The second, and most recent approach to this problem, proposed by Zhou et al. [2023], takes a geometric approach to the problem by building neural network weight encoding functions, termed neural functionals, that respect symmetric properties of permutation invariance and equivariance of the hidden layers of multilayer perceptrons under the action of an appropriately applied permutation group. While this approach respect these fundamental properties in the parameter space, it‚Äôs application is restricted, strictly, to multilayer perceptrons. Also, even when relaxations are made to extend this method to convolutional networks and combinations of convolutional layers and multilayer perceptrons, these only work under strict conditions of equivalence in the channel size in the last convolutional layer and the first linear layer. Hence it is clear that while the method proposed by Zhou et al. [2023] enjoys nice theoretical properties, its application is limited to only a small subset of carefully chosen architectures. Moreover, both approaches [Unterthiner et al., 2020, Zhou et al., 2023] have a fundamental limitation: their encoding methods are applicable only to a single fixed, pre chosen neural network architecture. Once the performance predictor is trained, in the case of Unterthiner et al. [2020], and the neural network encoder of Zhou et al. [2023] is defined, they cannot be used to predict the performance of neural networks of different architecture. Consequently, evaluating these models on diverse architectures is infeasible without training an new generalization performance predictor for each architecture. To this end, we propose a Setbased Neural Network Encoder (SNE) for predicting the performance of neural networks given only the model parameters that is agnostic to the network architecture. Specifically, we treat the neural network encoding problem from a set encoding perspective by utilising compositions of settoset andsettovector functions. However, the parameters of neural networks are ordered. To retain this order information, we utilize positional encoding Vaswani et al. [2017] at various stages in our model. Also, our model incorporates the hierarchical computational structure of neural networks in the encoder design by encoding independently, layerwise, culminating in a final encoding stage that compresses all the layerwise information into a single encoding vector used to predict the network performance. To handle the issue of large and variable parameter sizes efficiently, we incorporate a padchunkencode pipeline that is parallelizable and can be used to iteratively encode layer parameters. In terms of evaluation, we introduce two new tasks: crossdataset neural network performance prediction and crossarchitecture neural network performance prediction. In crossdataset neural network performance prediction, we fix the neural network architecture used to generate the training data and evaluate how well the performance predictors transfer to the same architecture trained on different datasets. For crossarchitecture neural network performance prediction, we fix only the architecture for generating the training data and evaluate the performance of the predictors on architectures unseen during training. Our contributions are as follows: 2‚Ä¢ We develop a Setbased Neural Network Encoder (SNE) for predicting the performance of neural networks given access only to parameter values that is capable of encoding neural networks of arbitrary architecture and takes into account the hierarchical computational structure of neural networks. ‚Ä¢We introduce the crossdataset neural network performance prediction task where we evaluate how well neural network performance predictors transfer across neural networks trained on different datasets. ‚Ä¢We introduce the crossarchitecture neural network performance prediction task where we evaluate how well neural network performance predictors trained on a specific architecture transfer to unseen architectures during training. ‚Ä¢We benchmark our method, SNE, against the relevant baselines on the crossdataset task and show significant improvement over the baselines. ‚Ä¢Finally, we provide the first set of results on the crossarchitecture task using our setbased neural network encoder, SNE. 2 Related Work "
499,Formal Verification of Robustness and Resilience of Learning-Enabled State Estimation Systems.txt,"This paper presents a formal verification guided approach for a principled
design and implementation of robust and resilient learning-enabled systems. We
focus on learning-enabled state estimation systems (LE-SESs), which have been
widely used in robotics applications to determine the current state (e.g.,
location, speed, direction, etc.) of a complex system. The LE-SESs are
networked systems composed of a set of connected components including Bayes
filters for localisation, and neural networks for processing sensory input. We
study LE-SESs from the perspective of formal verification, which determines the
satisfiability of a system model against the specified properties. Over
LE-SESs, we investigate two key properties - robustness and resilience - and
provide their formal definitions. To enable formal verification, we reduce the
LE-SESs to a novel class of labelled transition systems, named {PO}2-LTS in the
paper, and formally express the properties as constrained optimisation
objectives. We prove that the robustness verification is NP-complete. Based on
{PO}2-LTS and the optimisation objectives, practical verification algorithms
are developed to check the satisfiability of the properties on the LE-SESs. As
a major case study, we interrogate a real-world dynamic tracking system which
uses a single Kalman Filter (KF) - a special case of Bayes filter - to localise
and track a ground vehicle. Its perception system, based on convolutional
neural networks, processes a high-resolution Wide Area Motion Imagery (WAMI)
data stream. Experimental results show that our algorithms can not only verify
the properties of the WAMI tracking system but also provide representative
examples, the latter of which inspired us to take an enhanced LE-SESs design
where runtime monitors or joint-KFs are required. Experimental results confirm
the improvement of the robustness of the enhanced design.","An autonomous system is a complex, intelligent system that can make decisions according to its internal state and its understanding about the external environment. To meet their design requirements, autonomous systems can be designed and implemented by connecting a num ber of heterogeneous components [4] ‚Äì a form of networked ‚ãÜA preprint has been previously published in [1]. Part of this paper appeared in [2, 3]. ‚ãÜ‚ãÜThis work is supported by the UK EPSRC projects on Off shore Robotics for Certification of Assets (ORCA) [EP/R026173/1] and EndtoEnd Conceptual Guarding of Neural Architectures [EP/T026995/1], and the UK Dstl projects on Test Coverage Metrics for Artificial Intelligence. ‚àóCorresponding author Email addresses: huangwei@pmlabs.com.cn (Wei Huang), Yifan.Zhou@liverpool.ac.uk (Yifan Zhou), g.jin3@liverpool.ac.uk (Gaojie Jin), youcheng.sun@manchester.ac.uk (Youcheng Sun), 17034203@qq.com (Fan Zhang), xiaowei.huang@liverpool.ac.uk (Xiaowei Huang)system. In this paper, we consider a typical class of au tonomous systems that have been widely used in robotics applications, i.e., state estimation systems (SESs). A SES is used to determine the current state (e.g., location, speed, direction, etc.) of a dynamic system such as a spacecraft or a ground vehicle. Typical applications of SESs in a robotics context include localisation [5], tracking [6], and control [7]. Moreover, with more and more robotics appli cations adopting deep neural network components to take advantage of their high prediction precision [8], we focus on those SESs with Deep Neural Network (DNN) compo nents, and call them learningenabled SESs, or LESESs. Typically, in LESESs, neural networks are employed to process perceptional input received via sensors. For ex ample, Convolutional Neural Networks (CNNs) are usually taken to process imagery inputs. For a realworld system ‚Äì such as the Wide Area Motion Imagery (WAMI) tracking system which we will study in this paper ‚Äì the percep tional unit may include multiple neural networks, which interact to implement a complex perceptional function. In Preprint submitted to Elsevier July 12, 2023arXiv:2010.08311v3  [cs.RO]  11 Jul 2023addition to the perception unit, LESESs use other com ponents ‚Äì such as Bayes filters ‚Äì to estimate, update, and predict the state. However, neural networks have been found to be frag ile, for example they are vulnerable to adversarial at tacks [9], i.e., an imperceptibly small but valid per turbation on the input may incorrectly alter the clas sification output. Several approaches have been devel oped to study the robustness of neural networks, in cluding adversarial attacks [9, 10, 11], formal verification [12, 13, 14, 15, 16, 17, 18, 19, 20, 21], and coverageguided testing [22, 23, 24, 25, 26, 27, 28, 29]. All of these con tribute to understanding the trustworthiness (i.e. the con fidence that a system will provide an appropriate output for a given input) of systems containing deep neural net works; a recent survey can be found at [30]. As will be ex plained in the paper, for neural networks, robustness is a close concept to resilience. However, it is unclear whether this is the case for the LESESs, or more broadly, net worked systems with learning components. We will show that,for LESESs, there are subtle, yet important, differences between robustness and resilience . Gen erally, robustness is the ability to consistently deliver its expected functionality by accommodating disturbances to the input, while resilience is the ability to handle and re cover from challenging conditions including internal fail ures and external ‚Äòshocks‚Äô, maintaining and/or resuming part (if not all) of its designated functionality. Based on this general view, formal definitions of robustness and re silience on the WAMI tracking system are suggested. In our opinion: robustness quantifies the minimum external effort (of e.g., an attacker) to make a significant change to the system‚Äôs functionality‚Äìdynamic tracking; and re silience quantifies the supremum (i.e., least upper bound) of the deviation from its normal behaviour from which the system cannot recover. While these two properties are related, we show that they have subtle, yet important, difference from both their formal definitions and the ex periments. From the outset, we note that the use of the term robustness in this sense differs from that used in tra ditional safety engineering. Whilst we continue to apply the prevailing use of term in this paper, we will later urge for alignment with safety engineering to foster the use of Machine Learning (ML) in those applications. To study the properties of realworld LESESs in a prin cipled way, we apply formal verification techniques, which demonstrate that a system is correct against allpossible risks over a given specification ‚Äì a formal representation of property ‚Äì and the formal model of the system, and which returns counterexamples when it cannot. We adopt this approach to support the necessary identification of risks prior to deployment of safety critical applications. This paper reports the first time a formal verification approach has been developed for state estimation systems . Technically, we first formalise an LESES as a novel la belled transition system which has components for payoffs and partial order relations (i.e. relations that are reflexive, asymmetric and transitive). The labelled transition system is named {PO}2LTS in the paper. Specifically, ev ery transition is attached with a payoff, and for every state there is a partial order relation between its outgoing tran sitions from the same state. Second, we show that the ver ification of the properties ‚Äì both robustness and resilience ‚Äì on such a system can be reduced into a constrained op timisation problem. Third, we prove that the verification problem is NPcomplete for the robustness property on {PO}2LTS. Fourth, to enable practical verification, we develop an automated verification algorithm. As a major case study, we work with a realworld dy namic tracking system [7], which detects and tracks ground vehicles over the highresolution Wide Area Motion Im agery (WAMI) data stream, named WAMI tracking sys temin this paper. The system is composed of two major components: a state estimation unit and a perceptional unit. The perceptional unit includes multiple, networked CNNs, and the state estimation unit includes one or multi ple Kalman filters, which are a special case of Bayes filter. We apply the developed algorithm to the WAMI tracking system to analyse both robustness and resilience, in order to understand whether the system can function well when subject to adversarial attacks on the perceptional neural network components. The formal verification approach leads to a guided de sign of the LESESs. As the first design, we use a sin gle Kalman filter to interact with the perceptional unit, and our experimental results show that the LESES per forms very well in a tracking task, when there is no attack on the perceptional unit. However, it may perform less well in some cases when the perceptional unit is under adversarial attack. The returned counterexamples from our verification algorithms indicate that we may improve the safety performance of the system by adopting a better design. Therefore, a second, improved design ‚Äì with joint KFs to associate observations and/or a runtime monitor ‚Äì is taken. JointKFs increase the capability of the system in dealing with internal and external uncertainties, and a runtime monitor can reduce some potential risks. We show that in the resulting LESES, the robustness is improved, without compromising the precision of the tracking. The main contributions of this paper are as follows. 1.Robust and resilient LESES design: This paper proposes a principled and detailed design of ro bust and resilient learningenabled state estima tion systems (Section 4). 2.Formal guarantee: The robustness and resilience of the LESES is guaranteed by a novel formal verification technique (Sections 5,6,7). 3.Robustness vs resilience: This paper pioneers in aligning the definitions of robustness and re silience in LESESs with those applied in tradi 2tional highintegrity computing. Their similar ity and difference are examined both in theory (Section 6) and in experimental evaluation (Sec tion 8). In summary, the organisation of the paper is as follows. In the next section, we present preliminaries about neu ral networks and the Bayes (and Kalman) filters. In Sec tion 3, we introduce our first design of the WAMItracking system where a single Kalman filter is used. In Section 4, we present our enhanced design with a runtime monitor and/or jointKFs. The reduction of LESES system to {PO}2LTS is presented in Section 5. In Section 6, we present a methodological discussion on the difference be tween robustness and resilience, together with the formali sation of them as optimisation objectives. The automated verification algorithm is presented in Section 7, with the experimental results presented in Section 8. We discuss some aspects on the definitions of robustness and resilience that are not covered in LESESs in Section 9. Finally, we discuss related work in Section 10 and conclude the paper in Section 11. 2. Preliminaries 2.1. Convolutional Neural Networks LetXbe the input domain and Ybe the set of labels. A neural network N:X‚Üí D (Y) can be seen as a func tion mapping from Xto probabilistic distributions over Y. That is, N(x) is a probabilistic distribution, which assigns for each label y‚ààYa probability value ( N(x))y. We letfN:X‚ÜíYbe a function such that for any x‚ààX, fN(x) = arg max y‚ààY{(N(x))y}, i.e., fN(x) returns the classification. 2.2. Neural Network Enabled State Estimation We consider a timeseries linear state estimation prob lem that is widely assumed in the context of object track ing. The process model is defined as follows. sk=F¬∑sk‚àí1+œâk (1) where skis the state at time k,Fis the transition matrix, œâkis a zeromean Gaussian noise such that œâk‚àº N(0,Q), withQbeing the covariance of the process noise. Usually, the states are not observable and need to be determined indirectly by measurement and reasoning. The measure ment model is defined as: zk=H¬∑sk+vk (2) where zkis the observation, His the measurement matrix, vkis a zeromean Gaussian noise such that vk‚àº N(0,R), andRis the covariance of the measurement noise.Bayes filters have been used for reasoning about the ob servations, {zk}, with the goal of learning the underlying states {sk}. A Bayes filter maintains a pair of variables, (sk,Pk), over the time, denoting Gaussian estimate and Bayesian uncertainty, respectively. The basic procedure of a Bayes filter is to use a transition matrix, Fk, to pre dict the current state, ( ÀÜsk,ÀÜPk), given the previous state, (sk‚àí1,Pk‚àí1). The prediction state can be updated into (sk,Pk) if a new observation, zk, is obtained. In the con text of the aforementioned problem, this procedure is it erated for a number of time steps, and is always discrete time, linear, but subject to noises. We take the Kalman Filter (KF), one of the most widely used variants of Bayes filter, as an example to demonstrate the above procedure. Let s0‚ààRn‚àº N(ÀÜs0,ÀÜP0) be the ini tial state, such that ÀÜs0‚ààRnandÀÜP0‚ààRn√ónrepresent our knowledge about the initial estimate and the correspond ing covariance matrix, respectively. First, we perform the state prediction fork‚â•1: ÀÜsk=Fksk‚àí1 ÀÜPk=FkPk‚àí1FT k+Qk(3) Then, we can update the filter : sk=ÀÜsk+Kkyk Pk= (I‚àíKkHk)ÀÜPk(4) where yk=zk‚àíHkÀÜsk Sk=HkÀÜPkHT k+Rk Kk=ÀÜPkHT kS‚àí1 k(5) Intuitively, ykis usually called ‚Äúinnovation‚Äù in signal processing and represents the difference between the real observation and the predicted observation, Skis the co variance matrix of this innovation, and Kkis the Kalman gain, representing the relative importance of innovation yk with respect to the predicted estimate ÀÜsk. In a neural network enabled state estimation, a percep tion system ‚Äì which may include multiple CNNs ‚Äì will provide a set of candidate observations Zk, any of which can be chosen as the new observation zk. From the per spective of robotics, Zkincludes a set of possible states of the robot, measured by (possibly several different) sen sors at time k. These measurements are imprecise, and are subject to noise from both the environment (epistemic uncertainty) and the imprecision of sensors (aleatory un certainty). 3. A RealWorld WAMI Dynamic Tracking Sys tem In this part, we present a brief introduction, followed by the technical details, to the realworld WAMI dynamic tracking system that will be used as our major case study. The tracking system requires continuous imagery input from e.g., airborne highresolution cameras. In the case 3study, the input is a video, which consists of a finite se quence of WAMI images. Each image contains a number of vehicles. The essential processing chain of the WAMI tracking system is as follows. 1. Align a set of previous frames with the incoming frame. 2. Construct the background model of incoming frames using the median frame. 3. Extract moving objects using background subtraction. 4. Determine if the moving objects are vehicles by using a Binary CNN. 5. For complex cases, predict the locations of moving ob jects/vehicles using a regression CNN. 6. Track one of the vehicles using a Kalman filter. WAMI tracking uses Gated nearest neighbour (Gnn) to choose the new observation zk: from the set Zk, the one closest to the predicted measurement Hk¬∑ÀÜsk is chosen, i.e., zk= arg min z‚ààZk||z‚àíHk¬∑ÀÜsk||p (6) s.t.||z‚àíHk¬∑ÀÜsk||p‚â§œÑk (7) where || ¬∑ || pisLpnorm distance ( p= 2, i.e., Euclidean distance is used in this paper), and œÑkis the gate value, representing the maximum uncertainty in which the sys tem is able to work. Specifically, the WAMI system has the following defini tions of sandP: s=l v P=Œ£llŒ£lv Œ£vlŒ£vv (8) where sdenotes the mean values of two Gaussian stochas tic variables, lrepresenting the location which is measur able from the input videos, and v, representing the velocity which cannot be measured directly, respectively. In the measurement space, the elements in lare not cor related, which makes it possible to simplify the Bayesian uncertainty metric, œÑ, that is the trace of the covariance matrix: œÑ=tr(Œ£ll) (9) Therefore, œÑis partially related to the search range in which observations can be accepted. Normally, œÑwill grad ually shrink before being bounded ‚Äì the convergence prop erty of KF as explained below. 3.1. WideArea Motion Imagery Input The input to the tracking system is a video, which con sists of a finite sequence of images. Each image contains a number of vehicles. Similar to [31], we use the WPAFB 2009 [32] dataset. The images were taken by a camera sys tem with six optical sensors that had already been stitchedto cover a wide area of around 35 km2. The frame rate is 1.25Hz. This dataset includes 1025 frames, which is around 13 minutes of video and is divided into training video (512 frames) and testing video (513 frames), and where all the vehicles and their trajectories are manu ally annotated. There are multiple resolutions of videos in the dataset. For the experiment, we chose to use the 12,000√ó10,000 images, in which the size of vehicles is smaller than 10 √ó10 pixels. We use Œ±ito denote the i th frame and Œ±i(x, y) the pixel on the intersection of xth column and yth row of Œ±i. In the following, we explain how the tracking system works, where video is used as input. In general this is undertaken in two stages: detection and tracking. In Sec tion 3.2 through to Section 3.5, we explain the detection steps, i.e., how to detect a vehicle with CNNbased per ception units; this is followed by the tracking step in Sec tion 3.6. 3.2. Background Construction Vehicle detection in WAMI video is a challenging task due to the lack of vehicle appearances and the existence of frequent pixel noises. It has been discussed in [33, 34], that an appearancebased object detector may cause a large number of false alarms. For this reason, in this paper, we only consider detecting moving objects for tracking. Background construction is a fundamental step in ex tracting pixel changes from the input image. The back ground is built for the current environment from a number of previous frames captured by the moving camera system, through the following steps: Image registration. Is used to compensate for the cam era motion by aligning all the previous frames to the cur rent frame. The key is to estimate a transformation ma trix, hk‚àít k, which transforms frame Œ±k‚àítto frame Œ±kus ing a given transformation function. For the transforma tion function, we consider projective transformation (or homography), which has been widely applied in multi perspective geometry; an area where WAMI camera sys tems are already utilised. The estimation of hk‚àít kis generated by applying feature based approaches. First of all, feature points from images at frame Œ±k‚àítandŒ±k, respectively, are extracted by fea ture detectors (e.g., Harris corner or SIFTlike [35] ap proaches). Second, feature descriptors, such as SURF [36] and ORB [37], are computed for all detected feature points. Finally, pairs of corresponding feature points be tween two images can be identified and the matrix hk‚àít k can be estimated by using RANSAC [38], which is robust against outliers. Background Modeling. We generate the background, Ibg k, for each time k, by computing the median image of the L previouslyaligned frames, i.e., Ibg k(x, y) =1 LLX i=1Œ±k‚àíi(x, y) (10) 4In our experiments, we take either L= 4 or L= 5. Note that, to align the Lprevious frames to the newly received frame, only one image registration process is per formed. After obtaining the matrices hk‚àí2 k‚àí1, hk‚àí3 k‚àí1, ...by processing previous frames, we perform image registration once to get hk‚àí1 k, and then let hk‚àí2 k=hk‚àí1 k√óhk‚àí2 k‚àí1, hk‚àí3 k=hk‚àí1 k√óhk‚àí3 k‚àí1. (11) Extraction of Potential Moving Objects. By comparing the difference between Ibg kand the current frame Œ±k, we can extract a set Qbcof potential moving objects by first com puting the following set of pixels Pbc={(x, y)| |Ibg k(x, y)‚àíŒ±k(x, y)|> Œ¥bc,(x, y)‚ààŒì}(12) and then applying image morphology operation on Pbc, where Œì is the set of pixels and Œ¥bcis a threshold value to determine which pixels should be considered. 3.3. CNN for Detection Refinement After obtaining Pbc, we develop a CNN, Ndr, to detect vehicles. We highlight a few design decisions. The ma jor causes of false alarms generated by the background subtraction are: poor image registration, light changes and the parallax effect in high objects (e.g., buildings and trees). We emphasise that the objects of interest (e.g., ve hicles) mostly, but not exclusively, appear on roads. More over, we perceive that a moving object generates a tempo ral pattern (e.g., a track) that can be exploited to discern whether or not a detection is an object of interest. Thus, in addition to the shape of the vehicle in the current frame, we assert that the historical context of the same place can help to distinguish the objects of interest and false alarms. By the above observations, we create a binary classi fication CNN Ndr:R21√ó21√ó(m+1)‚àí ‚Üí {0,1}to predict whether a 21 √ó21 pixels window contains a moving ob ject given aligned image patches generated from the pre vious mframes. The 21 √ó21 pixels window is identified by considering the image patches from the set Qbc. We suggest m= 3 in this paper, as it is the maximum time for a vehicle to cross the window. The input to the CNN is a 21 √ó21√ó(m+ 1) matrix and the convolutional lay ers are identical to traditional 2D CNNs, except that the three colour channels are substituted with m+1 greylevel frames. Essentially, Ndracts as a filter to remove, from Qbc, objects that are unlikely to be vehicles. Let Qdrbe the obtained set of moving objects. If the size of an image patch in Qdris similar to a vehicle, we directly label it as a vehicle. On the other hand, if the size of the image patch in Qdris larger than a vehicle, i.e., there may be multiple vehicles, we pass this image patch to the location prediction for further processing. 3.4. CNN for Location Prediction We use a regression CNN Nlp:R45√ó45√ó(m+1)‚àí ‚ÜíR15√ó15 to process image patches passed over from the detectionrefinement phase. As in [34], a regression CNN can predict the locations of objects given spatial and temporal infor mation. The input to Nlpis similar to the classification CNN Ndrdescribed in Section 3.3, except that the size of the window is enlarged to 45 √ó45. The output of Nlp is a 225dimensional vector, equivalent to a downsampled image (15 √ó15) for reducing computational cost. For each 15 √ó15 image, we apply a filter to obtain those pixels whose values are greater than not only a threshold value Œ¥lpbut also the values of its adjacent pixels. We then obtain another 15 √ó15 image with a few bright pixels, each of which is labelled as a vehicle. Let Obe the set of moving objects updated from Qdrafter applying location prediction. 3.5. Detection Framework The processing chain of the detector is shown in Fig ure 1. At the beginning of the video, the detector takes the first Lframes to construct the background, thus the detections from frame L+ 1 can be generated. After the detection process finishes in each iteration, it is added to the template of previous frames. The updating process substitutes the oldest frame with the input frame. This is to ensure that the background always considers the lat est scene, since the frame rate is usually low in WAMI videos such that parallax effects and light changes can be pronounced. As we wish to detect very small and unclear vehicles, we apply a small background subtraction thresh old and a minimum blob size. This, therefore, leads to a huge number of potential blobs. The classification CNN is used to accept a number of blobs. As mentioned in Sec tion 3.3, the CNN only predicts if the window contains a moving object or not. According to our experiments, the cases where multiple blobs belong to one vehicle and one blob includes multiple vehicles, occur frequently. Thus, we design two corresponding scenarios: the blob is very close to another blob(s); the size of the blob is larger than 20√ó20. If any blob follows either of the two scenarios, we do not consider the blob for output. The regression CNN (Section 3.4) is performed on these scenarios to predict the locations of the vehicles in the corresponding region, and a default blob will be given. If the blob does not follow any of the scenarios, this blob will be outputted directly as a detection. Finally, the detected vehicles include the output of both sets. 3.6. Object Tracking 3.6.1. Problem Statement We consider a single target tracker (i.e. Kalman filter) to track a vehicle given all the detection points over time in the field of view. The track is initialised by manually giv ing a starting point and a zero initial velocity, such that the state vector is defined as st= [xt, yt,0,0]Twhere [ xt, yt] is the coordinate of the starting point. We define the initial 5Figure 1: The architecture of the vehicle detector. covariance of the target, P=diag[30,30,20,20]2, which is the initial uncertainty of the target‚Äôs state1. A nearconstant velocity model is applied as the dy namic model in the Kalman filter, which is defined as fol lows, by concretising Equation (1). ÀÜsk=F¬∑sk‚àí1+œâks.t.F=I2√ó2I2√ó2 O2√ó2I2√ó2 (13) where Iis a identity matrix, Ois a zero matrix, and sk‚àí1,ÀÜsk‚àí1andœâkare as defined in Section 2, such that the covariance matrix Qof the process noise is defined as follows: Q=œÉ2 q¬∑Ô£Æ Ô£∞1 3dt3¬∑I2√ó21 2dt2¬∑I2√ó2 1 2dt2¬∑I2√ó2 I2√ó2Ô£π Ô£ª (14) where dtis the time interval between two frames and œÉq is a configurable constant. œÉq= 3 is suggested for the aforementioned WAMI video. Next, we define the measurement model by concretising Equation (2): zk=H¬∑sk+vks.t. H= 1 0 0 0 0 1 0 0 (15) where zkis the measurement representing the position of the tracked vehicle, and skandvkare as defined in Section 2. The covariance matrix, R, is defined as 1With this configuration it is not necessary for the starting point to be a precise position of a vehicle, and the tracker will find a proximate target on which to track. However, it is possible to define a specific velocity and reduce the uncertainty in P, so that a particular target can be tracked.R=œÉ2 r¬∑I2√ó2, where we suggest œÉr= 5 for the WAMI video. Since the camera system is moving, the position should be compensated for such motion using the identical trans formation function for image registration. However, we ignore the influence to the velocity as it is relatively small, but consider integrating this into the process noise. 3.6.2. Measurement Association During the update step of the Kalman filter, the resid ual measurement should be calculated by subtracting the measurement ( zk) from the predicted state ( ÀÜsk). In the tracking system, a Gnn is used to obtain the measurement from a set of detections. Knearest neighbour is first ap plied to find the nearest detection, ÀÜzk, of the predicted measurement, H¬∑ÀÜsk. Then the Mahalanobis distance be tween ÀÜzkandH¬∑ÀÜskis calculated as follows: Dk=q (ÀÜzk‚àíH¬∑ÀÜsk)T¬∑ÀÜSk‚àí1¬∑(ÀÜzk‚àíH¬∑ÀÜsk) (16) where ÀÜPkis the innovation covariance, which is defined within the Kalman filter. A potential measurement is adopted if Dk‚â§gwith g= 2 in our experiment. If there is no available mea surement, the update step will not be performed and the state uncertainty accumulates. It can be noticed that a large covariance leads to a large search window. Because the search window can be unreasonably large, we halt the tracking process when the trace of the covariance matrix exceeds a predetermined value. 4. Improvements to WAMI Tracking System In this section, we introduce two techniques to improve the robustness and resilience of the LESESs. One of the 6techniques uses a runtime monitor to track a convergence property, expressed with the covariance matrix Pk; and the other considers components to track multiple objects around the primary target to enhance fault tolerance in the state estimation. 4.1. Runtime Monitor for Bayesian Uncertainty Generally speaking, a KF system includes two phases: prediction (Equation (3)) and update (Equation (4)). The oretically, a KF system can converge [39] with optimal pa rameters: F,H,Q, and R, that well describe the problem. In this paper, we assume that the KF system has been well designed to ensure the convergence. Empirically, this has been proven possible in many practical systems. We are interested in another characteristic of KF: where the un certainty, ÀÜPk, increases relative to Pk‚àí1, if no observation is available and thus the update phase will not be per formed. In such a case, the predicted covariance ÀÜPkwill be treated as the updated covariance Pkin this timestep. In the WAMI tracking system, when the track does not have associated available observations (e.g., mis detections) for a certain period of time, the magnitude of the uncertainty metric œÑwill be aggregated and finally ‚Äòexplode‚Äô, and thus the search range of observations is dra matically expanded. This case can be utilised to design a monitor to measure the attack, and therefore should be considered when analysing the robustness and resilience. The monitor for the Bayesian uncertainty can be de signed as follows: when œÑincreases, an alarm is set to alert the potential attack. From the perspective of an at tacker, to avoid this alert, a successful attack should try to hide the increment of œÑ. To understand when the incre ment may appear for the WAMI tracking system, we recall the discussion in Section 3, where a track associates the nearest observation zwithin a predefined threshold, in Mahalanobis distance, in each timestep. By attacking all the observations in Zk, we can create the scenario where no observations are within the search range, which mimics the aforementioned case: the Bayesian uncertainty metric increases due to the skipped update phase. Formally, we define a parameter Œì, defined in (17), which monitors the changes of the Kalman filter‚Äôs covari ance over time and considers the convergence process. Œì(eœÅk‚àí1,eœÅk) = 1 œÑ(eœÅk)‚â§œÑ(eœÅk‚àí1) 0 œÑ(eœÅk)> œÑ(eœÅk‚àí1)(17) 4.2. Joining Collaborative Components for Tracking Reasons for the previous WAMI tracking system mal functions are twofold: false alarms and misdetections. Note that, in this paper, we only track a single target. Using Gnn and a Kalman filter is sufficient to deal with false alarms in most cases. Nevertheless, misdetection still brings significant issues. As mentioned in Section 4.1, misdetections may cause the Bayesian uncertainty range to expand. This, compounded with the fact that there areusually many detections encountered in the WAMI videos, leads to the possibility that the tracking is switched to another target. In order to cope with this problem, we consider taking the approach of utilising joining col laborative components and we call it joint Kalman fil ters (jointKFs). More specifically, we track multiple tar gets near the primary target simultaneously with multiple Kalman filters; the detailed process is as follows: ‚Ä¢Two kinds of Kalman filter tracks are maintained: one track for the primary target, Tp, and multiple tracks for the refining association, Tr. ‚Ä¢At each timestep other than the initialisation step, we have predicted tracks {ÀÜTkp,ÀÜTkr}, a set Zkof detections from current timestep, and a set ÀúZk‚àí1of unassociated detections from the previous timestep. 1. Calculate the likelihoods of all the pairs of detec tions Zkand tracks {ÀÜTkp,ÀÜTkr}usingN(ÀÜsk,zk,Sk) where the parameters can be found in Kalman fil ter. 2. Sort the likelihoods from the largest to the small est, and do a gated onetoone data association in this order. 3. Perform standard Kalman filter updates for all the tracks. 4. For each detection in Zkthat is not associated and is located close to the primary target, calculate the distance to each element in Zk‚àí1. ‚ÄìIf the distance is smaller than a predefined value, initialize a track and treat the distance as velocity then add this track into Tr k. ‚ÄìOtherwise, store this detection in ÀúZk 5. Maintain all the tracks for refining association, Tr k: if a track is now far away from the primary target, remove it from the set. By applying this data association approach, if the pri mary target is misdetected, the track will not be associ ated to a false detection, and even when this occurs for a few timesteps and the search range becomes reasonably large, this system can still remain resilient (i.e. can still function and recover quickly). 5. Reduction of LESESs to Labelled Transition Systems Formal verification requires a formal model of the sys tem, so that all possible behaviour of the system model can be exploited to understand the existence of incorrect behaviour. In this section, we will reduce the LESESs to a novel class of labelled transition systems ‚Äì a formal model ‚Äì such that all safetyrelated behaviour is preserved. In the next few sections, we will discuss the formalisation of the properties, the automated verification algorithms, and the experimental results, respectively. 7Figure 2: The Workflow of Attack on WAMI System. 5.1. Threat Model of Adversarial Attack on Perception System In Section 3, a neural network based perception system determines whether or not there is a vehicle at a location z. Let x(z)‚ààRd1√ód2be an image covering the location z, a neural network function fN:Rd1√ód2‚Üí {0,1}maps x(z) into a Boolean value, fN(x(z)), representing whether or not a vehicle is present at location z. There are two types of erroneous detection: (1) a wrong classification predic tion of the image x(z), and (2) a wrong positioning of a moving object within x(z). We focus on the former since the WAMI tracking system has a comprehensive mecha nism to prevent the occurrence of the latter. The threat model of an adversary is summarised as in Figure 2. Assuming that fN(x(z)) = 1. An adversary must compute another input ex(z) which requires a pay off and has a different classification, i.e., fN(ex(z)) = 0. Without loss of generality, the payoff is measured with the normdistance from ex(z) to its original image x(z), or formally ||ex(z)‚àíx(z)||p (18) To deviate from an input image x(z) to its adver sarial input ex(z), a large body of adversarial example generation algorithms and adversarial test case genera tion algorithms are available. Given a neural network Nand an input x, an adversarial algorithm Aproduces an adversarial example A(N, x) such that fN(A(N, x))Ã∏= fN(x). On the other hand, for test case generation, an algorithm Aproduces a set of test cases A(N, x), among which the optimal adversarial test case is such that arg min ex‚ààA(N,x),fN(ex)Ã∏=fN(x)||ex‚àíx||p. We remark that, the work in this paper is independent from particular adversar ial algorithms. We use in our experiments two algorithms: ‚Ä¢DeepFool [40], which finds an adversarial example ex by projecting xonto the nearest decision boundary. The projection process is iterative because the deci sion boundary is nonlinear. ‚Ä¢DeepConcolic [22], which generates a test suite by ap plying combined symbolic execution and concrete exe cution, guided by adapted MC/DC metrics for neural networks [24]. We denote by payoff (A, N, x ), the payoff that an ad versarial algorithm Aneeds to compute for an adversarialNotations Description zk‚ààZk observed location by WAMI tracking x(z) and1√ód2image covering location z fN neural network function payoff (A, N, x )payoff for algorithm Acomputing an adversarial example from xandN qk= (sk,Pk)a state at step k, consisting of estimate and covariance matrix s(qk),P(qk) and z(qk)estimate of qk, covariance matrix of qk and observed location for transition ( qk‚àí1, qk) œÅ a path of consecutive states ql...qu œÅk,z(œÅk)alias: the state qkand the observed location z(qk) on the path œÅ Table 1: A Summary of Notations Used example from xandN. Furthermore, we assume that the adversary can observe the parameters of the Bayes filter, for example, Hk,Fk,Qk,Rkof the Kalman filter. 5.2.{PO}2Labelled Transition Systems LetProp be a set of atomic propositions. A payoff and partiallyordered label transition system, or {PO}2LTS, is a tuple M= (Q, q 0,kf, L, œÄ, Œ≤ ), where Qis a set of states, q0‚ààQis an initial state, kf‚äÜQ√óQis a transition relation, L:Q‚Üí2Propis a labelling function, œÄ:Q√óQ‚Üí R+is a payoff function assigning every transition a non negative real number, and Œ≤:kf‚Üíkfis a partial order relation between outgoing transitions from the same state. 5.3. Reduction of WAMI Tracking to {PO}2LTS We model a neural network enabled state estimation system as a {PO}2LTS. A brief summary of some key notations in this paper is provided in Table 1. We let each pair ( sk,Pk) be a state, and use the transition relation kf to model the transformation from a pair to another pair in a Bayes filter. We have the initial state q0by choosing a detected vehicle ( s0,P0) on the map. From a state qk‚àí1= (sk‚àí1,Pk‚àí1) and a set Zkof candidate observations, we have one transition ( qk‚àí1, qk) for each z‚ààZk, where qk= (sk,Pk) can be computed with Equations (3)(5) by having zkin Equation (6) as the new observation. For a state qk= (sk,Pk), we write s(qk) to denote the estimate sk, P(qk) to denote the covariance matrix Pk, and z(qk) to denote the new observation that has been used to compute s(qk) and P(qk) from its parent state qk‚àí1. Subsequently, for each transition ( qk‚àí1, qk), its associated payoff œÄ(qk‚àí1, qk) is denoted by payoff (A, N, x (z(qk))), i.e., the payoff that the ad versary uses the algorithm Ato manipulate x(z(qk)) ‚Äì the image covering the observation z(qk) ‚Äì into another image on which the neural network Nbelieves there exists no vehicle. For two transitions ( qk‚àí1, q1 k) and ( qk‚àí1, q2 k) from the same state qk‚àí1, we say that they have a partial order rela tion, written as ( qk‚àí1, q1 k)‚â∫(qk‚àí1, q2 k), if making z(q2 k) the new observation requires the adversary to fool the network Ninto misclassifying x(z(q1 k)). For example, in WAMI 8Figure 3: Tree diagram of an unfolding {PO}2LTS tracking, according to Equation (6), the condition means that||z(q2 k)‚àíz||p>||z(q1 k)‚àíz||p, where z=Hks(qk‚àí1) is the predicted location. Example 1. Figure 3 depicts a tree diagram for the un folding of a labelled transition system. The root node on top represents the initial state q0. Each layer comprises all possible states of qk= (sk,Pk)at step kof WAMI tracking, with skbeing one possible estimate, and Pkthe covariance matrix. Each transition connects a state qk‚àí1 at step k‚àí1toqkat step k.. . . ,zk,zk+1,zk+2, . . . are the observed locations at each step by WAMI tracking. Given a {PO}2LTS M, we define a path œÅas a sequence of consecutive states ql...qu, and z(œÅ) as a sequence of cor responding observed location zl...zufor 0‚â§l < u , where landuare the starting and ending time under considera tion, respectively. We write œÅkfor the state qk, and z(œÅk) for the observed location z(qk) on the path œÅ. 6. Property Specification: Robustness and Re silience Formal verification determines whether a specification œï holds on a given LTS M[41]. Usually, a logic language, such as CTL, LTL, or PCTL, is used to formally express the specification œï. In this paper, to suit our needs, we let the specification œïbe a constrained optimisation objective; and so verification is undertaken in two steps: 1. determine whether, given Mandœï, there is a solution to the constrained optimisation problem. If the an swer is affirmative, an optimal solution solopt(M, œï) is returned. 2. compare solopt(M, œï) with a prespecified threshold Œ∏. Ifsolopt(M, œï)> Œ∏then we say that the property œï holds on the model Mwith respect to the threshold Œ∏. Otherwise, it fails. Note that, we always take a minimisation objective in the first step. Since the optimisation is to find the minimal answer, in the second step, if solopt(M, œï)> Œ∏, we cannot have a better ‚Äì in terms of a smaller value ‚Äì solution forthe threshold Œ∏.Intuitively, it is a guarantee that no attacker can succeed with less cost than Œ∏, and the system is hence safe against the property. The above procedure can be easily adapted if we work with maximisation objectives. Before proceeding to the formal definition of the robust ness and resilience properties, we need several notations. First, we consider the measure for the loss of localisation precision. Let œÅbe an original path that has not suffered from an attack. The other path eœÅis obtained after an at tack on œÅ. For the WAMI tracking system, we define their distance at time kas dist(œÅk,eœÅk) =||x(z(œÅk))‚àíx(z(eœÅk))||p (19) which is the Lpnorm difference between two images x(z(œÅk)) and x(z(eœÅk)). Moreover, let ( eœÅk‚àí1,eœÅk) be a transition on an attacked patheœÅ, and so we have œÜ(eœÅk‚àí1,eœÅk) =X (eœÅk‚àí1,eœÅ‚ãÑ k)‚â∫(eœÅk‚àí1,eœÅk)œÄ(eœÅk‚àí1,eœÅ‚ãÑ k) (20) as the combined payoffs that are required to implement the transition ( eœÅk‚àí1,eœÅk). Intuitively, it requires that all the payoffs of the transitions ( eœÅk‚àí1,eœÅ‚ãÑ k), which are par tially ordered by the envisaged transition ( eœÅk‚àí1,eœÅk), are counted. In the WAMI tracking system, this means that the attack results in misclassifications of all the images x(z(eœÅ‚ãÑ k)) such that the observation z(eœÅ‚ãÑ k) is closer to the predicted location Fks(eqk‚àí1) than z(eœÅk). 6.1. Definition of Robustness Robustness is a concept that has been studied in many fields such as psychology [42], biomedical analysis [43], and chemical analysis [44]. Here, we adopt the general defini tion of robustness as used in the field of artificial intelli gence (we later discuss the difference between this and the definition applied in software engineering): Robustness is an enforced measure to represent a system‚Äôs ability to consistently deliver its expected functionality by accommodating disturbances to the input. In LESESs, we measure the quality of the system main taining its expected functionality under attack on a given scenario with the distance between two paths ‚Äì its original path and the attacked path. Formally, given a track œÅand an attacker, it is to consider the minimal perturbation to the input that can lead to misfunction. Intuitively, the larger the amount of perturbations a system can tolerate, the more robust it is. Let dist0,e(œÅ,eœÅ) =eX k=0dist(œÅk,eœÅk) (21) 9be the accumulated distance, between the original track œÅ and the attacked track eœÅ, from the start k= 0 to the end k=e. Moreover, we measure the disturbances to an LESES as the perturbation to its imagery input. Formally, we let œÜl,u(eœÅ) =uX k=l+1œÜ(eœÅk‚àí1,eœÅk) (22) be the accumulated combined payoff for the attacked track eœÅbetween time steps landu, such that l‚â•0 and u‚â§e. When œÜ0,e(eœÅ) = 0, there is no perturbation and eœÅis the original track œÅ. Finally, we have the following optimisation objective for robustness: minimize eœÅœÜl,u(eœÅ) subject to dist0,e(œÅ,eœÅ)> œµrobustness(23) Basically, œÜl,u(eœÅ) represents the amount of perturbation to the input, while the malfunctioning of system is formu lated as dist0,e(œÅ,eœÅ)> œµrobustness ; that is, the deviation of the attacked track from the original track exceeds a given tolerance œµrobustness . 6.2. Definition of Resilience For resilience we take an ecological view widely seen in longitudinal population[45], psychological[46], and biosystem[47] studies. Generally speaking, resilience indicates an innate capability to maintain orrecover sufficient function ality in the face of challenging conditions [48] against risk or uncertainty, while keeping a certain level of vitality and prosperity [46]. This definition of resilience does not consider the pres ence of risk as a parameter [45], whereas the risks usually present themselves as uncertainty with heterogeneity in unpredictable directions including violence [49]. The out come of the resilience is usually evidenced by either: a recovery of the partial functionality, albeit possibly with a deviation from its designated features [50]; or a syn thetisation of other functionalities with its adaptivity in congenital structure or inbred nature. In the context of this paper, therefore resilience can be summarised as the system‚Äôs ability to continue operation (even with reduced functionality) and recover in the face of adversity. In this light, robustness, inter alia , is a feature of a resilient sys tem. To avoid complicating discussions, we treat them separately. In our definition, we take diste,e(œÅ,eœÅ)‚â§œµresilience as the signal that the system has recovered to its designated functionality. Intuitively, diste,e(œÅ,eœÅ)‚â§œµresilience means that the tracking has already returned back to normal ‚Äìwithin acceptable deviation œµresilience ‚Äì on the time step e‚â•u. Moreover, we take distmax=maximise t‚àà[l..u]distt,t(œÅ,eœÅ) (24) to denote the deviation of a path eœÅfrom the normal path œÅ. Intuitively, it considers the maximum distance between two locations ‚Äì one on the original track and the other on the attacked track ‚Äì of some time step t. The notation max ondistmaxdenotes the time step corresponding to themaximal value. Then, the general idea of defining resilience for LESESs is that we measure the maximum deviation at some step t‚àà[l, u] and want to know if the whole system can re spond to the false information, gradually adjust itself, and eventually recover. Formally, taking e‚â•u, we have the following formal definition of resilience: minimise eœÅdistmax subject to diste,e(œÅ,eœÅ)> œµresilience(25) Intuitively, the general optimisation objective is to min imize the maximum deviation such that the system cannot recover at the end of the track. In other words, the time erepresents the end of the track, where the tracking func tionality should have recovered to a certain level ‚Äì subject to the loss œµresilience . We remark that, for resilience, the definition of ‚Äúre covery‚Äù can be varied. While in Equation (25) we use diste,e(œÅ,eœÅ)‚â§œµresilience to denote the success of a recov ery, there can be other definitions, for example, asking for a return to some track that does not necessarily have be the original one, so long as it is acceptable. 6.3. Computational Complexity We study the complexity of the {PO}2LTS verification problem and show that the problem is NPcomplete for robustness. Concretely, for the soundness, an adversary can take a nondeterministic algorithm to choose the states ÀÜœÅkfor a linear number of steps, and check whether the constraints satisfy in linear time. Therefore, the problem is in NP. To show the NPhardness, we reduce the knapsack problem ‚Äì a known NPcomplete problem ‚Äì to the same constrained optimisation problem as Equation (23) on a {PO}2LTS. The general Knapsack problem is to determine, given a set of items, each with a weight and a value, the number of each item to include in a collection so that the total weight is less than or equal to a given limit, and the total value is as large as possible. We consider 01 Knapsack problem, which restricts the number ciof copies of each kind of item to zero or one. Given a set of nitems numbered from 1 up to n, each with a weight giand a value vi, along with 10a maximum weight W, the aim is to compute maximisenX i=1vici subject tonX i=1gici‚â§W ‚àÄi‚àà[1..n] :ci‚àà {0,1}(26) where cirepresents the number of the item ito be included in the knapsack. Informally, the problem is to maximize the sum of the values of the items in the knapsack so that the sum of the weights is less than or equal to the knap sack‚Äôs capacity. We can construct a {PO}2LTS M= (Q, q 0,kf, L, œÄ, Œ≤ ), where Q={q0}‚à™Sn i=1{qi0, qi1}. Intuitively, for every item i, we have two states representing whether or not the item is selected, respectively. For the transition relation kf, we have that kf={(q0, q1j)|j‚àà {0,1}} ‚à™ { (qij, q(i+1)j‚Ä≤)|i‚àà {1..n‚àí1}, j, j‚Ä≤‚àà {0,1}}, which connects each state of item ito the states of the next item i+ 1. The payoff function œÄis defined as œÄ(q, qi0) = 0 and œÄ(q, qi1) =vi, for all ( q, qij)‚ààkfandj‚àà {0,1}, representing that it will takevipayoff to take the transition ( q, qi1) in order to add the item iinto the knapsack, and take 0 payoff to take the other transition ( q, qi0) in order to not add the item i. The partial order relation Œ≤can be defined as having transition (q, qi0)‚â∫(q, qi1), for all ( q, qij)‚ààkfandj‚àà {0,1}. For the specification, we have the following robustness related optimisation objective. minimize eœÅœÜ1,n(eœÅ) subject to dist1,n(œÅ,eœÅ)> W(27) such that dist(œÅk,eœÅk) =0 if eœÅk=qk0 gkifeœÅk=qk1(28) Recall that, œÜ1,n(eœÅ) is defined in Equations (22) and (20), anddist1,n(œÅ,eœÅ) is defined in Equation (21). As a result, the robustness of the model Mand the above robustness property is equivalent to the existence of a solution to the 01 Knapsack problem. This implies that the robustness problem on {PO}2LTSs is NPcomplete. 7. Automated Verification Algorithm An attack on the LESESs, as explained in Section 5.1, adds perturbations to the input images in order to fool a neural network, which is part of the perception unit, into making wrong detections. On one hand, these wrong detections will be passed on to the perception unit, which in turn affects the Bayes filter and leads to wrong state estimation; the LESES can be vulnerable to such attack. On the other hand, the LESESs may have internal or external mechanisms to tolerate such attack, and thereforeperform well with respect to properties such as robustness or resilience. It is important to have a formal, principled analysis to understand how good a LESES is with respect to the properties and whether a designed mechanism is helpful in improving its performance. We have introduced in Section 5 how to reduce an LE SES into a {PO}2LTS Mand formally express a prop erty ‚Äì either robustness or resilience ‚Äì with a constrained optimisation objective œïbased on a path œÅin Section 6. Thanks to this formalism, the verification of robust ness and resilience can be outlined using the same algo rithm. Now, given a model M, an optimisation objec tiveœï, and a prespecified threshold Œ∏, we aim to develop an automated verification algorithm to check whether the model Mis robust or resilient on the path œÅ; or formally, solopt(M, œï)> Œ∏, where solopt(M, œï) denotes the optimal value obtained from the constrained optimisation problem overMandœï. The general idea of our verification algorithm is as fol lows. It first enumerates all possible paths of Mobtain able by attacking the given path œÅ(Algorithm 1), and then determines the optimal solution solopt(M, œï) among the paths (Algorithm 2). Finally, the satisfiability of the property is determined by comparing solopt(M, œï) and Œ∏. 7.1. Exhaustive Search for All Possible Tracks The first step of the algorithm proceeds by exhaustively enumerating all possible attacked paths on the {PO}2LTS Mwith respect to œÅ. It is not hard to see that, the paths will form a tree, unfolded from the {PO}2LTS M, as il lustrated in Figure 3. Since a final deviation is not avail able until the end of a simulation, the tree has to be fully expanded from the root to the leaf and all the paths ex plored. Clearly, the time complexity of this procedure is exponential with respect to the number of steps, which is consistent with our complexity result, as presented in Sec tion 6.3. Specifically, breadthfirst search (BFS) is used to enumerate the paths. The details are presented in Algo rithm 1. We need several operation functions on the tree, includ ingleaf (which returns all leaf nodes of the root node), parent (which associates a node to its parent node), and path (which returns all tree paths from the given root node to the leaf nodes). Lines 212 in Algorithm 1 present the procedure of con structing the tree diagram. First, we set the root node œÅl‚àí1 (Line 2), that is, we will attack the system from the ( l‚àí1) th state of the original track œÅand enumerate all possible adversarial tracks. At each step k, function neighbours will list all observations near the predicted location (Line 5). Then, each observation is incorporated with current state œÅkfor the calculation of the next state œÅk+1(Line 7). If no observation is available or z=‚àÖ, the KF can still run normally, skipping the update phase. To enable each transition ( œÅk, œÅk+1), the partial order relation is fol lowed when attacking the system and recording the payoff œÜ(Line 8). Then, the potential œÅk+1is accepted and added 11Algorithm 1: Exhaustive Search based on BFS Input: LTS model M,n,l,u Output: path set P, payoff set œÜl,u 1:run original path œÅfrom k= 0 to k=n 2:setœÅl‚àí1as root node 3:forkfrom l‚àí1 toudo 4:foreach node eœÅkinleaf(œÅl‚àí1)do 5: find potential observations Z‚Üêneighbours (eœÅk) 6: foreach observed location zinZdo 7: eœÅk+1‚Üêkf(eœÅk,z) 8: calculate the attack payoff œÜ(eœÅk+1,eœÅk) 9: eœÅk=parent (eœÅk+1) 10: end for 11: end for 12:end for 13:P‚Üêpath(œÅl‚àí1) 14:run path eœÅin set Ptok=n 15:calculate the combined payoff for each path eœÅ œÜl,u(eœÅ) =Pu k=lœÜ(eœÅk‚àí1,eœÅk)/(u‚àíl) 16:return P,œÜl,u as the child node of œÅk. Once the tree is constructed, we continue simulating the tracks to the end of time, k=n, (Lines 1314). Finally, all the paths in set Pare output along with the attack payoff œÜl,u(Lines 1516). 7.2. Computing an Optimal Solution to the Constrained Optimisation Problem After enumerating all possible paths in P, we can com pute optimal solutions to the constrained optimisation problems as in Equation (23) and (25). We let objbe the objective function to minimize, and conbe the con straints to follow. For robustness, we have obj=œÜl,uand con=dist0,e, and for resilience, we have obj=distmax andcon=diste,e. Note that, our definitions in Equations (23) and (25) are set to work with cases that do not satisfy the properties, i.e., paths that are not robust or resilient, and identify the optimal one from them. Therefore, a path satisfying the constraints suggests that it does not satisfy the prop erty. We split the set Pof paths into two subsets, P+ andP‚àí. Intuitively, P+includes those paths satisfying the constraints, i.e., fail to perform well with respect to the property, and P‚àíincludes those paths that do not satisfy the constraints, i.e., perform well with respect to the property. For robustness, P+includes paths satisfying dist0,e(œÅ,eœÅ)> œµandP‚àísatisfying dist0,e(œÅ,eœÅ)‚â§œµ. For resilience, P+includes paths satisfying diste,e(œÅ,eœÅ)> œµ andP‚àísatisfying diste,e(œÅ,eœÅ)‚â§œµ. In addition to the optimal solutions that, according to the optimisation objectives, are some of the paths in P+, it is useful to identify certain paths in P‚àíthat are ro bust or resilient. Let solopt(M, œï) be the optimal obj value, from the optimal solution. We can sort the pathsAlgorithm 2: Computation of Optimal Solution and A Representative Path Input: path set P,obj,con,œµ Output: representative path eœÅ‚àó,objvalue Œ∏‚àóofœÅ‚àó, and optimal value solopt(M, œï) 1:find the original path œÅin set P 2:solopt(M, œï)‚Üê0,k‚Üê0,P+‚Üê ‚àÖ,P‚àí‚Üê ‚àÖ 3:foreœÅin set Pdo 4:ifcon(œÅ,eœÅ)> œµthen 5: k‚Üêk+ 1 6: P+‚ÜêP+‚à© {eœÅ} 7: ifk= 1 or obj(œÅ,eœÅ)< sol opt(M, œï)then 8: solopt(M, œï)‚Üêobj(œÅ,eœÅ) 9: end if 10: else 11: P‚àí‚ÜêP‚àí‚à© {eœÅ} 12: end if 13:end for 14:œÅ‚àó‚Üêarg max eœÅ‚ààP‚àí,obj<sol opt(M,œï)obj(œÅ,eœÅ) 15:Œ∏‚àó‚Üêobj(œÅ, œÅ‚àó) 16:return œÅ‚àó,Œ∏‚àó,solopt(M, œï) inP‚àíaccording to their objvalue, and let representa tive path œÅ‚àóbe the path whose objvalue is the great est among those smaller than solopt(M, œï). Intuitively, œÅ‚àó represents the path that is closest to the optimal solution of the optimisation problem but satisfies the correspond ing robust/resilient property. This path is representative because it serves as the worst case scenario for us to ex ercise the system‚Äôs robust property and resilient property respectively. Moreover, we let Œ∏‚àóbe the objvalue of ro bustness/resilience of the path œÅ‚àó, called representative value in the paper. The algorithm for the computation of the optimal solu tion and a representative path can be found in Algorithm 2. Lines 1 to 9 give the process to solve Equation (23) or (25) for the optimal value solopt(M, œï). The remaining Lines calculate the representative value Œ∏‚àóand a represen tative path œÅ‚àó. For each adversarial path in P, it is added into either P+ (Line 6) or P‚àí(Line 11). The minimum objective function is then found by comparing the adversarial tracks in set P+(Lines 49). We need to find the representative path in setP‚àí, which has the objvalue smaller than solopt(M, œï) but lager than any other path in P‚àí(Line 14). Its corre sponding representative value is computed in Line 15. 8. Experimental Results We conduct an extensive set of experiments to show the effectiveness of our verification algorithm in the de sign of the WAMI tracking system. We believe that our approaches can be easily generalised to work with other autonomous systems using both Bayes filter(s) and neural networks. 128.1. Research Questions Our evaluation experiments are guided by the following research questions. RQ1 What is the evidence of system level robustness and resilience for the WAMI tracking in Section 3? RQ2 What are the differences and similarity between ro bustness and resilience within the WAMI tracking? RQ3 Following RQ1 andRQ2 , can our verification ap proach be used to identify, and quantify, the risk to the robustness and resilience of the WAMI tracking system? RQ4 Are the improved design presented in Section 4 helpful in improving the system‚Äôs robustness and resilience? Their respective experiments and results are presented in Section 8.3, 8.4, 8.5 and 8.6. 8.2. Experimental Setup We consider a number of original tracks with maximum length of 20 steps ( e= 19, k‚àà[0,19]). An attack on the system is conducted between time steps landu, denoted as Attack (l, u), with the following configurations: l‚àà[4,12], and ( u‚àíl)‚àà[1,4]. The original track is coloured in green in both the highresolution images (Figure 4‚Äì10) and the state space unfolding (Figure 7c). The attacked track is coloured in red. The whitecolour arrows in the high resolution images indicate the groundtruth directions of the vehicle. Moreover, in all experiments, for every attacked track, we record the following measures: the combined payoff œÜ, the cumulative deviation dist0,e, the maximum deviation distmaxand the final step deviation diste,e, such that m is the time step for maximum deviation and eis the end of the track. 8.3. Evidence of System‚Äôs Robustness and Resilience To demonstrate the system‚Äôs robustness and resilience against the perturbance on its imagery input, we show the attack on the WAMI tracking in Figure 4a with combined payoff œÜ= 10 .47. The payoff is calculated as the total perturbations added to the input images for generating the current adversarial track (coloured in red) against the orig inal track (coloured in green). If we loosen the restriction on the attacker, for example, the attack payoff is increased toœÜ= 20.58, with other settings remaining unchanged, we get the results in Figure 4b. While the attacker‚Äôs effort is almost doubled (from œÜ= 10.47 to œÜ= 20.58), the devi ation from the original track is not increased that much. This is evidence of the system level robustness . To have a better understanding about this, we investigate the updat ing process for tracking at k= 6 and visualise the process in Figure 4c and 4d respectively. As shown in the Figure 4c and 4d, the blue point identi fies the predicted location of the tracking vehicle, the green (a)k= 6,œÜ= 10.47  (b)k= 6,œÜ= 20.58 (c) KF‚Äôs update process for (a)  (d) KF‚Äôs update process for (b) Figure 4: Illustration of WAMI system‚Äôs robustness to the consecu tive attack at k= 5‚àí6. With increased attack payoff, the deviation is still bounded. point is the correct observation, and other grey points are observations of other vehicles around the tracked one. Other vehicles are potential disturbances to the system. For Scene (a), the attacker makes the closest three de tections invisible to the system with an attack payoff œÜ= 10 .47. For scene (b), one more observation is mis detected with the payoff increased to œÜ= 20.58, and thus the KF associates the most distant observation as the ob servation for updating. Nevertheless, for both scenes, the wrong observations are still within the bound, which is denoted by the dashed circle. We can see that the WAMI tracking system is designed in a way to be robust against the local disturbances. First, as presented in its architecture by Figure 1, the back ground subtraction can guarantee that only moving ob jects are input to the CNNs for vehicle detection; this means that error observations that can influence the track ing accuracy are discrete and finite, which are easier to control and measure than continuous errors. Second, the KF‚Äôs covariance matrix leads to a search range, only within which the observations are considered. In other words, even if the attacker has infinite power ‚Äì measured as payoff ‚Äì to attack the system at some step, the possible devia tions can be enumerated and constrained within a known bound. To show the system‚Äôs resilience to erroneous behaviours, we consider the maximum deviation depicted in Figure 5a, which arises from a onestep attack at k= 8. After three steps forward, i.e., k= 12, we have the tracking results 13(a) vehicle tracking at k= 9  (b) vehicle tracking at k= 12 Figure 5: Illustration of WAMI system‚Äôs resilience to the one step attack at k= 8. The attack payoff œÜ= 6.49. as depicted in Figure 5b. Evident in this test scene, the adversarial tracking is corrected by the system itself, back to the original expected track in a short time period ‚Äì a clear evidence of resilience. Taking a careful look into Figure 5a, we can see that, atk= 8, the attacked track is associated with a wrong observation in the opposite lane. Due to the consistency in the KF, this false information may disturb the original tracking, but cannot completely change some key values of the KF‚Äôs state variables; for example, the direction of the velocity vector. That means that, even for the adversarial tracking, the prediction still advances in the same direction to the previous one. Hence, this wrong observation will not appear in the search range of its next step. For this reason, it is likely that the tracking can be compensated and returned to the original target vehicle . Another key fact is that, the KF‚Äôs covariance matrix will adjust according to the detection of observations. If no ob servation is available within the search range, the uncer tainty range ‚Äì decided by covariance matrix ‚Äì will enlarge and very likely, the error tracking can be corrected. This reflects the KF‚Äôs good adaption to the errors ‚Äì another key ability in achieving resilience. We have the following takeaway message to RQ1 : The WAMI tracking system in Section 3.6 is robust and resilient (to some extent) against the adversarial attacks on its neural network perceptional unit. 8.4. Comparison Between Robustness and Resilience Robustness and resilience as defined in Section 6 are both measures of a system‚Äôs capacity to handle pertur bations; however, they are not equivalent definitions. To assist in appreciating the distinction, Figure 6 provides examples. In Figure 6, we present two typical cases to illustrate a system‚Äôs robustness and resilience against the attack. Their deviations from the original tracks at each step are recorded in Figure 6c and Figure 6d, respectively. The hor izontal dash line can be seen as the enhanced robustness (a) robustness  (b) resilience (c) deviation of robust track  (d) deviation of resilient track Figure 6: Comparison between robustness and resilience in WAMI tracking threshold, requiring that each step‚Äôs deviation is smaller than some given threshold. For the vehicle tracking in Figure 6a, we can say the system satisfies the robustness property against the disturbance, since the deviation at each step is bounded. However, this tracking is not re silient to the errors due to the loss of ‚Äúrecovery‚Äù property: it is apparent to see the deviation worsens over time. In contrast, for the vehicle tracking in Figure 6b, the tracking is finally corrected ‚Äì with the tracking back to the origi nal track ‚Äì at the end even when the maximum deviation (at time step 9) exceeds the robustness threshold. There fore, to conclude, this vehicle tracking is resilient but not robust. We have the following takeaway message to RQ2 : Robustness and resilience are different concepts and may complement each other in describing the system‚Äôs resistance and adaption to the malicious attack. 8.5. Quantify the Robustness and Resilience Bound In the previous subsections, we have provided several examples to show the WAMI tracking system‚Äôs robustness and resilience to malicious attack. However, we still do not know to what extent the system is robust or resilient to natural environmental perturbation. In this subsection, we will show, from the verification perspective, a quan tification of robustness and resilience of the WAMI track ing design in Section 3. That is, given an original track and its associated scene, whether or not we can quantify 14the robustness and resilience of that track, by solving the optimisation problem defined in Equation (23) and (25). Moreover, as quantitative measures rather than the opti mal solutions, we will further get the representative path and representative value ‚Äì as defined in Section 7.2 ‚Äì of the tracking. (a) test scene  (b) original track (c) Enumeration of all possible Tracks Figure 7: Attack the system at k= 6,7,8 on a selected scene. Tree graph exhibits all possible tracks, where green is the original track, blue is the resilience representative track, and red is the robustness representation track. The labels on the nodes represent ‚Äú(time step) (ID of associated detection)‚Äù. Let us consider a track and the running test scene as shown in Figure 7. The white circle in Figure 7a contains the target vehicle and the green line in Figure 7b is the output of original tracking2. By attacking the original track from time step k= 6 to k= 8, we can enumerate all the possible variants (using Algorithm 1) in Figure 7c. To find the representative value, we record all the mea sures for each possible track in Table 2. Note that the attack payoff is calculated as the minimum perturbation for the current deviation, since we use the best attack approach, for example, Deepfool to find the shortest dis tance to the decision boundary in input space. Empiri cal parameters are set, e.g., like the robustness threshold œµrobustness = 120 (i.e., the system is robust if the cumula tive deviation of 20 time steps does not exceed 120), and the resilience threshold œµresilience = 1 (i.e., the system is resilient if the final deviation does not exceed 1). We re mark that, these two hyperparameters can be customised according to users‚Äô particular needs. We then apply Algorithm 2 to search for the optimal so lution to robustness and resilience verification, as defined 2The target vehicle in two images are in different locations due to the time difference.in Equation (23) and (25). The verification outcome is presented in Table 3. The results show that optimal so lution solopt(M, œï) to robustness verification is œÜ= 6.81; the minimum attack payoff to lead to the failure of the system. The attack payoff œÜof Track No.11 and No.15 is greater or equal to solopt(M, œï), and have dist0,eover the robustness threshold. The result of resilience verifica tion is distmax= 53.65, the minimum maximum deviation from which the system cannot recover. For example, the maximum deviation distmaxof Track No.1 and No.15 is greater or equal to solopt(M, œï), and have diste,eover the resilience threshold. Moreover, we are interested in three specific tracks: (1) the original track, denoted as Track No. 12; (2) an adver sarial track to represent the system‚Äôs robustness, denoted as Track No. 10; and (3) an adversarial track to represent the system‚Äôs resilience, denoted as Track No. 5. We can see that, the robustness representative value of the tracking is œÜ= 3.10. If the attack payoff is constrained within this bound (including the bound value), the tracking of inter est can have a guaranteed accumulative deviation smaller than 120. In addition, the resilience representative value isdistmax= 30.51. If the defender can monitor the track ing and control the maximum deviation to make it smaller than or equal to this bound, the system can resist the er rors and recover from the misfunction. These two tracks, reflecting the robustness and resilience respectively, are also plotted in Figure 8. (a) robustness representative track (b) resilience representative track Figure 8: Adversarial tracks to quantify the system‚Äôs robustness and resilience Additionally, Table 2 also provides some other interest ing observations that are worth discussing. For example, comparing Track No. 9, Track No.15 and Track No.16, it‚Äôs not difficult to determine that the deviation is very likely to increase dramatically when disturbances go over the system‚Äôs endurance. Under such circumstances, the maxi mum deviation normally occurs at the end of the tracking. In other words, the deviation will be increased further and further with time, and the KF is totally misled, such that it tracks other vehicles, distinctly distant to the intended one. We have the following takeaway message to RQ3 : 15Table 2: Measures of all possible tracks for test scene in Figure 7: œÜis the combined payoff; dist0,e,distmaxanddiste,eare accumulated deviation, maximum deviation and endpoint deviation between the original track œÅand the adversarial track eœÅrespectively. Track No. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 œÜ 20.32 19.44 12.63 20.15 20.01 12.56 13.27 10.62 9.91 3.10 6.81 0.00 18.53 11.72 12.61 11.65 11.82 dist0,e529.99 103.17 7.23 5447.39 138.59 138.37 50.95 20.54 115.58 24.75 530.24 0.00 58.47 38.89 5462.11 5467.95 2430.17 distmax53.65 26.62 4.42 936.97 30.51 29.91 29.91 14.53 26.05 14.53 53.65 0.00 27.44 22.83 936.97 936.98 220.95 diste,e53.65 0.07 0.01 936.97 0.06 0.06 0.01 0.01 0.06 0.01 53.65 0.00 0.01 0.01 936.97 936.98 210.13 Table 3: The outcome of robustness and resilience verification for test scene in Figure 7: solopt(M, œï) is the optimal value; Œ∏‚àóandœÅ‚àó represents the representative value and track (of the robustness and the resilience) respectively. Robustness Verification Resilience Verification solopt(M, œï) 6.81 53.65 Œ∏‚àó3.10 30.51 œÅ‚àócolored in red (Figure 7c) colored in blue (Figure 7c) Our verification approach can not only find the op timal values for the optimisation problems as specified in (23) and Equation (25), but also find representative values and paths as defined in Section 7.2 to exhibit and quantify the robustness and resilience. 8.6. Improvement to the robustness and resilience In this part, we apply the runtime monitor and the Joint KFs introduced in Section 4. We report whether theses two techniques can make an improvement to the WAMI tracking system through the experiments. In Figure 9, a runtime monitor runs along with the sys tem in order to continuously check the Bayesian uncer tainty of the KF. As discussed in Section 4.1, a KF alter nates between the prediction phase and the update phase, and the Bayesian uncertainty is gradually reduced until convergence. This can be seen from Figure 9a (Right), where there is no adversarial attack on the detection com ponent and the uncertainty curve is very smooth. How ever, if the system is under attack, it is likely that the expected functionality of the KF is disrupted, and the KF performs in an unstable circumstance. Consequently, there will be time steps where no observations are available, leading to the increasing of uncertainty. When it comes to the uncertainty curve, as shown in Figure 9b (Right), a spike is observed. The above discussion on uncertainty monitoring in Fig ure 9 is based on the condition that the environmental in put is not complex and the surrounding vehicles are sparse: the misdetection of vehicles is very likely to result in no observations seen by the system within the search range. For more complicated cases such that there are a signif icant number of vehicles in the input imagery, and the target tracking is more likely to be influenced by the sur roundings, we need to refer to the improved design of tak ing jointKFs for observation association filters in Section 4.2. (a) tracking without attack (b) tracking with attack Figure 9: Runtime monitoring on the WAMI system‚Äôs tracking The main idea of implementing jointKFs is to assign a tracking to each surrounding vehicle and the observation association is based on the maximum likelihood function as defined. In other words, if some surrounding vehicle has already been tracked by another KF, it will not be followed by the tracking of the current KF. An example is shown in Figure 10. In Figure 10a, the green line represents the original track and the green dots are vehicles detected by the system. Obviously, the whole system operates normally and con tinuously tracks the target vehicle. However, when we at tack the detection component at this time step, as shown in Figure 10b, the current observation becomes invisible to the system. While using the original approach, the track is deviated to the nearest vehicle (see the red line). When the joint KFs are applied, since the surrounding vehicles are associated to other trackers, the primary tracker will not be associated with a wrong observation and will skip the update phase (and move along the yellow line). Thus, after the attack is stopped, the track is always correct and can finally be associated to the true target (as shown in Figure 10b where the yellow line overlays the green line). In the experiments, we discovered that the application of 16(a) tracking without attack  (b) tracking with attack Figure 10: Comparison between tracking with single KF and joint KFs joint KFs is very effective when dealing with an attack when the vehicle traveses on a straight line, but it can be less sufficient when the attack activates while the true track is curved. This is because we adopt a constant veloc ity model within the dynamic model of the tracker, which is not optimal to describe the case: it makes the mean of the prediction always on a straight line and does not con sider the potential direction of the movement. Therefore, when there are many detections, the data association is more likely to be wrong and lead to a larger deviation. Table 4: The outcome of robustness and resilience verification for test scene in Figure 7 with jointKFs and Runtime Monitor (it should be read in comparison with Table 3). Robustness Verification Resilience Verification solopt(M, œï) inf. 53.65 Œ∏‚àóinf. 30.51 œÅ‚àónone remain same To understand how the above two techniques collectively improve the robustness and resilience, we consider the ex periments described in Section 8.5, with the improvement of using jointKFs as data association method and the at taching a runtime monitor to the tracker that are described in Section 4. Generally speaking, after enumerating all the possible tracks, we only get the original (and true) track, with all adversarial tracks being removed. Examining Figure 11, if we attach a runtime monitor to the system, those tracks that lack observations at some steps (detection ID is None) can be detected and eliminated. Furthermore, if we replace the system‚Äôs tracking component with jointKFs, the sys tem can be protected from influence by incorrect observa tions. These two methods combined together are effective to prevent any successful attack and thereby improve the tracking robustness. As shown in Table 4, since no adver sarial track exists, the attack payoff can be theoretically infinite. In practice, the payoff is usually constrained and we can introduce an oracle to judge if the very high attack payoff is valid or not. For example, too much noise added to the image will make it unrecognized by the system.Regarding the resilience of the tracker, there is no evi dence that the improvement methods have made a differ ence, even though all adversarial tracks (shown in Table 2) are eliminated successfully. The reason is that when the track has switched to a wrong target (by using large distmax, which is the case we test in determining the pos sibility of resilience), the history information of the true target is lost. The Kalman filter is designed to estimate the state of one object with some assumptions, and resilience to a extreme noise is beyond its capacity. We remark that, to improve the resilience, extra com ponent(s) that processes additional information about the target vehicle is needed, for example considering different appearances of the vehicles and the context of the road net work. With this kind of knowledge, the tracking system can incorporate a way to respond to the errors, and when the track is dramatically deviated, correct itself back. This will be investigated in future work. However, what can be reemphasised from the experiments is that the robustness and the resilience are indeed different. We have the following takeaway message to RQ4 : The runtime monitor approach can eliminate some wrong tracks, and the jointKFs approach can reduce the risks of being influenced by wrong observations. Both of them are effective in improving the robustness, but less so for the resilience. 9. Discussion: Robustness vs. Resilience In the discussion above, robustness and resilience can be seen as complementary concepts for the safety of a sys tem ‚Äì they express different safety aspects of the system in dealing with uncertainties. Robustness considers whether the system is tolerant, i.e., functions as usual, under the external change to the input. By contrast, resilience con siders whether the system can recover from serious dam ages, resume part of the designed functionality, and even show signs of managing the damages. We note here that the definition of robustness that has become generally accepted in the study of Artificial Intel ligence (in particular adversarial behaviour) differs from that traditionally found in Software Engineering for criti cal systems where the definition relates to the systems abil ity to function correctly in the presence of invalid inputs (e.g. see the IEEE standard for software vocabulary [51]). Surprisingly, resilience is not defined therein, possibly due to the relative newness of the field. However, Murray et. al[52] draw together several sources to suggest that re silient software should have the capacity to withstand and recover from the failure of a critical component in a timely manner. This ties in with our definition in Subsection 6.2, but can be considered as narrower since it does not ex tend to attributes that may prevent component failure (as in dealing with external perturbations). To facilitate the 17Figure 11: Improvement to WAMI tracking system by Runtime Monitor and jointKFs (Possible adversarial tracks are reduced). move toward integrating ML technologies in highintegrity software engineer practices the following recommendation is made: The definitions currently being adopted in stateof theart ML research, such as robustness and resilience, should be aligned to existing and accepted software engineering definitions. In the experimental sections such as Section 8.5, exam ples have been provided to show the difference between robustness (in the context of ML) and resilience on the LESESs. In the following, we discuss a few aspects that are not covered in the LESESs. 9.1. EndtoEnd Learning based on Feedforward Network Consider an endtoend learning system where the entire system itself is a feedforward neural network ‚Äì for example a convolutional neural network as in the NVIDIA DAVE2 selfdriving car [53]. A feedforward network is usually re garded as an instantaneous decision making mechanism, and treated as a ‚Äúblackbox‚Äù. These two assumptions mean that there is no temporal dimension to be consid ered. Therefore, we have that l= 0 and m=u=e= 1, for definitions in Equation (23) and Equation (25). Fur ther, if the adversarial perturbation [9] is the only source of uncertainties to the system, we have distmax=dist1,1(œÅ,eœÅ) =œÜ0,1(eœÅ) =œÜl,u(eœÅ) (29) and dist0,e(œÅ,eœÅ) =dist0,1(œÅ,eœÅ) = dist1,1(œÅ,eœÅ) =diste,e(œÅ,eœÅ)(30) i.e., both the objective and the constraints of Equation (23) and Equation (25) are the same. It may be justifiable that the abovementioned equiva lence of robustness and resilience is valid because, for in stantaneous decision making, both properties are focused on the resistance ‚Äì i.e., to resist the change and main tain the functionality of the system ‚Äì and less so on the adaptability ‚Äì i.e., adapt the behaviour to accommodate the change. Plainly, there is no time for recovering from the damages and showing the sign of managing the risks. Moreover, it may be that the feedforward neural network isa deterministic function, i.e., every input is assigned with a deterministic output, so there is no recovering mechanism that can be implemented. Nevertheless, the equivalence is somewhat counter intuitive ‚Äì it is generally believed that robustness and re silience are related but not equivalent. We believe this con tradiction may be from the assumptions of instantaneous decision making and blackbox . If we relax the assump tions, we will find that some equations ‚Äì such as l= 0, m=u=e= 1, and Equations (29) and (30) ‚Äì do not hold any more. Actually, even for a feedforward neural network, its decision making can be seen as a sequential process, going through input layer, hidden layers, to out put layer. That is, by taking a whitebox analysis method, there is an internal temporal dimension. If so, the defini tions in Equation (23) and Equation (25) do not equate, and capture different aspects of the feedforward network tolerating the faults, as they do for the LESESs. Ac tually, robustness is to ensure that the overall se quential process does not diverge, while resilience is to ensure that the hidden representation within a certain layer does not diverge . We remark that this robustness definition is different from that of [9]. Up to now, we are not aware of any research directly dealing with a definition of resilient neural networks. For robust ness, there is some research (such as [54, 55]) suggesting that this definition implies that of [9], without providing a formal definition and evaluation method, as we have done. Beyond feedforward neural networks, it will be an in teresting topic to understand the similarity and difference of robustness and resilience, and how to improve them, for other categories of machine learning systems, such as deep reinforcement learning and recurrent neural net works, both of which have temporal dimension. We believe our definitions can be generalised to work with these sys tems. 9.2. Showing Sign of Recovering For resilience, it is not required to always return to where the system was before the occurrence of the fail ure. Instead, it can resume part of its functionality. In this paper, for the LESESs, we define the status of ‚Äúre covered‚Äù to be diste,e(œÅ,eœÅ)‚â§œµresilience , i.e., the distance of the final location of the attacked track is close to that of the original track, within a certain threshold. While 18the status of ‚Äúrecovered‚Äù can be defined, it is harder to ‚Äúshow the sign of recovering‚Äù, which is a subjective evalu ation of the system‚Äôs recovering progress from an outside observer‚Äôs point of view. An outside observer does not necessarily have the full details of the recovering process, or the full details of the system implementation. Instead, an observer might conduct Bayesian inference or epistemic reasoning [56] by collecting evidence of recovering. Techni cally, a runtime monitor can be utilised to closely monitor some measurements of the recovering process; indeed, the runtime monitor we used for Kalman filter convergence (Section 4.1) can be seen as a monitor of the sign of re covering. If the Bayesian uncertainty is gradually reduced and converging, this can be considered evidence that the system is managing the failure. On the other hand, if the Bayesian uncertainty is fluctuating, we cannot claim signs of recovery, even if it might recover in the end, i.e., satis fying the condition diste,e(œÅ,eœÅ)‚â§œµresilience . 9.3. Resilience over Component Failure In the paper, we consider the uncertainties from the ex ternal environment of the system, or more specifically, the adversarial attacks on the inputs to the perception unit. While this might be sufficient for robustness, which quan tifies the ability to deal with erroneous input, there are other uncertainties ‚Äì such as internal component failure ‚Äì that may be worthy of consideration when working with resilience, because resilience may include not only the abil ity to deal with erroneous input but also the ability to cope with, and recover from, component failure, as suggested in e.g., Murray et. al [52] in software engineering. In LESESs, the component failure may include the fail ure of a perceptional unit or the failure of a Bayes filter. The failures of Bayes filter may include e.g., missing or perturbed values in the matrices F,H,Q, and R. The failures of the perceptional unit may include e.g., the fail ure of interactions between neural networks, the internal component failure of a neural network (e.g., some neuron does not function correctly), etc. The study of component failures, and their impact to resilience, will be considered in our future work. 10. Related Work "
112,Learning Safe Neural Network Controllers with Barrier Certificates.txt,"We provide a novel approach to synthesize controllers for nonlinear
continuous dynamical systems with control against safety properties. The
controllers are based on neural networks (NNs). To certify the safety property
we utilize barrier functions, which are represented by NNs as well. We train
the controller-NN and barrier-NN simultaneously, achieving a
verification-in-the-loop synthesis. We provide a prototype tool nncontroller
with a number of case studies. The experiment results confirm the feasibility
and efficacy of our approach.","Controller design and synthesis is one of the most fundamental problems in con trol theory. In recent years, especially with the boom of deep learning, there has been considerable research activities in the use of neural networks (NNs) for control of nonlinear systems [24,10]. NNs feature the versatile representational ability of nonlinear maps and fast computation, making them an ideal candidate for sophisticated control tasks [27]. Typical examples include selfdriving cars, drones, and smart cities. It is noteworthy that many of these applications are safetycritical systems, where safety refers to, in a basic form, that the system cannot reach a dangerous or unwanted state. For control systems in a multitude of CyberPhysicalSystem domains, designing safe controllers which can guar antee safety behaviors of the controlled systems is of paramount importance [32,3,33,12,38,5,6,43,17,39]. Typically, when a controller is given, formal verication is required to certify its safety. Our previous work [44] has dealt with the verication of continuous dynamical systems by the aid of neural networks. In a nutshell, we follow a deductive verication methodology therein by synthesizing a barrier function, the existence of which suces to show the safety of the controlled dynamicalarXiv:2009.09826v1  [eess.SY]  18 Sep 20202 H. Zhao et al. system. The crux was to use neural networks to represent the barrier functions, spurred by the wellknown universal approximation theorem [22] which assures the expressibility of NNs. It is imperative to realize that verication or certication of an existing con troller does not lend itself to eective and ecient construction of controllers, which is the main focus of the current work. Following a correctnessbydesign methodology, we aim to synthesize controllers which can guarantee that the con trolled system is safe. This question is considerably more challenging and perhaps more interesting from a system engineering perspective. To this end we adopt a datadriven approach for the design of controllers which are to be represented as an NN. A key issue of controller synthesis is to provide a formal guarantee of the quality for the obtained controller, of which safety is arguably the most fundamental. A common practice is to rst come up with a controller and then to verify it against desired properties. An interesting innovation of our work is, however, to integrate the synthesis and verication in a unied, datadriven framework, which is enabled by our earlier work by using NNs as a certica tion mechanism. At a high level, our approach for the controller synthesis will produce two neural networks simultaneously, i.e., one is used to represent the controller (henceforth referred to as controllerNN), and the other is used to rep resent the barrier function (henceforth referred to as barrierNN). The synergy of the two NNs, supported by an additional verication procedure to make sure the learned barrierNN is indeed a barrier certicate, provides the desired safety guarantee for the synthesized controller. Our method follows a datadriven framework in the sense that both NNs are trained from datasets. For that purpose, we generate training sets and pro pose specically designed loss functions which are the key towards application of standard learning algorithms for NNs. In terms of the learned NN controllers, we nd that they usually respect safety constraints, but may exhibit poor perfor mance in terms of, e.g., stability. To further improve the synthesized controllers, we propose a number of approaches such as imposing a larger safety region, stabilityaware loss functions, and bounded control inputs (via the Hardtanh activation function). In general, the advantages of our approach are threefold: (1) the approach is datadriven, requiring considerably less control theory expertise; (2) the ap proach can support nonlinear control systems and safety properties, owing to the representation power of neural networks; and (3) the approach can achieve vericationintheloop synthesis, owing to the cosynthesis of controller and bar rier functions, which can be seamlessly integrated to provide a correctnessby design controller as well as its certication. The main contributions of the paper are summarized as follows: {We put forward a learningbased framework to synthesize controllers as well as the associated safety certication. This is largely a datadriven approach, with little prior knowledge required, and enjoys great  exibility to eectively handle nonlinear (beyond polynomial) dynamics of ODEs.Learning Safe Neural Network Controllers with Barrier Certicates 3 {We instantiate the framework by using new class of activation functions. Moreover, we demonstrate how to generate training set, and to construct loss functions of neural networks. We also provide practical methods to formally verify the learnt barrier certicates represented as neural networks. {We carry out proofofconcept case studies to showcase the ecacy of the approach. 1.1 Related Work "
449,LMD: A Learnable Mask Network to Detect Adversarial Examples for Speaker Verification.txt,"Although the security of automatic speaker verification (ASV) is seriously
threatened by recently emerged adversarial attacks, there have been some
countermeasures to alleviate the threat. However, many defense approaches not
only require the prior knowledge of the attackers but also possess weak
interpretability. To address this issue, in this paper, we propose an
attacker-independent and interpretable method, named learnable mask detector
(LMD), to separate adversarial examples from the genuine ones. It utilizes
score variation as an indicator to detect adversarial examples, where the score
variation is the absolute discrepancy between the ASV scores of an original
audio recording and its transformed audio synthesized from its masked complex
spectrogram. A core component of the score variation detector is to generate
the masked spectrogram by a neural network. The neural network needs only
genuine examples for training, which makes it an attacker-independent approach.
Its interpretability lies that the neural network is trained to minimize the
score variation of the targeted ASV, and maximize the number of the masked
spectrogram bins of the genuine training examples. Its foundation is based on
the observation that, masking out the vast majority of the spectrogram bins
with little speaker information will inevitably introduce a large score
variation to the adversarial example, and a small score variation to the
genuine example. Experimental results with 12 attackers and two representative
ASV systems show that our proposed method outperforms five state-of-the-art
baselines. The extensive experimental results can also be a benchmark for the
detection-based ASV defenses.","AUTOMATIC speaker verification (ASV) is a task of verifying the identity of a speaker by his (or her) pre recorded utterance clips [1]. Deeplearningbased speaker ver ification techniques can be categorized into two representative frameworks: stagewise [2], [3], [4] and endtoend [5], [6], [7]. A fundamental difference between the two frameworks is their loss functions, which are called classificationbased loss and verificationbased loss, respectively [1]. Both of the two frameworks have achieved excellent performance and have penetrated our daily lives with realworld applications such Corresponding author: XiaoLei Zhang Xing Chen, Jie Wang, and XiaoLei Zhang are with the School of Marine Science and Technology, Northwestern Polytechnical University, Xi‚Äôan 710072, China, and with the Research & Development Insti tute of Northwestern Polytechnical University in Shenzhen, China (e mail: xing.chen@mail.nwpu.edu.cn, wangjie2017@mail.nwpu.edu.cn, xi aolei.zhang@nwpu.edu.cn). WeiQiang Zhang is with the Department of Electronic Engineering, Tsinghua University, Beijing 100084, China (email: wqzhang@tsinghua.edu.cn). Kunde Yang is with the Ocean Institute of Northwestern Polytechnical University, China (email: ykdzym@nwpu.edu.cn).as authentication, bank transaction and forensics. However, adversarial attacks [8] were found to be able to defeat an ASV system even at a high signaltonoise ratio (SNR) [9], which brought great challenges to the applications of the ASV systems. Adversarial attack is a technique that aims to induce an ASV system to make wrong decisions by adding human imperceptible perturbations into the clean speech during the inference phase of ASV . The perturbed speech, a.k.a adver sarial examples , has been extensively studied in the ASV research [10], [11]. It can be generally classified into white box attacks and blackbox attacks. In the case of whitebox attacks, i.e. the scenarios where the victim ASV model exposes all knowledge, including parameters, structure, and training data, to the attacker. Villalba et al. [9] found that the stateof theart (SOTA) xvector ASV models are extremely vulnerable even at a high SNR level of 30dB. Xie et al. [12] proposed to train a generator to efficiently craft adversarial examples. Since the whitebox attacks have many obstacles in the reality, the blackbox counterparts, which are knowledgeindependent, have been paid more attention. Chen et al. [13] deployed a graybox attack using only the output similarity scores of ASV . Further, ASV models were found to be vulnerable to transferbased blackbox attacks across training datasets [14] and model structures [15]. In addition, the works in [12], [16] explored robust adversarial examples in terms of the universality and imperceptibility, respectively. There are also some works focusing on applying adversarial attacks to realistic scenarios, such as the overtheair [17], [18] or streaming input [17], [19] situations, and defeating the tandem system of ASV and its auxiliary subsystems [18], [20]. Since adversarial attacks have posed the serious threat, it becomes foremost important to develop an effective coun termeasure to protect the ASV systems. The current coun termeasures fall into two categories: proactive defense and passive defense . Proactive defense mainly utilizes adversarial data augmentation techniques to retrain the ASV model, which is inconvenient to deploy [10]. For example, the works in [21], [22], [23] proposed to use adversarial examples generated by fast gradient sign method (FGSM), projected gradient descent (PGD) and feature scattering, respectively, to perform adver sarial training defenses [24]. Passive defense does not modify the ASV model, instead, it defends against adversarial attacks by a mitigation or detection component. For example, the works in [25], [26], [27] proposed to remove the adversarial noise with the adversarial separation network, ParallelWave GAN (PWG) module, and cascaded selfsupervised learning based reformer (SSLR), respectively. Wu et al. [28] alsoarXiv:2211.00825v2  [eess.AS]  14 Jun 2023IEEE/ACM TRANS. AUDIO, SPEECH, AND LANGUAGE PROCESSING, VOL. XX, NO. YY , JUNE 16, 2023 2 employed a voting strategy with random sampling to mitigate the adversarial attacks. This paper focuses on the detectionbased passive defense approaches. There have been many works in this direction. Liet al. [29] and Joshi et al. [30] discriminated adversar ial and genuine examples by training a VGGlike binary classification network and an embedding feature extractor, respectively. However, their performance drops dramatically in unseen attacks, since the training relies on the prior knowledge of adversarial examples. Wu et al. [27] picked out adversarial examples by the statistics of the similarity scores between enrollment utterance and synthesized utterances from multiple cascaded SSLRs. However, their experiments were conducted on the MFCClevel, which means it works in the timefrequency domain and relies on specific acoustic feature extractors. Peng et al. [31] proposed to train a binary classifier by the consistency of the scores of twin ASV models, i.e. a premier and a mirror one. Because training the classifier needs genuine examples only, the method gets rid of the dependence on specific attackers. However, it needs to find a SOTA fragile ASV and a rare robust ASV . Wu et al. [32] proposed to detect adversarial examples by score variation, which was obtained by a vocoder composed of the GriffinLim (GL) algorithm or PWG model. However, it lacks strong interpretability, since there is no significant correlation between the training loss of PWG and the score variation in the detector. Chen et al. [33] separated adversarial examples from genuine ones by a masking operation at the featurelevel. However, the masking operation is manually designed, and is dependent on the dimensionality of the input features. To address the aforementioned issues of attackerdependent, featuredimensionalitydependent and manual selection, in this paper, we propose to detect adversarial examples by a learn able mask detector (LMD). It takes score variation as an indicator, and calculates the score variation by a masking operation on complex spectrogram features. Specifically, it assumes that shorttime fourier transform (STFT) disperses manuallyadded adversarial perturbation uniformly from the time domain to the timefrequency domain. Naturally, due to the robustness of the ASV model to noise, masking insignif icant timefrequency bins of the complex spectrograms has a large impact on adversarial examples, and a small impact on genuine examples. Based on the above assumption and observation, we aim to learn an optimal mask matrix by a neural network, and then utilize the absolute discrepancy of ASV scores before and after the masking operation to detect the adversarial examples. It is worth noting that (i) LMD only requires the genuine examples for training, so it is attackerindependent; (ii) LMD transforms the masked complex spectrograms to speech signals in the time domain by the inverse shorttime fourier transform (iSTFT), thus it becomes feature dimensionalityindependent; (iii) LMD obtains the mask matrix by a neural network automatically, instead of designed manually; (iv) further, LMD calculates the score variation of the detection as part of the training loss of the neural network, which makes the detection and training closely related. We conducted experiments on two SOTA ASV models with diverse adversarial examples,and obtained an excellent detection performance. For example, detection equal error rates (EER) of no more than 5.9% and 10.1% are achieved on the ECAPA_TDNN ASV and the Fast ResNet34 ASV , respectively, in a noisy and blended detection scenarios. Our contributions are summarized as follows: ‚Ä¢We propose a maskbased and attackerindependent de tector, named LMD, which effectively mitigated the threat posed by adversarial examples to ASV systems. To demonstrate the advantage of learning a mask matrix through a neural network as LMD, we also propose a manually designed masking complex spectrogram (MCS) method as a baseline. ‚Ä¢We conducted experiments on two SOTA ASVs with abundant attackers. The two ASVs, which behave as either victims or defenders, are derived from two rep resentative frameworks, i.e. stagewise ASV and endto end ASV . The attackers cover three kinds of generation algorithms, and act as either an impostor or an evader to the ASVs in both whitebox and blackbox attacks. ‚Ä¢Inspired by [9], we evaluated the performance of a number of detectors under a given SNR budget. The experiments were also conducted in a scenario where the adversarial examples of a single attacker with different parameter settings were mixed, and the corresponding genuine examples were added with whitenoise at the same SNR. Experimental results show that our proposed method outperforms the SOTA baselines in terms of the detection EER at an SNR budget of 37dB and the above. The rest of the paper is organized as follows: Section II describes some preliminaries, including a brief introduction of ASV and three adversarial attack algorithms. Section III introduces our proposed methods. Section IV shows the exper imental settings and evaluation metrics, while the results are discussed in Section V. Finally, Section VI hands concluding remarks. II. P RELIMINARIES A. Automatic Speaker Verification ASV aims to confirm whether an utterance is pronounced by a specified speaker. Deeplearningbased ASV consist of a speaker embedding extractor (including feature engineering, encoder network, and temporal pooling module), a training objective function, and a similarity scoring backend [1]. An encoder network first extracts framelevel speaker em beddings from acoustic feature sequences, e.g. logarithmic filterbanks (LogFBank). Then, segmentlevel speaker features are obtained by the cascading of a pooling module and a feedforward network. Finally, either classificationbased or verificationbased objective functions are used to train the above framelevel and segmentlevel speaker embedding ex tractors jointly. To demonstrate the generalizability of the proposed method to different ASV systems, we adopt two representative train ing objective functions, i.e. additive angular margin softmax (AAMSoftmax) [4] and angular prototypical [7], for the victim ASV systems. In the test phase of ASV , we determineIEEE/ACM TRANS. AUDIO, SPEECH, AND LANGUAGE PROCESSING, VOL. XX, NO. YY , JUNE 16, 2023 3 whether a test utterance xtand an enrollment utterance xe belong to the same speaker by comparing the similarity of their speaker embeddings with a predefined threshold Œ∑. The test phase is formulated as: s=S f"
240,An SMT-Based Approach for Verifying Binarized Neural Networks.txt,"Deep learning has emerged as an effective approach for creating modern
software systems, with neural networks often surpassing hand-crafted systems.
Unfortunately, neural networks are known to suffer from various safety and
security issues. Formal verification is a promising avenue for tackling this
difficulty, by formally certifying that networks are correct. We propose an
SMT-based technique for verifying Binarized Neural Networks - a popular kind of
neural network, where some weights have been binarized in order to render the
neural network more memory and energy efficient, and quicker to evaluate. One
novelty of our technique is that it allows the verification of neural networks
that include both binarized and non-binarized components. Neural network
verification is computationally very difficult, and so we propose here various
optimizations, integrated into our SMT procedure as deduction steps, as well as
an approach for parallelizing verification queries. We implement our technique
as an extension to the Marabou framework, and use it to evaluate the approach
on popular binarized neural network architectures.","In recent years, deep neural networks (DNNs ) [21] have revolutionized the state of the art in a variety of tasks, such as image recognition [12,37], text classica tion [39], and many others. These DNNs, which are artifacts that are generated automatically from a set of training data, generalize very well | i.e., are very successful at handling inputs they had not encountered previously. The suc cess of DNNs is so signicant that they are increasingly being incorporated into highlycritical systems, such as autonomous vehicles and aircraft [7,30]. In order to tackle increasingly complex tasks, the size of modern DNNs has also been increasing, sometimes reaching many millions of neurons [46]. Con sequently, in some domains, DNN size has become a restricting factor: huge networks have a large memory footprint, and evaluating them consumes both time and energy. Thus, resourceecient networks are required in order to allow DNNs to be deployed on resourcelimited, embedded devices [23,42]. One promising approach for mitigating this problem is via DNN quantiza tion [4, 27]. Ordinarily, each edge in a DNN has an associated weight, typicallyarXiv:2011.02948v2  [cs.LG]  17 Jan 20212 G. Amir et al. stored as a 32bit  oating point number. In a quantized network, these weights are stored using fewer bits. Additionally, the activation functions used by the network are also quantized, so that their outputs consist of fewer bits. The net work's memory footprint thus becomes signicantly smaller, and its evaluation much quicker and cheaper. When the weights and activation function outputs are represented using just a single bit, the resulting network is called a binarized neural network (BNN ) [26]. BNNs are a highly popular variant of a quantized DNN [10, 40, 56, 57], as their computing time can be up to 58 times faster, and their memory footprint 32 times smaller, than that of traditional DNNs [45]. There are also network architectures in which some parts of the network are quantized, and others are not [45]. While quantization leads to some loss of network precision, quantized networks are suciently precise in many cases [45]. In recent years, various security and safety issues have been observed in DNNs [33,48]. This has led to the development of a large variety of verication tools and approaches (e.g., [16, 25, 33, 52], and many others). However, most of these approaches have not focused on binarized neural networks, although they are just as vulnerable to safety and security concerns as other DNNs. Recent work has shown that verifying quantized neural networks is PSPACE hard [24], and that it requires dierent methods than the ones used for verifying nonquantized DNNs [18]. The few existing approaches that do handle binarized networks focus on the strictly binarized case, i.e., on networks where allcomponents are binary, and verify them using a SAT solver encoding [29,43]. Neural networks that are only partially binarized [45] cannot be readily encoded as SAT formulas, and thus verifying these networks remains an open problem. Here, we propose an SMTbased [5] approach and tool for the formal ver ication of binarized neural networks. We build on top of the Reluplex algo rithm [33],3and extend it so that it can support the sign function, sign(x) =( x<0"
519,Sparse Neural Networks Topologies.txt,"We propose Sparse Neural Network architectures that are based on random or
structured bipartite graph topologies. Sparse architectures provide compression
of the models learned and speed-ups of computations, they can also surpass
their unstructured or fully connected counterparts. As we show, even more
compact topologies of the so-called SNN (Sparse Neural Network) can be achieved
with the use of structured graphs of connections between consecutive layers of
neurons. In this paper, we investigate how the accuracy and training speed of
the models depend on the topology and sparsity of the neural network. Previous
approaches using sparcity are all based on fully connected neural network
models and create sparcity during training phase, instead we explicitly define
a sparse architectures of connections before the training. Building compact
neural network models is coherent with empirical observations showing that
there is much redundancy in learned neural network models. We show
experimentally that the accuracy of the models learned with neural networks
depends on expander-like properties of the underlying topologies such as the
spectral gap and algebraic connectivity rather than the density of the graphs
of connections.","The last decade has seen a rapid development of neural network methods that are widely considered to be the best tools for solving hard machine learning problems such as speech [1],[2], [3], image [4], [5], [6] and video [7],[8] recognition. Neural networks are believed to learn complex models by iterating two operations: linear projections of highdimensional data and pointwise nonlinear mappings. However, the process of building a good quality neural network models is time consuming and the models‚Äô space complexity is usually very high. In this paper, we investigate how the quality of the neural network model depends on the topology of connections between consecutive layers. We propose Sparse Neural Network (SNN) architectures that can match or exceed the accuracy of their dense counterparts. First, we study random sparse architectures that are quite compressible, then we study sim ilar structured versions that provide even more compact description of the entire ar chitecture. Sparse structured graphs are highlycompressible, yet they can share some properties with their sparse random counterparts. We show good quality SNN model, with a well chosen topology, can equal or supersede its fully connected equivalent in accuracy, with a much smaller learned parameter space. We also show that our results our robust as they hold over multiple layer neural network, or with the use of some overÔ¨Åtting prevention techniques such as Dropout [9]. There is also additional in sight into Neural Network inner workings and limitations by implementing SNN‚Äôs and viewing them through the lens of graphs. We investigate how Algebraic Connectivity impacts a Neural Network‚Äôs power, and show that there is a strong correlation between how interconnected a Neural Network is, and its resulting testing accuracy. 2 Related work "
215,Temporal Reasoning Through Automatic Translation of tock-CSP into Timed Automata.txt,"In this work, we consider translating tock-CSP into Timed Automata for UPPAAL
to facilitate using UPPAAL in reasoning about temporal specifications of
tock-CSP models. The process algebra tock-CSP provides textual notations for
modelling discrete-time behaviours, with the support of tools for automatic
verification. Similarly, automatic verification of Timed Automata (TA) with a
graphical notation is supported by the UPPAAL real-time verification toolbox
\uppaal. The two modelling approaches, TA and tock-CSP, differ in both
modelling and verification approaches, temporal logic and refinement,
respectively, as well as their provided facilities for automatic verification.
For instance, liveness requirements are difficult to specify with the
constructs of tock-CSP, but they are easy to specify and verify in UPPAAL. To
take advantage of temporal logic, we translate tock-CSP into TA for \uppaal; we
have developed a translation technique and its supporting tool. We provide
rules for translating tock-CSP into a network of small TAs for capturing the
compositional structure of tock-CSP that is not available in TA. For
validation, we start with an experimental approach based on finite
approximations to trace sets. Then, we explore mathematical proof to establish
the correctness of the rules for covering infinite traces.","Communicating Sequential Processes (CSP) is an established process algebra that provides a formal notation for both modelling and verifying concurrent systems [19,32,34]. The use of CSP for verication has been supported by several tools including powerful modelcheckers [15,32,35]. Interest in using CSP motivated [32] the introduction of support for modelling discrete timed systems; tockCSP provides an additional event tock to record the progress of time. The notation of tockCSP is encoded in that of CSP, thus, verication is supported by the existing tools. As a result, tockCSP has been ?The authors gratefully acknowledge the nancial support of Petroleum Technology Development Fund (PTDF)arXiv:2104.13434v1  [cs.FL]  27 Apr 20212 A. Abba, et al used to verify realtime systems, such as security protocols [13] and railway systems [21]. Recently, tockCSP has been used to capture the semantics of RoboChart, a domainspecic language for modelling robotics applications [27]. In this work, we present a technique for automatic translation of tockCSP into TA to enable using Uppaal [5] and temporal logic to verify tockCSP models. Uppaal is a toolsuite for modelling hybrid systems using a network of TAs and verifying the systems. We describe list of translation rules and their implementation into a tool. Both temporal logic and renement are powerful approaches for model check ing [25]. The renement approach models both the system and its specications with the same notation [32, 34], while temporal logic enables asking whether a system captures logical formul of the requirements specication in the form of systemj=formula [9]. Lowe has investigated the relationship between the renement approach (in CSP) and the temporal logic approach [25]. The result shows that, in expressing temporal logic checks using renement, it is necessary to use the innite refusal testing model of CSP. The work highlights that capturing the expressive power of temporal logic to specify the availability of an event (liveness specication) is not possible in the renement model. Due to the diculty of capturing refusal testing, automatic support becomes problematic. A previous version of FDR supports refusal testing, but not its recent more ecient version [15]. Additionally, Lowe's work [25] proves that simple renement checks cannot match the expressive power of temporal logic, especially the three operators: eventually (p:pwill hold in a subsequent state ),until (pUq:pholds in every state until qholds ) and their negations : (:(p) and:(pUq). These three op erators express behaviour captured by innite traces. Our work presented here facilitates checking such specications. Example 1. Consider an Automatic Door System (ADS) that opens a door, and after at least onetime unit, closes the door in synchronisation with a lighting controller, which turns o the light. In tockCSP , this is expressed as: 1 ADS = Controller [|{close}|] Lighting 2Controller = open > tock > close > Controller 3Lighting = close > offLight > Lighting ADS has two components | Controller andLighting | that synchronise on the event close , which enables Lighting to turn o the light after closing the door. In tockCSP , there is no direct way of checking if the system eventu ally turns o the light. However, temporal logic provides a direct construct for specifying liveness requirements, supported in Uppaal , as follows. {A<> offLight  The system eventually turns o the light Uppaal uses a subset of Timed Computational Tree Logic (TCTL) based on the notions of path and state [5]. A path formula quanties over paths (traces), whereas a state formula describes locations. There are dierent forms of pathTitle Suppressed Due to Excessive Length 3 formul. Liveness is either A<>q (q is eventually satised) orp > q (a state satisfying p leads to a state satisfying q) . A reachability formula in form of E<>q (a state satisfying qis reachable from the initial state) . Safety is expressed as either A[]q (q holds in all reachable states) orE[]q (q holds in all states on at least one path) . To verify the correctness of the translation technique, rst, we construct a systematic list of interesting tockCSP processes, which pair all the constructs of tockCSP within the scope of this work. Second, we use the developed translation technique and its tool to translate the formulated processes into TA for Uppaal . Third, we use another tool we have developed to generate and compare nite traces of the input tockCSP models and the traces of the translated TA models. We use Haskell [20], a functional programming language, to express, imple ment and evaluate the translation technique. The expressive power of Haskell helps us provide formal descriptions of the translation technique as a list of translation rules, which is also suitable for constructing mathematical proof. The structure of this paper is as follows. Section 2 provides the essential background material. In Section 3, we summarise the translation technique. We discuss an evaluation of the translation technique in Section 4. In Section 5, we highlight related works and present a brief comparison with this work. Finally, in Section 6, we highlight future extensions of this work and conclude. Additional details of the missing proofs, implementation and further examples can be found in the extended versions [1,2]. 2 Background As an extension of CSP, tockCSP provides notations for modelling processes and their interactions, such as the basic processes: SKIP andSTOP , for success ful termination and deadlock, respectively. Operators include prefix (>) for describing availability of an event. For example, the process move>SKIP represents a mechanism that moves once and then terminates. There are binary operators such as sequential composition (;), which com bines two processes serially. For instance, the process P3 = P1;P2 behaves as process P1, and after successful termination of P1, then P3behaves as P2. There are other binary operators for concurrency, choice and interruption. Also, CSP has a special event tau() for invisible actions that are internal to a system. The collection of these operators provides a rich set of constructs for modelling untimed systems [32,34]. For modelling time, tockCSP has an event tock [32], which species at least single unit of time. For example, the following process Ptspecies behaviour that moves and then after at least two time units, turns and terminates. Pt = move>tock>tock>turn>SKIP Timed Automata for Uppaal model hybrid systems as a network of TA. Mathematically, a TA is a tuple ( L;l0;C;A;E;I ), whereLis a set of locations such thatl0is the initial location, Cis a set of clocks, Ais a set of actions, Eis4 A. Abba, et al a set of edges that connects the locations L, andIis an invariant associated to a locationl2Lin the form of I:L"
526,Why Quantization Improves Generalization: NTK of Binary Weight Neural Networks.txt,"Quantized neural networks have drawn a lot of attention as they reduce the
space and computational complexity during the inference. Moreover, there has
been folklore that quantization acts as an implicit regularizer and thus can
improve the generalizability of neural networks, yet no existing work
formalizes this interesting folklore. In this paper, we take the binary weights
in a neural network as random variables under stochastic rounding, and study
the distribution propagation over different layers in the neural network. We
propose a quasi neural network to approximate the distribution propagation,
which is a neural network with continuous parameters and smooth activation
function. We derive the neural tangent kernel (NTK) for this quasi neural
network, and show that the eigenvalue of NTK decays at approximately
exponential rate, which is comparable to that of Gaussian kernel with
randomized scale. This in turn indicates that the Reproducing Kernel Hilbert
Space (RKHS) of a binary weight neural network covers a strict subset of
functions compared with the one with real value weights. We use experiments to
verify that the quasi neural network we proposed can well approximate binary
weight neural network. Furthermore, binary weight neural network gives a lower
generalization gap compared with real value weight neural network, which is
similar to the difference between Gaussian kernel and Laplace kernel.","It has been found that by quantizing the parameters in a neural network, the memory footprint and computing cost can be greatly decreased with little to no loss in accuracy [Gupta et al., 2015]. Furthermore, Hubara et al. [2016], Courbariaux et al. [2015] argued that quantization serves as an implicit regularizer and thus should increase the general izability of neural network comparing to its full precision version. However, there is no formal theoretical investigation of this statement to the best of our knowledge. Empirical results show that the traditional statistical learning techniques based on uni form convergence (e.g., VCdimension [Blumer et al., 1989]) do not satisfactorily explain the generalization ability of neural networks. Zhang et al. [2016] showed that neural net works can perfectly t the training data even if the labels are random, yet it generalized well when the data are not random. This seems to suggest that the model capacity of a 1arXiv:2206.05916v1  [cs.LG]  13 Jun 2022neural network depends on not only the model, but also the dataset. Recent studies [He and Tao, 2020] managed to understand the empirical performance in a number of dierent aspects, including modeling stochastic gradient (SGD) with stochastic dierential equation (SDE) [Weinan et al., 2019], studying the geometric structure of loss surface [He et al., 2020], and overparameterization { a particular asymptotic behavior when the number of parameters of the neural network tends to innity [Li et al., 2018, Choromanska et al., 2015, AllenZhu et al., 2018, Arora et al., 2019a]. Recently, it was proven that the training process of neural network in the overparameterized regime corresponds to kernel regression with Neural Tangent Kernel (NTK) [Jacot et al., 2018]. A line of work [Bach, 2017, Bi etti and Mairal, 2019, Geifman et al., 2020, Chen and Xu, 2020] further studied Mercer's decomposition of NTK and proved that it is similar to a Laplacian kernel in terms of the eigenvalues. In this paper, we propose modeling a twolayer binary weight neural network using a model with continuous parameters. Specically, we assume the binary weights are drawn from the Bernoulli distribution where the parameters of the distribution (or the mean of the weights) are trainable parameters. We propose a quasi neural network , which has the same structure as a vanilla neural network but has a dierent activation function, and prove one can analytically approximate the expectation of output of this binary weight neural network with this quasi neural network. Using this model, our main contributions are as follows: ‚Ä¢Under the overparameterized regime, we prove that the gradient computed from BinaryConnect algorithm is approximately an unbiased estimator of the gradient of the quasi neural network, hence such a quasi neural network can model the training dynamic of binary weight neural network. ‚Ä¢We study the NTK of twolayer binary weight neural networks by studying the \quasi neural network"", and show that the eigenvalue of this kernel decays at an exponential rate, in contrast with the polynomial rate in a ReLU neural network Chen and Xu [2020], Geifman et al. [2020]. We reveal the similarity between the Reproducing kernel Hilbert space (RKHS) of this kernel with Gaussian kernel, and it is a strict subset of function as the RKHS of NTK in a ReLU neural network. This indicates that the model capacity of binary weight neural network is smaller than that with real weights, and explains higher training error and lower generalization gap observed empirically. 2 Related work "
275,Adversarial-Aware Deep Learning System based on a Secondary Classical Machine Learning Verification Approach.txt,"Deep learning models have been used in creating various effective image
classification applications. However, they are vulnerable to adversarial
attacks that seek to misguide the models into predicting incorrect classes. Our
study of major adversarial attack models shows that they all specifically
target and exploit the neural networking structures in their designs. This
understanding makes us develop a hypothesis that most classical machine
learning models, such as Random Forest (RF), are immune to adversarial attack
models because they do not rely on neural network design at all. Our
experimental study of classical machine learning models against popular
adversarial attacks supports this hypothesis. Based on this hypothesis, we
propose a new adversarial-aware deep learning system by using a classical
machine learning model as the secondary verification system to complement the
primary deep learning model in image classification. Although the secondary
classical machine learning model has less accurate output, it is only used for
verification purposes, which does not impact the output accuracy of the primary
deep learning model, and at the same time, can effectively detect an
adversarial attack when a clear mismatch occurs. Our experiments based on
CIFAR-100 dataset show that our proposed approach outperforms current
state-of-the-art adversarial defense systems.","As machine learning (ML) technology, especially deep learning technique, in computer  vision  continues  to advance,  the challenges  of adversarial  attacks  are becoming  increasingly  prevalent. Adversarial attacks refer to image manipulation to deceive computer vision  tasks where the image seems correct at human perception [ 1]. Some of these attacks can  lead  to harmful  failures  in sensitive  computer  vision based  applications,  such  as targeting  autonomous  vehicles  to mislead  the AI system  in those vehicles  to recognize  the road  STOP  sign as SPEED  LIMIT  65. The  increased  demand for AI applications may  increase  the risks  of this technology if it is not secured well before it is put on the market.  Therefore, in  recent years researchers have continued to develop algorithms and systems to prevent  adversarial attacks.  In this paper, we develop a novel adversarial aware deep learning  system by employing a classical ML algorithm as the auxiliary verification approach.   Deep Neural  Network (DNN)  theory,  also called  deep learning,  accelerates  the devel  opment of computer vision applications to advance [ 2‚Äì5]. Unlike other AI approaches, it  can quickly  learn  complex patterns and representations from  large  and high dimensional  datasets.  Therefore, according to Stone [ 6] study, DNN technology will be used in an  expanding range of real world applications within the next decade.  Examples of these  appli cations  include  autonomous  vehicles, security  surveillance  cameras,  and healthcare.  However, this technology faces serious security challenges because of two factors.  One  is the high dimension and complexity of the input data to DNN models, which means it  is hard to catch all potential attacks as adversarial attackers can insert small but enough        2 of 17     perturbations  to mislead  the system. Second  is the non linearity  in the decision boundaries  of DNNs, resulting in unexpected and complex behavi ors that are hard to predict.   1.1. Inspiration   In this paper, our proposed new idea in defending against adversarial attacks is  inspired  by analyzing  communication war in the real world,  as described below. Suppose  in a war scenario or simulation;  the Blue team uses satellite communication to operate   its military.  If the other side, the Red team, somehow is capable of modifying the Blue  team‚Äôs  satellite  communication  without  being  detected,  then  the Blue team  will be misled  and could  lose the war eventually.  In defending  against  such  an attack  in disruption  of its communication, the Blue team could add a radiotelegraphy secondary system to  complement its main satellite communication because the radiotel egraphy, relying on a  completely different mechanism, cannot be disrupted by the Red team satellite attack  methodology. Although radiotelegraphy using Morse code has very limited bandwidth,  it can transmit summary data that matches the complete data transm itted via satellite  communication. In this system, if the receiver finds out that the information between the  radiotelegraphy  and the satellite  communication do not match,  it can tell that a Red team  satellite based attack is ongoing and thus will not be fooled by the misinformation.   Our proposed defense system against adversarial attacks uses the same philosophy  as the war scenario described above. The deep learning image classification system is  an  analogy  to satellite  communication,  which could  be compromised  by various  adversarial  attacks. However,  we propose  to use a traditional  ML algorithm,  such  as RF, in analogy  to  radiotelegraphy, as the secondary verification system. Although it is less a ccurate than a  normal  deep  learning  image  classification  system, it is immune  to most  known adversarial  attacks because it does not rely on neural network structure.  In this way, we can detect  adversarial attacks easily when there is a mismatch between the outputs of the primary  deep learning module and the secondary RF module.   1.2. Research  Contributions  and Paper Outline   Based  on a large scale  experiment  and investigation,  we find a ground  similarity  be  tween  various  adversarial  attacks  on different  deep  learning  models,  which motivated  us to  develop  this research  work,  as illustrated  in Section  2.1. Our main  contribution to this paper  is integrating the primary deep learning model with an auxiliary traditional ML model that is not based  on neural  network  architecture (presented  in Section 2). Additionally,  a new defense metric for selecting the highest Top_k predicted class probabilities of an input sample is introduced in Section 2.3 . The m isclassification issue of DNN models is  also addressed in the same  section,  and an overall  DNN  model  with  improved  accuracy  is  discussed.   Next, our method surpasses all other state ofart defense methods in detecting multiple  adversarial  attacks  using  the CIFAR 100 dataset [7], which  is shown in Section  3. A thorough  discussion of our research is presented in Section 4, which covers both the solutions, the  challenges,  and the limitations  encountered.  Finally,  a comprehensive  conclusion is reached  in Section  5, and potential  future  research  avenues  are identified to improve  the reliability  of adversarial detection models further.   1.3. Related  Work   In this section,  we briefly  review  state oftheart existing  works  on adversarial  attacks  and defenses.  Also, we study  the competitive  detector  methods  that we compare  our work  with. These models are DkNN [ 8], LID [ 9], Mahalanibis [ 10], and NNIF [ 11].  1.3.1.  Adversarial  Attacks   In the past few years, many adversarial attacks have been proposed, and one and  most common attack proposed by [ 12] is called The Fast Gradient Sign Meth od (FGSM).  This  attack  adds  a small  perturbation  to the target  image  in the direction  of the gradient  of 3 of 17     the loss function with  respect  to the human perception  content  in order  to misclassify  the  trained targeted model. It is a white box attack where the attacker fully knows the deep  learning model, including its architecture, parameters, and training data.  Later, a more  efficient  attack  known as Deepfool  [13] finds  the smallest  perturbation  necessary  to cause  a  DNN to misclassify an input image, which increases the attack success rate compared to  FGSM.   The potential of deceiving the DNN models increased significantly with th e past  few years of adversarial attack development. Today, imperceptible perturbations can be  added  to input  images  with  the flexibility  of adjusting  the attack  goal  to either a white box  or a black box such as the one proposed in [ 14] and known after the founders‚Äô names  Carlini & Wagner (CW) attack.  This attack uses an optimization algorithm in order to  find the smallest perturbation that minimizes a loss function that balances the size of th e  perturbation  with  the misclassification  success  rate. Moreover,  the attack  has the ability  to  incorporate  constraints  on the perturbation,  like limiting  the magnitude  of the perturbation  or restricting pixel values of the perturbed image.  The power of this attack raises the  challenge of defense solutions against multiple attacks at once.   The white box approach  becomes  more  desirable for adversaries  as it was introduced  by [15] and is known as the complete white box adversary.  The researchers found that  the projected gradient descent (PGD) can lift any constraints on the amount of time and effort the attacker can put into findi ng the best attack.  The iterative feature of the PGD  attack  makes  it more  effective  than  other  attacks,  such as FGSM,  in finding  imperceptible  adversarial examples.  The variety and effectiveness of adversarial attacks open a wide  range of areas for researchers to develop different attacks, such as in [ 16,17], and finding  defense mechanisms on the other side.   1.3.2.  Adversarial  Defenses   Authors of [ 18] categorize the adversarial defense mechanisms in computer vision  into three approaches.  The first approach targets the deep learning model by making  modifications to the model itself in order to make it more resistant t o adversarial attacks.  The approach  was initially  employed  by researchers  Szegedy  and Goodfellow  [1,19] in 2013  and 2014,  respectively.  Years  later,  Madry  [15] delved deeper into this approach  by studying  the robustness  of neural  networks  against adversarial  attacks  from  a theoretical  standpoint,  using  robust  optimization  techniques. Despite  its limitations,  as discussed  in the article  by  in [15], adversarial  training  has garnered considerable  attention  from  the research  commu   nity.  In the paper  [20], a new  defense  algorithm  called  Misclassification Aware  adveRsarial  Training (MART) is proposed.  It distinguishes between misclassified and correctly clas   sified examples during the training process.  In another study [ 21], researchers su ggest  using  dropout  scheduling  to enhance  the efficiency  of adversarial  training  when  employing  single step methods. Researchers in [ 22] proposed a self supervised adversarial training  method, while [ 23] analyzed adversarial training for self supervision by incorporating it  into pretraining .  The second approach is a defense that targets the inputs to the model by cleaning  inputs  to make  them  benign  for the target  model. [ 24] proposed  ComDefend  that consists  of a compression convolutional neural network (ComCNN) and a reconstruction convo   lutional  neural  network  (RecCNN).  The ComCNN  model  compresses  the input  image  to maintain the original image structure information and purify any added perturbation.  The RecCNN model, on the ot her hand, reconstructs the output of ComCNN to a high  quality. This approach achieved high accuracy in defending multiple adversarial attacks.  GANs architecture  is another  technique  of input  transformation  introduced  by [25]. Their  method,  Defense GAN,  learns  the distribution  of clean  images.  In other  words,  it generates  an output image close to the input image without containing the potential adversarial  pertu rbation.   The third  approach  is a defense of adding  external  modules  (mainly  detectors)  to the  target  model.  Among  adversarial  defense/detection  techniques,  [8] inserted a K Nearest  4 of 17     Neighbours  model  (kNN)  at every  layer  of the pretrained DNN  model  to estimate  better  prediction, confidence, and credibility for a given test sample.  Afterward, a calibration  dataset was used to compute the nonconformity of every test sample for a specific label j.  This  involved  counting  the number  of nearest  neighbors  along  the DNN  layer  that differed  from  the chosen label  j. The researchers  discovered  that in cases  where  an adversarial  attack  was launched  on a test sample,  the true label exhibited  less similarity  with  the kNN labels  derived from the DNN activations across the layers.   The research in [ 9] charact erized the properties of regions named adversarial subspaces  by focusing on the dimensional properties vie using the Local Intrinsic Dimensionality  (LID).  The LID method  evaluates  the space filling  capability  of the area around  a reference  by analyzing the distance between the sample and its neighboring points.  A classifier  trained using a dataset comprising three types of examples:  adversarial as a positive  class, normal  and noisy  (non adversarial)  as a negative  class. The  feature s of each  sample  associated  with  each category  were then constructed  using  the LID score  calculated  at every  DNN  layer.  Finally,  a Logistic  Regression  (LR)  model  was fitted  on the LID features  for the  adversarial detection task.   Researchers in [ 10] developed generative classifiers that could detect adversarial  examples  by utilizing  DNN  activations  from  every  layer  of the training  set. They  used  a confidence score that relied on Mahalanobis distance.  First, they found the mean and  covariance of activations for each class and layer. Then, they measured the Mahalanobis  distance  between  a test sample  and its nearest  class conditional  Gaussi an using  Gaussian  distributions.  These distances served as features to train a logistic regression classifier.  The authors found that compared to using the Euclidean distance employed in [ 9], the  Mahalanobis distance was significantly more effective in detecting adversarial examples  and resulted in improved detection results.   In a study by Cohen et al.  [11], they utilized an influence function to create an  external adversarial detector.  This function calculates how much each training sample  affects the validation data, resulting in sample influence scores. Using these scores, they  identified the most suppor tive training instances for the validation samples. To compute  a ranking of the supportive training samples, a k NN model is also fitted on the model  activations.  According to their claims,  supportive samples are highly correlated with   the nearest neighbor s of clean test samples, whereas weak correlations were found for  adversarial inputs.   2. Materials  and Methods   This section introduces our proposed detection method in depth.  It starts with the  motivation, which lights up our research ideas.  Then we introduce our model in detail.  After  that,  we present  the adaptive  design  for our defense  method  based  on an application  specific security goals.   2.1. Motivation  and Threat  Model   Motivat ion: After multiple  assessments of the different  adversarial  attacks  on different  DNN models, we notice that once the attack succeeds on one deep learning model, it succeeds  on other  models  as well,  as shown  in Table  1 that is obtained  by running  multiple  adversarial attacks  FGSM, Deepfool, CW, and PGD on ResNet 34 [26] as a target model  using  CIFAR 100 dataset.  The generated  adversarial  samples  are then  tested  on VGG16   [27] and DenseNet [ 28] DNN models classifications.  We find out that the accuracy of   the targeted model is almost similar to un targeted DNN models.  Researchers in [29]  addressed the same  issue, naming  it ‚Äútransferability""  of adversarial  examples,  meaning  that  the generated samples from adversarial attacks on one targeted DNN model may work  on differ ent un targeted DNN models.  Therefore, a model from a different approach is  interesting to be studied, and we selected Random Forest (RF) [ 30] decision tree based  classifier  model  for our stud y, considering  all the challenges  of using  this limited  model  for  image classification.  5 of 17     Table 1.  Accuracy comparison of different DNN models before and after adversarial attacks on  CIFAR 100 dataset.      Attacks  Targeted  model  Untargeted  models   ResNet 34 VGG16  DenseNet    Accuracies  (%) without  attack  77.47  72.25  78.69   FGSM  34.25  35.09  36.19   Deepfool  25.78  24.79  24.84   CW 25.77  24.49  25.0  PGD  22.58  22.87  22.7      Figure 1.  Classification accuracy over Top_k before and after different adversarial attacks using  CIFAR 100 dataset,  by two classical  ML models:  (a) Random  Forest  model,  and (b) kNN  model.  The  accuracy  under  different adversarial  attacks  are almost identical,  thus  those  resulting  curves  override  each other and make a single purple color curve.   Threat  model: Our threat  model  assumes  that the attacker  knows  there is a detection  method employed but does not know what is the detection method. In this set ting, only  the DNN model and its parameters are known to the adversary.   2.2. Proposed  Methodology   We introduce our proposed adversarial attack detection method in this section. Our  primary image classification system, shown in Figure 2 , is based on the DNN approach,  and we choose ResNet with 34 layers here for our investigation.  The primary model  could be any other DNN model that uses backpropagation because adversarial attacks  exploit backpropagation to optimize the perturbations introduced to the input data on  DNN models.  The input is an image that could be a real image with no alteration or an  adversarial generated sample from one of four attacks:  FGSM, Deepfool, CW, or PGD.  Our output  of ResNet 34 is the highest  probability  index  that indicates  the class  the image  belongs to, which is referred to as Top_1 classification.   Unlike  the primary approach, we use the classical ML model, Random Forest (RF)  model, as a secondary model for adversarial attack detection. The RF model is a decision tree module based used in regression and multi classification problems [ 31‚Äì35]. It is an  extension of the bagging method  as it utilizes  both  bagging  and random  feature  selection  to create  an uncorrelated forest  of decision  trees. Also,  it reduces  overfitting  and increases  the diversity of the trees in the forest. The randomness in selecting the features for each  tree determines and eliminates the inserted perturbations information on the adversarial  samples as illus trated in Figure 1 where the accuracies of RF model before and after different  attacks  are almost  identical. In  the same  figure,  kNN model  is demonstrated as a classical  ML model that is not a ffected by the added perturbations as well.   Our outputs  of RF are the top k indices  (Top_k)  of the predicted class  probabilities  for  the inputs. We selected Top_k  and relied on it for our study  to match  the accuracy  of the RF  6 of 17   image  input   predicted   label   No Does  the DNN  predicted   label exist  in Top_k  labels?  Yes  image  input  Top_k  labels  Secondary  classical  ML model   (Random Forest)  clean image  adversarial   image    Main DNN  classification  model    with  the selected DNN  model on the CIFAR 100 dataset that has 100 classes. Top_1  in the  RF represents the worst  accuracy  as illustrated  in Figure  1 whereas Top_100  represents 100  percent accuracy  because  its decision is always  correct where the decision  group  includes  all possible  classes. When the parameter k in Top_k  equals  22, the accuracy  reaches  around  77 percent, the same percentage as the primary DNN method prediction accuracy at the  top_1  classification. Moreover,  by adjusting  the value  of k on the Top_k  classification,  our  methodology provides more control to its users and choices of selecting optimal security  versus classification  accuracy  based  on the AI application  design, as it will be described in  depth in section 2.3.        Figure 2.  Proposed adversarial detection system design, which is composed of a primary DNN  classification  decision  model  and a secondary  classical  ML model  for adversarial  attack  detection  and  verifica tion.   2.2.1.  Category  of Image  Dataset   Under Adversarial  Machine  Learning  (AML),  we run each adversarial  attack  individu  ally on the DNN  model, ResNet 34, using  the test set in CIFAR 100 dataset,  which  contains  10K images. The  attack  success  ratio  of each one of the adversarial  attacks  varies,  as illus  trated in Table 1.  During the categorization process as it is represented in Algorithm 1,  each image  x is first checked  by DNN  model for the correct label. The  mispredicted result  from DNN(x) adds x to SETmis set directly. In contrast, the correct predicted of x passes  to AML(x) algorithm for a trial (e.g., FGSM), and the successfully applied attack output   is added to SETadv set. The unsuccessful attack moved x to SETcrc set. In summary, we  categorize the outputs into three sets as follows:   ‚Ä¢ SETcrc:  The set of images  that DNN  can correctly  identify by DNN.  ‚Ä¢ SETmis: The set of images  that DNN  misidentifies  (misclassification).   ‚Ä¢ SETadv: The set of images produced by AML can successfully  and deliberately make  DNN misidentify as another object the attacker wants.   The percentage of misclassified images (SETmis) is maintained at 22.54 across various  attacks.  However, the percentages for the other  categories vary  depending on the strength  of each attack and it s parameters. Generally, the adversarial generated samples SETadv  or the attack success ratio received the highest percentage among other sets in all four adversarial attacks.   2.2.2.  Detection  Algorithm   The adversarial image detection model, denoted as Adv ‚àí awar e(x), is addressed in  Algorithm 2. We first pass a test image x to the primary DNN model, which is DNN(x)  with Top_1, and to the secondary model,  which is RF model with Top_k donated  by RF(x,  k). Then,  we will have  two outputs: a single class  prediction from  the primary  DNN  model,  7 of 17         Algorithm  1 Categorize  Image  Dataset.   [SETcrc, SETmis, SETadv] = Category (Image dataset, DNN classification results)  Input: {x, right label} ‚àà CIFAR 100(test set ), DNN  model  DNN(x), adv_attack  AML(x)  Output: The three categories of image  dataset according  to DNN  model classification  and  AML results.   Initialize  SETcrc,  SETmis,  SETadv to be all empty   for image  x ‚àà CIFAR 100 do  if DNN (x) is mispredict then  SETmis  ‚Üê x  else  if DNN (x) is correct  and AML(x) fail then  SETcrc ‚Üê x  else  SETadv ‚Üê x  end if  end if   end for  return [SETcrc,  SETmis,  SETadv]     y, and k classes  prediction from  the secondary model Top_k as a list of k classes. We  check  whether y predicted class exists in the Top_k prediction list.  If y exists in Top_k, then it  returns a boolean ""false"" value for forged status with the DNN(x) label, y . Otherwise, it  returns ""true"" without a label or None, which detects a possible adversarial sample.  For instance,  from  Figure  2, we use a STOP  road  sign as an input  sample  to our model.  It passes to the primary model and the secondary model concurrently. In an adversarial  attack scenario where the STOP sign image is a manipulated image, the predicted class  from  the primary  model  is SPEED LIMIT  70, whereas  the second  model  provides  Top_3  list  of predictions, for example, STOP , Roundabout , and No entry . Our model will detect the  input  image  as a forged ""true""  since  the predicted class  from  the primary  does not exist  in  the list of the secondary model. In the case of clean detection, the predictions have to be  found in both model predictions.  During our evaluation, we excluded misclassification  samples in this section, and will be tackled in section 2.3.  2.3. Defense System  Adaptive  Design   This section discusses a new technique for selecting the best value of k i n the Top_k  used in the secondary  model  based  on the underlying  applications‚Äô  specific  requirements  in  terms of accuracy  and security. Some  applications require zero tolerance  for attack  success.  On the other hand, a low success ratio of adversarial attacks in some other applications will not cause severe damage. Moreover, including the misclassification samples in this  adaptive  design  improves  the overall  detection  accuracy  of adversarial attacks.  The details  are explained in the following subsections.   2.3.1.  Outputs  of Our Proposed  Adversarial Aware  Image  Recognition System   Our image  recognition system  has two possible  outputs: (1). the  image  under inspec   tion is authentic, and its identified label is provided, or (2). the image under inspection is  forged by AML  and tagged  as forged . Therefore,  given  that there  are three  possible  sets of  images  in terms  of DNN  identification  (introduced  in Section 2.2.1), here are the six possible  decision scenarios by our proposed system:   ‚Ä¢ Decision A ( Dec a): An image  in SETcrc that is authentic  and correctly identified.   ‚Ä¢ Decision B ( Dec b): An image  in SETmis  that is correctly  identified  as forged.  8 of 17         Algorithm  2 Adversarial Aware  Deep  Learning  System.   [forged, label]  = Adv aware  (x)  Input: image x.   Output: Whether the image is forged by adversarial attack or clean image; classification  label if x is a clean image.   y ‚Üê DNN (x) #DNN  model classi f ication  label f or the image  x  Top_k  ‚Üê RF(x, k)  #The top k group  o f labels  generated by the RF classi f ication  model   if y ‚àà Top_k  then  forged = false; label = y  else  forged = true; label  = None   end if  return [forged, label]     ‚Ä¢ Decision C ( Dec c): An image  in SETadv that is correctly identified as forged.   ‚Ä¢ Decision D ( Dec d): An image  in SETcrc that is misidentified  as forged.   ‚Ä¢ Decision E ( Dec e): An  image  in SETmis  that is misidentified  as authentic  and misclas   sified.  ‚Ä¢ Decision F ( Dec f ): An image  in SETadv that is misidentified  as authentic.   From a user‚Äôs perspective, Dec a, Dec b, and Dec c are all ‚Äògood‚Äô and rightful decisions;  Dec d, Dec e, and Dec f are wrongful decisions that could cause negative impact/cost to the  user.   2.3.2.  Adjustable Parameter  in Our Proposed  System   In our proposed adversarial aware image recognition system, one critical parameter  that can be adjusted/controlled by the end user is the value  of k in the Top_k  classification  by the secondary model.  It can be used to make a delicate trade off between increasing  the defense accuracy of adversarial attack images and increasing the correct recognition  of normal images. The secondary verification ML module determines if an image under  inspection belongs to one of the Top_k classes among all possible classification classes.   Its classification setting Top_k can be, for example, Top_1, Top_10, Top_20, etc.  When k  increases, the classification decision by the DNN module will have a higher probability   of being included in the Top_k classes of the secondary verification system, which will increase  the possibility  of good  Dec a and increase  the possibility  of bad Decisions  Dec e and  Dec f as well.   In t his  paper,  we present a solution to the above  dilemma  by translating  and quantify   ing the problem  into optimizing  a careful defined objective  cost function. We  explain  it in  detail below.   2.3.3.  Using Objective  Cost  Function to Achieve  Optimal  Defense   Generally speaking, in most computer vision applications, a successful AML attack  will have  much  more  damage  to the user  than  a misclassified  event. In most  cases, misclas   sifying an object/content  in an image  will lead to a clearly  identifiable  wrongful  conclusion,  such that the user can easily  know  that this is a wrong  identification.  For example,  misiden   tifying  a road  STOP  sign as a red balloon  in autonomous  vehicle  driving will indicate  that  this is wrong  image  identification. However,  a successful  AML  attack  could  make  the user  misidentify the STOP sign as a SPEED LIMIT sign, which could result in a serious car  accident.   For this reason, when we decide how to adjust detection and defense settings for   our proposed  system,  we should  not use the classification  accuracy,  AUC  score,  or attack  success  rate directly  as the metric.  Instead,  we define an overall  cost objective  function,  that 9 of 17         Algorithm  3 Adaptive  Design  Algorithm.  [k] = Adaptive(DNN  classification  results,  RF classification  results)  Input: CIFAR 100(test set), DNN, RF   Output: optimal  parameter  k for the secondary RF model   for k ‚àà {1, 100} do  Set all the counters  Na, Nb, . . . , Nf to 0  for image  x ‚àà CIFAR  ‚àí 100 do  if x ‚àà SETcrc & DNN (x) ‚àà RF(x, k) then  Na + +  else  Nd + +  end if  if x ‚àà SETmis  & DNN (x) ‚àà/  Nb + +  else  Ne + +  end if  if x ‚àà SETadv & DNN (x) ‚àà/  Nc + +  else  Nf + +  end if  end for  RF(x, k) then        RF(x, k) then  Objective  function f (k) = ( Cd ¬∑ Nd + Ce ¬∑ Ne + Cf ¬∑ Nf ‚àí Ca ¬∑ Na ‚àí Cb ¬∑ Nb ‚àí Cc ¬∑ Nc)  end for  Among  all f (k), k ‚àà {1, 100} find the minimum  f (k‚àó)  Return t he  optimal  index k‚àó    is, the weighted summation of all image classification results to find the optimal defense  parameters that minimize this objective function.   For the six decision outputs  of our proposed  system  (Dec a to Dec f ), each  decision  for one image will have its own cost (due to misidentification) or gain (due to correct  identification), which can be treated as a positive or a negative costs. Let us define C a, Cb,  and Cc as the gains for each of those three good decisions Dec a, Dec b and Dec c; Cd, Ce, and  Cf are the cost values for each of those three wrongful decisions Dec d, Dec e and Dec f .  The objective  cost function Obj f (k) for choosing  the optimal  defense parameter Top_k  in the secondary RF classification module is illustrated in Algorithm 3  and shown in  Equation 1. We find the optimal value of k by selecting the minimum output ( min k) from  the equation  when  changing  k from  1 to 100. The  parameters Na to Nf refer  to the number  of times when decisions Dec a to Dec f happen, respectively.     Obj f (k) = min k(Cd ¬∑ Nd + Ce ¬∑ Ne + Cf ¬∑ Nf ‚àí Ca ¬∑ Na ‚àí Cb ¬∑ Nb ‚àí Cc ¬∑ Nc) (1)  To calculate Na, Nb, ..., and Nf , a loop is being conducted over the entire test set of  CIFAR 100 dataset.  In Algorithm 3 , each image x from the dataset is divided into three  sets previously  from  Algorithm  1 (SETcrc, SETmis, and SETadv).  Each  i f statement  checks  whether  x imag e belongs  to one of the sets and whether  the outcomes  of each  model  10 of 17     prediction (DNN and RF) are matched.  For example, if x is a human object and DNN  identifies it correctly, and the prediction also exists in the Top_3 RF outcomes, then the  decision state is set to Dec a and Na counter increments by one.   This optimization is conducted after the training stage w hen we know the ground  truth  of all images  as shown  in Section  3, and can calculate  the values  of Na to Nf for each  Top_k  parameter for all test images. Since  the number  of possible  values  of k is limited  (in  our model,  it has 100 possible  values  ranging  from  1 to 100),  therefore,  there  is no technical  challenge in solving the optimization problem.   2.3.4.  Examples  of Adjusting  Weights  on different  applications   In this section,  we use several  application  scenarios  to show  why  they  need  different  cost weights in our adaptive design and the above optimization Equation 1 . In different  image classification applications, users c an define the concrete values for the other cost  factors  according  to their  expert  opinion and application  scenarios. Four  applications  are  introduced  in the following,  and Table  4 in the following  section  presents  the outcomes  of  this adaptive method.   ‚Ä¢ Autonomous  driving : we can define Ca = 0.3, Cb = 0.1, and Cc = 0.5. The  value  of Cc is  higher than C a because, in autonomous driving, it is more important for us to detect  an adversarial  attack than  correctly  identify  a normal  roadside sign image. Similarly,  we can define C d = 0.1, C e = 0.3, and C f = 0.8. We define C f as having a significantly  higher value than others because Dec f means autonomous driving is compromised  under a deliberate adversarial  attack. For  example,  we could  treat  a STOP  sign image  as a right turn only sign, which could result in serious accident consequences. The  value  of Ce is higher  than  Cb in detecting  misclassified  images  by the model  due to the  risk value we assume.   ‚Ä¢ Healthcare:  although deep learning based healthcare systems could achieve high  accuracy in disease diagnosis, few such systems have been deployed in highly auto   mated disease scr eening settings due to a lack of trust. Therefore, the human based  double check  process  is usually  used,  and hence,  the deep  learning  healthcare  system  can be tolerated  in the security.  An example  values  of the weights  are Ca = 0.7, Cb  = 0.4, C c = 0.1, Cd = 0.4, Ce = 0.1, and C f 0.3. The Ca is the highest cost weight be   cause  the physician  will most  likely  discover  failure  in other  decisions  during  manual  double checking.   ‚Ä¢ Face  recognition  in checking  work  attendance : misrecognition or adversarial  impact  is low because the potential of utilizing these challenges by the employees is rare. Therefore,  we can give  the positive  gains higher  values  with  C a = 0.7, Cb = 0.4, and Cc  = 0.2. In contrast, we can value the negative decisions as C d = 0.4, C e = 0.2, and C f =  0.2.  ‚Ä¢ Detecting inappropriate digital content : mispredicting nudity images to protect  children  is another  example  where the costs  of AML  attack  are medium,  not as risky  as  in autonomous  driving,  nor as tolerable  as in face recognition. Hence,  we can choose  Ca = 0.7, Cb = 0.1, Cc = 0.2, Cd = 0.3, Ce = 0.1, and Cf = 0.1.   2.3.5.  The Cost  of Misclassified  Clean  Images   As far as of today, there are no image classification models that can provide a 100  percent  accurate  result. Table  1 shows  the accuracy  rates  of various  DNN models  without  any attacks.  ResNet 34 achieves  an accuracy  rate of 77.47 percent,  while  VGG16  has a lower  accuracy  rate of 72.25  percent.  On the other  hand,  DenseNet  boasts  a higher  accuracy  rate of  78.69  percent.  The percentage of misclassified  images  is enormous.  Therefore,  the business  models  of AI applications  should  consider  these  failure  cases  to assess their  risks in case of  using  any DNN  model  with  a high percentage  of misclassification.  On the other  hand,  our  approach  can detect  a significant  fraction of these  detection  failures  and categorize  them  as  forged by adversarial attacks.  11 of 17     As described  in the previous  section, Dec b can identify  the misclassification  of tested  samples and be counted as positive to DNN model accuracy.  On the other hand, Dec e,  where our approach wrongly identifies it as forged, is counted as negative to the overall  accuracy. Application  designers  can define  the costs  of these  decisions,  balancing  security  and safety with passing tolerance using Algorithm 3. The accuracy of the overall system  can be significantly affected, as demonstrated in Table 4 in Section 3.  2.3.6.  Evaluation  Metric   The evaluation technique for our proposed method is similar to previous works of  detection methods in [ 9‚Äì11]. We use the Area under the ROC Curve (AUC) score in our  assessments between clean Dec a and adversarial images Dec c, as it will be addressed in  Section 3 at Table  3. Accuracy  (acc.)  is another  metric  used  to evaluate  our proposed  model  based  on image  classification  application  parameters  that will be introduced  in Section  2.3  and Section 3 .  3. Results   In this section,  we showcase  the evaluation  and outcomes  of our study. First, settings  for the experiments  and the environment  utilized  are explained. Then,  the configurations  for the adversarial attacks we deploy to target the various deep learning models are outlined.  Lastly,  we present  and compare  the main  results  according  to each  proposed  approach  in  sections 2.2 and 2.3.  3.1. Experimental  Setup   To evaluate the robustness and effectiveness of the proposed scheme, we run our  training,  evaluation,  and attacks  using  NVIDIA  GeForce  RTX 3090  GPU.  We use Sklearn   [36] open source Python library for the classical ML Random Forest model. On the other  hand,  we use PyTorch lightning  [37] for DNN  models.  Finally, we use Torchattacks  [38] to  run the adversarial attacks.   3.2. Adversarial  Attack  Configuration   The attacker knows that the targeted image classification system uses ResNet 34 for  training the image classificat ion model. He/she also knows the data being used for that  training which is the CIFAR 100 training set. The attacker will use a test set of the same  dataset and state ofart adversarial  attack  algorithms: FGSM  [12], Deepfool  [13], CW [14],  and PGD  [15]. The  parameters  of each  type  of AML are listed  in Table  2 and defined in the  next.   Table 2. Experiment  settings.       Model            In the FGSM  trial,  we set the parameter œµ at 0.007,  which is a hyperparameter determin   ing the size of the perturbations  introduced  to the input  data. The  value  of œµ is a trade off  between the adversarial attack strength and the perturbation perceptibility. Raising this  value  could  increase  the exploit  success  rate;  however,  it might  show  an apparent  noise  on  the targeted image  that could  be revealed  to human  perception.  We select  the default  value  as 0.007 because the added perturbations are not easily perceived by human eyes.  The  FGSM  attack  success  accuracy  based  on the selected œµ on the CIFAR 100 test set is 65.75%.  Targeted  Dataset Adversarial  Attacks    Parameters  Attack  Success  Ratio  (%)   FGSM  œµ = 0.007  65.75   ResNet 34 CIFAR 100 Deepfool  s = 50, overshoot  = 0.02 99.92    CW c = 1.0, Œ∫ = 0, s = 50, lr = 0.01 98.64    PGD  œµ = 0.03, Œ± = 0.004,  s = 40 98.83    12 of 17     To execute  the Deepfool  attack, we  limit  the attack  iterations  to 50 steps  before  stopping.  During  each  iteration,  the attack  calculates  the direction  of the closest  decision boundary  to  the original  input  data  point  in order  to determine  the minimum  perturbation  required to  deceive the targeted  DNN  model. The  overshoot  parameter  is set to 0.02,  which multiplies  the computed  perturbation  vector  and adds  it to the input  image. With  these  settings, the  attack success accuracy reaches 99.92%.   To ensure a successful  attack  by CW method,  we utilize  the C&W  attack  parameters  listed  in Table  2: c = 1, Œ∫ = 0, steps  s = 50, and lr = 0.01. The  ‚Äôc‚Äô hyperparameter determines  the magnitude  of the perturbation,  while  the margin  parameter Œ∫ determines  the confidence  gap between  the predicted and target  classes. The  steps  s parameter represents  the number  of iterations  required for the attac k to succeed  or end. Lastly,  the learning  rate ‚Äôlr‚Äô controls  the optimization  iteration  steps.  With  these  adjustments,  we achieve  an attack  success  rate  of 98.64%.   The PGD  attack  was adjusted with  the following  parameters: œµ = 0.03,  alpha  Œ± = 0.004,  and steps = 40.  œµ and steps were explained in previous attacks, while alpha functions  similar  to the learning  rate,  determining  the size of each  optimization  step. This  attack  has  a success rate of 98.83%.   3.3. Main  Results   Tabel 3 summarizes the AUC scores of four adversarial attack detectors with our  proposed method from Section 2.2 using features from all the DNN penultimate layers.  For comparison, we compare our proposed method with four other popular adversarial  detection methods, DkNN [ 8], LID [ 9], Mahalanibis [ 10], and NNIF [ 11].  Overall, our proposed Top_1 threshold surpasses other methods in most at tacks, as  indicated in bold,  while  it founds  that the LID method  was the least  effective  in detecting  attacks.  The best FGSM  attack  detection  goes  to our proposed  Top_22  method.  Additionally,  "
285,Solving the Capsulation Attack against Backdoor-based Deep Neural Network Watermarks by Reversing Triggers.txt,"Backdoor-based watermarking schemes were proposed to protect the intellectual
property of artificial intelligence models, especially deep neural networks,
under the black-box setting. Compared with ordinary backdoors, backdoor-based
watermarks need to digitally incorporate the owner's identity, which fact adds
extra requirements to the trigger generation and verification programs.
Moreover, these concerns produce additional security risks after the
watermarking scheme has been published for as a forensics tool or the owner's
evidence has been eavesdropped on. This paper proposes the capsulation attack,
an efficient method that can invalidate most established backdoor-based
watermarking schemes without sacrificing the pirated model's functionality. By
encapsulating the deep neural network with a rule-based or Bayes filter, an
adversary can block ownership probing and reject the ownership verification. We
propose a metric, CAScore, to measure a backdoor-based watermarking scheme's
security against the capsulation attack. This paper also proposes a new
backdoor-based deep neural network watermarking scheme that is secure against
the capsulation attack by reversing the encoding process and randomizing the
exposure of triggers.","Watermark has been considered as a promising technique in protecting the copyright of artiÔ¨Åcial intelligence products, especially deep neural networks (DNN). Based on the type of access to the suspicious DNN, watermarking schemes are classiÔ¨Åed into whitebox DNN schemes and blackbox DNN ones [1]. Whitebox DNN watermark schemes encode the owner‚Äôs identity information into the network‚Äôs weights and parameters, whose revealing is possible only after the pirated DNN can be accessed as a whitebox. There have been var ious studies concerning the location of watermarking, the encoding and decoding formulation [2], the neuron permuta tion attack and the defense method [3], etc. Meanwhile, the blackbox DNN watermarks that are capable of verifying theownership even if the suspicious DNN can be accessed as no more than a blackbox are considered as the more practical choice. Since the pioneering works, blackbox DNN watermarks have been implemented through DNN backdoors [4]. This is because, in the blackbox setting, the inputoutput relation ship is the only source of information, whereas the backdoor is essentially deÔ¨Åned as specialized inputoutput pairs. By encoding identity information into speciÔ¨Åc backdoors, some schemes established ownership protection for the blackbox setting. Recent efforts have been devoted to defending the backdoorbased watermark from attacks including blind tun ing [5], anomaly detection [6], etc. It is remarkable that despite these results, there are several fundamental differences between the ordinary DNN backdoor and the blackbox DNN watermarks. For example, in the ownership veriÔ¨Åcation scenario, it is necessary that the re sponse reÔ¨Çects the owner‚Äôs identity in an unambiguous, un forgeable, and provable manner. Therefore, it is necessary that generating triggers is expensive for adversaries. but the difÔ¨Åculty in generating a backdoor trigger is never an aspect of interest for backdoor algorithms. As the cost of generating backdoor triggers is hard to measure (not to mention proving the difÔ¨Åculty of generating them), researchers have proposed to use a collection of multiple triggers and encode the own ership information into their correlations, in which case the level of security grows with the number of triggers [7]. Un fortunately, these schemes ignore the fact that an adversary knowing the encoding scheme or being given multiple trig gers has the ability to distinguish triggers from normal queries and devastate the ownership proof. Notice that, unlike a back door attack, this knowledge should be made available to every party including the adversary (the watermarking scheme is in applicable if only few parties can run the scheme), and block ing triggers need not to tune the DNN in the blackbox setting. These observations imply more requirements for triggers and their encoding methods for backdoorbased DNN watermark ing schemes, which go beyond the scope of traditional studies on DNN backdoors. To confront the deÔ¨Åciencies of current blackbox DNN watermarking schemes, we incorporate the previous observa tions and formulate a new threat, the Capsulation Attack , byarXiv:2208.14127v1  [cs.CR]  30 Aug 2022encapsulating the stolen DNN with an extra Ô¨Ålter to invali date triggers and thence ownership queries. Then we derive the necessary conditions for a secure blackbox DNN water marking scheme w.r.t. this attack. We also provide an own ership veriÔ¨Åcation protocol that minimizes the security risk under the blackbox setting. The contributions of this paper are: ‚Ä¢ We propose the capsulation attack against blackbox DNN watermarks. It can easily devastate current schemes with little cost and turns out to be a prac tical threat to copyright regulation. A new security metric CAScore is deÔ¨Åned according to this attack. ‚Ä¢ A new blackbox DNN watermarking scheme is pro posed to establish the ownership protection under the capsulation attack by reversing the trigger encoding and ownership veriÔ¨Åcation process. We show that the ownership integrity can be sufÔ¨Åciently preserved by a delicate encoding scheme without resorting to any advanced cryptological primitives even if the adversary is very knowledgable. 2. RELATED WORKS AND PRELIMINARIES "
72,Collocation Polynomial Neural Forms and Domain Fragmentation for solving Initial Value Problems.txt,"Several neural network approaches for solving differential equations employ
trial solutions with a feedforward neural network. There are different means to
incorporate the trial solution in the construction, for instance one may
include them directly in the cost function. Used within the corresponding
neural network, the trial solutions define the so-called neural form. Such
neural forms represent general, flexible tools by which one may solve various
differential equations. In this article we consider time-dependent initial
value problems, which require to set up the neural form framework adequately.
The neural forms presented up to now in the literature for such a setting can
be considered as first order polynomials. In this work we propose to extend the
polynomial order of the neural forms. The novel collocation-type construction
includes several feedforward neural networks, one for each order. Additionally,
we propose the fragmentation of the computational domain into subdomains. The
neural forms are solved on each subdomain, whereas the interfacing grid points
overlap in order to provide initial values over the whole fragmentation. We
illustrate in experiments that the combination of collocation neural forms of
higher order and the domain fragmentation allows to solve initial value
problems over large domains with high accuracy and reliability.","Over the last decades several neural network approaches for solving diÔ¨Äerential equations have been developed [1, 2, 3]. The application and extension of these approaches is a topic of recent research, including work on d iÔ¨Äerent network 1architectures like Legendre [4] and polynomial neural netw orks [5] as well as computational studies [6, 7]. One of the early proposed methods [8] introduced a trial solu tion (TS) in order to deÔ¨Åne a cost function using one feedforward neural n etwork. The TS is supposed to satisfy given initial or boundary values by cons truction. It is also referred to as neural form (NF) in this context [8, 9] which we will adopt from here on. Let us note that such NFs represent a general tool tha t enable to solve ordinary ordinary diÔ¨Äerential equations (ODEs), partial d iÔ¨Äerential equations (PDEs) and systems of ODEs/PDEs alike. We will refer here to t his approach as the trial solution method (TSM). Later, the initial metho d from [8] has been extended by a NF with two feedforward neural networks, w hich allows to deal with boundary value problems for irregular boundari es [10] and yields broader possibilities for constructing the TS [9]. In the la tter context, let us also mention [11] where an algorithm is proposed in order to creat e a TS based on grammatical evolution. Focusing on initial value problems (IVPs), one approach employs to learn solution bundles [12], making the trained n eural forms reusable for enquired initial values. A technique related to TSM that avoids the explicit construc tion of trial so lutions has been proposed in [13]. The given initial or bound ary values from the underlying diÔ¨Äerential equation are included in the cost fu nction as additional terms, so that the NF can be set to equal the neural network out put. We will refer to this approach as modiÔ¨Åed trial solution method (mTS M). The fact that the neural network output computation resembl es a linear combination of basis functions leads to a network architect ure as presented in [14] (for PDEs). In that work one hidden layer incorporates t wo sets of activation functions, one of which is supposed to satisfy the PDE and the second dealing with boundary conditions. The basis function coeÔ¨Écients ar e set to be the connecting weights from the hidden layer to the output neuro n, and the sum over all basis functions and coeÔ¨Écients makes up the NF. Motivated by the construction principle of collocation met hods in numerical analysis, we propose in this paper a novel extension of the NF approach. Our neural form extension is based on the observation, that the N F using one feed forward neural network as employed in [8] may be interpreted as a Ô¨Årst order collocation polynomial. We propose to extend the correspon ding polynomial order of the neural form. The novel construction includes se veral feedforward neural networks, one for each order. Compared to a collocati on method from standard numerics, the networks take on the role of coeÔ¨Écien ts in the collocation polynomial expansion. Furthermore, we aim to approximate initial value problems o n fairly large domains. Therefore, and based on the NF structures, we also p ropose a frag mentation of the computational domain into subdomains. In e ach subdomain, we solve the initial value problem with a collocation neural form. This is done proceeding in time from one domain fragment to the adjacent s ubdomain. The interfacing grid points in any subdomain provide the initia l value for the next subdomain. On a Ô¨Årst glance one may think of similarities to d omain decompo sition methods for PDEs in numerical analysis, cf. [15, 16]. We also show how to 2combine the domain fragmentation with the newly developed c ollocation poly nomial neural forms. Let us note that this article is a substantial extension of ou r conference paper [17]. There we brieÔ¨Çy introduced just the principle of the collocation based polynomial NF. Here we present a much more detailed inv estigation of the collocationbased NF, and as a substantial novelty the e xpansion and com bination with our novel domain fragmentation method for sol ving initial value problems. That enables us to discuss both methods in a merged context, which we Ô¨Ånd highly suitable. Moreover, we updated the notation to a more suitable form. Related work and problem statement In our previous work [18] we have shown that even simple feedforward neural networks (5 hidde n layer neurons) are capable of solving a stiÔ¨Ä initial value problem. The inve stigated and studied neural forms approaches are based on [8, 13]. Please Ô¨Ånd the a dditional related work to be addressed in the previous introduction paragraph s. The best results in the above mentioned computational study were provided by random weight initialisation, but with the drawback of a spread between th e results with dif ferent random initialisation for unchanged computational parameters. There we now want to improve constant weight initialisation. The m ain advantage of the latter is that results are exactly reproducible with unc hanged computational parameters. Based on the neural forms approach [8] we have al ready shown that a polynomial extension leads to a signiÔ¨Åcant increase of num erical accuracy for constant weight initialisation [17]. In the present work we now combine the polynomial neural forms and employ domain fragmentation to split the solution domain into smaller subdomains. This technique solves the n eural forms on such subdomains with the initial values provided by previou s subdomains. The inherent Ô¨Çexibility enables the approach to achieve useful results, even on fairly large domains. 2 Setting up the neural form (NF) In this section, we Ô¨Årst recall the TSM and its modiÔ¨Åed versio n mTSM, respec tively, compare [8, 13]. Then we proceed with details on the f eedforward neural networks we employ, followed by a description of the novel co llocationbased neural form and the subdomain approach. 2.1 Construction of the neural form Consider an initial value problem written in a general form a s G(t,u(t),Àôu(t)) = 0, u(t0) =u0, t‚ààD‚äÇR (1) with given initial value u(t0) =u0. In order to connect Gwith a neural network, several approaches introduce a NF as a diÔ¨Äerentiable functi onÀúu(t,p), where the vector pcontains the network weights. With the collocation method w e 3discretise the domain Dby a uniform grid with n+1grid points ti(t0< t1< ... < t n), so that the initial value problem (1) leads to the formulat ion G/parenleftbig ti,Àúu(ti,p),ÀôÀúu(ti,p)/parenrightbig =0 (2) Let us note that, in a slight abuse of notation, we identify G/parenleftbig ti,Àúu(ti,p),ÀôÀúu(ti,p)/parenrightbig with the vector of corresponding entries (grid points), sin ce this enables to give many formula a more elegant, compact notation. In order to satisfy the given initial value, TSM [8] employs t he NF as a sum of two terms Àúu(t,p) =A(t)+F(t,N(t,p)) (3) whereA(t)is supposed to match the initial condition (with the simples t choice to beA(t) =u(t0)), whileF(t,N(t,p))is constructed to eliminate the impact ofN(t,p)att0. The choice of F(t,N(t,p))determines the inÔ¨Çuence of N(t,p) over the domain. Since the NF as used in this work satisÔ¨Åes given initial value s by construction, we deÔ¨Åne the corresponding cost function incorporating Eq. (3) as E[p] =1 2/vextenddouble/vextenddouble/vextenddouble/vextenddoubleG/parenleftbig ti,Àúu(ti,p),ÀôÀúu(ti,p)/parenrightbig/vextenddouble/vextenddouble/vextenddouble/vextenddouble2 2(4) which is subject to minimisation. Although Eq. (2) denotes a system of equa tions which may be solvable w.r.t. p, the actual equation of interest is Eq. (4) and its optimisation will return suitable neural network we ights. Let us now turn to the mTSM approach after [13]. The mTSM appro ach chooses the NF to be equivalent to the neural network output d irectly Àúu(t,p) =N(t,p) (5) Since no condition is imposed by the initial value on the NF in this way, the conditions are added to the cost function when relying on Eq. (5): E[p] =1 2/vextenddouble/vextenddouble/vextenddouble/vextenddoubleG/parenleftbig ti,Àúu(ti,p),ÀôÀúu(ti,p)/parenrightbig/vextenddouble/vextenddouble/vextenddouble/vextenddouble2 2+1 2/vextenddouble/vextenddouble/vextenddouble/vextenddoubleN(t0,p)‚àíu(t0)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2 2(6) 2.2 Neural network architecture and optimisation In this section we will describe how a feedforward neural net work with one hidden layer operates in our setting. SpeciÔ¨Åc variants will be addressed in the corresponding sections. As depicted in Fig. 1 we employ one hidden layer, with Hhidden layer neurons supplemented by one bias neuron. Having in addition one bias neuron in the input layer and a linear output layer neuron, the neura l network output reads N(t,p) =H/summationdisplay j=1œÅjœÉj+Œ≥ (7) 4Thereby œÉj=œÉ(zj) = 1/(1+e‚àízj)represents the sigmoid activation function with the weighted sum zj=ŒΩjt+Œ∑j. Here,ŒΩj(input layer neuron), Œ∑j(input layer bias neuron), œÅj(hidden layer neurons) and Œ≥(hidden layer bias neuron) denote the weights which are stored in the weight vector p. The input layer passes the domain data t(that is in practice ti), weighted by ŒΩjandŒ∑j, to the hidden layer for processing. The neural network output N(t,p)is again a weighted sum of the values œÅjœÉ(zj)withŒ≥added. With N(t,p)given, the neural forms and cost functions in Eqs. (4),(6), are obtaine d. Input LayerHidden LayerOutput Layer tŒΩj 1 Œ∑jœÉ1 œÉ2 œÉ3 œÉ4 œÉ5œÅj 1Œ≥N Figure 1: The architecture of our incorporated feedforward neural network with one hidden layer bias.As usual, the cost function gradient is used to update pin order to Ô¨Ånd a (local) mini mum in the weight space. One training cy cle is called an epoch and consists of a full iteration over all training points points. The gradient, with respect to the network weights, determines their inÔ¨Çuence on the network out put. With this information, each incorpo rated weight can be adjusted individually to lead the network into a local minimum during the training process. For optimising the cost function we consider here Adam (adaptive moment estimation) [19] which is a stochas tic gradient descent method, using adaptive learning for every weight. If a weight update is performed after the gradient computation for a single grid point we call this method single batch training (SB training) here. An alternative proceeding, performing the weight update after a complete iteration over all grid points, averaging the cost function gradient and training error, is denoted here as full batch training (FBtr aining). Let us comment in some detail on the relation between grid poi nts and training points. Our setting is an unsupervised learning fr amework, where grid points are used for domain discretisation, and where the unk nowns are values of the ODE solution at exactly these grid points. Thus, in our setting, the grid points are identical with the training points. Let us stress in this context, that the grid points by themselves stay Ô¨Åxed during network optim isation. 3 The novel collocation neural form (CNF) Making Eq. (3) precise for our gridbased setting, a suitabl e choice for the neural form of TSM with given u(0) =u0is Àúu(t,p) =u0+N(t,p)t (8) wheretwill be evaluated at grid points ti. Please note, if the initial point is diÔ¨Äerent from t0= 0, this results in a shift of t‚Üí(t‚àít0)in Eq. (8). Compared to a Ô¨Årst order polynomial q1(t) =a0+a1tone may Ô¨Ånd similarities in the 5structure. Motivated by the expansion of an mth order collocation function polynomial [20] qm(t) =a0+m/summationdisplay k=1aktk(9) we are lead to set up our collocationbased NF (CNF) approach for TSM: ÀúuC(t,Pm) =u0+m/summationdisplay k=1Nk(t,pk)tk(10) The weight vector is denoted by pkand we deÔ¨Åne the matrix Pmofmweight vectors Pm= (p1,...,pm). The use of higher order monomial powers tkas in Eq. (10) not only gen eralises previous methods, but may also enable better stabi lity and accuracy properties, as we show in this paper. Let us also observe, tha t the neural net works take on the roles of coeÔ¨Écient functions for the values oftk. We conjecture at this point that this construction makes sense since in thi s way several possible multipliers (not only tas in Eq. (8)) are included for neural form construction. It is important to mention that the new neural form construct ion Eq. (10) fulÔ¨Ålls the initial condition. Let us stress that the proposed ansatz (Eq. (10)) includes mneural networks, whereNk(t,pk)represents the kth neural network Nk(t,pk) =H/summationdisplay j=1œÅj,kœÉ(ŒΩj,kt+Œ∑j,k)+Œ≥k (11) The corresponding cost function is then given as in Eq. (4). We extend the mTSM method in a similar way as we obtained the TS M extension in Eq. (10): ÀúuC(t,Pm) =N1(t,p1)+m/summationdisplay k=2Nk(t,pk)tk‚àí1(12) Thereby the Ô¨Årst neural network N1(t,p1)is set to learn the initial condition in the same way as stated in Eq. (6). From now on we will refer to the number of neural networks in th e neural form as the collocation neural form order, denoted by m. 4 The novel subdomain collocation neural form (SCNF) The previous described TSM and mTSM approaches use the IVP st ructure to gether with the given initial value in order to train the neur al networks on a certain domain. In a prior experimental study [7] we Ô¨Ågured o ut that especially 6TSM tends to struggle with approximating the solution on lar ger domains. How ever, on small domains the numerical error tends to remain sm all. Since the domain variable teÔ¨Äectively acts as a scaling of N(t,p), we conjecture that a large domain size variation may introduce the need for a hig her amount of training points or the use of a more complex neural network ar chitecture. These circumstances motivate us to introduce a second stage of discretising the domain. That is, we split the solution domain Din subdomains Dl,l= 1,...,h , withn+1grid points ti,lin each subdomain. Now the CNF is solved separately in each subdomain. The interfacing grid points o verlap, i.e. the computed value ÀúuC(tn,l‚àí1,Pm,l‚àí1)at the last grid point of any subdomain Dl‚àí1 is set to be the new initial value ÀúuC(t0,l,Pm,l)for the next subdomain Dl. Since the CNF for TSM is constructed in order to satisfy the gi ven initial values, we force the subdomain CNF (SCNF) to also hold that ch aracteristic. Therefore the SCNF is constructed to satisfy the new initial values in each subdomain, namely ÀúuC(ti,l,Pm,l) = ÀúuC(t0,l,Pm,l)+m/summationdisplay k=1Nk(ti,l,pk,l)(ti,l‚àít0,l)k(13) The neural networks are now scaled by (ti,l‚àít0,l)k, which in fact may avoid higher scaling factors, depending on the subdomain size. Th e arising cost func tion, similar to Eq. (4), is El[Pm,l] =1 2/vextenddouble/vextenddouble/vextenddouble/vextenddoubleG/parenleftbig ti,l,ÀúuC(ti,l,Pm,l),ÀôÀúuC(ti,l,Pm,l)/parenrightbig/vextenddouble/vextenddouble/vextenddouble/vextenddouble2 2(14) Proceeding to mTSM, we also adopt the CNF approach and set the Ô¨Årst neural network to learn the new initial values in each subdomain. Th at is, the SCNF reads ÀúuC(ti,l,Pm,l) =N1(ti,l,p1,l)+m/summationdisplay k=2Nk(ti,l,pk,l)(ti,l‚àít0,l)k‚àí1(15) and the corresponding cost function El[Pm,l] =1 2/vextenddouble/vextenddouble/vextenddouble/vextenddoubleG/parenleftbig ti,l,ÀúuC(ti,l,Pm,l),ÀôÀúuC(ti,l,Pm,l)/parenrightbig/vextenddouble/vextenddouble/vextenddouble/vextenddouble2 2+ (16) 1 2/vextenddouble/vextenddouble/vextenddouble/vextenddoubleN(t0,l,p1,l)‚àíÀúuC(t0,l,Pm,l)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2 2 Let us note at this point, that Gin Eq. (14) and (16) shares the same structure as the general problem in Eq. (1). However, the original solu tion function u(t) has been replaced by the SCNF ÀúuC(ti,l,Pm,l). Therefore, Ginvolved in the cost function now relies on one or more neural networks, dependin g on the neural forms order. Once trained, each subdomain has its unique lea rned weight matrix Pm,lwhich can later be used to recreate the solution or evaluate t he solution at grid points intermediate to the training points. 7In order to keep the overview of all terms and indices, we sum t hem up again: The ith grid point in the lth subdomain is denoted by ti,l, whilet0,lis the initial point in the subdomain Dlwith the initial value ÀúuC(t0,l,Pm,l). That is,tn,l‚àí1andt0,lare overlapping grid points. In D1,ÀúuC(t0,1,Pm,1) =u(t0) holds. The matrix Pm,lcontains the set of the mneural network weights in the corresponding subdomain l. Finally, Nk(ti,l,pk,l)denotes the kth neural network in Dl. 5 Experiments and results This section is divided into experiments on the collocation neural form (CNF), followed by experiments on the subdomain collocation neura l form (SCNF). Prior to this, we will provide detailed information about ho w the weight initial isation for the diÔ¨Äerent neural networks are realised. The d iscussion of constant weight initialisation is also one of the main subjects in the experimental section. As stated before, the speciÔ¨Åc neural network conÔ¨Ågurations will be addressed in the subsequent experiments. Weight initialisation with pinit constapplies to all corresponding neural networks so that they use the same initial values. Increasing the m for the initialisation withpinit rndworks systematically. For m= 1, a set of random weights for the neural network is generated. For m= 2(now with two neural networks), the Ô¨Årst neural network is again initialised with the generated weights from m= 1, while for neural network number two, a new set of weights is ge nerated. This holds for all mfor higher orders, subsequently, in all experiments. To ach ieve comparability, the same random initialised weights are use d in all experiments. For optimisation we use Adam, which parameters are Ô¨Åxed with , as employed in [19],Œ±= 1e3,Œ≤1= 9e1,Œ≤2= 9.99e1 and«´= 1e8. 5.1 Experiments on the collocation neural form (CNF) In this section, we want to test our novel CNF approach with th e initial value problem Àôu(t)+5u(t) = 0, u(0) = 1 (17) which has the analytical solution u(t) =e‚àí5tand is solved over the entire domainD= [0,2](without domain fragmentation). The Eq. (17) involves a damping mechanism, making this a simple model for stiÔ¨Ä pheno mena [21]. The numerical error ‚àÜushown in subsequent diagrams in this section is deÔ¨Åned as the l1norm of the diÔ¨Äerence between the exact solution and the corresponding CNF ‚àÜu=1 n+1/vextenddouble/vextenddoubleu(ti)‚àíÀúuC(ti,Pm)/vextenddouble/vextenddouble 1(18) If we do not say otherwise, the Ô¨Åxed computational parameter s in the subsequent experiments are: 1 input layer bias, 1 hidden layer with 5 sig moid neurons, 1e5 training epochs, 10 training points, D= [0,2]and the weight initialisation 8values which are pinit const=‚àí10andpinit rnd‚àà[‚àí10.5,‚àí9.5]. These values may seem arbitrarily chosen, but we found them to work well for bo th TSM and mTSM so that a useful comparison is possible. No.‚àÜu(pinit rnd)‚àÜu(pinit const) 1 5.7148e6 2.6653e6 2 7.5397e6 2.6653e6 3 3.7249e5 2.6653e6 4 1.1894e5 2.6653e6 5 7.7956e6 2.6653e6 Table 1: Results for Ô¨Åve dif ferent realisations during opti misation (mTSM, m= 2)Weight initialisation Let us comment in some more detail on weight initialisation. The weight initialisation plays an important role and determines the starting point for gradi ent descent. Poorly chosen, the optimisation method may fail to Ô¨Ånd a suitable local mini mum. The initial neural network weights are commonly chosen as small random values [22]. Let us note that this is sometimes consid ered as a computational characteristic of the stochastic gradient descent optimisation. An other option is to choose the initialisation to be constant. This method is not commonly used for the optimisation of neural networks since random weight initialisation may lead to better results. However, consta nt initialisation re turns reliably results of reasonable quality if the computa tional parameters in the network remain unchanged. As previous experiments have documented [7, 8, 13], both TSM and mTSM are able to solve diÔ¨Äerential equations up to a certain degre e of accuracy. How ever, an example illustrating the accuracy of Ô¨Åve computati ons with random weightspinit rndrespectively constant weights pinit constshows that the quality of ap proximations may vary considerably, see Table 1. As observe d in many experi ments, even a small discrepancy in the initialisation with s everal sets of random weights in the same range, may lead to a signiÔ¨Åcant diÔ¨Äerence in accuracy. On the other hand, the network initialisation with constant va lues very often gives reliable results by the proposed novel approach. This motiv ates us to study in detail the eÔ¨Äects of constant network initialisation. 5.1.1 CNF Experiment: number of training epochs The Ô¨Årst experiment shows for diÔ¨Äerent m how the numerical er ror‚àÜubehaves depending on the number of training epochs. The diagrams onl y display every hundredth data point. In Fig. 2(a) with TSM and pinit constresults for m= 1(blue) do not provide any useful approximation, independent of the batch trainin g method selected. With a second neural network for m= 2(orange) in the neural form, ‚àÜu approximately lowers by one order of magnitude so that we now obtain a solution which can be considered to rank at the lower end of reliabilit y. However, the most interesting result in Fig. 2(a) is m= 5(green) with the best accuracy at the end of the optimisation process but with the drawback of occu rring oscillations. These may arise by the chosen optimisation method. Table 2 shows the numeric error ‚àÜu(ti)at individual grid points ti. For both CNF and RungeKutta 4 (RK4) the results were computed wi th ten grid 9points, resulting in the CNF approach with pinit constperforming better over Runge Kutta 4. However, further reÔ¨Åning the grid for RungeKutta 4 will result in signiÔ¨Åcantly lower ‚àÜu(ti). For mTSM with SBtraining and pinit const, already m= 1converges to a solu tion accuracy that can be considered reliable. However, we o bserve within Fig. 2(b) that only the transition from m= 1(blue) to m= 2(orange) aÔ¨Äects ‚àÜu with increasing accuracy, while heavy oscillations start t o occur. ti‚àÜu(ti)(TSM) ‚àÜu(ti)(RK4) 0.00 0.0000e0 0.0000e0 0.22 3.8158e5 0.1769e0 0.44 3.5101e5 0.1478e0 0.66 1.4318e5 9.4013e2 0.88 1.2001e5 5.3900e2 1.11 4.5407e5 2.9361e2 1.33 5.2069e6 1.5546e2 1.55 6.6105e5 8.0942e3 1.77 1.2052e5 4.1712e3 2.00 7.9787e5 2.1357e3 Table 2: Numerical error comparison at individual grid points with m= 5and pinit constIn not documented results with pinit rnd, m has only minor inÔ¨Çuence on the accuracy. Especially FBtraining for mTSM shows the same trend for both initialisation methods with only minor diÔ¨Äerences in the last epochs. Let us note that the displayed re sults show the best approximations using constant or random initialisa tion. This means, we obtain the best results for TSM with FBtrain ing,m= 5(green) and for mTSM with SBtraining, m‚â•2, respectively. Concluding this experiment, we were able to get better results with pinit constoverpinit rnd. Increasing the m to at least order Ô¨Åve seems to be a good option for TSM and FBtrain ing, whereas further m may provide even better approximations. For mTSM w e can not observe beneÔ¨Åts for m above order 2. Moreover, we see especially that the increase in the order of the neural form in (10) appears to have a similar impact on solution accuracy as the discretisa tion order in classical numerical analysis. 0 2 4 6 8 10 number of epochs 1041e61e51e41e31e21e11e0 (a) TSM, FBtraining, pinit const0 2 4 6 8 10 number of epochs 1041e61e51e41e31e21e11e0 (b) mTSM, SBtraining, pinit const Figure 2: Experiment in 5.1.1 Number of training epochs, (blue) m= 1, (orange) m= 2, (yellow) m= 3, (purple) m= 4, (green) m= 5 105.1.2 CNF Experiment: domain size variation 0.1 1 2 3 4 5 6 7 8 9 10 tend1e71e61e51e41e31e21e11e01e1 (a) TSM, SBtraining, pinit const0.1 1 2 3 4 5 6 7 8 9 10 tend1e71e61e51e41e31e21e11e01e1 (b) TSM, FBtraining, pinit rnd 0.1 1 2 3 4 5 6 7 8 9 10 tend1e71e61e51e41e31e21e11e01e1 (c) mTSM, SBtraining, pinit const0.1 1 2 3 4 5 6 7 8 9 10 tend1e71e61e51e41e31e21e11e01e1 (d) mTSM, FBtraining, pinit rnd Figure 3: Experiment in 5.1.2 Domain size variation, (blue) m= 1, (orange) m= 2, (yellow) m= 3, (purple) m= 4, (green) m= 5 Investigating the methods concerning diÔ¨Äerent domain size s provides infor mation on the reliability of computations on larger domains . The domains in this experiment read as D= [0,tend]and we directly compare in this experiment pinit constwithpinit rnd. In Fig. 3(a), 3(b), we observe TSM from around tend= 3.5to incrementally plateau to unreliable approximations. Increasing m improv es‚àÜuon small do mains and shifts the observable steplike accuracy degener ation towards larger domains. However, even with m= 5(green) the results starting from domain size tend= 3.5towards larger sizes are unreliable. Previous to the Ô¨Årst pl ateau higher m provide signiÔ¨Åcant better ‚àÜuforpinit const, while there are only minor changes for pinit rndfor the TSM method. This holds for both SBtraining and FBtraining, and one can say that in this experiment TSM works better with pinit rnd, even without increasing m. Turning to the mTSM extension, we observe in Fig. 3(c) with SB training the existence of a certain point from where diÔ¨Äerent m return equ al values, whereas FBtraining returns (close to) equal results for all the inve stigated domain sizes. However, we see some evidence for the use of m= 2(orange) over m= 1(blue) to show an overall good performance. A further increase of m i s not necessary with this approach, conÔ¨Årming results from Experiment 5.1. 1. 11Let us also note that, with mTSM we Ô¨Ånd that a small domain seem s to favourpinit constwhich then provides better results than pinit rnd. 5.1.3 CNF Experiment: number of training points variation 2 10 20 30 40 50 number of training points1e61e51e41e31e21e11e01e1 (a) TSM, FBtraining, pinit const2 10 20 30 40 50 number of training points1e61e51e41e31e21e11e01e1 (b) mTSM, SBtraining, pinit const Figure 4: Experiment in 5.1.3 Number of training points variation, (blue) m= 1, (orange) m= 2, (yellow) m= 3, (purple) m= 4, (green) m= 5 The behaviour of numerical methods highly depend on the chos en amount of grid points, so that in this experiment we analogously inves tigate the inÔ¨Çuence of the number of training points (nTP). In every computation , the domain Dis discretised by equidistant grid points. As in the previous experiments, the m shows a major inÔ¨Çuence o n the re sults with TSM, and the best approximations are provided by pinit constwithm= 5 (green) as seen in Fig. 4(a). An interesting behaviour (obse rved also in a diÔ¨Äer ent context in Fig. 2(a)) is the equivalence between m= 3(yellow) and m= 4 (purple). Both converge to almost exactly the same ‚àÜu, where one may assume a saturation for the m. However, another increase in the orde r decreases the numerical error again by one order of accuracy. Turning to mTSM in Fig. 4(b) we again Ô¨Ånd a major increase in ac curacy after a transition from m= 1(blue) to m= 2. For nTP = 50, values for m‚â•2 converge to the same results as provided by TSM with m= 5. Concluding this experiment, we again Ô¨Ånd evidence that incr easing m in the proposed approach provides an improved accuracy for pinit const. However, increasing nTP seems not to improve the accuracy from a certa in point on, unlike for numerical methods. But one could argue, that the a nalogy between the number of grid points for numerical methods here is the nu mber of epochs. 5.2 Experiments on the subdomain collocation neural form (SCNF) In Section 5.1, while the test equation is stiÔ¨Ä, its solution is at the same time very smooth and the equation is solved on a small domain. Howe ver, Fig. 3 in Experiment 5.1.2, shows that TSM does not provide reliable s olutions on larger 12domains. Hence, we want to show that the novel SCNF approach i s able to work even on a fairly large domain with a diÔ¨Äerent initial value pr oblem. Therefore we use the following test equation Àôu(t)‚àítsin(10t)+u(t) = 0, u(0) =‚àí1 (19) with the analytical solution u(t) = sin(10 t)/parenleftbigg99 10201+t 101/parenrightbigg +cos(10t)/parenleftbigg20 10201‚àí10t 101/parenrightbigg ‚àí10221 10201e‚àít(20) The solution is shown in Fig. 5 for t‚àà[0,15]and incorporates heavily oscillating 0 2.5 5 7.5 10 12.5 15 t21.510.500.511.52u(t) Figure 5: Analytical solution for initial value problem (19 ) and increasing characteristics, similar to instabilities . Although our approach is not limited to certain types of IVPs, we Ô¨Ånd Eq. (19) to repr esent possible realworld behaviour and Ô¨Ånd it suitable to serve as an examp le IVP. The numerical error ‚àÜulis now deÔ¨Åned as the averaged l1norm of the diÔ¨Äer ence between the exact solution and the corresponding SCNF i n each subdomain ‚àÜul=1 n+1/vextenddouble/vextenddoubleu(ti,l)‚àíÀúuC(ti,l,Pm,l)/vextenddouble/vextenddouble 1(21) whereas ‚àÜuaverages the numerical error of the subdomains ‚àÜu=1 hh/summationdisplay l=1‚àÜul (22) The weight initialisation works as employed in Section 5 and the values are Ô¨Åxed topinit const= 0andpinit rnd‚àà[‚àí0.5,0.5]. In the subsequent experiments, the solution domain is kept constant to D= [0,15]and the neural networks are training with 1e5 epochs. In addition we use the method of training the neural networks incrementally which has been employed in [13]. That is, we initially train t he neural networks for the Ô¨Årst grid point, afterwards for the Ô¨Årst two grid poin ts. We continue the 13procedure up to a FBtraining of all grid points in each subdom ain. The initial weight initialisation is the same in each subdomain. Please note at this point, that we provide an explicit compar ison to the RungeKutta 4 method only in the last experiment of this sect ion. We Ô¨Ånd that "
48,Nonlinear Systems Identification Using Deep Dynamic Neural Networks.txt,"Neural networks are known to be effective function approximators. Recently,
deep neural networks have proven to be very effective in pattern recognition,
classification tasks and human-level control to model highly nonlinear
realworld systems. This paper investigates the effectiveness of deep neural
networks in the modeling of dynamical systems with complex behavior. Three deep
neural network structures are trained on sequential data, and we investigate
the effectiveness of these networks in modeling associated characteristics of
the underlying dynamical systems. We carry out similar evaluations on select
publicly available system identification datasets. We demonstrate that deep
neural networks are effective model estimators from input-output data","Methods for the adaptive identiÔ¨Åcation and control of linear, time invariant systems with unknown parameters are wellestablished and documented in linear systems theory, with stable adaptive laws for the adjustment of parameters that demonstrate global stability of the overall system. Be ing universal approximators, neural networks (NNs) have witnessed a Ô¨Çurry of use in modeling various nonlinear phenomena in the past three decades. Three broad classes of NNs that have received attention recently include 1) multilayer perceptrons, 2) recurrent neural networks, and 3) convolutional neural networks. Multilayer networks have been used in identiÔ¨Åcation and control of static and dynamic simple nonlinear systems [1], [2] while recurrent networks (and its variants) have been used as associative memories for the solution of timeseries/sequential optimization problems [3], [4] and in the dynamic identiÔ¨Åcation and control of nonlinear systems [5], [6]. Convolutional networks, on the other hand, have been successfully used in pattern recog nition, supervised classiÔ¨Åcation tasks and image processing problems [7], [8]. In complicated realworld systems, deep neural networks (DNNs) have proven very effective for classiÔ¨Åcation prob lems related with patterns in complicated systems such as image processing [8], speech processing [9], language models [10], handwriting recognition [7] and sequential data [3], [11]. These networks are termed ‚Äúdeep‚Äù because they are constructed by stacking multiple layers of nonlinear operations (such as NNs) atop one another with many hidden *This work was supported by the Radiation Oncology Department, UT Southwestern, Dallas, Texas, USA 1Olalekan Ogunmolu and Nicholas Gans are with the Department of Elec trical Engineering, University of Texas at Dallas, Richardson, TX 75080, USA folalekan.ogunmolu, ngans g@utdallas.edu 2Xuejun Gu and Steve Jiang are with the Department of Radiation Oncology, University of Texas Southwestern Medical Center, Dallas TX 75390, USA fXuejun.Gu, Steve.Jiang g@utsouthwestern.edulayers. They are analogous to complicated formulae that re use many subformulae in abstracting realworld representa tions with their parameters (or weights). The work discussed in this paper is largely motivated by the problem discussed in recent investigations of the identiÔ¨Åcation and control of softrobots for head and neck motion alignment during cancer radiotherapy (RT) [12], [13]. Here we design selforganizing networks, connected in a DNN fashion, to enable the development of efÔ¨Åcient and synaptic adaptive rules for arbitrarily connected NNs; this facilitates the development of an internal structure that is appropriate for a system identiÔ¨Åcation and control learning task. This work presents NNbased Hammerstein models evalu ated on SISO and MIMO datasets. The modeling procedure for approximating systems such as the ones we present in this work is a complicated task with highly nonlinear dynamics that may be too complicated to model with closed form equations. We extend the development of NNs for abstracting complex nonlinear realworld systems in the pattern recognition Ô¨Åeld over the past 2 decades to solving a recursive identiÔ¨Åcation, parameter estimation and control problem of a complex system. Three speciÔ¨Åc NN architectures are investigated namely the multilayer network, simple recurrent NN and its long shortterm memory (LSTM) variants, encoded in various suitable architectures appropriate to our learning task To demonstrate the applicability and extensibility of this identi Ô¨Åcation methods, we conduct separate identiÔ¨Åcation experi ments to test the effectiveness of these modeling procedures on select SISO and MIMOsystem identiÔ¨Åcation datasets from DaISy1. II. P RELIMINARIES AND BASIC CONCEPTS The underlying principle in artiÔ¨Åcial NN models are an adaptation of the natural network of neurons originally proposed by [14], whereby each single neuron predicts an output by weighing up the evidence of ‚Äútruths‚Äù from fed inputs and shifting the gradient of the resulting function based on an additive ‚Äò bias‚Äô term; a squashing unit applies a nonlinear transformation to the linearly combined inputs to produce a desired bounded, and constant nonlinear output, ^y(t). By combining a large sum of these simple component connections across the input space and forwarding them through the layers of the network neuron nodes, we obtain a function ^fDf, which uniformly approximates the 1DaISy: Database for the IdentiÔ¨Åcation of Systems by De Moor B.L.R.‚Äù, Department of Electrical Engineering, ESAT/STADIUS, KU Leuven, Bel gium. ‚Äùhttp://homes.esat.kuleuven.be/ smc/daisy/‚ÄùarXiv:1610.01439v1  [cs.NE]  5 Oct 2016continuous function f:DfRnu!Rnyto an acceptable bounded error,jj, whereDfis a compact subset of Rnu, given that there are enough nodes in the network layers. The inputoutput relation of the system can be described by the following equation zl j(k) =f(nX i=1wl ijxil"
137,Text-Independent Speaker Verification Using Long Short-Term Memory Networks.txt,"In this paper, an architecture based on Long Short-Term Memory Networks has
been proposed for the text-independent scenario which is aimed to capture the
temporal speaker-related information by operating over traditional speech
features. For speaker verification, at first, a background model must be
created for speaker representation. Then, in enrollment stage, the speaker
models will be created based on the enrollment utterances. For this work, the
model will be trained in an end-to-end fashion to combine the first two stages.
The main goal of end-to-end training is the model being optimized to be
consistent with the speaker verification protocol. The end- to-end training
jointly learns the background and speaker models by creating the representation
space. The LSTM architecture is trained to create a discrimination space for
validating the match and non-match pairs for speaker verification. The proposed
architecture demonstrate its superiority in the text-independent compared to
other traditional methods.","The main goal of Speaker VeriÔ¨Åcation (SV) is the process of verifying a query sample belonging to a speaker utterance by comparing to the exist ing speaker models. Speaker veriÔ¨Åcation is usually split into two textindependent and textdependant categories. Textdependent includes the scenario in which all the speakers are uttering the same phrase while in textindependent no prior information is considered for what the speakers are saying. The later setting is much more challenging as it can contain numerous variations for nonspeaker in formation that can be misleading while extracting solely speaker information is desired. The speaker veriÔ¨Åcation, in general, consists of three stages: Training, enrollment, and evaluation. In training, the universal background model is trained using the gallery of speakers. In enrollment, basedon the created background model, the new speakers will be enrolled in creating the speaker model. Tech nically, the speakers‚Äô models are generated using the universal background model. In the evaluation phase, the test utterances will be compared to the speaker models for further identiÔ¨Åcation or veriÔ¨Åca tion. Recently, by the success of deep learning in applications such as in biomedical purposes [1], [2], automatic speech recognition, image recogni tion and network sparsity [3]‚Äì[6], the DNNbased approaches have also been proposed for Speaker Recognition (SR) [7], [8]. The traditional speaker veriÔ¨Åcation models such as Gaussian Mixture ModelUniversal Background Model (GMMUBM) [9] and ivector [10] have been the stateoftheart for long. The drawback of these approaches is the employed unsupervised fashion that does not optimize them for veriÔ¨Åcation setup. Recently, supervised methods proposed for model adaptation to speaker veriÔ¨Åcation such as the one presented in [11] and PLDAbased ivectors model [12]. Convolutional Neural Networks (CNNs) has also been used for speech recognition and speaker veriÔ¨Åcation [8], [13] inspired by their their superior power for action recognition [14] and scene understanding [15]. Capsule networks introduced by Hinton et al. [16] has shown quite remarkable performance in different tasks [17], [18], and demonstrated the potential and power to be used for similar purposes. In the present work, we propose the use of LSTMs by using MFCCs1speech features for di rectly capturing the temporal information of the speakerrelated information rather than dealing with 1Mel Frequency Cepstral CoefÔ¨ÅcientsarXiv:1805.00604v3  [eess.AS]  7 Sep 20182 nonspeaker information which plays no role for speaker veriÔ¨Åcation. II. R ELATED WORKS "
419,An Empirical Study on Writer Identification & Verification from Intra-variable Individual Handwriting.txt,"The handwriting of an individual may vary substantially with factors such as
mood, time, space, writing speed, writing medium and tool, writing topic, etc.
It becomes challenging to perform automated writer verification/identification
on a particular set of handwritten patterns (e.g., speedy handwriting) of a
person, especially when the system is trained using a different set of writing
patterns (e.g., normal speed) of that same person. However, it would be
interesting to experimentally analyze if there exists any implicit
characteristic of individuality which is insensitive to high intra-variable
handwriting. In this paper, we study some handcrafted features and auto-derived
features extracted from intra-variable writing. Here, we work on writer
identification/verification from offline Bengali handwriting of high
intra-variability. To this end, we use various models mainly based on
handcrafted features with SVM (Support Vector Machine) and features
auto-derived by the convolutional network. For experimentation, we have
generated two handwritten databases from two different sets of 100 writers and
enlarged the dataset by a data-augmentation technique. We have obtained some
interesting results.","\Handwriting"" is basically a kind of pattern. However, from the prehistoric era, it bears the connotation of human civilization. The handwriting instrument progressed from nger and wedge (on clay/sand and stonebased medium) to quill, pencil, fountain/ball point pen (on parchment, papyrus/paper), and again nger (on the touchscreen of a smart device). Though the world is going fast towards a paperless eworld, \handwriting remains just as vital to the enduring saga of civilization ({Michael R. Sull)"". For computer scientists, automated analysis of handwriting is a recognized eld of study owing to the everincreasing complexity of extreme variations and having positive impacts on the elds of Forensics, Biometrics, Library Science and Data Science. Email addresses: chandranath.adak@uts.edu.au (Chandranath Adak), bbcisical@gmail.com (Bidyut B. Chaudhuri), michael.blumenstein@uts.edu.au (Michael Blumenstein) Preprint submitted to January 23, 2019arXiv:1708.03361v3  [cs.CV]  20 Jan 2019Figure 1: Ideal writer identication and verication system. The handwriting pattern varies with person due to individual writing style. This may be termed as interclass variance . It is also noted that handwriting samples of a single person may vary extensively with various factors such as mood, time, space (geo graphical location), writing medium and tool. This is referred to as intraclass variance . Sometimes, these interclass and intraclass variations are termed as \betweenwriter"" and \withinwriter"" variability, respectively [43]. Even for excessive stroke variation among handwritten specimens of a particular writer, the writer and others having long exposure to his/her writing may still recognize it. Some implicit stroke characteristics may be the reason behind this ability. In the eld of forensics and biometrics, verifying/identifying a writer from a hand writing sample is sometimes essential (e.g., in the case of the \2001 anthrax attacks""). Nowadays, computerassisted automated analysis is also quite popular in this applica tion. Writer verication is a task used to authenticate a given document whether it is written by a certain individual or not. In writer identication, the goal is to match the writers to their handwriting specimens. The target of the writer identication/verication task is to maximize intervariability and to minimize intravariability. The work ow of writer identication and verication approach is shown in Fig. 1. Here, we have a database of handwritten texts with its known authors/writers. A query text sample Texti is input to the writer identication system to obtain its writerid (Writeri ) as an output with a certain degree of accuracy where the database provides support for the retrieval. In the writer verication system, two text samples Texti and Textj are fed to decide whether they are written by the \ Same "" or \ Dierent "" persons. The Texti is a query sample to be veried and the Textj may be fed from the database of known authors. In the document image analysis literature, interest has grown in the area of automated writer identication/verication for the last four decades. A detailed survey of the reported research works on this topic up to the year 1989 have been compiled in [51]. Recent advancements on writer identication/verication can be found in [55, 68]. Most of the past research work [51, 55, 68] has focused on ideal handwriting generated in normal circumstances without paying much attention to the intravariability. However, a situation may arise where an author needs to be veried based on a quickly 2(A1)  (B1) (A2)  (B2) (A3)  (B3) Figure 2: Intravariable Bengali handwritten samples, left column : (A1), (A2), (A3) samples are of Writer A,right column : (B1), (B2), (B3) samples are of WriterB. The intravariability of WriterA's samples is less compared to WriterB's samples, as conrmed by handwriting experts. written, unadorned handwritten manuscript, whereas only regular neat/clean handwriting with known authorship is available in the training database. Similar situations may occur where we need to identify the writer from unclaimed tidy handwriting, but the available database contains only careless untidy writing. In such a situation, the available writing of the person in the database and the test document written by the same individual can be highly dissimilar. In Fig. 2, two sets of intravaried handwritten sample of two individual writers are shown. Here, for example, we may need to verify whether the sample of Fig. 2.(B1) is written by WriterB, on the basis of B's handwriting of say Fig. 2.(B3). In this paper, we focus on the situation of intravariation of individual handwrit ing to perform writer identication/verication. Ideally, withinwriter variation should be less than the betweenwriter variation, which is the basis of the writer identica tion/verication task [43]. However, where the intravariation is relatively higher (refer to Fig. 2), we need to nd some handwriting features less sensitive to intravariability and more sensitive to intervariability. We have generated two sets of database of intravariable handwriting to deal with such realistic scenarios of writing identication/verication. Our database contains oine handwriting of Bengali (endonym, Bangla ) script which is a fairly complex Indic script and used by more than 250 million people [49, 10]. Recent advancements in writer identi cation on Indic scripts have been reported in [13]. The general features of Bengali script can be found in [10]. In connection with writer identication, some useful characteristics of Bengali handwriting are mentioned in [13], for example, matra/headline, delta, hole, coil shape, etc. We have noted that these Bengali handwriting characteristics along with classical handwriting characteristics (intertextline and interword gap, textline skew, word/character slant, height/width of a character, text mainbody height, character for mation, etc.) usually vary with writing. In our generated database, the intravariation is relatively higher than most of the ex isting databases in the literature [68], as conrmed by some handwriting experts. There fore, here, we need to nd some handwriting features which can decrease the intra variability and increase the intervariability. The applicability of this work is as follows. First , it will be helpful in the elds of forensics and biometrics for writer identication and verication. Second , this work studies the impact of working with absent data, i.e., when a particular type of individual writing 3is absent in the training set, how the system performs while testing with that type. Third , this work may be useful in some applications of cultural heritage and library science. When some unpublished manuscripts of a scholar are found, the authorship is usually veried [32]. Now, for the case of newlydiscovered manuscripts, if they contain some unknown writing styles of the scholar, our work may provide some insights to analyze the authorship. Fourth , this work may have a modest understanding of the progress of some diseases such as Parkinson's, Alzheimer's, Dysgraphia, Dyslexia, Tourette syndrome, etc., which aect handwriting. Here, before and after the disease progression, handwritten specimens have high intravariability and provide some applicability of our work. In this paper, we analyze the intravariable handwriting for writer identication and verication tasks. The writer identication task is perceived as an nclass classication problem to classify handwritten documents in nnumber of writer classes. On the other hand, writer verication is perceived as a binary classication, where a document is marked with \Same"" or \Dierent"" class, if it is written by the same ordierent writer of the given document, respectively. For these tasks, we extract two types of features, handcrafted and autoderived [42], from an oine handwritten text sample set. Then the extracted features are classied to identify/verify a writer. In writer identication, SVM ( Support Vector Machine ) is used for handcrafted features and some deep neural models are used for autoderived features. In writer verication, we employ some similarity metrics on handcrafted and autoderived features. Our contribution to this paper is the study of writer identication/verication on the intravariable handwriting of an individual. Such a rigorous investigation is the ear liest attempt of its type. For this study, we have generated two databases containing intravariable handwriting in a controlled and uncontrolled way. The subgrouping of the uncontrolled database with respect to intravariability is rather new. Here, the handwrit ten pages of the uncontrolled database are initially clustered with some deep features, and then nally grouped by conrmation of a classication technique which is pretrained by the controlled database. We also propose two patch selection tactics to provide the input to the deep architectures without any normalization. Moreover, two writer identication strategies are introduced here, which are relatively new. The data augmentation technique is also a new addition here with respect to the oine handwritten data. The rest of the paper is organized as follows. Section 2 discusses related work and Section 3 describes the experimental dataset generation procedure. Then Section 4 men tions the preprocessing step before entering into the methodology. After that Section 5 and Section 6 describe the handcrafted and autoderived feature extraction techniques, respectively. The writer identication procedure is discussed in Section 7, followed by Section 8 with a description of the writer verication process. The subsequent Section 9 is comprised of experimental results and discussions. Finally, Section 10 concludes this paper. 2. Related Work "
257,Building Compact and Robust Deep Neural Networks with Toeplitz Matrices.txt,"Deep neural networks are state-of-the-art in a wide variety of tasks,
however, they exhibit important limitations which hinder their use and
deployment in real-world applications. When developing and training neural
networks, the accuracy should not be the only concern, neural networks must
also be cost-effective and reliable. Although accurate, large neural networks
often lack these properties. This thesis focuses on the problem of training
neural networks which are not only accurate but also compact, easy to train,
reliable and robust to adversarial examples. To tackle these problems, we
leverage the properties of structured matrices from the Toeplitz family to
build compact and secure neural networks.","1.1 Context and Motivation . . . . . . . . . . . . . . . . . . . . . . . . . 1 1.2 Problem Statement and Contributions . . . . . . . . . . . . . . . . . 4 1.2.1 Training Compact Neural Networks . . . . . . . . . . . . . . 6 1.2.2 Training Robust Neural Networks . . . . . . . . . . . . . . . 7 2 Background 9 2.1 A Primer on Circulant and Toeplitz Matrices . . . . . . . . . . . . . 10 2.1.1 Properties of Circulant Matrices . . . . . . . . . . . . . . . . 10 2.1.2 A Fourier Representation of Toeplitz Matrices . . . . . . . . . 13 2.1.3 Block Circulant, Block Toeplitz and the Convolution Operator 15 2.1.4 LDR: General Framework for Structured Matrices . . . . . . 19 2.2 Supervised Learning and Neural Networks . . . . . . . . . . . . . . . 21 2.2.1 Introduction to Supervised Learning . . . . . . . . . . . . . . 21 2.2.2 Preliminaries on Neural Networks . . . . . . . . . . . . . . . 26 xi2.2.3 Adversarial Attacks & Robustness of Neural Networks . . . . 29 2.2.4 Recent Results on the Theory of Neural Networks . . . . . . 32 2.3 Summary of the Chapter . . . . . . . . . . . . . . . . . . . . . . . . . 36 3 Related Work 37 "
424,Learning Metrics from Mean Teacher: A Supervised Learning Method for Improving the Generalization of Speaker Verification System.txt,"Most speaker verification tasks are studied as an open-set evaluation
scenario considering the real-world condition. Thus, the generalization power
to unseen speakers is of paramount important to the performance of the speaker
verification system. We propose to apply \textit {Mean Teacher}, a temporal
averaging model, to extract speaker embeddings with small intra-class variance
and large inter-class variance. The mean teacher network refers to the temporal
averaging of deep neural network parameters; it can produces more accurate and
stable representations than using weights after the training finished. By
learning the reliable intermediate representation of the mean teacher network,
we expect that the proposed method can explore more discriminatory embedding
spaces and improve the generalization performance of the speaker verification
system. Experimental results on the VoxCeleb1 test set demonstrate that the
proposed method relatively improves performance by 11.61\%, compared to a
baseline system.","A speaker veriÔ¨Åcation (SV) task authenticates whether a speaker of an unknown input utterance matches the target speaker, and is widely utilized in applications such as a voice as sistant system [1, 2]. The SV task is mainly studied as an open set scenario that tests using the unseen speaker‚Äôs utterances dur ing training phase, which requires strong generalization perfor mance of the model [2, 3]. Several recent studies have trained deep neural networks (DNNs) using metric learningbased ob jective functions rather than classiÔ¨Åcationbased objective func tions by considering the characteristics of SV task; these sys tems have demonstrated outstanding performance in terms of openset SV evaluation [4, 5]. In [6], the authors show that by solely averaging the DNN‚Äôs weight parameters after each step in the training phase can lead to more stable and accurate results than using the Ô¨Ånal weights directly, and refer to this technique as ‚Äútemporal averaging‚Äù. By leveraging this knowledge, in the Ô¨Åeld of semisupervised learn ing, Tarvainen et al. [7] proposed a novel framework that uti lizes a temporal averaging model, called Mean Teacher (MT), to train the DNN using unlabeled data. The MT framework comprises a teacher‚Äìstudent [8] setting, wherein the teacher net work, i.e, MT, is updated with an exponential moving average (EMA) of a set of student network parameters at each training step. Thus, the student network can learn unlabeled data by re ducing the Euclidean distance from the MT network‚Äôs relatively accurate predictions. yCorresponding authorThe MT network can be regarded as a temporal ensemble model in terms of aggregating the information about the student network at each training step. This MT network provides high quality features for the student network to learn stably. From this perspective, we hypothesize that the MT network as a kind of ensemble teacher [9] can be a sufÔ¨Åcient reference model to support student network training even in the supervised learning domain. Consequently, in this study, we propose a method that can improve the generalization performance of openset SV task by adapting the MT framework in a supervised learning condi tion. To widen the representation space and improve the perfor mance of the SV system, we modify the following two factors in the existing MT framework. First, the student network directly learns the speaker embeddings output from the MT network in stead of the predictions. Second, the consistency loss function between the student and the MT network is changed to a cosine similaritybased metric learning that utilizes the negative pairs together, rather than mean square error (MSE), which considers only positive pairs. All experiments performed herein use the entire V oxCeleb2 [10] dataset as a training dataset and the V ox Celeb1 [11] test set as an evaluation dataset. As a result of the experiment, the proposed method demonstrates a relative error reduction (RER) of 11.61% compared to the baseline system. 2. Related work "
76,"General Regression Neural Networks, Radial Basis Function Neural Networks, Support Vector Machines, and Feedforward Neural Networks.txt","The aim of this project is to develop a code to discover the optimal sigma
value that maximum the F1 score and the optimal sigma value that maximizes the
accuracy and to find out if they are the same. Four algorithms which can be
used to solve this problem are: Genetic Regression Neural Networks (GRNNs),
Radial Based Function (RBF) Neural Networks (RBFNNs), Support Vector Machines
(SVMs) and Feedforward Neural Network (FFNNs).","Based on the given data set, a second data set is generated. Any training instance with a desired output >0:5is relabeled as1:0, and any training instance that has a desired output <0:5is relabeled as"
417,Rethinking White-Box Watermarks on Deep Learning Models under Neural Structural Obfuscation.txt,"Copyright protection for deep neural networks (DNNs) is an urgent need for AI
corporations. To trace illegally distributed model copies, DNN watermarking is
an emerging technique for embedding and verifying secret identity messages in
the prediction behaviors or the model internals. Sacrificing less functionality
and involving more knowledge about the target DNN, the latter branch called
\textit{white-box DNN watermarking} is believed to be accurate, credible and
secure against most known watermark removal attacks, with emerging research
efforts in both the academy and the industry.
  In this paper, we present the first systematic study on how the mainstream
white-box DNN watermarks are commonly vulnerable to neural structural
obfuscation with \textit{dummy neurons}, a group of neurons which can be added
to a target model but leave the model behavior invariant. Devising a
comprehensive framework to automatically generate and inject dummy neurons with
high stealthiness, our novel attack intensively modifies the architecture of
the target model to inhibit the success of watermark verification. With
extensive evaluation, our work for the first time shows that nine published
watermarking schemes require amendments to their verification procedures.","Nowadays, the computational and engineering costs of train ing a giant DNN model increase faster than ever [1 ‚Äì4]. As a critical asset of AI corporations, welltrained DNNs are ex posed under the risk of model stealing attacks [5 ‚Äì10], which makes the need for model copyright protection current and pressing. As a rescue, the past few years witness the emer gence of DNN watermarking [11 ‚Äì22] for tracing illegal model copies in the wild [23]. Generally, a model watermarking scheme consists of watermark embedding andveriÔ¨Åcation . At the former stage, a secret identity message, i.e., the wa termark , is Ô¨Årst embedded into the target model along with the training process. At the latter stage, the scheme veriÔ¨ÅesTable 1: Compared with existing attacks, our attack is the Ô¨Årst to disable the veriÔ¨Åcation procedures of nine stateoftheart whitebox watermarks under no requirements on utility loss, dataset access, training costs or watermark knowledge. Attack TypeAttack ClassUtility LossTraining CostDataset AccessWatermark Knowledge Pruning Parameter Finetuning Parameter Overwriting Parameter Extraction Structure Ours Structure *//denote large/moderate/no tradeoff in each dimension. the ownership according to whether the same or a similar watermark is detected from a suspect model . According to the location of the embedded message, ex isting DNN watermarks are categorized into blackbox and whitebox . Intuitively, a blackbox watermark is embedded in the model‚Äôs prediction behavior on a special set of in puts [20 ‚Äì22,24], while a whitebox watermark is embedded in the model internals, including the model parameters [11 ‚Äì17] and the neuron activation [18, 19]. The difference above also determines the required access mode to the suspect model for veriÔ¨Åcation. As suggested by Fan et al. [14], in a realworld copyright dispute, the owner may Ô¨Årst collect evidence of model piracy via a blackbox query and then attain the white box access via law enforcement for ownership veriÔ¨Åcation. SacriÔ¨Åcing less functionality and involving more informa tion for veriÔ¨Åcation, whitebox model watermarks are widely considered more comprehensive compared with the black box counterpart [12 ‚Äì14, 22], with increasingly more research efforts on toptier AI/security/system venues and from indus try leaders (e.g., Microsoft [15, 19, 25]). In a typical attack scenario, the adversary with a stolen DNN would modify the parameters or the structure of the model to frustrate the suc cess of watermark veriÔ¨Åcation [26 ‚Äì35]. To achieve the attack goal, the primary constraints for the attacker are (i) the obfus cation process should not cost more resources than training a DNN from scratch and (ii) the utility of the obfuscated model should have no clear decrease. However, as summarized in Table 1, none of the existingarXiv:2303.09732v1  [cs.CR]  17 Mar 2023approaches can balance well the cost on utility or comput ing resources for fully removing the embedded watermark. On the one hand, removal attacks by parameter modiÔ¨Åcation inevitably encounter degradation in the normal model util ity [13 ‚Äì17, 20]. Relying on the internals of the suspect model, the embedded identity messages in whitebox watermarking are much strongly connected with the model performance. Therefore, attack attempts via conventional postprocessing techniques [26, 27], which show empirical success on black box model watermarks, inevitably perturb the model param eters at an unacceptable scale to fully remove a whitebox model watermark [11 ‚Äì19]. On the other hand, existing struc tural modiÔ¨Åcation attacks apply knowledge distillation on the target model to construct a substitute model with similar performance but of different neural architecture [28,36]. How ever, they usually require additional computational resources for training the substitute model. Besides, some attacks further require the access to a domain dataset or require additional knowledge about the embedded watermark [12], which are usually impractical for attacks in the wild. Our Work. We for the Ô¨Årst time show, most of the state oftheart whitebox DNN watermarks share common vul nerabilities in their veriÔ¨Åcation procedures which assume the structural integrity of the suspect model after being obfuscated by the attacker. Our current work constructs a novel neural structural obfuscation attack which intensively modiÔ¨Åes the architecture of the victim model to disable the veriÔ¨Åcation procedures of nine previously published schemes. Meanwhile, our attack incurs no utility loss and training costs, and requires neither dataset access nor the knowledge about the embedded watermark. At the core of our newly proposed attack is the concept of dummy neurons , literally a group of neurons which can be added to a target DNN model for intensively perturbing the embedded watermark while provably leaving the model behavior invariant (i.e., the model output remains the same under the same input). A naive example is neurons which have the input and output weights of zero values, which, if added to a DNN model, have no contribution to its output. As a preliminary yet effective attack, the adversary obfuscates the protected model by injecting a number of these neurons to every neural layer, which already inhibits most of the stateof theart whitebox watermarks from being executed, but has clear limitation in its attack stealthiness (¬ß5). Alternatively, we propose a more comprehensive attack framework to automatically generate and inject dummy neu rons into a victim model, which implements bydesign stealth iness of the injected dummy neurons when the obfuscated model is under inspection. For dummy neuron generation, we propose NeuronClique andNeuronSplit , two novel structural obfuscation primitives to construct groups of dummy neurons, where the neurons are associated with nonvanishing weights but still bring no change to the model output. SpeciÔ¨Åcally, theNeuronClique primitive directly generates an arbitrary number of neurons which are assigned with weights that cancancel the others‚Äô output out, while NeuronSplit converts a neuron in the victim model into two substitute neurons which preserve the replaced neuron‚Äôs functionality (¬ß6.2). For dummy neuron injection, our proposed framework care fully designs the injection order and leverages the reciprocity between dummy neurons in successive layers to enhance the attack stealthiness (¬ß6.3). Furthermore, we leverage the scal ing invariance in DNN [37] to provide the adversary with the Ô¨Çexibility to specify the weight distribution of the dummy neurons to follow the same distribution of the original neu rons, and the shufÔ¨Çing invariance in DNN [38] to randomize the location of the injected dummy neurons among the origi nal neurons. Finally, we also introduce the kernel expansion technique to further obfuscate the weight shape of the dummy neurons, which, as the Ô¨Ånal straw, turns the victim model into a structurally irrelevant model with its original self (¬ß6.4). In ¬ß7.4, we discuss and experiment with the feasibility for a defender of different knowledge on our attack to attempt to remove the dummy neurons. Our Contributions. In summary, we mainly make the fol lowing contributions: ‚Ä¢We for the Ô¨Årst time reveal the common vulnerability of the stateoftheart whitebox DNN watermarks to neural structural obfuscation with dummy neurons. ‚Ä¢We devise a comprehensive attack framework which auto matically generates groups of dummy neurons into a pro tected model with newly proposed attack primitives. ‚Ä¢We validate the success of our attack on a wide group of DNNs protected by nine published whitebox watermarking schemes. Despite the claimed robustness, the success rate of watermark veriÔ¨Åcation is reduced to random after our attack, while the normal model utility remains the same. ‚Ä¢We also provide a study on the stealthiness of these dummy neurons and present a dummy neuron elimination algorithm. This possible defense eliminates the dummy neurons, while the original model watermark in the protected model is recovered only when the defender has access to the original watermarked model. 2 Related Work "
475,Deep Trans-layer Unsupervised Networks for Representation Learning.txt,"Learning features from massive unlabelled data is a vast prevalent topic for
high-level tasks in many machine learning applications. The recent great
improvements on benchmark data sets achieved by increasingly complex
unsupervised learning methods and deep learning models with lots of parameters
usually requires many tedious tricks and much expertise to tune. However,
filters learned by these complex architectures are quite similar to standard
hand-crafted features visually. In this paper, unsupervised learning methods,
such as PCA or auto-encoder, are employed as the building block to learn filter
banks at each layer. The lower layer responses are transferred to the last
layer (trans-layer) to form a more complete representation retaining more
information. In addition, some beneficial methods such as local contrast
normalization and whitening are added to the proposed deep trans-layer networks
to further boost performance. The trans-layer representations are followed by
block histograms with binary encoder schema to learn translation and rotation
invariant representations, which are utilized to do high-level tasks such as
recognition and classification. Compared to traditional deep learning methods,
the implemented feature learning method has much less parameters and is
validated in several typical experiments, such as digit recognition on MNIST
and MNIST variations, object recognition on Caltech 101 dataset and face
verification on LFW dataset. The deep trans-layer unsupervised learning
achieves 99.45% accuracy on MNIST dataset, 67.11% accuracy on 15 samples per
class and 75.98% accuracy on 30 samples per class on Caltech 101 dataset,
87.10% on LFW dataset.","Almost all highlayertasks such as classiÔ¨Åcation, recognition and ve riÔ¨Åcation require us to design Ô¨Åne representationsfor their speciÔ¨Åc aims. Fo r classiÔ¨Åcation of images taken from the wild, numerous factors in the environment , such as diÔ¨Äerent lighting conditions, occlusions, corruptions and deformat ions, lead to large amount of intraclass variability in images. Good representatio ns should reduce such noninformativeintraclassvariability, whilst preserv ingdiscrimina tive information acrossclasses. However, designing good feature representations is a quite tough and diÔ¨Écult procedure for pattern recognition task s, which is a hot topic in machine learning Ô¨Åeld. The research of feature representations mainly contains two asp ects, hand crafted feature designing and automatic feature learning. Resea rchers and en gineers made enormous eÔ¨Äorts to devise robust feature represe ntations at their own domains a decade ago. Many successful features are propos ed such as SIFT [1] and HoG [2] features in computer vision domain. However, th ese handcrafted features have poor transfer ability over domains. Novel features need to be redesigned elaborately when the domain of application is ch anged. The other way is representation learning, which is a quite prevalent t opic after deep learning coming out [3]. Nevertheless, these fully learned repre sentations by multilayer unsupervised learning followed by a Ô¨Ånetuning proced ure have too many parameters to be tuned, and require much expertise kno wledge and sophisticated hardware support to train a long time. In this paper, we demonstrate a novel translayer neural netwo rk with quite simple and the most classical unsupervised learning method, PCA or a uto encoder, as the building block. DiÔ¨Äerent from the PCANet [4], a one byone two layer PCA network, the responses of the previous layer of our model are concatenated to that of the last layer to form a more complete rep resentation. Such translayer connections make up the rapid information loss in t he cascade unsupervised learning eÔ¨Äectively. In addition, the local contrast n ormalization [5] and whitening are added in our translayer unsupervised networ k to boost its learning ability, which are commonly used in deep neural networks [6 ]. The diÔ¨Äerence between the implemented deep translayer unsupervise d network and conventionalnetworksisthatthedeeptranslayerunsupervise dnetworkrequires no back propagation information to Ô¨Ånetune the feature banks. Experimental results indicate that the implemented translayer co nnection scheme boosts the deep translayer unsupervised network eÔ¨Äec tively, and com monly used local contrast normalization and whitening also contribut e to the performances. The demonstrated deep translayer unsupervis ed network is val idated on digit recognition and object recognition tasks. Quite surp risingly, the stacked conventional unsupervised learning with translayer representations achieves 99.45 % accuracy on MNIST dataset, and 67.11 % accuracy on 15 samples per class and 75.98 % accuracy on 30 samples per class on Calt ech 101 dataset [7]. We will start by reviewing the related works on feature learning and r ep resentation in Section 2. Then the idea of the deep translayer uns upervised 2network, including the preprocessing and translayer unsuperv ised learning, is illustrated detailedly in Section 3. How to use the deep translayerun supervised network to extract features and tackle applications is also describ ed in Section 3. The experimental results and comparative analysis on MNIST,MNISTvari ations and Caltech 101 datasets are presented on Section 4. Finally , discussions, conclusions and the future work are summarized in Section 5 and Sec tion 6. 2. Related works "
348,Trust Aware Privacy Preserving Routing Protocol for Wireless Adhoc Network.txt,"Wireless Ad-Hoc Networks are especially helpful and quite well for essential
circumstances such as defense, public safety, and disaster recovery. MANETs
require communication privacy and security, notably in core routing protocols,
when functioning in hostile or suspicious environments. The Trust Aware
Privacy-Preserving Protocol (TAP3) is a mechanism for supporting the origin in
proactively selecting a trust-able target and doing privacy-preserving route
verification. We suggest TAP3 using the fellow recommendation model for MANETs
in this work. Nodes use their features to discover their fellow node and use
the trust to create strong connections with the random node via a multi-hop
trusting chain by identifying the secure location. The verification duties are
then spread among the nodes and validate the log updates without exposing the
nodes' details. Unlike previous models that uncover node vulnerabilities or
misconduct after an attack, TAP3 may guarantee the origin node to prevent data
from being transferred through malicious nodes from the beginning and do
verification without needing a third party. Our results show that this approach
can locate problematic nodes with minimal overhead than the conventional
routing protocol.","To improve communication mobility, fourth generation  (4G) wireless communication combines mobile ad hoc  networks (MANET) with other connections such as cell  technology, wireless personal area networks, and third  generation (3G) networks. T he primary purpose of the 4G  network is to enable mobile nodes to migrate around the  world without even being constrained by enabling  infrastructure [1 3]. The 4G systems provide one of the  newer wireless networks known as MANETs. MANET is a  mobile node ne twork that uses  multi hop wireless  transmitting and can operate without centralized  infrastructure. Because wireless ad hoc lacks a stable  infrastructure, nodes increasingly depend on fellow nodes  for interaction [4]. The nodes can configure individually a nd  construct an ad hoc architecture on the move.     Moreover, many MANET implementation situations  include functioning in dangerous conditions, implying that  assaults are either anticipated or  possible at the very  minimum  [5].  Whereas most previous work in protected  MANET route discovery concentrated on security problems,  less attention to privacy. Note that privacy doesn't mean  confidentiality of interaction (i.e., data) between many  MANET endpoints; that's also a fundamental aspect of protected MANET opera tion. Cryptography quickly acquires  suitable access control remedies to establish or maintain the  network.     Integrating MANETs to the unsecured network for web  access, on the other hand, poses significant risks and  obstacles [10,11]. Ad hoc networking technologies typically  have different compatibility than traditional internet routing  algorithms. In ad hoc netw orks, routing protocols help with  route training and management, whereas the web handles  these activities by specialized routers executing routing  algorithms. The communication between web nodes and  mobile ad hoc networks is managed by customized mobile  gates (MG) positioned at the MANET's border and linked to   the communication infrastructure and the MANET. The MG  must execute the infrastructural network's routing  mechanism and the MANET's ad hoc routing algorithm to  offer an interconnection between the two  or more networks.     Nevertheless, these previous mechanism s cannot be  employed  in the decentralized and simultaneous secure  route finding process. Initially, the dynamic routing  protocol's connection overhead typically increases as the  network size grows. In contrast, reactive routing approaches  without a safe technique will result in some transmission B. Murugeshwari et al. / IJETT, 70(9), 362370, 2022    363 errors when malicious nodes are present. Furthermore, many  routes, including AODV, DSR, and Multicast, use source  based navigation. After sending the RREQ, t he origin does  not influence data transmission until a path to the target. As  a result, various assaults, such as the black hole attack [6]  and the wormhole attack [7], might occur during the route  discovery process. Most significantly, they fail miserably  to  validate the behavior of nodes anywhere along the system's  chosen path. The source has no way of knowing whether the  subsequent routes have securely delivered the necessary  communications and performed as intended without the  participation of vicious a ttackers. The major problem for  multi path algorithms is choosing the path that decreases  node failure probability while  extending the network's  lifespan [8]. During the routing discovery step, selecting a  friendly approach and performing the verification are  required.     This study offers TAP3 confirmation in MANETs, a  dynamic direction finding exploration, and an automatic  authentication process to address the issues above.  For  starters, using active learning, TAP3 can assist the source in  discovering the  actual destination.  The method then verifies  independently  throughout the route to determine whether the  intermediary routers are fraudulent. Our dynamic training  describes a systematic selection theory [9] determining  the  multivariate vector length betw een the targeted host's  present and typical states. Apart from that can be performed  in a disseminated manner without assembling the entire  node's data. Throughout authentication, the decentralized  nodes work together to extract evidence from the route log   using preset reasoning principles. Nodes may identify  suspicious nodes upon that path from source to destination  and their actual location using the obtained proof. Finally,  TAP3 does not jeopardize the objective of saving every  node's privacy  [21]. Joini ng log tables from multiple routers  is unnecessary to browse through several network log  entries . Instead of relying on log proof acquired during the  execution stage, TAP3 uses a combination of analysis and  verification to fight attackers .  2. Related Work   "
177,Evaluating Robustness of Neural Networks with Mixed Integer Programming.txt,"Neural networks have demonstrated considerable success on a wide variety of
real-world problems. However, networks trained only to optimize for training
accuracy can often be fooled by adversarial examples - slightly perturbed
inputs that are misclassified with high confidence. Verification of networks
enables us to gauge their vulnerability to such adversarial examples. We
formulate verification of piecewise-linear neural networks as a mixed integer
program. On a representative task of finding minimum adversarial distortions,
our verifier is two to three orders of magnitude quicker than the
state-of-the-art. We achieve this computational speedup via tight formulations
for non-linearities, as well as a novel presolve algorithm that makes full use
of all information available. The computational speedup allows us to verify
properties on convolutional networks with an order of magnitude more ReLUs than
networks previously verified by any complete verifier. In particular, we
determine for the first time the exact adversarial accuracy of an MNIST
classifier to perturbations with bounded $l_\infty$ norm $\epsilon=0.1$: for
this classifier, we find an adversarial example for 4.38% of samples, and a
certificate of robustness (to perturbations with bounded norm) for the
remainder. Across all robust training procedures and network architectures
considered, we are able to certify more samples than the state-of-the-art and
find more adversarial examples than a strong first-order attack.","Neural networks trained only to optimize for training accuracy have been shown to be vulnerable toadversarial examples : perturbed inputs that are very similar to some regular input but for which the output is radically different (Szegedy et al., 2014). There is now a large body of work proposing defense methods to produce classiÔ¨Åers that are more robust to adversarial examples. However, as long as a defense is evaluated only via heuristic attacks (such as the Fast Gradient Sign Method (FGSM) (Goodfellow et al., 2015) or Carlini & Wagner (2017b)‚Äôs attack (CW)), we have no guarantee that the defense actually increases the robustness of the classiÔ¨Åer produced. Defense methods thought to be successful when published have often later been found to be vulnerable to a new class of attacks. For instance, multiple defense methods are defeated in Carlini & Wagner (2017a) by constructing defensespeciÔ¨Åc loss functions and in Athalye et al. (2018) by overcoming obfuscated gradients. Fortunately, we canevaluate robustness to adversarial examples in a principled fashion. One option is to determine (for each test input) the minimum distance to the closest adversarial example, which we call the minimum adversarial distortion (Carlini et al., 2017). Alternatively, we can determine the adversarial test accuracy (Bastani et al., 2016), which is the proportion of the test set for which no perturbation in some bounded class causes a misclassiÔ¨Åcation. An increase in the mean minimum adversarial distortion or in the adversarial test accuracy indicates an improvement in robustness.1 We present an efÔ¨Åcient implementation of a mixedinteger linear programming (MILP) veriÔ¨Åer for properties of piecewiselinear feedforward neural networks. Our tight formulation for non linearities and our novel presolve algorithm combine to minimize the number of binary variables in the MILP problem and dramatically improve its numerical conditioning. Optimizations in our MILP 1The two measures are related: a solver that can Ô¨Ånd certiÔ¨Åcates for bounded perturbations can be used iteratively (in a binary search process) to Ô¨Ånd minimum distortions. 1arXiv:1711.07356v3  [cs.LG]  18 Feb 2019Published as a conference paper at ICLR 2019 implementation improve performance by several orders of magnitude when compared to a na ¬®ƒ±ve MILP implementation, and we are two to three orders of magnitude faster than the stateoftheart SatisÔ¨Åability Modulo Theories (SMT) based veriÔ¨Åer, Reluplex (Katz et al., 2017) We make the following key contributions: We demonstrate that, despite considering the full combinatorial nature of the network, our veriÔ¨Åer cansucceed at evaluating the robustness of larger neural networks, including those with convolutional and residual layers. We identify whywe can succeed on larger neural networks with hundreds of thousands of units. First, a large fraction of the ReLUs can be shown to be either always active or always inactive over the bounded input domain. Second, since the predicted label is determined by the unit in the Ô¨Ånal layer with the maximum activation, proving that a unit never has the maximum activation over all bounded perturbations eliminates it from consideration. We exploit both phenomena, reducing the overall number of nonlinearities considered. We determine for the Ô¨Årst time the exact adversarial accuracy for MNIST classiÔ¨Åers to perturbations with bounded l1norm. We are also able to certify more samples than the stateoftheart andÔ¨Ånd more adversarial examples across MNIST and CIFAR10 classiÔ¨Åers with different architectures trained with a variety of robust training procedures. Our code is available at https://github.com/vtjeng/MIPVerify.jl . 2 R ELATED WORK "
407,One-Shot Reachability Analysis of Neural Network Dynamical Systems.txt,"The arising application of neural networks (NN) in robotic systems has driven
the development of safety verification methods for neural network dynamical
systems (NNDS). Recursive techniques for reachability analysis of dynamical
systems in closed-loop with a NN controller, planner, or perception can
over-approximate the reachable sets of the NNDS by bounding the outputs of the
NN and propagating these NN output bounds forward. However, this recursive
reachability analysis may suffer from compounding errors, rapidly becoming
overly conservative over a longer horizon. In this work, we prove that an
alternative one-shot reachability analysis framework which directly verifies
the unrolled NNDS can significantly mitigate the compounding errors for a
general class of NN verification methods built on layerwise abstraction. Our
analysis is motivated by the fact that certain NN verification methods give
rise to looser bounds when applied in one shot than recursively. In our
analysis, we characterize the performance gap between the recursive and
one-shot frameworks for NNDS with general computational graphs. The
applicability of one-shot analysis is demonstrated through numerical examples
on a cart-pole system.","Robotic systems embedding learningenabled modules such as neural network (NN) controllers, planners, or perception have achieved stateoftheart performances in various complex tasks and are becoming increasingly popular. However, such neural network dynamical systems (NNDS) lack formal safety guarantees and are prone to failures due to the fragility of NNs to adversarial attacks or random input perturbation [1,2], which signiÔ¨Åcantly limits their deployment in safetycritical applications such as autonomous driving. Verifying the safety of NNDS before deployment provides a promising solution, but handling the large scale and high complexity of NNs in veriÔ¨Åcation is challenging. Neural network veriÔ¨Åcation consists in certifying that the output of a NN satisÔ¨Åes certain properties given a bounded set of inputs. A rich body of works has focused on developing specialized solvers [3 ‚Äì11] for NN veriÔ¨Åcation. Although NN veriÔ¨Åcation methods only consider NNs in isolation, they can be conveniently combined with existing reachability analysis tools to certify properties of NNDS [12 ‚Äì14] over a Ô¨Ånite horizon. For a discretetime NNDS, NN veriÔ¨Åcation methods can readily compute an overapproximation of the onestep reachable set given a bounded input set. Then, applying such onestep overapproximation method recursively for t= 0,1,¬∑¬∑¬∑,Tleads to a bounding tube of the NNDS trajectories (blue boxes in Fig. 1). ‚àóShaoru Chen and Victor M. Preciado are with the Department of Electrical and Systems Engineering, University of Pennsylvania. Email: {srchen, preciado}@seas.upenn.edu . Mahyar Fazlyab is with the Mathematical Institute for Data Science, Johns Hopkins University. Email: mahyarfazlyab@jhu.edu .arXiv:2209.11827v2  [eess.SY]  24 Oct 2022Figure 1: Reachable set overapproximations of a NN dynamical system can be obtained by applying NN veriÔ¨Åcation methods recursively (blue arrows) or in oneshot (red arrows). In the oneshot analysis, unrolled NN dynamics over multiple time steps is considered. In this work, we investigate in what cases the oneshot analysis generates tighter bounds than the recursive counterpart. We denote the above methodology as the recursive reachability analysis framework [15 ‚Äì17], and compare it with an alternative framework that computes overapproximations of the reachable sets in one shot [18,19]. In oneshot reachability analysis , the reachable set of NNDS at time tis bounded by directly applying NN veriÔ¨Åcation methods on the unrolled NN dynamics for tsteps (red boxes in Fig. 1). While one may observe that the oneshot analysis generates tighter bounds than the recursive counterpart due to the use of iterated dynamics [18], this property does not hold for general NN veriÔ¨Åcation tools. Correspondingly, our contributions are: ‚Ä¢We provide a counterexample where oneshot analysis results in worse bounds than the recursive framework, highlighting that the oneshot analysis does not always lead to tighter bounds. ‚Ä¢We formally prove conditions under which the oneshot framework provides tighter bounds compared with the recursive framework for a general class of NN veriÔ¨Åcation methods. ‚Ä¢Our analysis applies to NNs with general architectures and allows us to consider disturbances in the computation of the reachable set overapproximations. Numerical examples are provided to demonstrate the applicability of the oneshot framework. 1.1 Related works "
0,3DVerifier: Efficient Robustness Verification for 3D Point Cloud Models.txt,"3D point cloud models are widely applied in safety-critical scenes, which
delivers an urgent need to obtain more solid proofs to verify the robustness of
models. Existing verification method for point cloud model is time-expensive
and computationally unattainable on large networks. Additionally, they cannot
handle the complete PointNet model with joint alignment network (JANet) that
contains multiplication layers, which effectively boosts the performance of 3D
models. This motivates us to design a more efficient and general framework to
verify various architectures of point cloud models. The key challenges in
verifying the large-scale complete PointNet models are addressed as dealing
with the cross-non-linearity operations in the multiplication layers and the
high computational complexity of high-dimensional point cloud inputs and added
layers. Thus, we propose an efficient verification framework, 3DVerifier, to
tackle both challenges by adopting a linear relaxation function to bound the
multiplication layer and combining forward and backward propagation to compute
the certified bounds of the outputs of the point cloud models. Our
comprehensive experiments demonstrate that 3DVerifier outperforms existing
verification algorithms for 3D models in terms of both efficiency and accuracy.
Notably, our approach achieves an orders-of-magnitude improvement in
verification efficiency for the large network, and the obtained certified
bounds are also significantly tighter than the state-of-the-art verifiers. We
release our tool 3DVerifier via https://github.com/TrustAI/3DVerifier for use
by the community.","Recent years have witnessed increasing interest in 3D object detection, and Deep Neural Networks (DNNs) have also demonstrated their remarkable performance in this area (Qi et al, 2017a,b). For 3D object detectors, the point clouds are utilized to represent 3D objects, which are usually the raw data gained from LIDARs and depth cameras. Such 3D deep learning models have been widely employed in multiple safetycritical applications such as motion planning (Varley et al, 2017), virtual reality (Stets et al, 2017), and autonomous driving (Chen et al, 2017; Liang et al, 2018). However, extensive research has shown that DNNs are vulnerable to adversarial attacks, appearing as adding a small amount of nonrandom, ideally humaninvisible, perturbations on the input will cause DNNs to make abominable predictions (Szegedy et al, 2014; Carlini and Wagner, 2017; Jin et al, 2020). Therefore, there is an urgent need to address such safety concerns on DNNs caused by adversarial examples, especially on safetycritical 3D object detection scenarios. Recently, most works on analyzing the robustness of 3D models mainly focus on adversarial attacks with an aim to reveal the model's vulnerabilities under dierent types of perturbations, such as adding or removing points, and shifting positions of points (Liu et al, 2019; Zhang et al, 2019a). In the meanwhile, adversarial defenses are also proposed to detect or prevent these adversarial attacks (Zhang et al, 2019a; Zhou et al, 2019). However, as Tramer et al (2020) and Athalye et al (2018) indicated, even though these defenses are eective for some attacks, they still can be broken by other stronger attacks . Thereby, we need a more solid solution, ideally with provable guarantees , to verify whether the model is robust to anyadversarial attacks within an allowed perturbation budget1. This technique is also generally regarded as verication on (local) adversarial robustness2in the community. So far, various solutions have been proposed to tackle robustness verication, but they mostly focus on the image domain (Boopathy et al, 2019; Singh et al, 2019; Tjeng et al, 2018; Jin et al, 2022). Verifying the adversarial robustness of 3D point cloud models, by contrast, is barely explored by the community. As far as we know, 3DCertify, proposed by Lorenz et al (2021) is the rst and also the only work to verify the robustness of 3D models. Although 3DCertify is very inspiring, it has yet completely resolved some key challenges on robustness verication for 3D models according to our empirical study. Firstly, as the rst verication tool for 3D models, 3DCertify is time consuming and thus not computationally attainable on large neural networks. As 3DCertify is built upon DeepPoly (Singh et al, 2019), when directly applying the relaxation algorithm that is specically designed for images on the high dimensional point clouds, it will result in outofmemory issues and cause the termination of the verication. Moreover, 3DCertify can only verify a simplied 1In the community, we normally use a small predened lpnorm ball to quantify such pertur bations, namely, within this small perturbing space the decision should remain the same from a perspective of a human observer. 2For convenience, we use robustness verication orverication for short in this paper.Springer Nature 2021 L ATEX template 3DVerier: Ecient Robustness Verication for 3D Point Cloud Models 3 Fig. 1 The abstract framework of the PonitNet with joint alignment network (JANet), where MLP stands for multilayer perceptron. PointNet model without Joint Alignment Network (JANet) consisting of matrix multiplication operations. Figure 1 illustrates the abstract architecture of a complete PointNet (Qi et al, 2017a), one of the most widely used models on 3D object detection. As we can see, since the learnt representations are expected to be invariant to spatial transformations, JANet is the key enabler in PointNet to achieve this geometric invariant functionality by adopting the TNet and matrix multiplications. Recent research also demonstrates that JANet is an essential for boosting the performance of PointNet (Qi et al, 2017a) and thus widely applied in some safetycritical tasks (Paigwar et al, 2019; Aoki et al, 2019; Chen et al, 2021). Thirdly, 3DCertify can only work on l1norm metric, however, arguably, some researchers in the community regard other lpnorm metrics such as l1,l2norm metrics are equally (if not more) important in the study of adversarial robustness (Boopathy et al, 2019; Weng et al, 2018). Thus, a robustness verication tool that can work on a wide range of lpnorm metrics is also worthy of a comprehensive exploration. Thus, motivated by the aforementioned challenges yet to be resolved, this paper aims to design an ecient and scalable robustness verication tool that can handle a wide range of 3D models, including those with JANet structures under multiple lpnorm metrics including l1,l1, andl2norm. We achieve the verication eciently by adapting the ecient layerbylayer certication frame work used in (Weng et al, 2018; Boopathy et al, 2019). Considering that these veriers are designed for images and cannot be applied in largerscale 3D point cloud models, we introduce a novel relaxation function of global max pooling to make it applicable and ecient on PointNet. Moreover, the multiplication layers in the JANet structure involves two variables under perturbations, which brings the crossnonlinearity. Due to the high dimensionality in 3D models, such crossnonlinearity results in signicant computational overhead for computing a tight bound. Inspired by the recent advance of certication on transformers (Shi et al, 2020), we propose closedform linear functions to bound the multi plication layer and combine forward and backward propagation to speed up the bound computation, which can be calculated in only O(1) complexity. In summary, the main contributions of this paper are listed as below. ‚Ä¢Our method can achieve an ecient verication. We design a relaxation algorithm to resolve the crossnonlinearity challenge by combining theSpringer Nature 2021 L ATEX template 4 3DVerier: Ecient Robustness Verication for 3D Point Cloud Models forward and backwards propagation, enabling an ecient yet tight verication on matrix multiplications. ‚Ä¢We design an ecient and scalable verication tool, 3DVerier, with provable guarantees. It is a general framework that can verify the robustness for a wide range of 3D model architectures, especially it can work on complete and largescale 3D models under l1,l1, andl2norm perturbations. ‚Ä¢3DVerier, as far as we know, is one of the very few works on 3D model verication, which is more advanced than the existing work, 3DCertify, in terms of eciency, scalability and tightness of the certied bounds. 2 Related Work "
310,MMA Regularization: Decorrelating Weights of Neural Networks by Maximizing the Minimal Angles.txt,"The strong correlation between neurons or filters can significantly weaken
the generalization ability of neural networks. Inspired by the well-known
Tammes problem, we propose a novel diversity regularization method to address
this issue, which makes the normalized weight vectors of neurons or filters
distributed on a hypersphere as uniformly as possible, through maximizing the
minimal pairwise angles (MMA). This method can easily exert its effect by
plugging the MMA regularization term into the loss function with negligible
computational overhead. The MMA regularization is simple, efficient, and
effective. Therefore, it can be used as a basic regularization method in neural
network training. Extensive experiments demonstrate that MMA regularization is
able to enhance the generalization ability of various modern models and
achieves considerable performance improvements on CIFAR100 and TinyImageNet
datasets. In addition, experiments on face verification show that MMA
regularization is also effective for feature learning. Code is available at:
https://github.com/wznpub/MMA_Regularization.","Although neural networks have achieved stateoftheart results in a variety of tasks, they contain redundant neurons or Ô¨Ålters due to the overparametrization issue [ 41,21], which is prevalent in networks [ 39]. The redundance can lead to catching limited directions in feature space and poor generalization performance [27]. To address the redundancy problem and make neurons more discriminative, some methods are developed to encourage the angular diversity between pairwise weight vectors of neurons or Ô¨Ålters in a layer, which can be categorized into the following three types. The Ô¨Årst type reduces the redundancy by dropping some weights and then retraining them iteratively during optimization [ 35,12,36], which suffers from complex training scheme and very long training phase. The second type is the widely used orthogonal regularization [ 38,52,23,51], which exploits a regularization term in loss function to enforce the pairwise weight vectors as orthogonal as possible. However, it has been proven that orthogonal regularization tends to group neurons closer, especially when the number of neurons is greater than the dimension [ 24], and therefore it only produces marginal improvements [ 35]. The third type also utilizes a regularization term but to encourage the weight vectors uniformly spaced through minimizing the hyperspherical potential energy [ 24,22] inspired from the Thomson problem [ 47,44]. Nonetheless, its disadvantage is that both the time complexity and the space complexity are very yThe authors are with Shenzhen Key Laboratory of Advanced Machine Learning and Applications, Guangdong Key Laboratory of Intelligent Information Processing, Institute of ArtiÔ¨Åcial Intelligence and Advanced Communication, College of Electronics and Information Engineering, Shenzhen University. zThe author is with the Institute of ArtiÔ¨Åcial Intelligence and Advanced Communication, College of Mathematics and Statistics, Shenzhen University. Corresponding author: Wenbin Zou. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.(a) baseline (b) orthogonal (c) MHE (s=0) (d) MMAfilter index filter index filter index filter indexfilter index filter index filter index filter index 0     15     30     45     60 0     15     30     45     60 0     15     30     45     60 0     15     30     45     60 0 15 30 45 600 15 30 45 600 15 30 45 601.0 0.5 0.0 0.5 1.0 0 15 30 45 60Figure 1: Comparison of Ô¨Ålter cosine similarity from the Ô¨Årst layer of VGG19BN trained on CIFAR100 with several different methods of angular diversity regularization. The number of similarity values above 0.2 is 495 (baseline), 120 (orthogonal), 51 (MHE), 0 (MMA), demonstrating the effectiveness of MMA regularization. high [ 24], and it suffers from a huge number of local minima and stationary points due to its highly nonconvex and nonlinear objective function [22]. In this paper, we propose a simple, efÔ¨Åcient, and effective method of angular diversity regularization which penalizes the minimum angles between pairwise weight vectors in each layer. Similar to the intuition of the third type mentioned above, the most diverse state is that the normalized weight vectors are distributed on a hypersphere uniformly. To model the criterion of uniformity, we employ the wellknown Tammes problem, that is, to Ô¨Ånd the arrangement of npoints on a unit sphere which maximizes the minimum distance between any two points [ 46,29,33,26,32]. However, the optimal solutions for the Tammes problem only exist for some combinations of the number of points nand dimensionsd, which are collected on the N.J.A. Sloane‚Äôs homepage [ 43], and obtaining a uniform distribution for an arbitrary combination of nanddis still an open mathematical problem [ 29]. In this paper, we propose a numerical optimization method to get approximate solutions for the Tammes problem through maximizing theminimal pairwise angles between weight vectors, named as MMA for abbreviation. We further develop the MMA regularization for neural networks to promote the angular diversity of weight vectors in each layer and thus improve the generalization performance. There are several advantages of MMA regularization: (a) As analyzed in Section 3.2, the gradient of MMA loss is stable and consistent, therefore it is easy to optimize and get near optimal solutions for the Tammes problem as shown in Table 1; (b) As veriÔ¨Åed in Table 3, the MMA regularization is easy to implement with negligible computational overhead, but with considerable performance improvements; (c) The MMA regularization is effective for both the hidden layers and the output layer, decorrelating the Ô¨Ålters and enlarging the interclass separability respectively. Therefore, it can be applied to multiple tasks, such as image classiÔ¨Åcation and face veriÔ¨Åcation demonstrated in this paper. To intuitively make sense of the effectiveness of MMA regularization, we visualize the cosine similarity of Ô¨Ålters from the Ô¨Årst layer of VGG19BN trained on CIFAR100 in Figure 1. We compare several different methods of angular diversity regularization, including orthogonal regularization in [38], MHE regularization in [ 24], and the proposed MMA regularization. The results show that the MMA regularization gets the most uncorrelated Ô¨Ålters. Besides, the MMA regularization keeps some negative correlations which have been veriÔ¨Åed to be beneÔ¨Åcial for neural networks [5]. In summary, the main contributions of this paper are threefold: We propose a numerical method for the Tammes problem, called MMA, which can get near optimal solutions under arbitrary combinations of the number of points and dimensions. We develop the novel MMA regularization which effectively promotes the angular diversity of weight vectors and therefore improves the generalization power of neural networks. Various experiments on multiple tasks show that MMA regularization is generally effective and can become a basic regularization method for training neural networks. 2 Related Work "
504,VoxWatch: An open-set speaker recognition benchmark on VoxCeleb.txt,"Despite its broad practical applications such as in fraud prevention,
open-set speaker identification (OSI) has received less attention in the
speaker recognition community compared to speaker verification (SV). OSI deals
with determining if a test speech sample belongs to a speaker from a set of
pre-enrolled individuals (in-set) or if it is from an out-of-set speaker. In
addition to the typical challenges associated with speech variability, OSI is
prone to the ""false-alarm problem""; as the size of the in-set speaker
population (a.k.a watchlist) grows, the out-of-set scores become larger,
leading to increased false alarm rates. This is in particular challenging for
applications in financial institutions and border security where the watchlist
size is typically of the order of several thousand speakers. Therefore, it is
important to systematically quantify the false-alarm problem, and develop
techniques that alleviate the impact of watchlist size on detection
performance. Prior studies on this problem are sparse, and lack a common
benchmark for systematic evaluations. In this paper, we present the first
public benchmark for OSI, developed using the VoxCeleb dataset. We quantify the
effect of the watchlist size and speech duration on the watchlist-based speaker
detection task using three strong neural network based systems. In contrast to
the findings from prior research, we show that the commonly adopted adaptive
score normalization is not guaranteed to improve the performance for this task.
On the other hand, we show that score calibration and score fusion, two other
commonly used techniques in SV, result in significant improvements in OSI
performance.","Automatic speaker recognition has received much attention in recent times owing to its ubiquitous applications in tele phone banking, customer service, virtual assistants, and smart appliances, to mention a few. In particular, speaker verifica tion (SV), which deals with determining whether a speech sample belongs to the person claiming the identity, has been explored to a large extent. This has been facilitated by sev eral open benchmarking evaluations such as the National Institute of Standards and Technology Speaker Recognition Fig. 1 : Cosine similarity score histograms for 3 different watchlist sizes. As the watchlist size grows, the outofset scores shift to the right, leading to higher false alarm rates. Evaluations (NIST SRE) [1] and V oxCeleb speaker recogni tion challenges (V oxSRC) [2]. On the other hand, openset speaker identification (OSI) which is a generalization of SV and deals with determining whether a speech sample be longs to an individual from a set of preenrolled speakers, has remained relatively underexplored. OSI has wide ap plications such as known fraudster detection in telephone banking services, group access authorization in smart home devices, audio based triaging, and speakerbased informa tion retrieval from audio archives. In particular, financial institutions often maintain a list of known fraudsters (a.k.a a ‚Äúwatchlist‚Äù) identified manually through suspicious activity detection or automatically via call/number spoofing detection [3]. Enrollment speech from these fraudsters is stored in the watchlist for comparison against incoming speech samples (from unknown speakers) to identify and prevent recidivism via negative recognition. Despite its diverse applications, made more relevant by the recent rise in fraudulent activity, much of the prior work on OSI has focused on traditional speaker modeling techniques such as Gaussian mixture mod els (GMM) [4] and ivectors[5]. Modern neural network based methods for speaker modeling have thus far received little attention for OSI applications. In addition to the challenges known for speaker recogni tion (e.g., intrinsic and extrinsic variabilities) [6], OSI suffers from the ‚Äúfalsealarm problem‚Äù which stems from a shift in the distribution of nontarget scores (test sample not from anyarXiv:2307.00169v1  [eess.AS]  30 Jun 2023of the watchlist speakers) as a function of the number of en rolled speakers (i.e., the size of the watchlist) [3, 7]. As shown in Figure 1, a larger watchlist size results in the nontarget or outofset (OOS) similarity scores shifting towards the right, leading to a larger overlap with the target (inset) scores. This leads to a higher false alarm rate at a given fixed threshold. Intuitively, as the watchlist size grows, it is more likely for an OOS speaker to sound like one of the watchlist speakers, resulting in increased false alarms. Such degradation in per formance can hinder the largescale adoption of this technol ogy, as typically such speaker spotting services are expected to work with watchlist sizes of thousands or more enrolled individuals. For comparison, in Irisbased biometrics appli cations where watchlist sizes of more than a million subjects are typical, negative recognition is performed with a very high accuracy at a relatively low false alarm rate [3]. Therefore, it is crucial to characterize the performance degradation due to the wacthlist size and develop techniques to improve this tradeoff in OSI applications. Although this problem has been previously identified in the speaker recognition community [3, 7], prior work that studied and tackled this issue is sparse, likely due to the lack of a standard publicly available benchmark. In this study, we aim to address this by creating a reproducible watchlistbased speaker detection benchmark using the V oxCeleb dataset [8]. Using this benchmark, we quantify the effect of watchlist size and speech duration on speaker detection performance. We evaluate a recent publicly available ResNet model as well as two stateoftheart models trained inhouse on the V ox Celeb dataset, demonstrating that stronger speaker discrim ination leads to improved watchlistbased detection perfor mance. However, there is a limit by which speaker discrim ination can be improved, especially using fixed amount of labelled data. Therefore, we also evaluate the effectiveness of the commonly adopted adaptive score normalization (AS Norm) as well as quality measure based score calibration. 2. RELATED WORK "
328,xCos: An Explainable Cosine Metric for Face Verification Task.txt,"We study the XAI (explainable AI) on the face recognition task, particularly
the face verification here. Face verification is a crucial task in recent days
and it has been deployed to plenty of applications, such as access control,
surveillance, and automatic personal log-on for mobile devices. With the
increasing amount of data, deep convolutional neural networks can achieve very
high accuracy for the face verification task. Beyond exceptional performances,
deep face verification models need more interpretability so that we can trust
the results they generate. In this paper, we propose a novel similarity metric,
called explainable cosine ($xCos$), that comes with a learnable module that can
be plugged into most of the verification models to provide meaningful
explanations. With the help of $xCos$, we can see which parts of the two input
faces are similar, where the model pays its attention to, and how the local
similarities are weighted to form the output $xCos$ score. We demonstrate the
effectiveness of our proposed method on LFW and various competitive benchmarks,
resulting in not only providing novel and desiring model interpretability for
face verification but also ensuring the accuracy as plugging into existing face
recognition models.","Recent years have witnessed rapid development in the area of deep learning and it has been applied to many computer vision tasks, such as image classification [ 1,14], object detection [ 28], semantic segmentation [ 32], and face verification [33],etc. In spite of the astonishing success of convolutional neural networks (CNNs), computer vision communities still lack an effective method to understand the working mechanism of deep learning models due to their inborn nonlinear structures and complicated decisionmaking process (socalled ‚Äúblack box‚Äù). Moreover, when it comes to Authors‚Äô addresses: YuSheng Lin, biolin@cmlab.csie.ntu.edu.tw, National Taiwan University, Taipei, Taiwan; ZheYu Liu, National Taiwan University, Taipei, Taiwan, zhe2325138@cmlab.csie.ntu.edu.tw; YuAn Chen, National Taiwan University, Taipei, Taiwan, r07922076@cmlab.csie.ntu.edu.tw; YuSiang Wang, University of Toronto, Toronto, Canada, yswang@cs.toronto.edu; YaLiang Chang, National Taiwan University, RonoHills, Taipei, Taiwan, yaliangchang@cmlab.csie.ntu.edu.tw; Winston H. Hsu, National Taiwan University, Taipei, Taiwan, whsu@ntu.edu.tw. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. ¬©2018 Association for Computing Machinery. Manuscript submitted to ACM Manuscript submitted to ACM 1arXiv:2003.05383v3  [cs.CV]  15 Jul 2021Woodstock ‚Äô18, June 03‚Äì05, 2018, Woodstock, NY Lin, et al. Deep Face  Verification  Backbone Cos: 0.58 Deep Face  Verification Backbone The Traditional Face Verification Framework  The Proposed xCos Face Verification Framework   xCos  module  xCos: 0.64 < S, W >F Attention map  Patched cosine map  Fig. 1. Example of ùë•ùê∂ùëúùë† framework. Traditional face verification models provide no spatial clues about why the two images are the same identity or not. The models equipped with our proposed ùë•ùê∂ùëúùë† module allow the user to visualize the similarity map between two people for each part of a face and our model cares to produce the final similarity score, ùë•ùê∂ùëúùë† (explainable cosine). The <ùëÜ,ùëä >ùêπ denotes the Frobenius inner product between ùëÜandùëä. We can see that ùë•ùê∂ùëúùë† module can be plugged into any existed deep face verification models and the existed face verification models can be more easily interpreted with our proposed ùë•ùê∂ùëúùë† . security applications (e.g., face verification for mobile screen lock), the falsepositive results for unknown reasons by deep learning models could lead to serious security and privacy issues. The aforementioned problems will make users insecure about deep learning based systems and also make developers hard to improve them. Therefore, it is crucial to increase transparency during the decisionmaking process for deep learning models. A rising field to address this issue is called explainable AI (XAI) [ 12], which attempts to empower the researcher to understand the decisionmaking process of neural nets via explainable features or decision processes. With the support of explainable AI, we can understand and trust the neural networks‚Äô prediction more. In this work, we focus on building a more explainable face verification framework with our proposed novel ùë•ùê∂ùëúùë† module. With ùë•ùê∂ùëúùë† , we can exactly know how the model determines the similarity score via examining the local similarity map and the attention map. We begin our work with a pivotal question: ‚ÄùHow can the model produce more explainable results?‚Äù To answer this question, we first investigate the pipeline of current face verification models and then introduce the intuition of the human decisionmaking process for face verification. Next, we formulate our definition of interpretability and design the explainable framework that meets our needs. Stateoftheart face verification models [ 9,21] extract deep features of a pair of face images and compute the cosine similarity or the L2distance of the paired features. Two images are said to be from the same person if the similarity is larger than a threshold value. However, with this standard procedure, we can hardly interpret these high dimensional features with our knowledge. Although some previous works [ 4,6,30] attempt to visualize the most salient features, the saliency maps produced by these methods are mostly used to locate objects in a single image rather than interpret the similarity of two faces. In contrast, our framework interprets the verification result by combining the local similarity 2xCos: An Explainable Cosine Metric for Face Verification Task Woodstock ‚Äô18, June 03‚Äì05, 2018, Woodstock, NY map and the attention map. (cf. Fig. 5) With the proposed method, we can strike a balance between verification accuracy and visual interpretability. We observe that humans usually decide whether the two face images are from the same identity by comparing their face characteristics. For instance, if two face images are from the same person, then the same parts of the two face images should be similar, including the eyes, the nose, etc. Based on this insight, we develop a novel face verification framework, ùë•ùê∂ùëúùë† , which behaves closely to our observation. Illustrated by the observation above, we define the interpretability in the face verification that the output similarity metric aims to provide not only the local similarity information but also the spatial attention of the model. Based on our definition of interpretability, we propose a similarity metric, ùë•ùê∂ùëúùë† , that can be analyzed in an explainable way. As shown in Fig. 1, we can insert our novel ùë•ùê∂ùëúùë† module1into any deep face verification networks and get two spatialinterpretable maps. Here we plug the proposed ùë•ùê∂ùëúùë† module into ArcFace [ 9] and CosFace [ 34]. The first map displays the cosine similarity of each grid feature pair, and the second one shows what the model pays attention to. With the two visualized maps, we can directly understand which grid feature pair is more similar and important for the decisionmaking process. The main contributions of this work are as follows: ‚Ä¢We address the interpretability issue in the face verification task from the perspective of local similarity and model attention, and propose a novel explainable metric, ùë•ùê∂ùëúùë† (explainable cosine) . ‚Ä¢We treat the convolution feature as the face representation, which preserves location information while remaining good verification performances. ‚Ä¢The proposed ùë•ùê∂ùëúùë† module can be plugged into various face verification models, such as ArcFace [ 9] and CosFace [34] (cf. Table 1). 2 RELATED WORK "
120,Abstract Neural Networks.txt,"Deep Neural Networks (DNNs) are rapidly being applied to safety-critical
domains such as drone and airplane control, motivating techniques for verifying
the safety of their behavior. Unfortunately, DNN verification is NP-hard, with
current algorithms slowing exponentially with the number of nodes in the DNN.
This paper introduces the notion of Abstract Neural Networks (ANNs), which can
be used to soundly overapproximate DNNs while using fewer nodes. An ANN is like
a DNN except weight matrices are replaced by values in a given abstract domain.
We present a framework parameterized by the abstract domain and activation
functions used in the DNN that can be used to construct a corresponding ANN. We
present necessary and sufficient conditions on the DNN activation functions for
the constructed ANN to soundly over-approximate the given DNN. Prior work on
DNN abstraction was restricted to the interval domain and ReLU activation
function. Our framework can be instantiated with other abstract domains such as
octagons and polyhedra, as well as other activation functions such as Leaky
ReLU, Sigmoid, and Hyperbolic Tangent.","Deep Neural Networks (DNNs), deÔ¨Åned formally in Section 3, are loo pfree com puter programs organized into layers, each of which computes a linear combi nation of the layer‚Äôs inputs, then applies some nonlinear activation function to the resulting values. The activation function used varies between n etworks, with popular activation functions including ReLU, Hyperbolic Tangent, an d Leaky ReLU [13]. DNNs have rapidly become important in a variety of applicatio ns, including image recognition and safetycritical control systems, m otivating re search into the problem of verifying properties about their behavio r [18,9]. Although they lack loops, the use of nonlinear activation functions intro ducesexponential branching behavior into theDNN semantics.It hasbeen shown that DNN veriÔ¨Åcation is NPhard [18]. In particular, this exponential behavior scales with the number of nodesin a network. DNNs in practice have very large numbers of nodes, e.g., the aircraft collisionavoidance DNN ACAS Xu [17] has 300 and a modern image recognition network has tens of thousands [20]. The2 M. Sotoudeh and A. V. Thakur number of nodes in modern networks has also been growing with time a s more eÔ¨Äective training methods have been found [3]. One increasingly common way of addressing this problem is to compres s the DNN into a smaller proxy network which can be analyzed in its place. How  ever, most such approaches usually do not guarantee that prope rties of the proxy network hold in the original network (they are unsound). Re cently, Prab hakaret al.[30] introducedthe notionof Interval Neural Networks (INNs), which can produce a smaller proxy network that is guaranteed to overapproximatethe behavior of the original DNN. While promising, soundness is only guara nteed with a particular activation function (ReLU) and abstract domain (in tervals). In this work, we introduce Abstract Neural Networks (ANNs), which are like DNNs except weight matrices are replaced with values in an abstract domain. GivenaDNNandanabstractdomain,wepresentanalgorithmforcon structinga corresponding ANN with fewer nodes. The algorithm works by mergin g groups of nodes in the DNN to form corresponding abstract nodes in the AN N. We prove necessary and suÔ¨Écient conditions on the activation functio ns used for the constructed ANN to overapproximate the input DNN. If thes e conditions are met, the smaller ANN can be soundly analyzed in place of the DNN. O ur formalization and theoretical results generalize those of Prabhak ar et al. [30], which are an instantiation of our framework for ReLU activation fun ctions and the interval domain. Our results also show how to instantiate the alg orithm such that sound abstraction can be achieved with a variety of diÔ¨Äer ent abstract domains (including polytopes and octagons) as well as many popular a ctivation functions (including Hyperbolic Tangent, Leaky ReLU, and Sigmoid). Outline In this paper, we aim to lay strong theoretical foundations for res earch into abstracting neural networks for veriÔ¨Åcation. Section 2 gives an overview of our technique. Section 3 deÔ¨Ånes preliminaries. Section 4 deÔ¨Ånes Abstract Neural Networks (ANNs). Section 5 presents an algorithm for constructing an ANN from a given DNN. Section 6 motivates our theoretical results with a number of examples. Section 7 proves our soundness theorem. Section 8 disc usses related work, while Section 9 concludes with a discussion of future work. 2 Motivation DNNs are often denoted by a graph of the form shown in Figure 1a. T he input nodex1is assigned the input value , then the values of h1andh2are computed by Ô¨Årst a linear combination of the values of the previous layer (in this casex1) followed by some nonlinear activation function. The behavior of the network is dependent on the nonlinear activation function used. We will assu me that the output layer with nodes y1,y2, andy3uses the identity activation function I(x) =x. For the hidden layer with nodes h1andh2we will consider two scenarios, each using one of the following two activation functions: œÉ(x) =/braceleftÔ£¨igg xifx‚â•0 0 otherwise.œÜ(x) =/braceleftÔ£¨igg xifx‚â•0 0.5xotherwise..Abstract Neural Networks 3 x1h1 h2y1 y2 y31 ‚àí11 1 01 0 1 (a) DNN N1x1 hy1 y2 y3[‚àí1,1][2,2] [0,2] [0,2] (b) Corresponding INNx1 hy1 y2 y30.52 2 0 (c) One instantiation of the INN Fig.1: Example DNN to INN and one of many instantiations of the INN. UsingœÉas the activation function for the hidden layer, when x1= 1 we haveh1=œÉ(1x1) = 1 and h2=œÉ(‚àí1x1) = 0. That in turn gives us y1= I(1h1+1h2) = 1,y2=I(1h1+0h2) = 1, and y3=I(0h1+1h2) = 0. UsingœÉas the activation function for the hidden layer, when x1= 1, we have h1=œÉ(1x1) = 1 h2=œÉ(‚àí1x1) = 0 y1=I(1h1+1h2) = 1y2=I(1h1+0h2) = 1y3=I(0h1+1h2) = 0. UsingœÜas the activation function for the hidden layer, when x1= 1, we have h1=œÜ(1) = 1 h2=œÜ(‚àí1) =‚àí0.5 y1= 0.5 y2= 1 y3=‚àí0.5. 2.1 Merging Nodes Our goal is to mergenodes and their corresponding weights in this DNN to produce a smaller network that overapproximates the behavior o f the original one. One way of doing this was proposed by Prabhakar et al. [30], whe re nodes within a layer can be merged and the weighted interval hull of their edge weights istaken.Forexample,ifwemergeallofthe hinodestogetherintoasingle hnode, this process results in an Interval Neural Network (INN) shown in Figure 1b. Intuitively, given this new INN we can form a DNN instantiation by picking any weight within the interval for each edge. We can then Ô¨Ånd the ou tput of this DNN instantiation on, say, x1= 1. We take the output of the INN on an inputx1to be the set of allsuch (y1,y2,y3) triples outputted by some such instantiated DNN on x1. For example, we can take the instantiation in Figure 1c. Using the œÉacti vation function, this implies ( y1= 1,y2= 1,y3= 0) is in the output set of the INN on input x1= 1. In fact, the results of Prabhakar et al. [30] show that, if theœÉactivation function is used, then for anyinputx1we will have some assignment to the weights which produces the same output as the o riginal DNN (although many assignments will produce diÔ¨Äerent outputs ‚Äî the ou tput set is anoverapproximation of the behavior of the original network).4 M. Sotoudeh and A. V. Thakur However, something diÔ¨Äerent happens if the network were using th eœÜacti vation function, a case that was not considered by Prabhakar et a l. [30]. In that scenario, the original DNN had an output of (0 .5,1,‚àí0.5), so if the INN were to soundly overapproximate it there would need to be some instant iation of the weights where y1andy3could have opposite signs. But this cannot happen ‚Äî both will have the same (or zero) sign as h! Theseexampleshighlightthefactthatthesoundnessofthealgorit hmfromPrab hakar et al. [30] is speciÔ¨Åc to the ReLU activation function ( œÉabove) and In terval abstract domain. Their results make no statement about w hether INNs overapproximate DNNs using diÔ¨Äerent activation functions (such asœÜabove), or if abstractions using diÔ¨Äerent domains (such as the Octagon Neural Networks deÔ¨Åned in DeÔ¨Ånition 11) also permit sound DNN overapproximation. ThispaperdevelopsageneralframeworkforsuchDNNabstractio ns,parame terized by the abstract domain and activation functions used. In t his framework, we prove necessary and suÔ¨Écient conditions on the activation functions for a LayerWise Abstraction Algorithm generalizing that of Prabhakar et al. [30] to produceanANNsoundlyoverapproximatingthe givenDNN. Finally, w ediscuss ways to modify the abstraction algorithm in order to soundly overa pproximate common DNN architectures that fail the necessary conditions, ex tending the applicability of model abstraction to almost all currentlyused DNNs . These results lay a solid theoretical foundation for research into A bstract Neural Networks. Because our algorithm and proofs are paramet erized by the abstract domain and activation functions used, our proofs allow pr actitioners to experiment with diÔ¨Äerent abstractions, activation functions, and optimizations without having to reprove soundness for their particular instant iation (which, as we will see in Section 7, is a surprisingly subtle process). 3 Preliminaries In this section we deÔ¨Åne Deep Neural Networks and a number of com monlyused activation functions. 3.1 Deep Neural Networks In Section 2, we represented neural networks by graphs.While this is useful for intuition, in Section 4 we will talk about, e.g., octagons of layer weight matrices , forwhichthe graphrepresentationmakessigniÔ¨Åcantlylessintuitive sense.Hence, for the rest of the paper we will use an entirely equivalent matrix representation for DNNs, which will simplify the deÔ¨Ånitions, intuition, and proofs cons iderably. With this notation, we think of nodes as dimensions and layers of nodes as intermediate spaces. We then deÔ¨Åne a layerto be a transformation from one intermediate space to another. DeÔ¨Ånition 1. ADNN layer from ntomdimensions is a tuple (W,œÉ)whereW is anm√ónmatrix and œÉ:R‚ÜíRis an arbitrarilychosen activation function .Abstract Neural Networks 5 We will often abuse notation such that, for a vector v,œÉ(v) is the vector formed by applying œÉto each component of v. DeÔ¨Ånition 2. ADeep NeuralNetwork(DNN) with layersizes s0,s1,...,s nis a collection of nDNN layers (W(1),œÉ(1)),...,(W(n),œÉ(n)), where the (W(i),œÉ(i)) layer is from si‚àí1tosidimensions. Every DNN has a corresponding function, deÔ¨Åned below. DeÔ¨Ånition 3. Given a DNN from s0tosndimensions with layers (W(i),œÉ(i)), thefunction corresponding to the DNN is the function f:Rs0‚ÜíRsngiven byf(v) =v(n), where v(i)is deÔ¨Åned inductively by v(0)=vandv(i)= œÉ(i)(W(i)(v(i‚àí1))). Where convenient, we will often refer to the corresponding funct ion as the DNN or viceversa. Example 1. The DNN N1from Figure 1a, when using the œÉhiddenlayer ac tivation function, is represented by the layers/parenleftÔ£¨ig/bracketleftÔ£¨ig 1 ‚àí1/bracketrightÔ£¨ig ,œÉ/parenrightÔ£¨ig and/parenleftbigg/bracketleftbigg1 1 1 0 0 1/bracketrightbigg ,I/parenrightbigg . The function corresponding to the DNN is given by N1(x1) =/bracketleftbigg1 1 1 0 0 1/bracketrightbigg œÉ/parenleftÔ£¨ig/bracketleftÔ£¨ig 1 ‚àí1/bracketrightÔ£¨ig [x1]/parenrightÔ£¨ig . 3.2 Common Activation Functions There are a number of commonlyused activation functions, listed b elow. DeÔ¨Ånition 4. TheLeaky RectiÔ¨Åed Linear Unit (LReLU) [22], RectiÔ¨Åed Linear Unit(ReLU), Hyperbolic Tangent (tanh), andThreshold (thresh) activation functions are deÔ¨Åned: LReLU(x;c):=/braceleftÔ£¨igg x x‚â•0 cx x <0,ReLU(x):= LReLU( x;0), tanh:=e2x‚àí1 e2x+1,thresh(x;t,v):=/braceleftÔ£¨igg xifx‚â•t votherwise. HereLReLUandthreshactually represent familiesof activation functions pa rameterized by the constants c,t,v. The constants used varies between networks. c= 0is a common choice for the LReLUparameter, hence the explicit deÔ¨Ånition ofReLU. All of these activation functions are present in standard deeplea rning toolk its,suchasPytorch[27].LibrariessuchasPytorchalsoenableuse rstoimplement new activation functions. This variety of activation functions used in practice will motivate our study of necessary and suÔ¨Écient conditions on the activation function to permit sound overapproximation.6 M. Sotoudeh and A. V. Thakur 4 Abstract Neural Networks In this section, we formalize the syntax and semantics of Abstract Neural Net works (ANNs). We also present two types of ANNs: Interval Neur al Networks (INNs) and Octagon Neural Networks (ONNs). An ANN is like a DNN except the weights in each layer are represented b y an abstract value in some abstract domain. This is formalized below. DeÔ¨Ånition 5. Ann√ómweight set abstract domain is a lattice Awith Galois connection (Œ±A,Œ≥A)with the powerset lattice P(Rn√óm)ofn√ómmatrices. DeÔ¨Ånition 6. AnANN layerfrom ntomdimensions is a triple (A,A,œÉ)where Ais a member of the weight set abstraction AandœÉ:R‚ÜíRis an arbitrarily chosenactivation function . Thus, we see that each ANN layer ( A,A,œÉ) is associated with a set of weights Œ≥A(A). Finally, we can deÔ¨Åne the notion of an ANN: DeÔ¨Ånition 7. AnAbstractNeuralNetwork(ANN)withlayersizes s0,s1,...,s n is a collection of nANN layers (A(i),A(i),œÉ(i)), where the ith layer is from si‚àí1 tosidimensions. We consider the output of the ANN to be the set of outputs of all instantia tionsof the ANN into a DNN, as illustrated in Figure 2. DeÔ¨Ånition 8. We say a DNN with layers (W(i),œÉ(i))isan instantiation of an ANNTwith layers (A(i),A(i),œÉ(i))if eachW(i)‚ààŒ≥A(i)(A(i)). The set of all DNNs that are instantiations of an ANN Tis given by Œ≥(T). The semantics of an ANN naturally lift those of the DNN instantiations . DeÔ¨Ånition 9. For an ANN Tfroms0tosndimensions, the function corre sponding to Tis the setvalued function T:Rs0‚Üí P(Rsn)deÔ¨Åned by T(v):={g(v)|g‚ààŒ≥(T)}. Spaceconstraintspreventus fromdeÔ¨Åning afull Galoisconnection here,how ever one can be established between the lattice of ANNs of a certain architecture and the powerset of DNNs of the same architecture. The deÔ¨Ånition of an ANN above is agnostic to the actual abstract do main(s) used. For expository purposes, we now deÔ¨Åne two particular type s of ANNs: Interval Neural Networks (INNs) and Octagon Neural Networks (ONNs). DeÔ¨Ånition 10. AnInterval Neural Network (INN) is an ANN with layers (A(i),A(i),œÉ(i)), where each A(i)is aninterval hull domain [5]. The interval hull domain represents sets of matrices by their componentwise interval hull. Notably, the deÔ¨Ånition of INN in Prabhakar et al. [30] is equivalent to t he above,exceptthattheyfurtherassumeeveryactivationfunct ionœÉ(i)istheReLU function.Abstract Neural Networks 7 vA(1)œÉ(1)A(2)œÉ(2)A(3)œÉ(3) v w(1,1)v(1,1) H(1,1)œÉ(1)w(1,2)v(1,2) H(1,2)œÉ(2)w(1,3)v(1,3) H(1,3)œÉ(3)‚ààT(v) v w(2,1)v(2,1) H(2,1)œÉ(1)w(2,2)v(2,2) H(2,2)œÉ(2)w(2,3)v(2,3) H(2,3)œÉ(3)‚ààT(v) v w(j,1)v(j,1) H(j,1)œÉ(1)w(j,2)v(j,2) H(j,2)œÉ(2)w(j,3)v(j,3) H(j,3)œÉ(3)‚ààT(v)......... .........=Œ≥ = Œ≥ = Œ≥ =T(v) ‚àã Fig.2: Visualization of ANN semantics for a 3layerANN T(Ô¨Årst row). DiÔ¨Äerent DNNinstantiations (other rows) of Tare formed by replacing each abstract weight matrix A(i)by some concrete weight matrix H(j,i)‚ààŒ≥(A(i)).v(j,3)is the output of each instantiation on the input v. The set of all such outputs producable by some valid instantiation is taken to be the output T(v) of the ANN on vector v. Example 2. WeÔ¨Årstdemonstratetheintervalhulldomain: Œ≥Int/parenleftÔ£¨ig/bracketleftÔ£¨ig [‚àí1,1] [0,2] [‚àí3,‚àí2] [1,2]/bracketrightÔ£¨ig/parenrightÔ£¨ig =/braceleftÔ£¨ig/bracketleftÔ£¨ig a b c d/bracketrightÔ£¨ig |a‚àà[‚àí1,1],b‚àà[0,2],c‚àà[‚àí3,‚àí2],d‚àà[1,2]/bracerightÔ£¨ig . We can thus deÔ¨Åne a two layer INN f(v):=/bracketleftbig [0,1] [0,1]/bracketrightbig ReLU/parenleftÔ£¨ig/bracketleftÔ£¨ig [‚àí1,1] [0,2] [‚àí3,‚àí2] [1,2]/bracketrightÔ£¨ig v/parenrightÔ£¨ig . We can instantiate this network in a variety of ways, for example g(v):=/bracketleftbig0.5 1/bracketrightbig ReLU/parenleftÔ£¨ig/bracketleftÔ£¨ig 0 2 ‚àí2.5 1.5/bracketrightÔ£¨ig v/parenrightÔ£¨ig ‚àà Œ≥(f). Taking arbitrarily (1 ,1)Tas an example input, we have g((1,1)T) =/bracketleftbig1/bracketrightbig ‚àà f((1,1)T). In fact, f((1,1)T) is the set of allvalues that can be achieved by such instantiations, which in this case is the set given by f((1,1)T) =/bracketleftbig [0,3]/bracketrightbig . DeÔ¨Ånition 11. AnOctagon Neural Network (ONN) is an ANN with layers (A(i),A(i),œÉ(i)), where each A(i)is anoctagon hull domain [23]. The octagon hull domain represents sets of matrices by octagons in the sp ace of their compo nents. Example 3. Octagons representing a set of n√ómmatrices can be thought of exactly like an octagon in the vector space Rn¬∑m. Unfortunately, this is partic ularly diÔ¨Écult to visualize in higher dimensions, hence in this example we will stick to the case where nm= 2. LetO1,O2be octagons such that Œ≥Oct(O1) =/braceleftbigg/bracketleftbigg a b/bracketrightbigg |a‚àíb‚â§1,‚àía+b‚â§1,a+b‚â§2,‚àía‚àíb‚â§2/bracerightbigg , Œ≥Oct(O2) =/braceleftbig/bracketleftbiga b/bracketrightbig |a‚àíb‚â§2,‚àía+b‚â§3,a+b‚â§4,‚àía‚àíb‚â§5/bracerightbig .8 M. Sotoudeh and A. V. Thakur We can thus deÔ¨Åne a twolayer ONN f(v):=O2ReLU(O1v). One instantiation of this ONN fis the DNN g(v):=/bracketleftbig3 1/bracketrightbig ReLU/parenleftÔ£¨ig/bracketleftÔ£¨ig 0.5 1.5/bracketrightÔ£¨ig v/parenrightÔ£¨ig ‚ààŒ≥(f). We can conÔ¨Årm thatg(1) =/bracketleftbig 3/bracketrightbig ‚ààf(1). We can similarly deÔ¨Åne Polyhedra Neural Networks (PNNs) using the p oly hedra domain [6]. 5 LayerWise Abstraction Algorithm Given a large DNN, how might we construct a smaller ANN which soundly overapproximates that DNN? We deÔ¨Åne overapproximation formally below. DeÔ¨Ånition 12. An ANN Toverapproximates a DNNNif, for every v‚ààRn, N(v)‚ààT(v). Remark 1. By DeÔ¨Ånition 9, then, Toverapproximates Nif, for every vwe can Ô¨Ånd some instantiation Tv‚ààŒ≥(T) such that Tv(v) =N(v). Algorithm 3 constructs a small ANN that, under certain assumption s dis cussed in Section 2, soundly overapproximates the large DNN given . The basic idea is to mergegroups of dimensions together, forming an ANN where each di mension in the ANN represents a collection of dimensions in the original DNN. We formalize the notion of ‚Äúgroups of dimensions‚Äù as a layerwise partitioning. DeÔ¨Ånition 13. Given a DNN with layer sizes s0,s1,...,s n, alayerwise parti tioningPof the network is a set of partitionings P(0),P(1),...,P(n)where each P(i)partitions {1,2,...,s i}. For ease of notation, we will write partitionings with set notation but assume they have some intrinsic ordering fo r indexing. Remark 2. To maintain the same number of input and output dimensions in our ANNandDNN,weassume P(0)={{1},{2},...,{s0}}andP(n)={{1},{2},...,{sn}}. Example 4. Consider the DNN corresponding to the function f(x1) =/bracketleftbigg1 1 1 0 0 1/bracketrightbigg ReLU/parenleftÔ£¨ig/bracketleftÔ£¨ig 1 ‚àí1/bracketrightÔ£¨ig [x1]/parenrightÔ£¨ig . The layer sizes are s0= 1,s1= 2,s2= 3. Hence, one valid layerwise partitioning is to merge the two inner dimen sions: P(0)={{1}}P(1)={{1,2}}P(2)={{1},{2},{3}}. Here we have, e.g., P(0) 1={1},P(1) 1={1,2}, andP(2) 3={3}. Our layerwise abstraction algorithm is shown in Algorithm 3. For each layer in the DNN, we will call Algorithm 1 to abstract the set of mergings of the layer‚Äôs weight matrix. This abstract element becomes the abstract weightA(i) for the corresponding layer in the constructed ANN. The functions PCMs and ScaleCols are deÔ¨Åned more precisely below. DeÔ¨Ånition 14. LetPbe some partition, i.e., nonempty subset, of {1,2,...,n}. Then a vector c‚ààRnis apartition combination vector (PCV) if (i) each component ciis nonnegative, (ii) the components of cisum to one, and (iii) ci= 0whenever i/ne}a‚äîionslash‚ààP.Abstract Neural Networks 9 Algorithm1: /hatwideŒ±(M,Pin,Pout,A) Input: MatrixM. Partitionings Pin,Poutwith|Pin|=k. Abstract domain A. Output: Abstract element representing all merges of M. 1S‚Üê{} 2w‚Üê(|Pin 1|,|Pin 2|,...,|Pin k|) 3forC‚ààPCMs(Pin)do 4forD‚ààPCMs(Pout)do 5 S‚ÜêS‚à™ {ScaleCols( DTMC,w))} 6returnŒ±A(S)Algorithm2: /hatwideŒ±bin(M,Pin,Pout,A) Input: MatrixM. Partitionings Pin,Poutwith|Pin|=k. Abstract domain A. Output: Abstract element representing all binary merges of M 1S‚Üê{} 2w‚Üê(|Pin 1|,|Pin 2|,...,|Pin k|) 3forC‚ààBinPCMs(Pin)do 4forD‚ààBinPCMs(Pout)do 5 S‚ÜêS‚à™ {ScaleCols( DTMC,w))} 6returnŒ±A(S) Algorithm 3: AbstractLayerWise /an}bracke‚äîle{‚äîA,Œ£/an}bracke‚äîri}h‚äî(N,P,A) Input: DNNNconsisting of nlayers (W(i),œÉ(i)) with each œÉ(i)‚ààŒ£. Layerwise partitioning PofN. List of nabstract weight domains A(i)‚ààA. Output: An ANN with layers ( A(i),A(i),œÉ(i)) whereA(i)‚ààA(i)‚ààA. 1A‚Üê[ ] 2fori‚àà{1,2,...,n}do 3A(i)‚Üê/hatwideŒ±(W(i),P(i‚àí1),P(i),A(i)) 4A.append/parenleftbig (A(i),A(i),œÉ(i))/parenrightbig 5returnA DeÔ¨Ånition 15. Given a partitioning Pof{1,2,...,n}with|P|=k, aparti tioning combination matrix (PCM) is a matrix C=/bracketleftbigg c1c2¬∑¬∑¬∑ck/bracketrightbigg ,where each ci is a PCV of partition Pi. We refer to the set of all such PCMs for a partitioning PbyPCMs(P). DeÔ¨Ånition 16. A PCM is binaryif each entry is either 0 or 1. We refer to the set of all binary PCMs for a partitioning PasBinPCMs( P). DeÔ¨Ånition 17. For ann√ómmatrixM,PCMCof partitioning Pinof{1,2,...,m}, and PCM Dfor partitioning Poutof{1,2,...,n}, we call DTMCamerging ofM. Thejth column in MCis a convex combination of the columns of Mthat belong to partition Pin j, weighted by the jth column of C. Similarly, the ith row inDTMis a convex combination of the rows in Mthat belong to partition Pout i. In total, the i,jth entry of merged matrix DTMCis a convexcombination of the entries of Mwith indices in Pout i√óPin j. This observation will lead to Theorem 1 in Section 5.1.10 M. Sotoudeh and A. V. Thakur DeÔ¨Ånition 18. Given a matrix M, thecolumnscaled matrix formed by weights w1,w2,...,w kis the matrix with entries given componentwise by ScaleCols( M,(w1,...,w k))i,j:=Mi,jwj. Intuitively, columnscaling is needed because what were originally ndimen sions contributing to an input have been collapsed into a single repres entative dimension. This is demonstrated nicely for the speciÔ¨Åc case of Inter val Neural Network and ReLU activations by Figures 3 and 4 in Prabhakar et al. [3 0]. Example 5. Giventhematrix M=/bracketleftÔ£¨iggm1,1m1,2m1,3 m2,1m2,2m2,3 m3,1m3,2m3,3 m4,1m4,2m4,3/bracketrightÔ£¨igg ,partitioning P(0)={{1,3},{2}} of the input dimensions and P(1)={{2,4},{1,3}}of the output dimensions, we candeÔ¨Åne aPCMfor P(0)asC:=/bracketleftbigg0.25 0 0 1 0.75 0/bracketrightbigg and aPCMfor P(1)as:D:=/bracketleftÔ£¨igg0 0.99 0.4 0 0 0.01 0.6 0/bracketrightÔ£¨igg . Wecanthencomputethe column‚Äìmerged matrix MC=/bracketleftÔ£¨igg0.25m1,1+ 0.75m1,3m1,2 0.25m2,1+ 0.75m2,3m2,2 0.25m3,1+ 0.75m3,3m3,2 0.25m4,1+ 0.75m4,3m4,2/bracketrightÔ£¨igg , and furthermore the columnrow‚Äìmerged matrix DTMC=/bracketleftÔ£¨ig 0.4(0.25m2,1+ 0.75m2,3) + 0.6(0.25m4,1+ 0.75m4,3) 0.4m2,2+ 0.6m4,2 0.99(0.25m1,1+ 0.75m1,3) + 0.01(0.25m3,1+ 0.75m3,3) 0.99m1,2+ 0.01m3,2/bracketrightÔ£¨ig . Finally, we can columnscale this matrix like so: ScaleCols( DTMC,(2,2)) =/bracketleftbigg0.8(0.25m2,1+0.75m2,3)+1.2(0.25m4,1+0.75m4,3) 0.8m2,2+1.2m4,2 1.98(0.25m1,1+0.75m1,3)+0.02(0.25m3,1+0.75m3,3) 1.98m1,2+0.02m3,2/bracketrightbigg . 5.1 Computability In general, there are an inÔ¨Ånite number of mergings. Hence, to act ually compute /hatwideŒ±(Algorithm 1) we need some nontrivial way to compute the abstrac tion of the inÔ¨Ånite set of mergings. If the abstract domain A(i)isconvex, it can be shown that one only needs to iterate over the binary PCMs, of which there are Ô¨Ånitely many, producing a computationally feasible algorithm. DeÔ¨Ånition 19. A weight set abstract domain Aisconvexif, for any set Sof concrete values, Œ≥A(Œ±A(S))is convex. Many commonlyused abstractions ‚Äî including intervals [5], octagons [23], and polyhedra [6] ‚Äî are convex. Theorem 1. IfAis convex, then /hatwideŒ±(M,Pin,Pout,A) =/hatwideŒ±bin(M,Pin,Pout,A). Proof.Please see Appendix A for the proof of this theorem. Remark 3. ConsiderPCMs CandDcorrespondingtomergedmatrix DTW(i)C. We may think of CandDas vectors in the vector space of matrices. Then their outer product D‚äóCforms a convex coeÔ¨Écient matrix of the binary mergings RAbstract Neural Networks 11 ofW(i), such that ( D‚äóC)R=DTW(i)C. From this intuition, it follows that the converse to Theorem 1 does not hold, as every matrix Ecannot be decomposed into vectors D‚äóCas described (i.e., not every matrix has rank 1). Hence, the convexity condition may be slightly weakened. However, we are not p resently aware of any abstract domains that satisfy such a condition but no t convexity. Example 6. LetW(i)=/bracketleftbigg1‚àí2 3 4‚àí5 6 7‚àí8 9/bracketrightbigg and consider P(i‚àí1)={{1,2},{3}}andP(i)= {{1,3},{2}}.ThenwehavethebinaryPCMsBinPCMs( P(i‚àí1)) =/braceleftbigg/bracketleftbigg1 0 0 0 0 1/bracketrightbigg ,/bracketleftbigg0 0 1 0 0 1/bracketrightbigg/bracerightbigg and BinPCMs( P(i)) =/braceleftbigg/bracketleftbigg1 0 0 1 0 0/bracketrightbigg ,/bracketleftbigg0 0 0 1 1 0/bracketrightbigg/bracerightbigg .These correspond to the columnscaled binary mergings/braceleftÔ£¨ig/bracketleftÔ£¨ig 2 3 8 6/bracketrightÔ£¨ig ,/bracketleftÔ£¨ig ‚àí4 3 ‚àí10 6/bracketrightÔ£¨ig ,/bracketleftÔ£¨ig 14 9 8 6/bracketrightÔ£¨ig ,/bracketleftÔ£¨ig ‚àí16 9 ‚àí10 6/bracketrightÔ£¨ig/bracerightÔ£¨ig . We can take any PCMs such as C=/bracketleftbigg0.75 0 0.25 0 0 1/bracketrightbigg forP(i‚àí1)as well as D=/bracketleftbigg0.5 0 0 1 0.5 0/bracketrightbigg forP(i), resulting in the scaled merging ScaleCols( DTW(i)C,(2,1)) =/bracketleftÔ£¨ig 3.5 6 3.5 6/bracketrightÔ£¨ig . According to Theorem 1, we can write this as a convex combination of the four columnscaled binary merged matrices. In particular, we Ô¨Ånd the co mbination /bracketleftbigg 3.5 6 3.5 6/bracketrightbigg =(1.5/2)(1)(0.5)(1)/bracketleftbigg 2 3 8 6/bracketrightbigg + (0.5/2)(1)(0.5)(1)/bracketleftbigg ‚àí4 3 ‚àí10 6/bracketrightbigg + (1.5/2)(1)(0.5)(1)/bracketleftbigg 14 9 8 6/bracketrightbigg + (0.5/2)(1)(0.5)(1)/bracketleftbigg ‚àí16 9 ‚àí10 6/bracketrightbigg . We can conÔ¨Årm that this is a convex combination, as (1.5/2)(1)(0.5)(1)+(0 .5/2)(1)(0.5)(1)+(1 .5/2)(1)(0.5)(1)+(0 .5/2)(1)(0.5)(1)= 1 . Because we can Ô¨Ånd such a convex combination for any such nonbin ary merginginterms ofthe binaryones,and becausethe abstractdom ainis assumed to be convex, including only the binary mergings will ensure that allmergings are represented by the abstract element A(i). 5.2 Walkthrough Example Example 7. Consider again the DNN from Example 4 corresponding to f(x1) =/bracketleftbigg1 1 1 0 0 1/bracketrightbigg œÉ/parenleftÔ£¨ig/bracketleftÔ£¨ig 1 ‚àí1/bracketrightÔ£¨ig [x1]/parenrightÔ£¨ig , the partitioning P(0)={{1}},P(1)={{1,2}}, P(2)={{1},{2},{3}}, which collapses the two hidden dimensions, and assume the abstract domains A(i)are all convex. For the input layer, we have w= (1), because the only partition in P(0)has size 1. Similarly, the only binary PCM for P(0)isC=/bracketleftbig1/bracketrightbig . However, there are two binary PCMs for P(1), namely D=/bracketleftÔ£¨ig 1 0/bracketrightÔ£¨ig orD=/bracketleftÔ£¨ig 0 1/bracketrightÔ£¨ig . These correspond to the binary merged matrices/bracketleftbig 1/bracketrightbig and/bracketleftbig ‚àí1/bracketrightbig . Hence, we get A(1)=Œ±A(1)({/bracketleftbig 1/bracketrightbig ,/bracketleftbig ‚àí1/bracketrightbig }), completing the Ô¨Årst layer.12 M. Sotoudeh and A. V. Thakur For the output layer, we have w= (2), because the only partition in P(1) contains twonodes. Hence, the column scaling will need to play a role: because we have merged two dimensions in the domain, we should interpret any value from that dimension as being from bothof the dimensions that were merged. We have two binary mergings, namely/bracketleftbigg1 1 0/bracketrightbigg and/bracketleftbigg1 0 1/bracketrightbigg , which after rescaling gives us A(2)=Œ±A(2)/parenleftbigg/braceleftbigg/bracketleftbigg2 2 0/bracketrightbigg ,/bracketleftbigg2 0 2/bracketrightbigg/bracerightbigg/parenrightbigg . In total then, the returned ANN can be written ( A(1),œÉ), (A(2),x/ma‚àös‚äîo‚Üíx) or in a more functional notation as g(x) =A(2)œÉ(A(1)x), where in either case A(1)=Œ±A(1)({/bracketleftbig 1/bracketrightbig ,/bracketleftbig ‚àí1/bracketrightbig }), andA(2)=Œ±A(2)/parenleftbigg/braceleftbigg/bracketleftbigg2 2 0/bracketrightbigg ,/bracketleftbigg2 0 2/bracketrightbigg/bracerightbigg/parenrightbigg . Note in particular that, while the operation of the algorithm was agno stic to the exact abstract domains Aand activation functions Œ£used, the semantics of the resulting ANN depend entirelyon these. Hence, correctness of the algorithm will depend on the abstract domain and activation functions satisfy ing certain conditions. We will discuss this further in Section 6. 6 LayerWise Abstraction: Instantiations and Examples This section examines a number of examples. For some DNNs, Algorith m 3 will produce a soundly overapproximating ANN. For others, the ANN w ill provably notoverapproximate the given DNN. We will generalize these examples t o nec essary and suÔ¨Écient conditions on the activation functions Œ£used in order for AbstractLayerWise /an}bracke‚äîle{‚äîA,Œ£/an}bracke‚äîri}h‚äî(N,P,A) to soundly overapproximate N. 6.1 Interval Hull Domain with ReLU Activation Functions ConsideragaintheDNNfromExample7givenby f(x1) =/bracketleftbigg1 1 1 0 0 1/bracketrightbigg ReLU/parenleftÔ£¨ig/bracketleftÔ£¨ig 1 ‚àí1/bracketrightÔ£¨ig [x1]/parenrightÔ£¨ig and partitioning which merges the two intermediate dimensions. Using the inter valhulldomaininExample7givesthecorrespondingINN: g(x1) =/bracketleftbigg[2,2] [0,2] [0,2]/bracketrightbigg ReLU([ [‚àí1,1]][x1]). In fact, because the ReLU activation function and interval domain was used, itfollowsfromtheresultsofPrabhakaretal.[30]that ginfactoverapproximates f. To see this, consider two cases. If x1>0, then the second component in the hiddendimensionof fwillalwaysbecome0undertheactivationfunction.Hence, f(x1) =/bracketleftbigg1 1 0/bracketrightbigg ReLU([ 1][x1]) =/bracketleftbigg2 2 0/bracketrightbigg ReLU([ 0.5][x1]), which is a valid instantiation of the weights in g. Otherwise, if x1‚â§0, we Ô¨Ånd f(x1) =/bracketleftbigg2 0 2/bracketrightbigg ReLU([ ‚àí0.5][x1]), which is again a valid instantiation. Hence in all cases, the true output f(x1) can be madeby some valid instantiationofthe weightsin g. Therefore, f(x1)‚ààg(x1) for allx1and sogoverapproximates f.Abstract Neural Networks 13 SuÔ¨Éciency Condition The soundness of this particular instantiation can be generalized to a suÔ¨Éciency theorem, Theorem 2, for soundness of the layerwise abstraction algorithm. Its statement relies on the activation func tion satisfying theweakened intermediate value property, which is deÔ¨Åned below: DeÔ¨Ånition 20. A function f:R‚ÜíRsatisÔ¨Åes the Weakened Intermediate Value Property (WIVP) if, for every a1‚â§a2‚â§ ¬∑¬∑¬∑ ‚â§an‚ààR, there exists some b‚àà[a1,an]such that f(b) =/summationtext if(ai) n. Every continuous function satisÔ¨Åes the IVP and hence the WIVP. A lmost all commonlyused activation functions, except for thresh, are c ontinuous and, therefore, satisfy the WIVP. However, the WIVP is not equivalent to the IVP, as the below proof shows by constructing a function fsuch that f((a,b)) =Q for any nonempty open interval ( a,b). Proof.Please see Appendix B for the proof of this theorem. We now state the soundness theorem below, which is proved in Sectio n 7. Theorem 2. LetAbe a set of weight set abstract domains and Œ£a set of ac tivation functions. Suppose (i) each œÉ‚ààŒ£has entirely nonnegative outputs, and (ii) each œÉ‚ààŒ£satisÔ¨Åes the Weakened Intermediate Value Property (DeÔ¨Å nition 20). Then T= AbstractLayerWise /an}bracke‚äîle{‚äîA,Œ£/an}bracke‚äîri}h‚äî(N,P,A)(Algorithm 3) soundly overapproximates the DNN N. 6.2 Interval Hull Domain with LeakyReLUs Something diÔ¨Äerent happens if we slightly modify fin Example 7 to use an activation function producing negative values in the intermediate dimensions. This is quite common of activation functions like Leaky ReLU and tanh, and was not mentioned by Prabhakar et al. [30]. For example, we will take t he Leaky ReLU function (DeÔ¨Ånition 4) with c= 0.5 and consider the DNN f(x1) =/bracketleftbigg1 1 1 0 0 1/bracketrightbigg LReLU/parenleftÔ£¨ig/bracketleftÔ£¨ig 1 ‚àí1/bracketrightÔ£¨ig [x1];0.5/parenrightÔ£¨ig .UsingthesamepartitioninggivesustheINN g(x1) = /bracketleftbigg[2,2] [0,2] [0,2]/bracketrightbigg LReLU([ [‚àí1,1]][x1];0.5). Surprisingly, this small change to the activation function in fact mak es the constructed ANN no longer overapproximate the original DNN. Fo r example, note that f(1) =/bracketleftbig0.5 1‚àí0.5/bracketrightbigTand consider g(1). Ing, the output of the LReLU is onedimensional, hence, it will have either positive, negative, or ze ro sign. But no matter how the weights in the Ô¨Ånal matrix are instantiated, ever y component ofg(1) will have the same (or zero) sign , and so f(1)/ne}a‚äîionslash‚ààg(1), because f(1) has mixed signs.14 M. Sotoudeh and A. V. Thakur Necessary Condition: NonNegative Values We can generalize this coun terexample to the following necessary condition on soundness: Theorem 3. Suppose some œÉ‚ààŒ£is an activation function with neither entirely nonnegative nor entirely nonpositive outputs, and every A‚ààAis at least as precise as the interval hull abstraction. Then there exists a neural network Nthat usesœÉand a partitioning Psuch that T= AbstractLayerWise /an}bracke‚äîle{‚äîA,Œ£/an}bracke‚äîri}h‚äî(N,P,A) does not overapproximate N. Proof.Please see Appendix C for the proof of this theorem. Handling Negative Values Thankfully, there is a workaround to support sometimesnegativeactivationfunctions.Theconstructivetheo rembelowimplies that a given DNN can be modiÔ¨Åed into a shiftedversion of itself such that the inputoutput behavior on any arbitrary bounded region is retained , but the intermediate activations are all nonnegative. Theorem 4. LetNbe a DNN and suppose that, on some input region R, the output of the activation functions are lowerbounded by a co nstantC. Then, there exists another DNN N‚Ä≤, with at most one extra dimension per layer, which satisÔ¨Åes (i) N‚Ä≤(x) =N(x)for anyx‚ààR, (ii)N‚Ä≤has all nonnegative activation functions, and (iii) the new activation functions œÉ‚Ä≤are of the form œÉ‚Ä≤(x) = max(œÉ(x)+|C|,0). Notably, the proof of this theorem is constructive with a straightforward construction. The one requirement is that a lowerbound Cbe provided for the output of the nodes in the network. This lowerbound need not be t ight, and can be computed quickly using the same procedure discussed for up per bounds immediately followingEquation1in Prabhakaret al. [30]. Fortanh in part icular, its output is always lowerbounded by ‚àí1 so we can immediately take C=‚àí1 for a network using only tanh activations. Proof.Please see Appendix D for the proof of this theorem. 6.3 Interval Hull Abstraction with NonContinuous Functio ns Another way that the constructed ANN may not overapproximat e the DNN is if the activation function does not satisfy the Weakened Interme diate Value Property(WIVP) (DeÔ¨Ånition 20). Forexample,considerthe thres holdactivation function (DeÔ¨Ånition 4) with parameters t= 1,v= 0 and the same overall network, i.e. f(x1) =/bracketleftbigg1 1 1 0 0 1/bracketrightbigg thresh/parenleftÔ£¨ig/bracketleftÔ£¨ig 1 ‚àí1/bracketrightÔ£¨ig [x1];1,0/parenrightÔ£¨ig and the same partitioning. We get the INN g(x1) =/bracketleftbigg[2,2] [0,2] [0,2]/bracketrightbigg thresh([ [‚àí1,1]][x1];1,0). We have f(1) =/bracketleftbig1 1 0/bracketrightbigT, however, in g(1), no matter how we instantiate the [ ‚àí1,1] weight, the output of the thresh unit will either be 0 or 1. But then the output of the Ô¨År st output component must be either 0 or 2, neither of which is 1, and so gdoesnotover approximate f.Abstract Neural Networks 15 Necessary Condition: WIVP Wecangeneralizethisexampletothefollowing necessary condition: Theorem 5. Suppose some œÉ‚ààŒ£is an activation function which does not sat isfy the WIVP, and every A‚ààAis at least as precise as the interval hull abstrac tion. Then there exists a neural network Nusing only the identity and œÉactiva tion functions andpartitioning Psuchthat T= AbstractLayerWise /an}bracke‚äîle{‚äîA,Œ£/an}bracke‚äîri}h‚äî(N,P,A) does not overapproximate N. Proof.Please see Appendix E for the proof of this theorem. While this is of some theoretical curiosity, in practice almost all commo nly used activation functions do satisfy the WIVP. Nevertheless, if on e does wish to use such a function, one way to soundly overapproximate it with an ANN is to replace the scalaractivation function with a setvalued one. The ANN semantics can be extended to allow picking any output value from the activation function in addition to any weight from the weight set. For example, consider again the thresh( x;1,0) activation function. It can be completed to a setvalued activation function which satisÔ¨Åes the WI VP such as thresh‚Ä≤(x;1,0):=/braceleftÔ£¨igg {x} ifx >1 {a|a‚àà[0,1]}ifx= 1 {0} otherwise. The idea is that we ‚ÄúÔ¨Åll the gap‚Äù in the graph. Whereas in the original threshold function we had an issu e because there was no x‚àà[0,1] which satisÔ¨Åed thresh( x;1,0) =f(0)+f(1) 2=1 2, on the setvalued function we can take x= 1‚àà[0,1] to Ô¨Ånd1 2‚ààthresh‚Ä≤(1;1,0). 6.4 Powerset Abstraction, ReLU, and /hatwideŒ±bin Recall that/hatwideŒ±(Algorithm 1) requires abstracting the, usuallyinÔ¨Ånite, set of all merged matrices DTW(i)C. However, in Section 5.1 we showed that for convex abstract domains it suÔ¨Éces to only consider the Ô¨Ånitelymany binarymergings. The readermay wonderif thereareabstractdomainsfor whichit is notsuÔ¨Écient to consider only the binary PCMs. This section presents such an exa mple. Suppose we use the same ReLU DNN fas in Section 6.1, for which we noted before the corresponding INN overapproximates it. However, s uppose instead of intervals we used the powerset abstract domain, i.e., Œ±(S) =SandA‚äîB= A‚à™B. If we (incorrectly) used /hatwideŒ±bininstead of/hatwideŒ±, we would get the powerset ANNg(x1) =/braceleftbigg/bracketleftbigg2 2 0/bracketrightbigg ,/bracketleftbigg2 0 2/bracketrightbigg/bracerightbigg ReLU/parenleftbig {/bracketleftbig1/bracketrightbig ,/bracketleftbig‚àí1/bracketrightbig }/bracketleftbigx1/bracketrightbig/parenrightbig . Recall that f(1) =/bracketleftbig1 1 0/bracketrightbigT. However, with g(1), the Ô¨Årst output will always be either 0 or 2, so gdoesnot overapproximate f. The basic issue is that to get the correct output, we need to instantiate the inner weight to 0 .5, which is in the convex hull of the original weights, but is not either one of the original weights itself. Note that, in this particular example, it is possible to Ô¨Ånd an ANN that o ver approximates the DNN using only Ô¨Ånite sets for the abstract weight s. However, this is only because ReLU is piecewiselinear, and the size of the sets n eeded16 M. Sotoudeh and A. V. Thakur will grow exponentially with the number of dimensions. For other activ ation functions, e.g., tanh inÔ¨Ånite sets are required in general. In general, nonconvex abstract domains will need to use some oth er method of computing an overapproximation of /hatwideŒ±. One generalpurpose option is to use techniques such as those developed for symbolic abstraction [36] to iteratively compute an overapproximation of the true A(i)and use that instead. 7 Proof of SuÔ¨Écient Conditions We now prove Theorem 2, which provides suÔ¨Écient conditions on the a cti vation functions for which Algorithm 3 produces an ANN that soundly over approximates the given DNN. The structure of the proof is illustrated in Figure 3. To show that AN NT overapproximates DNN N, we must show that N(v)‚ààT(v) for every v. This occurs, by deÔ¨Ånition, only if there exists some instantiation Tv‚ààŒ≥(T) ofTfor whichN(v) =Tv(v).RecallthataninstantiationofanANNisaDNNformedby replacingeachabstractweight A(i)with aconcreteweightmatrix H(i)‚ààŒ≥(A(i)). In particular, our proof will proceed layerbylayer. On an input v=v(0), the ith layer of DNN Nmapsv(i‚àí1)tov(i)until the output v(n)is computed. We will prove that, for each abstract layer ( A(i),œÉ(i),A(i)), there is a matrix H(i)=G(A(i),v(i‚àí1))‚ààŒ≥(A(i)) for which the instantiated layer ( H(i),œÉ(i)), roughly speaking, also maps v(i‚àí1)tov(i). However, by design the abstract layer will havefewerdimensions, hencethe higherdimensional v(i‚àí1)andv(i)maynot belong to its domain and range (respectively). We resolve this by ass ociating with each vector v(i)in the intermediate spaces of Namean representative vectorv(i) /P(i)in the intermediate spaces of Tv. Then we can rigorously prove that the instantiated layer ( H(i),œÉ(i)) mapsv(i‚àí1) /P(i‚àí1)tov(i) /P(i). Applying this fact inductively gives us Tv(v/P(0)) = (N(v))/P(n). Because P(0)andP(n) are the singleton partitionings, this gives us exactly the desired rela tionship Tv(v) =N(v). 7.1 Vector Representatives Our proof relies heavily on the concept of representatives. DeÔ¨Ånition 21. Given a vector v= (v1,v2,...,v n)and apartitioning Pof{1,2,...,n} with|P|=k, we deÔ¨Åne the convex representative set ofvunderPto be R(v,P) =/braceleftbig (z1,z2,...,z k)| ‚àÄj.minh‚ààPjvh‚â§zj‚â§maxh‚ààPjvh/bracerightbig . R(v,P) is referred to as AV(v) in Prabhakar et al. [30], and is always a box inRk. Onerepresentativewillbeparticularlyuseful,sowegiveit aspeciÔ¨Åcn otation: DeÔ¨Ånition 22. Given a vector (v1,v2,...,v n)and a partitioning Pof{1,2,...,n} with|P|=k, we deÔ¨Åne the mean representative ofvunderPto be v/P=/parenleftÔ£¨ig/summationtext j‚ààP1vj |P1|,...,/summationtext j‚ààPkvj |Pk|/parenrightÔ£¨igAbstract Neural Networks 17 v(0) v‚Ä≤(0)w(1)v(1)W(1)œÉ(1) A(1) w‚Ä≤(1)v‚Ä≤(1) H(1)œÉ(1)G/hatwideŒ±w(2)v(2)W(2)œÉ(2) A(2) w‚Ä≤(2)v‚Ä≤(2) H(2)œÉ(2)G/hatwideŒ±w(3)v(3)W(3)œÉ(3) A(3) w‚Ä≤(3)v‚Ä≤(3) H(3)œÉ(3)G/hatwideŒ± ¬∑/P(0) ¬∑/P(1) ¬∑/P(2) ¬∑/P(3) = = R(¬∑,P(1)) R(¬∑,P(2)) R(¬∑,P(3)) Fig.3: Visualization of the relationships between concrete, abstra ct, and instan tiated elements in the soundness proof. The original DNN‚Äôs action on an input vectorv(0)is shown on the top row. This DNN is abstracted to an ANN, rep resented by the A(i)s on the middle row. We will show that we can instantiate the ANN such that the instantiation has the same output as the orig inal DNN onv(0). Example 8. Consider the vector v:= (5,6,11,2,1) and the partitioning P= {{1,3},{2,4,5}}. Then we have v/P= ((5 +11) /2,(6+2+1) /3) = (8,3) and R(v,P) ={(z1,z2)|z1‚àà[5,11],z2‚àà[1,6]}. 7.2 Proof of Soundness Theorem The operation Gpresented in Algorithm 4 shows how to instantiate an abstract weight matrix such that it has input/output behavior correspondin g to that of the original DNN layer. We now prove the correctness of Algorithm 4 . Lemma 1. Given any w‚Ä≤‚ààR(Mv,Pin), a vector vwith nonnegative entries, andH=G(M,Pin,Pout,v,w‚Ä≤), thenH‚ààŒ≥(/hatwideŒ±(M,Pin,Pout))andH(v/Pin) = w‚Ä≤. Proof.To prove correctness of Algorithm 4, it suÔ¨Éces to show that (i) CandD are PCMs, and (ii) the returned matrix HsatisÔ¨Åes the equality H(v/Pin) =w‚Ä≤. Cis a PCM by construction: The ith column only has nonzero entries for rows that are in the ith partition. The sum of all entries in a column is/summationtext j‚ààPin ivj/(/summationtext k‚ààPin ivk) = 1. All entries are nonnegative by assumption on v. Dis also a PCM: The ith column only has two entries. It suÔ¨Éces to show thatDa,iis in [0,1], which follows because w‚Ä≤‚ààR(Mv,Pout) implies w‚Ä≤ iis in between the minimum band maximum a. By associativity, line 11 is equivalent to returning H=DTMEwhereE= ScaleCols( C,s). Thus, to show that H(v/Pin) =w‚Ä≤, it suÔ¨Éces to show (i) that E(v/Pin) =v, and (ii) that DTMv=w‚Ä≤. Notethat here Ej,i=Cj,i|Pin i|. Then toshow(i), consideranyindex j‚àà Pin i. Then we Ô¨Ånd that the jth output component of E(v/Pin) is (vj/(/summationtext k‚ààPin ivk))|Pin i|((/summationtext k‚ààPin ivk)/|Pin i|) =vj. Hence, the entire output vector isv. To show (ii), note that each column of Dis exactly the convex combination that produces the output w‚Ä≤ ifrom the maximum/minimum indices of Mv.18 M. Sotoudeh and A. V. Thakur Algorithm 4: G(M,Pin,Pout,v,w‚Ä≤) Input: Ann√ómmatrixM. PartitioningsPin,Pout. A vector vwith nonnegative entries. A vector w‚Ä≤‚ààR(Mv,Pout). Output: A matrix H‚ààŒ≥(/hatwideŒ±(M,Pin,Pout)) such that H(v/Pin) =w‚Ä≤. 1C,D‚Üê0|Pin|√ón,0|Pout|√óm 2fori= 1,2,...,|Pin|do 3forj‚ààPin ido 4 Cj,i‚Üêvj/(/summationtext k‚ààPin ivk) 5w‚ÜêMv 6fori= 1,2,...,|Pout|do 7a,b‚Üêargmaxp‚ààPout iwp,argminp‚ààPout iwp 8Da,i‚Üê(w‚Ä≤ i‚àíwb)/(wa‚àíwb) 9Db,i‚Üê1‚àíDa,i 10s‚Üê(|Pin 1|,...,|Pin |Pin||) 11returnScaleCols/parenleftbig DTMC,s/parenrightbig In total then, the returned matrix is in Œ≥(/hatwideŒ±(M,Pin,Pout)) and satisÔ¨Åes H(v/Pin) =w‚Ä≤. The next lemma implies that we can always Ô¨Ånd such a w‚Ä≤‚ààR(Mv,Pin) satisfying the relations in Figure 3. Lemma 2. LetœÉbe an activation function satisfying the WIVP, wany vector, andPa partitioning the dimensions of w. Then there exists a vector w‚Ä≤‚ààR(w,P)such that œÉ(w‚Ä≤) = (œÉ(w))/P. Proof.BecauseœÉ(i)isdeÔ¨Ånedtobeacomponentwiseactivationfunction,wecan assume WLOG that P(i)has only a single partition, i.e., P(i)={{1,2,...,s(i)}}. In that case, label the components of w(i)such that w(i) 1‚â§w(i) 2‚â§...‚â§w(i) n. Then the statement of the lemma is equivalent to the assertion that there exists someb‚àà[w(i) 1,w(i) n] such that œÉ(i)(b) = (/summationtext jw(i) j)/n. But this is exactly the deÔ¨Ånition of the WIVP. Hence, by assumption that œÉ(i)satisÔ¨Åes the WIVP, we complete the proof. We are Ô¨Ånally prepared to prove the soundness theorem. It is rest ated here for clarity. Theorem 2. LetAbe a set of weight set abstract domains and Œ£a set of ac tivation functions. Suppose (i) each œÉ‚ààŒ£has entirely nonnegative outputs, and (ii) each œÉ‚ààŒ£satisÔ¨Åes the Weakened Intermediate Value Property (DeÔ¨Å nition 20). Then T= AbstractLayerWise /an}bracke‚äîle{‚äîA,Œ£/an}bracke‚äîri}h‚äî(N,P,A)(Algorithm 3) soundly overapproximates the DNN N.Abstract Neural Networks 19 Proof.A diagram of the proof is provided in Figure 3. Considerthe ithlayer.ByLemma2,thereexistssomevector w‚Ä≤(i)‚ààR(w(i),P(i)) such that œÉ(i)(w‚Ä≤(i)) =v/P(i). Furthermore, by Lemma 1 there exists some H(i)‚ààŒ≥(A(i)) such that H(i)(v(i‚àí1) /P(i‚àí1)) =w‚Ä≤(i). Therefore, in total we can instantiate the ith abstract layer to ( H(i),œÉ(i)), which maps v(i‚àí1) /P(i‚àí1) tov(i) /P(i). By applying this construction to each layer, we Ô¨Ånd an instantiation o f the ANN that maps v(0) /P(0)tov(n) /P(n). Assuming P(0)andP(n)are the singleton partitionings,then,wehavethattheinstantiationmaps v(0)=vtov(n)=N(v), as hoped for. Hence, N(v)‚ààT(v) for any such vector v, and so the ANN overapproximates the original DNN. 8 Related Work "
296,Leveraging Expert Models for Training Deep Neural Networks in Scarce Data Domains: Application to Offline Handwritten Signature Verification.txt,"This paper introduces a novel approach to leverage the knowledge of existing
expert models for training new Convolutional Neural Networks, on domains where
task-specific data are limited or unavailable. The presented scheme is applied
in offline handwritten signature verification (OffSV) which, akin to other
biometric applications, suffers from inherent data limitations due to
regulatory restrictions. The proposed Student-Teacher (S-T) configuration
utilizes feature-based knowledge distillation (FKD), combining graph-based
similarity for local activations with global similarity measures to supervise
student's training, using only handwritten text data. Remarkably, the models
trained using this technique exhibit comparable, if not superior, performance
to the teacher model across three popular signature datasets. More importantly,
these results are attained without employing any signatures during the feature
extraction training process. This study demonstrates the efficacy of leveraging
existing expert models to overcome data scarcity challenges in OffSV and
potentially other related domains.","  A signature is a handwritten symbol put on a document, a piece of paper or other material that allows  authenticating someone‚Äôs identity and consent.  Although there are findings from Sumerian civilization  using words and symbols to denote identity , the legal usage of signature s grew in Europe  during t he 16th  century with the voted Act of Statute of Frauds , which stipulated  that contracts must exist in writing and  bear a signature , and became a standard form around the world  since it adopted in colonial America ( by  the time J. Hancock placed his signature in the United States Declaration of Independence ) for validating  agreements . Nowadays, the determination of authenticity through signatures is employed  in many  sectors to ensure the security of financial and lega l documents ranging from bank and compliance forms  to contracts and mail ballots. While m anual signature comparison  seems like  an ineffective way to handle  the masses of documents that need to be checked  in a small amount of time , automatic  handwritten  signature verification systems (HSV) are pivotal to reduce fraud . A HSV system  authenticates the person ‚Äôs  identity on the basis of the claimed identity , meaning that detect s authenticity  (i.e., the questioned  signature  owns  to the claimed writer and thus it i s genuine)  or whether the signature  has been provided  from anyone else and thus it is forgery .    According to the acquisition conditions, signature verification is divided into offline (static) and online  (dynamic). Offline Signature Verification (OffSV) analyz es only the shape (visual information)  of the  signature after the writing process, typically using a digitized version of the signing document , while  Online Signature Verification (OnSV) requires a digitizing device (such as electronic tablets) and c ollects  additional information  during signing, like pen inclination, pressure, spatial coordinates, etc. (Plamondon  & Lorette, //) . Hence, in the first case , the signature is represented as a static ( digital ) image , making the   OffSV a very challenging problem due to the luck of dynamic measurements . On the other,  it is more  practical than OnSV because the latter involves rushed, abnormal , and device depending operations that  might decrease the trustworth iness  of the produced signatures (Impedovo & Pirlo, 2008) .    Depending on the signature verification design plan , there are two main approaches: writer dependent  (WD) and writer independent (WI). WD methods build one model per user and WI appr oach uses one  single (global) model for all user s. Given that , a typical HSV system comprises of three main stages: data  acquisition and preprocessing (for noise removal), feature extraction, and classification ( decision on   authenticity) , some stages could follow the WD approach and others the WI approach , leading to hybrid  systems.  Thus, a characterization of a HSV system as WD or WI is often not easy, especially when complex  deep learning schemes are utilized, which  commonly consist of WI preprocessi ng and WI feature  extraction stages along with WD classification (Diaz et al., 2019) . The WI methods usually take advantage  "
136,Learning Ability of Interpolating Convolutional Neural Networks.txt,"It is frequently observed that overparameterized neural networks generalize
well. Regarding such phenomena, existing theoretical work mainly devotes to
linear settings or fully connected neural networks. This paper studies learning
ability of an important family of deep neural networks, deep convolutional
neural networks (DCNNs), under underparameterized and overparameterized
settings. We establish the best learning rates of underparameterized DCNNs
without parameter restrictions presented in the literature. We also show that,
by adding well defined layers to an underparameterized DCNN, we can obtain some
interpolating DCNNs that maintain the good learning rates of the
underparameterized DCNN. This result is achieved by a novel network deepening
scheme designed for DCNNs. Our work provides theoretical verification on how
overfitted DCNNs generalize well.","Neural networks are computing systems with very powerful applications in many disciplines such as data analysis, pat tern and sequence recognition. In particular, deep neural networks with welldesigned structures, numerous trainable free parameters and massivescale input data have outstanding performance in function approximation, classiÔ¨Åcation, and feature extraction [1, 2, 3]. The success of deep neural networks in practice has motivated research activities intended to rigorously explain its capability and power, in addition to the literature on shallow neural networks [4]. Given that neural networks in general are powerful and versatile, researchers have been working to further improve their computational efÔ¨Åciency. When the data dimension is large such as the AlexNet [5] of input dimension about 150;000, fully connected neural networks are not feasible. Structures are often imposed on neural networks to rearXiv:2210.14184v1  [stat.ML]  25 Oct 2022Learning Ability of Interpolating Convolutional Neural Networks A P REPRINT duce the data dimension and get feasible deep learning algorithms for various practical tasks [6]. The structure we are interested in is induced by onedimensional convolution (1D convolution) and the resulting networks are deep convolutional neural networks (DCNNs) [7]. The convolutional structure of DCNNs reduces the computational com plexity and is believed to capture local shiftinvariance properties of image and speech data. Such features of DCNNs contributes to the huge popularity of DCNNs in image processing and speech recognition. It is frequently observed that overparameterized deep neural networks, such as DCNNs, generalize well while achiev ing zero training error [8, 9, 10, 11]. This phenomenon, known as benign overÔ¨Åtting, seems to confront the classical biasvariance tradeoff in statistical theory. Such mismatch between observations and classical theory sparkled avid research work attempting to understand how benign overÔ¨Åtting occurs. Theoretical work studying benign overÔ¨Åtting was initiated in [12], where a linear regression setting with Gaussian data and noise was considered. It presented conditions for minimumnorm interpolator to generalize well. In a nonlinear setting induced by ReLU activation function, benign overÔ¨Åtting is veriÔ¨Åed for deep fully connected neural network in [13]. In this paper, we study the learning ability of DCNNs under underparameterized and overparameterized settings. We aim to show that an overparameterized DCNN has the same convergence rate as an underparameterized one, while perfectly Ô¨Åts the input data. In other words, we intent on proving that interpolating DCNNs generalize well. The main contributions of the paper are as follows. Our Ô¨Årst result rigorously proves that for an arbitrary DCNN with good learning rates, possibly underparameterized, we can add more layers to build overparameterized DCNNs satisfying the interpolation condition while retaining good learning rates. Our second result establishes learning rates of DCNNs in general. Previously in [14], rates of approximation by DCNNs for functions in some Sobolev spaces were given. Moreover, learning rates of DCNNs were given in [15] where the bias vectors and Ô¨Ålters are assumed to be bounded, with bounds depending on the target function space. Unlike this existing work, the learning rates we derived does not require any restrictions on the bias vectors or Ô¨Ålters. Without boundedness of free parameters, the standard covering number arguments do not apply. To overcome such challenge, we make use of the special estimate of the pseudodimension of the induced hypothesis space given in [16], as well as the piecewise linear property of ReLU. This pseudodimension estimate can in turn bounds the empirical covering number of the hypothesis space. In such way, we can achieve our results without restrictions on free parameters. Combining our Ô¨Årst and second results, we prove that for any input data, there exists some overÔ¨Åtted DCNNs which interpolate the data, and achieves a good learning rate. This result provides theoretical support of the possible existence of benign overÔ¨Åtting under the DCNN setting, as we veriÔ¨Åed a necessary condition of the phenomenon of the benign overÔ¨Åtting. The rest of this paper is organized as follows. In Section 2, we introduce notations and deÔ¨Ånitions used throughout the paper, including the deÔ¨Ånition of DCNNs to be studied. In Section 3, we present our main results that describe how a DCNN achieves benign overÔ¨Åtting. The proof of our Ô¨Årst result is given in Section 4, and the proofs of our second and third results are given in Section 5. In Section 6, we present the results of numerical experiments which corroborate our theoretical Ô¨Åndings. Lastly in Section 7, we present some discussions and compare our work with the existing literature. 2 Problem Formulation In this section, we deÔ¨Åne the DCNNs to be studied in this paper and the corresponding hypothesis space (Section 2.1). Then, we deÔ¨Åne the data and the regression function (Section 2.2). 2Learning Ability of Interpolating Convolutional Neural Networks A P REPRINT 2.1 Deep Convolutional Neural Networks and the corresponding Hypothesis Space To begin with, we formulate the 1D convolution. Let w=fwjg+1 j="
386,Deep Transparent Prediction through Latent Representation Analysis.txt,"The paper presents a novel deep learning approach, which extracts latent
information from trained Deep Neural Networks (DNNs) and derives concise
representations that are analyzed in an effective, unified way for prediction
purposes. It is well known that DNNs are capable of analyzing complex data;
however, they lack transparency in their decision making, in the sense that it
is not straightforward to justify their prediction, or to visualize the
features on which the decision was based. Moreover, they generally require
large amounts of data in order to learn and become able to adapt to different
environments. This makes their use difficult in healthcare, where trust and
personalization are key issues. Transparency combined with high prediction
accuracy are the targeted goals of the proposed approach. It includes both
supervised DNN training and unsupervised learning of latent variables extracted
from the trained DNNs. Domain Adaptation from multiple sources is also
presented as an extension, where the extracted latent variable representations
are used to generate predictions in other, non-annotated, environments.
Successful application is illustrated through a large experimental study in
various fields: prediction of Parkinson's disease from MRI and DaTScans;
prediction of COVID-19 and pneumonia from CT scans and X-rays; optical
character verification in retail food packaging.","Over the last few years, Deep Learning (DL) and Deep Neural Networks (DNNs) have been successfully applied to numerous applications and domains due to the availability of large amounts of labeled data, including healthcare prediction, visual analysis and recognition [9,16,6]. Transfer learning (TL) [30] has been the main approach to train Deep Neural Networks when only small amounts of annotated data are available. TL uses networks previously trained with large datasets (even of generic patterns) and netunes the whole, or parts of them, using the small training datasets. AarXiv:2009.07044v2  [cs.LG]  20 Sep 20202 Kollias et al. serious problem is related to TL: as the DNN learns to make predictions in the new dataset, it tends to forget the old data that are not used in the retraining procedure; this is known as `catastrophic forgetting'. Moreover, when deploying a pretrained model to a reallife application, the assumption is that both the source (training set) and the target (applicationspecic) one are drawn from the same distribution. When this assumption is violated, the DL model trained on the source domain will not generalize well on the target domain due to the distribution dierences between the two domains; this is known as domain shift. Learning a discriminative model in the presence of domain shift between target datasets is known as Domain Adaptation (DA) [21] and is targeted when dealing with nonannotated data. Recent research has focused on extracting trained DNN representations and using them for classication purposes [4], either by an autoencoder methodology, or by monitoring neuron outputs in the convolutional or/and fully connected network layers [32,15]. Such developments are exploited in this paper, proposing a novel approach that is able to generate unied prediction models, providing transparency and visualization of their decision making process in a variety of application domains. At rst, we extract appropriate internal features, say features v, from a DNN model trained with some dataset of interest. Using a clustering methodology, we generate concise representations, say c, of these features. Using these representations and the nearest neighbour criterion, we can then predict, in an ecient and transparent way, the class of new data. Combining DNN training and clustering has been a topic of recent research. Surveys, focusing on dierent clustering methodologies and dierent combina tion ways can be found in [1,22]; specic combinations can also be found in [33,34,13]. Here, our aim is to derive the unied latent representation and predic tion framework, illustrating its successful use, especially in medical applications. The framework of interweaving DNNs and clustering has also been examined in our former publication [17]. Next, we present a new methodology that alleviates the `catastrophic forget ting' problem by generating a unied model over dierent datasets. According to this methodology, we apply the originally trained DNN to a new dataset deriv ing a corresponding set of representations, through which we train a new DNN. From the latter DNN, we extract a new set of features, say v0and a concise representation c0. A unied prediction model is then produced by merging the candc0representation sets. Having achieved high precision and recall metrics in the derivation of each one of these representations ensures that the generated unied model provides high prediction accuracy in the derived representation space. This alternative prediction is of great signicance in the case of new non annotated data, since it provides a transparent way for prediction; it is shown that it can also create richer representations of the prediction problem. We then use the extracted latent variable representations from trained DNNs in multiple sources, so as to generate predictions in other environments. The proposed methodology is applied to a variety of applications, focusing on medical imaging for healthcare, but also on other applications where imageDeep Transparent Prediction 3 analysis is used for anomaly prediction. In the latter case we focus on quality control in retail food packaging, based on real images provided by large super markets [24]. In the former case we focus: a) on prediction of Parkinsons, based on datasets of MRI and DaTScans, either created in collaboration with the Georgios Gennimatas Hospital (GGH) in Athens [29], or provided by the PPMI study sponsored by M. J. Fox for Parkinsons Research [20], b) on prediction of COVID19, based on CT chest scans and xrays, either public, or aggregated by GRNET in collaboration with the Hellenic Ministry of Health. The novel contributions of the paper are the following: i) we develop a novel unsupervised learning approach, extracting latent variables from trained DNNs, which, after appropriate clustering, provide unied concise representations that can be analyzed in an ecient and transparent way for prediction; ii) each con cise representation set is linked to the respective input data (i.e., medical images, or scans, or other information); we are, therefore, able to show  to the (medical) experts and users/patients  which were the main (similar) cases on which the provided prediction/diagnosis was based. It is then up to the experts/users to decide whether they trust (this basis of) the diagnosis, or not; iii) we present a DA framework, from multiple sources, which uses DNNs and extracted rep resentations from annotated datasets, so as to generate predictions in other, nonannotated data, collected in dierent environments; ii) we apply the pro posed approach to the following application domains: i) for unied Parkinson's disease prediction, over dierent datasets, based on medical imaging, ii) for ef fective prediction of COVID19 from CT chest scan series, or from xrays, iii) for optical character verication on food retail packaging, based on DA among dierent datasets. 2 Related work "
262,Overview of CheckThat! 2020: Automatic Identification and Verification of Claims in Social Media.txt,"We present an overview of the third edition of the CheckThat! Lab at CLEF
2020. The lab featured five tasks in two different languages: English and
Arabic. The first four tasks compose the full pipeline of claim verification in
social media: Task 1 on check-worthiness estimation, Task 2 on retrieving
previously fact-checked claims, Task 3 on evidence retrieval, and Task 4 on
claim verification. The lab is completed with Task 5 on check-worthiness
estimation in political debates and speeches. A total of 67 teams registered to
participate in the lab (up from 47 at CLEF 2019), and 23 of them actually
submitted runs (compared to 14 at CLEF 2019). Most teams used deep neural
networks based on BERT, LSTMs, or CNNs, and achieved sizable improvements over
the baselines on all tasks. Here we describe the tasks setup, the evaluation
results, and a summary of the approaches used by the participants, and we
discuss some lessons learned. Last but not least, we release to the research
community all datasets from the lab as well as the evaluation scripts, which
should enable further research in the important tasks of check-worthiness
estimation and automatic claim verification.","The CheckThat! lab1was run for the third time in the framework of CLEF 2020. The purpose of the 2020 edition was to foster the development of technology that would enable the (semi)automatic verication of claims posted in social media, in particular Twitter .2We turn our attention to Twitter because information posted on that platform is not checked by an authoritative entity before publi cation and such information tends to disseminate very quickly.3Moreover, social media posts lack context due to their short length and conversational nature; thus, identifying a claim's context is sometimes key for enabling eective fact checking [13]. The full identication and verication pipeline is displayed in Figure 1. The four tasks are dened as follows: Task 1 Checkworthiness estimation for tweets. Predict which tweet from a stream of tweets on a topic should be prioritized for factchecking. Task 2 Veried claim retrieval: Given a checkworthy tweet, and a set of previously checked claims, determine whether the claim in the tweet has been fact checked already. Task 3 Evidence retrieval. Given a checkworthy claim in a tweet on a specic topic and a set of text snippets extracted from potentiallyrelevant webpages, return a ranked list of evidence snippets for the claim. Task 4 Claim verication. Given a checkworthy claim in a tweet and a set of potentiallyrelevant Web pages, estimate the veracity of the claim. Task 5 complements the lab. It is as Task 1, but on political debates ad speeches rather than on tweets: given a debate segmented into sentences, to gether with speaker information, prioritize sentences for factchecking. Figure 1 shows how the dierent tasks relate to each other. The rst step is to detect tweets that contain checkworthy claims (Task 1; also, Task 5, which is on debates and speeches). The next step is to check whether a target checkworthy claim has been previously factchecked (Task 2). If not, then there is a need for factchecking, which involves supporting evidence retrieval (Task 3), followed by actual factchecking based on that evidence (Task 4). Tasks 1, 3, and 4 were run for Arabic, while Tasks 1, 2 and 5 were oered for English. The rest of the paper is organized as follows. Section 2 discusses related work. Section 3 describes the tasks that were run in Arabic (Tasks 1, 3 and 4). Section 4 presents the tasks that were run in English (Tasks 1, 2, and 5). Note that Sections 3 and 4 are not exhaustive; the reader should refer to [27] and [46], respectively, for further details. Finally, Section 5 concludes with nal remarks. 1https://sites.google.com/view/clef2020checkthat/ 2The 2018 edition [41] focused on the identication and verication of claims in politi cal debates. Beside political debates, the 2019 edition [15,16] also focused on isolated claims in conjunction with a closed set of Web documents to retrieve evidence from. 3Recently, Twitter started  agging some tweets that violate its policy.Fig. 1: The CheckThat! claim verication pipeline. Our tasks cover all four steps of the pipeline in Arabic or English. Tasks 1{4 focus on Twitter, while task 5 is run on political debates and speeches. 2 Related Work "
518,Real-Time Model Checking Support for AADL.txt,"We describe a model-checking toolchain for the behavioral verification of
AADL models that takes into account the realtime semantics of the language and
that is compatible with the AADL Behavioral Annex. We give a high-level view of
the tools and transformations involved in the verification process and focus on
the support offered by our framework for checking user-defined properties. We
also describe the experimental results obtained on a significant avionic
demonstrator, that models a network protocol in charge of data communications
between an airplane and ground stations.","The increasing complexity of the software and hardware components used in safety critical systems has encouraged the adoption of new architectures and computing modules, more powerful, but also more complex than their ancestors. Whilethesenewarchitecturesmakedevelopmentandmaintenanceeasier, italso make it more diÔ¨Écult to fully understand, analyze and test these systems. Formal veriÔ¨Åcation methods, such as modelchecking, are advocated as one of the solutions to this consistent increase in design complexity. While veriÔ¨Å cation activities should be performed at all stages of the development process, there are strong incentives for carrying out as much veriÔ¨Åcation as possible dur ing the early phases, especially during the functional and architectural design phases. Tosupportthistrend, anumberofhighlevelsystemmodelinglanguages have been proposed‚Äîoften referred to as Architecture Description Languages , or simply ADL‚Äîthat make it possible to analyze a system right from the design phase. Corresponding author Email address: dalzilio@laas.fr (S. Dal Zilio)arXiv:1503.00493v1  [cs.SE]  2 Mar 2015In this paper, we describe a modelchecking toolchain for the behavioral veriÔ¨Åcation of the Architecture Analysis and Design Language (AADL), an ADL standardized by the SAE that can describe both the hardware and software components of a system. The AADL standard address the problem of specifying and analyzing safetycritical, realtime embedded systems and is designed to supportaModelDrivenEngineeringapproach. Akeyextensiontothisstandard is the addition of a Behavioral Annex that reÔ¨Ånes the description of AADL threads behavior and that can therefore be used to describe more precisely the dynamic architecture of a system. An advantage of AADL, compared to many other ADL, is to be based on a precise, unambiguous semantics. Indeed, the AADL standard describe precisely the behavior of all its components, such as: when can messages be exchanged; how do periodic and sporadic threads interact; how threads interact with com munication or memory resources, such as registers or communication buses; ...Another motivation for choosing AADL is the fact that it relies on classical hypothesis taken when building realtime systems for its runtime; that is, AADL favors implementability over expressiveness. This is an interesting characteris tic, since it means that every feature of the language can be deÔ¨Åned without resorting to any ‚Äúunrealistic‚Äù primitives (like, e.g., the need for a global consen sus primitive). Those characteristics are very helpful for developing semantics related tools, like automatic code generators, schedulability analysis or formal veriÔ¨Åcation tools. Our modelchecking toolchain is based on a transformational approach, that is, on the interpretation (the translation) of an AADL model into a formal speciÔ¨Åcation language that will take into account the behavior of the model but also the dynamic semantics related to the AADL standard. We give a high level view of the tools and transformations involved in the veriÔ¨Åcation process and focus on the support oÔ¨Äered by our framework for checking userdeÔ¨Åned properties. We also report on some initial experiments carried out in order to evaluate our framework and give the Ô¨Årst experimental results obtained on signiÔ¨Åcant avionic demonstrator that models a network protocol in charge of data communications between an airplane and ground stations. Our toolchain (see Fig. 1) is connected for its input to Adele [1], a semantic editor for the elaboration of AADL models. At the other end, veriÔ¨Åcation activities ultimately relies on the Tina toolset [2], that provides statespace generation and modelchecking algorithms for timed Petri Nets. Inbetween, the generation of Tina models from an AADL description relies on the use of an intermediate formal speciÔ¨Åcation language, named Fiacre [3]. Fiacre oÔ¨Äers a formal framework to express and inspect the behavioral and timing aspects of the system. The intermediate Fiacre model provides a formal representation of a system behavior that is suitable for analysis using a modelchecking tool. Actually, most of the same toolchain can be used to derive formal speciÔ¨Åcations for the Tina and the CADP modelchecker [4]. The transformation from AADL to Fiacre is based on a Model Driven En gineering approach‚Äîwhere the adaptation and integration between tools is en suredbymodelbasedtechniques‚ÄîandhasbeenintegratedintoanEclipsebased 2Topcased (www.topcased.org ) (semantic) editors AADL +BA modeling languages RTFiacre libraries Fiacrepivot language CADP TinaveriÔ¨Åcation engineAADL2Fiacre frac Ô¨ÇacAdele Figure 1: AADL to Tina toolchain toolkit for system engineering called Topcased [5]. Topcased provides an open source, model oriented set of tooling and standard implementations and AADL was among the Ô¨Årst languages supported in this project. Our current toolchain is the result of the reÔ¨Ånement and maturation of sev eral previous versions of the AADL2Fiacre interpretation [6, 7]. In this most recent iteration of our tool, we have focused on the modularity of the transfor mation with the goal to increase its maintainability and to simplify the proof of its correctness. Indeed, our previous implementation were based on a mono lithic interpretation, that is supposed to generate fewer states but that was more delicate to debug and extend. One of the results obtained from our experimen tations is that it is possible to follow a compositional approach for the encoding without degrading the performances; actually, we observe that following a more compositional approach makes it is easier to take beneÔ¨Åt from symmetries in the system and to recover static dependencies than can help reduce the number of interleaving in the generated state space. Outline:. We brieÔ¨Çy describe the AADL execution model in Sect. 2 and focus on the behavior of threads and their interactions with communication events. Next, we give a highlevel view of the tools and languages involved and illus trate the successive transformations required by our veriÔ¨Åcation process. We describe the Fiacre language and its support for checking userdeÔ¨Åned, realtime properties. In particular, we show how to use realtime speciÔ¨Åcation patterns to check properties on the interpretation of an AADL model. Before concluding, we describe in Sect. 5 the results obtained on an AADL demonstrator. 2. AADL Execution Model and the Behavioral Annex The AADL standard has been designed with the goal to provide a precise description of both the software components of a system (such as processes, 3threads, data, ...) as well as the execution platforms supporting them (proces sors, devices, buses, memory, ...). The language has both a graphical and a textual syntax and includes all the usual concepts found in a componentbased languages: components are typed and are described using a semistructured set of properties; the interface of a component can be deÔ¨Åned using the notion of features; connections between components can be described using a notion of links. TheAADLexecutionmodelis suitabletodescriberealtimesystemsbecause it includes the main types of dispatch protocols for threads (periodic, aperiodic, sporadic, background) and the standard scheduling properties (period, prior ity, deadline, WCET, scheduling policy, ...). The language also includes the basicmethodsforinteraction; componentscancommunicatethroughports, syn chronous calls, and shared data. The AADL notion of process is the unit for describing the dynamic semantics ofa system. A process represents a virtual ad dress space, or a partition, that includes a program and all its subcomponents. A process must contain at least one thread (or thread group) that represents a sequential Ô¨Çow of execution. Threads are the only AADL components that can be scheduled. The AADL Behavioral Annex is used to add speciÔ¨Åc realtime properties to each component of the dynamic design model and to deÔ¨Åne the software behavior at the thread level. We can deÔ¨Åne the real time properties of threadsbysettingspeciÔ¨ÅcpropertiesintheAADLspeciÔ¨Åcation, likeforinstance the dispatch protocol (periodic or sporadic), the period (time) and the deadline (time). An example of thread declaration using the behavioral annex can be seen in the AADL code snippet of Listing 1. (An example of AADL graphical diagrams is given in page 16.) 1 THREAD t h A p p l i s 2 F E A T U R E S 3{ . . . } 4 END t h A p p l i s ; 5 6 THREAD I M P L E M E N T A T I O N t h A p p l i s .others 7 S U B C O M P O N E N T S 8 a p p _ m s g :DATA types : :msg.impl ; 9{ . . . } 10 P R O P E R T I E S 11 D i s p a t c h _ P r o t o c o l = > P e r i o d i c ;D e a d l i n e = > 10 ms;Period = > 10 ms; 12 { . . . } 13 ANNEX behavior_specification { 14 states"
375,Generating 2D and 3D Master Faces for Dictionary Attacks with a Network-Assisted Latent Space Evolution.txt,"A master face is a face image that passes face-based identity authentication
for a high percentage of the population. These faces can be used to
impersonate, with a high probability of success, any user, without having
access to any user information. We optimize these faces for 2D and 3D face
verification models, by using an evolutionary algorithm in the latent embedding
space of the StyleGAN face generator. For 2D face verification, multiple
evolutionary strategies are compared, and we propose a novel approach that
employs a neural network to direct the search toward promising samples, without
adding fitness evaluations. The results we present demonstrate that it is
possible to obtain a considerable coverage of the identities in the LFW or RFW
datasets with less than 10 master faces, for six leading deep face recognition
systems. In 3D, we generate faces using the 2D StyleGAN2 generator and predict
a 3D structure using a deep 3D face reconstruction network. When employing two
different 3D face recognition systems, we are able to obtain a coverage of
40%-50%. Additionally, we present the generation of paired 2D RGB and 3D master
faces, which simultaneously match 2D and 3D models with high impersonation
rates.","INdictionary attacks, one attempts to pass an authenti cation system by trying multiple inputs. In realworld biometric systems, one can typically try only a handful of inputs before being blocked. However, the matching in biometrics is not exact, and the space of biometric data is not uniformly distributed. This may suggest that with a handful of samples one can cover a high percentage of the population. Our results show that for both 2D and 3D face recognition, there are face images that would be authenticated successfully for a high percentage of users in a given dataset. This is demonstrated using stateof theart face recognition systems and acceptable matching thresholds. In some cases, a single 2D face can cover more than 20% of the identities in LFW [1] and a 3D master face covers more than 32% of the identities in the Texas 3D dataset [2]. Following previous work on Ô¨Ångerprints [3], we term such faces ‚Äúmaster faces‚Äù, due to the analogy to master keys. The process of master face generation employs a real istic face generator network, in our case StyleGAN [4], [5] for generating 2D faces. In 3D, a deep 3D reconstruction net work is applied on the output of the 2D generator to obtain the corresponding 3D structure. Since the objective function, i.e., the number of identities similar enough to the face image we optimize, is nondifferentiable, we use black box optimization methods. As expected, we Ô¨Ånd that methods tailored to highdimensional data outperform other meth ods. We then propose a novel method, in which a trained neural network is used to predict the competitiveness of a *Equal contributiongiven sample. When attempting to cover an even larger number of faces, we advocate a greedy method in which one repeats the master face generation process sequentially, each time attempting to cover the identities that were not covered by previously generated faces. Using such a greedy process, we obtain a coverage of 6%60% with nine images (the focus on nine images arises from a different experiment, in which the samples in the latent space are clustered). The experiments are conducted using six different deep face recognition models for the 2D scenario and two differ ent deep face recognition models for the 3D systems, each with its own processing pipeline, training dataset, objective, and similarity measure. For the 2D evaluations on the LFW dataset [1], a conservative similarity threshold based on obtaining a standard FAR value of 0.001 is used, or, when available, the threshold prescribed by the method itself. For the 2D evaluations on the racciallydiverse RFW dataset [6] and also in the 3D experiments, the unique threshold that balances FAR and FRR is used. Overall, our results indicate that performing a dictionary attack on face authentication systems is feasible, with high rates of success. This is demonstrated for both 2D and 3D, employing multiple face representations, and explored with several stateoftheart optimization methods. 2 R ELATED WORK "
92,Automation of Processor Verification Using Recurrent Neural Networks.txt,"When considering simulation-based verification of processors, the current
trend is to generate stimuli using pseudorandom generators (PRGs), apply them
to the processor inputs and monitor the achieved coverage of its functionality
in order to determine verification completeness. Stimuli can have different
forms, for example, they can be represented by bit vectors applied to the input
ports of the processor or by programs that are loaded directly into the program
memory. In this paper, we propose a new technique dynamically altering
constraints for PRG via recurrent neural network, which receives a coverage
feedback from the simulation of design under verification. For the
demonstration purposes we used processors provided by Codasip as their coverage
state space is reasonably big and differs for various kinds of processors.
Nevertheless, techniques presented in this paper are widely applicable. The
results of experiments show that not only the coverage closure is achieved much
sooner, but we are able to isolate a small set of stimuli with high coverage
that can be used for running regression tests.","With a raising demand on applicationspeciÔ¨Åc processors in today‚Äôs market it becomes a necessity to come up with new improved approaches that tackle the challenging task of their complex veriÔ¨Åcation. The current trend is to automate some of the routines of simulationbased veriÔ¨Åcation, for example, generation of stimuli or targeting corner cases in coverage. Pseudorandom stimuli generation is well deÔ¨Åned in the SystemVerilog language standard [1], in the Universal VeriÔ¨Å cation Methodology (UVM) [2] and even in a new standard for portable stimuli (currently in its Ô¨Ånal revision state). Various pseudorandom stimuli generators (PRGs) can be utilized for that purpose, either those inbuilt in RTL simulators or external ones (e.g. in C++) connected through direct programming interface. Pseudorandomness is achieved through constraints which are able to restrict the process of generation to gainful scenarios. This approach was devised to strike the balance between direct and random simulations. Instead of writing detailed veriÔ¨Åcation patterns manually, the user provides a set This paper has been supported by Brno University of Technology (FITS 173994) and by the EC Horizon 2020 project MegaM@Rt2 ECSELJU, No. 737494.of constraints and PRG generates a huge amount of stimuli in the order of seconds. The completeness of stimuli generation can be measured by various metrics commonly known as coverage (we will consider RTL coverage metrics in this paper such as branch, statement, expression or functional coverage). We say that the processor reached coverage closure when the value of every monitored coverage metric is high enough to proclaim it as veriÔ¨Åed. Such feedbackcontrolled method based on coverage analysis is called CoverageDriven VeriÔ¨Åcation (CDV). A problem of this approach comes from redundancy inbuilt in randomness, because if the coverage feedback is not properly propagated to PRG and reÔ¨Çected by suitable constraints, the same redundant stimuli can be applied to Design Under VeriÔ¨Å cation (DUV) without any coverage increase. Even intuitively we can observe that if the distribution of generated stimuli would reasonably change in every consequent stimuli genera tion (i.e. lower probability for already generated values), we would accelerate the veriÔ¨Åcation processes and reach corner cases and coverage closure faster. From the practical point of view, this paper targets two industrywide problems: 1) Speeding up the veriÔ¨Åcation process by doing optimiza tion of PRG constraints in such a way that coverage closure of DUV is achieved as fast as possible. 2) Seeking the smallest set of stimuli which reaches cover age closure for DUV . Such stimuli set is then ideal for regression testing. To resolve these problems, a new method for optimization of PRG constraints based on recurrent neural network (RNN) is proposed. This method has 3 signiÔ¨Åcant contributions. Firstly, it automates CDV ‚Äì veriÔ¨Åcation runs are repeated until either the coverage closure is reached or terminating conditions are met. Secondly, the proposed noninvasive solution can easily work with all veriÔ¨Åcation environments that support PRG and coverage analysis. Thirdly, values of some RNN parameters and methods for their further tuning are suggested based on extensive experiments. II. R ELATED WORK "
5,Contrastive-mixup learning for improved speaker verification.txt,"This paper proposes a novel formulation of prototypical loss with mixup for
speaker verification. Mixup is a simple yet efficient data augmentation
technique that fabricates a weighted combination of random data point and label
pairs for deep neural network training. Mixup has attracted increasing
attention due to its ability to improve robustness and generalization of deep
neural networks. Although mixup has shown success in diverse domains, most
applications have centered around closed-set classification tasks. In this
work, we propose contrastive-mixup, a novel augmentation strategy that learns
distinguishing representations based on a distance metric. During training,
mixup operations generate convex interpolations of both inputs and virtual
labels. Moreover, we have reformulated the prototypical loss function such that
mixup is enabled on metric learning objectives. To demonstrate its
generalization given limited training data, we conduct experiments by varying
the number of available utterances from each speaker in the VoxCeleb database.
Experimental results show that applying contrastive-mixup outperforms the
existing baseline, reducing error rate by 16% relatively, especially when the
number of training utterances per speaker is limited.","Extensive research has been devoted to improving speaker recog nition systems. The objective of speaker veriÔ¨Åcation is to answer the question ‚ÄùWas the input spoken by an enrolled speaker?‚Äù. The performance of a speaker veriÔ¨Åcation system relies on access to suf Ô¨Åcient and clean training data for supervised training [1]. However, one of the challenges in training speaker veriÔ¨Åcation models is the lack of large amounts of welllabelled training data. In other do mains, researchers have developed various data augmentation tech niques to overcome this bottleneck, enhancing the generalization of deep networks given limited data. For example, data augmentation has been used in computer vision [2], natural language processing [3], and semisupervised learning [4]. Some wellknown data augmentation approaches are applicable to speech recognition. Examples include adding noise, time stretch ing, pitch shift, and SpecAugment [5, 6]. The common idea behind these approaches is to deform either the raw audio or the spectro gram with various operations, such as time and frequency masking. Work done during an internship at Amazon. yEqual contributionsBy applying these augmentations, embedding extractors learn to be more robust to variations and thus enable better generalization [7]. In this paper, we propose contrastive mixup for training of a neu ral network‚Äôs embedding extractor. Mixup is a regularization tech nique that trains the network with linear interpolations of input sam ples and corresponding interpolated labels. While the mixup tech nique has proven effective for closedset classiÔ¨Åcation tasks [8], it is not clear how well it works for openset applications such as speaker veriÔ¨Åcation. Recent work has shed light on why mixup leads to im proved robustness and generalization of the trained model from a theoretical perspective [9]. However, to the best of our knowledge, little work has been done to apply mixup to speaker veriÔ¨Åcation sys tems. To Ô¨Åll this gap, we have developed contrastive mixup, a variant of the original mixup technique that is compatible with the training of speaker veriÔ¨Åcation models. The key innovation of this paper is to demonstrate how to im plement mixup for contrastive learning with metric learning objec tives. We focus on speaker veriÔ¨Åcation, which represents an open set classiÔ¨Åcation task. The speaker embeddings are extracted using a ResNetbased backbone model. To make a veriÔ¨Åcation decision, the distance (cosine distance in this paper) is computed between the ex tracted embedding and the proÔ¨Åle. The model is trained with batches consisting of a predeÔ¨Åned number of utterances from a predeÔ¨Åned number of speakers. During training, the prototype is calculated based on the original utterances from each individual speaker. Im portantly, the query utterance is obtained by conducting linear in terpolations of utterances from different speakers. Moreover, we choose angular prototypical loss to establish different baselines in speaker veriÔ¨Åcation systems due to the results reported in previous work [10, 11]. The prototypical networks are originally formulated for prob lems of fewshot learning, where each class can be represented and discriminated based on the mean of corresponding examples. One of the advantages of prototypical networks is that trained models can learn rare cases after being exposed to a small amount of prior infor mation [12]. However, it still remains unclear how to integrate the mixup algorithm with prototypical loss because the original proto typical loss function solely relies on a distance metric between sam ples, not involving the use of labels. Consequently, we have to re formulate the prototypical loss function by taking advantage of label information such that the mixup operation can be incorporated in the metric learning objective. Furthermore, we conducted experiments to compare different types of implementations of the mixup algorithms, in both time domain speech samples and Mel spectrogram features. The results demonstrate that contrastive mixup is effective in improving speakerarXiv:2202.10672v1  [eess.AS]  22 Feb 2022Fig. 1 . Schematic diagram of contrastive mixup veriÔ¨Åcation performance, especially when the number of utterances for each speaker is limited. Differently from existing augmentation approaches, such as adding noise [13] and room response simulation [14], we believe contrastive mixup offers a novel and effective aug mentation strategy that improves generalization while introducing negligible computational overhead. The remainder of this paper is structured as follows: Section 2 describes prior work related to mixup. Section 3 presents the pro posed contrastive mixup, Section 4 shows results and observations, and Section 5 summarizes our Ô¨Åndings. 2. RELATED WORK "
463,Combining Recurrent and Convolutional Neural Networks for Relation Classification.txt,"This paper investigates two different neural architectures for the task of
relation classification: convolutional neural networks and recurrent neural
networks. For both models, we demonstrate the effect of different architectural
choices. We present a new context representation for convolutional neural
networks for relation classification (extended middle context). Furthermore, we
propose connectionist bi-directional recurrent neural networks and introduce
ranking loss for their optimization. Finally, we show that combining
convolutional and recurrent neural networks using a simple voting scheme is
accurate enough to improve results. Our neural models achieve state-of-the-art
results on the SemEval 2010 relation classification task.","Relation classiÔ¨Åcation is the task of assigning sentences with two marked entities to a prede Ô¨Åned set of relations. The sentence ‚ÄúWe poured the<e1> milk</e1> into the <e2> pumpkin mix ture</e2> .‚Äù, for example, expresses the relation EntityDestination(e1,e2) . While early research mostly focused on support vector ma chines or maximum entropy classiÔ¨Åers (Rink and Harabagiu, 2010a; Tratz and Hovy, 2010), recent research showed performance improvements by ap plying neural networks (NNs) (Socher et al., 2012; Zeng et al., 2014; Yu et al., 2014; Nguyen and Gr ishman, 2015; Dos Santos et al., 2015; Zhang and Wang, 2015) on the benchmark data from SemEval 2010 shared task 8 (Hendrickx et al., 2010) .This study investigates two different types of NNs: recurrent neural networks (RNNs) and con volutional neural networks (CNNs) as well as their combination. We make the following contributions: (1) We propose extended middle context , a new context representation for CNNs for relation classi Ô¨Åcation. The extended middle context uses all parts of the sentence (the relation arguments, left of the relation arguments, between the arguments, right of the arguments) and pays special attention to the mid dle part. (2) We present connectionist bidirectional RNN models which are especially suited for sentence clas siÔ¨Åcation tasks since they combine all intermediate hidden layers for their Ô¨Ånal decision. Furthermore, the ranking loss function is introduced for the RNN model optimization which has not been investigated in the literature for relation classiÔ¨Åcation before. (3) Finally, we combine CNNs and RNNs using a simple voting scheme and achieve new stateofthe art results on the SemEval 2010 benchmark dataset. 2 Related Work "
333,Normalization Before Shaking Toward Learning Symmetrically Distributed Representation Without Margin in Speech Emotion Recognition.txt,"Regularization is crucial to the success of many practical deep learning
models, in particular in a more often than not scenario where there are only a
few to a moderate number of accessible training samples. In addition to weight
decay, data augmentation and dropout, regularization based on multi-branch
architectures, such as Shake-Shake regularization, has been proven successful
in many applications and attracted more and more attention. However, beyond
model-based representation augmentation, it is unclear how Shake-Shake
regularization helps to provide further improvement on classification tasks,
let alone the baffling interaction between batch normalization and shaking. In
this work, we present our investigation on Shake-Shake regularization, drawing
connections to the vicinal risk minimization principle and discriminative
feature learning in verification tasks. Furthermore, we identify a strong
resemblance between batch normalized residual blocks and batch normalized
recurrent neural networks, where both of them share a similar convergence
behavior, which could be mitigated by a proper initialization of batch
normalization. Based on the findings, our experiments on speech emotion
recognition demonstrate simultaneously an improvement on the classification
accuracy and a reduction on the generalization gap both with statistical
significance.","DEep convolutional neural networks have been success fully applied to several pattern recognition tasks such as image recognition [1], machine translation [2] and speec h emotion recognition [3]. Currently, to successfully train a deep neural network, one needs either a sufÔ¨Åcient number of training samples to implicitly regularize the learning p ro cess, or employ techniques like weight decay and dropout [4] and its variants to explicitly keep the model from over Ô¨Åtting. In the recent years, one of the most popular and success ful architectures is the residual neural network (ResNet) [ 1] and its variant ResNeXt [5] with multiple residual branches . The ResNet architecture was designed based on a key as sumption that it is more efÔ¨Åcient to optimize the residual term than the original task mapping. Since then, a great deal of effort in machine learning and computer vision has been dedicated to study the multibranch architecture. Deep convolutional neural networks have also gained much attention in the community of affective computing mainly because of its outstanding ability to formulate dis criminative features for the toplayer classiÔ¨Åer. Usually the number of parameters in a model is far more than the number of training samples and thus it requires heavy regularization to train deep neural networks for affective computing. However, since the introduction of batch nor ‚Ä¢The authors are with the Signal Analysis and Interpretation Laboratory (SAIL), Department of Electrical Engineering and Signal an d Image Processing Institute, University of Southern California, Los Angeles, CA 90089 USA Email: cheweihu@usc.edu; shri@sipi.usc.edu ‚Ä¢This work is supported by NSF.malization [6], the gains obtained by using dropout for regularization have decreased [6], [7], [8]. A recent work dedicated to study the disharmony between dropout and batch normalization [9] suggests that dropout introduces a variance shift between training and testing, which causes batch normalization to malfunction if batch normalization is placed after dropout, which severely limits the applicatio n of successful architectures such as ResNet or the applicati on of dropout to the topmost fully connected layers. Yet, multibranch architectures have emerged as a promising alternative for regularizing convolutional layers. Regularization techniques based on multibranch ar chitectures such as ShakeShake [10] and ShakeDrop [11] have delivered impressive performances on standard image datasets such as the CIFAR10 [12] dataset. In a clever way, both of them utilize multiple branches to learn different aspects of the relevant information and then a summation in the end follows for information alignment among branches. Also, both of ShakeShake and ShakeDrop regularizations emphasize on the important interaction between batch nor malization and shaking. However, none of them gave an explanation for this phenomenon, other than a brief discus sion on limiting the strength of shaking. Instead of using multiple branches, a recent work [13] based on a mixture of experts showed that randomly projecting samples is able to break the structure of adversarial noise that could easil y confound the model and as a result mislead the learning process. Despite not being an endtoend approach, it share s the same idea of integrating multiple streams of model based diversity. In addition, a recent trend of studies on data aug mentation, based on the Vicinal Risk Minimization (VRM)SUBMISSION TO THE IEEE TRANSACTIONS 2 [14] principle, proposed to interpolate and/or extrapolat e training samples in feature space, for example, [15] and [16 ]. Szegedy et al. [17] studied regularization of training by la  bel smoothing. Furthermore, Mixup [18] performed convex combinations of pairs of feature and label to demonstrate that expanding the coverage of training samples in feature space, leaving little to none of margin between classes, cou ld not only improve the performance of a model but also make it robust to adversarial samples. Effectively, Mixup reduces the uncertainty in prediction of a testing sample lying outside of the coverage of training samples in feature space by linear interpolation. Based on Mixup, Manifold Mixup [19] called for mixing intermediate representations instead of raw inputs. Our work follows the modelbased representation aug mentation thread like ShakeShake, ShakeDrop regulariza tion and Manifold Mixup. In this work, we study the Shake Shake regularized ResNeXt for speech emotion recognition. In addition to shaking the entire spectraltemporal featur e maps with the same strength, we propose to address differ ent spectral subbands independently based on our hypoth esis of the nonuniform distribution of affective informat ion over the spectral axis. Furthermore, we investigate and come up with an explanation for the ability of shaking regularization to improve classiÔ¨Åcation tasks and its cruc ial interaction with batch normalization. In order to achieve our goal, we conduct ablation studies on MNIST [20] and CIFAR10 datasets to highlight a subtle difference in the requirement of optimal embeddings by classiÔ¨Åcation tasks based on the VRM principle and by veriÔ¨Åcation tasks. In ad dition, we identify a strong resemblance in the mathematica l formulation between batch normalized residual blocks and batch normalized recurrent neural networks, where both of them suffer from a shared issue: faster convergence but more overÔ¨Åtting and could be Ô¨Åxed by the same technique. Our contributions are multifold. First, our work ex plains with visualization the key factor to the success of shaking regularization and the crucial property that batch normalization plays in a shaking regularized architecture , drawing a connection between shaking and the VRM prin ciple, and between batch normalization and discriminative embedding learning. Second, to the best of our knowledge, our work is the Ô¨Årst to highlight the subtle difference in the requirement of optimal embeddings by classiÔ¨Åcation tasks and by veriÔ¨Åcation tasks. Third, our work identify the resemblance between batch normalized residual blocks and batch normalized recurrent neural networks, and the shared issue they have. Based on the solution to batch normalized recurrent neural networks, we demonstrate a signiÔ¨Åcant reduction on the generalization gap, i.e. reduced over Ô¨Åtting, in a batchnormalized shakingregularized ResNeX t for speech emotion recognition without sacriÔ¨Åcing the vali  dation accuracy. The outline of this paper is as follows. We review related work in the next section, including ShakeShake regulariza  tion and its variants, discriminative feature learning in v er iÔ¨Åcation tasks and the vicinal risk minimization principle . Section 3 introduces subband shaking. Section 4 presents batch normalized shaking, including ablation studies on MNIST and CIFAR10 datasets, and the identiÔ¨Åcation of batch normalized residual blocks with batch normalized reŒ≤‚Üêrand(0,1 )Œ±‚Üêrand(0,1 ) (a) (b) (c)Mul()Conv 3x3 Mul(1 "
95,Deep Secure Encoding: An Application to Face Recognition.txt,"In this paper we present Deep Secure Encoding: a framework for secure
classification using deep neural networks, and apply it to the task of
biometric template protection for faces. Using deep convolutional neural
networks (CNNs), we learn a robust mapping of face classes to high entropy
secure codes. These secure codes are then hashed using standard hash functions
like SHA-256 to generate secure face templates. The efficacy of the approach is
shown on two face databases, namely, CMU-PIE and Extended Yale B, where we
achieve state of the art matching performance, along with cancelability and
high security with no unrealistic assumptions. Furthermore, the scheme can work
in both identification and verification modes.","Biometric template protection is an important factor in making the deployment of biometric authentication as widespread as string based password security. Authen tication on the basis of ‚Äúwho we are‚Äù instead of ‚Äúsome thing we possess‚Äù or ‚Äúsomething we remember‚Äù, offers convenience and often, stronger system security. The ad vantages of biometric authenticators are straightforward to see but the disadvantages require further thought. A typical biometric authentication system would use a few samples of user‚Äôs biometric modality (e.g. image of face, Ô¨Ångerprint or iris) for enrollment, and extract and store a template of the user from them. During authenti cation, veriÔ¨Åcation or identiÔ¨Åcation is performed where a given sample is matched against the stored templates and depending on the matching score, access is granted or de nied. In order to motivate the importance of storing the enrolled templates in a secure and cancelable manner, we compare a biometric template to a string based password.When registering a string password, a one way non invertible transform (i.e. a hash) of it is stored. During veriÔ¨Åcation, a password is entered and it‚Äôs hash value is calculated. The hash is compared with the stored hash and if the two strings matched exactly, their hashes would match as well, and access would be granted. In such a scenario, the stored hash reveals no information about the original password and also, if the password is compro mised, it can be changed and a new hash can be stored. This is the kind of security we desire from biometric tem plates as well. Unlike passwords, biometric modalities lack two important aspects. 1) They rarely match exactly between different readings, and 2) they cannot be changed if compromised. Thus, the objective of biometric tem plate protection schemes is to extract authenticators from biometric modalities that are 1) secure i.e. given the au thenticator, it should be infeasible to extract any informa tion about the original modality, and 2) cancelable i.e. if compromised, it should be possible to extract a new au thenticator from the same modality. 2 Previous work These objectives have been tackled for faces in different ways. Schemes that used cryptosystem based approaches but without hash functions include Fuzzy commitment schemes by Ao and Li [1], Lu et al. [10] and Van Der Veen et al. [21], and fuzzy vault by Wu and Qiu [22]. The fuzzy commitment schemes suffered from limited er ror correcting capacity or short keys in general. Fuzzy vault schemes suffer from the problem that the data is stored in the open between chaff points, and also that they cause an overhead in storage space. Some quantization schemes were used by Sutcu et al. [16, 17] to generate somewhat stable keys. There were also several works that combine the face data with user deÔ¨Åned keys or user spe ciÔ¨Åc keys. These include combination with a passwordarXiv:1506.04340v1  [cs.CV]  14 Jun 2015by Chen and Chandran [3], user speciÔ¨Åc token binding by Ngo et al. [11, 19, 20], biometric salting by Savvides et al.[13], and user speciÔ¨Åc random projection schemes by Teoh and Yuang [18] and Kim and Toh [8]. Hybrid ap proaches that combine transform based cancelability with cryptosystem based security like [6] have also been pro posed but give out user speciÔ¨Åc information to generate the template creating possibilities of masquerade attacks. Pandey and Govindraju [12] proposed a security centric scheme that used features extracted from local regions of the face to obtain exact matching and thus, beneÔ¨Åted from the security of hash functions like SHA256. Al though seemingly more secure, the matching accuracy of the scheme was low and the feature space being hashed was not uniformly distributed. Here, we propose a scheme that achieves state of the art matching accuracy while maintaining a very high level of security with no unrealistic assumptions. Furthermore, the scheme can work in both veriÔ¨Åcation and identiÔ¨Åca tion modes while being truly keyless. The contributions of this paper are as follows. 1. We design a secure classiÔ¨Åcation scheme that achieves state of the art matching performance on CMU PIE and Extended Yale B databases, while achieving tem plate cancelability and security. 2. We address the challenges of learning deep neural networks with limited data in a biometric setting, as well as, that of generating a ranged, tunable score from a clas siÔ¨Åcation framework. 3. We provide an analysis of the cancelability and secu rity of the generated templates in two scenarios and show that the second, more secure scenario, achieves high se curity without any assumptions on the data distribution or any need for parameter protection. 3 Method "
148,A New Periocular Dataset Collected by Mobile Devices in Unconstrained Scenarios.txt,"Recently, ocular biometrics in unconstrained environments using images
obtained at visible wavelength have gained the researchers' attention,
especially with images captured by mobile devices. Periocular recognition has
been demonstrated to be an alternative when the iris trait is not available due
to occlusions or low image resolution. However, the periocular trait does not
have the high uniqueness presented in the iris trait. Thus, the use of datasets
containing many subjects is essential to assess biometric systems' capacity to
extract discriminating information from the periocular region. Also, to address
the within-class variability caused by lighting and attributes in the
periocular region, it is of paramount importance to use datasets with images of
the same subject captured in distinct sessions. As the datasets available in
the literature do not present all these factors, in this work, we present a new
periocular dataset containing samples from 1,122 subjects, acquired in 3
sessions by 196 different mobile devices. The images were captured under
unconstrained environments with just a single instruction to the participants:
to place their eyes on a region of interest. We also performed an extensive
benchmark with several Convolutional Neural Network (CNN) architectures and
models that have been employed in state-of-the-art approaches based on
Multi-class Classification, Multitask Learning, Pairwise Filters Network, and
Siamese Network. The results achieved in the closed- and open-world protocol,
considering the identification and verification tasks, show that this area
still needs research and development.","BIOMETRIC systems that use ocular images have been extensively investigated due to the high level of singular ity in the iris and because the periocular region can provide discriminative patterns even in noisy images [1]‚Äì[6]. The term ocular comprises the periocular and iris regions [7]. The periocular region comprises eyebrows, eyelashes and eyelids, while the iris is the colored region between the sclera and pupil. There are two main modes that an ocular biometric system can operate: identiÔ¨Åcation ( 1:Ncomparison) and ver iÔ¨Åcation ( 1:1comparison). The identiÔ¨Åcation task consists of determining a subject‚Äôs identity, whereas the veriÔ¨Åcation one veriÔ¨Åes whether a subject is who she/he claims to be. There are also two main protocols to evaluate biometric systems: closed world and openworld [8], [9]. In the former, the training and test sets have different samples from exactly the same subjects. Luiz A. Zanlorensi, Rayson Laroca, Diego R. Lucio, Lucas R. Santos, and David Menotti are with the Federal University of Paran√° (UFPR), Brazil. Email: { lazjunior, rblsantos, drlucio, lrs14, menotti }@inf.ufpr.br Alceu S. Britto Jr. is with the PontiÔ¨Åcal Catholic University of Paran√° (PUCPR), Brazil. Email: alceu@ppgia.pucpr.br This is an authorprepared version. The Ô¨Ånal version is published in ScientiÔ¨Åc Reports (DOI: 10.1038/s4159802222811y).On the other hand, in the openworld protocol, the training and test sets must have samples from different subjects. With these modes and protocols, it is possible to evaluate some characteristic of biometric approaches to produce discrimina tive features and generalization capability. TABLE I COMPARISON OF THE AVAILABLE OCULAR DATASETS CONTAINING VISIBLE (VIS) IMAGES WITH OUR DATASET (UFPRP ERIOCULAR ). Dataset Subjects Images Sessions Sensors VSSIRIS [10] 28 560 1 2 CSIP [11] 50 2 ;004 N/A 7 QUT [12] 53 212 N/A 2 IIITD [13] 62 1 ;240 N/A 3 UPOL [14] 64 384 N/A 1 UTIRIS [15] 79 1 ;540 2 2 MICHEI [16] 92 3 ;732 2 3 CROSSEYED [17], [18] 120 3 ;840 N/A 2 PolyU CrossSpectral [19] 209 12 ;540 2 2 UBIRIS.v1 [20] 241 1 ;877 2 1 UBIRIS.v2 [21] 261 11 ;102 2 1 UBIPr [22] 261 10 ;950 2 1 VISOB [23] 550 158 ;136 2 3 UFPRPeriocular 1;122 33;660 3 196 Nowadays, with the advancement of deep learningbased techniques, several methodologies applying them to ocular images have been proposed for several tasks, for example, spooÔ¨Ång detection [24], [25], iris and periocular region de tection [26]‚Äì[28], iris and sclera segmentation [29], [30], and iris and periocular recognition [31]‚Äì[37]. The advancement of these technologies can be observed by the recent contests that have been conducted to evaluate the evolution of the stateoftheart methods for different applications, such as iris recognition in heterogeneous lighting conditions (NICE.I and NICE.II) [21], [38], iris recognition using mobile images (MICHE.I and MICHE.II) [2], [16], iris and periocular recog nition in crossspectral scenarios (CrossEyed 1 and 2) [17], [18], and periocular recognition using mobile images captured in different lighting conditions (VISOB 1 and 2) [23]. Note that all these contests used datasets containing images obtained in the visible wavelength. The most recent contests also used images captured by mobile devices [2], [23]. The results achieved by the proposed methods have shown that it is challenging to develop a robust biometric system in such conditions, mainly due to the high intraclass variability. Based on recent works [2], [5], [7], we can state that developing an ocular biometric system that operates in unconstrained environments is still a challenging task, especially with images obtained by mobile devices. In this condition, the images cap tured by the volunteer may present several variations caused by occlusion, pose, eye gaze, offangle, distance, resolution,arXiv:2011.12427v2  [cs.CV]  14 Nov 20222 and image quality (affected by the mobile device). With the existing periocular datasets, it is difÔ¨Åcult to assess the scalability performance of biometric applications, i.e., if an approach can produce discriminative features even in a large dataset in terms of the number of subjects. As we can see in Table I, the datasets in the literature do not present a large number of subjects and have few capture devices and session captures. As described in some previous works [5], [6], one common problem in ocular biometric systems is the withinclass variability, which is generally affected by noises and attributes present in the same individual images. A robust biometric system must handle images obtained from different capture devices, extracting distinctive representations regardless of the source and environments. In this sense, sam ples from the same subject obtained in different sessions are of paramount importance to capture the intraclass variation caused by various noise factors. Considering the above discussion, in this work, we introduce a new periocular dataset, called UFPRPeriocular . The sub jects themselves collected the images that compose our dataset through a mobile application (app). In this way, the images were captured in unconstrained environments, with a minimum of cooperation from the participant, and have real noises caused by poor lighting, occlusion, specular reÔ¨Çection, blur, and motion blur. Fig. 1 shows some samples from the UFPR Periocular. As part of this work, we also present an extensive benchmark, employing several stateoftheart architectures of CNN models that have been explored to develop ocular (periocular and iris) recognition biometric systems. Face and eye detection are not covered in this work. The recognition methods are evaluated with manually preprocessed images (also available in the dataset). Fig. 1. Sample images from the UFPRPeriocular dataset. Observe that there is great diversity in terms of lighting conditions, age, gender, eyeglasses, specular reÔ¨Çection, occlusion, resolution, eye gaze, and ethnic diversity. Note that our dataset is the largest one in terms of the number of subjects, sessions, and capture devices, as shown in Table I. It also has more images than all datasets except VISOB. Another key feature is that the proposed dataset has images captured by 196different mobile devices. The samples captured with less cooperation of the participant in uncon strained environments have several variations on the ocular images since they are obtained during three different sessions. To the best of our knowledge, this is the Ô¨Årst periocular datasetwith more than 1;000 subject samples and the largest one in different capture devices in the literature. Thus, we believe that it can provide a new benchmark to evaluate and develop new robust periocular biometric approaches. Recently, with the advancement of devices enabling the selfcapture of images that can be used as biometrics, the term ‚ÄúselÔ¨Åe biometrics‚Äù has been extensively explored by the research community [39], [40], especially in face and iris recognition [41]‚Äì[43]. As described by Rattani et al. [3], the term ‚ÄúselÔ¨Åe biometrics‚Äù consists of a biometric system where the input data is acquired by the user using the capture devices available in their device. Thus, we can consider the UFPR Periocular dataset, presented in this work, as a selÔ¨Åe biometric dataset since its images were acquired by the users through their own smartphones. The remainder of this work is organized as follows. In Section II, we describe the periocular datasets containing VIS images for periocular biometrics. In Section III, we present in formation about the UFPRPeriocular dataset and the proposed protocol to evaluate biometric systems. Section IV presents the CNN architectures used to perform the benchmark. In Section V, we present and discuss the benchmark results. Finally, the conclusions are given in Section VI. II. R ELATED WORK "
97,Face representation by deep learning: a linear encoding in a parameter space?.txt,"Recently, Convolutional Neural Networks (CNNs) have achieved tremendous
performances on face recognition, and one popular perspective regarding CNNs'
success is that CNNs could learn discriminative face representations from face
images with complex image feature encoding. However, it is still unclear what
is the intrinsic mechanism of face representation in CNNs. In this work, we
investigate this problem by formulating face images as points in a
shape-appearance parameter space, and our results demonstrate that: (i) The
encoding and decoding of the neuron responses (representations) to face images
in CNNs could be achieved under a linear model in the parameter space, in
agreement with the recent discovery in primate IT face neurons, but different
from the aforementioned perspective on CNNs' face representation with complex
image feature encoding; (ii) The linear model for face encoding and decoding in
the parameter space could achieve close or even better performances on face
recognition and verification than state-of-the-art CNNs, which might provide
new lights on the design strategies for face recognition systems; (iii) The
neuron responses to face images in CNNs could not be adequately modelled by the
axis model, a model recently proposed on face modelling in primate IT cortex.
All these results might shed some lights on the often complained blackbox
nature behind CNNs' tremendous performances on face recognition.","Human face representation, aiming to represent the identity of human face, is an impor tant and challenging topic in both the Ô¨Åelds of computer vision and neuroscience, and has attracted more and more attention in recent years. In the neuroscience Ô¨Åeld, visual object representation, including face representation, is generally believed to happen in primate inferotemporal (IT) cortex, and the popula tion responses of IT neurons to an object image stimulus is considered as the represen 2tation of this object [1, 2, 3, 4, 5, 6, 7, 8, 9]. In the early years, many traditional works on face representation assumed an exemplarbased mechanism for representing face identity in primate IT cortex: face identiÔ¨Åcation was mediated by units tuned to a set of exemplar faces. Such an exemplarbased representation mechanism is supported by the results in [1] that some neurons in the anterior medial face patch are viewindependent, which respond to faces of only a few speciÔ¨Åc individuals regardless of view orientations. Recently, different from the results in [1], Chang and Tsao [8] found that by formulating face images as points in a multidimensional linear parameter space, face images could be linearly encoded in macaque IT cortex, and they could also be linearly decoded from IT neuron responses, and a new face representation model, called ‚Äúthe axis model‚Äù, was proposed. Their experimental results demonstrated that the proposed axis model could achieve satisfactory encoding and decoding performances of IT neuron responses. In the computer vision Ô¨Åeld, the performances of face recognition systems depend heavily on face representation, which is naturally coupled with many adverse factors, such as pose variation, illumination change, expression, occlusion and so on. Face representation could either be manually designed or automatically learnt from face im age datasets. In the early days, the face representations were mainly constructed with manually designed features, such as Local Binary Patterns [10], Histogram of Oriented Gradients [11], etc. In recent years, Convolutional Neural Networks (CNNs), which are generally believed to be able to learn complex and effective representations from image stimuli, have achieved tremendous successes on object categorization and face recognition [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]. For example, DeepFace [13] trained a deep CNN to classify faces using a dataset of 400;000examplar images. 3DeepID [14] employed a CNN to learn face representations for identifying 10;000dif ferent faces. In [15], a new CNN was introduced to learn face representations, which was trained with both face identiÔ¨Åcation and veriÔ¨Åcation signals. Hayat et al. [25] pro posed a datadriven method to jointly learn registration with face representation in a CNN. Liu et al. [26] proposed a deep hypersphere embedding approach for face recog nition, where the angular Softmax loss for CNNs was introduced to learn discriminative face representations (called SphereFace) with angular margin. Zhang et al. [21] pro posed a disentangling siamese network, which could automatically disentangle the face features into the identity representations, as well as the identityorthogonal factors in cluding poses and illuminations. Wu et al. [23] proposed a light CNN framework to learn a compact face representation on the largescale face data with noisy labels. Deng et al. [24] proposed a geometrically interpretable loss function, called ArcFace, which is integrated with different CNN models (e.g. ResNet [27]) for face recognition and veriÔ¨Åcation. Why do CNNs perform so well on face recognition? One popular perspective is that CNNs could learn effective and discriminative face representations with complex image feature encoding, because of the repeatedly used nonlinear operators such as ReLU (RectiÔ¨Åed Linear Unit) and max pooling in CNNs. However, what is the intrin sic mechanism of face representation in CNNs? It seems this is still largely an open question. In addition, CNNs‚Äô successes in generic object categorization and recogni tion are often attributed by many researchers to their inherent hierarchical architectures, similar to the primate visual ventral pathway. It is also shown in [5] that if an object representation is monkey ITlike, it can give a good object recognition performance. 4Hence, a further question naturally comes up: is the face representation mechanism in CNNs is similar to that in monkey IT cortex found recently in [8]? or more speciÔ¨Åcally, could the responses of CNN neurons (units) to face stimuli be linearly modelled in a parameter space? If so, it would mean that although CNNs generally concatenate multiple convolution layers and nonlinear operators, there essentially exists a linear mapping between the face vectors in a parameter space and the corresponding face representations in DNNs. This linear mapping is more explicit and largely different from the aforementioned complex image feature encoding on CNNs‚Äô face representa tion. Addressing the above questions, we investigated the face representation problem at higher CNN layers by formulating face images as points in a parameter space in this work, with six typical multilayered CNNs for face recognition: VGGFace [17], DeepID [14], ResNetFace (deÔ¨Åved from ResNet [27]), SphereFace [22], LightCNN [23], and ArcFace [24], and three commonly used face datasets: MultiPIE [28], LFW [29], and MegaFace [30]. We found that there indeed exists a linear encoding/decoding model for face representation in these CNNs, i.e., face vectors in the parameter space could not only be effectively decoded from the neuron responses at the higher CNN layers, but also be encoded linearly for predicting the responses of CNN neurons, sim ilar to the face representation of monkey IT neurons reported in [8]. In addition, we found that the predicted representations by the linear model could achieve compara ble performances on face recognition and veriÔ¨Åcation to those by the above CNNs. However, we found that the neuron responses at the higher CNN layers could not be ad equately modelled by the axis model in [8]. These results partially reveal the linear face 5representation mechanism in CNNs, as well as the similarities and differences of face representation between CNNs and primate IT cortex. Additionally, the revealed linear face encoding might also be referenced for the future design of new face recognition systems. 2 Method "
40,The SJTU System for Short-duration Speaker Verification Challenge 2021.txt,"This paper presents the SJTU system for both text-dependent and
text-independent tasks in short-duration speaker verification (SdSV) challenge
2021. In this challenge, we explored different strong embedding extractors to
extract robust speaker embedding. For text-independent task, language-dependent
adaptive snorm is explored to improve the system performance under the
cross-lingual verification condition. For text-dependent task, we mainly focus
on the in-domain fine-tuning strategies based on the model pre-trained on
large-scale out-of-domain data. In order to improve the distinction between
different speakers uttering the same phrase, we proposed several novel
phrase-aware fine-tuning strategies and phrase-aware neural PLDA. With such
strategies, the system performance is further improved. Finally, we fused the
scores of different systems, and our fusion systems achieved 0.0473 in Task1
(rank 3) and 0.0581 in Task2 (rank 8) on the primary evaluation metric.","Speaker veriÔ¨Åcation system has gained great improvement with the development of deep learning. From the phonechannel [1] to inthewild condition [2], researchers have proposed different architectures [3, 4, 5, 6], different losses [7, 8, 9], and different training strategies [10, 11, 12] to improve the system perfor mance under different conditions. However, there are still some challenges unresolved when the speaker veriÔ¨Åcation system is applied in the real world, such as the short duration problem and crosslingual problem. In this paper, we introduce the SJTU system submitted to the shortduration speaker veriÔ¨Åcation (SdSV) challenge 2021 [13]. The SdSV challenge 2021 includes two tasks. The task1 is the textdependent task, where the speaker veriÔ¨Åca tion system should verify the test speaker identity and speak ing phrase at the same time. Task2 is textindependent task, the system should only consider the speaker identity. Particularly, the SdSV challenge introduces a new challenging veriÔ¨Åcation condition, the crosslingual veriÔ¨Åcation for task2, where one speaker may speak different languages at the enrollment and test stage. The SdSV 2021 is the second challenge of SdSV series and many competitive systems have been proposed in the last chal lenge. For textindependent task in the last challenge, Jenthe et al. proposed a new data mining strategy HPM [14] and in troduced adaptive snorm to improve system‚Äôs cross language veriÔ¨Åcation robustness. Peng et al. introduced a greedy fusion algorithm [15] to further improve the performance of the fusion ‚Ä†Yanmin Qian is the corresponding authorsystem. Besides, teams mainly focused on the backend opti mization [16, 17] in textdependent task. In this challenge, we Ô¨Årst explored different wellperformed architectures and trained them on all the available data. Then, we focus on the indomain data Ô¨Ånetuning strategies to further improve the system performance. To solve the crosslanguage veriÔ¨Åcation problem in textindependent task, we trained an other language identiÔ¨Åcation network to introduce the language information to the adaptive snorm [18] procedure. For text dependent task, we implemented different methods to increase the distinction between the target trial and different nontarget trials. We used an ASR system to classify the speaker phrase during the test stage and Ô¨Ålter out the phrasemismatch (speaker utters a wrong passphrase) trials directly. To better distinguish different speakers uttering the same phrase, we proposed sev eral novel phaseaware Ô¨Ånetuning strategies and phraseaware neural PLDA. Based on such strategies, the performance of our systems is further improved. The rest of the paper is organized as follows: Section 2 in troduces the dataset used in this challenge. Section 3 introduces our embedding extractor architectures and the proposed Ô¨Åne tuning strategies. The experimental results and corresponding analysis are given in Section 4. Finally, we make the conclu sion in Section 5. 2. Datasets 2.1. Training Data SdSV challenge adapted a Ô¨Åxed training condition where the system should only be trained on the designed set. The main training and evaluation data for SdSV challenge is the Deep Mine [19, 20] dataset which was recorded in realistic environ ments of Iran. And the collection protocol was designed to incorporate various kinds of noises during the recording. The main language is Persian while the most of the participants also participated in the English partition. ‚Ä¢ Task 1 indomain data: A dataset which is designed for building textdependent speaker veriÔ¨Åcation system. It consists of 101k utterances from 963 different speakers. The content of all utterances is limited to a Ô¨Åxed set in cluding Ô¨Åve Persian phrases and Ô¨Åve English phrases. ‚Ä¢ Task 2 indomain data: A dataset which has no restric tions on utterance content. It contains 125k utterances collected from 588 speakers while some of them have only Persian phrases. In addition to the indomain training data, other opening datasets allowed to be used in the training process are described as follows.arXiv:2208.01933v1  [cs.SD]  3 Aug 2022Voxceleb [21, 22]: V oxceleb 1&2 contain more than one million utterances from 7245 celebrities, which are collected from videos uploaded to YouTube. Librispeech [23]: A dataset which comprises 281k utter ances from 2338 speakers. It‚Äôs sourced from audio books and the majority of speech is US English. Common Voice Farsi [24]: The Common V oice corpus is a massivelymultilingual collection of transcribed speech. And only Persian part of it is used in this challenge. 2.2. Evaluation The evaluation data for task 1&2 are both part of the DeepMind indomain data. ‚Ä¢ In Task 1, each trial consists of a test segment along with a model identiÔ¨Åer which indicates three enrollment ut terances and a phrase ID that uttered in the utterances. These trials can be classiÔ¨Åed into four basic types in cluding TC, TW, IC and IW. The textdependent speaker veriÔ¨Åcation system should accept the TC trials and reject the other three types as imposture trials. ‚Ä¢ In Task 2, the enrollment data consists of one to sev eral variablelength utterances from the Persian language while the test utterances might from the different lan guage (English). For this task, systems should accept the trials if enroll and test utterances are both from the same speaker without considering language mismatch. The main metric adopted by SdSV challenge is normalized minimum detection cost function (minDCF), which is deÔ¨Åned as a weighted sum of false alarm and miss error probabilities. 3. Methods "
146,DeepCert: Verification of Contextually Relevant Robustness for Neural Network Image Classifiers.txt,"We introduce DeepCert, a tool-supported method for verifying the robustness
of deep neural network (DNN) image classifiers to contextually relevant
perturbations such as blur, haze, and changes in image contrast. While the
robustness of DNN classifiers has been the subject of intense research in
recent years, the solutions delivered by this research focus on verifying DNN
robustness to small perturbations in the images being classified, with
perturbation magnitude measured using established Lp norms. This is useful for
identifying potential adversarial attacks on DNN image classifiers, but cannot
verify DNN robustness to contextually relevant image perturbations, which are
typically not small when expressed with Lp norms. DeepCert addresses this
underexplored verification problem by supporting:(1) the encoding of real-world
image perturbations; (2) the systematic evaluation of contextually relevant DNN
robustness, using both testing and formal verification; (3) the generation of
contextually relevant counterexamples; and, through these, (4) the selection of
DNN image classifiers suitable for the operational context (i)envisaged when a
potentially safety-critical system is designed, or (ii)observed by a deployed
system. We demonstrate the effectiveness of DeepCert by showing how it can be
used to verify the robustness of DNN image classifiers build for two benchmark
datasets (`German Traffic Sign' and `CIFAR-10') to multiple contextually
relevant perturbations.","Deep neural network (DNN) image classiers are increasingly being proposed for use in safety critical applications [6,15,19,24], where their accuracy is quoted as close to, or exceeding, that of human operators [3]. It has been shown, however, that when the inputs to the classier are subjected to small perturbations, even highly accurate DNNs can produce erroneous results [8,9,30]. This has lead to intense research into verication techniques that check whether a DNN is robustarXiv:2103.01629v1  [cs.LG]  2 Mar 20212 Paterson et al. to perturbations within a small distance from a given input, where this distance is measured using an Lpnorm (e.g., the Euclidean norm for p= 2) [4,12,13,20]. These techniques are particularly useful for identifying potential adversarial at tacks on DNNs [8,14,17,18]. They are also useful when small changes in the DNN inputs correspond to meaningful changes in the real world, e.g., to changes in the speed and course of an aircraft for the ACAS Xu DNN veried in [12]. For DNN image classiers, small Lpnorm image changes are not always meaningful. Changes that may be more meaningful for such DNNs (e.g., image blurring, hazing, variations in lighting conditions, and other natural phenomena) can also cause misclassications, but are dicult to map to small pixel variations [10,16], and thus cannot be examined using traditional DNN verication tech niques. What is needed for the comparison and selection of DNN image classiers used in safetycritical systems is a contextually relevant robustness verication method capable of assessing the robustness of DNNs to these realworld phe nomena [1,2,25,31]. Moreover, this verication needs to be performed at DNN level (i.e., across large datasets with imagine samples from all relevant classes) rather than for a single sample image. The toolsupported DeepCert4method introduced in our paper addresses "
172,BRENDA: Browser Extension for Fake News Detection.txt,"Misinformation such as fake news has drawn a lot of attention in recent
years. It has serious consequences on society, politics and economy. This has
lead to a rise of manually fact-checking websites such as Snopes and
Politifact. However, the scale of misinformation limits their ability for
verification. In this demonstration, we propose BRENDA a browser extension
which can be used to automate the entire process of credibility assessments of
false claims. Behind the scenes BRENDA uses a tested deep neural network
architecture to automatically identify fact check worthy claims and classifies
as well as presents the result along with evidence to the user. Since BRENDA is
a browser extension, it facilities fast automated fact checking for the end
user without having to leave the Webpage.","Online fake news has become a major societal challenge due to its consequences in real life. For example, there are instances of stock market disruptions1, election meddling2and mob lynchings3. To address this, several fact checking organizations such as Snopes, Politifact and FullFact have become popular. Typically they employ experts and journalists who perform a tedious task of manually selecting fact check worthy claims made in online news and social media debunking them. 1http://business.time.com/2013/04/24/howdoesonefaketweetcauseastock marketcrash/ 2https://www.theguardian.com/commentisfree/2016/nov/14/ fakenewsdonaldtrumpelectionaltrightsocialmediatechcompanies 3https://en.wikipedia.org/wiki/Indian_WhatsApp_lynchings Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. SIGIR ‚Äô20, July 25‚Äì30, 2020, Virtual Event, China ¬©2020 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 9781450380164/20/07. . . $15.00 https://doi.org/10.1145/3397271.3401396We propose BRENDA a proof of concept browser extension which anyone can install on desktop browsers to perform endtoend fact checking. BRENDA automates following two tasks: (1) Selecting fact check worthy claims and (2) Verifying the truthfulness of claims based on the evidence found online. Existing demos (e.g, CredEye [ 6], FactMata4, [4] etc) are limiting to the users reading online news, since they have to first identify the claims within the articles, then switch to a different website for fact checking. There are also demos which either do only claim ranking [1] or just list the relevant websites [ 10]. Moreover, existing demos do not provide any explanation for the claim classifications. There are no existing demos which can jointly identify the claim and fact check them and provide evidence to the support the decision. To address these issues, BRENDA provides the following contributions: (1)BRENDA facilitates users to do fact checking without leaving the Website. If users are not sure on which claims to fact check, BRENDA can automatically filter fact check worthy claims. (2)BRENDA can automatically query online evidence via web search engines and verify claims. (3)BRENDA uses a proven pretrained deep neural network model coined SADHAN which considers the latentaspects of the claim to verify its truthfulness. (4)In addition to classifying the claims, BRENDA also provides evidence snippets highlighting the importance of both words and sentences relevant for classifying the claim using attention weights from the SADHAN deep neural network model [5]. 2 RELATED WORK "
219,Hardware Accelerator and Neural Network Co-Optimization for Ultra-Low-Power Audio Processing Devices.txt,"The increasing spread of artificial neural networks does not stop at
ultralow-power edge devices. However, these very often have high computational
demand and require specialized hardware accelerators to ensure the design meets
power and performance constraints. The manual optimization of neural networks
along with the corresponding hardware accelerators can be very challenging.
This paper presents HANNAH (Hardware Accelerator and Neural Network seArcH), a
framework for automated and combined hardware/software co-design of deep neural
networks and hardware accelerators for resource and power-constrained edge
devices. The optimization approach uses an evolution-based search algorithm, a
neural network template technique, and analytical KPI models for the
configurable UltraTrail hardware accelerator template to find an optimized
neural network and accelerator configuration. We demonstrate that HANNAH can
find suitable neural networks with minimized power consumption and high
accuracy for different audio classification tasks such as single-class wake
word detection, multi-class keyword detection, and voice activity detection,
which are superior to the related work.","ArtiÔ¨Åcial intelligence is increasingly spreading into the domain of alwayson ultralow power connected devices like Ô¨Åtness trackers, smart IoT sensors, hearing aids and smart speakers. The limited power budget on these devices and the high computational demand often mandates the use of specialized ultralow power hardware accelerators, specialized to a speciÔ¨Åc application or application domain. Hardware design, neural network training and optimized deployment often require manual optimization by the system designers, who need to deal with manifold often counterdirected issues. In this This work has been partly funded by the EU and the German Federal Ministry of Education and Research (BMBF) in the projects OCEAN12 (reference number: 16ESE0270). *These authors contributed equally to this work. HANNAH ‚ÄìTrain QAT Network Topologies Data AugmentationHANNAH ‚ÄìDeploy Scheduling Quantization Memory AllocationUltraTrail ‚ÄìNPU MAC Array Distributed Memory Programmable  Control UnitMetricsHANNAH ‚ÄìOptimize (Neural Architecture Search)Fig. 1: Overview of the HANNAH framework. work, we propose HANNAH (Hardware Accelerator and Neural Network seArcH) to automatically cooptimize neural network architectures and a corresponding neural network accelerator. The HANNAH design Ô¨Çow is shown in Figure 1. Neural Networks are instantiated and trained in the training component employing quantization aware training and dataset augmen tation. Trained neural networks are then handed over to the deployment component (Sec. III) for target code generation. Here, the neural network is quantized to a low word width representation the neural network operations are scheduled and ondevice memory is allocated for the neural network. Along with the target network architecture, a specialized hardware accelerator for the neural network processing is instantiated from a conÔ¨Ågurable Verilog template. Hardware dependent performance metrics like power consumption and chip area are then either generated by running the neural network on a gatelevel simulation or estimated using an analytical performance model. The evolutionbased search strategy (Sec. IV) implemented in the HANNAH optimizer is then used to incrementally search the neural network and hardware accelerator codesign space. The main contributions of this paper are: 1)We present an endtoend design Ô¨Çow from neural network descriptions down to synthesis and gatelevelarXiv:2209.03807v2  [cs.SD]  29 Sep 2022power estimation. 2)We propose a modelguided hardware and neural network cooptimization and architecture exploration Ô¨Çow for ultralow power devices. 3)The combined Ô¨Çow reaches stateoftheart results on a variety audio detection tasks. II. R ELATED WORK "
142,"From Speaker Verification to Multispeaker Speech Synthesis, Deep Transfer with Feedback Constraint.txt","High-fidelity speech can be synthesized by end-to-end text-to-speech models
in recent years. However, accessing and controlling speech attributes such as
speaker identity, prosody, and emotion in a text-to-speech system remains a
challenge. This paper presents a system involving feedback constraint for
multispeaker speech synthesis. We manage to enhance the knowledge transfer from
the speaker verification to the speech synthesis by engaging the speaker
verification network. The constraint is taken by an added loss related to the
speaker identity, which is centralized to improve the speaker similarity
between the synthesized speech and its natural reference audio. The model is
trained and evaluated on publicly available datasets. Experimental results,
including visualization on speaker embedding space, show significant
improvement in terms of speaker identity cloning in the spectrogram level.
Synthesized samples are available online for listening.
(https://caizexin.github.io/mlspk-syn-samples/index.html)","Speech synthesis, also known as texttospeech (TTS), speciÔ¨Åes the technique that achieves the transformation from text to audio waveform. It has been widely used in our daily life, e.g., navi gation systems, audiobooks, and virtual assistants. The perfor mance of the TTS system has been further improved recently by adopting the endtoend neural network framework [1, 2, 3, 4]. The endtoend principle is applied in the TTS model by a cohe sive and autoregressive chain of neural network structures that are connected by welldeÔ¨Åned inputoutput features. For in stance, the stateoftheart system Tacotron2 [2] consists of an encoderdecoder architecture and a neural vocoder Wavenet[5]. Extensions on these models have been developed for allow ing the TTS system to control the speech characteristics. These extensions are able to enrich the expressiveness of the synthe sized voice and further enhance the robustness of TTS systems. For example, Yuxuan Wang et al. proposed the style tokens to uncover the latent space regarding speech attributes that are hard to deÔ¨Åne and label [6, 7]. The models are jointly trained with the Tacotronbased TTS architecture in an unsupervised manner. On the other hand, controlling speech attributes that have easily found labels (e.g., language, emotion, and speaker identity) have also been investigated [8, 9, 10]. Typically, the speech attribute is controlled with a TTS model by conditioning the synthesizer with the vector representation called embedding. The multispeaker TTS system is one of the extensions, which is developed to clone and manage distinct voices either seen or not seen during training. Most systems use the speaker 1https://caizexin.github.io/mlspksynsamples/index.htmlembedding to characterize the expected voice and speaking style in the multispeaker TTS system [10, 11, 12], while speaker adaptation can also be used for speaker transfer TTS model ing [13]. V oice cloning by speaker adaptation acquires more data and computational resource for the target voice and usu ally is less robust compared with cloning by speaker embedding [14]. The speaker veriÔ¨Åcation system plays an essential role in the multispeaker TTS system for cloning unseen voices. Eliya Nachmani et al. has proposed an approach where the speaker veriÔ¨Åcation system and the synthesizer are jointly trained [15]. However, the knowledge for discriminative speaker representa tions is limited by the training dataset in this case. Then Ye Jia et al. further investigated the knowledge transfer in terms of speaker characteristics by decoupling these two tasks, where the speaker veriÔ¨Åcation network is trained with a dataset that contains a larger amount of speakers but is not suitable for TTS training [10]. The discriminative speaker embedding extracted from the speaker veriÔ¨Åcation network is used for conditioning the TTS synthesizer and leads to better performance on openset voice cloning. Although the model proposed in [10] increases the robust ness of the synthesizer for openset multispeaker synthesis, the speaker‚Äôs similarity is not close between the synthesized speech and the speaker‚Äôs natural speech. Concerning the same speaker, the embeddings extracted from synthesized speech and those extracted from natural speech may have two distinct distribu tions. To further transfer the knowledge from a speaker ver iÔ¨Åcation model to the speech synthesizer, we propose a mul tispeaker TTS model with the feedback constraint toward the speaker embedding space. SpeciÔ¨Åcally, an added score asso ciated with the speaker similarity is performed by the veriÔ¨Åca tion network for forcing the synthesizer to derive the knowledge for speaker identity cloning. The proposed method is evaluated on publicly available datasets. As demonstrated in the visual ization of the embedding space, speaker embeddings extracted from our synthesized speech lies in the same cluster as those from natural speech. Therefore, the model may be useful for data augmentation and the whitebox spooÔ¨Ång attack toward speaker veriÔ¨Åcation in the future. This paper is organized as follows: section 2 describes the related works in terms of speaker veriÔ¨Åcation and speech syn thesis. Our proposed system is presented in section 3. Exper imental setup and results are shown in section 4. Finally, we conclude the paper in section 5. 2. Related works "
115,Verifying Generalization in Deep Learning.txt,"Deep neural networks (DNNs) are the workhorses of deep learning, which
constitutes the state of the art in numerous application domains. However,
DNN-based decision rules are notoriously prone to poor generalization, i.e.,
may prove inadequate on inputs not encountered during training. This limitation
poses a significant obstacle to employing deep learning for mission-critical
tasks, and also in real-world environments that exhibit high variability. We
propose a novel, verification-driven methodology for identifying DNN-based
decision rules that generalize well to new input domains. Our approach
quantifies generalization to an input domain by the extent to which decisions
reached by independently trained DNNs are in agreement for inputs in this
domain. We show how, by harnessing the power of DNN verification, our approach
can be efficiently and effectively realized. We evaluate our verification-based
approach on three deep reinforcement learning (DRL) benchmarks, including a
system for Internet congestion control. Our results establish the usefulness of
our approach. More broadly, our work puts forth a novel objective for formal
verification, with the potential for mitigating the risks associated with
deploying DNN-based systems in the wild.","Over the past decade, deep learning [41] has achieved stateoftheart results in natural language processing, image recognition, game playing, computational biology, and many additional elds [4, 18, 24, 51, 56, 93, 94]. However, despite its impressive success, deep learning still suers from severe drawbacks that limit its applicability in domains that involve missioncritical tasks or highly variable inputs. One such crucial limitation is the notorious diculty of deep neural networks (DNNs) to generalize to new input domains, i.e., their tendency to perform poorly on inputs that signicantly dier from those encountered while training. During training, a DNN is presented with input data sampled from a specic dis tribution over some input domain (\ indistribution "" inputs). The induced DNN based rules may fail in generalizing to inputs not encountered during training due to (1) the DNN being invoked \outofdistribution"" (OOD), i.e., when there is a mismatch between the distribution over inputs in the training data and in the DNN's operational data; (2) some inputs not being suciently represented [*] Both authors contributed equally.arXiv:2302.05745v2  [cs.LG]  9 May 2023in the nite training data (e.g., various lowprobability corner cases); and (3) \overtting"" the decision rule to the training data. A notable example of the importance of establishing the generalizability of DNNbased decisions lies in recently proposed applications of deep reinforce ment learning (DRL) [62] to realworld systems. Under DRL, an agent , realized as a DNN, is trained by repeatedly interacting with its environment to learn a decisionmaking policy that attains high performance with respect to a certain objective (\ reward ""). DRL has recently been applied to many realworld chal lenges [22, 50, 60, 61, 70{73, 105, 117]. In many application domains, the learned policy is expected to perform well across a daunting breadth of operational en vironments, whose diversity cannot possibly be captured in the training data. Further, the cost of erroneous decisions can be dire. Our discussion of DRLbased Internet congestion control (see Sec. 4.3) illustrates this point. Here, we present a methodology for identifying DNNbased decision rules that generalize well to all possible distributions over an input domain of interest. Our approach hinges on the following key observation. DNN training in general, and DRL policy training in particular, incorporate multiple stochastic aspects, such as the initialization of the DNN's weights and the order in which inputs are observed during training. Consequently, even when DNNs with the same architecture are trained to perform an identical task on the same data, somewhat dierent decision rules will typically be learned. Paraphrasing Tolstoy's Anna Karenina [102], we argue that \successful decision rules are all alike; but every unsuccessful decision rule is unsuccessful in its own way"". Dierently put, when examining the decisions by several independently trained DNNs on a certain input, these are likely to agree only when their (similar) decisions yield high performance. In light of the above, we propose the following heuristic for generating DNN based decision rules that generalize well to an entire given domain of inputs: independently train multiple DNNs, and then seek a subset of these DNNs that are in strong agreement across allpossible inputs in the considered input domain (implying, by our hypothesis, that these DNNs' learned decision rules generalize well to all probability distributions over this domain). Our evaluation demon strates (see Sec. 4) that this methodology is extremely powerful and enables distilling from a collection of decision rules the few that indeed generalize better to inputs within this domain. Since our heuristic seeks DNNs whose decisions are in agreement for each and every input in a specic domain, the decision rules reached this way achieve robustly high generalization across dierent possible distributions over inputs in this domain. Since our methodology involves contrasting the outputs of dierent DNNs over possibly innite input domains, using formal verication is natural. To this end, we build on recent advances in formal verication of DNNs [2, 11, 13, 15,31,66,84,95,111]. DNN verication literature has focused on establishing the local adversarial robustness of DNNs, i.e., seeking small input perturbations that result in misclassication by the DNN [37, 42, 67]. Our approach broadens the applicability of DNN verication by demonstrating, for the rst time (to the bestof our knowledge), how it can also be used to identify DNNbased decision rules that generalize well. More specically, we show how, for a given input domain, a DNN verier can be utilized to assign a score to a DNN re ecting its level of agreement with other DNNs across the entire input domain. This enables iteratively pruning the set of candidate DNNs, eventually keeping only those in strong agreement, which tend to generalize well. To evaluate our methodology, we focus on three popular DRL benchmarks: (i)Cartpole , which involves controlling a cart while balancing a pendulum; (ii)Mountain Car , which involves controlling a car that needs to escape a valley; and (iii) Aurora , an Internet congestion controller. Aurora is a particularly compelling example for our approach. While Aurora is intended to tame network congestion across a vast diversity of realworld Internet environments, Aurora is trained only on synthetically generated data. Thus, to deploy Aurora in the real world, it is critical to ensure that its policy is sound for numerous scenarios not captured by its training inputs. Our evaluation results show that, in all three settings, our vericationdriven approach is successful at ranking DNNbased DRL policies according to their ability to generalize well to outofdistribution inputs. Our experiments also demonstrate that formal verication is superior to gradientbased methods and predictive uncertainty methods. These results showcase the potential of our ap proach. Our code and benchmarks are publicly available as an artifact accom panying this work [7]. The rest of the paper is organized as follows. Sec. 2 contains background on DNNs, DRLs, and DNN verication. In Sec. 3 we present our vericationbased methodology for identifying DNNs that successfully generalize to OOD inputs. We present our evaluation in Sec. 4. Related work is covered in Sec. 5, and we "
345,Model-Agnostic Reachability Analysis on Deep Neural Networks.txt,"Verification plays an essential role in the formal analysis of
safety-critical systems. Most current verification methods have specific
requirements when working on Deep Neural Networks (DNNs). They either target
one particular network category, e.g., Feedforward Neural Networks (FNNs), or
networks with specific activation functions, e.g., RdLU. In this paper, we
develop a model-agnostic verification framework, called DeepAgn, and show that
it can be applied to FNNs, Recurrent Neural Networks (RNNs), or a mixture of
both. Under the assumption of Lipschitz continuity, DeepAgn analyses the
reachability of DNNs based on a novel optimisation scheme with a global
convergence guarantee. It does not require access to the network's internal
structures, such as layers and parameters. Through reachability analysis,
DeepAgn can tackle several well-known robustness problems, including computing
the maximum safe radius for a given input, and generating the ground-truth
adversarial examples. We also empirically demonstrate DeepAgn's superior
capability and efficiency in handling a broader class of deep neural networks,
including both FNNs, and RNNs with very deep layers and millions of neurons,
than other state-of-the-art verification approaches.","DNNs, or systems with neural network components, are widely applied in many applications such as image processing, speech recognition, and medical diagnosis [10]. However, DNNs are vulnerable to adversarial examples [25] [12] [33]. It is vital to analyse the safety and robustness of DNNs before deploying them in practice, particularly in safetycritical applications. The research on evaluating the robustness of DNNs mainly falls into two cat egories: falsiÔ¨Åcationbased and veriÔ¨Åcationbased approaches. While falsiÔ¨Åcation approaches (e.g. adversarial attacks) [11]can eÔ¨Äectively Ô¨Ånd adversarial exam ples, they cannot provide theoretical guarantees. VeriÔ¨Åcation techniques, on the other hand, can rigorously prove the robustness of deep learning systems witharXiv:2304.00813v1  [cs.LG]  3 Apr 20232 C. Zhang, W. Ruan et al. Fig. 1.Illustration of DeepAgn working on a blackbox threeoutput neural network. In reachability problem, given a set of inputs (quantiÔ¨Åed by a predeÔ¨Åned Lpnorm ball) and a welltrained blackbox neural network, DeepAgn can calculate the output range, namely, the minimal and maximum output conÔ¨Ådence of each label (i.e., [y1min;y1max], [y2min;y2max], and [y3min;y3max]). For the safety veriÔ¨Åcation problem, we can use a binary search upon the reachability to Ô¨Ånd the maximum safe radius rmaxwhere the conÔ¨Ådence intervals of the original label y1and target label y2meet. guarantees [18,19,12,13,24]. Some researchers propose to reduce the safety veriÔ¨Å cation problems to constraint satisfaction problems that can be tackled by con straint solvers such as MixedInteger Linear Programming (MILP) [1],Boolean SatisÔ¨Åability (SAT) [20], or SatisÔ¨Åability Modulo Theories (SMT) [15]. An other popular technique is to apply search algorithms [13] or Monte Carlo tree search [32] over discretised vector spaces on the inputs of DNNs. To improve the eÔ¨Éciency, these methods can also be combined with a heuristic searching strategy to search for a counterexample or an activation pattern that satisÔ¨Åes certain constraints, such as SHERLOCK [4] and Reluplex [15]. Nevertheless, the study subjects of these veriÔ¨Åcation methods are restricted. They either target speciÔ¨Åc layers (e.g., fullyconnected or convolutional layers), have restrictions on activation functions (e.g., ReLU activation only), or are only workable on a speciÔ¨Åc neural network structure (e.g., feedforward neural networks). Particu larly, in comparison to FNNs, veriÔ¨Åcation on RNNs is still in its infancy, with only a handful of representative works available, including [16,14,34]. The adop tion of [16] requires short input sequences, and [14,34] can result in irresolvable overapproximation error. This paper proposes a novel modelagnostic solution for safety veriÔ¨Åcation on both feedforward and recurrent neural networks without suÔ¨Äering from the above weaknesses. Figure 1 outlines the working principle of DeepAgn, demon strating its safety evaluation process and the calculation of the maximum safety radius. To the best of our knowledge, DeepAgn is one of the pioneering attempts onmodelagnostic veriÔ¨Åcation that can work on both modern feedforward and recurrent neural networks under a uniÔ¨Åed framework. DeepAgn can deal with DNNs with very deep layers, a large number of neurons, and any type of acti vation function, via a blackbox manner (without access to the internal struc tures/parameters of the network). Our contributions are summarised below: ‚ÄìTo theoretically justify the applicability of DeepAgn, we prove that recurrent neural networks are also Lipschitz continuous for bounded inputs.ModelAgnostic Reachability Analysis on Deep Neural Networks 3 Table 1. Comparison with other veriÔ¨Åcation techniques from diÔ¨Äerent aspects Guarantees Core Techniques Neural Network TypesModel AgnosticExact ComputationModel Access Reluplex [15] Deterministic SMT+LP ReLubased FNNs 7 3 Model parameters Planet[5] Deterministic SAT+LP ReLUbased FNNs 7 3 Model parameters AI2[6] Upper bound Abstract Interpretation ReLUbased FNNs 7 7 Model Parameters ConDual [31] Upper bound Convex relaxation ReLUbased FNNs 7 7 Model parameters DeepGO [24] Converging bound Lipschitz OptimisationFNNs with Lipschitz continuous layers (ReLU, Sigmoid, Tanh, etc.)7 3 ConÔ¨Ådence values FastLip [29] Upper bound Lipschitz estimation ReLUbased FNNs 7 7 Model parameters DeepGame [32]Approximated converging boundSearch based ReLU/Tanh/Sigmod based FNNs 7 3 ConÔ¨Ådence values POPQORN [16]Upper bound Unrolling RNNs, LSTMs, GRUs 7 7 Model parameters RnnVerify [14] Upper bound Invariant Inference RNNs 7 7 Model parameters VERRNN [34] Upper bound Unrolling+MILP RNNs 7 7 Model parameters DeepAgn Converging bound Lipschitz OptimisationFNNs (CNNs), RNNs, Hybrid networks with Lipschitz continuous layers3 3 ConÔ¨Ådence values ‚ÄìWedevelopaneÔ¨ÉcientmethodforreachabilityanalysisonDNNs.Wedemon strate that this genericanduniÔ¨Åedmodelagnostic veriÔ¨Åcation framework can work on FNNs, RNNs, and a hybrid of both. DeepAgn is an anytime algorithm, i.e., it can return both intermediate lower and upper bounds that are gradually, but strictly, improved as the computation proceeds; and it has provable guarantees, i.e., both the bounds can converge to the optimal value within an arbitrarily small error with provable guarantees. ‚ÄìOur experiments demonstrate that DeepAgn outperforms the stateofthe art veriÔ¨Åcation tools in terms of both accuracy and eÔ¨Éciency when dealing with complex, large and hybrid deep learning models. 2 Related Work "
153,Optimising the topology of complex neural networks.txt,"In this paper, we study instances of complex neural networks, i.e. neural
netwo rks with complex topologies. We use Self-Organizing Map neural networks
whose n eighbourhood relationships are defined by a complex network, to
classify handwr itten digits. We show that topology has a small impact on
performance and robus tness to neuron failures, at least at long learning
times. Performance may howe ver be increased (by almost 10%) by artificial
evolution of the network topo logy. In our experimental conditions, the evolved
networks are more random than their parents, but display a more heterogeneous
degree distribution.","The connectivity structure of complex networks (i.e. their topolog y) is a cru cial determinant of information transfer in large networks (intern et, social networks, metabolic networks...) [1]. Hence, the computation made b y com plex neural networks, i.e. neural networks with complex connectiv ity struc ture, could be dependent on their topology. For instance, recent studies have shown that introducing a smallworld topology in a multilayer perceptr on increases its performance [13, 2]. However, other studies have ins pected the performance of HopÔ¨Åeld [5, 10, 9, 14] or Echo state networks [3] w ith small world or scalefree topologies and reported more contrasted res ults. Using artiÔ¨Åcial evolutionary algorithms to modify the topology of neu  ral networks so as to optimise their performance has become wides pread in the artiÔ¨Åcial neural networks community for several years [11, 1 6]. But, in most cases, the studied topologies are quite simple and the number o f connec tions/neurons is low. Furthermore, the evolutionary mechanisms u sed in most of these studies do not modify the topology in an intensive manner. H ence, the optimisation of large, complex neural networks through artiÔ¨Åc ial evolu tion has hardly been studied. Note however that in related systems , such has 1Dcellular automata [8] or boolean networks [12], the optimisation of com plex topologies has recently begun to conÔ¨Årm the inÔ¨Çuence of topolo gy on performance and the interest of evolutionary algorithms.2 Fei Jiang, Hugues Berry, and Marc Schoenauer In the case of SelfOrganising (or Kohonen) maps (SOMs), the role of network topology has been studied for several years with the per spective of the development of network topologies that preserve that of the data [15]. In the context of complex networks, a diÔ¨Äerent problem is: considerin g a given data set, do diÔ¨Äerent complex network topologies yield signiÔ¨Åcant diÔ¨Ä erences with respect of performance or robustness? This paper investigates this issue through an experimental study o n the relationship between complex topology and performance for a SOM o n a su pervised learning problem (handwritten digit classiÔ¨Åcation). The rob ustness of the results with respect to noise are also addressed. After intr oducing the context in Section 2, Section 3 is devoted to the direct problem , i.e. observing the performances of networks with diÔ¨Äerent topologies. The inverse problem is addressed in Section 4: what topology emerges from the evolution ary opti misation of the classiÔ¨Åcation accuracy of a class of networks? 2 Methods & Experiments "
477,Explaining Deep Learning Hidden Neuron Activations using Concept Induction.txt,"One of the current key challenges in Explainable AI is in correctly
interpreting activations of hidden neurons. It seems evident that accurate
interpretations thereof would provide insights into the question what a deep
learning system has internally \emph{detected} as relevant on the input, thus
lifting some of the black box character of deep learning systems.
  The state of the art on this front indicates that hidden node activations
appear to be interpretable in a way that makes sense to humans, at least in
some cases. Yet, systematic automated methods that would be able to first
hypothesize an interpretation of hidden neuron activations, and then verify it,
are mostly missing.
  In this paper, we provide such a method and demonstrate that it provides
meaningful interpretations. It is based on using large-scale background
knowledge -- a class hierarchy of approx. 2 million classes curated from the
Wikipedia Concept Hierarchy -- together with a symbolic reasoning approach
called \emph{concept induction} based on description logics that was originally
developed for applications in the Semantic Web field.
  Our results show that we can automatically attach meaningful labels from the
background knowledge to individual neurons in the dense layer of a
Convolutional Neural Network through a hypothesis and verification process.","The origins of Articial Intelligence trace back several decades ago, and AI has been successfully applied to multiple complex tasks such as image classication [25], speech recognition [11], language translation [2], drug design [31], treatment diagnosis [9], and climate sciences [21], as an instance for just a few. Articially intelligent machines reach exceptional performance levels in learning to solve more and more complex computational problems by possessing the capabilities of learning, thinking, and adapting { mimicking human behavior to some extent, making them crucial for future development. Despite their success in a wide variety of tasks, there is a general distrust of their results. Powerful AI machines particularly Deep Neural Networks, arearXiv:2301.09611v1  [cs.LG]  23 Jan 20232 Dalal, A., Sarker, M., Barua, A, and Hitzler, P. hard to explain and are often referred to as ""Black Boxes"" simply because there are no clear humanunderstandable explanations as to why the network gave the particular output. Many cases have been reported; for example, In 2019 Apple cofounder Steve Wozniak accused Apple Card of gender discrimination, claiming that the card gave him a credit limit that was ten times higher than that of his wife, even though the couple shares all property.3. In CEO image search, while 27% of US CEOs were women, only 11% of the top image results for \CEOs"" were featured as women.4In continuation to the mentioned observation, the output of a network's classication can be altered by introducing Adversarial examples [6], and there are many more attack techniques. It becomes a need to understand the reasoning behind how a system behaves and generates an output in a humaninterpretable way, especially since the popularity of these systems has grown to such an extent that these systems are responsible for decisions previously taken by human beings in safetycritical situations, for example like selfdriving cars [8], drug discovery and treatment recommendations [27,12]. Explainable AI has been pursued for several years already, and the quest for ecient algorithms to generate humanunderstandable explanations has led to a signicant number of contributions based on dierent approaches. or internal unit summarizing [36,6]. Improvements in deep learning show that neurons in the hidden layer of the neural network can detect humaninterpretable concepts that were not explicitly taught to the network, such as objects, parts, gender, context, sentiment etc [4,18,24]. In our approach which we present in this paper, we make central use of concept induction [20], which has been developed for use in the Semantic Web eld and is based on deductive reasoning over description logics, i.e., over logics relevant to ontologies, knowledge graphs and generally the Semantic Web eld [17,16]. In a nutshell { and more details are given below { a concept induction system accepts three inputs, a set of positive examples P, a set of negative examples N, and a knowledge base (or ontology) K, all expressed as description logic theories, and where we have xoccurring as instances (constants) in K for all x2P[N. It then returns description logic class expressions Esuch thatKj=E(p) for all p2PandK6j=E(q) for all q2N. If no such class expressions exist, then it returns approximations for Etogether with a number of accuracy measures. In this paper, for scalability reasons, we use the heuristic concept induction system ECII [28] together with a background knowledge base that consists only of a class hierarchy, however with approximately 2 million classes, as presented in [29]. Given a hidden neuron, Pis a set of inputs to the deep learning system that activate the neuron, and Nis a set of inputs that do not activate the neuron. Inputs are annotated with classes from the background knowledge for concept induction, however these annotations and the background knowledge are not part of the input to the deep learning system. 3https://worldline.com/en/home/knowledgehub/blog/2021/january/everheardof theaIblackboxproblem.html 4https://www.mckinsey.com/featuredinsights/articialintelligence/tacklingbias inarticialintelligenceandinhumansExplaining Hidden Neuron Activations using Concept Induction 3 As we will see below, this approach is able to provide meaningful explanations for hidden neuron activation. The rest of this paper is organized as follows. Section 2 discusses relevant work in the led of generating explanations using knowledge graph. Sections 3 present our study design and Section 4 discusses the results of our study along with the ndings and their implications. Finally, Section 5 sums up the paper and proposes some possibilities for future research. 2 Related Work "
252,Power Law in Sparsified Deep Neural Networks.txt,"The power law has been observed in the degree distributions of many
biological neural networks. Sparse deep neural networks, which learn an
economical representation from the data, resemble biological neural networks in
many ways. In this paper, we study if these artificial networks also exhibit
properties of the power law. Experimental results on two popular deep learning
models, namely, multilayer perceptrons and convolutional neural networks, are
affirmative. The power law is also naturally related to preferential
attachment. To study the dynamical properties of deep networks in continual
learning, we propose an internal preferential attachment model to explain how
the network topology evolves. Experimental results show that with the arrival
of a new task, the new connections made follow this preferential attachment
process.","The power law distribution has been commonly used to describe the underlying mechanisms of a wide variety of physical, biological and manmade networks [1]. Its probability density function is of the form: f(x)/x"
168,Practical No-box Adversarial Attacks against DNNs.txt,"The study of adversarial vulnerabilities of deep neural networks (DNNs) has
progressed rapidly. Existing attacks require either internal access (to the
architecture, parameters, or training set of the victim model) or external
access (to query the model). However, both the access may be infeasible or
expensive in many scenarios. We investigate no-box adversarial examples, where
the attacker can neither access the model information or the training set nor
query the model. Instead, the attacker can only gather a small number of
examples from the same problem domain as that of the victim model. Such a
stronger threat model greatly expands the applicability of adversarial attacks.
We propose three mechanisms for training with a very small dataset (on the
order of tens of examples) and find that prototypical reconstruction is the
most effective. Our experiments show that adversarial examples crafted on
prototypical auto-encoding models transfer well to a variety of image
classification and face verification models. On a commercial celebrity
recognition system held by clarifai.com, our approach significantly diminishes
the average prediction accuracy of the system to only 15.40%, which is on par
with the attack that transfers adversarial examples from a pre-trained Arcface
model.","The adversarial vulnerability of deep neural networks (DNNs) have been extensively studied over the past few years [ 46,12,35,30,3,29,1]. It has been demonstrated that an attacker is able to generate small, humanimperceptible perturbations to fool advanced DNN models to make incorrect decisions. These attacks pose great threats to securitycritical systems where DNNs are deployed and lead to increasing concerns about the robustness of DNNs. Based on how much information the attacker knows, we can divide existing attacks into whitebox and blackbox settings. In blackbox attacks, the attacker cannot access the architecture, the parameters, or the training data of the victim model. Early attempts for blackbox adversarial attacks [ 33,34] relied on the transferability of adversarial examples. They trained substitute architectures by querying the victim models. Recent progress considered gradient estimation [ 5,20,50,21,13,6,4] and boundary tracing [2]. Blackbox attacks rely on querying the victim models, a.k.a. , ‚Äúoracles‚Äù. However, in many scenarios, such queries are either infeasible (e.g., the model API is inaccessible to the attacker) or are expensive in time or money. To overcome this limitation, we consider a stronger threat model where the attacker makes no query to the victim model (and also has no access to the model parameters or its training data). This was coined as the ‚Äúnobox‚Äù threat model [ 5] but no practical attack has been studied to the best of our knowledge. We investigate such nobox attacks against DNNs on computer vision models. Similar to some strong blackbox attacks [ 34], we assume that the attacker can access neither a large ‚àóWork done during an internship at ByteDance ‚Ä†Corresponding author 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.arXiv:2012.02525v1  [cs.CV]  4 Dec 2020scale training data nor pretrained models on it. Instead, she or he can collect only a small number of auxiliary examples (on the order of tens or less) from the same problem domain. Given this small sample size, it is challenging to obtain a substitute model using conventional supervised training. Inspired by recent advances in unsupervised representation learning and distribution modeling [ 48, 41], we developed autoencoders that can learn discriminative features given very little data ,e.g.,20 images from 2classes. We investigated three training mechanisms by (a) estimating the front view of each rotated image, (b) estimating the best Ô¨Åt of each possible jigsaw puzzle, and (c) constructing prototypical images, respectively. They entail discriminative and, more importantly, generalizable feature representations. We evaluated our approach on two computer vision tasks: image classiÔ¨Åcation and face veriÔ¨Åcation. Our experiments show that adversarial examples crafted on such autoencoding models transfer well to a variety of opensource victim models, and their effectiveness is sometimes even on par with those crafted using pretrained models trained on the same largescale data set as the victim models. On a celebrity recognition system hosted by clarifai.com , our approach reduced the prediction accuracy of the system from 100.00% to only 15.40%, using only 10facial images for training and crafting each adversarial example. We also studied the quality of the generated adversarial example in such a way, and we showed in the supplementary materials that the generated nobox adversarial examples were intrinsically different from the adversarial examples generated in the whitebox/blackbox settings, which probably worth further exploring. 2 Related Work "
189,A Fast Exact Quantum Algorithm for Solitude Verification.txt,"Solitude verification is arguably one of the simplest fundamental problems in
distributed computing, where the goal is to verify that there is a unique
contender in a network. This paper devises a quantum algorithm that exactly
solves the problem on an anonymous network, which is known as a network model
with minimal assumptions [Angluin, STOC'80]. The algorithm runs in $O(N)$
rounds if every party initially has the common knowledge of an upper bound $N$
on the number of parties. This implies that all solvable problems can be solved
in $O(N)$ rounds on average without error (i.e., with zero-sided error) on the
network. As a generalization, a quantum algorithm that works in $O(N\log_2
(\max\{k,2\}))$ rounds is obtained for the problem of exactly computing any
symmetric Boolean function, over $n$ distributed input bits, which is constant
over all the $n$ bits whose sum is larger than $k$ for $k\in \{0,1,\dots,
N-1\}$. All these algorithms work with the bit complexities bounded by a
polynomial in $N$.","1.1 Background Insynchronous distributed modelsofcomputation, thenumb er ofrounds (alsocalledtheroundcomplexity) is one of the most important complexity measures, especiall y when we want to design fast distributed algorithms. From a complexitytheoretic point of view, see king lowround complexity leads to clarifying howmuchparallelism theproblem inherently has. Thiswould bereminiscent ofthestudyofshallow circuit classes (e.g., NC), in which the depth of a circuit solving a problem correspon ds to the inherent parallelism of the problem. In this paper, westudy distributed algorith ms with lowround complexity. Theroundcomplexityiscloselyrelatedtothediameter ofth eunderlying graphofagivennetwork. This is because, when computing global properties of the network , it necessarily takes at least as many rounds formessageexchanges asthevalueofthediameterforsomepa rtytogetinformationfromthefarthest party. Therefore, when every party‚Äôs initial knowledge includes a n upper bound ‚àÜon the diameter, the ultimate goal is to achieve a round complexity close to (typically, li near in)‚àÜ. In particular, we are interested in whether the round complexity O(n)(resp.,O(N)) can be achieved when every party‚Äôs initial knowledge includes the number nof parties (resp., an upper bound Nonn). This can actually be achieved in a straightforwardmannerifthereisauniqueparty(calledth eleader)distinguishablefromtheothersor,almost equivalently, if every party has its own identity: The uniqu e leader, which can be elected in O(‚àÜ)rounds if every party has its own identity, can gather all the distri buted inputs, solve the problem, and distribute the solution to every party in O(‚àÜ)rounds. However, it is not a simple task to bound the achievab le round complexity for networks where no party has its own identity ( namely, all parties with the same number of communication links are identical). Such a network is cal led ananonymous network , which was Ô¨Årst introduced byAngluin [Ang80] toexamine how mucheach party inanetwork needs toknowabout itsown identity and other parties‚Äô (e.g., Refs. [IR81, IR90, AM94, KKvdB94, BSV+96, YK96a, YK96b, BV02]), 1and thereby understand the fundamental properties of distr ibuted computing. It has been revealed in the literature that anonymous networks make it highly nontriv ial or even impossible to exactly solve many distributed problems, including the leader election one, t hat are easy to solve on nonanonymous networks (i.e., the networks in which every party has its own identity ). Here, by ‚Äúexactly solve‚Äù, we mean ‚Äúsolve without error within a bounded time‚Äù. The good news is that if the numbernof parties is provided to each party, all solvable problems can be solved exactly in O(n)rounds1for any unknown underlying graph by constructing treeshaped data structures, called univers al covers [Ang80] or views [YK96a]. Obviously, however, this does not help us deal with the inÔ¨Ånitely many in stances of fundamental problems that are impossible to solve on anonymous networks. The best known am ong them is the leader election problem (LEn), the problem of electing a unique leader. There are inÔ¨Ånite ly manynsuch that LEncannot be solved exactly for anonymous networks with certain underlying gra phs overnnodes even if nis provided to each party [Ang80, YK96a, BV02]. The above situation changes drastically if quantum computa tion and communication are allowed on anonymous networks (called anonymous quantum networks ):LEncan be solved exactly for any unknown underlyinggraph,evenwhenonlyanupperbound Nonnisprovidedtoeveryparty[TKM12]. Thisimplies that, if a problem is solvable in nonanonymous networks, th en it is also solvable in anonymous quantum networks. For the round complexity, however, the known quan tum algorithms for electing a unique leader require superlinear rounds in N(ornwhennisprovided) [TKM05,TKM12]. Motivatedbythissituation, westudythelinearround exac tsolvability ofanother fundamental problem, thesolitudeveriÔ¨Åcationproblem( SVn)[AAHK86,AAHK94,HKAA97],inanonymousquantumnetworks. Thegoalof SVnistoverifythatthereisauniquecontender inanetworkwith anunknownsetofcontenders (which may be empty) among the nparties. Although the Ô¨Ånal target is to clarify whether a uni que leader can beelectedin linear rounds or not, SVnwould be a natural choice as the Ô¨Årst step. This is because SVn is a subproblem of many common problems, including the leade r election problem: a unique leader can be elected by repeating attrition and solitude veriÔ¨Åcation as observed in Ref. [AAHK86]. Another reason is thatSVnisoneofthesimplest nontrivial problems concerned withth eglobal properties ofagivennetwork, as pointed out in Ref. [AAHK94]. Indeed, SVnis not always solvable in the classical case: One can easily show, by modifying the proof of Theorem 4.5inRef. [Ang80],t hat it is impossible toexactly solve SVnon anyanonymousclassicalnetworkwhoseunderlying graphisn otatreeifonlyanupperbound Nisprovided to each party (the problem can be solved exactly in O(n)rounds ifnis provided). In the quantum setting, the only quantum algorithms for SVnare the straightforward ones that Ô¨Årst elect a unique leader (with a superlinear round complexity), who then veriÔ¨Åes that ther e is aunique contender. Recently, Kobayashi et al. [KMT14] proposed an O(N)round quantum algorithm when each communication link in the network is bidirectional, i.e., t he underlying graph is undirected. However, their algorithm cannotwork in the more general case where the underlying graph is di rected. This is due to a technicality that isdistinctive inquantum computing: The iralgorithm usesastandard quantum technique to erase‚Äúgarbage‚Äù information generated inthecourseofcomp utation. Thetechnique inverts someoperations that have been performed and thus involves sending back mess ages via bidirectional communication links inthe distributed computing setting. 1.2 OurResults LetDnbe the set of all strongly connected digraphs with nnodes. Our main result is an O(N)round quantum algorithm that exactly solves SVn, where the input to each party is a binary value indicating whether theparty isacontender or not (see Sec. 2.2for amore formal deÔ¨Ånition). 1If the diameter Œ¥isgiven, allsolvable problems canbe solved in O(Œ¥)rounds [Hen14]. 2Theorem 1 There exists a quantum algorithm that, if an upper bound Non the number nof parties is provided to each party, exactly solves SVninO(N)rounds with bit complexity ÀúO(N8)on an anonymous network withany unknown underlying graph in Dn. As described previously, we are most interested in whether LEncan be solved exactly in O(N)rounds. For the present, we do not have an answer to this question. We c an, however, obtain a partial answer as a corollary of Theorem 1: There exists an O(N)roundzeroerror quantum algorithm for LEn. Here, we say that a problem is solved with zero error if there exists an algorithm that outputs a correct answer with probability at least 1‚àí«´and gives up with probability at most «´, where«´is some nonnegative constant less than1. Wecan assume without loss of generality that «´isanarbitrarily small constant, since aconstant number of repetitions reduce the ‚Äúgiveup‚Äù probability to a n arbitrary small constant, which changes the complexity by at most aconstant factor. Corollary 2 There exists a zeroerror quantum algorithm that, if an uppe r boundNon the number nof parties is provided to each party, solves LEninO(N)rounds with bit complexity ÀúO(N9)on an anonymous network withany unknown underlying graph in Dn. This implies that in the quantum setting, anonymous network s can be converted to the corresponding nonanonymous ones without error in O(N)rounds on average, since a unique leader can assign a unique number to each party in O(N)rounds (in the worst case). In the special case of N=O(n), if a classical problem is solvable in a nonanonymous classi cal/quantum network in O(n)rounds with a polynomial bit complexity, then in the corresponding anony mous networks the problem is still solvable without error in O(n)rounds on average withapolynomial bit complexity whenever quantum computation and communication are allowed. We next consider a generalization of Theorem 1. Note that we c an think of SVnas the problem of deciding whether the Hamming weight (i.e., the sum) of the ninput bits is exactly one or not, which is equivalent to computing the corresponding symmetric funct ion. As generalizations of this function, let us consider a collection Sn(k), fork‚àà{0,1,...,N‚àí1}, of all symmetric Boolean functions f:{0,1}n‚Üí {0,1}such thatf(x)is constant over all x:= (x1,...,x n)‚àà {0,1}nwith/summationtextn i=1xi> k. Note that Sn(k)‚äÇSn(k+1)foreachk‚àà[0..n‚àí2], andSn(k)foranyk‚â•n‚àí1represents thesetofallsymmetric functions over nbits. In particular, the function corresponding to SVnbelongs toSn(1). We then have the following theorem. Theorem 3 Suppose that there are nparties on an anonymous network with any unknown underlying graph inDnin which an upper bound Nonnis provided to each party. For every f‚àà Sn(k)with k‚àà{0,1,...,N‚àí1}, there exists a quantum algorithm that exactly computes f(x)over distributed input x‚àà {0,1}non the network in O(Nlog2(max{k,2}))rounds with a bit complexity bounded by some polynomial in N. Note that an O(N)round quantum algorithm for LEnwould imply that all solvable problems, including computingSn(k), can besolved in O(N)rounds (since the leader canconvert theanonymous network i nto the corresponding nonanonymous one). Computing Sn(k)is thus something lying between SVnandLEn withrespect tolinearround solvability. 1.3 Technical Outline Recallthatthereasonthe O(N)roundleaderelectionalgorithminRef.[KMT14]doesnotwo rkondirected graphs isthat it sends back messages via bidirectional comm unication links to erase ‚Äúgarbage‚Äù information producedinthecourseofcomputation. Thisseemsinevitabl easituses(aversionof)thequantumamplitude ampliÔ¨Åcation [CK98] (or aspecial case of the general quantu m amplitude ampliÔ¨Åcation [BHMT02]). It is a 3critical issue, however, when the underlying graph is direc ted, since, although strong connectivity ensures at least one directed path on which the message could be sent b ack, parties cannot identify the path in the anonymous network (since the original sender of the message cannot be identiÔ¨Åed). In the classical setting, such an issue cannot arise since the message need not be sent b ack (the sender has only to keep a copy of the message if it needs to). Our idea for resolving this issue istoemploy the symmetryb reaking procedure introduced in[TKM12, Sec. 4]. The procedure was used to solve the leader election p roblem as follows: Initially, all parties are candidates for the leader and they repeatedly perform a cert ain distributed procedure that reduces the set Sof the candidates by at least 1. More concretely, the procedu re partitions Sinto at least two subsets if |S|‚â•2and removes one of them from S. A simple but effective way of viewing this is that it not only reducesSbut decides whether |S|is at least two or not, since it can partition Sonly when there are at least two candidates. This observation would exactly solve SVnby regarding Sas the set of contenders if the procedure outputs the correct answer with certainty. However, the procedure heavily depends on the following unknowns: the cardinality of Sand the number nof parties. In Ref. [KMT14], a similar problem arises when deciding whether an nbit string xis of Hamming weight at most 1, and it is resolved by running a base algorithm in parallel for all possible gues ses at|x|and making the decision based on the set of all outputs (the ‚Äúbase algorithm‚Äù uses amplitude a mpliÔ¨Åcation and is totally different from the symmetrybreaking approach). Together withasimplealgor ithm fortesting whether xistheallzero string, the parallel execution of the base algorithm is used in the le ader election algorithm [KMT14] to verify that a random xis of Hamming weight exactly one. This veriÔ¨Åcation framewor k actually works in our case, and it underlies the entire structure of our algorithm . Namely, we replace the base algorithm in the framework with a subroutine constructed by carefully co mbining the symmetrybreaking procedure introduced in Ref. [TKM12] with classical techniques relat ed to the view [YK96a, Nor95, BV02, Tan12]. Thismeans that all parties collaborate to perform this subr outine inparallel for all possible pairs of guesses at(n,|S|). The round complexity is thus equal to the number of rounds re quired to perform the subroutine once, i.e.,O(N)rounds. To show the correctness, we prove that the set of the o utputs over all possible pairs of the guesses yields the correct answer to any SVninstance with certainty. This needs an indepth and careful analysis of all operations of which our algorith m consists for every pair not necessarily equal to (n,|S|). Before the present work, it has seemed as if the symmetrybre aking approach introduced in Refs. [TKM05, TKM12] is entirely different from the amplitu de ampliÔ¨Åcation approach used in Ref.[KMT14]. OuralgorithmÔ¨Årstdemonstratesthattheseap proachesarequitecompatible,and,indeed,the technical core of Refs. [TKM05, TKM12] can effectively func tion in the algorithmic framework proposed in Ref. [KMT14]. This would contribute to a better understan ding of distributed quantum computing and would be very helpful for future studies of quantum algorith ms. Our algorithm can be generalized to the case of computing a fa milySn(k)of more general symmetric functionsasfollows: Allpartiescollaboratetopartition Sintosubsetsbyrecursivelyapplyingtheprocedure up to‚åàlog2max{k,2}‚åâlevels. If there is a singleton set among the subsets at a cert ain recursion level, then the algorithm stops and all parties elect the only membe r of the subset as a leader, who can compute |S|and thus compute the value of the given function in Sk. If no singleton set appears even after the‚åàlog2max{k,2}‚åâth recursion level, there must be more than kparties inS, in which case any function inSkisconstant by thedeÔ¨Ånition. 1.4 Related Work "
61,Can pruning improve certified robustness of neural networks?.txt,"With the rapid development of deep learning, the sizes of neural networks
become larger and larger so that the training and inference often overwhelm the
hardware resources. Given the fact that neural networks are often
over-parameterized, one effective way to reduce such computational overhead is
neural network pruning, by removing redundant parameters from trained neural
networks. It has been recently observed that pruning can not only reduce
computational overhead but also can improve empirical robustness of deep neural
networks (NNs), potentially owing to removing spurious correlations while
preserving the predictive accuracies. This paper for the first time
demonstrates that pruning can generally improve certified robustness for
ReLU-based NNs under the complete verification setting. Using the popular
Branch-and-Bound (BaB) framework, we find that pruning can enhance the
estimated bound tightness of certified robustness verification, by alleviating
linear relaxation and sub-domain split problems. We empirically verify our
findings with off-the-shelf pruning methods and further present a new
stability-based pruning method tailored for reducing neuron instability, that
outperforms existing pruning methods in enhancing certified robustness. Our
experiments show that by appropriately pruning an NN, its certified accuracy
can be boosted up to 8.2% under standard training, and up to 24.5% under
adversarial training on the CIFAR10 dataset. We additionally observe the
existence of certified lottery tickets that can match both standard and
certified robust accuracies of the original dense models across different
datasets. Our findings offer a new angle to study the intriguing interaction
between sparsity and robustness, i.e. interpreting the interaction of sparsity
and certified robustness via neuron stability. Codes are available at:
https://github.com/VITA-Group/CertifiedPruning.","Neural Network (NN)based framework is a strong general solution to many problems, yet many of these solutions remain impractical for realworld applications of low fault tolerance. A slight perturbation in the raw input sensory data could completely change the predicting behaviors of the networks. Furthermore, researchers have shown that various kinds of targeted adversarial attacks can easily fool the neural networks [32,10], which poses threat to many deep learning applications. Fortunately, researchers introduced formal methods to verify neural network behaviors, which made it possible to mathemat ically derive the prediction bound of a neural network w.r.t. a certain input, and thus evaluate the certiÔ¨Åed robustness of the neural network. For example, in the image classiÔ¨Åcation task, given an input image with some perturbation, if the lower bound of the output probability of the correct label is higher than the upper bound of probabilities of other incorrect labels, we saythe model is certiÔ¨Åably robust w.r.t. this image sample. The goal of neural network veriÔ¨Åcation is to estimate the groundtruth bound as close as possible. In this paper, we are concerned about the certiÔ¨Åed robustness under the complete veriÔ¨Åcation setting, where the veriÔ¨Åer should output the exact bounds given the input domain C, rather than some relaxation of C, given sufÔ¨Åcient time. Despite its theoretical appeal, the complete veriÔ¨Åcation of neural networks is known to be a challenging NPhard problem [16,37], mainly due to the nonlinear activation functions in neural networks, such as Sigmoid and ReLU. The popular BranchandBound (BaB) framework [ 4] utilized the feature of ReLU activations and adopted the classical divideand conquer method to solve the complete veriÔ¨Åcation problem. It branches the bound computation into multiple subdomains recursively on ReLU nodes and computes the bounds on each subdomain respectively. The time complexity of this framework is exponential, and typically has preset time limit for each sample veriÔ¨Åcation. Several veriÔ¨Åers [ 43,35] based on the BaB framework were later proposed for efÔ¨Åcient complete veriÔ¨Åcation. The core problem addressed in these methods is how to estimate the pre activation bound (i.e. propagated input bounds of the nonlinear activation layers) as tight as possible given limited time. To approach this, they use LinearRelaxation based Perturbation Analysis (LiRPA) to relax nonlinear bound propagation with linear ones and use GPUaccelerated BaB methods to further tighten the estimated bounds as much as possible. However, the estimated bound is still loose, mainly because (1) an efÔ¨Åcient linear relaxation of multiple nonlinear activation layers is loose both empirically [ 28] and theoretically [ 16,37], where tightening the relaxation requires an exponential number of linear constraints which is inefÔ¨Åcient [ 33]; and (2) the BaB framework requires solving an exceedingly large number of subdomains (which is exponential in the worst case [ 16]) to provide a tight bound, so in practice we often solve only a part of the subdomains which yields a loose bound. Recent efforts [ 9,11,13,44,15,41] reveal that proper network pruning can empirically enhance neural network ro bustness to adversarial attacks. We take one step further to argue that pruning can also be utilized to improve the estimated bound tightness of certiÔ¨Åed robustness veriÔ¨Åcation, by alleviating linear relaxation and subdomain split problems. Improving empirical robustness (as a surrogate of ‚Äúgroundtruth‚Äù robustness) and veriÔ¨Åcation tightness can together lead to overall measurable certiÔ¨Åed robustness, and we Ô¨Ånd that existing pruning schemesarXiv:2206.07311v2  [cs.LG]  17 Jun 2022can already coachieve both. Moreover, inspired by that sparsity can eliminate unstable neurons and improve nonlinear neuron stability for veriÔ¨Åcation [ 41], we present a new stability based pruning method, that even outperforms existing pruning methods on improving certiÔ¨Åed robustness. As one last ‚Äúhidden gem‚Äù Ô¨Ånding, we demonstrate the existence of certiÔ¨Åed lottery tickets , that generalizes the lottery ticket hypothesis [ 8] to the certiÔ¨Åed robustness Ô¨Åeld for the Ô¨Årst time: it is deÔ¨Åned as those sparse subnetworks found by pruning that can match both the standard and certiÔ¨Åed accuracies of the original dense models. Our contributions are outlined below:  For the Ô¨Årst time, we demonstrate that pruning can gen erally improve certiÔ¨Åed robustness. We analyze pruning effects from the perspectives of both improving ground truth robustness of the model and the veriÔ¨Åcation bound tightness, and empirically validate it with extensive pruning methods and training schemes.  As pruning can be utilized to improve nonlinear neuron stability, we propose a novel regularizer for pruning called NRSLoss (see Figure 2) that effectively regularizes the neuron stability and outperforms exist ing pruning methods in enhancing certiÔ¨Åed robustness.  Our experiments validate the above proposals by presenting veriÔ¨Åcation results under various settings. For example on the CIFAR10 dataset, under certiÔ¨Åed training, existing pruning methods as well as our proposed NRSLossbased pruning boost the certiÔ¨Åed accuracy for 1.67.1% and 8.2% respectively; under adversarial training, they boost the certiÔ¨Åed accuracy for 12.524.5%.  We additionally observe the existence of certiÔ¨Åed lottery tickets that can match both standard and certiÔ¨Åed robust accuracies of the original dense models, using either the classical iterative magnitude pruning (IMP) [8] or NRSLossbased pruning. II. R ELATED WORK "
384,TUTOR: Training Neural Networks Using Decision Rules as Model Priors.txt,"The human brain has the ability to carry out new tasks with limited
experience. It utilizes prior learning experiences to adapt the solution
strategy to new domains. On the other hand, deep neural networks (DNNs)
generally need large amounts of data and computational resources for training.
However, this requirement is not met in many settings. To address these
challenges, we propose the TUTOR DNN synthesis framework. TUTOR targets tabular
datasets. It synthesizes accurate DNN models with limited available data and
reduced memory/computational requirements. It consists of three sequential
steps. The first step involves generation, verification, and labeling of
synthetic data. The synthetic data generation module targets both the
categorical and continuous features. TUTOR generates the synthetic data from
the same probability distribution as the real data. It then verifies the
integrity of the generated synthetic data using a semantic integrity classifier
module. It labels the synthetic data based on a set of rules extracted from the
real dataset. Next, TUTOR uses two training schemes that combine synthetic and
training data to learn the parameters of the DNN model. These two schemes focus
on two different ways in which synthetic data can be used to derive a prior on
the model parameters and, hence, provide a better DNN initialization for
training with real data. In the third step, TUTOR employs a grow-and-prune
synthesis paradigm to learn both the weights and the architecture of the DNN to
reduce model size while ensuring its accuracy. We evaluate the performance of
TUTOR on nine datasets of various sizes. We show that in comparison to fully
connected DNNs, TUTOR, on an average, reduces the need for data by 5.9x,
improves accuracy by 3.4%, and reduces the number of parameters (fFLOPs) by
4.7x (4.3x). Thus, TUTOR enables a less data-hungry, more accurate, and more
compact DNN synthesis.","ANexceptional aspect of human intelligence is its ability to leverage prior experiences to solve problems in a new domain with limited experience. A similar ability to learn efÔ¨Åciently under limited available data and computational resources is also a desirable attribute of artiÔ¨Åcial intelligent (AI) agents. Over the last decade, deep neural networks (DNNs) have revolutionized a variety of application domains, such as computer vision, speech recognition, and robotic control. However, data scarcity is still a limiting factor in training DNNs for various applications, such as healthcare and cognitive modeling of human decisions [1]‚Äì[3]. Many such This work was supported by NSF under Grant No. CNS1907381. Shayan Hassantabar, Prerit Terway, and Niraj K. Jha are with the Department of Electrical & Computer Engineering, Princeton University, Princeton, NJ 08544, USA, email: fseyedh, pterway,jhag@princeton.edu.applications offer just a few thousand data instances for training. Training of DNN models with such small datasets may lead to overÔ¨Åtting, hence limit their applicability to realworld environments. Some of the drawbacks of the current DNN training process are as follows: Need to obtain and label large datasets : Collecting a large number of data instances and manually labeling them is costly and timeconsuming, even more so in domains where experts are needed to label the data instances. As a result, reducing the cost of labeling is an active area of research [4]. Ignoring domain knowledge : Training DNN architec tures only on available training data does not take into account available expert domain knowledge or the set of rules that may have been derived for the domain. As a result, the process is not efÔ¨Åcient and, in turn, exacerbates the need for large datasets. Substantial redundancy : Most DNN architectures need substantial storage, memory bandwidth, and compu tational resources for training. However, recent work shows that it is possible to signiÔ¨Åcantly reduce the number of parameters and Ô¨Çoatingpoint operations (FLOPs), with no loss in accuracy [5], [6]. There has been a recent spurt of interest in combining domainspeciÔ¨Åc information in the form of rulebased AI with modern statistical AI [7], [8]. In such works, rulebased AI can act as an inductive bias to enhance the learning efÔ¨Åcacy of novel tasks. Imposing prior knowledge mitigates the need for a large amount of training data. However, extracting domain knowledge or creating a set of rules for a novel domain is often challenging as it requires speciÔ¨Åc expertise in the area. Nevertheless, domains, such as natural language processing, often have predeÔ¨Åned rules that make such a combination attractive [9]. Researchers have also explored various synthetic data generation methods to address a number of problems, such as preserving privacy when sharing data, testing new tools, and increasing dataset size. Generative models, such as variational autoencoders [10] and generative adversarial networks (GANs) [11], provide an appealing solution for generating wellperforming synthetic data. Using image and text data, these models learn the probability distribution of training data. Recently, GANs have also been used in the generation of tabular synthetic data [12]. They havearXiv:2010.05429v3  [cs.NE]  16 Feb 20222 been shown to generate synthetic data that are close to the real data distribution. However, the use of neural network models with a large number of parameters in the generator and discriminator components of GANs necessitates large training datasets to generate highquality synthetic data. In this work, we assume we have access to only a limited number of data instances in order to synthesize accurate models that generalize well. As a result, we aim to develop a synthetic data generation module that is sampleefÔ¨Åcient and maximizes the use of the small available data. To address the above problems, we propose a new DNN training and synthesis framework called TUTOR, which is particularly suitable for tasks where limited training data and computational resources are available. It relies on the generation of synthetic data from the same probability distribution as the available training data, to enable the DNN to start its training from a better initialization point. TUTOR consists of three sequential stages: (1) synthetic data generation, veriÔ¨Åcation, and labeling, (2) training schemes for incorporating synthetic and real data into the training process, and (3) growandprune DNN synthesis to ensure model compactness as well as to enhance performance. Data augmentation is an effective technique, often used in image classiÔ¨Åcation applications, to increase dataset size, help the model learn invariance, and regularize the model [13]. However, TUTOR targets tabular datasets. It generates synthetic data by modeling the joint multivariate distribution of the given dataset and sampling from the learned distribu tion. The synthetic data generation module simultaneously generates categorical and continuous features. To ensure the semantic integrity of synthetic data, TUTOR uses a semantic integrity classiÔ¨Åer module that veriÔ¨Åes the validity of the generated synthetic data. This classiÔ¨Åer veriÔ¨Åes the values of categorical features with respect to other features of the synthetic data instance. We label the synthetic data by incorporating a set of rules extracted from real data. These rules are obtained using a random forest model trained on real data. Finally, TUTOR uses the synthetic data alongside the real data in two training schemes. The intuition behind using synthetic data in DNN training is to provide a suitable inductive bias to the DNN weights. It thus mitigates the problem of limited data availability. To address the problem of network redundancy, we use the growandprune synthesis paradigm [6] by leveraging three different operations: connection growth, neuron growth, and connection pruning. It allows the DNN architecture to grow neurons and connections to adapt to the prediction problem at hand. Subsequently, it prunes away the neurons and connections of little importance. In addition, it does not Ô¨Åx the number of layers in the architecture beforehand, enabling the architecture to be learned during the training process. The major contributions of this article are as follows: TUTOR addresses two challenges in the design of predictive DNN models: lack of sufÔ¨Åcient data and computational resources. It focuses on tabular datasets and addresses the lack of sufÔ¨Åcient data by generating synthetic data from the same probability distribution as the training data using three different density estimation methods. It uses semantic integrityclassiÔ¨Åers to verify the integrity of the generated synthetic data. By relying on decision rules generated from a random forest machine learning model, it obviates the need for domain experts to label the synthetic data. TUTOR uses a training Ô¨Çow to combine synthetic and real data to train the DNN models and learn both the weights and the architecture by using a grow andprune synthesis paradigm. This addresses the problem of Ô¨Åxed network capacity while reducing memory and computational costs. Less data: TUTOR requires 5:9fewer data instances to match or exceed the classiÔ¨Åcation accuracy of conventional fullyconnected (FC) DNNs. EfÔ¨Åciency: TUTOR uses 4:7fewer parameters and 4.3fewer FLOPs relative to FC DNNs. Accuracy: TUTOR enhances classiÔ¨Åcation accuracy by 3:4%over conventional FC DNNs. Privacy enhancement: The synthetic data generated by TUTOR can be separately used to train a DNN, with little to no drop in accuracy, without the need for real data. This is useful in applications where privacy issues make sharing of real data infeasible. The rest of the article is organized as follows. Section 2 covers related work. Section 3 provides some necessary background and the theoretical motivation behind this work. Then, in Section 4, we discuss the proposed TUTOR framework in detail. Section 5 presents evaluation results for TUTOR. In Section 6, we provide a short discussion on analogies between the human brain and the TUTOR training Ô¨Çow. Finally, Section 7 concludes the paper. 2 R ELATED WORK "
461,Are Transformers More Robust? Towards Exact Robustness Verification for Transformers.txt,"As an emerging type of Neural Networks (NNs), Transformers are used in many
domains ranging from Natural Language Processing to Autonomous Driving. In this
paper, we study the robustness problem of Transformers, a key characteristic as
low robustness may cause safety concerns. Specifically, we focus on
Sparsemax-based Transformers and reduce the finding of their maximum robustness
to a Mixed Integer Quadratically Constrained Programming (MIQCP) problem. We
also design two pre-processing heuristics that can be embedded in the MIQCP
encoding and substantially accelerate its solving. We then conduct experiments
using the application of Land Departure Warning to compare the robustness of
Sparsemax-based Transformers against that of the more conventional
Multi-Layer-Perceptron (MLP) NNs. To our surprise, Transformers are not
necessarily more robust, leading to profound considerations in selecting
appropriate NN architectures for safety-critical domain applications.","Over the past decade, Neural Networks (NNs) have been widely adopted for many ap plications, including automated vehicles (A Vs) [2]. Lately, as an emerging type of NNs, Transformers [29] are often found to be the most effective models, compared to the more conventional MultiLayer Perceptrons (MLPs) or their convolutional and recur rent variants [6], thereby gradually replacing them in these applications. For instance, Tesla and Cruise use Transformers in their perception units [5,27]. However, most of the studies and discussions focus on evaluating NNs‚Äô accuracy. Parallel research has shown that NNs often lack robustness against input changes such as adversarial attacks or domain shifts, hence hindering the overall dependability of the NNbased applica tions [11,14,26]. The above background naturally prompts a question of whether Transformers are more robust than MLPs, given the often better accuracy and wide applications. To an swer this question, we study the maximum robustness of the NNs against local in put perturbations commonly modeled by lpdistances, i.e., exact robustness veriÔ¨Åcation ? This project has received funding from the European Union‚Äôs Horizon 2020 research and innovation programme under grant agreement No 956123  FOCETA.arXiv:2202.03932v4  [cs.LG]  19 May 20232 B. H.C. Liao et al. (where pcan be 1 ;2;:::;¬•). Ultimately, the goal is to hold a direct comparison of the robustness of the two kinds of NNs, Transformers and MLPs, and gain insights from the results. In the literature, research efforts have been made to enable exact robustness ver iÔ¨Åcation for MLPs, particularly ones with feedforward layers and ReLU activation function [4,7,19,28]. The main approach is to employ an optimization framework, en code the NNs‚Äô architecture into the constraints, and calculate the exact robustness within some admissible input perturbation region [4,28]. However, there is still a gap for Trans formers‚Äô exact robustness veriÔ¨Åcation due to the more complex operations in this kind of NNs, namely the dot product between variables and the activation function in the MultiHead SelfAttention (MSA) block [29]. The existing (small volume of) works handle these operations with approximations during veriÔ¨Åcation yet at the expense of veriÔ¨Åcation precision [3,25] (more details can be found in Section 2). Our work attempts to close the gap towards exact robustness veriÔ¨Åcation for Trans formers but provides merely an interim solution. To elaborate, having formulated a Mixed Integer Programming (MIP)based optimization problem, we focus on the Trans formers that use Sparsemax (instead of Softmax) for MSA activation. This allows for precisely encoding the NN into the MIP, or more particularly, Mixed Integer Quadrat ically Constrained Programming (MIQCP) due to the remaining quadratic terms. We provide a comparison study to show that the Sparsemaxbased Transformers perform similarly to their Softmaxbased counterparts. Then, to faster solve the MIQCP, we de vise two preprocessing heuristics that lead to a total speedup of an order of magnitude. Notably, these heuristics are not restricted to our work but can be applied to related studies. We perform the experiments using a Lane Departure Warning (LDW) application, which is widely adopted in A Vs. Such an LDW application can be used for human driving assistance or runtime monitoring on separate automated driving functions. Es sentially, an LDW application is a timeseries classiÔ¨Åcation and regression task. The embedded model, usually an NN, has to predict the direction of and the time to a poten tial lane departure, given a sequence of past driving information such as the ego vehicle velocity and estimated time to collision against adjacent vehicles. Our methodology and experimental results, though limited (similar to the exact robustness veriÔ¨Åcation works focusing on ReLUbased MLPs), demonstrate that Sparsemaxbased Transform ers tend to be less robust than similarsized MLPs despite generally higher accuracy. Resonating the government publications [8] and industrial guidelines [23], our Ô¨Åndings suggest that conducting thorough studies and providing rigorous guarantees on metrics beyond accuracy is crucial before deploying an NNbased application. In summary, our contributions include the following: ‚ÄìTo implement exact robustness veriÔ¨Åcation for Sparsemaxbased Transformers; ‚ÄìTo propose two accelerating heuristics for related robustness veriÔ¨Åcation studies; ‚ÄìTo benchmark ATN and MLP accuracy and robustness with an industrial applica tion (i.e., LDW). The rest of the paper is organized in the following way. Section 2 browses the rel evant literature emphasizing veriÔ¨Åcation methods for general NNs and Transformers; Section 3 introduces the branch of Transformers concerned in this paper. Section 4Towards Exact Robustness VeriÔ¨Åcation for Transformers 3 details the problem formulation and our heuristics for robustness veriÔ¨Åcation, whose effectiveness and efÔ¨Åciency are demonstrated and discussed in Section 5. Lastly, Sec tion 6 concludes with a few Ô¨Ånal remarks. 2 Related Works "
443,Decomposing spiking neural networks with Graphical Neural Activity Threads.txt,"A satisfactory understanding of information processing in spiking neural
networks requires appropriate computational abstractions of neural activity.
Traditionally, the neural population state vector has been the most common
abstraction applied to spiking neural networks, but this requires artificially
partitioning time into bins that are not obviously relevant to the network
itself. We introduce a distinct set of techniques for analyzing spiking neural
networks that decomposes neural activity into multiple, disjoint, parallel
threads of activity. We construct these threads by estimating the degree of
causal relatedness between pairs of spikes, then use these estimates to
construct a directed acyclic graph that traces how the network activity evolves
through individual spikes. We find that this graph of spiking activity
naturally decomposes into disjoint connected components that overlap in space
and time, which we call Graphical Neural Activity Threads (GNATs). We provide
an efficient algorithm for finding analogous threads that reoccur in large
spiking datasets, revealing that seemingly distinct spike trains are composed
of similar underlying threads of activity, a hallmark of compositionality. The
picture of spiking neural networks provided by our GNAT analysis points to new
abstractions for spiking neural computation that are naturally adapted to the
spatiotemporally distributed dynamics of spiking neural networks.","The robustness, flexibility, and efficiency of natural intelligence is thought to emerge from the unique computational characteristics of the brain‚Äôs highly recurrent and dynamical spiking neural networks. Despite an explosion of neuroscientific data at all organizational levels, our understanding of spiking neural computation is tentative. Both neuroscientists and researchers in neural computing seek the right abstractions. A theoretical framework is required to interpret the myriad of patterns of spiking activity generated by spiking neural networks and how these patterns relate to neural computations. In particular, spiking neural networks lack a satisfactory theory of compositionality, namely, how complex computations are built from simpler parts. Defining a useful abstraction for spiking neural computation requires specifying the meaningful relations between spikes that support these computations. Abstractions emerge from equivalences, and Preprint. Under review.arXiv:2306.16684v1  [cs.NE]  29 Jun 2023specifying a meaningful relation also specifies an appropriate notion of equivalence ‚Äì for example, the abstraction of binary bits in conventional computer architectures partitions the states of the physical system into the classes ‚Äú1‚Äù and ‚Äú0‚Äù. Most computational abstractions of recurrent spiking neural networks depend on the concept of a population state vector. In these approaches, simultaneous population activity forms a distributed representation of computational variables as a vector in a highdimensional space [ 11]. The action of the spiking network corresponds to a dynamical system evolving the state vector to the desired result of the computation. The population state vector interpretation requires assuming that every neuron agrees that simultaneity with respect to the time bins is the meaningful relation between spikes that defines neural computations. If conduction delays between neurons are exactly equal or negligible, this may be valid. However, biological evidence suggests that delays and other asynchronous attributes of spiking networks are critical for computation [ 5]. Regardless, the validity of reducing neural activity to a sequence of state vectors is an empirical question [2]. Another aspect of spiking networks is temporal variability. Spiking neural networks rarely respond to identical input with temporally identical spike trains, even though they are biophysically capable of such precision [ 9]. Within the state vector abstraction, this means that the computation must be expressed probabilistically, because the state vectors rarely trace identical sequences through time. Mounting evidence suggests that some neural variability is due to flexibly warping invariant spike patterns in time [ 13] or through the unknown mechanisms behind representational drift [ 10]. Attributing neural variability to stochastic noise may overlook invariant patterns in less observer centric descriptions. In other words, neural activity that looks variable may be exquisitely precise with respect to a different point of view [9]. Overall, the assumptions imposed by current abstractions of spiking networks are in tension with the observed properties of biological networks. This motivates a search for alternative descriptions of spiking neural networks that are more naturally adapted to spiking dynamics and can serve as a foundation for computational abstractions. In this work, we introduce an alternative approach to decomposing spiking neural network activity that avoids many of these assumptions. Our analyses reveal neural activity intrinsically partitions itself into disjoint causal threads of activity, that we refer to as Graphical Neural Activity Threads (GNATs). We analyze the GNATs that emerge from a spiking neural network simulation receiving both random and patterned stimulation through externally imposed spikes. We also provide a technique for identifying analogous GNATs that reoccur at different times in our simulations. The GNATs display many properties that suggest they are a useful computational abstraction for spiking neural networks, such as spatiotemporal parallelism (more than one GNAT can exist in the same space or time) and compositionality (GNATs are built from smaller threads that are flexibly reused and rearranged). 2 Related Work "
163,Query-Efficient Decision-based Black-Box Patch Attack.txt,"Deep neural networks (DNNs) have been showed to be highly vulnerable to
imperceptible adversarial perturbations. As a complementary type of adversary,
patch attacks that introduce perceptible perturbations to the images have
attracted the interest of researchers. Existing patch attacks rely on the
architecture of the model or the probabilities of predictions and perform
poorly in the decision-based setting, which can still construct a perturbation
with the minimal information exposed -- the top-1 predicted label. In this
work, we first explore the decision-based patch attack. To enhance the attack
efficiency, we model the patches using paired key-points and use targeted
images as the initialization of patches, and parameter optimizations are all
performed on the integer domain. Then, we propose a differential evolutionary
algorithm named DevoPatch for query-efficient decision-based patch attacks.
Experiments demonstrate that DevoPatch outperforms the state-of-the-art
black-box patch attacks in terms of patch area and attack success rate within a
given query budget on image classification and face verification. Additionally,
we conduct the vulnerability evaluation of ViT and MLP on image classification
in the decision-based patch attack setting for the first time. Using DevoPatch,
we can evaluate the robustness of models to black-box patch attacks. We believe
this method could inspire the design and deployment of robust vision models
based on various DNN architectures in the future.","Nowadays, deep neural networks (DNNs) have been em ployed as the fundamental techniques in the advancement of artificial intelligence in computer vision. Despite the success of DNNs, recent studies have identified that DNNs are vulnerable to adversarial examples [1]. By introducing maliciously crafted perturbations to the input images, these adversarial examples are able to evade and mislead DNNs. Consequently, studying the adversarial vulnerability of DNNs has emerged as an important research area, providing the opportunity to better understand and improve computer vision models. Classical works [1]‚Äì[7] focus on studying the adversarial vulnerability of DNNs against virtually imperceptible pertur bations that are constrained to have a small norm but are typically applied to the whole input image. Recently, as a complementary type of adversary, patch attacks that introduce perceptible (large norm) but localized perturbations to the Corresponding authors are Bo Li and Wenqiang Zhang. Zhaoyu Chen and Wenqiang Zhang are with Academy for Engineer ing and Technology, Fudan University, Shanghai, China, and also with Yiwu Research Institute of Fudan University, Yiwu, China. The emails of these authors are: zhaoyuchen20@fudan.edu.cn, njumagiclibo@gmail.com, wqzhang@fudan.edu.cn. 0 50 100Query   Budget  ResNet  ViT MLP   Targeted Image  Source Image   Classified as    Wall Clock    Classified as   Indian Elephant    Indian Elephant   Indian Elephant   Indian Elephant   Fig. 1. Introduction of DevoPatch. With regard to limited query budgets, we generate adversarial examples of patch attacks using DevoPatch applied to blackbox models on image classification. As the number of queries increases, DevoPatch efficiently optimizes the quality of adversarial patches and achieves queryefficient decisionbased patch attacks under a few query budgets. images have attracted the interest of researchers. Pioneering works [8]‚Äì[12] perform patch attacks in the whitebox setting: with full access to the model‚Äôs parameters and architectures, they can directly use gradientbased optimization to find successful adversarial examples. Due to the fact that most real world applications do not publicly release the actual models they use, this attack scenario usually is less practical in real world systems, e.g., attacking image analysis APIs [13] like Google Cloud Vision or selfdriving cars [14]‚Äì[16]. As a more practical scenario in realworld systems, black box patch attacks have attracted a lot of attention in recent years. There are transferbased attacks [17] and querybased attacks [18]‚Äì[21] for blackbox patch attacks, depending on whether the attacker needs to query the victim‚Äôs machine learning model. Despite the fact that transferbased attacks do not require query access to the model, it assumes the attacker has access to a large training set to create a carefully designed substitute model [22]‚Äì[24], and there is no guarantee of success [25]. Querybased attacks assume that attackers can only query the target network and obtain its outputs (score or label) for a given input. According to the output information of the queried models, querybased attacks can be classified into two subcategories: scorebased setting which has access to the class probabilities of the model, and decisionbased setting which solely relies on the top1 predicted label. Signif icantly, decisionbased settings present more practical threats 0000‚Äì0000/00$00.00 ¬© 2021 IEEEarXiv:2307.00477v1  [cs.CV]  2 Jul 20232 to deployed systems and applications because an adversary is still capable of exploiting the very minimal information exposed ‚Äì the top1 predicted label ‚Äì for constructing an adversarial perturbation. Recently, some scorebased patch attacks [18]‚Äì[21] have been proposed. However, when these methods are applied to the decisionbased setting, they hardly achieve high attack success rate and query efficiency because the information provided by labels is limited. In this paper, we first explore the decisionbased patch attack to better measure the practical threat of patch attacks. To successfully conduct decisionbased blackbox patch attacks, there are still nonnegligible challenges to overcome: Complex Solution Space. Performing patch attacks is ex tremely challenging since it involves searching for all possible positions, shapes, and perturbations of adversarial patches, which implies an enormous solution space. Moreover, unlike whitebox scenarios or the scorebased blackbox setting, in the decisionbased blackbox setting, there is almost no valid information to guide the search direction. Query efficiency. In the querybased setting, achieving high query efficiency with a high attack success rate is integral to adversarial objectives. Because: i) adversaries are able to carry out attacks at scale; ii) the cost of mounting the attack is reduced, and iii) adversaries are capable of bypassing defense systems that can recognize malicious activities as a fraud based on a pragmatically large number of successive queries with analogous inputs. Last but not least, the advantage of a smaller query budget is that it correlates to a lower cost of evaluation and research, which is useful for determining the robustness of the model to adversarial attacks. To address the aforementioned issues, we propose a dif ferential evolutionary algorithm named DevoPatch for query efficient adversarial patch attacks in the decisionbased black box setting. Differential evolutionary algorithm is a black box optimization algorithm that does not need to know the details of the model and is suitable for parameter search when information is limited. Given the attack objective function, DevoPatch is able to optimize it in a blackbox manner through queries only. To simplify the solution space, we restrict param eter optimization to the integer domain and carefully design a differential evolution algorithm based on the integer domain. Further, we model the patches using paired keypoints and use targeted images as the initialization of patches. Consequently, the query efficiency of DevoPatch is significantly improved. In addition, it is worth noting that some novel DNN architectures have recently emerged including the Vision Transformer (ViT) model [26] and Multilayer Perceptron (MLP) based model [27]. They demonstrate compelling performance, sometimes even outperforming classical convolutional architectures. Al though a few studies have explored the vulnerability of ViT against imperceptible adversarial perturbations [28], [29], the adversarial robustness of ViT and MLP under patch attacks has not been considered. This raises a critical security con cern for the reliable deployment of realworld applications based on ViT and MLP models. Therefore, we extend our study scope and apply DevoPatch to ViT and MLP to better understand the vulnerability of a wide variety of DNNs under adversarial patch attacks. We illustrate an example patch attackwith DevoPatch against ILSVRC2012 in Fig. 1 on image classification. Extensive experiments on image classification and face verification demonstrate that DevoPatch is a query efficient decisionbased blackbox patch attack. We summarize our contributions and results below: ‚Ä¢We first explore the decisionbased patch attack, which can still construct a perturbation with the minimal infor mation exposed ‚Äì the top1 predicted label. ‚Ä¢To simplify the solution space, we model the patches using paired keypoints and use targeted images as the initialization of patches, and parameter optimizations are all performed on the integer domain. ‚Ä¢We propose a novel patch attack ‚Äì DevoPatch ‚Äì an evolutionary algorithm capable of exploiting access to solely the top1 predicted label from a model to search for an adversarial example, whilst minimizing the image area that needs to be corrupted for a successful attack. ‚Ä¢Comprehensive experiments on image classification and face verification show that DevoPatch achieves consider ably higher success rates compared to related work, while being more efficient in terms of the number of queries. ‚Ä¢We conduct the vulnerability evaluation of ViT and MLP on image classification in the decisionbased blackbox patch attack setting for the first time. We compare results with ResNet to assess the relative robustness of the ViT and MLP models. The remainder of the paper is organized as follows. Sec tion II briefly reviews the literature related to adversarial examples and adversarial patches, whitebox patch attacks, blackbox patch attacks, and adversarial attacks with evolu tionary algorithms. Section III first introduces the definition of decisionbased blackbox patch attacks and then details the proposed differential evolutionary patch attack. Section IV shows the experimental results to demonstrate the effectiveness of the proposed differential evolutionary patch attack. Firstly, we choose appropriate hyperparameters for DevoPatch. After ward, we evaluate the adversarial robustness of several image classification and face recognition models. In Section V, we further analyze the effects of adversarial patches on different DNN architectures. We summarize the paper in Section VI. II. R ELATED WORK "
176,Continuous Safety Verification of Neural Networks.txt,"Deploying deep neural networks (DNNs) as core functions in autonomous driving
creates unique verification and validation challenges. In particular, the
continuous engineering paradigm of gradually perfecting a DNN-based perception
can make the previously established result of safety verification no longer
valid. This can occur either due to the newly encountered examples (i.e., input
domain enlargement) inside the Operational Design Domain or due to the
subsequent parameter fine-tuning activities of a DNN. This paper considers
approaches to transfer results established in the previous DNN safety
verification problem to the modified problem setting. By considering the reuse
of state abstractions, network abstractions, and Lipschitz constants, we
develop several sufficient conditions that only require formally analyzing a
small part of the DNN in the new problem. The overall concept is evaluated in a
$1/10$-scaled vehicle that equips a DNN controller to determine the visual
waypoint from the perceived image.","Deep neural networks (DNNs) have been widely adopted in automated driving, with proveninuse applications from perception to assisting complex decision making. Deploying autonomous driving functionalities in the open environment creates substantial challenges in the underlying AI (artiÔ¨Åcial intelligence)/ML (machine learning) component, partly due to the safetycritical nature and partly due to the encountering of ‚Äúblack swans‚Äù, i.e., scenarios that were not considered in the design time. Recently developed safety guidelines in automated driving such as ISO TR4804 or UL4600 explicitly suggest the monitoring of abnormal cases in operation, either in an online or an ofÔ¨Çine fashion. When encountering these cases, the involved DNN component should be improved accordingly. The underlying rationale is to admit the imper fection of the initially engineered system while targeting a continuous improvement . One natural question that arises is regarding the huge computational efforts in formally verifying a DNN: to what extent can results in formal veriÔ¨Åcation of previous models be reused? In this paper, we consider the problem of formal DNN safety veriÔ¨Åcation under continuous engineering (Ô¨Ånetuning) . Moti vated by concrete issues in automated driving, the problem is This research is part of FOCETA project that has received funding from the European Union‚Äôs Horizon 2020 research and innovation programme under grant agreement No 956123. This work has been partly funded by Key Research Program of Frontier Sciences, CAS, under Grant No. QYZDJSSW JSC036, the CASINRIA major project under No. 171311KYSB20170027.related to migrating the result of one veriÔ¨Åcation problem to another, with two problems differing in two aspects. Due to the discovery of black swans (more precisely speaking, outofdistribution data points) in run time, the input domain for veriÔ¨Åcation will be enlarged. Here we take the approach of abstractionbased monitoring [1], [2] where the abstraction Dincapturing the indistribution data will be enlarged to Din[in, due to the newly discovered data d2infalling outside Din. The trained parameters (weights, bias) between two neu ral networks may only differ slightly, due to their Ô¨Åne tunings (i.e., the new model is further tuned from the old model with a very small learning rate such as 10"
87,Sound and Complete Verification of Polynomial Networks.txt,"Polynomial Networks (PNs) have demonstrated promising performance on face and
image recognition recently. However, robustness of PNs is unclear and thus
obtaining certificates becomes imperative for enabling their adoption in
real-world applications. Existing verification algorithms on ReLU neural
networks (NNs) based on classical branch and bound (BaB) techniques cannot be
trivially applied to PN verification. In this work, we devise a new bounding
method, equipped with BaB for global convergence guarantees, called
Verification of Polynomial Networks or VPN for short. One key insight is that
we obtain much tighter bounds than the interval bound propagation (IBP) and
DeepT-Fast [Bonaert et al., 2021] baselines. This enables sound and complete PN
verification with empirical validation on MNIST, CIFAR10 and STL10 datasets. We
believe our method has its own interest to NN verification. The source code is
publicly available at https://github.com/megaelius/PNVerification.","Polynomial Networks (PNs) have demonstrated promising per formance across image recognition and generation [Chrysos et al., 2021, Chrysos and Panagakis , 2020] being stateoftheart on large scale face recognition2.Unlike the conventional Neural Networks (NNs), where non linearitiy is introduced with the use of activation functions [LeCun et al ., 2015], PNs are able to learn non linear mappings without the need of activation functions by exploiting multiplicative interactions (Hadamard products). Recent works have uncovered interest ing properties of PNs in terms of model expressivity [Fan et al., 2021] and spectral bias [Choraria et al., 2022]. However, one critical issue before considering PNs for realworld applications is thei r robustness. Neural networks are prone to small (often imperceptible to t he human eye), but malicious perturba tions in the input data points [Szegedy et al., 2014, Goodfel low et al., 2015]. Those perturbations can have a detrimental effect on image recognition systems, e.g., as illustrated in face recogni tion [Goswami et al., 2019, Zhong and Deng, 2019, Dong et al., 2019, Li et al., 2020]. Guarding ‚àóWork developed during an exchange coming from Universitat P olit√®cnica de Catalunya (UPC), Spain. Currently at Universidad Carlos III de Madrid (UC3M). 2https://paperswithcode.com/sota/faceverificationo nmegaface 36th Conference on Neural Information Processing Systems ( NeurIPS 2022).against such attacks has so far proven futile [Shafahi et al. , 2019, Dou et al., 2018]. Instead, a Ô¨Çurry of research has been published on certifying robustness of N Ns against this performance degradation [Katz et al., 2017, Ehlers, 2017, Tjeng et al., 2019, Bunel et al., 2020b, Wang et al., 2021, Ferrari et al., 2022]. However, most of the veriÔ¨Åcation algo rithms for NNs are developed for the ReLU activation function by exploiting its piecewise linea rity property and might not trivially ex tend to other nonlinear activation functions [Wang et al., 2 021].Indeed, Zhu et al. [2022] illustrate that guarding PNs against adversarial attacks is challengi ng. Therefore, we pose the following ques tion: Can we obtain certiÔ¨Åable performance for PNs against advers arial attacks? In this work, we answer afÔ¨Årmatively and provide a method for the veriÔ¨Åcation of PNs. Concretely, we take advantage of the twicedifferentiable nature of PNs to build a lower bounding method based onŒ±convexiÔ¨Åcation [Adjiman and Floudas, 1996], which is inte grated into a Branch and Bound (BaB) algorithm [Land and Doig, 1960] to guarantee complete ness of our veriÔ¨Åcation method. In order to use Œ±convexiÔ¨Åcation, a lower bound Œ±of the minimum eigenvalue of the Hessian matrix over the possible perturbation set is needed. We use interva l bound propagation together with the the oretical properties of the lower bounding Hessian matrix [A djiman et al., 1998], in order to develop an algorithm to efÔ¨Åciently compute Œ±. Ourcontributions can be summarized as follows: (i)We propose the Ô¨Årst algorithm for the veriÔ¨Å cation of PNs. (ii)We thoroughly analyze the performance of our method by compa ring it with a blackbox solver, with an interval bound propagation (IBP) BaB algorithm and with the zonotope based abstraction method DeepTFast [Bonaert et al., 2021] .(iii)We empirically show that using Œ±convexitication for lower bounding provides tighter boun ds than IBP and DeepTFast for PN veriÔ¨Å cation. To encourage the community to improve the veriÔ¨Åcati on of PNs, we make our code publicly available in https://github.com/megaelius/PNVerification . The proposed approach can practically verify PNs and that could theoretically be appl ied for sound and complete veriÔ¨Åcation of any twicedifferentiable network. Notation: We use the shorthand [n] :={1,2,...,n}for a positive integer n. We use bold capital (lowercase) letters, e.g., X(x) for representing matrices (vectors). The jthcolumn of a matrix Xis given byx:j. The element in the ithrow andjthcolumn is given by xij, similarly, the ithelement of a vectorxis given by xi. The elementwise (Hadamard) product, symbolized with ‚àó, of two matrices (or vectors) in Rd1√ód2(orRd) gives another matrix (or vector) in Rd1√ód2(orRd). The‚Ñì‚àûnorm of a vectorx‚ààRdis given by: ||x||‚àû= max i‚àà[d]|xi|. Lastly, the operators LandUgive the lower and upper bounds of a scalar, vector or matrix function by IBP , see Section 3.1. Roadmap: We provide the necessary background by introducing the PN ar chitecture and formal izing the Robustness VeriÔ¨Åcation problem in Section 2. Sect ion 3 provides a sound andcomplete method called VPN to tackle PN veriÔ¨Åcation problem. Section 4 is devoted to experimental valida tion. Additional experiments, details and proofs are defer red to the appendix. 2 Background We give an overview of PN architecture in Section 2.1 and the r obustness veriÔ¨Åcation problem in Section 2.2. 2.1 Polynomial Networks (PNs) Polynomial Networks (PNs) are inspired by the fact that any s mooth function can be approximated via a polynomial expansion [Stone, 1948]. However, the numb er of parameters increases exponen tially with the polynomial degree, which makes it intractab le to use high degree polynomials for highdimensional data problems such as image classiÔ¨Åcatio n where the input can be in the order of105[Deng et al., 2009]. Chrysos et al. [2021] introduce a joint f actorization of polynomial co efÔ¨Åcients in a lowrank manner, reducing the number of param eters to linear with the polynomial degree and allowing the expression as a neural network (NN). We brieÔ¨Çy recap one fundamental factorization below. LetNbe the polynomial degree, z‚ààRdbe the input vector, d,kandobe the input, hidden and output sizes, respectively. The recursive equation of PNs c an be expressed as: x(n)= (W‚ä§ [n]z)‚àóx(n‚àí1)+x(n‚àí1),‚àÄn‚àà[N], (1) 2z W[1] ‚àó +W[2] ‚àó +W[3] C +Œ≤ f(z)x(1)x(2)x(3) Figure 1: Third degree PN architecture. Blue boxes depict le arnable parameters, yellow depict mathematical operations, the green and red boxes are the inp ut and the output respectively. Note that no activation functions are involved, only elementwi se (Hadamard) products ‚àóand additions +. This Ô¨Ågure represents the recursive formula of Eq. (1). wherex(1)=W‚ä§ [1]z,f(z) =Cx(N)+Œ≤and‚àódenotes the Hadamard product. W[n]‚ààRd√ókand C‚ààRo√ókare weight matrices, Œ≤‚ààRois a bias vector. A graphical representation of a third degre e PN architecture corresponding to Eq. (1) can be found in Fig. 1. Further details on the factorization (as well as other factorizations) are deferred to the Append ix C.1 (Appendix C.2). 2.2 Robustness VeriÔ¨Åcation Robustness veriÔ¨Åcation [Bastani et al., 2016, Liu et al., 20 21] consists of verifying that a property regarding the input and output of a NN is satisÔ¨Åed, e.g. check ing whether or not a small perturbation in the input will produce a change in the network output that m akes it classify the input into another class. Let f: [0,1]d‚ÜíRobe a function, e.g., a NN or a PN, that classiÔ¨Åes the input zinto a class c, such that c= argmax f(z). Our target is to verify that for any input satisfying a set of constraints Cin, the output of the network will satisfy a set of output constr aintsCout. Mathematically, z‚ààCin=‚áíf(x)‚ààCout. (2) In this work we focus on adversarial robustness [Szegedy et al., 2014, Carlini and Wagner, 2017] in classiÔ¨Åcation. Given an observation z0, lett= argmax f(z0)be the correct class, our goal is to check whether every input in a neighbourhood of z0, is classiÔ¨Åed as t. In this work, we focus on adversarial attacks restricted to neighbourhoods deÔ¨Åne d in terms of ‚Ñì‚àûnorm, which is a popular normbounded attack in the veriÔ¨Åcation community [Liu et al ., 2021]. Then, the constraint sets become: Cin={z:||z‚àíz0||‚àû‚â§«´,zi‚àà[0,1],‚àÄi‚àà[d]} ={z: max{0,z0i‚àí«´} ‚â§zi‚â§min{1,z0i+«´},‚àÄi‚àà[d]} Cout={y:yt> yj,‚àÄj/ne}ationslash=t}.(3) In other words, we need an algorithm that given a function f, an input z0and an adversarial budget «´, checks whether Eq. (2) is satisÔ¨Åed. In the case of ReLU NNs, t his has been proven to be an NPcomplete problem [Katz et al., 2017]. This can be reformu lated as a constrained optimization problem. For every adversarial class Œ≥/ne}ationslash=t= argmax f(z0), we can solve: min zg(z) =f(z)t‚àíf(z)Œ≥s.t.z‚àà C in. (4) If the solution z‚àówithv‚àó=f(z‚àó)t‚àíf(z‚àó)Œ≥‚â§f(z)t‚àíf(z)Œ≥,‚àÄz‚àà C insatisÔ¨Åesv‚àó>0then robustness is veriÔ¨Åed for the adversarial class Œ≥. There are two main properties that a veriÔ¨Åcation algorithm a dmits: soundness andcompleteness . An algorithm is sound (complete ) if every time it veriÔ¨Åes (falsiÔ¨Åes) a property, it is guaran teed to be the correct answer. In practice, when an algorithm is guaran teed to provide the exact global minima of Eq. (4), i.e., v‚àó, it is said to be sound andcomplete (usually referred in the literature as simply complete [Ferrari et al., 2022]), whereas if a lower bound of it is prov idedÀÜv‚àó‚â§v‚àó, the algorithm issound but not complete . In our work, we will not consider just complete veriÔ¨Åcation, which simply aims at looking for adversarial examples, e.g., Madr y et al. [2018]. For a deeper discussion onsoundness andcompleteness , we refer to Liu et al. [2021]. 3 Method "
221,HyperNCA: Growing Developmental Networks with Neural Cellular Automata.txt,"In contrast to deep reinforcement learning agents, biological neural networks
are grown through a self-organized developmental process. Here we propose a new
hypernetwork approach to grow artificial neural networks based on neural
cellular automata (NCA). Inspired by self-organising systems and
information-theoretic approaches to developmental biology, we show that our
HyperNCA method can grow neural networks capable of solving common
reinforcement learning tasks. Finally, we explore how the same approach can be
used to build developmental metamorphosis networks capable of transforming
their weights to solve variations of the initial RL task.","Reinforcement learning (RL) agents are either trained with policy gradient methods (Arulkumaran et al., 2017), or evolved with evolutionary strategies (Salimans et al., 2017) or genetic algorithms (Such et al., 2017; Risi & Stanley, 2019). In both of these approaches, the neural network weights are directly optimised, meaning that the search space is the weight space. An alternative approach to Ô¨Ånding optimal policies are the socalled indirect encodings (Stanley et al., 2019; Stanley & Miikkulainen, 2003). These methods introduce an intermediate step into the training process which decouples the optimisation space from the policy weight space: instead of directly searching for optimal policy weights, we optimise a model whose output is the policy weights. A wellknown indirect encoding example found in nature is the genotypephenotype relation be tween DNA sequences and the proteins they encode. For instance, the information needed to grow a fullyfunctioning human brain must be contained in the human genome. However, DNA does not encode the Ô¨Ånal position of every neuron or the presence of every synapse. A simple a backofthe envelope calculation shows that the amount of information in the human DNA sequence ‚Äîapprox imately 1 GB‚Äî is not sufÔ¨Åcient to explicitly encode the 1015synapses present in the human brain (Zador, 2019). In other words, your brain adjacency matrix is nowhere to be found in your DNA. Unlike RL agents, animals grow their neural circuitry through a developmental process in which neurons determine their synaptic connections solely based on local interactions. In biological sys tems, the growth of the nervous system ‚Äîas any other tissue‚Äî is governed by gene regulatory networks: a single set of rules encoded in the cells‚Äô DNA which, depending on the cells state, will produce different developmental outcomes. The fundamental insight, acting as the foundation of this paper, is the connection between the notion ofcomputational irreducibility and biological developmental processes. Some dynamical systems ‚Äînotably chaotic ones, but not only‚Äî can have the interesting cooccurrence of two properties: being deterministic and unpredictable simultaneously. In order to determine the state after nsteps of such a system, one must evolve the system for nsteps according to its dynamical equation; in other words, there does not exist an analytical expression describing the state of the system for any stepn. Such systems are said to be computationally irreducible (Zwirn & Delahaye, 2011). It is conjectured that the developmental process of biological systems is computationally irreducible: the only way to resolve the Ô¨Ånal conÔ¨Åguration of the neural circuitry of the brain is to let unfold the genetic information present in the DNA through an algorithmic growth process (Hiesinger, 2021). 1arXiv:2204.11674v1  [cs.NE]  25 Apr 2022From Cells to Societies: Collective Learning Across Scales  ICLR 2022 Workshop The power of algorithmic growth resides in not requiring to explicitly codify each of the details of the Ô¨Ånal conÔ¨Åguration of the system. Instead, a small amount of information ‚Äîwhich encodes the growth process‚Äî is capable of giving rise to a more complex system purely through its self organised dynamics. Cellular automata (CA) are computational models able to exhibit computational irreducibility (Wol fram, 2002). They can display complex dynamical patterns emerging exclusively from the local interaction of its elements via simple rules. Recently, neural cellular automata (NCA) ‚Äîwhich re place the update rule of the CA by a neural network (Wulff & Hertz, 1992; Nichele et al., 2017; Mordvintsev et al., 2020)‚Äî have gained popularity by taking advantage of modern deep learning tools. On the other hand, a recent trend aims to make deep learning systems more robust by com bining them with ideas from collective intelligence such as CAs and selforganization (Ha & Tang, 2021; Risi, 2021). Building on insights from algorithmic growth and computational irreducibility, we aim to grow neu ral networks using neural cellular automata to solve reinforcement learning tasks. We introduce HyperNCAs , NCAs acting as Hypernetworks, and show that they are capable of producing pol icy networks with a signiÔ¨Åcantly larger number of parameters able to solve modern reinforcement learning tasks such as a discrete action environment (e.g. Lunar Lander) and a quadrupedal robot locomotion task. Unlike existing Hypernetwork approaches (Ha et al., 2016; Stanley et al., 2009; Carvelli et al., 2020), our proposed indirectencoding relies on a developmental process guiding the emergence of the Ô¨Ånal policy network. Finally, we propose the notion of metamorphosis networks : a NCAbased approach to morph neural networks such that the network information is preserved and reused. We demonstrate how metamorphosis networks can be used to morph the weights of a policy network in order to adapt to differently damaged morphologies. The goal of this work is not to reach the everelusive stateoftheart at any given RL tasks, but rather, to introduce a new kind of indirect encoding that puts forward the value of selforganisation and algorithmic growth to generate neural policies for reinforcement learning agents. 2 R ELATED WORK "
170,Coarse and fine-grained automatic cropping deep convolutional neural network.txt,"The existing convolutional neural network pruning algorithms can be divided
into two categories: coarse-grained clipping and fine-grained clipping. This
paper proposes a coarse and fine-grained automatic pruning algorithm, which can
achieve more efficient and accurate compression acceleration for convolutional
neural networks. First, cluster the intermediate feature maps of the
convolutional neural network to obtain the network structure after
coarse-grained clipping, and then use the particle swarm optimization algorithm
to iteratively search and optimize the structure. Finally, the optimal network
tailoring substructure is obtained.","Deep neural networks [1][2][3] have achieved great success in scientific research and  engineering with the continuous expansion of data sets and the substantial increase in hardware  computing power. As one of the important branches, convolutional neural network [4] has  outstanding performanc e in image feature extraction by virtue of its parameter sharing and  translation invariance characteristics. It has been widely used in image classification [5], target  detection [6], style Significant breakthroughs have been made in the fields of transfor mation [7] and  semantic segmentation [8]. As image tasks become more complex, the depth and width of the  network are gradually increasing, and the scale of the network has also become extremely large  while improving performance. As a result, some existing deep convolutional neural networks can  only be trained on GPUs, TPUs, or cloud processors, and cannot be deployed on mobile terminals  and wearable devices with limited computing and storage capabilities and high real time  requirements. It greatly limits th e development and application of convolutional neural networks.   In order to solve this problem, a large number of researchers have compressed and accelerated  the deep convolutional neural network, aiming at the redundancy of the parameters and structure of   the existing network, reducing the number of parameters and the number of floating point operations  (FLOPs). The current mainstream methods mainly include designing dedicated hardware  architecture [9] [10], optimizing convolution calculation methods [11] [12] and designing network compression algorithms. Among them, network compression algorithms are mainly divided into  four types: network pruning, low rank factorization [13], quantification [14] [15] [16] and  knowledge distillation [17]. The low rank fact orization operation can achieve network sparseness  and directly compress and accelerate the network. However, additional calculations are introduced  in the implementation process, which is not conducive to the reduction of floating point operations.  Quanti zation can speed up the calculation but cannot reduce the number of parameters, and when  the network is more complex, the inference accuracy is relatively low. Knowledge distillation can  make the deeper model narrower, but the similarity requirements for t he two model tasks are higher,  and it may get worse performance in actual use. The pruning algorithm of the convolutional neural  network starts from the redundancy of the network, and uses the importance evaluation index of the  parameters to cut the unimpo rtant parameters and their connections. The pruning algorithm has  received widespread attention because it is easy to implement and can effectively compress and  accelerate the original convolutional neural network. Existing convolutional neural network pru ning  algorithms can be roughly divided into two categories: the first category is coarse grained clipping,  such as based on the convolution kernel and the magnitude of the channel [18] [19][20] or based on  similarity [21] The implementation process of this  type of method is relatively simple, but the  stability is poor, and the final compact network experiment has a large loss of accuracy; the second  type is fine grained pruning, for example, [22] considers error propagation for pruning By  minimizing the fin al response layer, the neurons are clipped layer by layer to obtain a compact  network. [23] implements network pruning through reinforcement learning, etc. The final compact  network obtained by this type of method has less accuracy loss, but the cutting pr ocess is time  consuming Labor intensive. [21] proved the effectiveness of using the cosine similarity between  feature maps as a parameter redundancy evaluation index. [24] demonstrated the guiding role of  neural structure search in neural network structure  optimization. Inspired by the above two works,  this paper proposes a coarse and fine grained automatic pruning algorithm.   The coarse and fine grained automatic pruning algorithm in this paper first performs inference  tests on the pre trained baseline conv olutional neural network on the image classification data set,  statistics the feature maps generated during the test, and calculates the cosine distance between each  two feature maps , And then perform cluster analysis on the number of channels in each lay er of the  network according to this distance, and use the clustering result as the number of channels after  coarse grained cropping in each layer to form a convolutional neural network structure after coarse  grained cropping. Then initialize the network st ructure on the basis of the initially formed compact  network structure, and finally use the particle swarm optimization algorithm to automatically search  and optimize these network structures to obtain the final compact neural network to realize the  compre ssion and acceleration of the original convolutional neural network . Coarse grained  clustering and cropping of the original network first, and then fine grained cropping through  automatic iterative search optimization has the following two advantages: Fir st, the coarse grained  clustering and cropping itself is efficient, and it can provide smaller size for fine grained cropping.  Initialize the network structure range of the network, accelerate the efficiency of fine grained search  and tailor, and then make  the entire network tailoring process more efficient; secondly, coarse  grained tailoring can provide a better initialization network structure for the optimization algorithm  during fine grained tailoring, thereby reducing The accuracy of the final compact network is lost.  This article has carried out concrete experimental verification on three data sets of CIFAR 10,  CIFAR 100 and ILSVRC 2012.  The coarse and fine grained automatic pruning algorithm in this article can directly perform  channel level pruning o n the existing convolutional neural network structure without introducing  sparsity, without the assistance of additional sparse matrix operations and acceleration libraries, and  the entire pruning process is It is realized by controlling the hyperparameter s, which greatly reduces  the intervention of manual operation, and can realize the automatic compression and acceleration of  the network.   The main contributions of this article are as follows:   1. This paper proposes a coarse grained pruning algorithm for c onvolutional neural networks,  which clusters all channels in each layer of the original network, and uses the sum of the number of  clusters and the number of noise channels as the current layer The number of channels after  preliminary pruning, after cluste ring all layers, the coarse grained pruned structure of the original  convolutional neural network is obtained.   2. This paper proposes a fine grained pruning algorithm for convolutional neural networks.  The network structure obtained by coarse grained pruni ng is initialized as a structure population,  and then the particle swarm optimization algorithm is used to iteratively search and optimize the  coarse grained pruning. The obtained compact network structure is optimized to obtain the optimal  pruning network .  3. This article combines coarse grained and fine grained pruning algorithms to propose a  coarse and fine grained automatic pruning algorithm for convolutional neural networks. Only one  hyperparameter is controlled to achieve different amplitude compressi on and acceleration of the  original network, which is easy to implement and can make the final result. The compact network  has a high image classification accuracy.   4. This article conducted a lot of comparative experiments on the CIFAR 10, CIFAR 100 and  ILSVRC 2012 data sets, and proved the effectiveness and accuracy of the coarse and fine grained  automatic pruning algorithm in the compression and acceleration of convolutional neural networks.  The ablation analysis experiment verified that the adjustment o f hyperparameters has a stable  control on the network clipping ratio.   The latter part of this article is organized as follows: The second part introduces related work  in this field; the third part specifically describes the coarse and fine grained pruning method  proposed in this article and its implementation details; the fourth part shows a large number of  comparative verification experiments and ablation analysis; The full text is summarized.   2 Related work   "
66,Neural SDE: Stabilizing Neural ODE Networks with Stochastic Noise.txt,"Neural Ordinary Differential Equation (Neural ODE) has been proposed as a
continuous approximation to the ResNet architecture. Some commonly used
regularization mechanisms in discrete neural networks (e.g. dropout, Gaussian
noise) are missing in current Neural ODE networks. In this paper, we propose a
new continuous neural network framework called Neural Stochastic Differential
Equation (Neural SDE) network, which naturally incorporates various commonly
used regularization mechanisms based on random noise injection. Our framework
can model various types of noise injection frequently used in discrete networks
for regularization purpose, such as dropout and additive/multiplicative noise
in each block. We provide theoretical analysis explaining the improved
robustness of Neural SDE models against input perturbations/adversarial
attacks. Furthermore, we demonstrate that the Neural SDE network can achieve
better generalization than the Neural ODE and is more resistant to adversarial
and non-adversarial input perturbations.","Residual neural networks (ResNet) [ 1] are composed of multiple residual blocks transforming the hidden states according to: hn+1=hn+f(hn;wn); (1) wherehnis the input to the nth layer and f(hn;wn)is a nonlinear function parameterized by wn. Recently, a continuous approximation to the ResNet architecture has been proposed [ 2], where the evolution of the hidden state htcan be described as a dynamic system obeying the equation: ht=hs+Zt sf(h;;w) d; (2) 1arXiv:1906.02355v1  [cs.LG]  5 Jun 2019wheref(h;;w)is the continuous form of the nonlinear function f(hn;wn);hsandhtare hidden states at two diÔ¨Äerent time s6=t. A standard ODE solver can be used to solve all the hidden states and Ô¨Ånal states (output from the neural network), starting from an initial state (input to the neural network). The continuous neural network described in (2)exhibits several advantages over its discrete counterpart described in (1), in terms of memory eÔ¨Éciency, parameter eÔ¨Éciency, explicit control of the numerical error of Ô¨Ånal output, etc. One missing component in the current Neural ODE network is the various regularization mecha nisms commonly employed in discrete neural networks. These regularization techniques have been demonstrated to be crucial in reducing generalization errors, and in improving the robustness of neural networks to adversarial attacks. Many of these regularization techniques are based on stochastic noise injection. For instance, dropout [ 3] is widely adopted to prevent overÔ¨Åtting; injecting Gaussian random noise during the forward propagation is eÔ¨Äective in improving generalization [ 4,5] as well as robustness to adversarial attacks [ 6,7]. However, these regularization methods in discrete neural networks are not directly applicable to Neural ODE network, because Neural ODE network is a deterministic system. Our work attempts to incorporate the abovementioned stochastic noise injection based regular ization mechanisms to the current Neural ODE network, to improve the generalization ability and the robustness of the network. In this paper, we propose a new continuous neural network framework calledNeural Stochastic DiÔ¨Äerential Equation (Neural SDE) network, which models stochas tic noise injection by stochastic diÔ¨Äerential equations (SDE). In this new framework, we can employ existing techniques from the stability theory of SDE to study the robustness of neural networks. Our results provide theoretical insights to understanding why introducing stochasticity during neural network training and testing leads to improved robustness against adversarial attacks. Furthermore, we demonstrate that, by incorporating the noise injection regularization mechanism to the continuous neural network, we can reduce overÔ¨Åtting and achieve lower generalization error. For instance, on the CIFAR10 dataset, we observe that the new Neural SDE can improve the test accuracy of the Neural ODE from 81.63% to 84.55%, with other factors unchanged. Our contributions can be summarized as follows: We propose a new Stochastic DiÔ¨Äerential Equation (SDE) framework to incorporate randomness in continuous neural networks. The proposed random noise injection can be used as a dropin component in any continuous neural networks. Our Neural SDE framework can model various types of noises widely used for regularization purpose in discrete networks, such as dropout (Bernoulli type) and Gaussian noise. Training the new SDE network requires developing diÔ¨Äerent backpropagation approach from the Neural ODE network. We develop a new eÔ¨Écient backpropagation method to calculate the gradient, and to train the Neural SDE network in a scalable way. The proposed method has its roots in stochastic control theory. We carry out a theoretical analysis of the stability conditions of the Neural SDE network, to prove that the randomness introduced in the Neural SDE network can stabilize the dynamical system, which helps improve the robustness and generalization ability of the neural network. We verify by numerical experiments that stochastic noise injection in the SDE network can successfully regularize the continuous neural network models, and the proposed Neural SDE network achieves better robustness and improves generalization performance. 2Notations: Throughout this paper, we use h2Rnto denote the hidden states in a neural network, whereh0=xis the input (also called initial condition) and yis the label. The residual block with parametersw2Rdcan be written as a nonlinear transform f(h;;w). We assume the integration is always taken from 0toT.Bt2Rmismdimensional Brownian motion. G(h;;v)2Rnmis the diÔ¨Äusion matrix parameterized by v. Unless stated explicitly, we use kkto represent `2norm for vector and Frobenius norm for matrix. 2 Related work "
327,Cross Architecture Distillation for Face Recognition.txt,"Transformers have emerged as the superior choice for face recognition tasks,
but their insufficient platform acceleration hinders their application on
mobile devices. In contrast, Convolutional Neural Networks (CNNs) capitalize on
hardware-compatible acceleration libraries. Consequently, it has become
indispensable to preserve the distillation efficacy when transferring knowledge
from a Transformer-based teacher model to a CNN-based student model, known as
Cross-Architecture Knowledge Distillation (CAKD). Despite its potential, the
deployment of CAKD in face recognition encounters two challenges: 1) the
teacher and student share disparate spatial information for each pixel,
obstructing the alignment of feature space, and 2) the teacher network is not
trained in the role of a teacher, lacking proficiency in handling
distillation-specific knowledge. To surmount these two constraints, 1) we first
introduce a Unified Receptive Fields Mapping module (URFM) that maps pixel
features of the teacher and student into local features with unified receptive
fields, thereby synchronizing the pixel-wise spatial information of teacher and
student. Subsequently, 2) we develop an Adaptable Prompting Teacher network
(APT) that integrates prompts into the teacher, enabling it to manage
distillation-specific knowledge while preserving the model's discriminative
capacity. Extensive experiments on popular face benchmarks and two large-scale
verification sets demonstrate the superiority of our method.","Face recognition has attained tremendous success in various appli cation areas [ 21,23,58]. However, compact yet discriminative face recognition models are highly desirable due to the proliferation of identification systems on mobile and peripheral devices [ 15]. Despite the variant proposals of enhanced neural network designs, there remains an immense performance disparity between these compressed networks and the heavy networks with millions of pa rameters. A natural option is to optimize neural network architec tures for mobile devices, e.g., MobileFaceNet [ 4], and MobileNetV3 /uni00000029/uni0000004c/uni00000057/uni00000031/uni00000048/uni00000057 /uni00000035/uni0000002e/uni00000027 /uni00000026/uni00000026/uni0000002e/uni00000027 /uni00000027/uni00000044/uni00000055/uni0000004e/uni00000035/uni00000044/uni00000051/uni0000004e /uni00000028/uni0000002e/uni00000027 /uni00000036/uni00000033 /uni0000002e/uni00000027/uni0000001c/uni00000013/uni00000011/uni00000013/uni0000001c/uni00000014/uni00000011/uni00000013/uni0000001c/uni00000015/uni00000011/uni00000013/uni0000001c/uni00000016/uni00000011/uni00000013/uni0000001c/uni00000017/uni00000011/uni00000013/uni0000001c/uni00000018/uni00000011/uni00000013/uni0000001c/uni00000019/uni00000011/uni00000013/uni0000001c/uni0000001a/uni00000011/uni00000013/uni0000001c/uni0000001b/uni00000011/uni00000013/uni00000024/uni00000046/uni00000046/uni00000058/uni00000055/uni00000044/uni00000046/uni0000005c/uni00000003/uni0000003f/uni00000008 /uni00000037/uni00000048/uni00000044/uni00000046/uni0000004b/uni00000048/uni00000055/uni00000010/uni00000026/uni00000055/uni00000052/uni00000056/uni00000056 /uni00000037/uni00000048/uni00000044/uni00000046/uni0000004b/uni00000048/uni00000055/uni00000010/uni0000002b/uni00000052/uni00000050/uni00000052/uni0000002b/uni00000052/uni00000050/uni00000052/uni0000004f/uni00000052/uni0000004a/uni00000052/uni00000058/uni00000056 /uni00000026/uni00000055/uni00000052/uni00000056/uni00000056(a) Performance variation on LFW, CFPFP, CPLFW, AgeDB and CALFW /uni00000029/uni0000004c/uni00000057/uni00000031/uni00000048/uni00000057 /uni00000035/uni0000002e/uni00000027 /uni00000026/uni00000026/uni0000002e/uni00000027 /uni00000027/uni00000044/uni00000055/uni0000004e/uni00000035/uni00000044/uni00000051/uni0000004e /uni00000028/uni0000002e/uni00000027 /uni00000036/uni00000033 /uni0000002e/uni00000027/uni0000001b/uni00000019/uni00000011/uni00000013/uni0000001b/uni0000001b/uni00000011/uni00000013/uni0000001c/uni00000013/uni00000011/uni00000013/uni0000001c/uni00000015/uni00000011/uni00000013/uni0000001c/uni00000017/uni00000011/uni00000013/uni0000001c/uni00000019/uni00000011/uni00000013/uni0000001c/uni0000001b/uni00000011/uni00000013/uni00000024/uni00000046/uni00000046/uni00000058/uni00000055/uni00000044/uni00000046/uni0000005c/uni00000003/uni0000003f/uni00000008 /uni00000037/uni00000048/uni00000044/uni00000046/uni0000004b/uni00000048/uni00000055/uni00000010/uni00000026/uni00000055/uni00000052/uni00000056/uni00000056 /uni00000037/uni00000048/uni00000044/uni00000046/uni0000004b/uni00000048/uni00000055/uni00000010/uni0000002b/uni00000052/uni00000050/uni00000052/uni0000002b/uni00000052/uni00000050/uni00000052/uni0000004f/uni00000052/uni0000004a/uni00000052/uni00000058/uni00000056 /uni00000026/uni00000055/uni00000052/uni00000056/uni00000056(b) Performance variation on IJBB and IJBC datasets Figure 1: Existing KD methods suffer from performance degradation in crossarchitecture distillation compared to the homologousarchitecture distillation. With the student network identified as MobileFacenet [ 4], we adopt IResNet 50 [7] as the teacher for homologousarchitecture distillation and SwinS as the teacher for crossarchitecture distillation. Then, we evaluate the performance variation of students with different KD methods [ 5,10,15,38,39,42,49] in both scenar ios by: (a) the average accuracy on the five popular face bench marks [ 13,35,44,59,60], and (b) the average TPR@FAR=1e4 on IJBB [ 54] and IJBC [ 33]. Practical application requires a solution to transfer knowledge from Transformer to CNN, which serves as the primary focus of this study. [12]. However, discriminative networks always benefit from a large modeling capacity, which is time and laborintensive. Knowledge distillation (KD) refers to the vanilla method for enhancing the performance of light models [ 10,42]. A typical scenario involves distilling either the intermediate features or subsequent logits from a strong teacher neural network to a compact student network, aiming at substantially improving the performance of the student model. Nevertheless, existing KD techniques primarily focus on homologousarchitecture distillation, i.e., CNN to CNN. Recently, Transformers have demonstrated exceptional capa bilities in various vision tasks [ 2,8,30]. Nonetheless, their high computational requirements and insufficient support for platform acceleration have hindered their deployment on mobile devices. On the other hand, CNNs have undergone significant development in recent years, with hardwarefriendly acceleration libraries such as CUDA [ 36] and TensorRT [ 37] rendering them suitable for both servers and mobile devices. Consequently, considering the excep tional modelling capacity of Transformers and the compatibility ofarXiv:2306.14662v1  [cs.CV]  26 Jun 2023MM ‚Äô23, October 28‚ÄìNovmber 03, 2023, Ottawa, Canada Zhao et al. EmbedLayer L        &      Layer L+1 Shifted Window Attention Teacher StudentArchitecture Gap Pixel FeaturesPixel Features Pixel wise Receptive Fields Receptive Fields Unalignment Figure 2: Illustration of the receptive fields of a pixel feature for teacher (Swin) and student (CNN). There exists a theoreti cal receptive field unalignment between teacher and student due to the architectural difference. CNNs, it has become a prevalent practice to employ a Transformer as a teacher network and maintain CNN as a student network for KD. However, current KD methods concentrate on homologous architecture distillation and overlook the architectural gap between teacher and student networks, leading to inferior performance of Transformer to CNN compared with that of CNN to CNN. Therefore, we probe the implication of the architecture gap on knowledge distil lation in face recognition. Specifically, we first trained an IResNet50 [7] on MS1MV2 [ 7] as a teacher network under the homologous architecture scenario, followed by training a SwinS [ 30] as a teacher network under the crossarchitecture scenario. It is worth noting that SwinS has a slight performance improvement over the IResNet 50. For the student network, we choose MobileFaceNet [ 4] as the backbone. We reproduce the canonical knowledge distillation meth ods [ 5,10,15,38,39,42,49] in face recognition in the homologous and crossarchitecture settings, respectively. We calculate the per formance variation of different methods from homologous to cross architecture scenarios, as shown in Fig. 1. Most methods suffer from performance degradation in crossarchitecture scenarios. However, we believe Crossarchitecture knowledge distillation is still effective in face recognition due to the highly organized face structure. In this paper, we find that the deployment of crossarchitecture knowledge distillation in face recognition encounters two major challenges. First, as illustrated in Fig. 2, there is a significant ar chitecture gap between teacher and student networks in terms of pixelwise receptive fields, i.e., the teacher network adopts shifted window attention [ 30] and the student utilizes conventional con volution operations. To demonstrate this, We visualize ERF [ 32] of pixelwise receptive fields for the teacher and student. As illustrated in Sec 4.5.3, the teacher and student share disparate pixelwise spa tial information. Second, the teacher network is not trained in the role of a teacher, lacking awareness of managing distillationspecific knowledge. The challenge lies in developing an auxiliary module that enables the teacher to manage distillationspecific knowledge while preserving its discriminative capacity. To address the aforementioned challenges, we first introduce a Unified Receptive Fields Mapping module (URFM) designed tomap pixel features of the teacher and student models into local features with congruent receptive fields. To achieve this, we utilize learnable local centers as the query embedding, supplemented with facial positional encoding to synchronize the receptive fields of the pixel features in both teacher and student. Additionally, recent research explores the feasibility of prompts in visual recognition and continual learning [ 17,45,53]. In this paper, we investigate the applicability of prompts in KD, allowing the teacher to optimize during distillation. Specifically, we develop an Adaptable Prompting Teacher network (APT) that integrates prompts into the teacher, enabling it to manage distillationspecific knowledge. In summary, the contributions of this paper include: ‚Ä¢We propose a novel module called Unified Receptive Fields Mapping (URFM) that maps pixelwise features to local fea tures with unified receptive fields. In URFM module, we exploit learnable local centers as the query embedding on which we supplement a facial positional encoding with the facial key points to synchronize the pixelwise receptive fields of teacher and student networks. ‚Ä¢We introduce Adaptable Prompting Teacher network (APT) that supplements learnable prompts in the teacher, enalbing it to manage distillationspecific knowledge while preserving model‚Äôs discriminative capacity. We further propose to adapt the model‚Äôs adaptable capacity by altering the number of prompts. To the best of our knowledge, we are the first to explore the feasibility of prompts in KD. ‚Ä¢The extensive experiments on popular face recognition bench marks demonstrate the superiority of the proposed method over the stateoftheart methods. 2 RELATED WORK "
198,Verification Code Recognition Based on Active and Deep Learning.txt,"A verification code is an automated test method used to distinguish between
humans and computers. Humans can easily identify verification codes, whereas
machines cannot. With the development of convolutional neural networks,
automatically recognizing a verification code is now possible for machines.
However, the advantages of convolutional neural networks depend on the data
used by the training classifier, particularly the size of the training set.
Therefore, identifying a verification code using a convolutional neural network
is difficult when training data are insufficient. This study proposes an active
and deep learning strategy to obtain new training data on a special
verification code set without manual intervention. A feature learning model for
a scene with less training data is presented in this work, and the verification
code is identified by the designed convolutional neural network. Experiments
show that the method can considerably improve the recognition accuracy of a
neural network when the amount of initial training data is small.","A verification code is a publicly  automated program used  to distinguish whether a user is a computer or a human [1 3].  Such program must generate tests that humans can easily pass  but are difficult for computer s to accomplish.  The aim of  verification code identification  algorithm is to automatically  identify the  content in verification code which can better   improve work efficiency and ensure real time [46]. The  verification  code generation technology can be promoted  by  the study of verification code identification  technology. Each  of the verification code generation  or recognition progress will  affect the safety of verification code, this will also promote   more advanced verification code technology  and rapid  development of the image  recognition technology  [79].   Verification code identification technology  is widely  researched abroad especially in developed  countries.  A valid  verification code should have a human recognition rate higher  than 80%, and the probability that a  machine will recognize its  content by using certain resources should be  less than 0.01%  [10,11]. Verification code technology  has been widely used to  improve the security and anti attack capabilities of websites   due to its simplicity , easy implementation, and small amount  of data transmi ssion . This technology aims to prevent the bulk registration of websites, violent password breaking, and  malicious att acks.   Researchers have begun to study techniques for  automatically identifying verification code s. Most  concepts  for  these solutions include  perform ing character segmentation and  identification. However, this type of scheme has limitations   for verificatio n codes that contain skewed characters.  Therefore, a rectangular window cannot be used to split  characters, and a more efficient classification method is   necessary. In addition, a  verification code picture differ s from  an object in a natural image, as show n in Figure 1.  Verification code picture s and training data are relatively   different  due to certain  factors , such as skew ness of characters.     Figure 1 Sample of a verification code   This study  proposes a method based on active learning to  solve the aforementioned problems. First, a small scale set is  used for training. In each training process, the addition of   samples to the training data is determined according to the  uncertainty associated with the classifier and the given  prediction result. Assuming that the uncertainty is calibrated, the information rich samples are selected for training, and the  number of training samples required for the algorithm is  considerably reduced compared with that for  standard passive  learning. In addition, the algorithm is applicable to situation s  where in the input data considerably differ from the current  training data. Unlike other forms of active learning, the  algorithm does not require human supervision to obtain real  time training tags. Instead , the return value is automatically  obtained when verification code recogni tion is used. The  current data are used for retraining when the classifier  correctly identifies the verification code. At this moment , the  realtime training tag is known.  When  recognition fails, no  similar sample exists in the training set, and the algorithm will  demonstrate the  training of  a neural network only through  successfully identified samples. In summary , this research has  the following objectives :  2   1. To calculate the uncertainty associated with the given  predictor results and to determine the relationship to the  correct classification .  2. To use a convolutional neural network for active  learning.   3. To conduct training with correct but uncertain  classification samples and obtain good training r esults with  less training data  in the absence of manual intervention .  II. RELATED WORK   "
119,Pruning and Slicing Neural Networks using Formal Verification.txt,"Deep neural networks (DNNs) play an increasingly important role in various
computer systems. In order to create these networks, engineers typically
specify a desired topology, and then use an automated training algorithm to
select the network's weights. While training algorithms have been studied
extensively and are well understood, the selection of topology remains a form
of art, and can often result in networks that are unnecessarily large - and
consequently are incompatible with end devices that have limited memory,
battery or computational power. Here, we propose to address this challenge by
harnessing recent advances in DNN verification. We present a framework and a
methodology for discovering redundancies in DNNs - i.e., for finding neurons
that are not needed, and can be removed in order to reduce the size of the DNN.
By using sound verification techniques, we can formally guarantee that our
simplified network is equivalent to the original, either completely, or up to a
prescribed tolerance. Further, we show how to combine our technique with
slicing, which results in a family of very small DNNs, which are together
equivalent to the original. Our approach can produce DNNs that are
significantly smaller than the original, rendering them suitable for deployment
on additional kinds of systems, and even more amenable to subsequent formal
verification. We provide a proof-of-concept implementation of our approach, and
use it to evaluate our techniques on several real-world DNNs.","The widespread adoption of deep learning [17] has caused a signiÔ¨Åcant leap forward in many domains within computer science. Deep neural networks (DNNs ) have now become the state of the art solution for a myriad of realworld problems, such as game playing [39], image recognition [40] , and autonomous vehicles [5], [25]. This trend is likely to continue and intensify, thus creating an urgent need for too ls and techniques to analyze and manipulate DNNs. A part of the appeal of DNNs is that they are produced in a mostly automated way. In order to create a DNN for a particu lar task at hand, engineers Ô¨Årst specify the network archite cture ‚Äî speciÔ¨Åcally, the number of layers in the network, the size and type of each layer, and the interlayer connections. The n, they invoke an automated training algorithm for assigning weights to the network‚Äôs edges [17]. While the automated training process has been extensively studied and is genera lly well understood [17], the choice of network architecture is still performed according to various rules of thumb, and is considered a form of art. This can often lead to a choice of architecture that is wasteful ‚Äî i.e., which results in a larg e [*] This is the extended version of a paper with the same title that is about to appear in FMCAD 2021. See https://fmcad.org/DNN, whereas a smaller DNN could have achieved similar accuracy [15], [19], [23]. For DNNs intended to run on device s with limited resources (e.g., mobile phones, or embedded circuits), excessive DNN size can be a limiting factor [25]. One successful approach for mitigating this difÔ¨Åculty is to Ô¨Årst train a large network, and then shrink it by removing re dundant neurons . Informally, we say that a neuron is redundant if removing it does not change the DNN‚Äôs output; and thus, removing it from a network Nresults in a smaller network, N‚Ä≤, that is equivalent toN. In order to identify redundant neurons within a DNN, prior work has focused primarily onheuristic pruning : heuristically identifying neurons and edges that contribute little to the network‚Äôs output, remov ing these neurons, and then performing additional training of t he network [19], [23]. These methods have been highly successf ul in reducing DNN sizes, but they provide no formal guarantees ; i.e., the removed neurons are not guaranteed to have been redundant, and the simpliÔ¨Åed network can thus be dramatical ly different from the original, producing different results f or various inputs [34]. Recently, there has been a surge of interest in the formal veriÔ¨Åcation of neural networks (e.g., [2], [14], [20], [26] , [28], [32], [45], and many others). These new capabilities have made it possible to identify and remove redundancies in a network, in a way that guarantees that the smaller network is completely equivalent to the original [15]. SpeciÔ¨Åcally , Gokulanathan et al. showed how veriÔ¨Åcation could be used to identify and remove ‚Äúdead‚Äù neurons, i.e. neurons whose output is 0regardless of the network‚Äôs inputs. This approach was shown to reduce network sizes by up to 10%, which is quite signiÔ¨Åcant, while preserving complete equivalence t o the original network. Here, we propose a new technique, which also attempts to apply formal veriÔ¨Åcation in order to remove neurons from a DNN, but which is signiÔ¨Åcantly stronger. SpeciÔ¨Åcally, our technique: (i) can identify additional kinds of redundant n eu rons (beyond ‚Äúdead‚Äù neurons), whose removal does not affect the network‚Äôs outputs at all; and (ii) can identify addition al redundant neurons, whose removal does affect the network‚Äôs outputs, but only up to a small, provable bound. Finally, we propose a method that takes our approach to the extreme, by integrating it with network slicing . This method, in which a network is simpliÔ¨Åed into a family of much smaller subnetworks, is appropriate for cases where fast inferenc e is crucial: an input is checked to identify the appropriate sub network for handling it, and then only that network needs to be evaluated for that speciÔ¨Åc input. Slicing is achieved by partitioning the DNN‚Äôs input domain into small subdomains , maintaining a separate DNN for each input subdomain, and then applying the aforementioned simpliÔ¨Åcation technique s on each of these DNNs. We demonstrate that the use of small input subdomains causes many neurons to become redundant, and consequently removable. For evaluation purposes, we implemented our approach in an opensource, publicly available tool [33]. As a backend, our tool uses the Marabou DNN veriÔ¨Åcation tool [29]. We note, however, that our approach is agnostic of the underlyi ng veriÔ¨Åcation engine ‚Äî indeed, it could be integrated with any other tool, and will consequently beneÔ¨Åt from any developme nt in DNN veriÔ¨Åcation technology. We evaluated our approach on a set of airborne collision avoidance networks [25], obtain ing highly favorable results. SpeciÔ¨Åcally, we were able to achi eve a reduction of up to 71% in overall network sizes, while keeping the outputs identical (up to a prescribed tolerance) to thos e produced by the original DNN. This reduction in network sizes is a signiÔ¨Åcant improvement over the previous state of the art [15]. Further, while prior techniques were speciÔ¨Åca lly tailored to networks with only a speciÔ¨Åc activation functio n (i.e., rectiÔ¨Åed linear units [15]), our technique is applic able to multiple kinds of DNNs. The rest of this paper is organized as follows. In Section II, we provide the necessary background on DNNs and their veriÔ¨Åcation. Next, in Section III we present the basic build ing block of our approach, namely the removal of a single neuron. We then specify multiple kinds of neurons that can be removed in Section IV, and discuss the simultaneous removal of neu rons in Section V. Subsequently, in Section VI we present how input slicing and simpliÔ¨Åcation can be used to improve network evaluation time. An evaluation appears in Section V II, followed by a discussion of related work in Section VIII. We then conclude in Section IX. II. B ACKGROUND : DNN S AND THEIR VERIFICATION A deep neural network [17] is a directed, acyclic graph, whose nodes (also referred to as neurons ) are grouped into layers. The Ô¨Årst layer is the input layer ; the Ô¨Ånal layer is theoutput layer ; and the intermediate layers are the hidden layers . When the network is evaluated, the input neurons are assigned some values (e.g., sensor readings), and these val ues are then propagated through the network, layer by layer, unt il the output values are computed. In regression networks, the numeric value of the output is of interest, while in the case ofclassiÔ¨Åcation networks, the output neurons correspond to possible labels that the network can classify the input into; and the label whose neuron obtained the highest score is the one returned by the network. Each layer in the DNN has a type, which determines how its neuron values are computed. Here, we will focus on two types: weighted sum layers, and piecewiselinear activation layers. In a weightedsum layer, the value of a neuron yis computed as y=b+/summationtextcivifor neurons vifrom precedinglayers, where the weightsciare determined when the network is Ô¨Årst trained. In a piecewiselinear activation layer, th e value of neuron yis computed as y=Ô£± Ô£¥Ô£¥Ô£¥Ô£≤ Ô£¥Ô£¥Ô£¥Ô£≥a1x+b1ifs1‚â§x < s2, a2x+b2ifs2‚â§x < s3, ... akx+bkifsk‚â§x‚â§sk+1 wherexis a neuron from some preceding layer, and the ai, biandsiparameters determine the piecewise linear func tion being computed. A common example of a piecewise linear activation function is the ReLU function, given by ‚àí1.00 ‚àí0.75 ‚àí0.50 ‚àí0.25 0.00 0.25 0.50 0.75‚àí0.20.00.20.40.60.81.0 Fig. 1: The ReLU function.y= max(x,0) =/braceleftBigg 0ifx <0 xifx‚â•0 (see Fig. 1). Together, weighted sum layers and piecewiselinear activation functions make up many common DNN architec tures [17]. Typically, they are used in alternation (see Fig. 2). Extending our approach to activation functions that are not piecewiselinear remain s a work in progress. InputsWS ReLU WS ReLU ReLU OutputsReLU ReLU ReLUReLU ReLU ReLU. . . . . . . . . . . . . . . . . .. . . Fig. 2: An illustration of a DNN with alternating weighteds um (WS) and ReLU layers. More formally, we regard a DNN Nwithkinputs and moutputs as a mapping Rk‚ÜíRm. The DNN is given as a sequence of layers L1,...,L n, whereL1is the input layer and Lnis the output layer. We use sito denote the size of layer Li, and usev1 i,...,vsi ito refer to the individual neurons of Li. We useVito refer to the column vector [v1 i,...,vsi i]T. When the network is being evaluated, we assume that the input values V1are given, and that V2,...,V nare computed iteratively. The type of each hidden layer is given via the mapping TN: N‚Üí T . For simplicity we set T={weightedsum ,ReLU}, although our technique applies to all types of piecewiseli near activation functions. In a weightedsum layer Li, each neuron vj iis associated with a linear function vj i=bj i+/summationtextcl,t¬∑vt l; i.e.,vj iis computed as a weightedsum of neurons vt lfrom preceding layers l < i , plus a bias value bj i. In a ReLU layer Li, each neuron vj iis associated with a speciÔ¨Åc neuron vt lfrom a preceding layer l < i , and its value is given by vj i=ReLU(vt l) = max( vt l,0). Note that each neuron‚Äôs value depends only on neurons from preceding layers.In recent years, various security and safety issues have bee n discovered in DNNs [26], [42]. This has led the veriÔ¨Åcation community to study the DNN veriÔ¨Åcation problem [35]. Gen erally, this problem is deÔ¨Åned by a set of constraints Pon the DNN‚Äôs inputs, and a set of constraints Qon the DNN‚Äôs outputs; and solving it entails Ô¨Ånding (or proving the non existence of) an input xsuch that P(x)‚àßQ(N(x)); i.e., an inputxthat satisÔ¨Åes the input condition, and is mapped by the DNN to a point that satisÔ¨Åes the output condition. When PandQcharacterize an unsafe behavior of the DNN, an UNSAT answer to the aforementioned query indicates that the DNN is safe; whereas a SAT answer, accompanied by a satisfying assignment, demonstrates an unsafe behavior. This formalization is sufÔ¨Åciently expressive for capturin g many properties of interest [26]. Many approaches for solvi ng the DNN veriÔ¨Åcation problem have been proposed recently (e.g., [14], [20], [26], [45], and many others). The techniq ues we discuss in this work use a DNN veriÔ¨Åcation engine as a backend, and do not depend on the precise method used ‚Äî and so we do not elaborate on this topic. We refer the interested reader to [35] for a survey. III. R EMOVING A SINGLE NEURON The core of our DNN simpliÔ¨Åcation approach is the identi Ô¨Åcation, and then the removal, of redundant neurons . Given a DNNN, we seek to identify a redundant neuron vj i, and then produce another network, N‚Ä≤, which is identical to Nexcept for the redundant neuron that has been removed. Ideally, we would like to ensure that NandN‚Ä≤are equivalent; i.e., that‚àÄx.N(x) =N‚Ä≤(x). Because N‚Ä≤is obtained from N by removing a neuron, it is smaller; and this process can be repeated iteratively, to eventually obtain a signiÔ¨Åcantly smaller network that is equivalent to N. Of course, the key points that need addressing are: (i) how to technically remove a redunda nt neuron from the network; and (ii) how to identify redundant neurons. In this section we focus on the Ô¨Årst challenge, and describe the mechanics of removing a neuron. In order to maintain compatibility with the original networ k, we will refrain from removing neurons from the network‚Äôs input or output layers; all other neurons are considered candidates for removal. We distinguish between neurons in weightedsum layers, and neurons in activation function la yers. In fact, our proposed approach only supports the removal of weightedsum neurons that feed only into other weightedsu m neurons; and the removal of activation function neurons wil l be performed by Ô¨Årst transforming them into weightedsum neurons, as described in later sections. Consider a neuron vcomputed as a weightedsum v=bv+/summationdisplay ci¬∑xi, wherexiare neurons from preceding layers. Suppose that v only feeds into other weightedsum neurons, and let ube such a neuron: u=bu+c¬∑v+/summationdisplay di¬∑yi,whereyiare again neurons from preceding layers. In this case, u‚Äôs equation can be updated into: u= (bu+c¬∑bv)+/summationdisplay c¬∑ci¬∑xi+/summationdisplay di¬∑yi. If this process is repeated for every (weightedsum) neuron thatvfeeds into, then afterwards vwill have no outgoing edges. Consequently, vcould then be eliminated from the network altogether. It is straightforward to show that such an operation will never affect the value of u, and that the modiÔ¨Åed network will thus be completely equivalent to the original. Also, identifying neurons that can be eliminated is simple, and amounts to searching for weightedsum neurons that are only connected to other weightedsum neurons. In practice, DNN topology usually alternates between weightedsum and activation function layers, and so con secutive weightedsum neurons are likely to be scarce. Our strategy will thus be to replace activation function neuron s with weightedsum neurons, in a way that will enable neuron removal while preserving network accuracy. As an example, let us consider a ReLU neuron, y=ReLU(x). Because of layertype alternation, it is reasonable to assume that xis a weightedsum neuron. In this case, if we can express y as a linear function of x, i.e.y=ax+bfor some aand b, then the previous case of two consecutive weightedsum neurons applies: we can remove xentirely, change y‚Äôs type to weightedsum, and connect ytox‚Äôs inputs. Further, if y also feeds into weightedsum neurons, then we can apply simpliÔ¨Åcation once again, and remove yas well. An illustration appears in Fig. 3. x yReLU ReLUReLU Fig. 3: Illustration: removing a neuron. xis a weightedsum neuron which feeds into y, a ReLU neuron. After converting yinto a weightedsum neuron, both xandycan be removed. The aforementioned steps constitute the framework of our approach ‚Äî to repeat, until saturation, the two steps: (i) id en tify any weightedsum neurons that only feed into weighted sum neurons, and remove them; and (ii) identify any activati on function neurons that can be changed into weightedsum neurons, without harming the network‚Äôs accuracy. The key remaining issue is how to identify those neurons to which ste p 2 can be applied. We elaborate on this issue in the following sections. IV. L INEARIZING ACTIVATION FUNCTIONS We next propose various criteria for determining which activation function neuron can be changed into weightedsu m neurons. Applying these criteria in practice is discussed l ater, in Section V. Phase Redundancy. In order to transform an activation function neuron into a weightedsum neuron without chang ing the network‚Äôs outputs, we leverage the properties ofpiecewiselinear functions. Let xbe a weightedsum neuron and lety=f(x)be an activation function neuron; then, by deÔ¨Ånition, the value range of xis divided into segments [s1,s2],[s2,s3],...[sk,sk+1], and in each segment yis a linear function (a weightedsum) of x. If we are able to discover that xis in fact restricted to one of these segments, i.e.si‚â§x < s i+1for some i, then we can safely discard the constraint y=f(x)and replace it with a linear constraint y=aix+bi, thus changing yto be a weightedsum neuron. We stress that this change does not alter the value of y, and consequently does not alter the network‚Äôs outputs. When thi s phenomenon occurs, we say that yisphaseredundant . For the ReLU function, this happens if we discover that x <0(y isinactiveredundant ), orx‚â•0(yisactiveredundant ). As previously stated, transforming the piecewiselinear con straint into a linear one will often allow us to eliminate two neurons from the network, without changing its outputs. Forward Redundancy. Phaseredundancy captures the case where an activation function neuron is Ô¨Åxed to a single linea r phase, for all possible inputs. However, there actually exi st unstable activationfunction neurons, i.e. neurons not Ô¨Åxed to a particular linear phase, which can still be soundly transfo rmed into weightedsum neurons computing one of these linear phases. Intuitively, this happens when neuron y‚Äôs assignment affects its ksucceeding layers, for some k >0, but gets ‚Äúcanceled out‚Äù in layer k+ 1. A small, illustrative example appears in Fig. 4. When replacing ywith a weightedsum neuron only affects neurons that are at most klayers away fromy, we say that yiskforwardredundant . Much like phaseredundant neurons, kforwardredundant neurons can be removed from the network without harming its accuracy. Input [‚àí1,1]+0WS +1yReLU +1WS +1ReLU +0WS +0ReLU Output1 11 ‚àí11 11 11 11 1 Fig. 4: The orange ReLU neuron, marked y, is2forwardredundant . Replacing ywith a constant zero affects the following WS and ReLU layers, but it does not affect the last WS layer (and thus the n etwork output). For example, observe that if we input 1into the network, y evaluates to 1, and the network‚Äôs output evaluates to 12. This output value is unchanged even if we replace y‚Äôs value with 0. A careful examination of the network reveals that this will always be t he case, regardless of the network‚Äôs input value. More formally, let vj ibe an activation function neuron, and letN‚Ä≤be a network obtained from Nreplacing vwith a weightedsum neuron vj i=bj i+/summationtextckxk. LetV1denote an input vector, on which both NandN‚Ä≤are evaluated; and letV2,...,V nandV‚Ä≤ 2,...,V‚Ä≤ ndenote the layer evaluations ofNandN‚Ä≤(respectively) on V1. If, for every V1, it holds thatVi+k=V‚Ä≤ i+k, then we say that neuron vj iiskforward redundant (note that this implies Vi+k‚Ä≤=V‚Ä≤ i+k‚Ä≤for every k‚Ä≤> k). We note that a neuron that is phaseredundant is alsokforwardredundant, for any k‚â•0.Relaxed Redundancy. So far, we discussed replacing a piecewiselinear activation neuron with a weightedsum ne u ron that corresponds to one of the activation function‚Äôs lin ear segments; e.g., in the case of y=ReLU(x), neuronywould be changed into a weightedsum neuron computing either y= 0 ory=x. We observe that, although these linear functions are natural candidates for replacing the original constrai nt, in fact any linear function y=‚Ñì(x)could be used. SpeciÔ¨Åcally, given an activation function y=f(x)and some known lower and upper bounds lbandubforx(computed, e.g., using interval arithmetic [26] or abstract interpretation [14], [45]), we propose to Ô¨Ånd a linear function ‚Ñì(x)that has minimal error compared to f(x). We deÔ¨Åne this error to be max lb‚â§x‚â§ub|f(x)‚àí‚Ñì(x)| See Fig. 5 for an illustration of replacing a ReLU constraint , whose phase is not Ô¨Åxed, with three linear constraints. In ea ch illustration, the blue line is the ReLU, the dashed line is th e linear replacement, and the red area is the introduced error . In case (c), the maximal introduced error (the height of the red region) is the smallest among the three options. ‚àí1.00 ‚àí0.75 ‚àí0.50 ‚àí0.25 0.00 0.25 0.50 0.75 1.00‚àí1.0‚àí0.50.00.51.0 (a) Replacing a ReLU with the zero function‚àí1.00 ‚àí0.75 ‚àí0.50 ‚àí0.25 0.00 0.25 0.50 0.75 1.00‚àí1.0‚àí0.50.00.51.0 (b) Replacing a ReLU with iden tity function ‚àí1.00 ‚àí0.75 ‚àí0.50 ‚àí0.25 0.00 0.25 0.50 0.75 1.00‚àí1.0‚àí0.50.00.51.0 (c) Replacing a ReLU with an arbitrary linear function Fig. 5: Replacing a ReLU with linear functions. Unlike in the phaseredundancy and kforwardredundancy cases, setting y=‚Ñì(x)will introduce some imprecision to the network‚Äôs output. The motivation is that by replacing y=f(x) withy=‚Ñì(x)that has minimal error, we would be introducing only a small imprecision, while enabling the removal of y. Letetbe some userdeÔ¨Åned error threshold; when replacing y=f(x)with‚Ñì(x)introduces an error esuch that e‚â§et, we say that neuron yisrelaxedredundant . Let us focus on the y=ReLU(x)function as an example, and suppose we know that x‚àà[lb,ub]. Iflb <0and ub >0, the neuron is not phaseredundant. In this case, a linear function y=lm(x)with minimal error can be easily computed, and is given by: lm(x) =ub ub‚àílb¬∑x+‚àílb¬∑ub 2(ub‚àílb).It is straightforward to check that the maximum error is obtained when x= 0, and it is given by‚àílb¬∑ub 2(ub‚àílb)(a proof appears in Appendix A). Unsurprisingly, when lborubare close to0, the error becomes very small ‚Äî indicating that such ReLUs, which are ‚Äúalmost phaseredundant‚Äù, could be removed at a small cost to precision. It should be noted, however, that minimizing the maximum error introduced by the removal of a single neuron does not necessarily minimize the overall imprecision introduced to the network‚Äôs output s. ResultPreserving Redundancy. In classiÔ¨Åcation networks, it may be acceptable to give up some precision, as long as the output label for each input is unchanged; i.e., if the origin al network classiÔ¨Åed input xas labellwith80% conÔ¨Ådence, it may be acceptable to remove neurons in a way that reduces this conÔ¨Ådence to 60%, as long as xis still classiÔ¨Åed as l. More formally, let y=f(x)be an activation neuron in a network N, and let N‚Ä≤denote the same network with y replaced by a weighted sum neuron, y=‚Ñì(x). If, for every input vector V1, it holds that argmax (Vn) =argmax(V‚Ä≤ n), i.e. if both networks classify each input vector in the same way (regardless of the actual output neuron values computed), t hen we say that neuron yisresultpreserving redundant . See Fig. 6 for an example. Input [‚àí1,1]+0WS ‚àí0.2ReLU y+0WS +0.1#1Outputs #21 12 11 ‚àí1 Fig. 6: The orange ReLU, marked y, is resultpreserving redundant and can be replaced with a constant zero. Observe that any inp ut in range (0.1,1]is classiÔ¨Åed as label #1, while any input in range [‚àí1,0.1)is classiÔ¨Åed as label #2. The ReLU in orange is active only for inputs in (0.2,1], and it only increases the conÔ¨Ådence in label #1. For example, the network output for input 0.5is[1.3,0.3]T, and after replacing ywith0the output becomes [1.0,0.6]T. Label#1 still wins, but with a lower conÔ¨Ådence. Thus, yis resultpreserving redundant ‚Äî replacing it with a constant zero does not change the winning class, for the entire input domain. Note that resultpreserving redundancy is, in a way, more permissive than the previous categories: we do not directly try to bound the imprecision introduced, but rather only try to maintain the same output label for every input. Clearly, any neuron that is phaseredundant or kforwardredundant is also resultpreserving; and it is reasonable to assume that rela xed redundant neurons with a small error would also be result preserving redundant. The motivation for considering this kind of redundancy is that, due to its more permissive nature, it c an identify additional redundant neurons. Our deÔ¨Ånition of resultpreserving redundancy can also be slightly relaxed, to exclude inputs whose classiÔ¨Åcation wa s borderline ; i.e., inputs whose highestscored label and the secondhighest label received very similar scores. Intuit ively, with this alteration, a neuron is considered resultpreser ving redundant if it does not change the classiÔ¨Åcation of any inputs which were previously classiÔ¨Åed with a high degreeof conÔ¨Ådence, but may Ô¨Çip the classiÔ¨Åcation of inputs about which the DNN was not sure to begin with. The motivation for this change is to allow the removal of additional neurons . V. N EURON REMOVAL STRATEGIES In Section III we laid the theoretical foundations of our DNN simpliÔ¨Åcation approach, by deÔ¨Åning four kinds of redun dant neurons that could be removed to reduce network size. There exist many strategies for applying these deÔ¨Ånitions i n practice, in order to reduce network sizes. Intuitively, a g ood strategy is one that identiÔ¨Åes large sets of neurons that can be removed simultaneously, in a way that is computationally efÔ¨Åcient. In this Section, we propose one such strategy, whi ch we have empirically observed to perform well. Step 1: Bound Estimation using MILP. Letvbe an activation function neuron which we are considering for removal. In this context, it is useful to deduce lower and upper bounds forvthat are as tight as possible. Such bounds could lead, for example, to the classiÔ¨Åcation of vas phaseredundant, or enable us to compute lm(v)and declare vto be relaxed redundant. MixedInteger Linear Programming (MILP) [9] is a well studied method for solving a system of linear constraints wi th real and integer variables. In the context of DNN veriÔ¨Åcatio n, MILP can be used to derive lower and upper bounds on the values that the various neurons in the DNN can obtain [10], [43]. This is done by encoding a linear overapproximation o f the neural network into the MILP solver, and then using the solver‚Äôs objective function to maximize/minimize each of t he individual neurons. For example, after encoding a network N, we could set the solver‚Äôs objective function to 1¬∑v, wherevis some neuron in N; and the optimal solution discovered would then constitute v‚Äôs upper bound. As a Ô¨Årst step in the simpliÔ¨Åcation process, we propose to run such MILP queries for every neuron that is candidate for removal. The number of resulting queries can be large ‚Äî two queries per neuron, one for each bound ‚Äî but the gains are signiÔ¨Åcant, as the discovered bounds can often be quite tight [43]. At the end of this step, we immediately remove all phaseredundant neurons. In practice, it is useful to run the MILP solver with a short timeout (e.g., 10 second) for each neuron. In case a timeout occurs, modern solvers are able to provide a sound approxi mation of the optimal solution [37]. In our experiments, we observed that this initial step already detects a large numb er of phaseredundant neurons. Step 2: Simulations. After the MILP phase is concluded, we are left with multiple activationfunction neurons whos e phases are not yet Ô¨Åxed. It is possible that some of these neu rons are also phaseredundant, but that the bounds discover ed in the MILP pass were too loose to indicate this. It is also possible that they are kforwardredundant or resultpreserving redundant. At this point we wish to quickly rule out as many of these candidates as possible, before applying computation ally expensive steps to dispatch the remaining candidates.To do this, we follow in the footsteps of Gokulanathan et al. [15], and apply simulations ; i.e., we evaluate the network on a large number of random inputs, and for each input record the values assigned to the network‚Äôs neurons. Simulations c an easily show that a neuron is not phaseredundant, by demon strating two different inputs for which the neuron is in two different linear phases. Similarly, they can show that a neu ron is notkforwardredundant or resultpreserving redundant. Step 3: Formal VeriÔ¨Åcation. After the MILP and simulation phases, we are left with activationfunction neurons that a re candidates for removal, if we can prove them redundant. We now apply formal veriÔ¨Åcation to classify these remaining ne u rons. SpeciÔ¨Åcally, for each candidate neuron v, we: (i) apply veriÔ¨Åcation to check whether vis Ô¨Åxed to one if its linear phases, and is hence phaseredundant; and if not, (ii) if Nis a classiÔ¨Åcation network, apply veriÔ¨Åcation to check whether vis resultpreserving redundant; else, if Nis a regression network, apply veriÔ¨Åcation to check whether viskforwardredundant, for a value of kthat corresponds to the output layer. Each of these conditions can be posed as a DNN veriÔ¨Åcation query, as described next. As soon as a neuron is marked redundant, it is removed, and the process continues. In order to determine whether v=f(x)is phaseredundant, we must check whether xis restricted to a certain linear seg ment. Let [s1,s2],[s2,s3],...[sk,sk+1]be the set of possible segments. For each such segment [si,si+1], we can encode the DNN into the veriÔ¨Åer, and pose the query: ‚àÉV1.(x < si)‚à®(x > si+1). If the answer is UNSAT , we know that xis indeed Ô¨Åxed into segment [si,si+1]. An illustration appears in Fig. 7. Inputs x >0 vOutputsReLU ReLU ReLUReLU Fig. 7: A query for determining whether ReLU node v=ReLU(x) isphaseredundant : we check whether it is possible that x >0, and if not, we conclude that vis inactiveredundant. To facilitate the veriÔ¨Åcation process, the neurons in subsequent layers, as w ell as all other neurons in layer 2 (grayed out), are not encoded. Determining whether v=f(x)iskforwardredundant is done by creating a query where the part of the network startin g from the neuron in question is duplicated. One copy of the network is the unmodiÔ¨Åed one, and in the other copy v= f(x)is replaced with a weightedsum neuron, v‚Ä≤=‚Ñì(x). We query the veriÔ¨Åer whether it is possible that a neuron klayers away from vis assigned different values in the original and modiÔ¨Åed copies. If the answer is UNSAT , the neuron is k forwardredundant. See Fig. 8 for an illustration. Determining whether v=f(x)is resultpreserving redun dant is done by creating a query similar to the kforward redundant case, only this time we ask the veriÔ¨Åer whether ?=Inputs Outputs Fig. 8: 4ForwardRedundancy query illustration. The neuron in orange is the neuron being checked for forwardredundancy. In this case the layer being checked is at distance 4, which happens t o be the output layer. there exists an input that the two networks classify differe ntly. If the answer is UNSAT , we know that the neuron is indeed resultpreserving redundant. Step 4: Relaxed Redundancy and Accumulative Error. The aforementioned steps were aimed at identifying and removin g redundant neurons, without introducing any imprecision in to the simpliÔ¨Åed network. Last but not least, we discuss the removal of relaxedredundant neurons. Recall that relaxed  redundant neurons are determined by a userspeciÔ¨Åed error threshold et. Identifying these neurons is thus a local opera tion, that does not require veriÔ¨Åcation; for every neuron we can compute the maximum error introduced by replacing it withlm, and see whether it exceeds the threshold. While each relaxedredundant neuron can be identiÔ¨Åed locally, removing multiple neurons simultaneously runs th e risk of compounding the overall error, beyond the permitted threshold. To circumvent this issue and allow the efÔ¨Åcient removal of multiple relaxedredundant neurons, we introdu ce the following lemma: Lemma 1. LetNbe a neural network, and let N‚Ä≤be a simpliÔ¨Åed network, obtained from Nby removing relaxed redundant neurons u1,...,u n. Consider another neuron vin N‚Ä≤that is relaxedredundant, and let eindenote the error to v‚Äôsinput , previously introduced by the removal of u1,...,u n. Letevdenote the error introduced by the removal of v. Then, if we remove v, the overall error introduced to its output is upper bounded by: ein+ev This lemma tells us that the iterative removal of relaxed redundant neurons does not compound the introduced error; instead, the error introduced by the removal of each neuronis only added to the error already introduced by the removal of other neurons. This enables us, through a straightforwar d computation, to upper bound the overall imprecision (on the output layer) that the removal of a set of relaxedredundant neurons might cause. Consequently, our proposed strategy i s to begin removing relaxedredundant neurons with small err or rates, each time recomputing the overall network inaccurac y, until hitting the prescribed overall error threshold. A ful l, formal description of these claims appears in Appendix B. VI. I NTRODUCING REDUNDANCIES VIA INPUT SLICING So far, our simpliÔ¨Åcation efforts have hinged on the exis tence of redundant neurons. Next, we introduce a technique that can cause neurons to become redundant, even if they are initially not so. The core idea is to: (i) slice the input domain Dof the DNN Ninto smaller subdomains D1,...,Dn; (ii) duplicate the original network ntimes, resulting in networks N1,...,N n, such that network Niis associated with domain Di; and (iii) apply the simpliÔ¨Åcation process described in Section V for eachNi, separately. Intuitively, splitting the input domain into subdomains can serve to separate ‚Äúsimpler‚Äù inputs regions , in which many neurons are phaseredundant, from more ‚Äúcom plex‚Äù input domains where neurons Ô¨Çuctuate between phases. Various heuristics can be used for splitting the input domai n, depending on the network in question. A simple splitting method, which we used in our evaluation, is to split the range of each input coordinate into neven subranges. After the slicing and simpliÔ¨Åcation is done, we are left with a family of DNNs N1,...,N n, which are together equivalent to the original N. Evaluation is then performed in two steps: given an input vector V1, we Ô¨Årst identify the domain Dito whichV1belongs; and then compute Ni(V1)and return the result. As our evaluation shows, the resulting Ninetworks can be quite small, resulting in a signiÔ¨Åcant improvement to the expected number of operations required for evaluating t he network. This improvement might come at the expense of increased space requirements for storing the resulting fam ily of networks, making this approach suitable for cases where spa ce is abundant but fast inference is crucial. We note that, as a s ide effect, the resulting networks may be easier to verify [45], [47]. Discussion: Dependency on Input Dimensions. Our pro posed slicing method relies on splitting the input domain, by restricting input neurons to various values. This approa ch works quite well on DNNs with relatively few input neurons (e.g., the ACAS Xu family of networks [25]; see Section VII for details). For networks with a larger number of input neu rons (e.g., image recognition networks), the number of inpu t subdomains might be prohibitively large. Indeed, a simila r phenomenon has been observed for veriÔ¨Åcation techniques th at rely on input slicing [45], [47]. One approach for mitigating this difÔ¨Åculty is through per forming slicing not on the input layer, but on some smaller intermediate layer Lkin the network. Then, the network would be evaluated by evaluating the original network‚Äôs lay ersL1...Lk‚àí1, and then using the values computed for layer Lk in choosing from a set of networks for continuing the evalua tion. We speculate that for an intermediate layer of a modera te size, this approach could lead to improved performance over input slicing. We leave this for future work. Extreme Slicing: Complete Linearization. We observe that input slicing can be used to completely linearize every sub domain of the input space; that is, if the resulting sub domains are sufÔ¨Åciently small, then in each network Niall activation functions will become phaseredundant, effect ively collapsing the DNN into a linear transformation. Additiona lly, even if the slicing does not Ô¨Åx the phase of all activation function neurons, extreme slicing tends to decrease the err or introduced by removing relaxedredundant neurons; and thu s, complete linearization could be achieved by removing these neurons, even if they have not become phaseredundant. This linearization approach can thus be regarded as providing us with a simple, piecewiselinear approximation of the netwo rk as a whole ‚Äî with an upper bound on the error in each sub domain. Our experimental results in Section VII demonstrat e very low error rates on most subdomains. Complete linearization incorporates a tradeoff: in order to obtain very small, nearlylinear networks, the input domai n would have to be sliced many times. Users can Ô¨Ånetune the number of slices used, and consequently the sizes of the resulting DNNs, to their speciÔ¨Åc needs. VII. E VALUATION We created a proofofconcept implementation of our ap proach as a Python framework, available online [33] (togeth er with all benchmarks reported in this section). The framewor k provides all the functionality discussed so far: after impo rting a network, it can run MILP queries to compute neuron bounds; perform simulations; and identify phaseredundant, kforward redundant and resultpreserving redundant neurons, by run ning veriÔ¨Åcation queries. The framework uses the Gurobi [37] MILP solver and the Marabou [29] DNN veriÔ¨Åcation engine as backends, although other backends could also be used. For evaluation purposes, we conducted extensive experi ments on the ACAS Xu system: an airborne collision avoid ance system, implemented as a family of 45 neural net works [25]. Each of these neural networks has 5 input neurons , 5 output neurons, and 6 hidden layers with 50 neurons each and ReLU activation functions (310 neurons in total). Keepi ng the network sizes small was a key consideration in developin g the ACAS Xu system [25], making it a prime candidate on which to apply simpliÔ¨Åcation techniques. We began by comparing our approach to that of Goku lanathan et al. [15], which is the current stateoftheart in veriÔ¨Åcationbased simpliÔ¨Åcation of DNNs. Their technique can be regarded as a privatecase of ours, in which only spe ciÔ¨Åc phaseredundant neurons (speciÔ¨Åcally, inactivered undant ReLUs) are removed. We compared that approach to our framework, conÔ¨Ågured to identify and remove both active redundant and inactiveredundant ReLUs, and also to removerelaxedredundant neurons. We ran both tools on all 45 ACAS Xu networks; the results appear in Table I. TABLE I: PhaseRedundancy and RelaxedRedundancy on ACAS Xu networks. Inactive Active RelaxedRedundant Redundant Redundant «´= 10‚àí4«´= 10‚àí3«´= 10‚àí2 % of all neurons4% 4.2% 4.2% 4.6% 4.9% % of redundant neuronsbaseline 3.5% 5.3% 13.6% 21.5% output error bound0 0 0.02 2.64 525.1 The table depicts the accumulated numbers of redundant neurons, when read from left to right (which is the or der in which the techniques were applied). First, inactive redundant neurons are removed (this is the technique of [15] ), accounting for 4% of all neurons in the network. Active redundant neurons are next, removing another 0.2% of all neurons, which is a 3.5% increase in the number of removed neurons. Finally, relaxedredundant neurons are removed, with three possible alternative «´values. The most permissive one, «´= 10‚àí2, leads to the removal of 4.9% of the neurons in total, which is a 21.5% increase over the baseline ‚Äî but the resulting network error bound in this case, 525.1, is quite high.«´= 10‚àí3appears a better choice, with a total removal rate of4.6% and a signiÔ¨Åcantly smaller error bound of 2.64. We note that our evaluation indicates that the output error bounds currently computed are far from tight; devising tigh ter bounding schemes is a work in progress. In our second experiment, we evaluated our complete sim pliÔ¨Åcation pipeline. First, we applied inputslicing, div iding the input domain into 32,768 equal subdomains (3 rounds of bisecting the range of each of the 5input neurons in 2). Next, for each subdomain we: (i) ran MILP and removed any discovered phaseredundant neurons; (ii) ran simulations , and then formal veriÔ¨Åcation to discover and remove any remain ing phaseredundant neurons; and (iii) identiÔ¨Åed all resul t preserving neurons, and greedily attempted to simultaneou sly remove large sets thereof, using veriÔ¨Åcation. We note that identifying the largest set possible of resultpreserving neurons that can be removed simultaneously is a difÔ¨Åcult problem, an d our current heuristic was a simple, greedy approach. Devisi ng more sophisticated heuristics is left for future work. We ran the MILP step on all 32,768 subdomains, which resulted in the discovery of 67.3% phaseredundant neurons on average in each subdomain. We continued to run the pipeline on a sample of 50 subdomains selected at random. Most notably, we observed an average removal of 82.5% redundant neurons (out of all neurons in the network), with 7.2% additional neurons still candidates for removal, but f or which the underlying veriÔ¨Åcation engine timedout. Of the 82.5% removed neurons, 70.2% were phaseredundant, which is a very signiÔ¨Åcant increase from the 4.2% neurons removed when the pipeline was run over the entire input domain.This demonstrates the high effectiveness of input slicing. In addition, about 21% of phaseredundant neurons were active  redundant, which signiÔ¨Åes the importance of the generaliza tion from ‚Äúdead neurons‚Äù [15] to phaseredundancy. The remainin g 12.3% neurons removed were resultpreserving redundant. Fig. 9 shows the breakdown. 68% 12%11%7%PhaseRedundant by MILP PhaseRedundant by Formal Verification Result Preserving NonRedundant Unknown (Timeouts) Fig. 9: Redundant neuron removal, averaged over 10 ACAS Xu in put subdomains. Slicing is highly beneÔ¨Åcial for neuron removal, but results in a large number of subdomains that need to be checked. Within our pipeline, veriÔ¨Åcation steps are the most expensi ve, whereas MILP queries and simulations are relatively cheap. We observe, however, that MILP queries already account for most of the removed neurons. SpeciÔ¨Åcally, 68.5% of all phase  redundant neurons removed were discovered through MILP (about 83% of all redundant neurons), with a 10 second timeout for each individual MILP query. The next step, namely simulations, is also computationally cheap and highly effective. For each subdomain, we ran 100,000 simulations; and out of the of 31.5% neurons which were still candidates for removal after the MILP phase, an average of 26.4% of the neurons were ruled not phase redundant through simulations. This left only a small numbe r of candidates to be dispatched through veriÔ¨Åcation (5.1% of the neurons), which in turn discovered the remaining 1.7% redundant neurons, on average. In our experiment, each Marabou veriÔ¨Åcation query was run with a 4hour timeout. As discussed above, we used a fairly na¬® ƒ±ve strategy for discovering resultpreserving redundant neurons. SpeciÔ¨Å cally, we ran formal veriÔ¨Åcation on each candidate neuron to check whether it was individually resultpreserving redundant; this resulted in a set of candidates for removal. Then, we ran resultpreserving simulations, iteratively removing add itional candidate neurons from the network, as long as the simulatio ns could not Ô¨Ånd a counterexample to the redundancy of the currently removed set. Finally, we ran a single veriÔ¨Åcation query to verify that removing our selected neurons was indee d a resultpreserving operation. On 75% of the subdomains checked, this strategy worked. In subdomains where we were successful, we found an additional 24.6% forwardredundan t and resultpreserving redundant neurons; whereas in sub domains where we were not successful, we had a similar amount of candidates for removal on average. In the Ô¨Ånal step of our experiment, we tested our hypothesis that slicing can lead to the complete linearization of some of the subdomains. Indeed, for some of the subdomains explored, the simpliÔ¨Åcation pipeline was able to remove all neurons, resulting in a DNN that is effectively a lineartransformation. We noticed, however, a high variability ‚Äî for example, in another subdomain we were only able to remove 58% of the neurons. See Fig. 10 for additional details . We conclude that there is an inherent difference between the subdomains: apparently, some of them compute simpler transformations than others. 81% 17%37% 5% 42%15%PhaseRedundant by MILP PhaseRedundant by Formal Verification Result Preserving NonRedundant Unknown (Timeouts) Fig. 10: An ‚Äúalmost‚Äù linear subdomain (left) vs. a complex s ub domain (right). VIII. R ELATED WORK "
508,DTCA: Decision Tree-based Co-Attention Networks for Explainable Claim Verification.txt,"Recently, many methods discover effective evidence from reliable sources by
appropriate neural networks for explainable claim verification, which has been
widely recognized. However, in these methods, the discovery process of evidence
is nontransparent and unexplained. Simultaneously, the discovered evidence only
roughly aims at the interpretability of the whole sequence of claims but
insufficient to focus on the false parts of claims. In this paper, we propose a
Decision Tree-based Co-Attention model (DTCA) to discover evidence for
explainable claim verification. Specifically, we first construct Decision
Tree-based Evidence model (DTE) to select comments with high credibility as
evidence in a transparent and interpretable way. Then we design Co-attention
Self-attention networks (CaSa) to make the selected evidence interact with
claims, which is for 1) training DTE to determine the optimal decision
thresholds and obtain more powerful evidence; and 2) utilizing the evidence to
find the false parts in the claim. Experiments on two public datasets,
RumourEval and PHEME, demonstrate that DTCA not only provides explanations for
the results of claim verification but also achieves the state-of-the-art
performance, boosting the F1-score by 3.11%, 2.41%, respectively.","The increasing popularity of social media has brought unprecedented challenges to the ecology of information dissemination, causing rampancy of a large volume of false or unveriÔ¨Åed claims, like extreme news, hoaxes, rumors, fake news, etc. Re search indicates that during the US presidential election (2016), fake news accounts for nearly 6% of all news consumption, where 1% of users are ex posed to 80% of fake news, and 0.1% of users are responsible for sharing 80% of fake news (Grinberget al., 2019), and democratic elections are vulnera ble to manipulation of the false or unveriÔ¨Åed claims on social media (Aral and Eckles, 2019), which ren ders the automatic veriÔ¨Åcation of claims a crucial problem. Currently, the methods for automatic claim veri Ô¨Åcation could be divided into two categories: the Ô¨Årst is that the methods relying on deep neural net works learn credibility indicators from claim con tent and auxiliary relevant articles or comments (i.e., responses) (V olkova et al., 2017; Rashkin et al., 2017; Dungs et al., 2018). Despite their effec tiveness, these methods are difÔ¨Åcult to explain why claims are true or false in practice. To overcome the weakness, a trend in recent studies (the sec ond category) is to endeavor to explore evidence based veriÔ¨Åcation solutions, which focuses on cap turing the fragments of evidence obtained from reli able sources by appropriate neural networks (Popat et al., 2018; Hanselowski et al., 2018; Ma et al., 2019; Nie et al., 2019). For instance, Thorne et al. (2018) build multitask learning to extract evidence from Wikipedia and synthesize information from multiple documents to verify claims. Popat et al. (2018) capture signals from external evidence arti cles and model joint interactions between various factors, like the context of a claim and trustworthi ness of sources of related articles, for assessment of claims. Ma et al. (2019) propose hierarchical attention networks to learn sentencelevel evidence from claims and their related articles based on co herence modeling and natural language inference for claim veriÔ¨Åcation. Although these methods provide evidence to solve the explainability of claim veriÔ¨Åcation in a manner, there are still several limitations. First , they are generally hard to interpret the discovery process of evidence for claims, namely, lack the in terpretability of methods themselves because these methods are all based on neural networks, belongarXiv:2004.13455v1  [cs.CL]  28 Apr 2020ing to nontransparent black box models. Secondly , the provided evidence only offers a coarsegrained explanation to claims. They are all aimed at the interpretability of the whole sequence of claims but insufÔ¨Åcient to focus on the false parts of claims. To address the above problems, we de sign Decision Treebased CoAttention networks (DTCA) to discover evidence for explainable claim veriÔ¨Åcation, which contains two stages: 1) Decision Treebased Evidence model (DTE) for discovering evidence in a transparent and inter pretable way; and 2) Coattention Selfattention networks (CaSa) using the evidence to explore the false parts of claims. SpeciÔ¨Åcally, DTE is con structed on the basis of structured and hierarchical comments (aiming at the claim), which considers many factors as decision conditions from the per spective of content and meta data of comments and selects high credibility comments as evidence. CaSa exploits the selected evidence to interact with claims at the deep semantic level, which is for two roles: one is to train DTE to pursue the optimal decision threshold and Ô¨Ånally obtain more pow erful evidence; and another is to utilize the evi dence to Ô¨Ånd the false parts in claims. Experimen tal results reveal that DTCA not only achieves the stateoftheart performance but also provides the interpretability of results of claim veriÔ¨Åcation and the interpretability of selection process of evidence. Our contributions are summarized as follows: We propose a transparent and interpretable scheme that incorporates decision tree model into coattention networks, which not only dis covers evidence for explainable claim veriÔ¨Å cation (Section 4.4.3) but also provides inter pretation for the discovery process of evidence through the decision conditions (Section 4.4.2). Designed coattention networks promote the deep semantic interaction between evidence and claims, which can train DTE to obtain more pow erful evidence and effectively focus on the false parts of claims (Section 4.4.3). Experiments on two public, widely used fake news datasets demonstrate that our DTCA achieves more excellent performance than previ ous stateoftheart methods (Section 4.3.2). 2 Related Work "
161,Deep Speaker Vectors for Semi Text-independent Speaker Verification.txt,"Recent research shows that deep neural networks (DNNs) can be used to extract
deep speaker vectors (d-vectors) that preserve speaker characteristics and can
be used in speaker verification. This new method has been tested on
text-dependent speaker verification tasks, and improvement was reported when
combined with the conventional i-vector method.
  This paper extends the d-vector approach to semi text-independent speaker
verification tasks, i.e., the text of the speech is in a limited set of short
phrases. We explore various settings of the DNN structure used for d-vector
extraction, and present a phone-dependent training which employs the posterior
features obtained from an ASR system. The experimental results show that it is
possible to apply d-vectors on semi text-independent speaker recognition, and
the phone-dependent training improves system performance.","SPEAKER veriÔ¨Åcation, also known as voiceprint veriÔ¨Åca tion, is an important biometric authentication technique that has been widely used to verify speakers‚Äô identities. According to the text that are allowed to speak in enrollment and test, speaker veriÔ¨Åcation systems can be categorized into either textdependent or textindependent. While a text dependent system requires the same words/sentences to be spoken in enrollment and test, a textindependent system permits any words to speak. This paper focuses on a semi textindependent scenario where the words for enrollment and test are constrained in a limited set of short phrases, e.g., ‚Äòturn on the radio‚Äô. With this limitation, people can speak different sentences in enrollment and test while the system performance is not signiÔ¨Åcantly deteriorated, which makes the system more acceptable in practice. Most of the successful approaches to speaker veriÔ¨Åcation are based on generative models and with unsupervised learning, e.g., the famous Gaussian mixture modeluniversal background model (GMMUBM) framework [1]. A number of advanced models have been proposed based on the GMMUBM archi tecture, among which the ivector model [2] [3] is perhaps the most successful. Despite the impressive success, the GMM UBM model and the subsequent ivector model share the intrinsic disadvantage of all unsupervised learning methods: This work was supported by the National Natural Science Foundation of China under Grant No. 61371136 and No. 61271389, it was also supported by the National Basic Research Program (973 Program) of China under Grant No. 2013CB329302. The authors are with Division of Technical Innovation and Development of Tsinghua National Laboratory for Information Science and Technology and Research Institute of Information Technology (RIIT) of Tsinghua University. This paper is also supported by Sinovoice and Pachira. (Corresponding email: fzheng@tsinghua.edu.cn)the goal of the model training is to describe the distributions of the acoustic features, instead of discriminating speakers. This problem can be solved in two directions. The Ô¨Årst direction is to employ various discriminative models to en hance the generative framework. For example, the SVM model for GMMUBMs [4], and the PLDA model for ivectors [5]. All these approaches provide signiÔ¨Åcant improvement over the baseline. Another direction is to look for more discriminative features, i.e., the features that are more sensitive to speaker change and largely invariant to change of other irrelevant factors, such as phone contents and channels [6]. However, the improvement obtained by the ‚Äòfeature engineering‚Äô is much less signiÔ¨Åcant compared to the achievements obtained by the discriminative models such as SVM and PLDA. A possible reason is that most of the features are humancrafted and thus tend to be suboptimal in practical usage. Recent research on deep learning offers a new idea of ‚Äòfeature learning‚Äô. It has been shown that with a deep neural network (DNN), taskoriented features can be learned layer by layer from very raw features. For example in automatic speech recognition (ASR), phonediscriminative features can be learned from spectrum or Ô¨Ålter bank energies (Fbanks). The learned features are very powerful and have defeated the conventional feature based on Mel frequency cepstral coefÔ¨Åcients (MFCCs) that has dominated in ASR for several decades [7]. This favorable property of DNNs in learning taskoriented features can be utilized to learn speakerdiscriminative features as well. A recent study shows that this is possible at least in textdependent tasks [8]. The authors constructed a DNN model and set the training objective as to discriminate a set of speakers, and for each frame, the speakerdiscriminative features were read from the activations of the last hidden layer. They tested the method on a footprint textdependent speaker veriÔ¨Åcation task (only a short phrase ‚Äòok, google‚Äô). The experimental results showed that reasonable performance can be achieved with the DNNbased features, although it is still difÔ¨Åcult to compete the ivector baseline. In this paper, we extend the application of the DNNbased feature learning approach to semi textindependent tasks, and present a phonedependent training which involves phone posteriors obtained from an ASR system in the training. The experimental results show that the DNNbased feature learning works well on textindependent tasks, actually even better than on textdependent tasks, and the phonedependent training offers marginal but consistent gains. The rest of this paper is organized as follows. Section II describes the related work, and Section III presents the DNNarXiv:1505.06427v1  [cs.CL]  24 May 2015JOURNAL OF L ATEX CLASS FILES, VOL. 13, NO. 9, SEPTEMBER 2014 2 based speaker feature learning. The experiments are presented in Section IV, and Section V concludes the paper. II. R ELATED WORK "
311,Social Media Writing Style Fingerprint.txt,"We present our approach for computer-aided social media text authorship
attribution based on recent advances in short text authorship verification. We
use various natural language techniques to create word-level and
character-level models that act as hidden layers to simulate a simple neural
network. The choice of word-level and character-level models in each layer was
informed through validation performance. The output layer of our system uses an
unweighted majority vote vector to arrive at a conclusion. We also considered
writing bias in social media posts while collecting our training dataset to
increase system robustness. Our system achieved a precision, recall, and
F-measure of 0.82, 0.926 and 0.869 respectively."," Humans have the cognitive ability to understand          various writing styles and distinguish between writing          samples from different authors. This also allows          humans to tell whether or not a writing sample            belongs to a given author after having read enough of             their articles. We want to apply computeraided          authorship detection on shorter writing samples that          we gathered through social media to intelligently          identify authors of such posts. In this paper, we            explore how we can identify whether a given author‚Äôs            writing actually belongs to them by using various           natural ‚Äã  ‚Äã language ‚Äã  ‚Äã and ‚Äã  ‚Äã machine ‚Äã  ‚Äã learning ‚Äã  ‚Äã approaches.       Methods to determine authorship of a writing sample           have been developed and studied a lot since 19 ‚Äã th            Century. The most famous example was figuring out           authors for federalist papers, a collection of          politicallymotivated articles. It has formed a branch          in nature language processing called stylometry.         There are several stylometric features we can consider           in order to measure the similarities between author‚Äôs           writing and the target writing sample. These features         can be primarily categorized as lexical, syntactic,          semantic, and application specific. As technology         advances and computing becomes faster and more          accessible, various statistical and machine learning         methods make it possible to use these features to            distinguish between writing samples of various         authors with relatively high confidence. In this paper,           we study Reddit posts and are able to tell whether the              post belongs to a given user or not. Reddit is a social               news aggregation website where users can share news           articles and make comments to contribute to          discussion. Normally, a comment is short (no more           than 100 words) and casual in nature. We are            particularly interested in these comments to see which           user account they belong to. We built various           wordlevel and characterlevel models utilizing        stylometric features and aggregated the results using          an unweighted majority voting system to arrive at a            final decision. With this method of ensemble learning,           we are able to achieve fairly high system           performance.    2 Motivation    We are in an information era now where social media             is booming and a ton of data is generated daily. There              are several applications of being able to identify the            author of a short text, such as detecting hacked social             media accounts. If we are able to verify that posts             coming from a certain account do not seem to be             written by the actual owner of the account, that could             be a possible indication of a hacked account.           Moreover, we could establish the credibility of a           source. We figure out the credibility of a piece of             content (post or a comment) written by a user on             social media if we are able to detect whether the             content posted is actually by the account owner or            someone else. This is very useful as many notable            politicians, such as presidents, are using social media           to post politically motivated writings. In addition, we           can prevent negative phenomenon like bullying in          group texts, messages, or an aggregated piece of text            if we are able to identify who the author might be              from ‚Äã  ‚Äã a ‚Äã  ‚Äã potential ‚Äã  ‚Äã pool ‚Äã  ‚Äã of ‚Äã  ‚Äã contributors.            2.1 ‚Äã  ‚Äã‚Äã  ‚Äã Personal ‚Äã  ‚Äã Motivation       One of our close friends had his Facebook account            hacked multiple times and did not realize that he had             been hacked until a few days had passed even though             there were posts made from his account. When we            noticed that the content posted from his account did            not look like something he would write, we notified            him immediately, and he was able to regain control of             his ‚Äã  ‚Äã account.          Figure ‚Äã  ‚Äã 1: ‚Äã ‚Äã  ‚Äã Our ‚Äã  ‚Äã friend‚Äôs ‚Äã  ‚Äã post ‚Äã  ‚Äã‚Äã  ‚Äã after ‚Äã  ‚Äã getting ‚Äã  ‚Äã hacked       This led to us exploring more about what we could do              to aid this process of detecting authorship in social            media ‚Äã  ‚Äã posts ‚Äã  ‚Äã and ‚Äã  ‚Äã its ‚Äã  ‚Äã various ‚Äã  ‚Äã use ‚Äã  ‚Äã cases.    3 Result    We collected over 1000 comments made by Redditor           VRCkid and 1000 random comments made by top 20            Reddit users. We built five models for VRCkid and            partitioned 70 percent of his posts as training data and             crosstested with 30 percent of VRCkid‚Äôs remaining          posts combined with 30% of other aggregated random           Redditors‚Äô posts. We used 10fold crossvalidation         and were able to achieve a precision, recall and            Fmeasure ‚Äã  ‚Äã of ‚Äã  ‚Äã 0.82, ‚Äã  ‚Äã 0.926 ‚Äã  ‚Äã and ‚Äã  ‚Äã 0.869 ‚Äã  ‚Äã respectively.    4 Experiment    We began by collecting user comments from Reddit           and applied a combination of five different models to            conduct ‚Äã  ‚Äã our ‚Äã  ‚Äã experiment.    4.1 Data ‚Äã  ‚Äã Collection    We used Python Reddit API Wrapper (PRAW) library           to pull user data from Reddit and save it in JSON              format so we can interpret and process it easily later.             We considered bias in social media posts on Reddit            and realized that most posts made by authors in            subreddits were a collection of best practices,          questions, and links, and these did not accurately           describe the author‚Äôs natural writing style. Hence, we           decided to focus on the authors‚Äô comments instead.         Comments on Reddit seemed to more naturally reflect           author‚Äôs writing and provided a better sense of their            writing style. We gathered 1000 random comments          for the 20 top Redditor‚Äôs in addition to all of             VRCkid‚Äôs comments, and we separated them by user           names. Each file we stored represented a user and            contained ‚Äã  ‚Äã an ‚Äã  ‚Äã array ‚Äã  ‚Äã of ‚Äã  ‚Äã strings.    4.2 Method ‚Äã  ‚Äã 1: ‚Äã  ‚Äã Word ‚Äã  ‚Äã Frequency   "
359,Kernel-based Translations of Convolutional Networks.txt,"Convolutional Neural Networks, as most artificial neural networks, are
commonly viewed as methods different in essence from kernel-based methods. We
provide a systematic translation of Convolutional Neural Networks (ConvNets)
into their kernel-based counterparts, Convolutional Kernel Networks (CKNs), and
demonstrate that this perception is unfounded both formally and empirically. We
show that, given a Convolutional Neural Network, we can design a corresponding
Convolutional Kernel Network, easily trainable using a new stochastic gradient
algorithm based on an accurate gradient computation, that performs on par with
its Convolutional Neural Network counterpart. We present experimental results
supporting our claims on landmark ConvNet architectures comparing each ConvNet
to its CKN counterpart over several parameter settings.","For many tasks, convolutional neural networks (ConvNets) are currently the most successful approach to learning a functional mapping from inputs to outputs. For example, this is true for image classiÔ¨Åcation, where they can learn a mapping from an image to a visual object category. The common description of a convolutional neural network decomposes the architecture into layers that implement particular parameterized functions (Goodfellow et al., 2016). The Ô¨Årst generation of ConvNets, which include the Neocognitron (Fukushima, 1980) and the LeNet series (LeCun, 1988, 1989; LeCun et al., 1989, 1995, 2001) stack two main types of layers: convolutional layers and pooling layers. These two types of layers were motivated from the HubelWiesel model of human visual perception (Hubel and Wiesel, 1962). A convolutional layer decomposes into several units. Each unit is connected to local patches in the feature maps of the previous layer through a set of weights. A pooling layer computes a local statistic of a patch of units in one feature map. This operational description of ConvNets contrasts with the mathematical description of kernelbased methods. Kernelbased methods, such as support vector machines, were at one point the most popular array of approaches to learning functional mappings from input examples to output labels (Sch√∂lkopf and Smola, 2002; Steinwart and Christmann, 2008). Kernels are positivedeÔ¨Ånite pairwise similarity measures that allow one to design and learn such mappings by deÔ¨Åning them as linear functionals in a Hilbert space. Owing to the socalled reproducing property of kernels, these linear functionals can be learned from data. This apparent antagonism between the two families of approaches is, however, misleading and somewhat unproductive. We argue and demonstrate that, in fact, any convolutional neural network can potentially be translated into a convolutional kernel network , a kernelbased method with an appropriate hierarchical compositional kernel. Indeed, the operational description of a ConvNet can be seen as the description of a datadependent approximation of an appropriate kernel map. 1arXiv:1903.08131v1  [stat.ML]  19 Mar 2019The kernel viewpoint brings important insights. Despite the widespread use of ConvNets, relatively little is understood about them. We would, in general, like to be able to address questions such as the following: What kinds of activation functions should be used? How many Ô¨Ålters should there be at each layer? Why should we use spatial pooling? Through CKNs we can begin to understand the answers to these questions. Activation functions used in ConvNets are used to approximate a kernel, i.e., a similarity measure, between patches. The number of Ô¨Ålters determines the quality of the approximation. Moreover, spatial pooling may be viewed as approximately taking into account the distance between patches when measuring the similarity between images. We lay out a systematic translation framework between ConvNets and CKNs and put it to practice with three landmark architectures on two problems. The three ConvNet architectures, LeNet1, LeNet5, and AllCNNC, correspond to milestones in the development of ConvNets. We consider digit classiÔ¨Åcation with LeNet1 and LeNet5 on MNIST (LeCun et al., 1995, 2001) and image classiÔ¨Åcation with AllCNNC (Springenberg et al., 2015) on CIFAR10 (Krizhevsky and Hinton, 2009). We present an efÔ¨Åcient algorithm to train a convolutional kernel network endtoend, based on a Ô¨Årst stage of unsupervised training and a second stage of gradientbased supervised training. To our knowledge, this work presents the Ô¨Årst systematic experimental comparison on an equal standing of the two approaches on realworld datasets. By equal standing we mean that the two architectures compared are analogous from a functional viewpoint and are trained similarly from an algorithmic viewpoint. This is also the Ô¨Årst time kernelbased counterparts of convolutional nets are shown to perform on par with convolutional neural nets on several real datasets over a wide range of settings. In summary, we make the following contributions: Translating the LeNet1, LeNet5, and AllCNNC ConvNet architectures into their Convolutional Kernel Net counterparts; Establishing a general gradient formula and algorithm to train a Convolutional Kernel Net in a supervised manner; Demonstrating that Convolutional Kernel Nets can achieve comparable performance to their ConvNet counterparts. The CKN code for this project is publicly available in the software package yesweckn athttps://github. com/cjones6/yesweckn . 2 Related work "
271,Neural Network Compression of ACAS Xu Early Prototype is Unsafe: Closed-Loop Verification through Quantized State Backreachability.txt,"ACAS Xu is an air-to-air collision avoidance system designed for unmanned
aircraft that issues horizontal turn advisories to avoid an intruder aircraft.
Due the use of a large lookup table in the design, a neural network compression
of the policy was proposed. Analysis of this system has spurred a significant
body of research in the formal methods community on neural network
verification. While many powerful methods have been developed, most work
focuses on open-loop properties of the networks, rather than the main point of
the system -- collision avoidance -- which requires closed-loop analysis.
  In this work, we develop a technique to verify a closed-loop approximation of
the system using state quantization and backreachability. We use favorable
assumptions for the analysis -- perfect sensor information, instant following
of advisories, ideal aircraft maneuvers and an intruder that only flies
straight. When the method fails to prove the system is safe, we refine the
quantization parameters until generating counterexamples where the original
(non-quantized) system also has collisions.","The Airborne Collision Avoidance System X (ACAS X) is a midair collision avoidance system under development [26], with the ACAS Xu variant focused on collision avoidance for unmanned aircraft [20]. Originally designed oine using dynamic programming and Markov decision processes (MDPs) [21], the large rule table was compressed by a factor of 1000 using a set of neural networks [19]. The proposed system is an example of a neural network control system (NNCS), where the system's execution alternates between the aircraft dynamics and a neural network controller. As collision avoidance is safetycritical, analysis of the neural networks has spurred a signicant body of research on neural network verication. Most existing work, however, focuses on openloop verication, such as property 3from the original work [20], which states, \if the intruder isarXiv:2201.06626v3  [math.NA]  27 Mar 20222 S. Bak and H.D. Tran directly ahead and is moving towards the ownship, [a turn will be commanded]."" Openloop properties can be expressed in terms of constraints over the inputs and outputs of a single execution of the neural network. However, satisfying open loop properties does not prove the system is safe, as this requires reasoning with the physical system dynamics|how the aircraft responds to turn commands. Also, the system is running continuously and may change advisories at a future time, complicating safety analysis. Verication of closedloop safety of provided collision avoidance system under all designed operating conditions is thus a sort of grand challenge. While verication of neural networks is continuously improving, an intrigu ing alternate approach has recently been proposed based on input quantiza tion [15]. Rather than verifying the neural network directly, which requires rea soning about the semantics at each layer, the system's execution semantics are changed to round the inputs to a discrete set of possible values before running the network. To be clear, this type of quantization is a preprocessing layer be fore the network runs; it does not change the representation of the  oatingpoint values inside the network itself. Through input quantization, proving openloop properties of a neural network is reduced to the problem of network execution for each of a nite set of possible inputs. Due to the possibility of combina torial explosion, this strategy can only work if the number of inputs is small, which is often the case for neural networks used in control systems. When the strategy is applicable, however, it enjoys several advantages: (i) batch execu tion of neural networks is often used in training and so optimized hardware like GPUs can be leveraged to enumerate the possible inputs for verication, (ii) the performance of the nal quantized system approximates the performance of the original neural network and the approximation can be tuned through the quanti zation parameters, and (iii) the verication method only requires execution, and works regardless of the network size, the network architecture, or the layer types, unlike most neural network verication methods. In the context of verication, however, quantization has only been considered for openloop properties. In this work, we propose an approach to formally verify quantized closed loop NNCS. Although the technique is general, we focus primarily on proving safety for quantized version of the wellstudied aircraft collision avoidance neu ral network benchmark. Two key ideas are needed to make this work: (1) we perform state quantization rather than input quantization and (2) we use back reachability from the unsafe states to reduce the number of partitions. We prove the approach is sound and complete, in the sense that by continuing to rene quantization parameters, either the quantized system will eventually be proven safe or an unsafe counterexample will be found in the original system. When the method fails to prove safety of quantized closedloop system, we rene the quan tization values until discovering cases where the original (unquantized) version of the system fails. We also show that with stricter assumptions on the ownship aircraft's velocity, the quantized system can guarantee safety.Neural Network Compression of ACAS Xu Early Prototype is Unsafe 3 Fig. 1: The closedloop airtoair collision avoidance system design. 2 Background and Problem Formulation We next review key aspects of the system design, proof assumptions, and provide background onAHPolytopes before formulating the safety verication problem. 2.1 Collision Avoidance System Design We are interested in safety verication and falsication of the closedloop air toair collision avoidance system [21,20] depicted in Figure 1. The system com putes advisory commands to control an ownship aircraft with physical dynamics described by a set of ordinary dierential equations (ODEs), trying to avoid collisions with a nearby intruder. A detailed description of the inputs and actions in the system is shown in Table 1. The system receives 7 inputs about the state of an ownship and a nearby intruder aircraft, I=f;; ;vown;vint;;aprevg, and produces one of ve possible advisories for the ownship, A=fcoc, wl, wr, sl, sr g. The turn advisories in the system are generated by 45 deep ReLU neural networks with 6 layers and 50 neurons per layer for each network. Control switches between dierent neural networks Naprev;based on the previous ad visoryaprev (total of 5 choices) and the time until loss of vertical separation =f0;1;5;10;20;50;60;80;100g(total of 9 choices). For example, the network N5;3will be invoked if the previous advisory is aprev =srand= 5. If the ownship and the intruder are at the same altitude, then = 0 and only ve neural network controllers need to be used, N1;1;N2;1;N3;1;N4;1, andN5;1. 2.2 Assumptions and Plant Model Before we describe the plant model used in analysis, we rst state our system as sumptions: (i) the intruder  ies in straightline trajectories with constant speed,4 S. Bak and H.D. Tran (ii) the ownship  ies with constant speed and its heading is adjusted every sec ond (the NNCS control period), (iii) the actions correspond to heading changes in the intruder of 1 :5 deg/sec for weak turn commands, 3 :0 deg/sec for strong turns and 0 :0 deg/sec for clearofcon ict commands [19], (iv) there is no sensor noise and (v) advisories are followed exactly and immediately. Many of these are fairly strong and the real system would need to be robust to maneuvering intruders, pilot delay and sensor noise. From a safety proof perspective, however, we would want the system to at least be safe under these ideal assumptions. To model the state of the system with these assumptions, we use Carte sian coordinates. The values xown;yown;xint;yintrefer to the xandyposi tions of the ownship and the intruder; vown=p (vxown)2+ (vy own)2andvint=p (vx int)2+ (vy int)2are the speed of the ownship and the intruder; ownandint are the heading of the ownship and the intruder w.r.t the xaxis. The system performs idealized turn maneuvers modeled with Dubins aircraft dynamics: _xown=vx own=vowncos(own) _yown=vy own=vownsin(own) _xint=vx int=vintcos(int) _yint=vy int=vintsin(int)(1) Equation 1 does not show clearly how the aircraft can be controlled by chang ing their heading. Taking derivatives of the Equation 1 one more time and notic ing that _ownis a constant between advisories, _own= (=180)u=c(rad=s ), and then taking _int= 0, we obtain the following 8d linear system dynamics: 2 66666666664_xown _yown _vx own _vy own _xint _yint _vx int _vy int3 77777777775=2 666666666640 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0"
293,Investigating the Impact of Inclusion in Face Recognition Training Data on Individual Face Identification.txt,"Modern face recognition systems leverage datasets containing images of
hundreds of thousands of specific individuals' faces to train deep
convolutional neural networks to learn an embedding space that maps an
arbitrary individual's face to a vector representation of their identity. The
performance of a face recognition system in face verification (1:1) and face
identification (1:N) tasks is directly related to the ability of an embedding
space to discriminate between identities. Recently, there has been significant
public scrutiny into the source and privacy implications of large-scale face
recognition training datasets such as MS-Celeb-1M and MegaFace, as many people
are uncomfortable with their face being used to train dual-use technologies
that can enable mass surveillance. However, the impact of an individual's
inclusion in training data on a derived system's ability to recognize them has
not previously been studied. In this work, we audit ArcFace, a
state-of-the-art, open source face recognition system, in a large-scale face
identification experiment with more than one million distractor images. We find
a Rank-1 face identification accuracy of 79.71% for individuals present in the
model's training data and an accuracy of 75.73% for those not present. This
modest difference in accuracy demonstrates that face recognition systems using
deep learning work better for individuals they are trained on, which has
serious privacy implications when one considers all major open source face
recognition training datasets do not obtain informed consent from individuals
during their collection.","Face recognition systems using Deep Convolutional Neural Net works (DCNNs) depend on the collection of large image datasets containing thousands of sets of specific individuals‚Äô faces for train ing. Using this data, DCNNs learn a set of parameters that can map an arbitrary individual‚Äôs face to a feature representation, or faceprint , that has small intraclass and large interclass variability. The ability of a face recognition system to distinguish between identities within this embedding space depends on the size and diversity of its training data, along with its model capacity and underlying algorithms. Face recognition systems have benefited from the enabling power of Internet in the collection of largescale image datasets and from hardware improvements in enabling effi cient training of large models. Recently, increased attention to face recognition by academia, industry and government has brought new researchers, ideas and funding to the field, leading to perfor mance improvements on benchmark tasks Labelled Faces in the Wild (LFW) [ 20] and MegaFace [ 32]. Consequently, face recogni tion systems are now being integrated into consumer and industrial electronic devices and offered as application programming inter faces (APIs) by providers such as Amazon, Microsoft, IBM, Megvii and Kairos. However, along with improved performance has come increased public discourse on the ethics of face recognition systems and their development. Algorithmic auditing of commercial face analysis applications has uncovered disparate performance for intersectional groups across several tasks. Poor performance for darker skinned females by commercial face analysis APIs has been reported by Buolamwini, Gebru and Raji [ 5,35], as has lower accuracy in face identification by commercial systems with respect to lower (darker) skin reflectance by researchers at the US Department of Homeland Security [ 9]. As bias in training data begets bias in model performance, efforts to create more diverse datasets for these tasks have resulted. IBM‚Äôs Diversity in Faces dataset [ 28], released in January 2019, is a direct response to this body of research. Using ten established coding schemes from scientific literature, researchers annotated one mil lion face images in an effort to advance the study of fairness and accuracy in face recognition. However, this dataset has seen public scrutiny from a different, but equally notable perspective. A March 2019 investigation by NBC News into the origins of the datasetarXiv:2001.03071v2  [cs.CY]  10 Jan 2020brought to the public conversation the issue of informed consent in largescale academic image datasets, as IBM leveraged images from Flickr with a Creative Commons Licence without notifying content owners of their use [40]. To rationalize the collection of largescale image datasets without explicit consent of individuals, some computer vision researchers appeal to the noncommercial nature of their work. However, work by Harvey et al. at MegaPixels have found that authors‚Äô stated limi tations on dataset use do not translate to realworld restrictions [ 16]. In the case of Microsoft‚Äôs MSCeleb1M dataset, authors included an explicit ‚Äúnoncommercial research purpose only"" clause with the dataset, which was the largest publiclyavailable face recogni tion dataset at the time. However, as the dataset has been cited in published works by the research arms of many commercial entities, findings cannot easily be isolated from improvements in product of ferings. As a direct result of MegaPixel‚Äôs work on the ethics, origins, and privacy implications of face recognition datasets, MSCeleb1M [15], Stanford‚Äôs Brainwash dataset [ 41] and Duke‚Äôs MultiTarget, MultiCamera dataset [ 37] were removed from their authors‚Äô web sites in June 2019. However, in the case of MSCeleb1M, the data remains accessible via torrents, derived datasets and other hosts [16]. In addition to issues of bias and informed consent in data col lection, the general use of face recognition systems by commercial and government agencies has been raised by civil rights groups and research centers, as there is no oversight for its deployment in civil society [ 1,49]. For these and other reasons, multiple cities in the United States have banned the use of face recognition systems for law enforcement purposes [8, 36, 51]. Many people are concerned with their identify being used to train the dualuse technology that is face recognition. With reports of face recognition being used by law enforcement entities to identify protesters in London [ 4] and Hong Kong [ 29], and measures enacted to ban face masks in the latter location [ 53], there is merit in understanding the impact of one‚Äôs inclusion in the training data that fuels the development of these systems. In an effort to inform the conversation about informed consent and privacy in the domain of face recognition, we conduct exper iments on a stateoftheart system. The goal of this work is to determine the impact of an individual‚Äôs inclusion in face recogni tion training data on a derived system‚Äôs ability to recognize them. To the best of the authors‚Äô knowledge, this is the first paper to investigate this relationship. The remainder of this paper is organized in the following man ner; section two outlines ethical considerations for some decisions in the design and implementation of this work, section three pro vides background for the taxonomy, algorithms and data used in face recognition research, section four outlines the design of exper iments used to address the research question, section five presents our results and adds discussion and the paper concludes in section six. 2 ETHICAL CONSIDERATIONS 2.1 Intent The intent of this work is to investigate the performance of face recognition systems with respect to inclusion in training datasets.While one interpretation of this work may be to motivate efforts to mitigate demographic bias in the development of face recognition systems, it should be noted that increasing the performance of face recognition systems in any context can increase their ability to be used for oppressive purposes. In addition, due to historical societal injustices against marginalized populations and raciallybiased po lice practices in the United States, a disproportionate number of African Americans and Hispanics are present in mugshot databases, often used by law enforcement agencies as data sources for face recognition systems [ 14,31]. These populations are therefore poised to receive a greater burden of the effects of improved face recog nition systems. We therefore position this work as informing the discussion on data privacy and consent when it comes to face recog nition systems and do not advocate for technical improvements without a larger discussion on the appropriate use and legality of the technology. 2.2 Use of MSCeleb1M As noted in the introduction, the MSCeleb1M dataset was re moved from Microsoft‚Äôs website in June 2019. In a response to a Financial Times inquiry, Microsoft stated the website was retired ‚Äúbecause the research challenge is over‚Äù [ 30]. However, a version of this dataset with detected and aligned faces from a ‚Äúcleaned‚Äù subset of the original images is available from the Intelligent Behaviour and Understanding Group (iBUG) at Imperial College London. The dataset was offered as training data for the ‚ÄúLightweight Face Recog nition Challenge & Workshop‚Äù1the group organized at ICCV 2019. The group has pretrained face recognition models available as benchmarks for the challenge, trained on this data. As this work aims to conduct experiments in a realistic setting in order to better inform the conversation around data collection processes, the analysis of a stateoftheart model, trained on a large dataset is necessary to gain insights that are applicable to commercial applications. We therefore have decided to use the MS Celeb1M dataset, through its derived version offered for the ICCV 2019 Workshop, for the limited scope of this work. 3 BACKGROUND 3.1 Face Recognition Tasks Within the domain of face recognition lies two categories of tasks: face verification andface identification [24]. In face verification, the goal is to assess if a presented image matches with the reference image of an individual, often to grant access to a physical device or location. Unlocking a smartphone with one‚Äôs face provides an example of face verification; a person presents their face to a phone and it is verified against a reference image of the known owner of the device. This task is referred to as 1:1 matching, as there is only one individual that the presented face image is compared against. In order to confirm a match, a threshold of similarity must be met, which can be set by the developer of a system to meet a specific level of security. Performance of a system on face verification tasks is reported in terms of accuracy; the number of correct verifications of all verification attempts. 1https://ibug.doc.ic.ac.uk/resources/lightweightfacerecognitionchallenge workshop/Table 1: Prominent opensource face recognition training datasets Dataset Year Released # Identities # Images Informed Consent Obtained? Source CASIA WebFace 2014 10,575 494K No [52] CelebA 2015 10,177 203K No [26] VGGFace 2015 2,622 2.6M No [34] MSCeleb1M 2016 99,952 10.0M No [15] UMDFaces 2016 8,277 368K No [3] MegaFace (Challenge 2) 2016 672,057 4.7M No [32] VGGFace2 2018 9,131 3.3M No [6] In face identification, a gallery of known identities is constructed from face images of individuals in advance of testing. Subsequently, a face image of unknown identity is presented to the system as the probe . The probe is then matched for similarity with all images in the gallery, constituting 1:N matching. If the system guarantees that the identity of the probe is within the gallery of identities, the problem is considered closedset face identification , otherwise it is considered openset face identification . Closedset face identification tasks are common in academic benchmarks, as galleries are carefully constructed by their authors to contain all probes. In openset face identification, a confidence threshold must be set to reject matches that do not meet a certain level of similarity. The selection of an appropriate threshold is es pecially relevant in highrisk applications such as law enforcement in which false positives have significant implications. Face identification performance is reported in terms of accuracy in returning the correct identity of a probe from the gallery, or in the openset case, no identity if the probe does not exist in the galley. Common performance metrics include Rank1 accuracy; of all identification attempts, the number of times the correct identity in the gallery is the most similar identity to the probe, and Rank10 accuracy; the number of times the correct identity is in the ten most similar identities to the probe. 3.2 Deep Face Recognition Rapid improvements in image classification in the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) [ 38] by AlexNet [ 23], ZFNet [ 54], GoogLeNet [ 42] and ResNet [ 17] from 2012 to 2015 cemented the DCNN as the standard method in computer vision research and applications. While early uses of convolutional neural networks in face verification showed preliminary success [ 7,19], it was not until the introduction of the aforementioned network architectures that the modern era of deep face recognition was in full swing. Coupled with innovations in loss function design and access to larger image datasets, modern face recognition systems have improved stateoftheart performance on benchmark face ver ification and identification tasks significantly in the past six years. For a complete survey of the development of deep face recognition systems, please refer to the review paper by Wang and Deng [ 47]; the following is a brief summary of major milestones. The first system to adapt findings from ILSVRC to face recogni tion was Facebook‚Äôs DeepFace [ 43], published in 2014 by Taigman et al. . The ninelayer AlexNetbased model was trained on a private dataset of 4.4M images of 4K identities and achieved stateoftheartaccuracy on face verification tasks LFW and YouTube Faces (YTF) [50], reducing the error rate by more than 50% on the latter task. Following this work, Google introduced FaceNet in 2015 with a major innovation in loss function design [ 39]. While the standard softmax loss function optimized interclass differences, researchers found that intraclass differences remained high, problematic in the domain of face recognition. To rectify this problem, the triplet loss was introduced to jointly minimize the Euclidean distance between an anchor example and a positive example of the same identity and maximize the distance between an anchor and negative example. Using a ZFNetbased model and a private dataset of 200M images of 8M identities, they achieved stateoftheart performance on LFW and YTF. Innovations in loss functions dominated the next wave of im provements in benchmark tasks, motivated by improving discrimi nation between classes by making features more separable. Wen et al. introduced the Center Loss in 2016 [ 48], followed by Liu et al.with the Angular Softmax in 2017 [ 25]. The Large Margin Co sine Loss was introduced in 2018 by Wang et al. [46], and in 2019, Deng et al. incorporated the Additive Angular Margin Loss into the ArcFace model [ 10], considered stateoftheart on multiple face recognition benchmarks when published. 3.3 Face Recognition Training Datasets Access to largescale face recognition training datasets has been essential to the development of modern solutions by the academic community. While early published resulted in the DCNNera of face recognition came out of companies with access to massive private datasets, such as Facebook‚Äôs 500M images and 10M identities [44] and Google‚Äôs 200M images and 8M identities [ 39], the release of several opensource datasets in the ensuing years has allowed researchers to train models at scale. A summary of notable face recognition training datasets of the past six years is provided in Table 1. These datasets catalyzed the field of face recognition and lead to great advances in model performance on benchmark tasks. They largely consist of celebrity identities and copyrighted images scraped from the internet. One exception is MegaFace, which is derived from the YFCC100M dataset of 100M photos with a Creative Commons Licence, from 550K personal Flickr accounts [ 45]. While the Creative Commons Licence permits the fair use of images, including in this context, Ryan Merkley, CEO of Creative Commons, noted the trouble of conflating copyright with privacy in a March 2019 statement: ‚Äú... copyright is not a good tool to protect individual privacy, to address.. MS1MRetinaFace(5.2M images of 93,431 identities)Training SetProbe SetsMS1MRetinaFace(93,431 IDs)VGGFace2(9,131 IDs)OutofDomain Probe SetInDomain Probe SetGallerySet Select 1000 random IDs per probe set, 50 random images per ID  MegaFaceChallenge 1(1.0M images of 690,572 identities)Assume no overlap with MS1MRetinaFace IDsArcFaceTraining..........512D Features............512D Features............512D FeaturesArcFaceInferenceArcFaceInferenceArcFaceInferenceFigure 1: Experimental procedure to generate feature representations of images in gallery and probe sets from ArcFace model research ethics in AI development, or to regulate the use of surveil lance tools employed online. Those issues rightly belong in the public policy space, and good solutions will consider both the law and the community norms of CC licenses and content shared online in general‚Äù [ 27]. While MegaFace contains unknown, noncelebrity identities, an October 2019 investigation by the New York Times demonstrated that account metadata associated with images in the dataset allows for a trivial realworld identification of individuals [18]. In all datasets, no informed consent was sought or obtained for individuals contained therein. 4 METHODOLOGY "
132,Information Verification for Humanitarians: A Critical Review.txt,"Quality humanitarian information is essential for efficient, effective and
coordinated humanitarian responses. During crises, however, humanitarian
responders rarely have access to quality information in order to provide the
much-needed relief in a timely fashion. Traditional methods for the acquisition
and evaluation of humanitarian information typically confront challenges such
as poor accessibility, limited sources, and the capacity of monitoring and
documentation. The more recent emergence of user generated content from online
social platforms addressed some challenges faced by traditional methods, but it
also raised many concerns regarding information quality and verifiability,
among others, that affect both the public and humanitarian actors. This paper
provides an overview of information verification methods in literature and
reviews information collection and verification practices and tools used by
news agencies and humanitarian organizations. Twenty crowd-sourced information
projects in humanitarian and human rights nature are surveyed. We discuss the
findings and give recommendations for future research.","2 An Overview of Information VeriÔ¨Åcation Methods 3 3 Information VeriÔ¨Åcation in News Organizations 3 4 Information VeriÔ¨Åcation in Humanitarian Organizations 6 5 Discussion and Future Research 7 1 Introduction Since the 1950s, the number and magnitude of disasters have incr eased exponentially (√ñzdamar and Ertem, 2015 ). About 300 million people on the average are effected annual ly since the 1990s ( ibid. ). Faced with complex humanitarian situations, responders rar ely have access to quality information for decisionmaking to provide much the needed relief in a timel y fashion. Besides the local knowl edge, examples of such information include the aid requests of victims, the numbers and locations of 1internally displaced persons, the incidents reports, the con ditions of essential local infrastructures, just to name a few. Humanitarian information is valued as the sine qua non of humanitarian response (OCHA, 2006 ), and humanitarian information management and exchange ar e the principle source of situational awareness, crisis decisionmaking and coordina tion (Altay and Labonte, 2014 ). Traditional methods for the acquisition and evaluation of hum anitarian information typically confront a number of challenges. First, to deliver aid and assi stance, humanitarian actors need to assess the situation and /or to seek representatives of the affected populations for i nterviews, but the actors are not always present in the vicinity of conÔ¨Çict or dis aster zones, or have access to those areas. Second, due to limited resources, accessibility, security and time, it is often very hard if not impossi ble to Ô¨Ånd victims and witnesses who can and are willing to prov ide potentially sensitive information. Third, humanitarian actors rarely have the capacity to conti nually monitor and document the inci dents over time in the affected areas, and to provide the affect ed populations timely and effective aid in return. In recent humanitarian crises such as the 2010 Haiti earthqu ake and the 2011 Egyptian revolu tion, incorporating humanitarian information from social media and User Generated Content (UGC) proved useful when the information was inspected at an aggre gated level (Dugdale et al., 2012 ). Dur ing those crises, online platforms such as Twitter and Facebo ok facilitated reporting information more efÔ¨Åciently than traditional communication channels (Norhe imHagtun and Meier, 2010 ; Hermida et al.,2014 ), and addressed some challenges faced by the traditional metho ds. The information con tained in UGC can be vital for effective response (Takahashi e t al., 2015 ), and can be used to boost the speed and accuracy of relief operations in realtime, an d to empower and uplift the morale of the local populations (Carley et al., 2016 ; Conrado et al., 2016 ; Panagiotopoulos et al., 2016 ; Haworth, 2016 ). Nevertheless, existing humanitarian information syste ms using technologies such as social media and crowdsourcing have shortcomings including but are no t limited to the following (Tapia et al., 2011 ; Dugdale et al., 2012 ; Haworth, 2016 ; Conrado et al., 2016 ; Anson et al., 2017 ): 1. The systems are not effective in collecting relevant and q uality information. While there is information overload and processing difÔ¨Åculties, there is a lso a high risk of receiving inaccurate and incorrect information (including that from malicious us ers). 2. There is no or limited evaluation of the reliability of the s ources and the credibility of the infor mation, making humanitarian actors and affected communiti es vulnerable to inaccurate and incorrect information. 3. The contributed information has largely been deemed as unver iÔ¨Åable and untrustworthy. Thus it is construed as unsuitable to incorporate into established mechanisms for decisionmaking. 4. There is a lack of feedback loops and empowerment of those (of ten the affected populations) who contributed the information, partly due to the above shortc omings. The quality of information from UGC is a major challenge that affects both the public and human itarian actors (Haworth, 2016 ). The vast volume of UGC circulating in social media contains relevant and useful information, which is potentially lifesaving, but it also contains Ô¨Çoods of irrelevancy, in accuracy and rumours (Anson et al., 2017 ). For these reasons, although there have been needs and interests from the humanitarian actors and local communiti es in the Ô¨Åeld to establish (effective and reliable) information exchange, many humanitarian actors a re sceptical about the levels of reliabil ity of selfreported information since the information is o ften unveriÔ¨Åable (Altay and Labonte, 2014 ; Conrado et al., 2016 ). How to detect relevant humanitarian information and verify t he information in an effective and efÔ¨Åcient manner is the concern of this paper. In the followin g, we Ô¨Årst provide an overview of informa tion veriÔ¨Åcation methods in literature, then review informa tion collection and veriÔ¨Åcation practices and tools used by news organizations and humanitarian organ izations. We end with a discussion of the Ô¨Åndings and recommendations for future research. 22 An Overview of Information VeriÔ¨Åcation Methods In literature, some researchers make no distinction between da ta (quality) and information (quality) (e.g., Wand and Wang, 1996 ; Pipino et al., 2002 ; Loshin, 2011 ) while some others see the difference as being crucial (e.g., Ackoff, 1989 ; Lillrank, 2003 ; Price and Shanks, 2005 ). The deÔ¨Ånitions of data or information quality in literature are also equivocal. In this paper, information quality refers to the semantic and pragmatic clarity of UGC rather than its syn tactic clarity (Huang, 2013 ). Important dimensions of information quality include relevance, accura cy, volume, completeness, timeliness, reliability and veriÔ¨Åability (Shanteau, 1992 ; Yildiz, 2015 ; Shamala et al., 2017 ). In relation to those, ve racity can be deÔ¨Åned as the combination of how accurate, complet e, reliable and timely the informa tion in question is (Lin et al., 2016 ). Veracity can also include trustworthiness which is an aggr egated dimension determined by the data origins (or the sources), and t he data collection and processing methods ( ibid. ). Information detection and veriÔ¨Åcation are often researched in the context of investigative jour nalism and (business, police, civilian or military) intelli gence, and in more general applications. Four major types of (not necessarily mutually exclusive) (text based) information detection and veriÔ¨Åca tion methods can be identiÔ¨Åed in literature: 1) crossvalidatio n, 2) expert opinion, 3) crowdsourcing, and 4) machine learning; see Table 1. Crossvalidation a.k.a. triangulation, of independent data sources is the proce ss where humanitar ian actors utilize additional information to validate the vera city of given information extracted from UGC (Crowley et al., 2013 ). A major limitation is the required manual input of users fo r validation. Its effectiveness is directly and entirely depende nt on the skill and ability of the users (Daume et al., 2014 ). Expert opinion is the process where experts or people of authority utilize t heir expertise or author itative sources to validate the veracity of information (Mar tin, 2016 ). This type of methods is limited by the availability of experts in the Ô¨Åeld ( ibid. ). Similar to crossvalidation, it often re quires extensive manual input, and the knowledge, skill and n etwork of the users ( ibid. ). Crowdsourcing is the use of Internet platforms in combination with the input of social media in order to validate the veracity of information harnessed from U GC (Riccardi, 2016 ). The users verify whether the given information is of good quality. Thi s requires a large number of users to determine the veracity of the information (a.k.a the wisdom of the masses, or collective in telligence) (Howe, 2008 ; Basu et al., 2016 ). Machine learning is the technology of getting computer systems to act without being explicitly pro grammed (Michalski et al., 2013 ), achieved through automated statistical methods (Alpaydin , 2014 ). Machine learning is applied in many Ô¨Åelds such as voice and i mage recognition, Ô¨Ånan cial predictions, information veriÔ¨Åcation and many other Ô¨Åe lds. Decision makers in the hu manitarian domain are still hesitant to use such methods due to t he uncertain accuracy and poor understandability (Altay and Labonte, 2014 ; Conrado et al., 2016 ). In addition, all the above methods do not explicitly and effective ly detect malicious uses and ru mours along the detection and veriÔ¨Åcation of relevant inform ation. Malicious uses and rumours are sources of instability during relief operations (Conrado et al .,2016 ; Riccardi, 2016 ). They can disrupt the Ô¨Çow of humanitarian operations (Haworth, 2016 ). For example, terrorists and kidnappers, and sometimes even the affected communities, media and humanita rian actors might publish false or unveriÔ¨Åed information (Altay and Labonte, 2014 ; Riccardi, 2016 ). The abuse and misuse of informa tion can create additional conÔ¨Çict and problems, and possibly pu t people in danger and jeopardize the success of the relief operation (Riccardi, 2016 ). 3 Information VeriÔ¨Åcation in News Organizations Some news agencies (particularly investigative journalis ts) and humanitarian actors lately started us ing information veriÔ¨Åcation tools for UGC due to the emergenc e of new media (Brandtzaeg et al., 2016 ; Altay and Labonte, 2014 ): 3Method Limitation Reference "
389,Profile to Frontal Face Recognition in the Wild Using Coupled Conditional GAN.txt,"In recent years, with the advent of deep-learning, face recognition has
achieved exceptional success. However, many of these deep face recognition
models perform much better in handling frontal faces compared to profile faces.
The major reason for poor performance in handling of profile faces is that it
is inherently difficult to learn pose-invariant deep representations that are
useful for profile face recognition. In this paper, we hypothesize that the
profile face domain possesses a latent connection with the frontal face domain
in a latent feature subspace. We look to exploit this latent connection by
projecting the profile faces and frontal faces into a common latent subspace
and perform verification or retrieval in the latent domain. We leverage a
coupled conditional generative adversarial network (cpGAN) structure to find
the hidden relationship between the profile and frontal images in a latent
common embedding subspace. Specifically, the cpGAN framework consists of two
conditional GAN-based sub-networks, one dedicated to the frontal domain and the
other dedicated to the profile domain. Each sub-network tends to find a
projection that maximizes the pair-wise correlation between the two feature
domains in a common embedding feature subspace. The efficacy of our approach
compared with the state-of-the-art is demonstrated using the CFP, CMU
Multi-PIE, IJB-A, and IJB-C datasets. Additionally, we have also implemented a
coupled convolutional neural network (cpCNN) and an adversarial discriminative
domain adaptation network (ADDA) for profile to frontal face recognition. We
have evaluated the performance of cpCNN and ADDA and compared it with the
proposed cpGAN. Finally, we have also evaluated our cpGAN for reconstruction of
frontal faces from input profile faces contained in the VGGFace2 dataset.","Due to the emergence of deeplearning, face recognition has achieved exceptional success in recent years [1]. However, many of these deep face recognition models perform relatively poorly in handling proÔ¨Åle faces compared to frontal faces [2]. When faces are captured in an unconstrained environment, in the wild, they are often in a proÔ¨Åle orientation. Thus there is an equiv alency between the challenging problems of unconstrained face recognition and proÔ¨Åle face recognition. Pose, expression, and lighting variations are considered to be major obstacles in attaining high unconstrained face recognition performance. Some methods [1], [3] attempt to address the posevariation issue by learning poseinvariant features, while some other methods [4], [5], [6], [7], [8] try to normalize images while preserving identity to a single frontal pose before recognition. However, there are three major difÔ¨Åculties related to face frontalization or normalization in unconstrained environments: Complicated facevariations besides pose: In comparison to a controlled environment, there are more complex face variations, e.g., lighting, head pose, expression, in real world scenarios. It is a difÔ¨Åcult task to directly warp the input face to a normalized view [7]. Unpaired data: Undoubtedly, obtaining a strictly normal ized face is expensive and timeconsuming, but getting an effective pair of images consisting of a target normalized face (i.e., frontalfacing, neutral expression) and an input face is difÔ¨Åcult due to highly imbalanced datasets [7]. Presence of artifacts: Synthesized ‚Äòfrontal‚Äô faces contain artifacts caused by occlusions and nonrigid expressions. * Authors Contributed Equally ¬ß. * Fariborz Taherkhani and Veeru Talreja contributed equallyIn this paper, we hypothesize that the proÔ¨Åle face domain shares a latent connection with the frontal face domain in a latent deep feature subspace. We aim to exploit this connection by projecting the proÔ¨Åle faces and frontal faces into a common latent subspace and perform veriÔ¨Åcation or retrieval in this latent domain. We propose an embedding model for proÔ¨Åle to frontal face veriÔ¨Åcation based on a deep coupled learning framework which uses a generative adversarial network (GAN) to Ô¨Ånd the hidden relationship between the proÔ¨Åle face features and frontal face features in a latent common embedding subspace. Our work is conceptually related to the embedding category of superresolution [9], [10], [11], [12] in that our approach also performs veriÔ¨Åcation of proÔ¨Åle and frontal faces in the latent space but not in the original image space. From our experiments, we observe that transforming proÔ¨Åle and frontal face features into a latent embedding subspace could yield higher performance than imagelevel face frontalization, which is susceptible to the negative inÔ¨Çuence of artifacts as a result of image synthesis. To our best knowledge, this study is the Ô¨Årst attempt to perform proÔ¨Åle tofrontal face veriÔ¨Åcation in a latent embedding subspace using generative modeling. This work is an extension of our previous work [13]. This paper makes the following contributions: The paper develops of a novel proÔ¨Åle to frontal face recog nition model using a coupled conditional GAN (cpGAN) framework with multiple loss functions. The paper includes comprehensive experiments using dif ferent datasets and a comparison of the proposed method with the stateoftheart methods, indicating the efÔ¨Åcacy of the proposed GAN framework. The proposed framework can potentially be used to imarXiv:2107.13742v1  [cs.CV]  29 Jul 2021JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 2 prove the performance of traditional face recognition methods by integrating it as a preprocessing procedure for a facefrontalization schema. The paper includes experiments to evaluate the frontaliza tion performance of the cpGAN by using a face matcher (veriÔ¨Åer) to compare offpose faces with a gallery of frontal faces and also compare the frontalized images with the gallery to see if frontalizing the face would increase the face matcher performance. The paper implements a coupled CNN (cpCNN) and includes experiments to evaluate the beneÔ¨Åts of using the GAN by comparing the performance of a cpCNN with our proposed approach (cpGAN). The paper implements an adversarial discriminative do main adaptation (ADDA) framework for proÔ¨Åle to frontal face recognition and includes experiments to compare the performance of our proposed cpGAN with an ADDA network. The paper includes generated qualitative results for the VGGFace2 dataset to test the robustness and reconstruc tion ability of our proposed coupled GAN framework. 2 R ELATED WORK "
381,Convex Bounds on the Softmax Function with Applications to Robustness Verification.txt,"The softmax function is a ubiquitous component at the output of neural
networks and increasingly in intermediate layers as well. This paper provides
convex lower bounds and concave upper bounds on the softmax function, which are
compatible with convex optimization formulations for characterizing neural
networks and other ML models. We derive bounds using both a natural
exponential-reciprocal decomposition of the softmax as well as an alternative
decomposition in terms of the log-sum-exp function. The new bounds are provably
and/or numerically tighter than linear bounds obtained in previous work on
robustness verification of transformers. As illustrations of the utility of the
bounds, we apply them to verification of transformers as well as of the
robustness of predictive uncertainty estimates of deep ensembles.","The softmax function is an indispensable component of multiclass classiÔ¨Åers ranging from multinomial logistic re gression models to deep neural networks (NNs). It is most often deployed at the output of a classiÔ¨Åer to con vertKrealvalued scores corresponding to Kclasses into a probability distribution over the classes. More recently, the softmax is playing an increasing role in intermedi ate layers as well with the popularization of Transform ers (Vaswani et al., 2017), whose quintessential compo nent, the (self)attention mechanism (Luong et al., 2015; Proceedings of the 26thInternational Conference on ArtiÔ¨Åcial Intelligence and Statistics (AISTATS) 2023, Valencia, Spain. PMLR: V olume 206. Copyright 2023 by the author(s).Gehring et al., 2017), utilizes softmax to compute attention scores. Our main contribution in this paper is to provide convex bounds on the softmax function. More precisely, we derive lower bounds on the outputs of the softmax that are convex functions of the inputs, and upper bounds on the outputs that are concave functions of the inputs (see (4) later). This enables the formulation of convex optimization problems for characterizing ML models with softmax components, particularly in intermediate layers. We apply our bounds to veriÔ¨Åcation of the robustness of NNs against adversarial input perturbations. We consider in particular the quantiÔ¨Åcation of predictive uncertainty for multiclass classiÔ¨Åers, which is typically assessed in terms of accurate estimation of the conditional probability distri bution. We are not aware of prior work that directly ad dresses the robustness of uncertainty estimation metrics, especially for deep ensembles (Lakshminarayanan et al., 2017; Rahaman and Thiery, 2021), although the works of Bitterwolf et al. (2020); Berrada et al. (2021) are related. Our results are summarized as follows. In Section 3, we Ô¨Årst consider an exponentialreciprocal decomposition of the softmax function, used by Shi et al. (2020); Bonaert et al. (2021) in robustness veriÔ¨Åcation of transformers. While Shi et al. (2020); Bonaert et al. (2021) limited them selves to linear bounds, we instead derive nonlinear con vex bounds (which we refer to as ‚ÄúER‚Äù) and show that these are tighter than the previous linear bounds (‚Äúlin‚Äù). We then consider in Section 4 an alternative decomposition in terms of the logsumexp (LSE) function, a wellknown convex function (Boyd et al., 2004), and obtain correspond ing bounds. We prove that the LSE upper bound is always tighter than the ER upper bound, and that the LSE lower bound is tighter than the ER lower bound for the case of K= 2 inputs. These analytical results are summarized by the following inequalities, where L(x)andU(x)denotearXiv:2303.01713v1  [cs.LG]  3 Mar 2023Convex Bounds on the Softmax Function for Robustness VeriÔ¨Åcation lower and upper bounds that are functions of the input x: Llin(x)LER(x)|{z} K=2LLSE(x)softmax(x) ULSE(x)UER(x)Ulin(x):(1) ForK > 2inputs, while there are instances where LER(x)> LLSE(x), our numerical experiment in Sec tion 6 suggests that this does not occur often and that in some regimes, LLSEis tighter by factors of 3or more in terms of the mean gap with respect to softmax(x). For the upper bounds, we Ô¨Ånd that UER(x)improves considerably uponUlin(x), which can be rather loose, and ULSE(x)con sistently improves upon UER(x)by a further factor of 2. In Section 7, we describe experiments on robustness veriÔ¨Åca tion of transformers and of uncertainty estimation by deep ensembles. The results provide further evidence of the hier archy in (1) and of the potential usefulness of the bounds. 1.1 Related Work "
15,A Review of Formal Methods applied to Machine Learning.txt,"We review state-of-the-art formal methods applied to the emerging field of
the verification of machine learning systems. Formal methods can provide
rigorous correctness guarantees on hardware and software systems. Thanks to the
availability of mature tools, their use is well established in the industry,
and in particular to check safety-critical applications as they undergo a
stringent certification process. As machine learning is becoming more popular,
machine-learned components are now considered for inclusion in critical
systems. This raises the question of their safety and their verification. Yet,
established formal methods are limited to classic, i.e. non machine-learned
software. Applying formal methods to verify systems that include machine
learning has only been considered recently and poses novel challenges in
soundness, precision, and scalability.
  We first recall established formal methods and their current use in an
exemplar safety-critical field, avionic software, with a focus on abstract
interpretation based techniques as they provide a high level of scalability.
This provides a golden standard and sets high expectations for machine learning
verification. We then provide a comprehensive and detailed review of the formal
methods developed so far for machine learning, highlighting their strengths and
limitations. The large majority of them verify trained neural networks and
employ either SMT, optimization, or abstract interpretation techniques. We also
discuss methods for support vector machines and decision tree ensembles, as
well as methods targeting training and data preparation, which are critical but
often neglected aspects of machine learning. Finally, we offer perspectives for
future research directions towards the formal verification of machine learning
systems.","Recent advances in artiÔ¨Åcial intelligence and machine learning and the availability of vast amounts of data allow us to develop computer software that efÔ¨Åciently and autonomously perform complex tasks that are difÔ¨Åcult or even impossible to design using traditional explicit programming (e.g., image classiÔ¨Åcation, speech recognition, etc.). This makes machinelearned software particularly attractive even in safety critical applications , as it enables performing a whole world of new functions that could not be envisioned before, e.g., autonomous driving in the automotive indus try, or imagebased operations (taxiing, takeoff, landing) and aircraft voice control in 1arXiv:2104.02466v2  [cs.PL]  21 Apr 2021the avionics industry. Another attractive aspect of machinelearned software is its ability to efÔ¨Åciently approximate or simulate complex processes and systems and au tomate decisionmaking, e.g., diagnosis and drug discovery processes in healthcare, or aircraft collision avoidance systems in avionics [90]. Safetycritical applications require an extremely high level of insurance that the software systems behave correctly and reliably. Today, formal methods are an integral part of the development process of traditional (non machinelearned) critical software system, to provide strong, mathematicallygrounded guarantees on the software be havior. For instance, they are used at an industrial level in avionics [146], where the development processes of aircraft software systems have very stringent assurance and veriÔ¨Åcation requirements mandated by international standards (i.e., DO178C). This success is due to the recognition of formal methods by certiÔ¨Åcation authorities and the availability of effective and efÔ¨Åcient veriÔ¨Åcation tools. Among formal veriÔ¨Åcation techniques, static analyzers are particularly successful as they are fully automated, efÔ¨Åcient, and correct by construction. A notable example is the Astr ¬¥ee static analyzer [13], used to ensure absence of runtime errors in critical avionics C code. In contrast, research in formal methods for the development and assurance of ma chine learning systems remains today extremely limited. It is however rapidly gaining interest and popularity, mostly driven by the growing needs of the automotive and avionics industries. The purpose of this document is to keep up with these devel opments and gain a better understanding of the research ecosystem that is forming around the veriÔ¨Åcation of machine learning software, and discuss further research directions. SpeciÔ¨Åcally, in the following, we give an introduction to formal meth ods (Section 2) with a particular focus on static analysis by abstract interpretation [37], as it offers a unifying theory for reasoning about disparate formal veriÔ¨Åcation approaches (Section 2.3). We then thoroughly overview the current state of the art in formal methods for machine learning (Section 3). We provide descriptions of the different underlying techniques and discuss and compare the scope of their applica tion and their advantages and disadvantages. Finally, we discuss perspectives and expectations for possible worthwhile future research directions (Section 4). 2 Formal Methods This section gives an informal overview of current formal methods for software veriÔ¨Å cation, notably abstract interpretation, and selected recent examples of applications on embedded safetycritical software. We refer to [40] for another short introduction to abstract interpretation and to [114] for a tutorial. 2.1 Overview of Formal Methods Formal methods are an array of techniques that employ logic and mathematics in order to provide rigorous guarantees about the correctness of computer software. The Ô¨Årst principled formal methods date back from the pioneering work of Floyd [68], Hoare [83] and Naur [121] on program logic in the late 60s, although similar ideas have been attested as far back as the late 40s with a notable work by Turing [158]. Early works describe such methods through penandpaper proofs of tiny programs in idealized languages. Developing and checking by hand the very large proofs that are required to verify realsized applications in realistic languages would be intractable. Hence, the last few decades have seen the development of software veriÔ¨Åcation tools. Keeping in mind the fundamental undecidability of correctness properties of pro grams as a consequence of Rice‚Äôs Theorem [133], it is in fact impossible to design a 2tool that can decide precisely for every program whether it is correct or not. Tools must abandon either full automation (thus requiring some manual assistance), gen erality (handling only a subset of programs), or completeness (sometimes reporting as incorrect a correct program, which we call a false alarm, or failing to terminate). In the rest of the section, we discuss the broad categories of computerassisted veriÔ¨Åca tion methods that have been subsequently proposed, and the tradeoffs they make to solve these issues in practice. These approaches also vary in the set of correctness properties that can be checked and how the programmer can express them. However, a requirement of all formal methods is that they should be sound , that is, any cor rectness property established by the tool is indeed true of the actual executions of the program. In practice, tools may only be sound for subsets of programming languages (e.g., not supporting the ‚Äúeval‚Äù construction), or for an idealized semantics (e.g., using reals instead of Ô¨Çoatingpoint numbers), or by making implicit assumptions that must be checked by other means (e.g., no aliasing between pointers passed to functions) [107]. A formal veriÔ¨Åcation tool must then make these limitations explicit and state clearly the formal guarantees that are expected despite the limitations. Deductive VeriÔ¨Åcation. Deductive methods stem directly from the work of Floyd, Hoare, and Naur [68, 83, 121]. The user provides a program and a formal speciÔ¨Å cation expressed in a logic language. The speciÔ¨Åcation is then propagated through the program source code, using symbolic execution as proposed by Burstall [23] or weakest preconditions as proposed by Dijkstra [51]. This generates automatically a set of veriÔ¨Åcation conditions implying that the program obeys its speciÔ¨Åcation. The conditions are then proved correct with the help of a solver, such as a fully automated SMT (satisÔ¨Åability modulo theory) solver (e.g., Z3 [49]). One beneÔ¨Åt of deductive veriÔ¨Åcation is its ability to handle complex speciÔ¨Åcations using decidable logical theories (reasoning about, e.g., integers, Ô¨Çoatingpoint num bers, pointers, arrays, recursive datastructures) and to perform modular veriÔ¨Åcation by breaking down the speciÔ¨Åcation into function contracts with preconditions and postconditions. However, automation is limited by the need to supplement the spec iÔ¨Åcation with additional annotations, notably loop variants and invariants, contracts for internal functions, and ghost variables so that the veriÔ¨Åcation conditions become tractable for the prover. The progress of solvers has made deductive veriÔ¨Åcation an attractive approach, but there is still the occasional need to help the solver through interactive proofs. Examples of current deductive veriÔ¨Åcation platforms include Why 3 [65], as well as FramaC [45] used to check industrial C software. Design by ReÔ¨Ånement. Design by reÔ¨Ånement is a related approach based on suc cessive reÔ¨Ånements of a sequence of state machines, from an abstract speciÔ¨Åcation up to an executable implementation. Each reÔ¨Ånement step is proven formally with the aid of an automated solver. This technique requires a large speciÔ¨Åcation effort and is suited to develop formally veriÔ¨Åed software from the ground up rather than verifying existing software. A popular instance of this technique is the B method [1]. Proof Assistants. Interactive proof assistants are generalpurpose tools able to pro duce reliable proofs of theorems, with application to mathematics, logic, and com puter science. Their strength lies in the use of very expressive logic and the ability to check every proof with a small trusted core, reducing the possibilities of errors. Although they can offer some degree of automation (e.g., through tactics), they em ploy undecidable logics and essentially rely on a very tight interaction between the programmer and the tool, which can prove time consuming. Unlike automated SMT 3solvers, the limit of what can be proved with proof assistants lies solely in the in genuity (and time and dedication) of the user. One popular proof assistant is Coq [12], which also acts as a programming language and is able to automatically extract an executable implementation from a constructive proof. Proof assistants have been applied to prove involved correctness properties on a few complex pieces of software, such as the CompCert certiÔ¨Åed C compiler [103]. In the case of CompCert, Coq was used to prove to equivalence between a source code and its compiled version (pro vided that the former is free of undeÔ¨Åned behavior), which is a very strong example of functional correctness result. Model Checking. In the 80s, Clarke and Emerson [33] and Queille and Sifakis [128] independently invented model checking, which checks speciÔ¨Åcations on Ô¨Ånitestate models of hardware or software systems by exhaustive exploration. It provides a sound, complete, and automatic veriÔ¨Åcation method on models. Early model check ing methods relied on explicit state representations, which suffer from combinatorial explosion and severely limit the size of the models considered. Symbolic model check ing [111] subsequently introduced more compact representations that also permit the veriÔ¨Åcation of some regular classes of inÔ¨Ånitestate models. The beneÔ¨Åts of model checking are achieving both soundness and completeness, the use of temporal logic [124] to express rich speciÔ¨Åcations (including termination and other liveness properties), and the ability to check concurrent models. Model checking has been particularly successful to check hardware systems (for instance at Intel [66]) which are inherently Ô¨Ånite. However, whenever the system to be checked is inÔ¨Ånitestate, or is simply too large, it is the responsibility of the user to provide a simpliÔ¨Åed model. Crafting a model that is both faithful and efÔ¨Åciently checked is a difÔ¨Åcult task. Even then, the soundness and completeness properties only hold with respect to the model, not the original system. More recently, software model checking has targeted the direct veriÔ¨Åcation of source code without requiring a handcrafted model, but several tradeoffs had to be made to sidestep the intractability of an exhaustive exploration of the state space. Bounded model checking [14] (e.g., the CBMC tool [35]) limits the exploration to exe cution traces of Ô¨Åxed length. The drawback of this method is that it loses soundness and completeness with respect to the full program; while it can uncover errors oc curring at the beginning of the execution of the program, it cannot prove the absence of errors. Counterexampleguided abstraction reÔ¨Ånement (CEGAR) [34] automatically extracts an abstract model from the source code based on a Ô¨Ånite set of predicates, which is then veriÔ¨Åed using modelchecking. If the correctness proof fails, the model checker extracts a counterexample which is used to reÔ¨Åne automatically the abstract model, and the process is iterated until the proof is established. The CEGAR method has been successfully used to check the correctness of Windows device drivers at Microsoft [6]. In certain cases, however, the reÔ¨Ånement process does not terminate. Semantic Static Analysis. Static program analyzers perform a direct and fully au tomated analysis of the source code of a program without executing it. In the broad sense, the term ‚Äústatic analysis‚Äù also includes syntactic style checkers (socalled ‚Äúlin ters‚Äù). We only focus here on semanticbased static analyzers that offer formal guar antees on the result of the analysis, i.e., they belong to the category of formal methods. To achieve full automation, termination, and scalability, static analyzers interpret programs at an abstract level, focusing only on the properties of interest. A classic method for static analysis is dataÔ¨Çow analysis, introduced in the 70s by Kildall [94]. This technique infers program properties by propagating abstract values 4from a Ô¨Åniteheight lattice of properties along the control Ô¨Çow of the program. The method is popular in compilers as it features very efÔ¨Åcient algorithms and can infer properties useful for optimization (constant propagation, live variable analysis, etc.). However, such properties are generally not expressive enough to support program veriÔ¨Åcation. More general analyzers can be constructed through abstract interpre tation, a theory of the approximation of program semantics introduced by Cousot and Cousot [37]. They are not limited to Ô¨Åniteheight abstractions and can, for in stance, infer variable bounds and relationships, handle dynamic memory allocation, etc. While less efÔ¨Åcient than dataÔ¨Çow analyses used in compiler, they always ter minate and remain relatively efÔ¨Åcient thanks to abstractions that ignore irrelevant (or too complex) details and perform approximations. They nevertheless guarantee soundness by erring on the safe side: they overapproximate the set of possible be haviors of programs when they cannot be modeled faithfully, so that any property inferred as true on the overapproximation is also true on the original program. The beneÔ¨Åt of static analysis by abstract interpretation is full automation, parameterized precision, and the ability to verify large programs in real languages at the source level (C, Java, etc.) or binary level. The analysis is however inherently incomplete, and can fail to verify a desired property due to overapproximations. Thus, it can output false alarms, that must be checked by other means. Static analyzers by abstract interpretation can perform wholeprogram analysis to prove nonfunctional properties, such as absence of runtime errors, that are implic itly speciÔ¨Åed by the language and embedded in the choice of abstraction. An example is the Astr ¬¥ee analyzer [13] for embedded C code, discussed in the next section. They can also perform a modular proof of userprovided contracts, as in CodeContracts [64], achieving a similar goal to deductive veriÔ¨Åcation but with full automation, by re moving the need to annotate the program with loop invariants or contracts for private functions. In each tool, the abstractions have been tailored to the class of proper ties to be veriÔ¨Åed. Compared to classic model checking and deductive methods, the effort has thus shifted from the user to the analysis designer. We discuss abstract interpretation in more details in Section 2.3. 2.2 Applications in Embedded Critical Software Formal methods have transitioned from academia to hardware and software indus tries, with many individual success stories (see [88] for a recent review). We present here an account, based on [146, 4], of its use on safetycritical embedded software in the avionics industry. It is a signiÔ¨Åcant example as this industry is an early adopter of formal methods due to the stringent safety requirements on software, although such methods have recently made their way into less critical industries such as Facebook [52]. Nevertheless, it provides a picture of a fully realized integration of these meth ods and also hints at the level of maturity expected from formal methods for artiÔ¨Åcial intelligence to become usable in safetycritical applications. As a critical aircraft component, avionic software is subject to certiÔ¨Åcation by certi Ô¨Åcation authorities and must obey the DO178 international standard, which notably describes the veriÔ¨Åcation process that such software must follow. Traditional meth ods consist in massive test campaigns and intellectual reviews, which have difÔ¨Åculties scaling up and maintaining a reasonable cost (which already accounts for more than half of the cost of overall software development). A shift occurred in the 2010s with the new DO178C revision (and its DO333 supplement) which opens the door to cer tiÔ¨Åcation by formal methods. One key aspect of the standard is the emphasis on employing sound formal methods . Another key aspect is that any veriÔ¨Åcation tech nique (formal or not) employed at the source level cannot be considered valid at the 5binary level unless the compilation process is also certiÔ¨Åed, which is important in practice as some tools can only reason at the source level. Classic certiÔ¨Åcation processes combine a variety of techniques (reviews, unit tests, integration tests, etc.). Likewise, when introducing formal methods into the veriÔ¨Åca tion process, Atki et al. [4] present an array of different tools and techniques that are currently used (or are considered in the future) to supplement or replace legacy tech niques with, as goal, to improve industrial efÔ¨Åciency while maintaining the requested safety and reliability level: ‚Ä¢ Deductive veriÔ¨Åcation with FramaC [45] is used to implement unit proofs of in dividual C functions of some software subsets. The article reports that 95% of the proof obligations are solved automatically by the SMT solver, and the remain ing part requires interactions with the prover. This activity can partially replace classic unit testing, with the additional beneÔ¨Åt of ensuring that the properties tested are fully formalized in a contract language. ‚Ä¢ The Astr ¬¥ee [13] abstract interpretationbased static analyzer is used to check for the absence of runtime errors as deÔ¨Åned by the C standard (integer and Ô¨Çoating point arithmetic errors, pointer or array access errors, invalid operations, etc.) as well as assertion failures. Astr ¬¥ee performs a wholeprogram analysis at the C source level, scaling to programs of a few million lines with very few false alarms. ‚Ä¢ The Fluctuat [48] abstract interpretationbased static analyzer is used to assess the numerical accuracy of Ô¨Çoatingpoint computations in C libraries of control programs. ‚Ä¢ The StackAnalyzer and aiT WCET abstract interpretationbased static analyz ers from AbsInt ( https://www.absint.com ) are used at the binary level on the compiled code in order to compute (overapproximations of) the worstcase exe cution time and the worstcase stack usage, and ensure that they do not exceed the allocated resources. ‚Ä¢ The CompCert certiÔ¨Åed compiler [103] is used to compile the C code into binary. This ensures that the compilation process does not introduce any error that was absent from the source. Note that, although the design of CompCert required a massive proof effort in Coq, its use by avionic software programmers does not require any effort at all. These tools are complementary. For instance, the unit proof of FramaC implicitly assumes the absence of invalid pointers, aliasing, or arithmetic overÔ¨Çows to optimize proof automation. Likewise, CompCert assumes that the C source has no undeÔ¨Åned behaviors and does not offer any guarantee otherwise. These properties are ensured by the wholeprogram analysis performed by Astr ¬¥ee. In return, CompCert ensures the equivalence of the source and binary code, hence, the properties that FramaC and Astr ¬¥ee validated on the C source can be assumed to hold on the binary code. We can conclude from the choice of formal methods reported in [4] that two desir able properties for formal veriÔ¨Åcation methods of safetycritical software are sound ness (including with respect to Ô¨Çoatingpoint computations) and automation . 2.3 Abstract Interpretation Abstract interpretation is a general theory of the approximation of program semantics introduced in the late 70s by Cousot and Cousot [37]. It provides mathematical tools to compare different semantics and prove crucial properties, such as soundness and completeness, and formalizes the notions of approximation and abstraction. 6Static Analysis by Abstract Interpretation. One important practical application of abstract interpretation is the design of static analyzers. It allows deriving, in a principled way, static analyzers from program semantics focusing on a desired pro gram property, ensuring soundness by construction. This is achieved by applying a sequence of abstractions until the semantics becomes effectively computable. (a)  (b)  (c) Figure 1: From Trace Semantics (a), to State Semantics (b), to Interval Semantics (c). The method starts with a concrete semantics providing a precise mathematical expression of program behaviors. A natural idea is to model a program execution as a discrete sequence of program states. The trace semantics of a program is then the set of all its possible execution traces. Figure 1a depicts, informally, the trace semantics of a program. A state is composed of the full snapshot of the memory (depicted here simply as the value of variable X) and a control location (depicted with different shapes and colors). A Ô¨Årst abstraction consists in collecting, at each location, the set of possible memory states, as depicted in Figure 1b. This state semantics forgets about the history of computation (i.e., which state appears before which state), and so, cannot be used to verify temporal properties. However, it is sufÔ¨Åcient (i.e., complete for) state reachability properties, such as the absence of runtime errors. A further abstraction, the interval semantics, overapproximates the set of values of Xat each control location with an interval. The beneÔ¨Åt is that an abstract memory state can be represented in a very compact way, as a pair of a lower and upper bound for Xinstead of a set of values. However, we cannot tell whether the values within these bounds are actually reachable or not and, to ensure that we cover all possible program behaviors, we must assume that all these values are possible. This is represented in Figure 1c. With this abstraction, we can no longer prove that Xnever takes the value 4. (a)  (b)  (c) Figure 2: Concrete Set of TwoDimensional Points (a), its Interval Abstraction (b), and its Polyhedral Abstraction (c). Figure 2 gives another example, abstracting a set of points in two dimensions rep resenting variables XandY. When using the interval abstraction independently on each variable we obtain, in Figure 2b, an interval with many spurious points (shown as hollow squares in the Ô¨Ågure). The original setbased semantics is undecidable if we assume an inÔ¨Ånite range for variable values and, at best, extremely costly to 7compute when assuming a Ô¨Ånite but realistically large range for variables (such as ["
249,"A Fine-tuned Wav2vec 2.0_HuBERT Benchmark For Speech Emotion Recognition, Speaker Verification and Spoken Language Understanding.txt","Speech self-supervised models such as wav2vec 2.0 and HuBERT are making
revolutionary progress in Automatic Speech Recognition (ASR). However, they
have not been totally proven to produce better performance on tasks other than
ASR. In this work, we explored partial fine-tuning and entire fine-tuning on
wav2vec 2.0 and HuBERT pre-trained models for three non-ASR speech tasks:
Speech Emotion Recognition, Speaker Verification and Spoken Language
Understanding. With simple proposed downstream frameworks, the best scores
reached 79.58% weighted accuracy on speaker-dependent setting and 73.01%
weighted accuracy on speaker-independent setting for Speech Emotion Recognition
on IEMOCAP, 2.36% equal error rate for Speaker Verification on VoxCeleb1,
89.38% accuracy for Intent Classification and 78.92% F1 for Slot Filling on
SLURP, showing the strength of fine-tuned wav2vec 2.0 and HuBERT on learning
prosodic, voice-print and semantic representations.","Nowadays, people are expecting less labeled data to train well generalized models for supervised tasks, since data labeling is a very time and moneyconsuming process. Furthermore, people have been attempting to Ô¨Ånd a powerful feature embedding that can assist the Ô¨Ånetuning and multitask training for downstream tasks. The appearance of selfsupervised learning meets the above two requirements exactly. In speech domain, excellent selfsupervised models are emerging [1, 2, 3, 4, 5, 6, 7, 8, 9], among which the most highperforming and the most widely used are wav2vec 2.0 [10] and HuBERT [11]. Many wav2vec 2.0/HuBERT pretrained models have also been published and this has greatly promoted their applications in the Ô¨Åeld of speech. Therefore, we chose wav2vec2.0 and HuBERT as our research objects in this work. The wav2vec 2.0 model architecture contains mainly three modules. A convolutional neural network (CNN) feature encoder encodes the raw waveform inputs into latent speech representations. Mask operations are applied before they are fed to the Transformer based contextualized encoder . Aquantization module is used to quantize the latent speech representations from the CNN encoder into a discretized embedding which is then used as the target. The objective is to optimize the contrastive loss, which enforces the model to identify the true quantized latent speech representations. HuBERT shares the same architecture as wav2vec 2.0. Instead of constructing a contrastive loss, HuBERT uses an ofÔ¨Çine clustering step to generate noisy labels for Masked Language Model pretrain ing. SpeciÔ¨Åcally, HuBERT consumes masked continuous speech features to predict predetermined cluster assignments. The predic tive loss is applied over the masked regions, forcing the model tolearn good highlevel representations of unmasked inputs in order to infer the targets of masked ones correctly. Wav2vec 2.0 and HuBERT outperformed all existing ASR mod els at that time, proving that they can construct a better verbal em bedding. However, speech also contains other important information such as emotion, speaker and semantics, for which the industry also has high expectations. In the Ô¨Åeld of Speech Emotion Recogni tion (SER ),Speaker VeriÔ¨Åcation (SV) and Spoken Language Un derstanding (SLU ), it is still vague whether selfsupervised mod els can produce better performance compared with traditional super vised models (spectral features + CNNbased feature extraction + RNN/Transformer based time series modeling) [12, 13, 14, 15, 16]. However, meaningful attempts have been made in some previous works, which we will introduce below. In SUPERB [17], the performance of different frozen self supervised encoders were benchmarked across a wide range of speech tasks. For SER, the HuBERT large model stood out from other selfsupervised encoders with 67.62% accuracy (ACC) on IEMOCAP [18]. For SV , the HuBERT base model obtained the best Equal Error Rate (EER) 5.11% on V oxCeleb1 [19]. SLU contains two separate subtasks: Intent ClassiÔ¨Åcation (IC) and Slot Filling (SF). The HuBERT large model achieved the best results on both IC and SF tasks with 98.76% ACC on Fluent Speech Commands dataset [20] and 89.81% F1 score on SNIPS [21] respectively. For SER, [22] combined the features from frozen wav2vec2.0 with other handcrafted prosodic features and then fed them into a 1dCNN for a deeper extraction. [23] explored wav2vec Ô¨Ånetuning strategies and 65.4% WA on IEMOCAP was achieved. For SV , [24, 25] both explored Ô¨Ånetuned wav2vec 2.0, [24] obtained 3.61% EER on V oxCeleb1, while [25] also obtained 1.91% EER on V oxCeleb1 by adding V oxCeleb2 into the training set. We notice that selfsupervised models were only used as frozen feature extractors in SUPERB and some other works. Believing that only by Ô¨Ånetuning can we show the real power of selfsupervised models, we explored the Ô¨Ånetuning of wav2vec2.0/HuBERT on three speech tasks and provided full Ô¨Ånetuning experiment de tails. Taking inspiration from [10] and [11], we added another Ô¨Ånetuning method by splitting a pretrained wav2vec 2.0/HuBERT model into two parts: the CNN feature encoder and the Transformer contextualized encoder. We froze the CNN feature encoder and only Ô¨Ånetuned the Transformer contextualized encoder. We then tested partially Ô¨Ånetuned wav2vec2.0/HuBERT pretrained models together with the entirely Ô¨Ånetuned ones with the following tasks below: ‚Ä¢ Speech Emotion Recognition on IEMOCAP ‚Ä¢ Speaker VeriÔ¨Åcation on V oxCeleb1 ‚Ä¢ Spoken Language Understanding on SLURP [26] The results show that our Ô¨Ånetuned models achieved excellent results on the three tasks, which further proves their strong capacarXiv:2111.02735v3  [cs.CL]  3 Oct 2022Fig. 1 . Partial Ô¨Ånetuning (left) and entire Ô¨Ånetuning (right) of wav2vec 2.0/HuBERT. ity on constructing problemagnostic representations. The code and Ô¨Ånetuned models for SER and SLU have been opensourced on SpeechBrain [27]1. 2. METHOD "
8,"Switch as a Verifier: Toward Scalable Data Plane Checking via Distributed, On-Device Verification.txt","Data plane verification (DPV) is important for finding network errors.
Current DPV tools employ a centralized architecture, where a server collects
the data planes of all devices and verifies them. Despite substantial efforts
on accelerating DPV, this centralized architecture is inherently unscalable. In
this paper, to tackle the scalability challenge of DPV, we circumvent the
scalability bottleneck of centralized design and design Coral, a distributed,
on-device DPV framework. The key insight of Coral is that DPV can be
transformed into a counting problem on a directed acyclic graph, which can be
naturally decomposed into lightweight tasks executed at network devices,
enabling scalability. Coral consists of (1) a declarative requirement
specification language, (2) a planner that employs a novel data structure DVNet
to systematically decompose global verification into on-device counting tasks,
and (3) a distributed verification (DV) protocol that specifies how on-device
verifiers communicate task results efficiently to collaboratively verify the
requirements. We implement a prototype of Coral. Extensive experiments with
real-world datasets (WAN/LAN/DC) show that Coral consistently achieves scalable
DPV under various networks and DPV scenarios, i.e., up to 1250 times speed up
in the scenario of burst update, and up to 202 times speed up on 80% quantile
of incremental verification, than state-of-the-art DPV tools, with little
overhead on commodity network devices.","Network errors such as forwarding loops, undesired black holes and waypoint violations are the outcome of various issues ( e.g., software bugs, faulty hardware, protocol miscon figurations, and oversight negligence). They can happen in all types of networks ( e.g., enterprise networks, wide area net works and data center networks), and have both disastrous financial and social consequences [ 1‚Äì5]. How to detect and prevent such errors efficiently is a fundamental challenge for the network community. A major advance for this problem has been network verification, which analyzes the control plane [ 6,11,13‚Äì15,26‚Äì28,30‚Äì32,40,59,64,68,71,78,84] If you are interested in learning more about Coral, please contact Qiao Xiang (xiangq27@gmail.com).and data plane [ 8,9,35,39,42,43,51,58,69,70,73,74,76, 77, 81, 83] of network devices to identify errors. There has been a long line of research on data plane verifi cation (DPV), because this approach can detect a wider range of network errors by checking the actual data plane at the network devices ( e.g., switch OS bugs). More specifically, ear lier tools analyzed a snapshot of the complete data plane of the network [ 8,9,42,49,51,58,69,70,73,74,76,77,81]; and more recent solutions focus on incremental verification ( i.e., verifying forwarding rule updates) [ 35,39,41,43,83]. State oftheart DPV tools (e.g., [ 83]) can achieve incremental verification times of tens of microseconds per rule update. Despite the substantial progress in accelerating DPV, exist ing tools employ a centralized architecture, which lacks the scalability needed for deployment in large networks. Specifi cally, they use a centralized server to collect the data plane from each network device and verify the requirement. Such a design requires a management network to provide reli able connections between the server and network devices, which is hard to build itself. Moreover, the server becomes the performance bottleneck and the single point of failure of DPV tools. To scale up DPV, Libra [ 81] partitions the data plane into disjoint packet spaces and uses MapReduce to achieve parallel verification in a cluster; Azure RCDC [ 39] partitions the data plane by device to verify the availability of all shortest paths with a higher level of parallelization in a cluster. However, both are still centralized designs with the limitations above, and RCDC can only verify that particular requirement. In this paper, we systematically tackle the important prob lem of how to scale the data plane verification to be appli cable in real, large networks. Not only can a scalable DPV tool quickly find network errors in large networks, it can also support novel services such as fast rollback and switch ing among multiple data planes [ 21,45,67], and data plane verification across administrative domains [22, 75]. To this end, instead of continuing to squeeze incremen tal performance improvements out of centralized DPV, we embrace a distributed design to circumvent the inherent scal ability bottleneck of centralized design. Azure [ 39] takes a first step along this direction by partitioning verification 1arXiv:2205.07808v3  [eess.SY]  30 Sep 2022Technical Report, January, 2022, Online Xiang et al. into local contracts of devices. It gives an interesting anal ogy between such local contracts and program verification using annotation with inductive loop invariants, but stops at designing communicationfree local contracts for the partic ular allshortestpath availability requirement and validating them in parallel on a centralized cluster. In contrast, we go beyond this point and show that for a wide range of require ments ( e.g., reachability, waypoint, multicast and anycast), with lightweight tasks running on commodity network de vices and limited communication among them, we can verify these requirements in a compositional way, achieving scal able data plane checkups in generic settings. To be concrete, we design Coral, a generic, distributed, ondevice DPV framework with a key insight: the problem of DPV can be transformed into a counting problem in a directed acyclic graph (DAG) representing all valid paths in the network; the latter can then be decomposed into small tasks at nodes on the DAG, which can be distributively exe cuted at corresponding network devices, enabling scalability. Figure 1 gives the architecture and basic workflow of Coral, which consists of three novel components: A declarative requirement specification language (¬ß3). This language abstracts a requirement as a tuple of packet space, ingress devices and behavior, where a behavior is a predicate on whether the paths of packets match a pattern specified in a regular expression. This design allows oper ators to flexibly specify common requirements studied by existing DPV tools ( e.g., reachability, blackhole free, way point and isolation), and more advanced, yet understudied requirements ( e.g., multicast, anycast, noredundantdelivery and allshortestpath availability). A verification planner (¬ß4). Given a requirement, the plan ner decides the tasks to be executed on devices to verify it. The core challenge is how to make these tasks lightweight, because commodity network devices have little computa tion power to spare. To this end, the planner first uses the requirement and the network topology to compute a novel data structure called DVNet , a DAG compactly representing all paths in the network that satisfies the path patterns in the requirement. It then transforms the DPV problem into a counting problem on DVNet . The latter can be solved by a re verse topological traversal along DVNet . In its turn, each node inDVNet takes as input the data plane of its corresponding device and the counting results of its downstream nodes to compute for different packets, how many copies of them can be delivered to the intended destinations along downstream paths in DVNet . This traversal can be naturally decomposed to ondevice counting tasks, one for each node in DVNet , and distributed to the corresponding network devices by the planner. We also design optimizations to compute the min imal counting information of each node in DVNet to send to its upstream neighbors, and prove that for requirements RequirementSpecificationLanguage(¬ß3)VerificationPlanner(¬ß4)OnDeviceVerifiers/DVProtocol(¬ß5) NetworkTopologyVerificationRequirement+ VerificationMessagesDVNetOnDeviceTasksFigure 1: The architecture and workflow of Coral. such as allshortestpath availability, their minimal counting information is an empty set, making the local contracts in RCDC [39] a special case of Coral. Ondevice verifiers equipped with a DV protocol (¬ß5). Ondevice verifiers execute the ondevice counting tasks specified by the planner, and share their results with neigh bor devices to collaboratively verify the requirements. In particular, we are inspired by vectorbased routing protocols [53,61] to design a DV protocol that specifies how neighbor ing ondevice verifiers communicate counting results in an efficient, correct way. Experiment results (¬ß7). We implement a prototype of Coral and will opensource it upon the publication of this paper. We evaluate it extensively using realworld datasets, in both testbed and simulations. Coral consistently outper forms stateoftheart DPV tools under various networks (WAN/LAN/DC) and DPV scenarios, i.e., up to 1250√óspeed up in the scenario of burst update, and up to 202√óspeed up on 80% quantile of incremental verification, with little over head on commodity network devices. Coral achieves scalable DPV for two reasons. First, by decomposing verification into lightweight tasks executed on devices, the performance of Coral achieves a scalability approximately linear to the net work diameter. Second, when a data plane update happens, only devices whose counting results may change need to incrementally update their results, and send them to needed neighbors incrementally. As such, its verification time can be substantially shortened in large networks. Updates from v2. Compared with the previous version, we have redone the incremental update experiment on the dat acenter topologies of the two data plane verification tools, APKeep and AP, and updated the experimental results here. The reasons are as follows. For APKeep, in our previous in cremental update experiment on datacenter topologies, we mistakenly used only 1000 rule updates, but 10000 for other tools. We correct this mistake to make the results fair and consistent, by using 10,000 rule updates in the experiments of APKeep. For the same experiments on the datacenter topolo gies of AP, we accidently misconfigured the rules in one switch, making the datasets inconsistent with other tools. 2Distributed, OnDevice Data Plane Verification Technical Report, January, 2022, Online 2 OVERVIEW This section introduces some key concepts in Coral, and illustrates its basic workflow using an example. 2.1 Basic Concepts Data plane model. For ease of exposition, given a network device, we model its data plane as a matchaction table. En tries in the table are ordered in descending priority. Each entry has a match field to match packets on packet headers (e.g., TCP/IP 5tuple) and an action field to process packets. Possible actions include modifying the headers of the packet and forwarding the packet to a group of nexthops [ 29,39]. An empty group means the action is to drop the packet. If an action forwards the packet to all nexthops in a nonempty group, we call it an ùê¥ùêøùêøtype action. If it forwards the packet to one of the nexthops in a nonempty group, we call it an ùê¥ùëÅùëå type action. Given an ùê¥ùëÅùëå type action, we do not as sume any knowledge on how the device selects one nexthop from the group. This is because this selection algorithm is vendorspecific, and sometimes a blackbox [29]. Packet traces and universes. Inspired by NetKAT [ 9], we introduce the concept of packet trace to record the state of a packet as it travels from device to device, and use it to define the network behavior of forwarding packets. When ùëùenters a network from an ingress device ùëÜ, apacket trace ofùëùis defined as a nonempty sequence of devices visited by ùëùuntil it is delivered to the destination device or dropped. However, due to ALLtype actions, a packet may not be limited to one packet trace each time it enters a network. For example, in Figure 2, Case 1, the network forwards ùëùalong a set of two traces{[ùëÜ,ùê¥,ùêµ,ùê∑],[ùëÜ,ùê¥,ùê∂]}becauseùê¥forwards ùëùto bothùêµandùê∂. We denote this set to be a universe of packetùëùfrom ingress ùëÜ. In addition, with the existence of ANYtype actions, a packet may traverse one of a number of different setsof packet traces (universes) each time it enters a network. For example, in Figure 2, if the action of ùêµis changed to ùëìùë§ùëë(ùê¥ùëÅùëå,{ùê∂,ùê∑}), whenùëùenters the network in different instances, the network may forward ùëùaccord ing to the universe {[ùëÜ,ùê¥,ùêµ,ùê∂],[ùëÜ,ùê¥,ùê∂]}or the universe {[ùëÜ,ùê¥,ùêµ,ùê∑],[ùëÜ,ùê¥,ùê∂]}, becauseùêµforwardsùëùto eitherùê∂or ùê∑. These universes (each being a set of traces) can be thought of as a ""multiverse""  should the packet enter the network multiple times, it may experience different fates each time. The notion of universes is a foundation of Coral. We are inspired by multipath consistency [ 28], a property where a packet is either accepted on all paths or dropped on all paths, but go beyond. In particular, for each requirement, we verify whether it is satisfied across all universes. 2.2 Workflow We demonstrate the basic workflow of Coral using an ex ample in Figure 3. We consider the network in Figure 3a and the following requirement: for all packets destined to MatchAction*fwd(ALL,{A})MatchAction*fwd(ALL,{B, C})MatchAction*droppSABCDMatchAction*fwd(ANY ,{C,D})MatchAction*fwd(ALL,{D})Case1:Case2:Figure 2: An example to demonstrate the data plane model, packet traces and universes. Case 1: ùëùhas 1 universe of 2 traces, [ùëÜ,ùê¥,ùêµ,ùê∑]and[ùëÜ,ùê¥,ùê∂]. Case 2:ùëù has 2 universes of 2 traces: {[ùëÜ,ùê¥,ùêµ,ùê∂],[ùëÜ,ùê¥,ùê∂]}and {[ùëÜ,ùê¥,ùêµ,ùê∑],[ùëÜ,ùê¥,ùê∂]}. 10.0.0.0/23, when they enter the network from ùëÜ, they must be able to reach ùê∑, the device with an external port reachable to 10.0.0.0/23, via a simple path passing ùëä. Coral verifies this requirement in three phases. 2.2.1 Requirement Specification. In Coral, operators spec ify verification requirements using a declarative language. A requirement is specified as a (ùëùùëéùëêùëòùëíùë° _ùë†ùëùùëéùëêùëí,ùëñùëõùëîùëüùëíùë†ùë† _ùë†ùëíùë°, ùëèùëí‚Ñéùëéùë£ùëñùëúùëü)tuple. The semantic means: for each packet ùëù inùëùùëéùëêùëòùëíùë° _ùë†ùëùùëéùëêùëí entering the network from any device in ùëñùëõùëîùëüùëíùë†ùë† _ùë†ùëíùë°, the traces of ùëùin all its universes must satisfy the constraint specified in ùëèùëí‚Ñéùëéùë£ùëñùëúùëü , which is specified as a tuple of a regular expression of valid paths ùëùùëéùë°‚Ñé _ùëíùë•ùëùand a match operator. Figure 3a gives the program of the example requirement, where loop_free is a shortcut in the language for a regular expression that accepts no path with a loop. It specifies that when any ùëùdestined to 10.0.0.0/23 enters from ùëÜ, at least 1 copy of it will be delivered to ùê∑along a simple path waypointing ùëä. 2.2.2 Verification Decomposition and Distribution. Given a requirement, Coral uses a planner to decide the tasks to be executed distributively on devices to verify it. The core challenge is how to make these ondevice tasks lightweight, because a network device typically runs multiple protocols (e.g., SNMP, OSPF and BGP) on a lowend CPU, with little computation power to spare. To this end, the Coral planner employs a data structure called DVNet to decompose the DPV problem into small ondevice verification tasks, and dis tribute them to ondevice verifiers for distributed execution. From requirement and topology to DVNet .The planner first leverages the automata theory [ 46] to take the product of the regular expression ùëùùëéùë°‚Ñé _ùëíùë•ùëùin the requirement and the topology, and get a DAG called DVNet . Similar to the logical topology in Merlin [ 62] and the product graph in Propane [ 16] and Contra [ 37], aDVNet compactly represents all paths in the topology that match the pattern ùëùùëéùë°‚Ñé _ùëíùë•ùëù. It is decided only by ùëùùëéùë°‚Ñé _ùëíùë•ùëùand the topology, and is inde pendent of the actual data plane of the network. Figure 3c gives the computed DVNet in our example. Note the devices in the network and the nodes in DVNet have a 1tomany mapping. For each node ùë¢inDVNet , we assign a 3Technical Report, January, 2022, Online Xiang et al. (dstIP=10.0.0.0/23,[S],(exist>=1,S.*W.*Dandloop_free))Requirement:allpacketsenteringthenetworkfromSwithadestinationIPin10.0.0.0/23mustbedeliveredtoDinasimplepathwaypointingW.Topology:10.0.0.0/23SABCDW (a)An example topology and requirement. MatchAction10.0.0.0/24fwd(ANY,{B,W})10.0.1.0/24fwd(ALL,{W})AMatchAction10.0.0.0/23fwd(ALL,{C})BMatchAction10.0.0.0/23fwd(ALL,{C})WMatchAction10.0.0.0/23fwd(ALL,{D})CMatchAction10.0.0.0/23fwd(ALL,{A})S (b)The network data plane. S1B1C2 B2C1W2D1W1W3A1[(P1,1)]P1:dstIP=10.0.0.0/23P2:dstIP=10.0.0.0/24P3:dstIP=10.0.1.0/24[(P1,0)][(P1,1)][(P1,0)][(P1,0)][(P1,1)][(P1,1)][(P1,1)][(P2,[0,1]),(P3,1)][(P2,[0,1]),(P3,1)][(P1,1)][(P1,1)][(P1,1)] [(P1,0)][‚Ä¶]:UpdatedcountingwhenBupdatesitsDPtoforwardP1toW. (c)TheDVNet and the counting process. Figure 3: An illustration example to demonstrate the workflow of Coral. unique identifier, which is a concatenation of ùë¢.ùëëùëíùë£ and an in teger. For example, device ùê∂in the network is mapped to two nodesùê∂1andùê∂2inDVNet , because the regular expression allows packets to reach ùê∑via[ùê∂,ùëä,ùê∑]or[ùëä,ùê∂,ùê∑]. Backward counting along DVNet .With DVNet , a DPV problem is transformed into a counting problem on DVNet : given a packet ùëù, can the network deliver a satisfactory number of copies ofùëùto the destination node along paths in the DVNet in each universe? In our example, the problem of verifying whether the data plane of the network (Figure 3b) satisfies the requirement is transformed to the problem of counting whether at least 1 copy of each ùëùdestined to 10.0.0.0/23 is delivered to ùê∑1in Figure 3c in all of ùëù‚Äôs universes. This counting problem can be solved by a centralized algorithm that traverses the nodes in DVNet in reverse topo logical order. At its turn, each node ùë¢takes as input (1) the data plane of ùë¢.ùëëùëíùë£ and (2) for different ùëùinùëùùëéùëêùëòùëíùë° _ùë†ùëùùëéùëêùëí , the number of copies that can be delivered from each of ùë¢‚Äôs downstream neighbors to the destination, along DVNet , by the network data plane, to compute the number of copies that can be delivered from ùë¢to the destination along DVNet by the network data plane. In the end, the source node of DVNet computes the final result of the counting problem. Figure 3c illustrates this algorithm. For simplicity, we use ùëÉ1,ùëÉ2,ùëÉ3to represent the packet spaces with destination IP prefixes of 10.0.0.0/23,10.0.0.0/24, and 10.0.1.0/24, respec tively. Note that ùëÉ2‚à©ùëÉ3=‚àÖandùëÉ1=ùëÉ2‚à™ùëÉ3. Eachùë¢in DVNet initializes a ùëùùëéùëêùëòùëíùë°ùë†ùëùùëéùëêùëí‚Ü¶‚Üíùëêùëúùë¢ùëõùë° mapping,(ùëÉ1,0), except forùê∑1that initializes the mapping as (ùëÉ1,1)(i.e., one copy of any packet in ùëÉ1will be sent to the correct external ports). Afterwards, we traverse all the nodes in DVNet in re verse topological order to update their mappings. Each node ùë¢checks the data plane of ùë¢.ùëëùëíùë£ to find the set of nexthop devicesùë¢.ùëëùëíùë£ will forward ùëÉ1to. If the action of forwarding to this nexthop set is of ùê¥ùêøùêøtype, the mapping at ùë¢can be updated by adding up the count of all downstream neigh bors ofùë¢whose corresponding device belongs to the set of nexthops of ùë¢.ùëëùëíùë£ for forwarding ùëÉ1. For example, node ùê∂1 updates its mapping to (ùëÉ1,1)because device ùê∂forwards toùê∑, but nodeùëä2‚Äôs mapping is still (ùëÉ1,0)becauseùëädoes not forward ùëÉ1toùê∑. Similarly, although ùëä1has two down stream neighbors ùê∂1anùê∑1, each with an updated mapping (ùëÉ1,1). At its turn, we update its mapping to (ùëÉ1,1)instead of(ùëÉ1,2), because device ùëäonly forwards ùëÉ1toùê∂, notùê∑. Given a node ùë¢inDVNet , if the action of forwarding is ofùê¥ùëÅùëå type, the count may vary at different universes. As such, we update the mapping at ùë¢to record distinct counts at different universes. Consider the mapping update at ùê¥1. ùê¥would forward ùëÉ2to eitherùêµorùëä. As such, in one uni verse where ùê¥forwardsùëÉ2toùêµ, the mapping at ùê¥1is(ùëÉ2,0), becauseùêµ1‚Äôs updated mapping is (ùëÉ1,0)andùëÉ2‚äÇùëÉ1. In the other universe where ùê¥forwardsùëÉ2toùëä, the mapping at ùê¥1 is(ùëÉ2,1)becauseùëä3‚Äôs updated mapping is (ùëÉ1,1). Therefore, the updated mapping for ùëÉ2atùê¥1is(ùëÉ2,[0,1]), indicating the different counts at different universes. In the end, the updated mapping of ùëÜ1[(ùëÉ2,[0,1]),(ùëÉ3,1)]reflects the final counting results, indicating that the data plane in Figure 3b does not satisfy the requirements in Figure 3b in all universes. In other words, the network data plane is erroneous. Counting decomposition and distribution. The central ized counting algorithm in DVNet allows a natural decompo sition into ondevice counting tasks to be executed distribu tively on network devices. Specifically, for each node ùë¢in DVNet , an ondevice counting task: (1) takes as input the data plane ofùë¢.ùëëùëíùë£ and the results of ondevice counting tasks of all downstream neighbors of ùë¢whose corresponding devices belong to the set of nexthop devices ùë¢.ùëëùëíùë£ forwards packets to; (2) computes the number of copies that can be delivered fromùë¢to the destination along DVNet , by the network data plane in each universe; and (3) sends the computed result to devices where its upstream neighbors in DVNet reside in. After the decomposition, the planner sends the ondevice counting task of each ùë¢, as well as the lists of ùë¢‚Äôs downstream and upstream neighbors, to device ùë¢.ùëëùëíùë£ . 2.2.3 Distributed, EventDriven Verification using DV Pro tocol. After receiving the tasks from the planner, ondevice verifiers execute them in a distributed, eventdriven way. When events ( e.g., rule update, link down and the arrival of 4Distributed, OnDevice Data Plane Verification Technical Report, January, 2022, Online reqs ::=req‚àó req ::=(ùëùùëéùëêùëòùëíùë° _ùë†ùëùùëéùëêùëí,ùëñùëõùëîùëüùëíùë†ùë† _ùë†ùëíùë°,ùëèùëí‚Ñéùëéùë£ùëñùëúùëü) ùëèùëí‚Ñéùëéùë£ùëñùëúùëü ::=(ùëöùëéùë°ùëê‚Ñé _ùëúùëù, ùëùùëéùë°‚Ñé _ùëíùë•ùëù)|notùëèùëí‚Ñéùëéùë£ùëñùëúùëü |ùëèùëí‚Ñéùëéùë£ùëñùëúùëü orùëèùëí‚Ñéùëéùë£ùëñùëúùëü |ùëèùëí‚Ñéùëéùë£ùëñùëúùëü andùëèùëí‚Ñéùëéùë£ùëñùëúùëü ùëùùëéùë°‚Ñé _ùëíùë•ùëù ::=regular expression over the set of devices ùëöùëéùë°ùëê‚Ñé _ùëúùëù ::=existùëêùëúùë¢ùëõùë° _ùëíùë•ùëù|equal ùëíùë•ùëñùë†ùë° _ùëíùë•ùëù ::= ==ùëÅ|>=ùëÅ|>ùëÅ|<=ùëÅ|<ùëÅ Figure 4: The basic abstract syntax of the Coral re quirement specification language. updated results from neighbor devices) happen, ondevice verifiers update the results of their tasks, and send them to neighbors if needed. We design a DV protocol that speci fies how ondevice verifiers incrementally update their on device tasks, as well as how they communicate task results, efficiently and correctly. Consider a scenario in Figure 3, where ùêµupdates its data plane to forward ùëÉ1toùëä, instead of to ùê∂. The changed map pings of different nodes are circled with boxes in Figure 3c. In this case, device ùêµlocally updates the task results of ùêµ1and ùêµ2to[(ùëÉ1,1)]and[(ùëÉ1,0)], respectively, and sends corre sponding updates to the devices of their upstream neighbors, i.e.,[(ùëÉ1,1)]sent toùê¥following the opposite of (ùê¥1,ùêµ1)and [(ùëÉ1,0)]sent toùëäfollowing the opposite of (ùëä3,ùêµ2). Upon receiving the update, ùëädoes not need to update its mapping for node ùëä3, becauseùëädoes not forward any packet toùêµ. As such,ùëädoes not need to send any update toùê¥along the opposite of (ùê¥1,ùëä3). In contrast, ùê¥needs to update its task result for node ùê¥1to[(ùëÉ1,1)]because (1) no matter whether ùê¥forwards packets in ùëÉ2toùêµorùëä, 1 copy of each packet will be sent to ùê∑, and (2)ùëÉ2‚à™ùëÉ3=ùëÉ1. After updating its local result, ùê¥sends the update to ùëÜalong the opposite of(ùëÜ1,ùê¥1). Finally,ùëÜupdates its local result for ùëÜ1 to[(ùëÉ1,1)],i.e., the requirement is satisfied after the update. 3 SPECIFICATION LANGUAGE Coral provides a declarative language for operators to specify verification requirements based on the concepts of traces and universes. Figure 4 gives its simplified grammar. Language overview. On a high level, a requirement is spec ified by a(ùëùùëéùëêùëòùëíùë° _ùë†ùëùùëéùëêùëí,ùëñùëõùëîùëüùëíùë†ùë† _ùë†ùëíùë°,ùëèùëí‚Ñéùëéùë£ùëñùëúùëü)tuple, with the semantic explained in ¬ß2.2.1. To specify behaviors, we use the building block of (ùëöùëéùë°ùëê‚Ñé _ùëúùëù,ùëùùëéùë°‚Ñé _ùëíùë•ùëù)entries. The basic syntax provides two ùëöùëéùë°ùëê‚Ñé _ùëúùëùoperators. One is exist ùëêùëúùë¢ùëõùë° _ùëíùë•ùëù, which requires that in each universe, the number of traces matching ùëùùëéùë°‚Ñé _ùëíùë•ùëù(a regular expression over the set of devices) satisfies ùëêùëúùë¢ùëõùë° _ùëíùë•ùëù. For example, exist >=1 specifies at least one trace should match ùëùùëéùë°‚Ñé _ùëíùë•ùëùin each universe, and can be used to express reachability require ments. The other operator is equal , which specifies an equiva lence behavior: the union of universes for each ùëùinùëùùëòùë°_ùë†ùëùùëéùëêùëífrom each ingress in ùëñùëõùëîùëüùëíùë†ùë† _ùë†ùëíùë°must be equal to the set of all possible paths that match ùëùùëéùë°‚Ñé _ùëíùë•ùëù[39]. Finally, behav iors can also be specified as conjunctions, disjunctions, and negations of these (ùëöùëéùë°ùëê‚Ñé _ùëúùëùùëñ,ùëùùëéùë°‚Ñé _ùëíùë•ùëù)pairs. These two operators can be used to form a wide range of requirements in data plane verification. Table 1 provides examples of requirements that can be specified and verified in Coral, and the corresponding specifications in the Coral language. For example, using existùëêùëúùë¢ùëõùë° _ùëíùë•ùëù, operators can express simpler requirements such as reachability, waypoint reachability, and loopfreeness, which are well studied by existing DPV tools [ 41‚Äì43,74,83], as well as more advanced requirements, such as multicast, anycast and noredundant delivery routing. Another example is a requirement given in Azure RCDC [ 39], which requires that all pairs of ToR devices should reach each other along a shortest path, and all ToRtoToR shortest paths should be available in the data plane. This can be formulated as an equal behavior on all shortest paths across all universes (row 9 in Table 1). Note that once a requirement is specified, Coral checks whether it is consistently satisfied across all universes. As such, the multipath consistency [ 28,49] is expressed sepa rately as reachability and isolation requirements. Convenience features. Coral builds and provides opera tors with a(ùëëùëíùë£ùëñùëêùëí,ùêºùëÉ _ùëùùëüùëíùëìùëñùë•)mapping for network de vices with external ports ( e.g., a ToR switch or a border router), where each tuple indicates that ùêºùëÉ_ùëùùëüùëíùëìùëñùë• can be reached via an external port of ùëëùëíùë£ùëñùëêùëí . If a requirement is submitted with inconsistencies between the destination IPs inùëùùëéùëêùëòùëíùë° _ùë†ùëùùëéùëêùëí and the end (destination) devices in its cor respondingùëùùëéùë°‚Ñé _ùëíùë•ùëù, Coral will raise an error for operators to update this requirement. The language provides syntax sugar to simplify the expres sion of requirements. For example, it allows users to specify a device set and provides device iterators. It provides shortcuts of behaviors, e.g.,loop_free for the loopfree requirement. It also provides a third ùëöùëéùë°ùëê‚Ñé _ùëúùëùcalled subset , which re quires for packet ùëùentering the network from ingress ùëÜ, the set of traces of ùëùin each universe is a nonempty sub set ofùëùùëéùë°‚Ñé _ùëíùë•ùëù. A behavior subsetùëùùëéùë°‚Ñé _ùëíùë•ùëùis a shortcut of(match >=1ùëùùëéùë°‚Ñé _ùëíùë•ùëù)and(match ==0.‚àóand(not ùëùùëéùë°‚Ñé _ùëíùë•ùëù)). We omit their details for the sake of simplicity. Expressiveness and limitation. Our language is expres sive in that it can specify all verification requirements studied in DPV literature, except for middlebox traversal symme try [49] (i.e.,ùëÜùê∑andùê∑ùëÜmust pass the same middlebox). In addition, although not studied in DPV literature, path node / linkdisjointness cannot be expressed using our language, either. To be precise, our language can express all ""single path"" requirements that compare the packet traces of one packet space with a regularexpression ùëùùëéùë°‚Ñé _ùëíùë•ùëù, but cannot specify ""multipath"" requirements that compare the packet 5Technical Report, January, 2022, Online Xiang et al. Requirements Coral specifications Reachability [28, 49, 52](ùëÉ,[ùëÜ],(exist>=1,ùëÜ.‚àóùê∑)) Isolation [28, 49, 52] (ùëÉ,[ùëÜ],(exist ==0,ùëÜ.‚àóùê∑)) Loopfreeness [52](ùëÉ,[ùëÜ],(exist == 0,.‚àóand not((notùëã)‚àó or((notùëã)‚àóùëã(notùëã)‚àó))and((notùëå)‚àó or((notùëå)‚àóùëå(notùëå)‚àó))...,)) Black hole freeness [52](ùëÉ,[ùëÜ],(exist ==0,.‚àóand notùëÜ.‚àóùê∑)) Waypoint reachability [41](ùëÉ,[ùëÜ],(exist>=1,ùëÜ.‚àóùëä.‚àóùê∑)) Reachability with limited path length [41](ùëÉ,[ùëÜ],(exist>=1,ùëÜùê∑|ùëÜ.ùê∑|ùëÜ..ùê∑)) Differentingress same reachability [43, 52](ùëÉ,[ùëã,ùëå],(exist>=1,ùëã.‚àóùê∑|ùëå.‚àóùê∑)) In/Crosspod allshortest path reachability [39](ùëÉ,[ùëÜ],(equal ,ùëÜ.ùê∑))/(ùëÉ,[ùëÜ],(equal , ùëÜ...ùê∑)) Nonredundant reachabil ity[Coral](ùëÉ,[ùëÜ],(exist ==1,ùëÜ.‚àóùê∑)) Mulicast [Coral] (ùëÉ,[ùëÜ],((exist>=1,ùëÜ.‚àóùê∑)and(ùëíùë•ùëñùë†ùë° >= 1,ùëÜ.‚àóùê∏))) Anycast [Coral] (ùëÉ,[ùëÜ],((exist>=1,ùëÜ.‚àóùê∑)and(exist == 0,ùëÜ.‚àóùê∏))or((exist == 0,ùëÜ.‚àóùê∑) and(exist ==1,ùëÜ.‚àóùê∏))) Table 1: Selected requirements and their Coral specifi cations. 01S2W3DŒ£\{D}Œ£\{W} Figure 5: The finite automata of ùëÜ.‚àóùëä.‚àóùê∑with an alpha betŒ£={ùëÜ,ùëä,ùê¥,ùêµ,ùê∂,ùê∑}. traces of two packet spaces. We discuss how to extend Coral to specify and verify such requirements in ¬ß6. 4 VERIFICATION PLANNER We now present the design details of the planner. For ease of presentation, we first introduce DVNet and how to use it for verification decomposition assuming a requirement has only one regular expression. We then describe how to handle requirements with more than one regular expressions. 4.1 DVNet Given a regular expression ùëùùëéùë°‚Ñé _ùëíùë•ùëùand a network, DVNet is a DAG compactly representing all paths in the network that matches ùëùùëéùë°‚Ñé _ùëíùë•ùëù. There are different ways to construct aDVNet (e.g., graph dual variables). In Coral, we are inspired by network synthesis [ 16,37,62], and leverage the automata theory [46] for DVNet construction. Specifically, given a ùëùùëéùë°‚Ñé _ùëíùë•ùëù, we first convert it into a finite automata(Œ£,ùëÑ,ùêπ,ùëû 0,ùõø).Œ£is the alphabet whose sym bols are network device identifiers. ùëÑis the set of states. ùëû0is the initial state. ùêπis the set of accepting states. ùõø:ùëÑ√óŒ£‚ÜíùëÑ is the state transition function. For example, for regular ex pressionùëÜ.‚àóùëä.‚àóùê∑with a network of devices ùëÜ,ùëä,ùê¥,ùêµ,ùê∂,ùê∑ , its corresponding finite automata is in Figure 5. After converting ùëùùëéùë°‚Ñé _ùëíùë•ùëùto a finite automata, the plan ner multiplies it with the topology. The multiplication yields aproduct graph ùê∫‚Ä≤=(ùëâ‚Ä≤,ùê∏‚Ä≤). Each node ùë¢‚ààùëâ‚Ä≤has an attributeùëëùëíùë£representing the identifier of a device in theAlgorithm 1: Count(DVNet,ùëù). 1Sort nodes in DVNet in reverse topological order: ùë¢1,...,ùë¢ ùëõ; 2foreachùë¢ùëñ,ùëñ=1,...,ùëõ do 3 ifùë¢ùëñis a destination then 4 cùëñ‚Üê1 5 else 6 foreachùë£ùëó‚ààùëÅùëë(ùë¢ùëñ)do 7 ifùë£ùëó.ùëëùëíùë£‚ààùë¢ùëñ.ùëëùëíùë£.ùëìùë§ùëë(ùëù)then 8 ùëèùëñ ùëó‚Üê1; 9 ifùë¢ùëñ.ùëëùëíùë£.ùëìùë§ùëë(ùëù).ùë°ùë¶ùëùùëí ==ùê¥ùêøùêø then 10 Update cùë¢with Equation (1); 11 else 12 Update cùë¢with Equation (2); 13return cùëõ; network and attribute ùë†ùë°ùëéùë°ùëí representing its state in the fi nite automata of ùëùùëéùë°‚Ñé _ùëíùë•ùëù. Given two nodes ùë¢,ùë£‚ààùëâ‚Ä≤, there exists a directed link (ùë¢,ùë£)‚ààùê∏‚Ä≤if (1)(ùë¢.ùëëùëíùë£,ùë£.ùëëùëíùë£)is a link in the network, and (2) ùõø(ùë¢.ùë†ùë°ùëéùë°ùëí,ùë£.ùëëùëíùë£)=ùë£.ùë†ùë°ùëéùë°ùëí . Finally, the planner performs state minimization on ùê∫‚Ä≤to remove redundant nodes, and assigns each remaining node ùë¢ a unique identifier (a concatenation of ùë¢.ùëëùëíùë£ and an integer), to get the DVNet . An example of DVNet was given in Figure 3. 4.2 Verification Decomposition The core insight of Coral is that we can transform DPV into a counting problem on DVNet , which can be naturally decomposed to small ondevice counting tasks running dis tributively. To be concrete, first consider a requirement on a packetùëùin the form of(existùëêùëúùë¢ùëõùë° _ùëíùë•ùëù,ùëùùëéùë°‚Ñé _ùëíùë•ùëù). We can verify it by counting whether the network can deliver a satisfactory number of copies of ùëùto the destination along paths in the DVNet in each universe. Such a problem can be solved by a traversal of nodes in DVNet in reverse topological order (Algorithm 1), during which each node ùë¢counts the number of copies of ùëùin allùëù‚Äôs universes that can reach the destination nodes of DVNet fromùë¢. Counting at nodes. Eachùë¢ùëñonly keeps unique counting results of different universes to avoid information explosion. Ifùë¢ùëñis a destination node in DVNet , its count is 1. Denote the downstream neighbors of ùë¢ùëñinDVNet asùëÅùëë(ùë¢ùëñ)={ùë£ùëó}ùëó, and their counting results as sets {cùë£ùëó}ùëó. Letùëèùëñùëó=1if the group of nexthops for ùëùonùë¢ùëñ.ùëëùëíùë£ includesùë£ùëó.ùëëùëíùë£, and 0 otherwise. Define ‚äóas the crossproduct sum operator for sets, i.e.,c1‚äóc2=(ùëé+ùëè|ùëé‚ààc1,ùëè‚ààc2). Ifùë¢ùëñ.ùëëùëíùë£‚Äôs forwarding action forùëùis of typeùê¥ùêøùêø,i.e., a copy ofùëùwill be forwarded to each nexthop in the rule, the count of ùëùatùë¢ùëñis, cùë¢ùëñ=‚äóùëó:ùëèùëñ ùëó=1(cùë£ùëó). (1) For example, in Figure 3c, for packets in ùëÉ1, the count at ùëä1 is[1], the result of ùê∂1, becauseùëäonly forwards ùëÉ1toùê∂, not other devices. 6Distributed, OnDevice Data Plane Verification Technical Report, January, 2022, Online Next, define‚äïas the union operator for sets. Let ùõø=1if ùë¢ùëñ.ùëëùëíùë£forwardsùëùto at least one device that does not have a corresponding node in ùëÅùëë(ùë¢ùëñ)inDVNet , and 0 otherwise. Ifùë¢ùëñ‚Äôs forwarding action for ùëùis of typeùê¥ùëÅùëå ,i.e.,ùëùwill be forwarded to one of the nexthops in the rule, the count of ùëù atùë¢ùëñis, cùë¢ùëñ=( ‚äïùëó:ùëèùëñ ùëó=1(cùë£ùëó), ifùõø=0, (‚äïùëó:ùëèùëñ ùëó=1(cùë£ùëó))‚äï0,ifùõø=1.(2) Still in Figure 3c, for packets in ùëÉ2, the count at ùê¥1is[0,1], the union of[0]fromùêµ1and[1]fromùëä3becauseùê¥1‚Äôs deviceùê¥forwards packets in ùëÉ2to eitherùêµorùëä. We give a proof sketch of Algorithm 1‚Äôs correctness in Appendix A.1. Distributed counting. Algorithm 1 can be naturally decom posed to small counting tasks, one for each node ùë¢inDVNet , to enable distributed counting. The planner sends the task ofùë¢toùë¢.ùëëùëíùë£ , with the lists of downstream and upstream neighbors of ùë¢.ùë¢.ùëëùëíùë£ receives the counts from ùë£ùëó.ùëëùëíùë£, where ùë£ùëó‚ààùëÅùëë(ùë¢), computes cùë¢using Equations (1)(2), and sends cùë¢ to the corresponding devices of all ùë¢‚Äôs upstream neighbors in DVNet . In the end, the counts at source node of DVNet (e.g., cùëÜ1atùëÜ1in Figure 3c) is the numbers of copies of ùëùdelivered to the destination of DVNet in allùëù‚Äôs universes. The device of the source node can then easily verify the requirement. Optimizing counting result propagation. When there are a huge number of paths in DVNet , the counting result set cùë¢can be large due to ùê¥ùëÅùëå type actions at devices ( e.g., a chained diamond topology). Letting ùë¢.ùëëùëíùë£ send the complete cùë¢to the devices of ùë¢‚Äôs upstream neighbors may result in large communication and computation overhead at devices. Given a requirement, we define the minimal counting infor mation of each node ùë¢as the minimal set of elements in cùë¢ that needs sending to its upstream nodes so that the source node in DVNet can correctly verify the requirement, assum ing arbitrary data planes at devices. We design optimizations to find such minimal counting information for requirements with existùëêùëúùë¢ùëõùë° _ùëíùë•ùëùandequal operations, respectively. Forexistùëêùëúùë¢ùëõùë° _ùëíùë•ùëùoperation, our optimization is based on the monotonicity of‚äó. Suppose two sets c1,c2whose elements are all nonnegative. For any ùë•‚ààc1andùë¶‚ààc2, ùëé=ùë•+ùë¶‚ààc1‚äóc2satisfiesùëé‚â•ùë•andùëé‚â•ùë¶. We then have: Proposition 1.Given a requirement with existùëêùëúùë¢ùëõùë° _ùëíùë•ùëù operation, the minimal counting information of node ùë¢is ùëöùëñùëõ(cùë¢)(ùëöùëéùë•(cùë¢)) ifùëêùëúùë¢ùëõùë° _ùëíùë•ùëùis‚â•ùëÅor>ùëÅ(‚â§ùëÅor<ùëÅ), and the first ùëöùëñùëõ(|cùë¢|,2)smallest elements in cùë¢ifùëêùëúùë¢ùëõùë° _ùëíùë•ùëù is==ùëÅ. The proof is in Appendix A.2. For a requirement with an equal operator, we prove that the minimal counting information of any ùë¢is‚àÖ, making dis tributed verification become local verification. Specifically, no nodeùë¢even needs to compute cùë¢. Instead, it only needs to check ifùë¢.ùëëùëíùë£ forwards any packet specified in the require ment to all the devices corresponding to the downstream SDEPMatchActionPfwd(ANY ,{D,E})(a)A network for anycast. E1D1S1[P ,(S.*D, 1)][P ,(S.*E, 0)][P ,(S.*D, 0)][P ,(S.*E, 1)] (b)The correct DVNet and count ing. Figure 6: Verifying an anycast, a requirement with multipleùëùùëéùë°‚Ñé_ùëíùë•ùëùwith different destinations. neighbors of ùë¢inDVNet . If not, a network error is identified, andùë¢.ùëëùëíùë£ can immediately report it to the operators. This op timization achieves local verification on generic equivalence requirements, making the local contracts on allshortestpath availability in Azure RCDC [39] a special case. Computing consistent counting results. Counting tasks are eventdriven. Given a task for ùë¢, when an event ( e.g., a rule update or a physical port down at ùë¢.ùëëùëíùë£ , or a count update received from the device of a downstream neighbor ofùë¢),ùë¢.ùëëùëíùë£ updates the counting result for ùë¢, and sends it to the devices of ùë¢‚Äôs upstream neighbors if the result changes. As such, assuming the network becomes stable at some point, the device of source node of DVNet will eventually update its count result to be consistent with the network data plane. Updating tasks. The process of the planner decomposing requirement to count tasks and sending to devices is similar to configuring routing protocols. After the planner sends the tasks to devices, the ondevice verifiers run independently without the need of the planner. Only when the planner receives a new requirement, or the topology is changed by administrator ( e.g., adding a link), the planner will update the tasks by regenerating DVNet , and send them to the devices. 4.3 Compound requirements We now describe how the planner decides the ondevice counting tasks for a requirement with multiple ùëùùëéùë°‚Ñé _ùëíùë•ùëùs. We focus on requirements with a logic combination of multi ple(existùëêùëúùë¢ùëõùë° _ùëíùë•ùëù,ùëùùëéùë°‚Ñé _ùëíùë•ùëù)pairs, because equal opera tor can be verified locally. In particular, the case where a com pound requirement with ùëùùëéùë°‚Ñé _ùëíùë•ùëùs with different sources can be handled by adding a virtual source device connecting to all the sources. As such, we divide compound requirements based on the destinations of regular expressions. Regular expressions with different destinations. One may think a natural solution is to build a DVNet for each ùëùùëéùë°‚Ñé _ùëíùë•ùëù, let devices count along all DVNet s, and cross produce the results at the source. However, this is incor rect. Consider an anycast requirement for ùëÜto reachùê∑or ùê∏, but not both (Figure 6a). This requirement is satisfied in the network. However, if we build two DVNet s, one for each destination, we get two chains ùëÜ1‚Üíùê∑1, andùëÜ2‚Üíùê∏1. After 7Technical Report, January, 2022, Online Xiang et al. counting on both DVNet s,ùëÜ1gets a set[0,1]for reaching ùê∑1, andùëÜ2gets[0,1]for reaching ùê∏1. The crossproduct computed by device ùëÜwould be[(0,0),(0,1),(0,1),(1,1)], raising a false positive of network error. To address this issue, for a requirement with multiple (existùëêùëúùë¢ùëõùë° _ùëíùë•ùëù, ùëùùëéùë°‚Ñé _ùëíùë•ùëù)pairs where ùëùùëéùë°‚Ñé _ùëíùë•ùëùs have different destinations, we let the planner construct a single DVNet representing all paths in the network that match at least oneùëùùëéùë°‚Ñé _ùëíùë•ùëù, by multiplying the union of all regular expressions with the topology, and specify one counting task for one regular expression, at all nodes in DVNet , including all destination nodes. Consider the same anycast example. The planner computes one DVNet in Figure 6b. Each node counts the number of packets reaching both ùê∑andùê∏. The count ofùê∑1is[(ùëÜ.‚àóùê∑,1),(ùëÜ.‚àóùê∏,0)]andùê∏1is[(ùëÜ.‚àóùê∑,0),(ùëÜ.‚àóùê∏,1)]. Such results are sent to ùëÜ1. AfterùëÜ1processes it using Equa tion (2), it determines that in each universe, a packet is sent toùê∑orùê∏, but not both, i.e., the requirement is satisfied. Regular expressions with the same destination. Follow ing the design for the case of different destinations, one may be tempted to handle this case by also constructing a single DVNet for the union of such ùëùùëéùë°‚Ñé _ùëíùë•ùëùs. However, because theseùëùùëéùë°‚Ñé _ùëíùë•ùëùs have the same destination, the counting along DVNet cannot differentiate the counts for different ùëùùëéùë°‚Ñé _ùë†ùëíùë°s, unless the information of paths are collected and sent along with the counting results. This would lead to large communication and computation overhead across devices. Another strawman is to construct one DVNet for one reg ular expression, count separately and aggregate the result at the source via crossproducing. However, false positives again can arise. Consider Figure 7a and the requirement (ùëÉ,[ùëÜ],(exist>=2,(ùëÜ.‚àóùê∑and loop _free) or(exist>=1,ùëÜ.‚àóùëä.‚àóùê∑and loop _free))),(3) which specifies at least two copies of each packet in ùëÉshould be sent toùê∑along a loopfree path, or at least one copy should be sent to ùê∑along a loopfree path passing ùëä. We observe that the data plane satisfies this requirement. How ever, suppose we construct a DVNet for eachùëùùëéùë°‚Ñé _ùëíùë•ùëù, and perform counting separately. ùëÜwill receive a counting result [1,2]for reaching ùê∑with a simple path, and a counting re sult[0,1]for reaching ùê∑with a simple path passing ùëä. The crossproduct results [(1,0),(1,1),(2,0),(2,1)]indicate that a phantom violation is found. To address issue, we handle this requirement by adding vir tual destination devices. Suppose a requirement has ùëö(exist ùëêùëúùë¢ùëõùë° _ùëíùë•ùëùùëñ, ùëùùëéùë°‚Ñé _ùëíùë•ùëùùëñ)pairs where ùëùùëéùë°‚Ñé _ùëíùë•ùëùùëñs have the same destination ùê∑. The planner changes ùê∑toùê∑1and adds ùëö‚àí1virtual devices ùê∑ùëñ(ùëñ=2,...,ùëö ). Eachùê∑ùëñhas the same set of neighbors as ùê∑does, in the network topology. It then rewrites the destination of ùëùùëéùë°‚Ñé _ùëíùë•ùëùùëñtoùê∑ùëñ(ùëñ=1,...,ùëö ). MatchActionPfwd(ALL,{D})MatchActionPfwd(ANY ,{A, W})MatchActionPfwd(ALL,{BÔºåD})PBSAWDMatchActionPfwd(ALL,{D})ABWS(a)A network and its data plane. PBSAWD1D2 (b)The updated topology with virtual destinations. Figure 7: Verifying Equation (3), a requirement with multipleùëùùëéùë°‚Ñé_ùëíùë•ùëùs with the same destination. Figure 7b gives the updated topology of Figure 7a to handle the requirement in Equation (3). Afterwards, the planner takes the union of all ùëùùëéùë°‚Ñé _ùëíùë•ùëùs, intersects it with an auxiliary ùëùùëéùë°‚Ñé _ùëíùë•ùëùspecifying no any twoùê∑ùëñ,ùê∑ùëóshould coexist in a path. It then multiplies the resulting regular expression with the new topology to gener ate one single DVNet . Counting can then proceed as the case for regular expressions with different destinations, by letting each device treat all its actions forwarding to ùê∑as forwarding toallùê∑ùëñs, and adjust Equations (1)(2) accordingly. 5 DV PROTOCOL This section presents the details of the DV protocol. While the planner specifies the ondevice tasks, the DV protocol specifies how ondevice verifiers share their counting results with neighbors in an efficient, correct way, to collaboratively verify a requirement. For ease of presentation, we introduce the protocol assuming a single destination in DVNet . Given link(ùë¢,ùë£)inDVNet , the DV protocol specifies the format and order of messages ùë£.ùëëùëíùë£ needs to send to ùë¢.ùëëùëíùë£ , and the actions ùë¢.ùëëùëíùë£ needs to take when receiving the mes sages. The DV protocol design is inspired by vectorbased routing protocols ( e.g., RIP [ 53] and BGP [ 61]). One distinc tion is that it needs no loopprevention mechanism. This is because the messages are sent along the reverse direction in the DAG DVNet . As a result, no message loop will be formed. 5.1 Information Storage Each device stores two types of information: LEC (local equiv alence class) and CIB (counting information base). Given a deviceùëã, an LEC is a set of packets whose actions are identi cal atùëã.ùëãstores its LECs in a table of (ùëùùëéùëêùëòùëíùë° _ùë†ùëùùëéùëêùëí,ùëéùëêùë°ùëñùëúùëõ) mapping called the LEC table. Multiple existing DPV tools can be used to compute and maintain the LEC table. In our implementation, we choose to encode the packet sets as predicates using Binary Decision Diagram (BDD [ 19]), and use BDDbased DPV tools [ 74,83] to maintain a table of a minimal number of LECs at devices. This is because the DV protocol requires devices to perform packet set opera tions ( e.g., intersection and union), which can be realized efficiently using logical operations on BDD. Given a device ùëã, CIB stores for each ùëã.ùëõùëúùëëùëí inDVNet (i.e., nodes with a device ID ùëã), for different packet sets, the number of packet copies that can reach from ùëã.ùëõùëúùëëùëí to the 8Distributed, OnDevice Data Plane Verification Technical Report, January, 2022, Online vzu[P1,1][P1,1] predicateactionP1fwd(ALL,{z.dev,v.dev})LECTablepredicatecountactioncausalityP12fwd(ALL,{z.dev,v.dev})([v,P1,1],[z,P1,1])LocCIB(u)predicatecountP11CIBIn(v)predicatecountP11CIBIn(z) (a)ADVNet with LEC table of ùë¢.ùëëùëíùë£ ,ùê∂ùêºùêµùêºùëõ andùêøùëúùëêùê∂ùêºùêµ ofùë¢. withdrawn predicates P1 incoming counting results Predicate count P2 1 P3 0predicate count action causality P2 2fwd(ALL, {z.dev ,v.dev })([z,P1,1], [v,P2,1]) P3 1fwd(ALL, {z.dev ,v.dev })([z,P1,1], [v,P3,0])LocCIB (u) Message(v) predicate count P2 1 P3 0CIBIn (v) P1 = P2 ‚à™ P3(b)ùë¢.ùëëùëíùë£ handles an UPDATE from ùë£.ùëëùëíùë£ to updateùê∂ùêºùêµùêºùëõ(ùë£)andùêøùëúùëêùê∂ùêºùêµ(ùë¢). Figure 8: An illustration example to demonstrate the key data structure and process of the DV protocol. destination node in DVNet . Specifically, for each ùëã.ùëõùëúùëëùëí ,ùëã stores three distinct types of CIB: ‚Ä¢ùê∂ùêºùêµùêºùëõ(ùë£)for each of ùëã.ùëõùëúùëëùëí ‚Äôs downstream neighbors ùë£: it stores the latest, unprocessed counting results received fromùë£in a(ùëùùëüùëíùëëùëñùëêùëéùë°ùëí,ùëêùëúùë¢ùëõùë°)mapping; ‚Ä¢ùêøùëúùëêùê∂ùêºùêµ(ùëã.ùëõùëúùëëùëí): it stores for different predicates, the lat est number of packet copies that can reach from ùëã.ùëõùëúùëëùëí to the destination node in (ùëùùëüùëíùëëùëñùëêùëéùë°ùëí,ùëêùëúùë¢ùëõùë°,ùëéùëêùë°ùëñùëúùëõ,ùëêùëéùë¢ùë†ùëéùëôùëñùë°ùë¶ ) tuples, where the ùëêùëéùë¢ùë†ùëéùëôùëñùë°ùë¶ field records the input to get theùëêùëúùë¢ùëõùë° field ( i.e., the right hand side of Equations (1)(2)); ‚Ä¢ùê∂ùêºùêµùëÇùë¢ùë°(ùëã.ùëõùëúùëëùëí): it stores the counting results to be sent to the upstream nodes of ùëã.ùëõùëúùëëùëí in(ùëùùëüùëíùëëùëñùëêùëéùë°ùëí,ùëêùëúùë¢ùëõùë°)tu ples. Figure 8a gives an example DVNet , with the counts of node ùë£,ùëß, the LEC table of ùë¢.ùëëùëíùë£ , andùê∂ùêºùêµùêºùëõ(ùë£),ùê∂ùêºùêµùêºùëõ(ùëß)and ùêøùëúùëêùê∂ùêºùêµ(ùë¢)at nodeùë¢. Specifically, the ùëêùëéùë¢ùë†ùëéùëôùëñùë°ùë¶ field is([ùë£,ùëÉ 1, 1],[ùëß,ùëÉ 1,1])because the ùëêùëúùë¢ùëõùë° 2 of predicate ùëÉ1is computed via the results of both ùë£andùëß(i.e.,2=1+1). 5.2 Message Format and Handling Messages in the DV protocol are sent over TCP connec tions. The protocol defines control messages ( e.g., OPEN and KEEPALIVE) to manage the connections between devices. We focus on the UPDATE message, which is used to transfer counting results from the device of a node to the devices of its upstream neighbors in DVNet . UPDATE message format. An UPDATE message includes three fields: (1) intended link: a tuple indicating along which link in DVNet the counting result is propagated oppositely; (2) withdrawn predicates: a list of predicates whose counting results are obsolete; and (3) incoming counting results: a list of predicates with their latest counts. The intended link is to differentiate links in DVNet with the same pair of devices (e.g.,(ùëä1,ùê∂1)and(ùëä3,ùê∂1)in Figure 3c). UPDATE message invariant. For the withdrawn predi cates and incoming counting results, the DV protocol main tains an important invariant: for each UPDATE message, the union of the withdrawn predicates equals the union of the predicates in the incoming counting results. This ensures that a node always receives the latest, complete counting results from its downstream neighbors, guaranteeing theeventual consistency between the verification result at the device of source node of DVNet and a stable data plane. UPDATE message handling. Consider link(ùë¢,ùë£)inDVNet . Supposeùë¢.ùëëùëíùë£ receives from ùë£.ùëëùëíùë£ an UPDATE message whose intended link is (ùë¢,ùë£).ùë¢.ùëëùëíùë£ handles it in three steps. Step 1: updating ùê∂ùêºùêµùêºùëõ(ùë£).ùë¢.ùëëùëíùë£ updatesùê∂ùêºùêµùêºùëõ(ùë£)by re moving entries whose predicates belong to withdrawn pred icates and inserting all entries in incoming counting results. Step 2: updating ùêøùëúùëêùê∂ùêºùêµ(ùë¢).To updateùêøùëúùëêùê∂ùêºùêµ(ùë¢),ùë¢.ùëëùëíùë£ first finds all affected entries, i.e., the ones that need to be updated. To be concrete, an entry in ùêøùëúùëêùê∂ùêºùêµ(ùë¢)needs to be updated if its ùëêùëéùë¢ùë†ùëéùëôùëñùë°ùë¶ field has one predicate from ùë£and belongs to the withdrawn predicates of this message. It then updates the counting results of all affected entries one by one. Specifically, for each pair of an affected entry ùëüand an entryùëü‚Ä≤from the incoming counting results, ùë¢.ùëëùëíùë£ computes the intersection of their predicates. If the intersection is not empty, a new entry ùëüùëõùëíùë§is created in ùêøùëúùëêùê∂ùêºùêµ(ùë¢)for predicateùëü.ùëùùëüùëíùëë‚à©ùëü‚Ä≤.ùëùùëüùëíùëë . Theùëêùëúùë¢ùëõùë° ofùëüùëõùëíùë§is computed in two steps: (1) perform an inverse operation of ‚äóor‚äïbetween ùëü.ùëêùëúùë¢ùëõùë° andùë£‚Äôs previous counting result in ùëü.ùëêùëéùë¢ùë†ùëéùëôùëñùë°ùë¶ , to remove the impact of the latter; and (2) perform ‚äóor‚äï between the result from the last step and ùëü‚Ä≤.ùëêùëúùë¢ùëõùë° to get the latest counting result. The ùëéùëêùë°ùëñùëúùëõ field is the same as ùëü. The ùëêùëéùë¢ùë†ùëéùëôùëñùë°ùë¶ of this entry inherits from that of ùëü, with tuple (ùë£,ùëü‚Ä≤)replacingùë£‚Äôs previous record. After computing and inserting all new entries, all affected entries are removed fromùêøùëúùëêùê∂ùêºùêµ(ùë¢). Figure 8b shows how ùë¢in Figure 8a processes an UPDATE message from ùë£.ùëëùëíùë£ to update its ùê∂ùêºùêµùêºùëõ(ùë£)andùêøùëúùëêùê∂ùêºùêµ(ùë¢). Step 3: updating ùê∂ùêºùêµùëÇùë¢ùë°(ùë¢).ùë¢.ùëëùëíùë£ puts the predicates of all entries removed from ùêøùëúùëêùê∂ùêºùêµ(ùë¢)in the withdrawn pred icates. For all inserted entries of ùêøùëúùëêùê∂ùêºùêµ(ùë¢), it strips the ùëéùëêùë°ùëñùëúùëõ andùëêùëéùë¢ùë†ùëéùëôùëñùë°ùë¶ fields, merges entries with the same ùëêùëúùë¢ùëõùë° value, and puts the results in the incoming counting results. After processing the UPDATE message, for each upstream neighborùë§ofùë¢,ùë¢.ùëëùëíùë£ sends an UPDATE messaging consist ing of an intended link (ùë§,ùë¢)andùê∂ùêºùêµùëÇùë¢ùë°(ùë¢). 9Technical Report, January, 2022, Online Xiang et al. Internal event handling. Ifùë¢.ùëëùëíùë£ has an internal event (e.g., rule update or link down), we handle it similar to han dling an UPDATE message. For example, if a link is down, we consider predicates forwarded to that link update their counts to 0. Specifically, the predicates whose forwarding ac tions are changed by the event are considered as withdrawn predicates and the predicates in incoming count results of an UPDATE message. Different from handling regular UP DATE messages, no ùê∂ùêºùêµùêºùëõ(ùë£)needs updating. The counts of newly inserted entries in ùêøùëúùëêùê∂ùêºùêµ(ùë¢)are computed by invert ing‚äó/‚äïand reading related entries in different ùê∂ùêºùêµùêºùëõ(ùë£)s. Only predicates with new counts are included as withdrawn predicates and incoming counting results in ùê∂ùêºùêµùëÇùë¢ùë°(ùë¢). Outbound UPDATE message suppression. Multiple rule updates may occur in a short time during a network event (e.g., a configuration update). Verifying the transient DP may not be necessary, and waste computation and communication resources. As such, the DV protocol provides an optional dampening mechanism: after ùë¢.ùëëùëíùë£ finishes processing an UPDATE message, before sending any UPDATE messages, it first checks if it still has unprocessed UPDATE messages with an intended link from ùë¢or internal events. If so, it continues processing them until no one is left unprocessed, and sends the latestùê∂ùêºùêµùëÇùë¢ùë°(ùë¢)in one UPDATE message. 6 EXTENSIONS Packet transformations. For data planes with packet trans formations, Coral uses BDD to encode such actions [ 77], and extends the CIB and the DV UPDATE message to record and share the count results of packet transformation actions. Large networks with a huge number of valid paths. One concern is that DVNet may be too large to generate in large networks with a huge number of valid paths. First, our survey and private conversations with operators sug gest that they usually want the network to use paths with limited hops, if not the shortest one. The number of such paths is small even in large networks. Second, if a network wants to verify requirements with a huge number of valid paths, Coral is inspired by BGP to verify them via divide andconquer: divide the network into partitions abstracted as onebigswitches, construct DVNet on this abstract network, and perform intra/interpartition distributed verifications. Incremental deployment. Coral can be deployed incre mentally in two ways. The first is to assign an offdevice instance ( e.g., VM) for each device without an ondevice veri fier, who plays as a verifier to collect the data plane from the device and exchange messages with other verifiers based on DVNet . This is a generalization of the deployment of RCDC, whose local verifiers are deployed in offdevice instances. The second is the divideandconquer approach above. We deploy one verifier on one server for each partition. The verifier collects the data planes of devices in its partitionModels CPU Cores Mellanox SN2700 [54] Intel(R) Celeron(R) CPU 1047UE @ 1.40GHz 2 Edgecore Wedge32100X [24] Intel(R) Pentium(R) CPU D1517 @ 1.60GHz 4 Barefoot S918032X [12] Intel(R) Xeon(R) CPU D1527 @ 2.20GHz 8 Table 2: Devices in the testbed. to perform intrapartition verification, and exchanges the results with verifiers of other partitions for interpartition verification. The two approaches are not exclusive. Multipath comparison. The Coral specification language (¬ß3) currently does not support specifying ""multipath"" re quirements that compare the packet traces of two packet spaces ( e.g., route symmetry and nodedisjointness). To ad dress this issue, one may extend the syntax with an ùëñùëëkey word to refer to different packet spaces, and allow users to define trace comparison operators using predicate logic. To verify them, one may construct the reachability DVNet for each packet space, let ondevice verifiers collect the actual downstream paths and send them to their upstream neigh bors, and eventually perform the userdefined comparison operation with the complete paths of the two packet spaces as input. We leave its full investigation as future work. 7 PERFORMANCE EVALUATION We implement a prototype of Coral in Java with ~8K LoC (Appendix B) and conduct extensive evaluations. We focus on answering the following questions: (1) What is the capa bility of Coral in verifying a wide range of requirements? (¬ß7.1) (2) What is the performance of Coral in a testbed envi ronment with different types of network devices, mimicking a realworld wide area network (WAN)? (¬ß7.2) (3) What is the performance of Coral in various realworld, largescale net works (WAN/LAN/DC) under various DPV scenarios? (¬ß7.3) (4) What is the overhead of running Coral on commodity network devices? (¬ß7.4) 7.1 Functionality Demonstrations To demonstrate the capability of Coral in verifying a wide range of DPV requirements, we assemble a network of six switches: 4 Mellanox SN2700 switches, 1 Edgecore whitebox switch and 1 Barefoot Tofino switch (Table 2). The first two models are installed SONiC [ 55], and the third is installed ONL [ 60]. The topology is the same as in Figure 3a. For each device, we deploy a Coral ondevice verifier. We run experiments to verify (1) loopfree, waypoint reachability from ùëÜtoùê∑in Figure 3a, (2) loopfree, multicast fromùëÜtoùê∂andùê∑, (3) loopfree, anycast from ùëÜtoùêµandùê∑, (4) differentingress consistent loopfree reachability from ùëÜ andùêµtoùê∑, and (5) allshortestpath availability from ùëÜto ùê∂. After the planner sends the ondevice tasks to switches, we disconnect it from the switches. We then configure de vices with a correct data plane satisfying these requirements and run the experiment. As expected, no data plane error is reported by ondevice verifiers. Next, we iteratively recon figure devices with an erroneous data plane that violates one 10Distributed, OnDevice Data Plane Verification Technical Report, January, 2022, Online of the requirements above, and rerun the experiments. Each time, the ondevice verifier at ùëÜsuccessfully reports the error, except for the final experiment, where we configure device ùêµwith an incorrect data plane to violate the allshortest path reachability from ùëÜtoùê∂. This time, the verifier on ùêµ locally detects and reports this error without propagating any message to neighbors. This shows that Coral can verify the allshortestpath availability locally as RCDC does, mak ing it a special case of Coral. Details of these demos can be found at [10]. 7.2 Testbed Experiments We extend our testbed with 3 Barefoot switches, to mimic the 9device Internet2 WAN [ 56]. We install the forward ing rules of different devices to corresponding switches in the testbed, and inject latencies between switches, based on the propagation latencies between the locations of Inter net2 devices [ 72]. We verify the conjunction of loopfreeness, blackholefreeness and allpair reachability between switches along paths with (‚â§x+2) hops, where ùë•is the smallesthop count for each pair of switches. Experiment 1: burst update. We first evaluate Coral in the scenario of burst update, i.e., all forwarding rules are installed to corresponding switches all at once. Coral fin ishes the verification in 0.99 seconds, outperforming the best centralized DPV in comparison by 2.09 √ó(Figure 9a). Experiment 2: incremental update. We start from the snapshot after the burst update, randomly generate 10ùêærule updates distributed evenly across devices and apply them one by one. After each update, we incrementally verify the network. For 80% of the updates, Coral finishes the incremen tal verification‚â§5.42ùëöùë†, outperforming the best centralized DPV in comparison by 4.90 √ó. This is because in Coral, when a rule update happens, only devices whose ondevice task results are affected need to incrementally update their re sults, and only these changed results are sent to neighbors incrementally. For most rule updates, the number of these affected devices is small (shown in Appendix D). For both experiments, we also measure the overhead of running Coral ondevice verifiers on switches. We present the results in a more comprehensive way in ¬ß7.4. 7.3 LargeScale Simulations We implement an eventdriven simulator to evaluate Coral in various realworld networks, on a server with 2 Intel Xeon Silver 4210R CPUs and 128 GB memory. 7.3.1 Simulation Setup. We first introduce the settings. Datasets. We use 13 datasets in Table 3. The first four are public datasets and the others are synthesized with public topologies [ 34,38,44,63]. Fattree is a 48ary fattree [ 7]. NG Clos is a real, large, Closbased DC. For WAN, we assign link latencies based on the device locations in the datasets [ 72]. For LAN and DC, we assign 10 ùúás latency for each link.Network #Devices #Links #Rules Type Internet2 [56] 9 28 7.74√ó104WAN Stanford [42] 16 74 3.84√ó103LAN Airtel11 [35] 16 26 2.83√ó104WAN Airtel21 [35] 68 158 3.81√ó104WAN Airtel12 16 26 9.60√ó104WAN Airtel22 68 158 4.56√ó105WAN B42013 12 18 7.92√ó104WAN B42018 33 56 2.11√ó105WAN BT North America 36 76 2.52√ó105WAN NTT 47 63 1.98√ó105WAN OTEGlobe 93 103 7.22√ó105WAN Fattree (ùëò=48) 2,880 55,296 3.31√ó106DC NGClos 6,016 43,008 3.23√ó107DC Table 3: Datasets statistics. Comparison methods. We compare Coral with four state oftheart centralized DPV tools: AP [ 74], APKeep [ 83], Delta net [35] and Veriflow [ 43]. We reproduce APKeep and Delta net, and use the opensourced version of AP and Veriflow. Requirements. We verify the allpair loopfree, blackhole free, (‚â§x+2)hop reachability in ¬ß7.2 for WAN/LAN and the allToRpair shortest path reachability for DC. We also use Coral to verify the local contracts of allshortestpath avail ability of DC, as RCDC does, in Appendix F. Metric. We study the verification time. It is computed as the period from the arrival of data plane updates at devices to the time when all requirements are verified, including the propagation delays. For centralized DPV, we randomly assign a device as the location of the server, and let all devices send data planes to the server along lowestlatency paths. We also measure Coral‚Äôs message overhead in Appendix D. 7.3.2 Results: Burst Update. Figure 9a gives the results. For WAN/LAN, Coral completes the verification in ‚â§1.60ùë† and achieves an up to 6.35 √óspeedup than the fastest cen tralized DPV. For DC, this speedup is up to 1250.28 √ó. This is because Coral decomposes verification into lightweight ondevice tasks, which have a dependency chain roughly linear to the network diameter. A DC has a small diameter (e.g., 4 hops). As such, ondevice verifiers achieve a very high level of parallelization, enabling high scalability of Coral. We note that Coral is slower than AP in Airtel11 and Airtel12, but faster in Airtel12 and Airtel22 whose topolo gies are the same pairwise. This is because the latter two have a much higher number of rules (3.39 √óand 11.97√ó). The bottleneck of AP is to transform rules to equivalence classes (ECs), whose time increases linearly with the number of rules, leading to a linear increase of total time. In contrast, Coral only computes LEC on devices in parallel, and is not a bottleneck (Appendix C). As such, with more rules, Coral becomes faster than AP. 7.3.3 Results: Incremental Update. We evaluate Coral for incremental verification using the same methodology as in ¬ß7.2. Figure 9b gives the results. The 80% quantile verification time of Coral is up to 202.58 √ófaster than the fastest central ized DPV. Among all datasets, Coral finishes verifying at least 72.72% rule updates in less than 10 ùëöùë†, while this lower 11Technical Report, January, 2022, Online Xiang et al. NetworkAPAPKeep DeltanetVeriFlowCoralInternet22.072.88104.7111.20exp: 0.99 (2.09√ó)simu: 0.95(2.18√ó)Stanford0.490.2913.280.120.06(2.00√ó)Airtel110.351.0013.571.140.70(0.50√ó)Airtel210.491.9519.081.551.10(0.45√ó)Airtel120.822.5650.961,771.140.72(1.14√ó)Airtel225.9318.23237.1639,979.641.60(3.71√ó)B420130.581.8431.861,133.780.49(1.18√ó)B420181.766.30115.756,139.240.50(3.52√ó)BT North America2.057.25123.1712,085.860.46(4.46√ó)NTT1.656.5389.057,472.410.65(2.54√ó)OTEGlobe7.6241.18442.4862,028.211.20(6.35√ó)Fattree(k=48)40,608.793,293.30MemoryOut46,103.034.05(813.16√ó)NGClos50,573.80111,558.28MemoryOut188692.1140.45(1250.28√ó) (a)Verification time of burst update (seconds). NetworkPercentage < 10 ms 80% quantile ( ms) APAPKeepDeltanetVeriFlowCoral APAPKeepDeltanetVeriFlowCoral Internet2 29.29%27.97 % 0.03 %exp: 81.55%simu: 83.63%2,782.10345.62 36.55 26.555.42 (4.90 √ó) 8.83 (3.01 √ó) Stanford 1.23%99.93%98.73 % 22.55 % 99.76 %10522.6611.22 1.43 0.27 Airtel1 1 15.19%15.19 % 0.30 % 96.97 %635.30121.77 121.74 256.93 0.65 (187.29 √ó)Airtel2 1 6.88%18.12%18.23 % 4.29 % 82.64 %171.85186.38 121.56 121.55 0.60 (202.58 √ó)Airtel1 2 4.89%13.20%11.76 % 0.00 % 85.50 %1,488.84336.88 122.44 122.25 4.99 (24.50 √ó) Airtel2 2 1.49%10.73%9.69 % 0.00 % 73.38 %924.10129.81 127.781,127.7873.64 (1.74 √ó) B42013 0.04%7.96 % 7.96 % 0.00 % 79.80 %831.54254.35 63.23 63.65 22.17 (2.85 √ó) B42018 0.96 % 0.96 % 0.00 % 72.72 %1,287 .5783. 83. 77 404.34 13 6.21 (13.39 √ó)BT North America16.98%15.87 % 0.00 % 83.38 %1,000.06631.19 39.28 39.17 7.78 (5.03 √ó) NTT 6.73 % 6.49 % 0.00 % 75.94 %911.03559.44 118.67 120.79 26.88 (4.41 √ó) OTEGlobe 0.39%0.38 % 0.39 % 0.00 % 80.16 %645.92116.18 120.923,228.219.48 (12.26 √ó) Fattree (k=48)Memory Out0.00% 96.81 %Memory Out18,962.000.12 (5.92 √ó) NGClosMemory Out0.00% 96.81 %Memory Out47,385.640.00% 0.00% 0.00% 0.00% 0.00% 0.00% 86.17 29.21 0.00% 9.60% 32.43% 282.560.06  (4.50 √ó)  693.63 0.12 (2354.67 √ó) (b)Verification time of incremental update. Figure 9: Verification time of experiments and largescale simulations. 0.00 0.25 0.50 0.75 1.00 1.25 1.50 Total Time per Device (s) 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 CDF Mellanox Barefoot Edgecore 0 2 4 6 8 10 12 14 16 18 Maximal Memory per Device (MB) 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 CDF 19.6 Mellanox Barefoot Edgecore 0.0 0.1 0.2 0.3 0.4 CPU Load0.00.10.20.30.40.50.60.70.80.91.0CDF 0.48Mellanox Barefoot EdgecoreFigure 10: Initialization over head. bound of other tools is less than 1%. This is for the same rea son as in experiments (¬ß7.2) and shown in Appendix D, and demonstrates that Coral consistently enables scalable data plane checkups under various networks and DPV scenarios. 7.4 OnDevice Microbenchmarks We run extensive microbenchmarks to measure the overhead of Coral ondevice verifiers. We also measure the latency of computing DVNet and ondevice tasks in Appendix G. Initialization overhead. For each of 414 devices from WAN / LAN and 6 devices from NGClos/Fattree (one edge, aggrega tion and core switch, respectively), we measure the overhead of its initialization phase in burst update ( i.e., computing the initial LEC and CIB), in terms of total time, maximal memory and CPU load, on the three switch models in our testbed. The CPU load is computed as ùê∂ùëÉùëàùë°ùëñùëöùëí/(ùë°ùëúùë°ùëéùëôùë°ùëñùëöùëí √óùëõùë¢ùëöùëèùëíùëüùëúùëì ùëêùëúùëüùëíùë†). Figure 10 plots their CDFs. On all three switches, all devices in the datasets complete initialization in‚â§1.5ùë†, with a CPU load‚â§0.48, and a maximal memory ‚â§19.6ùëÄùêµ. DV UPDATE message processing overhead. For each of the same set of devices in the datasets, we collect the trace of their received DV UPDATE messages during burst update and incremental update experiments, replay the traces con secutively on each of the three switches, and measure the message processing overhead in terms of total time, max imal memory, CPU load and per message processing time. Figure 11 shows their CDFs. For 90% of devices, all three switches process all UPDATE messages in ‚â§2.29ùë†, with amaximal memory‚â§32.08ùëÄùêµ, and a CPU load‚â§0.20. And for 90% of all 835.2ùëòUPDATE messages, the switches can process it in‚â§4ùëöùë†. To summarize, the initialization and messaging process ing overhead microbenchmarks show that Coral ondevice verifiers can be deployed on commodity network devices with little overhead. 8 RELATED WORK "
421,"What sets Verified Users apart? Insights, Analysis and Prediction of Verified Users on Twitter.txt","Social network and publishing platforms, such as Twitter, support the concept
of a secret proprietary verification process, for handles they deem worthy of
platform-wide public interest. In line with significant prior work which
suggests that possessing such a status symbolizes enhanced credibility in the
eyes of the platform audience, a verified badge is clearly coveted among public
figures and brands. What are less obvious are the inner workings of the
verification process and what being verified represents. This lack of clarity,
coupled with the flak that Twitter received by extending aforementioned status
to political extremists in 2017, backed Twitter into publicly admitting that
the process and what the status represented needed to be rethought.
  With this in mind, we seek to unravel the aspects of a user's profile which
likely engender or preclude verification. The aim of the paper is two-fold:
First, we test if discerning the verification status of a handle from profile
metadata and content features is feasible. Second, we unravel the features
which have the greatest bearing on a handle's verification status. We collected
a dataset consisting of profile metadata of all 231,235 verified
English-speaking users (as of July 2018), a control sample of 175,930
non-verified English-speaking users and all their 494 million tweets over a one
year collection period. Our proposed models are able to reliably identify
verification status (Area under curve AUC > 99%). We show that number of public
list memberships, presence of neutral sentiment in tweets and an authoritative
language style are the most pertinent predictors of verification status.
  To the best of our knowledge, this work represents the first attempt at
discerning and classifying verification worthy users on Twitter.","The increased relevance of social media in our daily life has been accompanied by an exigent demand for a means to affirm the au thenticity and authority of content sources. This challenge becomes even more apparent during the dissemination of realtime or break ing news, whose arrival on such platforms often precedes eventual traditional media reportage [ 19,38]. In line with this need, major social networks such as Twitter, Facebook and Instagram have in corporated a verification process to authenticate handles they deem important enough to be worth impersonating. Usually conferred to accounts of wellknown public personalities and businesses, verified accounts1are indicated with a badge next to the screen name (e.g., on Twitter and  on Facebook). Twitter‚Äôs verification policy [ 67] states that an account is verified if it belongs to a personality or business deemed to be of sufficient public interest in diverse fields, such as journalism, politics, sports, etc. However, the exact decision making process behind evaluating the strength of a user‚Äôs case for verification remains a trade secret. This work attempts to unravel the likely factors that strengthen a user‚Äôs case for verification by delving into the aspects of a user‚Äôs Twitter presence, that most reliably predict platform verification. 1.1 Motivation Our motivation behind this work was twofold and is elaborated in the following text. Lack of procedural clarity and imputation of bias: Despite repeated statements by Twitter about verification not being equiva lent to endorsement, aspects of the process ‚Äì the rarity of the status and its prominent visual signalling [ 68] ‚Äì have led users to conflate authenticity and credibility. This perception was confirmed in full public view when Twitter was backed into suspending its requests for verification in response to being accused of granting verified status to political extremists2, with the insinuation being that the 1The exact term varies by platform, with other social networks using the term ‚ÄúVerified Profiles‚Äù. However in the interest of consistency, all ownerauthenticated accounts are referred to as verified accounts , and their owners as verified users . 2https://www .bbc .com/news/technology41934831arXiv:1903.04879v1  [cs.SI]  12 Mar 2019WebSci ‚Äô19, June 30‚ÄìJuly 03, 2019, Boston, MA Paul, et al. verified badge lent their otherwise extremist opinions a facade of mainstream credibility. This however, engendered accusations of Twitter‚Äôs verification procedure harbouring a liberal bias. Multiple tweets imputing the same gave rise to the hashtag #VerifiedHate. Similar insinuations have been made by rightleaning Indian users of the platform in the lead up to the 2019 Indian General Elections under the hashtag #ProtestAgainstTwitter. These hitherto unfounded allegations of bias prompted us to delve deeper into understanding what may be driving the process and inferring whether these claims were justified or could the difference in status be explained away by less insidious factors relating to a user‚Äôs profile and content. Positive perception and coveted nature: Despite having its detractors, the fact remains that a verified badge is highly coveted amongst public figures and influencers. This is with good reason as in spite of being intended as a mark of authenticity, prior work in social sciences and psychology points to verified badges confer ring additional credibility to a handle‚Äôs posted tweets [ 11,23,51]. Psychological testing [ 24] has also revealed that the credibility of a message and its reception is influenced by its purported source and presentation rather than just its pertinence or credulity. Captology studies [ 21] indicate that widely endorsed information originating from a wellknown source is easier to perceive as trustworthy and back up the former claim. This is pertinent as owners of verified accounts are usually wellknown and their content is on an aver age more frequently liked and retweeted than that of the generic Twittersphere [58, 63]. Adding to the desirability of exclusive visual indicators is the de manding nature of credibility assessment on Twitter. The imposed character limit and a minimal scope of visually customizing con tent, coupled with the feverish rate at which content is consumed ‚Äì with users on average devoting a mere three seconds of attention per tweet [ 17] ‚Äì makes users resort to heuristics to judge online content. There is substantial work on heuristic based models for online credibility evaluation [ 14,29,61]. Particularly relevant to this inquiry is the endorsement heuristic , which is associated with credibility conferred to it (e.g. a verified badge) and the consistency heuristic , which stems from endorsements by several authorities (e.g. a user verified in one platform is likely to be verified on others). Unsurprisingly, a verified status is highly sought after by preem inent entities, as evidenced by the prevalence of getverifiedquick schemes such as promoted tweets from the now suspended account ‚Äò@verified845‚Äô [ 9,65]. Our work attempts to obtain actionable in sights into verification process, thus providing entities looking to get verified a means to strengthen their case. 1.2 Research Questions The aforementioned motivating factors pose a few avenues of re search enquiry which we attempt to answer in this work are are detailed below. RQ1: Can the verification status of a user be predicted from profile metadata and tweet contents? If so what are the most reliably discriminative features? RQ2: Do any inconsistencies exist between verified and nonverified users with respect to peripheral aspects like the choice and variety of topics they tweet about?1.3 Contributions Our contributions can be summarized as follows: ‚Ä¢We motivate and propose the problem of predicting verifica tion status of a Twitter user. ‚Ä¢We detail a framework extracting a substantial set of features from data and metadata about social media users, including friends, tweet content and sentiment, activity time series, and profile trajectories. We plan to make this dataset of 407,165 users and 494 million tweets, publicly available upon publication of the work.3 ‚Ä¢Additionally, we factored in stateoftheart bot detection analysis into our predictive model. We use these features to train highlyaccurate models capable of discerning a user‚Äôs verified status. For a general user, we are able to provide a zero to one score representing their likelihood of being verified in Twitter. ‚Ä¢We report the most informative features in discriminating verified users from nonverified ones and also shed light on the manner in which the span and gamut of topic coverage between their tweets differs. The rest of the paper is organized as follows. Section 2 details relevant prior work, hence putting our work in perspective. Sec tion 3 elaborates our data acquisition methodology. In Sections 4 and 5, we conduct a comparative analysis between verified and non verified users, addressing RQ1 and RQ2 respectively, and attempt to uncover features that can reliably classify them. We conclude with a brief summary in Section 6. 2 RELATED WORK "
265,Neural Network Branch-and-Bound for Neural Network Verification.txt,"Many available formal verification methods have been shown to be instances of
a unified Branch-and-Bound (BaB) formulation. We propose a novel machine
learning framework that can be used for designing an effective branching
strategy as well as for computing better lower bounds. Specifically, we learn
two graph neural networks (GNN) that both directly treat the network we want to
verify as a graph input and perform forward-backward passes through the GNN
layers. We use one GNN to simulate the strong branching heuristic behaviour and
another to compute a feasible dual solution of the convex relaxation, thereby
providing a valid lower bound.
  We provide a new verification dataset that is more challenging than those
used in the literature, thereby providing an effective alternative for testing
algorithmic improvements for verification. Whilst using just one of the GNNs
leads to a reduction in verification time, we get optimal performance when
combining the two GNN approaches. Our combined framework achieves a 50\%
reduction in both the number of branches and the time required for verification
on various convolutional networks when compared to several state-of-the-art
verification methods. In addition, we show that our GNN models generalize well
to harder properties on larger unseen networks.","Despite their outstanding performances on various tasks, neural networks are found to be vulnerable to adversarial examples (Goodfellow et al., 2015; Szegedy et al., 2013) ‚Äî examples that are similar to real inputs but ones which the neural network misclassiÔ¨Åes with a high probability. They are obtained by applying small but deliberately chosen perturbations that are often imperceptible to the human eye. The brittleness of neural networks can have costly consequences in areas such as autonomous vehicles (Bojarski et al., 2016) and personalized medicine (Weiss et al., 2012). When one requires robustness to adversarial examples, traditional model evaluation approaches, which test the trained model on a holdout set, do not sufÔ¨Åce. Instead, formal veriÔ¨Åcation of properties such as adversarial robustness becomes necessary. For instance, to ensure selfdriving cars make consistent correct decisions even when the input image is slightly perturbed, the required property to verify is that the underlying neural network outputs the same correct prediction for all points within a norm ball whose radius is determined by the maximum perturbation allowed. Several methods have been proposed for verifying properties on neural networks. Bunel et al. (2018a) showed that many of the available methods can be viewed as instances of a uniÔ¨Åed branch andbound (BaB) framework. The BaB framework solves a mixed integer programming (MIP) formulation of the veriÔ¨Åcation problem. In other words, the veriÔ¨Åcation problem is formulated as the minimization of a linear objective under linear constraints over variables that can take real values or can be restricted to take only integral values. A BaB algorithm consists of two key components: branching strategies and bounding methods. Branching strategies decide how the feasible domain of the MIP is recursively split into smaller subdomains. For each subdomain the bounding method then computes an upper and a lower bound of the MIP objective. If the upper bound of a subdomain is less than the lower bound of another, the latter subdomain can be pruned thereby reducing the domain for the optimal solution. Branching strategies have a signiÔ¨Åcant impact on the overall problemsolving process, as they directly inÔ¨Çuence the total number of steps, and consequently the total time, required to solve the problem at hand. The quality of a branching strategy is even more important when neural network veriÔ¨Åcation problems are considered, which generally have a very large domain. Each input dimen sion or each activation unit can be a potential branching option and neural networks of interest often have high dimensional inputs and thousands of hidden activation units. With such a large problem domain, an effective branching strategy could mean a large reduction of the total number of branches required, and consequently of the time required to solve a problem. Developing an effective strat egy is thus of signiÔ¨Åcant importance to the success of BaB based neural network veriÔ¨Åcation. So far, to the best of our knowledge, branching rules adopted by BaB based veriÔ¨Åcation methods are either random selection (Katz et al., 2017a; Ehlers, 2017a) or handdesigned heuristics (Wang et al., 2018b; Bunel et al., 2018a; Royo et al., 2019; Bunel et al., 2020b). Random selection is gener ally inefÔ¨Åcient as the distribution of the best branching decision is rarely uniform. In practice, this strategy often results in an almost exhaustive search to make a veriÔ¨Åcation decision. On the other hand, handdesigned heuristics often involve a tradeoff between effectiveness and computational cost. For instance, strong branching is generally one of the best performing heuristics for BaB methods in terms of the number of branches, but it is computationally prohibitive as each branching decision requires an expensive exhaustive search over all possible options. The heuristics that are currently used in practice are either inspired by the corresponding dual problem when veriÔ¨Åcation is formulated as an optimization problem (Bunel et al., 2018a; Royo et al., 2019) or incorporating 2NEURAL NETWORK BABFOR NEURAL NETWORK VERIFICATION the gradient information of the neural network (Wang et al., 2018b). These heuristics normally have better computational efÔ¨Åciency. However, given the complex nature of the problem domain, it is unlikely that any handdesigned heuristic is able to fully exploit the structure of the problem and the data distribution encountered in practice. As mentioned earlier, for large size neural network veriÔ¨Å cation problems, a slight reduction in the quality of the branching strategy could lead to substantial increase in the total number of branches required to solve the problem. A computationally cheap but high quality branching strategy is thus much needed. The bounding component of the BaB algorithm consists of two parts: Ô¨Ånding upper and lower bounds. The former is efÔ¨Åcient to compute as it involves evaluating the objective for any feasible solution. In contrast, the lower bound computation requires solving a large convex relaxation. Typi cally, the relaxation is solved using either commercial solvers such as Gurobi (Gurobi Optimization, 2020) or traditional optimization algorithms such as subgradient descent (Dvijotham et al., 2018b) or proximal minimization (Bunel et al., 2020a). However, neither approach scales elegantly with the size of the relaxation, which prevents current formal veriÔ¨Åcation methods from being applied to deep stateoftheart networks. In other words, lower bound estimation forms a computational bottleneck for BaB. A natural question that arises is why do traditional algorithms fail? We argue that by their very nature, they ignore the rich inherent structure of lower bound estimation for the problem of veriÔ¨Åcation. SpeciÔ¨Åcally, all lower bounds that one wishes to estimate across multiple subdomains of the same property, across multiple properties of the same network, and across multiple networks share the same form of variables, constraints and objectives. Furthermore, the coefÔ¨Åcients of the objective and constraints are determined from network weights, which themselves are not random but are estimated using real data. Traditional optimization algorithms are agnostic to this complex highdimensional structure as it is not ‚Äúvisible‚Äù to human intelligence. The aforementioned arguments suggest that, in order to scaleup veriÔ¨Åcation, we require com putationally cheap methods that can exploit the inherent structure of the problem and the data. To this end, we propose a novel machine learning framework that can be used for designing a branching strategy and for the estimation of lower bounds. Our framework is both computationally efÔ¨Åcient and effective, giving branching decisions that are of a similar quality to that of strong branching. Moreover, we use the same framework to return tighter lower bounds more quickly than other opti mization methods. SpeciÔ¨Åcally, we make the following contributions: ‚Ä¢ We use a graph neural network (GNN) to exploit the structure of the neural network we want to verify. The embedding vectors of the GNN are updated by a novel schedule, which is both computationally cheap and memory efÔ¨Åcient. In detail, we mimic the forward and backward passes of the neural network to update the embedding vectors. In addition, the proposed GNN allows a customised schedule to update embedding vectors via shared parameters. That means, once training is done, the trained GNN model is applicable to various veriÔ¨Åcation properties on different neural network structures. ‚Ä¢ We train two GNNs: one for branching and another for bounding. We provide ways to gen erate training data cheaply but inclusive enough to represent problems at different stages of a BaB process for various veriÔ¨Åcation properties. With the ability to exploit the neural network structure and a comprehensive training data set, our GNNs are easy to train and converge quickly. 3JAECKLE , LU AND KUMAR ‚Ä¢ Our learnt GNNs also enjoy transferability both horizontally and vertically. Horizontally, although trained with easy properties, the learnt GNNs give similar performance on medium and difÔ¨Åcult level properties. More importantly, vertically, given that all other parts of BaB algorithms remain the same, the GNNs trained on small networks perform well on large networks. Since the network size determines the total cost for generating training data and is positively correlated with the difÔ¨Åculty of learning, this vertical transferability allows our framework to be readily applicable to large scale problems. ‚Ä¢ Finally, we supply a dataset on convolutional neural network veriÔ¨Åcation problems, covering problems at different difÔ¨Åculty levels over neural networks of different sizes. We hope that by providing a large problem dataset it could allow easy comparisons among existing methods and additionally encourage the development of better methods. Since most available veriÔ¨Åcation methods work on ReLUbased deep neural networks, we focus on neural networks with ReLU activation units in this paper. However, we point out that our framework is applicable to other neural network architectures using different nonlinearities such as sigmoid or the hyperbolic tangent. A preliminary version of this work appeared in the 2020 proceedings of the International Con ference on Learning Representations, in which we focused on learning how to branch. We have extended the work to now also include learnt bounding algorithms. Moreover, we have merged the branching and the bounding methods to get a learnt complete veriÔ¨Åcation algorithm that outperforms stateoftheart solvers. 2. Background Formal veriÔ¨Åcation of neural networks refers to the problem of proving or disproving a property over a bounded input domain. Properties are functions of neural network outputs. When a property can be expressed as a Boolean expression over linear forms, we can modify the neural network in a suitable way so that the property can be simpliÔ¨Åed to checking the sign of the neural network output (Bunel et al., 2018a). Note that all the properties studied in previous works satisfy this form, thereby allowing us to use the aforementioned simpliÔ¨Åcation. Mathematically, given the modiÔ¨Åed neural network f, a bounded convex input domain C, formal veriÔ¨Åcation examines the truthfulness of the following statement: 8x2C; f(x)0: (1) If the above statement is true, the property holds. Otherwise, the property does not hold. 2.1 BranchandBound VeriÔ¨Åcation tasks are often treated as a global optimization problem. We want to Ô¨Ånd the minimum off(x)overCin order to compare it with the threshold 0. SpeciÔ¨Åcally, we consider an Llayer feed forward neural network, f:Rd!R, with nonlinear activations ssuch that for any x02CRd, f(x0) =ÀÜxL2Rwhere ÀÜxi+1=Wi+1xi+bi+1; fori=0;:::; L"
332,Fundamental Limits in Formal Verification of Message-Passing Neural Networks.txt,"Output reachability and adversarial robustness are among the most relevant
safety properties of neural networks. We show that in the context of Message
Passing Neural Networks (MPNN), a common Graph Neural Network (GNN) model,
formal verification is impossible. In particular, we show that output
reachability of graph-classifier MPNN, working over graphs of unbounded size,
non-trivial degree and sufficiently expressive node labels, cannot be verified
formally: there is no algorithm that answers correctly (with yes or no), given
an MPNN, whether there exists some valid input to the MPNN such that the
corresponding output satisfies a given specification. However, we also show
that output reachability and adversarial robustness of node-classifier MPNN can
be verified formally when a limit on the degree of input graphs is given a
priori. We discuss the implications of these results, for the purpose of
obtaining a complete picture of the principle possibility to formally verify
GNN, depending on the expressiveness of the involved GNN models and
input-output specifications.","The Graph Neural Network (GNN) framework, i.e. models that c ompute functions over graphs, has become a goto technique for learning tasks over structur ed data. This is not surprising since GNN application possibilities are enormous, ranging from n atural sciences (cf. Kipf et al. (2018); Fout et al. (2017)) over recommender systems (cf. Fan et al. ( 2019)) to general knowledge graph applications which itself includes a broad range of applica tions (cf. Zhou et al. (2020)). Naturally, the high interest in GNN and their broad range of application s including safetycritical ones, for instance in trafÔ¨Åc situations, impose two necessities: Ô¨Års t, a solid foundational theory of GNN is needed that describes possibilities and limits of GNN model s. Second, methods for assessing the safety of GNN are needed, in the best case giving guarantees f or certain safety properties. Compared to the amount of work on performance improvement fo r GNN or the development of new model variants, the amount of work studying basic theore tical results about GNN is rather limited. Some general results have been obtained as follows : independently, Xu et al. (2019) and Morris et al. (2019) showed that GNN belonging to the model of Message Passing Neural Net works (MPNN) (cf. Gilmer et al. (2017)) are nonuniversal in the se nse that they cannot be trained to distinguish speciÔ¨Åc graph structures. Furthermore, bot h relate the expressiveness of MPNN to the WeisfeilerLeman graph isomorphism test. This charact erisation is thoroughly described and extended by Grohe (2021). Loukas (2020) showed that MPNN can be Turing universal under cer tain conditions and gave impossibility results of MPNN with restricted depth and width for solving certain graph problems. Similarly, there is a lack of work regarding safety guarante es for GNN, or in other words work onformal veriÔ¨Åcation of GNN. Research in this direction is almost exclusively con cerned with certifying adversarial robustness properties (ARP) of nodeclassifying GNN (see Sect. 1.1 for details). There, usually considered ARP specify a set of val id inputs by giving a center graph and a bounded budget of allowed modiÔ¨Åcations and are satisÔ¨Åed by some GNN if all valid inputs are classiÔ¨Åed to the same, correct class. However, due to the nat ure of allowed modiÔ¨Åcations, these properties cover only local parts of the input space, namely neighbourhoods around a center graph. 1Under review as a conference paper at ICLR 2023 This local notion of adversarial robustness is also common i n formal veriÔ¨Åcation of classical neural networks (NN). However, in NN veriÔ¨Åcation, the absence of mi sbehaviour of a more global kind is adressed using so called output reachability properties (ORP) (cf. Huang et al. (2020)). A common choice of ORP speciÔ¨Åes a convex set of valid input vectors and a convex set of valid output vectors and is satisÔ¨Åed by some NN if there is a valid input that leads t o a valid output. Thus, falsifying ORP, speciÔ¨Åying unwanted behaviour as valid outputs, guarantee s the absence of respective misbehaviour regarding the set of valid inputs. To the best of our knowledg e there currently is no research directly concerned with ORP of GNN. This work adresses both of the above mentioned gaps: we prese nt fundamental results regarding the (im)possibility of formal veriÔ¨Åcation of GNN. We prove tha t ‚Äì in direct contrast to formal veriÔ¨Åca tion of NN ‚Äì there are nontrivial classes of ORP and ARP used f or MPNN graph classiÔ¨Åcation, that cannot be veriÔ¨Åed formally. Namely, as soon as the chosen kin d of input speciÔ¨Åcations allows for graphs of unbounded size, nontrivial degree and sufÔ¨Åcient ly expressive labels, formal veriÔ¨Åcation is no longer automatically possible in the following sense: th ere is no algorithm that, given an MPNN and speciÔ¨Åcations of valid inputs and outputs, answers corr ectly (yes/no) whether some valid input is mapped to some (in)valud output. Additionally, we show t hat ORP and ARP of MPNN used for node classiÔ¨Åcation are formally veriÔ¨Åable as soon as the deg ree of valid input graphs is bounded. In the ARP case, this extends the previously known bounds. The remaining part of this work is structured as follows: we g ive necessary deÔ¨Ånitions in Sect. 2 and a comprehensive overview of our results in Sect.3. In Sec t. 4 and Sect. 5, we cover formal arguments, with purely technical parts outsourced to App. A and B. Finally, we discuss and evaluate our possibility and impossibility results in Sect.6. 1.1 R ELATED WORK "
99,Combining a Convolutional Neural Network with Autoencoders to Predict the Survival Chance of COVID-19 Patients.txt,"COVID-19 has caused many deaths worldwide. The automation of the diagnosis of
this virus is highly desired. Convolutional neural networks (CNNs) have shown
outstanding classification performance on image datasets. To date, it appears
that COVID computer-aided diagnosis systems based on CNNs and clinical
information have not yet been analysed or explored. We propose a novel method,
named the CNN-AE, to predict the survival chance of COVID-19 patients using a
CNN trained with clinical information. Notably, the required resources to
prepare CT images are expensive and limited compared to those required to
collect clinical data, such as blood pressure, liver disease, etc. We evaluated
our method using a publicly available clinical dataset that we collected. The
dataset properties were carefully analysed to extract important features and
compute the correlations of features. A data augmentation procedure based on
autoencoders (AEs) was proposed to balance the dataset. The experimental
results revealed that the average accuracy of the CNN-AE (96.05%) was higher
than that of the CNN (92.49%). To demonstrate the generality of our
augmentation method, we trained some existing mortality risk prediction methods
on our dataset (with and without data augmentation) and compared their
performances. We also evaluated our method using another dataset for further
generality verification. To show that clinical data can be used for COVID-19
survival chance prediction, the CNN-AE was compared with multiple pre-trained
deep models that were tuned based on CT images.","Currently , medical centres  hold huge amount s of patient  data. Medical biomarkers, demographic data and  image modalities can help and support medical specialists to diagnose infectious diseases  [1],  Alzheimer ‚Äôs [2], Parkinson  [3] and coronary artery disease  [4]. However, these data must be processed  and analysed  if they are to become usable information  for specialists.  Automated solutions based on  artificial intelligence have the potential to carry out the required process effi ciently [5].  Recently, a new type of coronavirus ( i.e., Coronavirus Disease 2019 [ COVID 19]) emerged , which has  taken many lives  worldwide [69]. The virus outbreak was observed for the first time in late 2019 [10,  11]. COVID 19 primarily targets the lungs  [12, 13] . Thus , if the virus is not properly diagnosed in the  early stages of infection, it can severely damage the lungs  [14]. The mortality rate of the virus is low ;  however, it must not be overlooked , as the virus is  highly contagious. The virus threat becomes more  serious when the resources  of medical centres  cannot provide service s to the large number of peopl e who  are infected each day [15].  The p rediction of  the survival chance of  infected individuals  is as important as the early detection of the  virus. Under resource scarcity, medical centres  can take into account patients‚Äô conditions and use the  available resources wisely. Previous research on COVID 19 detection has proven that deep neural  networks are very effective in the early detection of COVID 19 [16]. Thus , it may be that deep networks   are also useful for survival chance prediction. In this study, w e relied on a clinical  dataset, which  included  data about gender, age and blood type , to perform a diagnostic analysis of the COVID 19 virus. To the  best of our knowledge, this appears to be the first paper to propose a survival chance predictor for  COVID 19 patients using clinical  features. To evaluate the effectiveness of our proposed method, we  compare d its performance against a standard convolutional  neural network  (CNN)  trained on image data.   This study makes a numbe r of contributions  as follows:   ÔÇ∑ The s urvival chance prediction of COVID 19 patients based on clinical features   ÔÇ∑ Preparing clinical dataset to predict the survival chance of COVID 19 patients for the first time   ÔÇ∑ Providing  a careful analysis of the dataset char acteristics , including an examination of the effect s  of features on the mortality rate and the correlation s between each feature pair   ÔÇ∑ Making our dataset publicly available   ÔÇ∑ Combining Autoencoder  (AE)  with CNN to increase prediction accuracy   ÔÇ∑ Proposing a data  augmentation procedure to balance the number of samples of different classes of  the dataset. Notably, o ur data augmentation method is generic and applicable to any other dataset.   The remaining sections of the paper are organi sed as follows: Section 2  reviews the related literature ;  Section 3 briefly sets out the required background;  Section 4 describes our dataset ; Section 5 explains  the  proposed methodology ; Section 6 presents our e xperimental results ; and Sections 7 and 8 present our  discussion, conclusion  and future works.   2 Literature Review   This study sought to predict the survival chance of COVID 19 patients using clinical  features. We began  by review ing the  COVID 19 detection  methods that rely on clinical  features  and image data . We also  review ed methods on mortality estimation s of infected patients.   To contain the COVID 19 threat as soon as  possible, researchers approached  this virus from multiple  directions. Some focused on the fast and accurate detection of infected patients . For example, Wu et al. [17] extracted 11 vital blood indices using the random forest (RF) method to design an assistant  discrimination tool. Their method had an accuracy of 96.97% and 97.95% for the test set and cross  validation set , respectively. The assistant tool was well  equipped to perform a preliminary investigation of  suspected patients and suggest quarantine  and timely treatment.  In another study , Rahman et al. [18]  reviewed various studies on treatment, complications, seasonality, symptoms, clinical features and the  epidemiology of COVID 19 infection to assist medical pract itioners by providing necessary guidance for  the pandemic.  Using a CNN , they tried to detect infected patients to isolate them from healthy patients .  Various hybrid approaches have been adopted  to improve COVID 19 diagnosis accuracy. Islam  et al.  [19]  employed a CNN  for feature extraction and long short term memory f or the classifica tion of patients  based on  Xray images.  EMCNet [20] is another hybrid diagnosis approach that uses a CNN for feature  extraction and carries out binary classification using a number of learning techniques , including RF and  support vector machine (SVM) , on Xray images . Islam  et al.  [21] also used a CNN for feature extraction  but relied on a recurrent neural network (RNN) for classification based on the extracted features.  Multiple   experiments have been conducted using a combination of architectures , such as VGG19  and  DenseNet121 , with an RNN.  VGG19+RNN  was reported to have the best performance .  In addition to distinguishing  between infected and noninfected patients , it is also important to determine  whether infected patients have sever e condition s. Muhammad et al. [22] relied on data mining to predict  the recovery condition of infected patients. Their method was able to determine the age group of high risk  patient s who  are less likely to recover and those who are likely to recover quickly.  Their method was able  to provide the minimum and the maximum number of days required  for a  patient ‚Äôs recovery.  Chen  et al.  [23] studied 148 severe and 214 non severe COVID 19 patients from Wuhan, China using their  laboratory test results and symptoms as features to de sign a RF. The task of the RF was to classify  COVID 19 patients into sever e and non sever e types using the features . Using the laboratory results and  symptom as input, the  accuracy  of their  model was over 90%. Some of the key features they identified  were lactate dehydrogenase  (LDG) , interleukin 6, absolute neutrophil count, D Dimer, diabetes, gender,  cardiovascular di sease, hypertension and age.   Other researcher s have focused on the mortality risk prediction  of the  patients. Gao et al. [24] proposed a  mortality risk prediction model for COVID 19 (MRPMC) that applied clinical data to stratify patients by  mortality risk and predicted mortality 20 days in advance. Thei r ensemble framework was based on four  machine learning techniques ; that is,  a neural network (NN) , a gradient boosted decision tree [25], a  SVM  and logistic regr ession. Their model was able to accurate ly and expeditio usly stratify the  mortality  risk of COVID 19 patients.   Zhu e t al. [26] presented a risk stratification score system as a multilayer perceptron  (MLP)  with six dense  layers  to predict mortality. 78 clinical variables were identified a nd prediction performance was compared   with the pneumonia severity index , the confusion, uraemia , respiratory rate, BP, age ‚â• 65 years score  and  the COVID ‚Äê19 severity score. They derived the top five predictors of mortality ; that is, LDH , C‚Äêreactive  protein,  the neutrophil  to lymphocyte ratio, the Oxygenation Index and D ‚Äêdimer. Thei r model was proved  to be effective in resource ‚Äêconstrained and time ‚Äêsensitive environment s.  The power of the XGBoost algorithm has also be en leveraged for mortality risk prediction . For example,   Yan et al. [27] collected blood samples of 485 infected patients from China to detect key predictive  biomarkers of COVID 19 mortality. The y employed a XGBoost classifier  that was able to predict the  mortality of patients with 90% accuracy more than 10 days in advance. In another study , Bertsimas et al.  [28] developed a data driven mortality risk calculator for in hospital patients. Labora tory, clinical and  demographic variables were accumulated at the time of hospital admission. Again, t hey applied XGBoost to predict the mortality of patients. Adopting a different approach, Abdulaal et al. [29] devised a point of admission mortality risk scoring system using a MLP  for COVID 19 patients. The network  exploited  patient specific features , including present symptoms, smoking history, comorbidities and demographics ,  and predicted the mortality risk bas ed on these features . The mortality prediction model demonstrated a  specificity of 85.94%, a sensitivity of 87.50% and  an accuracy of 86.25%.   As the symptoms of different viruses may be similar to some extent, t here has been an attempt to  distinguish diffe rent viruses from one an other  [30]. To this end , multiple classical machine learning  algorithms were trained to classify textual clinical reports into the four classes  of Severe acute respiratory  syndrome  (SARS ), acute respiratory distress syndrome , COVID 19 and both SARS  and COVID 19.  Feature engineering  has also been carried out  using report length, bag of word s and etc . Multinomial   Na√Øve Bayes and logistic regression outperformed other classifiers with a testing accuracy of 96.2%. A  summary of the reviewed works are presented in Table 1.  Most existing studies  on COVID 19 have relied  on computed tomography ( CT) and X ray images to  achieve their research objectives.  AlWaisy et al. [31] proposed COVID DeepNet , a hybri d multimodal  deep learning system for  diagnosing COVID 19 using  chest  Xray images.  After the preprocessing  phase, the prediction s from two models  (a deep belief network and a convolutional deep belief network)   were fused to improve diagnosis accuracy.  Another fusion of two models  (ResNet34 and a high  resolution network model ) was proposed in [32] to form  the COVID CheXNet  method  for COVID 19  diagnosis.  Mohammed  et al.  collected a dataset of X ray images and made it publicly available. The  dataset has been used to benchmark  various machine learning methods for COVID 19 diagnosis [33].  They reported that the ResNet50 model achieved the best performan ce. In another benchmarking study   [34], 12 COVID 19 diagnostic methods were examined based on 10 evaluation criteria. To this end,  multicriteria decision making (MCDM)  and the technique order of preference by similarity to ideal  solution were  employed.  The 10 criteria were weighted based on entropy.  The SVM classifier was  reported to have the best performance among the benchmarked methods.   Slowing down the spread of COV ID19 and supporting infec ted patients are  as important as COVID 19  detection. Several works  have  investigat ed the possibility of using existing technologies to benefit   infected patients. Rahman et al. [35] proposed a deeplearn ing architecture to determine whether people  are wearing a facial mask. The monitor ing was reali sed via closed circuit television cameras in public  places.  Islam et al. [36] reviewed existing technologies that can facilitate the breathing of infected  patients.  Wearable technologies and how they can be used to provide initial treatment to peop le have  also  been investigated [37]. Ullah et al.  [38] reviewed tele health services and the possible ways in which they  can be used to provide patient s with necessary treatments while keeping the social distance between  patients and doctors.   Some works have adopted a broader approach and reviewed various recently developed deep learning  methods with application to COVID 19 diagnosis.  For example , Islam e t al. [39] reviewed these methods  based on X ray and CT images  while the overall application of deep learning for di agnosis purposes to  control the pandemic threat has been discussed in  [40].  Based on the review presented above, it is apparent that existing works  based  on clinical data  are rather  scarce . Thus , we sought to conduct another study using clinical  data for mortality risk assessment.  The  difference between our method and existing research on mortality risk assessment is twofold. First, we  developed  a new approach for carry ing out the assessment. Second, some of the clinical features that we  considered had never been used previously, which is why we  have  release d our dataset publicly . As will  be discussed further below , clinical  data are more cost effective than CT images , and classifiers trained on clinical data achieve a level of performance that is almost equal to  that achieved by classifiers  trained on  CT images. To justify this claim, we compare d the performance  of our method  trained on clinical data to  a standard CNN  trained on CT images.   Table 1. Summary of  the reviewed literature   Ref Method  objective   Gao et al. [24] An Ensemble of NN, grad boosted decision  tree, SVM, and logistic regression  mortality risk prediction   Zhu et al. [26] MLP  mortality risk prediction   Yan et al. [27] XGBoost classifier  mortality risk prediction   Bertsimas et al. [28] XGBoost classifier  mortality risk prediction   Abdulaal et al. [29] MLP mortality risk prediction   Wu et al. [17] RF COVID 19 detection   Rahman et al. [18] CNN  COVID 19 detection   Khanday et al. [30] Multinomial Na√Øve Bayes and Logistic  regression  Patients classification into four  classes {SARS, ARDS, COVID  19, Both (SARS, COVID 19)}  Chen et al. [23] RF COVID 19 se verity classification   3 Background   Our proposed method comprises  two modules : the classifier and data augmenter. The classification is  carried out using a CNN. The data augmentation is reali sed using 10 AEs. In this section, we briefly  review the main conce pts of CNN s and AEs.   3.1 CNN s  CNNs are massively used in image based learning applications. Due to  the automatic feature extraction  mechanism of CNNs, they can discover valuable information from training samples. CNNs are usually  designed with several co nvolutional, pooling  and fully connected layers [41]. As Figure 1 shows , feature  extraction is done by convolving the input with convolutional kernels. The pooling layer reduces the  computational volume of the network without making a noticeable change in the re solution of the feature  map. In CNNs, the size of the pooling layers  usually  decreases as the number of layers increases. Two of  the most popular types of pooling layers are max pooling and average pooling [42].    Figure 1. A CNN schematic .  3.2 AEs  AEs belong to the realm of unsupervised learning , as they do not need labelled  data for their training. In  brief , an AE compresses input data to a lower dimensional latent space and then reconstructs the dat a by  decompressing the latent space representation. Similar to principle component analysis (PCA), AEs  perform dimensionality reduction in the compression phase. However, unlike PCA , which  relies on linear  transformation, AEs carry out nonlinear transforma tion using deep neural networks [43]. Figure 2 shows  the architecture of a typical AE.    Figure 2. AE architecture: High dimension input data are encoded (compressed) to form a latent (hidden)  space that has a lower dimension than that of the original input. The latent representation is reconstructed  (decoded) to yield decompressed output.   3.3 Information Gain  In this secti on, we review information gain (IG) , as it is used to determine the degree to which  each  feature  of our dataset  contributes  to the patients‚Äô death s (see Section 4) . IG calculates the entropy  reduction that results from  splitting a dataset , ùê∑, based on a given value , ùëé, of a random variable , ùê¥, such  that:  ùêºùê∫(ùê∑,ùê¥ = ùëé)=ùêª(ùê∑)‚àíùêª(ùê∑|ùê¥ = ùëé),  where ùêª(ùê∑) and ùêª(ùê∑|ùê¥ = ùëé) are entropy on dataset ùê∑ and conditional entropy  on dataset ùê∑,  respectively,  given  that ùê¥ = ùëé.  Conditional entropy is  computed as:   ùêª(ùê∑|ùê¥ = ùëé)=‚àë|ùê∑ùê¥ = ùëé| |ùê∑|ùë£‚ààùë£ùëéùëôùë¢ùëíùë† (ùê¥) ùêª(ùê∑ùê¥ = ùëé), (1)  where ùê∑ùê¥ = ùëé‚äÇùê∑ is the set of samples with variable ùê¥ = ùëé and |ùê∑ùê¥=ùëé| and |ùê∑| denote the cardinality of  subset ùê∑ùê¥ = ùëé and set ùê∑, respectively. In Equation (1), the sum is computed over all possible values of ùê¥.  4 Description of our clinical dataset   The dataset we collected in this paper comprised 320 patients ( 300 cases of  recovered patients  and 20  cases  of deceased  patients ). The percentage of female cases was 55%.  The mean age of patients in the  dataset  was 49.5 years old , and the standard deviation was 18.5. The patients referred to Tehran Omid  hospital  in Iran from 3 March 2020 to 21 April 2020 . Ethical approval for the use of these data was  obtained  from the Tehran Omid hospital . In gathering  the data, patients‚Äô history (as collected by doctors ),  questionnaires  (as completed  by patients ), laboratory test s, and vital sign measurement s were used .  Description s of the dataset fea tures are presented in Table 2. Our dataset is publicly available in  [44].  Institutional approval was granted for the use of  the patient datasets in research studies for diagnostic and  therapeutic purposes. Approval was granted on the grounds of existing datasets. Informed consent was  obtained from all  of the  patients in this study. All methods were carried out in accordance with relevant  guidelines and regulations .  Table 2. Description of the dataset features used for classification .  Feature Name  Range   Gender  {Male, Female}   Age 1195 years old   Blood Type  {A, A+, B , B+, AB , AB+, O , O+}   BCG Vaccine  {Yes, No}   CBC  {Normal, Abnormal }  Diabetes  {Yes, No}   blood pressure  {Yes, No}   Asthma  {Yes, No}   Heart disease  {Yes, No}   kidney disease  {Yes, No}   Respiratory disease  {Yes, No}   Cancer  {Yes, No}   Corticosteroids  {Yes, No}   Transplant  {Yes, No}   HEM  {Yes, No}   Immunodeficiency  {Yes, No}   Liver disease  {Yes, No}   Rheumatological disease  {Yes, No}   Chest pain  {Yes, No}   Fever  {Yes, No}   Trembling or Shakes  {Yes, No}   Weakness  {Yes, No}   Sweating  {Yes, No}   Sore throat  {Yes, No}   Dyspnea  {Yes, No}   Dry cough  {Yes, No}   Cough with sputum  {Yes, No}   Fatigue, whole body hurts  {Yes, No}   Anosmia  {Yes, No}   Ageusia  {Yes, No}   Anorexia  {Yes, No}   Eczema  {Yes, No}   Conjunctivitis (Pink eye)  {Yes, No}   Blindness and Tunnel vision  {Yes, No}   Vertigo  {Yes, No}   Nausea/Diarrhea  {Yes, No}   Tobacco  {Yes, No}     As our dataset ha d not been released previously , it was vital to assess the degree to which each dataset  feature contribute d to patients‚Äô death s. Such an analysis provides researchers  with valuable insight s into  the characteristics of the collected data. Various feature  selection methods are available to determine the  weight of each feature in the classification of dataset samples. We chose IG [45], which is one of the most widely used feature  selection methods [46]. In Figure 3 , the importance of each feature ( i.e., the IG) is  shown as  a bar. Age had a much larger IG (0.149 ) than other features. Thus , age was not included in  Figure  3 to make  it easier to compare  the importance of  the other features.  According to the bar chart,  (after age) cancer , heart  and kidney  disease s were the second , third  and fo urth most important feature s  related  to patients‚Äô death s, respectively . Thus , it was clear that patients with poor health conditions were  more vulnerable  to COVID 19. It should be noted that  Figure 3 does not include the features with zero  IG.  We also inspected the interplay between the dataset features to determine  the potential correlation  between them.  To this end , the grid in Figure 4 is presented . Figure 4  can be thought as a heat map that  show s the  positive/negative correlation between features. Each cell ùëê(ùëñ,ùëó) in the grid of Figure 4  represents the correlation of features in  the ith row and j th column.  As the cell colour  approaches red ,  the positive correlation between the feature pairs  is higher . For example , anosmia (the loss of the ability  to smell) and ageusia (the loss of the ability to taste with the tongue) had a high positive correlation ,  which means they were usually  observed simultaneously .      Figure  3. Feature  effect s on mortality rate  based on IG.    Figure 4. Correlation between dataset features .  5 Proposed Methodology   This study  investigated  the survival chance prediction of  COVID 19 patients  who referred to the Omid  hospital in Tehran . The classification was based on features obtained from patients‚Äô  information. In the  dataset  collected , the number of recovered patients was 300 and the number of de ceased patients was 20.  The number of recovered patients  was clear ly much hi gher than that of the deceased patients . To ensure  accurate  classification , it was necessary to balance the recovered to the deceased ratio of the dataset  samples. To do this, the number of instances of the lower class was increased , such that the number of  data in both classes was approximately equal. To increase the number of data of deceased patients , an AE  model was used.  To carry out the data augmentation, the 20 samples of the deceased class were fed to the  AE to undergo the compressi on and decompression routine s. The output of this process  comprised 20  reconstructed samples that were similar (but not identical ) to the original ones . Thus , we augmented the  original 20 samples with 20 reconstructed samples . Training the AE 10 times usin g different training and  validation sets yielded 10 AEs with a similar architecture but different parameters. Each of the 10 AEs  generate d 20 reconstructed deceased samples , yielding reconstructed samples of 200  overall , which were   added to  the original deceased samples. To provide an  insight into the function of the  AEs, sample vector s  before and after recons truction are presented in Table 3. For the majority of ‚Äò1‚Äô elements  of input vector  ùëê, the AE outputted values near  1 as the elements  of reconstructed vector ùëêÃÇ. Similarly , most of the  reconstructed element s corresponding to original ‚Äò0‚Äô elements  had values near ‚Äò0‚Äô, which shows that the  reconstruction process was sound.   Table 3. An example of reconstruction performed by an AE: Vector ùëê is the original sample and  vector  ùëêÃÇ is its  reconstructed counterpart .  ùëê[1:10] 1 0 0 1 0 0 0 0 0 0  ùëêÃÇ[1:10] 0.9940  0.1291  0.0001  0.4697  0.1581  0.0240  0.0525  0.0068  0.0061  0.0202   ùëê[11:20] 0 0 0 1 0 0 0 0 1 1  ùëêÃÇ[11:20] 0 0 0.0003  0.4004  0.0004  0.0596  0.0040  0.0027  0.9516  0.4450   ùëê[21:30] 0 0 0 1 1 0 1 0 0 0  ùëêÃÇ[21:30] 0.1305  0.0018  0.0042  0.9565  0.5750  0.0029  0.9281  0.0111  0.0140  0.0966   ùëê[31:39] 0 0 0 0 0 0 0 0 1   ùëêÃÇ[31:39] 0.0087  0.0004  0 0.0110  0.0024  0 0.0017  0.0015  0.9814      The details of the augmentation process are explained in  more detail  in Subsection 5.1. It should be noted   that our augmentation procedure is generic and can be applied to any other dataset.   5.1 Implementation details  of CNN AE  The proposed CNN AE method comprises  multiple steps (see Figure 5  for a summary) . The pseudo code  of the method is also available in Algorithm 1. The detailed explanation of the pseudo code is presented  below:   1. 10 AEs {ùê¥ùê∏1,‚Ä¶,ùê¥ùê∏10} were designed with identical configuration but  different initial  parameters for data augmentation  (line 1) .   2. Each of the 10 AEs was trained  on 300 samples representing the recovered patients. Our objective  was to have 10 models with different parameters at the end of the training. To this end, we  divide d the 300 samples into 10 groups of 30 samples {ùëîùëó,ùëó = 1,2,‚Ä¶,10} where  ùëîùëó is the j th  group of samples. To train  the ith model, ùëîùëñ was set aside for validation and the nine remaining  groups { ùëîùëó,ùëó‚àà{1,2,‚Ä¶,10}‚àí{ùëñ}} (270 samples) were used for training. It should be noted that  each model was initiali sed with different parameters, trained on partially different training  samples and validated on  a totally different validation set. Thus , the proposed training procedure  yield ed 10 different AEs (lines 2‚Äì4).  3. The 20 deceased samples were fed to each of the  10 trained AEs. The samples under went  the  compression and decompression routine of the AEs. As the decompression procedure was lossy ,  the 20 reconstructed samples (after decompression) were not identical to the original samples .  Additionally , the 10 trained AEs exhibit ed different behaviours  on the same input data , as their  parameters were different from each other. Thus , feeding the same 20 samples to the 10  AEs  yield ed 200 new samples that belong ed to the deceased class  (lines 5‚Äì8). The explained  procedure sought to augment the  data to remedy the lack of sufficient samples for the deceased  class.   4. The 200 reconstructed samples were attached to 320 original samples to yield a dataset of  520 samples  (line 9).  5. A CNN model  was designed  to classify 520 samples as recovered or deceased  (line 10).  6. The CNN model was trained using all 520 samples. A 10fold cross validation  was applied   during the training  (lines 11 ‚Äì20). Thus , the training sample size was 468 (samples of 9 folds) , and  the test sample size was 52 (samples of 1fold).  7. The trained CNN  was used  to classify the test data  (line 21) .   Figure 5. The steps for implementing the proposed method.   Algorithm 1 . CNN AE pseu docode   Input:  dataset ùê∑={ùê∑ùëüùëíùëêùëúùë£ùëíùëüùëíùëë ‚à™ùê∑ùëëùëíùëêùëíùëéùë†ùëíùëë }, training epochs N, batch size B, number of folds K    // Autoencoders initialization   1: Create 10 autoencoders with initial random parameters: { ùê¥ùê∏1,‚Ä¶,ùê¥ùê∏10}      // Autoencoders training   2: Partition samples in ùê∑ùëüùëíùëêùëúùë£ùëíùëüùëíùëë  to 10 subsets: {ùëî1,‚Ä¶,ùëî10}  3: For i=1:10   4:        Train ùê¥ùê∏ùëñ on ùê∑ùëüùëíùëêùëúùë£ùëíùëüùëíùëë ‚àíùëîùëñ and perform validation on ùëîùëñ      // Augmented data generation   5: ùê¥=[]  6: For i=1:10   7:        ùëéùëñ=ùê¥ùê∏ùëñ(ùê∑ùëëùëíùëêùëíùëéùë†ùëíùëë )  8:        A=ùê¥‚à™ùëéùëñ  9: ùê∑ùëéùë¢ùëîùëöùëíùëõùë°ùëíùëë =ùê∑‚à™ùê¥  10: Create CNN ùê∂ with initial random parameters     11: // KFold cross validation   Partition ùê∑ùëéùë¢ùëîùëöùëíùëõùë°ùëíùëë  to 90% training set ùê∑ùë°ùëüùëéùëñùëõ  and 10% test set ùê∑ùë°ùëíùë†ùë°  12: Partition ùê∑ùë°ùëüùëéùëñùëõ  to K subsets  {ùêπ1,‚Ä¶,ùêπùêæ}  13: For k=1:K   14:        ùê∑ùë°ùëüùëéùëñùëõ =ùê∑ùëéùë¢ùëîùëöùëíùëõùë°ùëíùëë ‚àíùêπùêæ  15:        ùê∑ùë£ùëéùëôùëñùëë =ùêπùêæ  16:        For e=1:N   17:               ùëèùëéùë°ùëê ‚Ñéùë° = sample_batch( ùê∑ùëéùë¢ùëîùëöùëíùëõùë°ùëíùëë ,ùêµ)  18:              CNN.train( ùëèùëéùë°ùëê ‚Ñéùë°)  19:               ùëèùëéùë°ùëê ‚Ñéùë£ = sample_batch( ùê∑ùë£ùëéùëôùëñùëë ,ùêµ)  20:               CNN.validate( ùëèùëéùë°ùëê ‚Ñéùë£)  21: CNN.test( ùê∑ùë°ùëíùë†ùë°)  22: Return CNN     To i mplement the proposed method , we used Python language and  the Keras library , which has a  TensorFlow backend.  In this study, the dataset contain ed 320 samples of infected cases . Of these 320  cases, the number of recovered cases was 300, and the  number of deceased cases was  20. Additionally ,  we also generated  200 reco nstructed deceased cases to balance the  recovered to the deceased ratio of our  dataset . After the reconstruction phase, our dataset contained 520 cases. We used a 10fold cross  validation. Additionally , 80% of 9 of the folds were used for training , and the remaining 20% was used  for validation.  The implementation details of CNN and  AE are illustrated in Figure s 6 and 7, respectively.     Figure 6 . Implementation details of CNN . ‚ÄòCL‚Äô and ‚ÄòDense ‚Äô represent convolutional and fully connected  layers, respectively. C ircles with  the letter  ‚ÄòB‚Äô represent batch normali sation layer s, and circles with  the  letter  ‚ÄòD‚Äô represent dropout layer s with a probability 0.5.    Figure 7. The implemented AE: The  39dimensional input vector was compressed to a 32 dimensional vector.  During reconstruction, the 32 dimensional vector was decompressed to a 39 dimensional vector .  6 Experiments   In this section , the experimental results are presented. The implementation de tails of CNN and AEs are  explained in Section 6.1. We report on the performance of the proposed method  (CNN AE) and compare  it to a CNN in Section 6.2.  6.1 Experiment al details   Our experiments consist ed of two scenarios. In the first scenario , our CNN AE method  was compared to a  standard CNN  method that was  trained on clinical  data.  The architecture of the CNN is presented in   Table 4. To ensure a fair comparison, we use d the same CNN architecture in our method. The  implementation details of  the AEs used in  the CNN AE are presented in Table 5.  Table 4. Implementation details of the CNN trained on clinical  data.   Hyper parameters  Values   Input dimension  39√ó1 (39 medical features)   Number of convolutional layers  3  Number of fully connected layers  3  Number of filters for each convolutional layer  256  Size of convolutional kernels  3√ó3  Strides size  1  Activation function for hidden layers  ReLU   Activation function of the last layer  Sigmoid   Adam hyper parameters  ùõΩ1=0.9,ùõΩ2=0.999  Learning rate  0.001   Loss function  Binary Cross Entropy (BCE)   Number of  neurons of fully connected layers  64, 32, 2   Dropout probability  0.5  Number of epochs  100    Table 5. AE implementation details .  Hyper parameters  values  Input dimension  39√ó1 (39 medical features)   Number of neurons of the first layer  39√ó1  Number of neurons of the second layer  32√ó1  Number of neurons of the third layer  39√ó1  First and second layers activation function  ReLU   Third layer activation function  Sigmoid   Adam hyper parameters  ùõΩ1=0.9,ùõΩ2=0.999  Learning rate  0.001   Loss function  Binary Cross Entropy (BCE)   Number of epochs  100   In the second phase of our experiments, we compare d the CNN AE trained on clinical  data to a standard  CNN trained on image data.  The CNN architecture is presented in  Figure 8 . After multiple trials, we  obtained  the best set of  the CNN hyperparameters  (see Table 6).  Table 6. Implementation details of the CNN trained on image data .  Hyper parameters  Values   Number of convolutional kernels of first layer  64  Number of convolutional kernels of second layer  128  Number of convolutional kernels of third  layer  256  Size of convolutional kernels  3√ó3  Strides size  2  Input dimension  100 √ó100  Output dimension  2  Number of convolutional layers  3  Number of fully connected layers  2  Activation function for convolutional and fully connected layers  ReLU   Activation function of last layer  Sigmoid   Adam hyper parameters  ùõΩ1=0.9,ùõΩ2=0.999  Learning rate  0.001   Loss function  Binary Cross Entropy (BCE)   Number of neurons of the fourth layer  (fully connected)  256  Number of neurons of fifth layer (fully connected)  128  Dropout probability  0.5  Number of epochs  30  Batch size  128      Figure  8. Implementation details of the CNN trained on CT image s. ‚ÄòCL‚Äô and ‚ÄòDense ‚Äô represent convolutional and  fully connected layers, respectively. Circles with  the letter  ‚ÄòD‚Äô represent dropout layer s with a probability 0.5 .  6.2 Experimental results   We sought  to answer two important questions about th e proposed method. First , we compare d our method  performance with a standard CNN trained on clinical  data. This experiment examined  the effect s of the  proposed data augmentation technique using multiple AEs. We also  trained a standard CNN for the same  purpose ( to predict patients‚Äô survival ch ance) but used CT image s. This experiment sough t to determine  how well CT image s can represent patients‚Äô survival chance using a CNN as the predictor.   6.2.1 Examining the  data augmentation approach   As mentioned in  Section 5.1, we use d 10 AEs to augment the available dataset.  Data augmentation is  critical to successful training when the number of samples from different classes is unbalanced.  Data  imbalance can defea t any powerful classifier  even a state oftheart CNN , which is why we  employ ed the  data augmentation technique.   To investigate the effectiveness of our data augmentation procedure, we trained a CNN on the original  dataset and our CNN AE on an augmented dataset. The original dataset comprised only 20 samples with  the deceased label , but had 300 samples with the recovered label . Comparing the 300 to 20 reveals  severe  data imbalance from which  the CNN suffered during training (see Table 7). However , using an  augmented data set with 300 recovered samples and 220 deceased samples facilitated the CNN training   and improved  accuracy ( see Table 7). Additionally , the area under the curve ( AUC ) measure of the CNN  AE was almost twice that of the CNN.  The specificity measure of CNN was almost zero, which was due  to the fact that the CNN was unable to distinguish  between  deceased and recovered samples due to the  insufficient number of deceased samples in the original dataset.  As Table 7 shows , the CNN AE training  took more time ; however, this was due to the time it took to train  the 10 AEs required for data  augmentation.   Table 7. Comparison of the CNN and the CNN AE using different evaluation metrics based on a 10fold cross  validation.   Methods   Fold No.   Accuracy (%)   PPV (%)   Recall (%)   Specificity (%)   F1score (%)   AUC (%)   Loss   Total training  time (s)   CNN  1 93.75  94 100 0 97 50 0.2157  27.04   2 93.75  94 100 0 97 50 0.2104  20.48   3 93.75  94 100 0 97 50 0.2733  21.34   4 90.63  97 94 0 95 46.77  0.6140  21.49   5 96.88  97 100 66.67  98 83.33  0.0916  21.70   6 90.63  97 94 0 95 46.77  0.2164  22.00   7 93.75  94 100 0 97 50 0.1642  21.51   8 93.75  94 100 0 97 50 0.1816  21.83   9 81.25  96 81 80 88 80.74  0.7327  21.97   10 96.77  97 100 0 98 50 0.1214  22.75   95% confidence interval over 10  folds   92.49 ¬±  2.75 95.40¬±  0.88 96.90¬±  3.73 14.67 ¬±  19.00  95.90¬±  1.82 55.76 ¬±  8.54 0.282 ¬±  0.13 22.21 ¬±  0.37  CNN AE 1 98.08  97 100 94.74  99 97.37  0.0925  33.01   2 94.23  94 97 90.91  95 93.79  0.2600  31.50   3 100 100 100 100 100 100 0.0096  31.35   4 96.15  96 96 95.83  96 96.13  0.2600  31.60   5 93.27  91 97 85 94 90.94  0.4017  31.90   6 92.31  94 94 90.48  94 92.01  0.3678  31.99   7 98.08  97 100 95.45  98 97.73  0.0858  32.30   8 96.15  94 100 90.91  97 95.45  0.2027  32.90   9 94.23  92 96 92.59  94 94.3 0.1572  33.13   10 98.04  97 100 95.45  98 97.73  0.0614  33.83   95% confidence interval over 10  folds   96.05 ¬±  1.48 95.2¬±  1.63 98¬±  1.33 93.14 ¬±  2.52 96.5¬±  1.27 95.55 ¬±  1.70 0.19¬±  0.07 32.35 ¬±  0.49   In Table 7, the CNN AE method  had an average accuracy of 96.05% and thus outperform ed the CNN  method , which had  an average accuracy of 92.49 %. Additionally , due to the augmented data, our method  was able to reduce  the training/validation loss faster than CNN (as is evident in  Figure 9 ). Similarly, the  CNN AE reached higher accuracy faster than the CNN  (see the plots in Figure 10 ). During training, our  method exhibit ed great variation in the validation plo ts compared to  those of the  CNN. Th is is because the   CNN quickly overfit ted to the small number of deceased samples but  the CNN AE had to deal with more  versatile augmented samples. Thus , the training of the  CNN AE was more difficult,  but it achieved better  overall performance.     Figure  9. Loss plots of the CNN and CNN AE methods during the training of our dataset .    Figure  10. Accuracy plots of the CNN and CNN AE methods during training of our dataset .  6.2.2 Comparison s with existing deep models  trained on image data   In this section , we evaluate d the performance of various existing deep models that were trained on a  dataset of CT images . The CT images were  taken from the same patients for whom the clinical  dataset  was collected.  Thus , the results  of this section reveal how well deep models  trained on CT images  perform compared to a CNN trained on clinical  data.  It should be noted  that most of the experiments in  the COVID 19 literature revolve around classifying infected and non infected people usi ng CT images.  This section sheds some light on how well deep models can predict the survival chance of already  infected patients based on CT images.   The dataset comprised  2822 CT image s of recovered  patients and  2269 CT images of deceased patients .  The CT im age dataset size was much greater  than the clinical  dataset size , as the CT dataset contained  multiple images for each patient.  As the number of samples of the two classes in the dataset was almost  balanced, we did not apply our data augmentation  technique to the CT dataset.  Additionally , having  multiple images for each patient served as a form of data augmentation. This was not the case for the  clinical  dataset for which each patient had only one value per feature.   In Table 8, the performance metrics  for the evaluated deep models  are presented  as 95% confidence  intervals (CIs) that have been computed over a 10fold cross validation . The re sults in Table 8 show that   UNet  had the best performance among the evaluated methods , followed by Inception Net  V3 and  DenseNet121 , respectively . Overall, Table 8 suggests that some of the famous deep models with pre  trained parameters can be tuned via training to predict the survival chance of C OVID 19 patient s based on  CT images . A performance c omparison of  the deep models (see Table 8) and the CNN AE (see Table 7)  revealed that a CNN trained on clinical  data performed on p ar with various  pretrained  deep m odels  which have been tuned via training  on CT data.  As stated above,  the CT image dataset size was almost 10  times that of the clinical  dataset size. However , the CNN trained on clinical  data perform ed almost  as well  as the deep models  trained on CT data.  Thus , clinical  data could be a good replacement for CT training  data if the preparation of the CT images would  be difficult  or expensive.   Table 8. Results of existing deep models  trained on CT images .  Method  Accuracy  (%) PPV (%)  Recall (%)  Specificity  (%) F1score  (%) AUC (%)  Loss   CNN  98.88¬±1.09  98.90¬±1.07  98.90¬±0.91  98.10¬±1.22  98.90¬±0.87  98.89¬±0.92  0.01¬±0.01   DenseNet121   [47] 99.10¬±0.10  99.00¬±1.55  99.60¬±0.60  98.95¬±0.36  99.20¬±0.82  99.05¬±1.10  0.06¬±0.07   EfficientNet  B1[48] 55.67¬±1.81  56.70¬±3.32  95.40¬±9.02  50.36¬±2.45  70.00¬±2.34  51.16¬±2.08  9.34¬±5.85   InceptionNet V3  [49] 99.16¬±1.26  99.80¬±0.39  98.90¬±1.95  99.65¬±0.22  99.40¬±0.98  99.27¬±1.02  0.32¬±0.61   MobileNet  [50] 75.33¬±1.62  80.70¬±2.30  73.10¬±1.66  79.56¬±1.48  76.60¬±1.83  75.58¬±1.75  0.51¬±0.02   ResNet50  [51] 81.63¬±1.05  80.50¬±1.38  88.00¬±1.01  78.36¬±1.74  84.20¬±1.05  80.84¬±1.06  0.46¬±0.01   VGG19  [52] 98.02¬±0.36  99.00¬±0.30  97.30¬±0.72  98.79¬±0.81  98.40¬±0.43  98.08¬±0.35  0.07¬±0.01   Xception  [53] 83.34¬±0.81  93.80¬±1.20  74.90¬±0.85  88.64¬±0.92  83.10¬± 0.94 84.36¬±0.86  0.36¬±0.01   UNet [54] 99.25¬±0.21 99.80 ¬±0.26 99.70 ¬±0.30 98.97 ¬±0.19 99.70 ¬±0.30 99.66 ¬±0.20 0.02¬±0.01    6.3 Comparison with other methods  trained on clinical data   In this section , we compare  the performance of  our CNN AE with  some of the existing works on  mortality prediction  [23, 26, 27] . To this end, we implemented  the methods of  Chen et al.  [23], Zhu et al.  [26] and Yan et al. [27]. As mentioned above in the literature review, Chen et al.  relied  on the RF to  assess the severity of COVID 19 patients. For mortality risk prediction, Zhu et al.  [26] and Yan et al.  [27]  used MLP and XGBoost , respective ly. These method s were specifically designed to achieve COVID 19 related objectives. For a broader perspective, we also experimented with Na√Øve Bayes , which is a generic method that can be used regardless of  the classification objective.  The conducted expe riments reveal ed  that our data augmentation approach was generic and beneficial to any classification method.   6.3.1 Methods‚Äô performance   "
525,Linearity Grafting: Relaxed Neuron Pruning Helps Certifiable Robustness.txt,"Certifiable robustness is a highly desirable property for adopting deep
neural networks (DNNs) in safety-critical scenarios, but often demands tedious
computations to establish. The main hurdle lies in the massive amount of
non-linearity in large DNNs. To trade off the DNN expressiveness (which calls
for more non-linearity) and robustness certification scalability (which prefers
more linearity), we propose a novel solution to strategically manipulate
neurons, by ""grafting"" appropriate levels of linearity. The core of our
proposal is to first linearize insignificant ReLU neurons, to eliminate the
non-linear components that are both redundant for DNN performance and harmful
to its certification. We then optimize the associated slopes and intercepts of
the replaced linear activations for restoring model performance while
maintaining certifiability. Hence, typical neuron pruning could be viewed as a
special case of grafting a linear function of the fixed zero slopes and
intercept, that might overly restrict the network flexibility and sacrifice its
performance. Extensive experiments on multiple datasets and network backbones
show that our linearity grafting can (1) effectively tighten certified bounds;
(2) achieve competitive certifiable robustness without certified robust
training (i.e., over 30% improvements on CIFAR-10 models); and (3) scale up
complete verification to large adversarially trained models with 17M
parameters. Codes are available at
https://github.com/VITA-Group/Linearity-Grafting.","Despite the prevailing successes of deep neural networks (DNNs), they remain vulnerable to adversarial exam ples (Szegedy et al., 2013). Therefore, certifying whether a DNN is provably robust under all bounded input pertur bations are crucial for adopting DNNs in highstake and safetycritical applications. To obtain nontrivial certiÔ¨Åed robust accuracy, certiÔ¨Åed adversarial defense (Raghunathan et al., 2018a; Wong & Kolter, 2018; Mirman et al., 2018; Gowal et al., 2018; Zhang et al., 2019b) which minimize a certiÔ¨Åable loss during training, and robustness veriÔ¨Åcation methods (Gehr et al., 2018; Dvijotham et al., 2018; Zhang et al., 2018; Wang et al., 2021) which compute tight cer tiÔ¨Åed bounds for posttraining networks serve as the most effective two approaches. However, several pain points persist for these two mecha nisms: (i) As DNNs grow larger (e.g., dozens of layers), (complete) veriÔ¨Åcation can be extremely timeconsuming and computationally expensive due to the massive non linearity in activation functions like ReLU. For ReLU net works under input perturbations, the ReLU neurons whose inputs may cross zero (referred to as ‚Äúunstable‚Äù neurons) are often the key factor to determine the difÔ¨Åculty of veriÔ¨Åca tion. Current solutions like linear relaxations (Zhang et al., 2018; Singh et al., 2019b), semideÔ¨Ånite relaxations (Raghu nathan et al., 2018b) or Branch and Bound (BaB) (Bunel et al., 2017; Wang et al., 2021) suffer from either trivially loose bounds or exponentially increased complexity for largescale networks. ( ii) Many certiÔ¨Åed robust training methods (Mirman et al., 2018; Gowal et al., 2018; Wong et al., 2018; Balunovic & Vechev, 2019) tend to reduce non linearity ( ‚Äúunstable‚Äù ReLU neurons) to improve certiÔ¨Åable robustness. For example, many certiÔ¨Åed defense approaches tend increase the number of ‚Äúinactive‚Äù neurons (ReLU neu rons with negative inputs and zero output) for tightening bounds (Shi et al., 2021). This often leads to reduced stan dard accuracy, and in order to stably train a network with certiÔ¨Åed defense, a much longer training schedule is often required: e.g., Xu et al. (2020a) used 2;000epochs and Zhang et al. (2019b) used 3;200epochs for training a con volutional neural network on CIFAR10 to stateoftheart certiÔ¨Åed performance, much longer than conventionally ad versarial training ( 100200epochs) (Madry et al., 2018).arXiv:2206.07839v1  [cs.LG]  15 Jun 2022Linearity Grafting: Relaxed Neuron Pruning Helps CertiÔ¨Åable Robustness To address these pain points, this paper proposes a brand new alternative, linearity grafting , to remarkably alleviate the burden of certiÔ¨Åcation, by strategically operating neu rons to control an appropriate level of nonlinearity on a pretrained network. Linearity grafting is inspired by neu ron pruning, which strategically removes a large portion of neurons in a network while maintaining its performance. However since we aim to enhance certiÔ¨Åability rather than reducing network size or computation, we can relax the typical pruning paradigm by exploiting the fact that certi Ô¨Åcation is easy for linear neurons. SpeciÔ¨Åcally, linearity grafting rst treats a pretrained model using adversarial training as the starting point which has good empirical ro bustness but usually undergoes poor certiÔ¨Åable robustness. Then , it replaces unstable yet insigniÔ¨Åcant ReLU neurons with a linear activation function, balancing the certiÔ¨Åcation scalability and network expressiveness. Lastly , the slope and intercept are further tuned to maintain competitive clas siÔ¨Åcation performance thanks to its enhanced representation power compared to inactive (completely pruned) ReLU neu rons. Note that vanilla neuron pruning is a special case of our proposal, where it grafts a Ô¨Åxed linear function of zero to unstable neurons, yet often ends up with worse perfor mance due to overrestriction. Our contributions can be summarized as follows: ‚Ä¢We pioneer a thorough investigation to reveal that intro ducing appropriate linearity beneÔ¨Åts certiÔ¨Åable robust ness in multiple aspects: ( 1) substantially shrinking the bounds and reducing the number of unstable ReLU neurons; ( 2) improving certiÔ¨Åcation scalability and en abling complete veriÔ¨Åcation on largescale networks; (3) obtaining competitive certiÔ¨Åed accuracy in a more efÔ¨Åcient manner without explicitly certiÔ¨Åed training. ‚Ä¢We propose a new algorithm, grafting , for trimming down the unnecessary nonlinearity for networks under veriÔ¨Åcation. It linearizes the unstable yet insigniÔ¨Åcant neurons by replacing the ReLU with a linear activation function, whose slope and intercept are subsequently optimized to achieve better model performance. ‚Ä¢Extensive experiments across diverse network architec tures on MNIST, SVHN, and CIFAR10, validate our proposal by demonstrating the superior certiÔ¨Åed accu racies (up to 82:30% improvements) without certiÔ¨Åed robust training . Furthermore, our grafted largescale networks with17M parameters reach competitive certiÔ¨Åed accuracy ( 32:30% at= 8=255) without us ing certiÔ¨Åed defense training. 2. Related Work "
124,Reliability Validation of Learning Enabled Vehicle Tracking.txt,"This paper studies the reliability of a real-world learning-enabled system,
which conducts dynamic vehicle tracking based on a high-resolution wide-area
motion imagery input. The system consists of multiple neural network components
-- to process the imagery inputs -- and multiple symbolic (Kalman filter)
components -- to analyse the processed information for vehicle tracking. It is
known that neural networks suffer from adversarial examples, which make them
lack robustness. However, it is unclear if and how the adversarial examples
over learning components can affect the overall system-level reliability. By
integrating a coverage-guided neural network testing tool, DeepConcolic, with
the vehicle tracking system, we found that (1) the overall system can be
resilient to some adversarial examples thanks to the existence of other
components, and (2) the overall system presents an extra level of uncertainty
which cannot be determined by analysing the deep learning components only. This
research suggests the need for novel verification and validation methods for
learning-enabled systems.","The widescale deployment of Deep Neural Networks (DNNs) in safetycritical applications, such as selfdriving cars, healthcare and Unmanned Air Vehicles (UA Vs), in creases the demand for tools that can test, validate, verify, and ultimately certify such systems [ 1]. Normally, autonomous systems, or more speciÔ¨Åcally learningenabled systems, con tain both datadriven learning components and modelbased nonlearning components [ 2], and a certiÔ¨Åcation needs to consider both categories of components, and the system as a whole. Structural code coverage combined with requirements coverage has been the primary approach for measuring test completeness as assurance evidence to support safety arguments, for the certiÔ¨Åcation of safetycritical software. Testing techniques for machine learning components, pri marily DNNs, are comparatively new and have only been actively developed in the past few years, e.g., [ 3], [4]. Unlike modelbased software systems, DNNs are usually considered as black boxes, and therefore it is difÔ¨Åcult to understand their behaviour by means of inspection. In [ 5], we developed a tool, DeepConcolic, to work with a number of extensions to the MC/DC coverage metric, targeting DNNs. The MC/DC coverage metric [ 6] is recommended in a number of certiÔ¨Åcation documents and standards, such as RTCA‚Äôs DO178C and ISO26262, for the development Youcheng Sun and Yifan Zhou contribute equally to this work. 1School of Electrical Engineering, Electronics and Computer Science, Queen‚Äôs University Belfast, UK 2School of Electrical Engineering, Electronics and Computer Science, University of Liverpool, UK 3Defence Science and Technology Laboratory (Dstl), UKof safety critical software. Its extension to DNN testing has been shown to be successful in testing DNNs by utilising whitebox testing methods, i.e., by exercising the known structure with the parameters of a DNN to gather assurance evidence. It is, however, unclear whether such a testing tool can still be effective when working with learning enabled systems containing both learning and modelbased components. Primarily, we want to understand the following two research questions: Q1Can the system as a whole be resilient against the deÔ¨Åcits discovered over the learning components? Q2Is there new uncertainty needed to be considered in terms of the interaction between learning and nonlearning components? The key motivation for considering Q1 is to understand whether, when generating a test suite, a DNN testing tool needs to consider the existence of other components in order to assess the safety of the system. The key motivation for considering Q2 is to understand whether a DNN testing tool can take advantage of the uncertainty presented in the interaction between learning and nonlearning components in generating test cases. SpeciÔ¨Åcally, for the learningenabled systems, we consider in this paper a tracking system in Wide Area Motion Imagery (WAMI) [ 7], where the vehicle detection is implemented by a few DNNs and the tracking is implemented with a Kalman Ô¨Ålter based method. Using this system, we consider its reliability when running in an adversarial environment, where an adversary can have limited access to the system by intercepting the inputs to the perception unit. Our experiments provide afÔ¨Årmative answers to the above research questions and point out the urgent need to develop systemlevel testing tools to support the certiÔ¨Åcation of learningenabled systems. II. P RELIMINARIES A (feedforward and deep) neural network Nis a function that maps an input xto an output. According to the tasks, the output can be of different format. For example, for classiÔ¨Åcation task, the DNN computes a label , which is denoted byN(x):label . Adversarial examples [8] are two very similar inputs with different labels. The existence of such pairs has been used as a proxy metric for the training quality of a DNN. Given an inputx1that is correctly labeled by a DNN N, another inputx2is said to be an adversarial example if x1andx2 are ‚Äúclose enough‚Äù, i.e., jjx1"
413,Plausibility Verification For 3D Object Detectors Using Energy-Based Optimization.txt,"Environmental perception obtained via object detectors have no predictable
safety layer encoded into their model schema, which creates the question of
trustworthiness about the system's prediction. As can be seen from recent
adversarial attacks, most of the current object detection networks are
vulnerable to input tampering, which in the real world could compromise the
safety of autonomous vehicles. The problem would be amplified even more when
uncertainty errors could not propagate into the submodules, if these are not a
part of the end-to-end system design. To address these concerns, a parallel
module which verifies the predictions of the object proposals coming out of
Deep Neural Networks are required. This work aims to verify 3D object proposals
from MonoRUn model by proposing a plausibility framework that leverages cross
sensor streams to reduce false positives. The verification metric being
proposed uses prior knowledge in the form of four different energy functions,
each utilizing a certain prior to output an energy value leading to a
plausibility justification for the hypothesis under consideration. We also
employ a novel two-step schema to improve the optimization of the composite
energy function representing the energy model.","Adversarial attacks on object detection networks are making the realworld de ployment of Neural Networks (NN) susceptible to safety violations, hindering the approval and conformance of vehicles to SOTIF standards. This is attributed mainly to the black box nature of NN themselves. Often the perception module, with the object detector at its core, plays a key part in situations where these errors occur. An object detector‚Äôs (OD) failure to perceive an object (e.g., an other car or a pedestrian crossing the street) can immediately result in an unsafe situation both for the vehicle‚Äôs passengers and other traffic participants. However, detections which are misclassified or falsely proposed by the OD also constitutes considerable risk under the Operational Design Domain (ODD) of an automated vehicle. These artifacts are called as ghost detections orfalse pos itives often appear due to perception gaps or sensor noises. False positives notarXiv:2211.05233v1  [cs.CV]  2 Nov 20222 Vivekanandan et al. only cause sudden jerks, contributing to an uncomfortable driving experience, but could also lead to rear end collisions when braking is applied without the need for it. Motivated by the dangers and risk posed, we propose to develop a parallel checker module following the architecture design of RunTime Assur ance (RTA) [6] tests. Through experiments, we extensively show that our module checks for the plausibility of an object (in this work we chose the category car) using combinations of energy functions, thereby significantly reducing the num ber of False Positives relative to the base NN. The energy functions are made up of simple priors, which conforms to our definition of world knowledge [23][25]. The base network under consideration is MonoRUn [5] which uses RGB images to predict 3D Bounding Boxes defining the position and orientation of an object, forming an initial hypothesis which needs to be checked for. As shown in Fig. 1, the checker modules (marked through dashed rectangle boxes) uses raw LiDAR point clouds and Camera streams with the assumption that the sensors are syn chronized accurately to provide valuable environmental information to different parts of the module. In summary, we: 1) Design a parallel checker module for plausibility checks for the outputs of a 3DOD network. 2) Propose a novel twostep optimization schema for composite energy function, which depends on 3D shape priors. 3) Developed computationally light rendering module to obtain 2D segmentation masks from the optimized 3D shape priors represented through the notation (y‚àó, z‚àó). 4) Finally, we propose a simple empirically evaluated threshold based False Positive filter with the help of an energybased model. 2 Related work "
288,DRLGENCERT: Deep Learning-based Automated Testing of Certificate Verification in SSL_TLS Implementations.txt,"The Secure Sockets Layer (SSL) and Transport Layer Security (TLS) protocols
are the foundation of network security. The certificate verification in SSL/TLS
implementations is vital and may become the weak link in the whole network
ecosystem. In previous works, some research focused on the automated testing of
certificate verification, and the main approaches rely on generating massive
certificates through randomly combining parts of seed certificates for fuzzing.
Although the generated certificates could meet the semantic constraints, the
cost is quite heavy, and the performance is limited due to the randomness. To
fill this gap, in this paper, we propose DRLGENCERT, the first framework of
applying deep reinforcement learning to the automated testing of certificate
verification in SSL/TLS implementations. DRLGENCERT accepts ordinary
certificates as input and outputs newly generated certificates which could
trigger discrepancies with high efficiency. Benefited by the deep reinforcement
learning, when generating certificates, our framework could choose the best
next action according to the result of a previous modification, instead of
simple random combinations. At the same time, we developed a set of new
techniques to support the overall design, like new feature extraction method
for X.509 certificates, fine-grained differential testing, and so forth. Also,
we implemented a prototype of DRLGENCERT and carried out a series of real-world
experiments. The results show DRLGENCERT is quite efficient, and we obtained
84,661 discrepancy-triggering certificates from 181,900 certificate seeds, say
around 46.5% effectiveness. Also, we evaluated six popular SSL/TLS
implementations, including GnuTLS, MatrixSSL, MbedTLS, NSS, OpenSSL, and
wolfSSL. DRLGENCERT successfully discovered 23 serious certificate verification
flaws, and most of them were previously unknown.","The Transport Layer Security (SSL) [ ?] and its predeces sor Transport Layer Security (TLS) [18] protocols are the foundation of network security. They are designed to provide security and data integrity assurance for Internet commu nications. During the SSL/TLS communication, the X.509 certiÔ¨Åcate is used to authenticate the identity of communi cating party. The semantics and syntax of X.509 certiÔ¨Åcates have many limitations, described semiformally in dozens of IETF‚Äôs RFCs (including RFC 2246[13], 2527[11], 2818[26], 4346[14], 5246[15], 5280[12], 6101[18], and 6125[27]). Verifying the validity of a certiÔ¨Åcate is a complex process that includes verifying each certiÔ¨Åcate in the certiÔ¨Åcate chain, checking period of validity, public key, extension, and so forth. There are many open source SSL/TLS implementations available online, and developers can use these implementations for certiÔ¨Åcate validation without implementing the code by themselves. However, since the certiÔ¨Åcate validation is com plicated, described in many tedious documents, the authors of SSL/TLS implementations may have their own understandings of how to code the logic. In other words, there is no guarantee that these SSL/TLS implementations can verify each certiÔ¨Åcate correctly, which may become the ‚Äúweak link‚Äù in the whole network ecosystem. Some researchers[9], [10] have noticed this issue and tried to achieve the automated testing of certiÔ¨Åcate veriÔ¨Åcation in SSL/TLS implementations. One of the mainstream approaches is the differential testing. If multiple certiÔ¨Åcate veriÔ¨Åcation codes give different veriÔ¨Åcation results for the same certiÔ¨Åcate, it means some of the certiÔ¨Åcate veriÔ¨Åcation codes may be Ô¨Çawed. In the differential testing, the effectiveness of test results is decided by the quality of input test cases (i.e., modiÔ¨Åed certiÔ¨Åcates) directly. Better test cases could discover more design Ô¨Çaws with less time consumption. In previous attempts, it is common to generate massive certiÔ¨Åcates (as test cases) through randomly combining parts of seed certiÔ¨Åcates, like Frankencert [9] and Mucert [10]. Although the generated certiÔ¨Åcates could meet the semantic constraints, the cost is quite heavy, and the performance is limited due to the randomness. It may generate a large number of unhelpful certiÔ¨Åcates which cannot trigger any Ô¨Çaw. On the other side, the deep learning technology shows the powerful capability of information mining and has been widely applied in biology, medicine, graphics, and cybersecurity, and so forth. We Ô¨Ånd the deep learning is suitable for the task of automated testing of certiÔ¨Åcate veriÔ¨Åcation. Our Approach. In this paper, we propose DRLgencert (using Deep Reinforcement Learning to generate certiÔ¨Åcates), thearXiv:1808.05444v1  [cs.CR]  16 Aug 2018Ô¨Årst framework on applying deep reinforcement learning to the automated testing of certiÔ¨Åcate veriÔ¨Åcation in SSL/TLS implementations. DRLgencert accepts ordinary certiÔ¨Åcates as input and outputs the newly generated certiÔ¨Åcates which could trigger discrepancies with high efÔ¨Åciency. BeneÔ¨Åted by the deep reinforcement learning, when generating certiÔ¨Åcates, our framework could choose the best next action according to the result of a previous modiÔ¨Åcation, instead of simple random combinations. At the same time, we developed a set of new techniques to support the overall design, like new feature ex traction method for X.509 certiÔ¨Åcates, Ô¨Ånegrained differential testing module, and so forth. In our research, we implemented DRLgencert and carried out a series of realworld experiments based on six popu lar SSL/TLS implementations, including GnuTLS [1], Ma trixSSL [3], mbedTLS [4], NSS [5], OpenSSL [6], and wolf SSL [7]. The overall performance analysis shows DRLgencert is quite efÔ¨Åcient, and we could obtain 84,661 discrepancy triggering certiÔ¨Åcates from 181,900 certiÔ¨Åcate seeds after the Ô¨Årst training episode of DRL network. It means more than 46.5% generated certiÔ¨Åcates are effective, which is better than all existing works. Also, DRLgencert successfully discovered 23 serious certiÔ¨Åcate veriÔ¨Åcation Ô¨Çaws on six implementations, and most of them were previously unknown. For example, we found GnuTLS, NSS, and OpenSSL accept version 1, 2, or 4 certiÔ¨Åcates, even these v1, v2, v4 certiÔ¨Åcates have v3 extensions that should only exist in version 3 certiÔ¨Åcate, which violates the RFC documents [12]. The reason is that the ver sion testing and extension testing functions are implemented as two independent components in code. We have reported all these Ô¨Çaws to the corresponding vendors, and the assessments are in process. Contributions. The main contributions of this paper are: New framework. We proposed DRLgencert, the Ô¨Årst framework on applying deep reinforcement learning to the automated testing of certiÔ¨Åcate veriÔ¨Åcation in SS L/TLS implementations. DRLgencert accepts normal cer tiÔ¨Åcates as input and outputs the newly generated certiÔ¨Å cates (as the test cases of differential testing) which could trigger discrepancies with high efÔ¨Åciency. New techniques. We developed a set of new techniques to enable the overall design of DRLgencert, including new feature extraction method for X.509 certiÔ¨Åcates, Ô¨Ånegrained differential testing, and improved certiÔ¨Åcate modiÔ¨Åcation actions. Implementation and Ô¨Åndings. We implemented a pro totype of DRLgencert and evaluated it through a se ries of realworld experiments. The overall performance analysis shows DRLgencert is quite efÔ¨Åcient, and we obtained 84,661 discrepancytriggering certiÔ¨Åcates from 181,900 certiÔ¨Åcate seeds. Also, DRLgencert successfully discovered 23 serious certiÔ¨Åcate veriÔ¨Åcation Ô¨Çaws on six popular SSL/TLS implementations, and most of them were previously unknown. tbsCertificate    version   serialNumber    signature    issuer    Validity (Not  Before /After )   subject    subjectPublicKeyInfo   issuerUniqueID    subjectUniqueID    extensions  signatureAlgorithm  signature tbsCertificate    version   serialNumber    signature    issuer    Validity (Not Before /After )   subject    subjectPublicKeyInfo   issuerUniqueID    subjectUniqueID    extensions  signatureAlgorithm  signature tbsCertificate    version   serialNumber    signature    issuer    Validity (Not Before /After )   subject    subjectPublicKeyInfo   issuerUniqueID    subjectUniqueID    extensions  signatureAlgorithm  signature  Leaf cert Intermediate CA cert Root CA certificateVersion 3Version 2Version 1Fig. 1. General certiÔ¨Åcate chain structure. Environment AgentState RewardAction Fig. 2. The process of reinforcement learning. Roadmap. The rest of this paper is organized as follows. Section II gives the background of certiÔ¨Åcate validation and deep reinforcement learning. Section III provides the overview design of DRLgencert. Section IV and Section V illustrate the differential testing module and deep reinforcement learning network module respectively. The evaluation results are sum marized in Section VI. Section VII reviews the related work, and Ô¨Ånally Section VIII concludes this paper. II. B ACKGROUND A. CertiÔ¨Åcate Validation CertiÔ¨Åcate validation usually requires two inputs: trusted CA certiÔ¨Åcates and a chain of certiÔ¨Åcates to be validated. The general structure of a certiÔ¨Åcate chain is shown in Figure 1. Starting from the leaf certiÔ¨Åcate (endentity certiÔ¨Åcate), each certiÔ¨Åcate is issued by a superior certiÔ¨Åcate until a selfsigned CA certiÔ¨Åcate. In the veriÔ¨Åcation process, the leaf certiÔ¨Åcate in the certiÔ¨Å cate chain is usually veriÔ¨Åed Ô¨Årst to conÔ¨Årm that the content of the certiÔ¨Åcate is valid, including the validity period and extension content. Then the SSL/TLS client checks whether the certiÔ¨Åcate is issued by a higherlevel certiÔ¨Åcate in the certiÔ¨Åcate chain, including verifying the issuer, signature, and extension content. This process continues recursively until the certiÔ¨Åcate to be veriÔ¨Åed appears in the trusted certiÔ¨Åcate set. B. Deep Reinforcement Learning Deep reinforcement learning is a combination of deep learning and reinforcement learning, which enables robots to learn independently. The initial achievement is the Deep Q Learning algorithm proposed by DeepMind in 2013 [24].In the Ô¨Åeld of artiÔ¨Åcial intelligence, an agent is used to represent a capable object, such as a robot, an unmanned vehicle, a person, and the like. The problem solved by re inforcement learning is to guide the interaction between the agent and environment. For example, playing a racing game on a computer, the game is the environment, and then we enter actions (keyboard operations) to control. What is observed on the screen is the state of the car and the score. The score is known as the reward, a factor in the reinforcement learning. No matter what kind of task, it contains a series of actions, observations, and feedback valuerewards. The observed information is the state of the agent. When the agent executes the action and interacts with the environment, the environment changes. The reward expresses the degree of good and bad caused by the change. Figure 2 illustrates the process of reinforcement learning. Reinforcement learning learns from previous states, actions, rewards to guide the choice of next action. Combining deep learning with reinforcement learning can handle more complex tasks. Deep reinforcement learning, through continuous training, can get a policy that makes an agent get as much reward as possible in the task. III. O VERVIEW OF DRL GENCERT In this paper, we propose DRLgencert, the Ô¨Årst deep learningbased testing framework for automatic certiÔ¨Åcate validation in SSL/TLS implementations. DRLgencert accepts normal certiÔ¨Åcates as input and outputs the newly generated certiÔ¨Åcates which could trigger discrepancies with high ef Ô¨Åciency. As shown in Figure 3, the DRLgencert framework consists of three main components: a certiÔ¨Åcate set ,the deep reinforcement learning network , and the differential testing module (containing multiple certiÔ¨Åcate veriÔ¨Åcation programs). A. Settings The reinforcement learning is a cyclic process in which an agent takes actions to change its state and interact with the environment to obtain a reward. In this process, the agent judges the merits and demerits of previous actions according to the reward given by the environment and obtains experience, so that the agent could choose a better behavior in the future same or similar state. In DRLgencert, we have the following settings: A certiÔ¨Åcate instance acts as an agent. Multiple SSL/TLS implementations are used as the envi ronment. The state is deÔ¨Åned as a certiÔ¨Åcate content feature. The action is deÔ¨Åned as a certiÔ¨Åcate modiÔ¨Åcation opera tion. The reward results from the validation results of multiple SSL/TLS implementations. B. Framework Overview DRLgencert starts to run from choosing a certiÔ¨Åcate in stance from the prepared certiÔ¨Åcate set. Before passing the certiÔ¨Åcate to the deep learning network, the differential testing(see Section IV) is performed on the original certiÔ¨Åcate(step1 in Ô¨Åg 3). If the test result shows that the certiÔ¨Åcate has reached the goal we want, namely, the certiÔ¨Åcate triggers a discrepancy(step7,8,2 in Ô¨Åg 3), there is no need to modify this certiÔ¨Åcate. Otherwise, we need to extract features from the certiÔ¨Åcate based on the predeÔ¨Åned feature extraction scheme(step3 in Ô¨Åg 3). The deÔ¨Ånition of certiÔ¨Åcate feature will be discussed in detail in Section VA later, respectively. The neural network uses the certiÔ¨Åcate feature as input(step4 in Ô¨Åg 3), and the output represents the modiÔ¨Åcation actions. Each number of the output represents the value of the corresponding modiÔ¨Åcation action. As mentioned in Section IIB, the deep reinforcement learning network learns the feedback coming from the agent interacting with the environment by taking actions. In DRLgencert, the certiÔ¨Åcate modiÔ¨Åcation actions are the actions taken by the deep reinforcement learning on certiÔ¨Åcates, and more details will be given in Section VB. During the training phase, we select the modiÔ¨Åcation action to be adopted based on the ""Greedy strategy. Each time we choose the most valuable modiÔ¨Åcation action with 90% probability and randomly select a modiÔ¨Åcation operation with 10% probability(step5 in Ô¨Åg 3). As an advantage, we could make sure that most modiÔ¨Åcation operations can achieve the desired effect and also allow some certiÔ¨Åcate to explore new combinations of modiÔ¨Åcation actions. In the testing phase of the neural network, we no longer need to explore new combinations of actions. Instead, we should guarantee the maximum validity of the modiÔ¨Åcation actions. Therefore, the certiÔ¨Åcate modiÔ¨Åcation action used during the usage phase is always the most valuable one in all modiÔ¨Åcation actions. After the certiÔ¨Åcate is modiÔ¨Åed, we obtain a new cer tiÔ¨Åcate. This newly generated certiÔ¨Åcate will be inputted to the differential testing for multiple certiÔ¨Åcate veriÔ¨Åcation programs(step6 in Ô¨Åg 3). After the differential testing, we obtained the veriÔ¨Åcation result set of each veriÔ¨Åcation pro gram. According to the predeÔ¨Åned reward deÔ¨Ånition scheme, the result is transformed to the corresponding reward(step7,8,9 in Ô¨Åg 3). The deÔ¨Ånition of reward will be given in Section VC. In the DRLgencert framework, we set the range of reward for 1 and 100. If reward = 100, it means that the certiÔ¨Åcate achieves the target we want. It will be collected into our target certiÔ¨Åcate database(step2 in Ô¨Åg 3). Its content and veriÔ¨Åcation result set may help us to analyze and discover possible Ô¨Çaws of certiÔ¨Åcate veriÔ¨Åcation implementations. Then choose a new certiÔ¨Åcate from database and a new loop begins(step12 in Ô¨Åg 3). However, if reward = 1, it indicates that, under our settings, this certiÔ¨Åcate has no value in analyzing certiÔ¨Åcate veriÔ¨Åcation implementations, and further change actions to the certiÔ¨Åcate content are required(step10 in Ô¨Åg 3). This process is described in Algorithm 1: In our DRLgencert framework, we set maxmodification (in Algorithm 1) to 9 and allow up to 10 changes per certiÔ¨Å cate, that is a maximum of 10 variants except for the initial certiÔ¨Åcate. If this certiÔ¨Åcate still cannot trigger a discrepancy, we will discard it and select a new one(step11 in Ô¨Åg 3). In our experiments, we found 95.5% of the certiÔ¨Åcates whichOpenssl Gnutls NSS ...Certificate  validation code Openssl Gnutls NSS ...Validation  results Discrepancies Verification  result  classificationDifferential testing Cert DB Choose  cert Cert Cert  feature Extractor Feature definition (Feature extraction rule ) Neural Network Action Action selection Cert‚Äô Both  ""valid "" and ""invalid ""  in  validation results Reward = 1 ( Unwanted Cert ) Number of  cert  modifications > Threshold Discrepancy  triggering   cert DB Reward =100 (Wanted cert ) Deep reinforcement learningDefect report 12 3 4 567 8 9 10 1112Fig. 3. Overview of DRLgencert framework. Algorithm 1 Modifying certiÔ¨Åcates Input:certDB;max episode;max modification Output:targetcertDB 1:episode 0 2:whileepisode<max episode do 3: forcert incertDB do 4:modification 0 5: whilemodification< =maxmodification do 6: action NETWORK (cert) 7: cert TAKE ACTION (cert;action ) 8: reward DIFFERENTIAL TESTING (cert) 9: ifreward == 100 then 10: addcert totargetcertDB 11: break 12: end if 13: modification modification + 1 14: end while 15: end for 16:episode episode + 1 17:end while 18:returntargetcertDB get reward = 100 were modiÔ¨Åed less than 6 times. Therefore, if a certiÔ¨Åcate undoubtedly has the potential to trigger a discrepancy, 10 times is enough to trigger a discrepancy. Through the above process, DRLgencert helps us quickly obtain a large number of certiÔ¨Åcates suitable for differential testing, based on the collected certiÔ¨Åcate data set.TABLE I VERIFICATION PROGRAMS AND SUPPORTED MODES Program Version CS ModeFile Mode (with veriÔ¨Åcation utility) GnuTLS 3.6.0 Y Y(certtool) MatrixSSL 3.9.3 Y Y(certValidate) MbedTLS 2.6.0 Y Y(cert app) NSS 3.28.4 Y Y(certutil) OpenSSL 1.0.2g Y Y(openssl) wolfSSL 3.12.2 Y / Remarks: The mode we used is labeled with bold Y. IV. D IFFERENTIAL TESTING Differential testing [23] (also known as differential fuzz testing) is a popular software testing technique that attempts to detect errors of a series of similar applications (or different implementations of the same application) by providing the same input and observing their execution differences. VeriÔ¨Åcation Program Setup. In DRLgencert, the initial cer tiÔ¨Åcates and modiÔ¨Åed certiÔ¨Åcates are both classiÔ¨Åed by six veriÔ¨Åcation programs, including GnuTLS [1], MatrixSSL [3], mbedTLS [4] (formerly PolarSSL), NSS [5], OpenSSL [6], and wolfSSL [7] (formerly CyaSSL). We used the latest versions of these programs (as listed in Table I) and deployed them on Ubuntu 16.04. Most of these veriÔ¨Åcation programs provide two veriÔ¨Åcation methods: CS mode and Ô¨Åle mode. The only exception is wolfSSL which only supports the CS mode. In the CS mode, the client establishes a connection with the server, receives thecertiÔ¨Åcate provided by the server, and validates it. Compared with the CS mode, the Ô¨Åle mode is more convenient. The program directly loads trust certiÔ¨Åcates and the certiÔ¨Åcate to be veriÔ¨Åed, then veriÔ¨Åes it. In both modes, when they need to verify a certiÔ¨Åcate, they call the same functions to verify. The veriÔ¨Åcation process is the same for both. However, because in the cs mode, the program needs to establish a connection between the client and server Ô¨Årst, the operation is more tedious, and the connection may fail due to network reasons and the certiÔ¨Åcate veriÔ¨Åcation section cannot be performed. In order to speed up the veriÔ¨Åcation process and avoid the veriÔ¨Åcation failure caused by the connection issue, we selected the Ô¨Åle mode as the certiÔ¨Åcate veriÔ¨Åcation method with a priority in DRLgencert. If the Ô¨Åle mode is not available, we used the CS mode. Table I shows the mode we selected in each program. VeriÔ¨Åcation Result Processing. Since each veriÔ¨Åcation pro gram has its own understanding of certiÔ¨Åcate veriÔ¨Åcation, it leads to different expressions for the same error. Also, the meanings of the same error code from different programs are usually diverse. The granularity of veriÔ¨Åcation results of different programs is not the same, and the veriÔ¨Åcation result sets are also different. Inspired by the work of Acer et al. [8], we designed a normalized solution to process the various veriÔ¨Åcation results. In details, we grouped the veriÔ¨Åcation results of each program encountered in our experiment into 16 categories, with a new error code, making it easy to redeÔ¨Åne the reward and analyze veriÔ¨Åcation codes. Table II shows the classiÔ¨Åcation of veriÔ¨Åcation results in our system and the number in the second column (‚ÄúError Code‚Äù) indicates the new encoding value of veriÔ¨Åcation results. Due to the diverse granularity, sometimes multiple veriÔ¨Åcation results from the same veriÔ¨Å cation program are classiÔ¨Åed into same result type. If there are any validation results that have not been encountered in previous experiments, they are uniformly grouped into the type of ‚Äúother error ‚Äù and reclassiÔ¨Åed into an appropriate result category in next experiment through the updated classiÔ¨Åcation policies. Each veriÔ¨Åcation program has its own understanding of the logic of certiÔ¨Åcate veriÔ¨Åcation. Therefore, different programs may give different veriÔ¨Åcation results for the same certiÔ¨Åcate, even giving the opposite results. If a certiÔ¨Åcate is given dif ferent veriÔ¨Åcation results (i.e., rejected for different reasons), it means that the validation logic of the involved veriÔ¨Åcation programs is different, and the logic of some programs may be Ô¨Çawed. As shown in the example of Figure 4, OpenSSL accepts the certiÔ¨Åcate, while other programs report different rejection reasons respectively. To our framework, this certiÔ¨Åcate sample has the value of analysis. In DRLgencert, if there exist both acceptance and rejection in the veriÔ¨Åcation results of a certiÔ¨Åcate, we deÔ¨Åne it as a discrepancy and record this certiÔ¨Åcate and its veriÔ¨Åcation results for later analysis. 2 2 4 7 110GnuTLS    MatrixSSL  MbedTLS NSSOpenSSL wolfSSL Cert Number: error code as in Table IIFig. 4. Example of result encoding. V. D EEPREINFORCEMENT LEARNING NETWORK The core part of DRLgencert is the deep reinforcement learning network, which is used to generate a large number of certiÔ¨Åcates suitable for differential testing. Compared with other popular deep learning algorithms (e.g., CNN and LSTM), deep reinforcement learning is un supervised, can learn from histories, and provide the optimal choice. The most famous deployment case is AlphaGo [28], every time it could select the optimal strategy based on the current situation. To be speciÔ¨Åc, we consider: sometimes the program is very sensitive to the changes in input content, just like the existence of adversarial examples [20] in image recognition Ô¨Åeld. That is, the image recognition program can correctly recognize a dog‚Äôs photo, but if you make minor changes to the photos, the human cannot distinguish between the difference before and after the two photos. However, the image recognition program may identify the modiÔ¨Åed image as other objects, such as cars, just because of multiple subtle superimposed changes on several certain pixels. To certiÔ¨Åcates, we think that the certiÔ¨Åcate also has such nature that the programs is very sensitive to content changes in certiÔ¨Åcates even the change is very small. It is unlikely that a onetime modiÔ¨Åcation makes a certiÔ¨Åcate get a different verify result, so the combination of multiple modiÔ¨Åcations is a better choice. Therefore, we chose deep reinforcement learning, as it can help us choose the best next action according to the result of a previous modiÔ¨Åcation. Based on the practical testing and our empirical knowledge, we deployed a threelayer neural network for DRLgencert. The concrete conÔ¨Åguration parameters are listed in Table III. According to the classic deÔ¨Ånition of Mnih et al. [24], the loss function in DRLgencert is deÔ¨Åned as Equation 1, in which: reward : Aftercert being changed to cert0,reward is gotten from differential testing. max(network (cert)): Using acert as input, it is the max value in output. max(network (cert0)): Usingcert0as input, it is the max value in output.  : It is a constant, between 0 and 1. We set it to 0.9 in our experiment. As shown in Figure 3, the neural network uses the certiÔ¨Åcate feature as input, and the output represents the modiÔ¨Åcation actions. The reward (from the differential testing result) deter mines whether further actions are required. In the following subsections, we will discuss the designs of feature, modiÔ¨Åca tion action, and reward respectively.TABLE II VERIFICATION RESULTS CLASSIFICATION VeriÔ¨Åcation Result Error Code GnuTLS MatrixSSL MbedTLS NSS OpenSSL wolfSSL Valid 1pppppp Unknown issuer 1p ppp Validity period error 2pppppp Parsing error 3pppp Version error 4pp p Algorithm error 5p Signature error 6pppp Subject/Issuer error 7pp Key usage error 8pp p Casic constraints error 9p Unknown critical extension 10p pp Chain error 11pp Self sign 12p Connection error 13p Other extension error 14p Other error 15 pindicates that the veriÔ¨Åcation result has been triggered by the program. indicates that multiple different veriÔ¨Åcation results are grouped into the category. TABLE III NETWORK CONFIGURATION PARAMETERS Layer Input Dimension Output Dimension Activation Function Layer 0: fully connected layer 101 100 ReLU Layer 1: fully connected layer 100 100 ReLU Layer 2: fully connected layer 100 86 / loss(cert) =( reward"
154,Simultaneous Face Hallucination and Translation for Thermal to Visible Face Verification using Axial-GAN.txt,"Existing thermal-to-visible face verification approaches expect the thermal
and visible face images to be of similar resolution. This is unlikely in
real-world long-range surveillance systems, since humans are distant from the
cameras. To address this issue, we introduce the task of thermal-to-visible
face verification from low-resolution thermal images. Furthermore, we propose
Axial-Generative Adversarial Network (Axial-GAN) to synthesize high-resolution
visible images for matching. In the proposed approach we augment the GAN
framework with axial-attention layers which leverage the recent advances in
transformers for modelling long-range dependencies. We demonstrate the
effectiveness of the proposed method by evaluating on two different
thermal-visible face datasets. When compared to related state-of-the-art works,
our results show significant improvements in both image quality and face
verification performance, and are also much more efficient.","In practical scenarios such as lowlight or nighttime conditions, one has to use thermal cameras for surveillance in order to detect and recognize faces. The acquired ther mal images of faces in such scenarios have to be matched with existing biometric datasets that contain visible face im ages. SigniÔ¨Åcant progress has been made by several works [5‚Äì7, 10, 11, 14, 40] to address the thermaltovisible cross spectrum face recognition problem. But existing works ex pect the thermal and visible face images to be of similar resolution. This is unlikely in realworld surveillance sys tems as humans are further away from cameras, thereby the region occupied by a face is much less when compared to an image in the visible face dataset. We illustrate the described issue in Figure 1. To address this, we introduce the task of 9781665437806/21/$31.00 ¬©2021 IEEE Figure 1. A typical thermal image [1]. Note that the captured im ages are of very lowresolution. In order to perform crossmodal face recognition, one needs to synthesize a highresolution visible face image from a lowresolution thermal face image. matching lowresolution (LR) thermal face images against highresolution (HR) visible face images. The large domain discrepancy between the thermal and visible images and the low resolution of the thermal im ages makes the introduced task quite challenging. To tackle it, we propose a hybrid network that augments an image conditional generative adversarial network (GAN) [8] with axialattention [31] layers. The generator synthesizes face images in the visible domain, which are then matched against a gallery of visible images using an offtheshelf face matching algorithm. Using selfattentionbased mod els [25, 30, 31] allows capturing the structural patterns of the face effectively, which is essential for tasks such as face veriÔ¨Åcation. However, standalone selfattention models re quire largescale datasets for training. Therefore, we de velop a hybrid network that makes use of both convolutions and selfattention layers to efÔ¨Åciently capture the local and global information, respectively. Additionally, augmenting our network with selfattention avoids the use of several stacked convolutional layers for modelling global depen dencies. This makes our network extremely parameter ef Ô¨Åcient without any reduction in performance. Although Di et al. [5] proposed a similar hybrid network, it doesn‚Äôt utiarXiv:2104.06534v2  [cs.CV]  7 Aug 2021Conv 1x1Multi Head Attn HeightMulti Head Attn WidthConv 1x1 + InputAxialattention block (a)xWV WK WQrqrkrvsoftmaxy y Positional   Embeddings Weights Matrix Multiplication Addition (b)Axialattention layer OutputFigure 2. (a) The residual axialattention block used in AxialGAN. (b) Axialattention layer, which is the basic building block of both height and width multihead attention modules in the axialattention block. lize positional information and multihead design that are essential for capturing spatial structures and a mixture of features, which we incorporate into our network. To the best of our knowledge, this is one of the Ô¨Årst works to pro pose a transformerbased GAN for face translation and face hallucination. We evaluate our approach on the ARLVTF dataset [24] and the polarimetric thermal face recognition dataset [6]. We compare the performance of our approach with stateof theart methods in thermaltovisible synthesis and also face hallucination. Our results show signiÔ¨Åcant performance im provements in both image quality and face veriÔ¨Åcation. Fur thermore, an ablation study is conducted to demonstrate the effectiveness of axialattention. Code is available at https://github.com/sam575/axialgan . 2. Related Work "
58,Differentiable Neural Architecture Learning for Efficient Neural Network Design.txt,"Automated neural network design has received ever-increasing attention with
the evolution of deep convolutional neural networks (CNNs), especially
involving their deployment on embedded and mobile platforms. One of the biggest
problems that neural architecture search (NAS) confronts is that a large number
of candidate neural architectures are required to train, using, for instance,
reinforcement learning and evolutionary optimisation algorithms, at a vast
computation cost. Even recent differentiable neural architecture search (DNAS)
samples a small number of candidate neural architectures based on the
probability distribution of learned architecture parameters to select the final
neural architecture. To address this computational complexity issue, we
introduce a novel \emph{architecture parameterisation} based on scaled sigmoid
function, and propose a general \emph{Differentiable Neural Architecture
Learning} (DNAL) method to optimize the neural architecture without the need to
evaluate candidate neural networks. Specifically, for stochastic supernets as
well as conventional CNNs, we build a new channel-wise module layer with the
architecture components controlled by a scaled sigmoid function. We train these
neural network models from scratch. The network optimization is decoupled into
the weight optimization and the architecture optimization. We address the
non-convex optimization problem of neural architecture by the continuous scaled
sigmoid method with convergence guarantees. Extensive experiments demonstrate
our DNAL method delivers superior performance in terms of neural architecture
search cost. The optimal networks learned by DNAL surpass those produced by the
state-of-the-art methods on the benchmark CIFAR-10 and ImageNet-1K dataset in
accuracy, model size and computational complexity.","Although convolutional neural networks have made great progress in various computer vision tasks, such as image classiÔ¨Åcation [1]‚Äì[4], object detection [5]‚Äì[7] and semantic segmentation [8]‚Äì[11], their deployment into many embedded applications, including robotics, selfdriving cars, mobile apps Manuscript received June 28, 2019and surveillance cameras, is hindered by the constrains of model size, latency and energy budget. A lot of approaches have been proposed to improve the efÔ¨Åciency of neural net works to handle those hardware constraints. These approaches can be divided into three categories: conventional model compression [12]‚Äì[14], lightweight network design [15]‚Äì[17] and automatic neural architecture search [18]‚Äì[20]. Thanks to the overparameterisation of deep neural networks, the conventional methods compress neural network models by different compression techniques, such as pruning [21], [22], network quantization [23], [24], tensor factorization [25], [26], and knowledge distilling [27]. The lightweight network is heuristically constructed by designing efÔ¨Åcient modules, including group convolutions, depthwise separable convolutions, shufÔ¨Çe operations, etc. Recently, in order to automatically explore the large design space, the NAS methods leverage reinforcement learning [18], [28], [29], evolutionary optimisa tion algorithm [19], [30], [31] and gradientbased method [20], [32], [33] for efÔ¨Åcient neural network search, achieving the stateoftheart recognition performance. However, these existing methods suffer from three problems. (1) Both the heuristic compression policy and lightweight mod ule design require domain expertise to explore the architecture space. However, the space is so large that such handcrafted methods cannot afford the architecture search cost. Due to the limitations imposed on the search space, the resulting neural networks are usually suboptimal. Moreover, these methods have to take the constraint of hardware resources into account. Unfortunately, the computational complexity makes it prohibitive to produce application and hardware speciÔ¨Åc models. (2) Previous NAS methods exploit reinforcement learning and evolutionary optimisation algorithms to automatically explore the discrete search space, thus achieving the stateoftheart recognition performance. However, such methods generate a large number of candidate neural architectures, more than 20,000 candidate neural networks across 500GPUs over 4 days in [34]. It is timeconsuming to train and evaluate them so as to guide the neural net architecture search. (3) The existing DNAS methods relax the problem to search discrete neural architectures to optimize the probability of stochastic supernets, and allow us to explore continuous search spaces by using gradientbased methods. However, some DNAS methods stillarXiv:2103.02126v1  [cs.LG]  3 Mar 2021MANUSCRIPT 2 require a few candidate neural architectures to identify the best candidate by sampling based on the probability distribution of learned architecture parameters [20]. To address these problems, we introduce a novel approach which converts the discrete optimisation problem into a contin uous one. This is achieved by proposing a differentiable neural architecture learning method to automatically search for the optimal neural network parameterised in terms of a continuous scaled sigmoid function. This is the Ô¨Årst work to apply the scaled sigmoid function to facilitate the search for efÔ¨Åcient neural networks to the best of our knowledge. SpeciÔ¨Åcally, for both conventional CNNs and stochastic supernets, we build a new channelwise module layer controlled by the scaled sigmoid function, which can be inserted into any existing neural architectures without any special design. This module relaxes the discrete space of neural architecture search by continuous architecture representation. By progressively reducing the smoothness of the scaled sigmoid function, the continuous optimization problem is gradually turned into the original architecture optimization problem. Thus, the optimal neural architecture can be learned by using gradientbased methods with few epochs, while guaranteeing the conver gence. No additional candidate neural networks are produced, signiÔ¨Åcantly improving the efÔ¨Åciency of neural architecture search. In order to avoid the interaction between the weight optimization and the architecture optimization, the network optimization is decoupled into the weight optimization and the architecture optimization. This also alleviates the vanishing gradient problem. After optimizing the neural architecture, we achieve its potential representation ability by Ô¨Ånetuning. Extensive experiments demonstrate that our DNAL method is applicable to conventional CNNs (e.g., VGG16 [2] and ResNet50 [3]), lightweight CNNs (e.g., MobileNetV2 [35]) and stochastic supernets (e.g., ProxylessNAS [36]), and achieves the stateoftheart performance on the classiÔ¨Åcation task on CIFAR10 [37] and ImageNet1K [38] in terms of model size, FLOPs, accuracy, and more importantly, search cost. Our contributions can be summarized as follows. We build a new standalone control module based on the scaled sigmoid function to enrich the neural network mod ule family to enable the neural architecture optimization. We relax the discrete architecture optimization problem into a continuous one and learn the optimal neural architecture by using gradientbased methods. Our DNAL method produces no candidate neural archi tectures but one, thus drastically improving the efÔ¨Åciency of neural architecture search. It is applicable to conventional CNNs, lightweight CNNs, and stochastic supernets for automated neural architecture learning. Extensive experiments conÔ¨Årm that our DNAL method achieves the stateoftheart performance on various CNN architectures, including VGG16, ResNet50, MobileNetV2, and ProxylessNAS, over the task of CIFAR10 and ImageNet1K classiÔ¨Åcation. The rest of this paper is organized as follows: We Ô¨Årst investigate the related work in Section II. We then present thedifferentiable neural architecture learning method in Section III. Subsequently, we demonstrate that our proposed DNAL method delivers superior performance through extensive experiments on various popular network models and datasets in Section V. We present an ablation study, which enhances the understanding of DNAL in Section VI. Finally, we draw the paper to a conclusion in Section VII. II. R ELATED WORK "
398,Modeling and Efficient Verification of Wireless Ad hoc Networks.txt,"Wireless ad hoc networks, in particular mobile ad hoc networks (MANETs), are
growing very fast as they make communication easier and more available.
However, their protocols tend to be difficult to design due to topology
dependent behavior of wireless communication, and their distributed and
adaptive operations to topology dynamism. Therefore, it is desirable to have
them modeled and verified using formal methods. In this paper, we present an
actor-based modeling language with the aim to model MANETs. We address main
challenges of modeling wireless ad hoc networks such as local broadcast,
underlying topology, and its changes, and discuss how they can be efficiently
modeled at the semantic level to make their verification amenable. The new
framework abstracts the data link layer services by providing asynchronous
(local) broadcast and unicast communication, while message delivery is in order
and is guaranteed for connected receivers. We illustrate the applicability of
our framework through two routing protocols, namely flooding and AODVv2-11, and
show how efficiently their state spaces can be reduced by the proposed
techniques. Furthermore, we demonstrate a loop formation scenario in AODV,
found by our analysis tool.","Applicability of wireless communications is rapidly growing from home net works to satellite transmissions due to their high accessibility and low cost. Wireless communication has a broadcasting nature, as messages sent by each node can be received by all nodes in its transmission ran ge, called local broadcast . Therefore, by paying the cost of one transmission, several nodes may receive the message, which leads to lower energy consumption for the sender and throughput improvement [CCH07]. Mobile ad hoc networks (MANETs) consist of several portable host s with no preexisting infrastructure, such as routersin wired networksor accesspoints in managed (infr astructure) wireless networks.In such net works, nodes can freely change their locations so the network top ology is constantly changing. For unicasting a message to a speciÔ¨Åc node beyond the transmission range of a nod e, it is needed to relay the message by Correspondence and oÔ¨Äprint requests to :ChristianeNotarmarco, SpringerVerlagLondon Limited, Sweetapple House, Catteshall Road, Godalming, Surrey GU7 3DJ, UK. email: chris@svl.co. uk2 Behnaz YouseÔ¨Å, Fatemeh Ghassemi, Ramtin Khosravi some intermediate nodes to reach the desired destination. Due to la ck of any predesigned infrastructure and global network topologyinformation, network functions such as r outing protocols are devised in a completely distributed manner and adaptive to topology changes. Topology de pendent behavior of wireless communica tion, distribution and adaptation requirements make the design of M ANET protocols complicated and more in need of modeling and veriÔ¨Åcation so that it can be trusted. For inst ance, MANET protocols like the Ad hoc On Demand Distance Vector (AODV) routing protocol [PB99] h as been evolved as new failure scenarios were experienced or errors were found in the protocol design [BO G02, NT15b, FVGH+13]. The actor model [Agh90, Hew77] has been introduced for the purp ose of modeling concurrent and dis tributed applications. It is an agentbased language introduced by Hewitt [Hew77], extended by Agha to an objectbased concurrent computation model [Agh90]. An actor model consists of a set of actors communicat ing with eachother throughunicasting asynchronousmessages.E achcomputation unit, modeled by an actor, has a unique address and mailbox. Messages sent to an actor are st ored in its mailbox. Each actor is deÔ¨Åned through a set of message handlers, called message servers , to specify the actor behavior upon processing of each message. In this model, message delivery is guaranteed but is n ot inorder. This policy implicitly ab stracts away from eÔ¨Äects of the network, i.e., delays over diÔ¨Äeren t routing paths, message conÔ¨Çicts, etc., and consequently makes it a suitable modeling framework for concurren t and distributed applications. Rebeca [SMSdB04] is an actorbased modeling language which aims to bridge th e gap between formal veriÔ¨Åcation techniques and the realworld software engineering of concurren t and distributed applications. It provides an operational interpretation of the actor model through a Java like syntax, which makes it easy to learn and use. Rebeca is supported by a robust model checking tool, nam ed Afra [afrb], which takes advantage of various reduction techniques [JSM+10, SS10] to make eÔ¨Écient veriÔ¨Åcationpossible. With the aim of reduc ing the state space, computations, i.e., executions of message serve rs in actors, are assumed to be instantaneous while message delivery is inorder. Consequently, instructions of me ssage servers are not interleaved and hence, execution of message servers becomes atomic in semantic m odel and each actor mailbox is modeled through a FIFO queue. In [YGK15] we introduced bRebeca as an extension to Rebeca, to su pport broadcast communication which abstracts the global broadcast communications [BG92]. To abstract the eÔ¨Äect of network, the order of receipts for two consequent broadcast communications is not n ecessarily the same as their corresponding sends in an actor model. Hence, each actor mailbox was modeled by a b ag. The resulting framework is suitable for modeling and eÔ¨Écient veriÔ¨Åcation of broadcasting proto cols above the network layer, but not appropriate for modeling MANETs in two ways: Ô¨Årstly the topology is n ot deÔ¨Åned, and every actor (node) can receive all messages, in other words all nodes are connected t o each other. Secondly, as there is no topology deÔ¨Åned, mobility is not concerned. In this paper, we extend the actorbasedmodeling languagebRebe ca [YGK15] to addresslocal broadcast, topology, and its changes. The aim of the current paper is to provid e a framework to detect malfunctions of a MANET protocol caused by conceptual mistakes in the protoc ol design, rather than by an unreliable communication. Therefore, the new framework abstracts away f rom the data link layer services by providing asynchronous reliable local broadcast, multicast, and unicast com munications [Pen08, SL04]. Since only onehop communications are considered, the message delivery is in order and is guaranteed for connected receivers.Consequently, eachactor mailboxis modeled througha q ueue. The reliable communicationservices of the data link layer provide feedback (to its upper layer application s) in case of (un)successful delivery. Therefore, our framework provides conditional unicast to model protocol behaviors in each scenario (in the semantic model, the status of the underlying topology deÔ¨Ånes the b ehavior of actors). The resulting framework provides a suitable means to model the beh avior of ad hoc networks in a compositional way without the need to consider asynchronous com munications handled by message storages in the computation model. However, to minimize the eÔ¨Äect of message storages on the growth of the state space, we exploit techniques to reduce it. Since nodes can communic ate through broadcast and a limited form of multicast/unicast, it is possible to consider actors that hav e the same neighbors and local states as identical according to the counter abstraction technique [BMWK09 , PXZ02, ET99]. Therefore, the states whose number of actors (irrespective of their identiÔ¨Åers) with the same neighbors and local state are the same for each local state value, will be aggregated, thus the stat e space is reduced considerably. The reduced semantics is strongly bisimilar to the original one. To examine resistance and adaptation of MANET protocols to chang es of the underlying topology, we address mobility via arbitrary changes of the topology at the seman tic level. Since network protocols have no control over movement of MANET nodes and mobility is an intrinsic cha racteristic of such nodes, the topol ogy should be implicitly manipulated at the semantics. In other words, with the aim of verifying behaviors ofModeling and EÔ¨Écient VeriÔ¨Åcation of Wireless Ad hoc Network s 3 MANET protocols for any mobility scenario, the underlying topology is arbitrarily changed at each semantic state. We provide mechanisms to restrict this random changes in th e topology through specifying constraints over the topology. However, these random changes make the sta te space grow exponentially while the pro posed counter abstraction technique becomes invalid. To this end, each state is instead explored for each possible topology and meanwhile topology information is removed from the state. Therefore, two next states only diÔ¨Äerent in their topologies are consolidated together and henc e, the state space is reduced considerably. Due to arbitrary changes of the underlying topology, states with d iÔ¨Äerent topologies are reachable from each other (through œÑtransitions denoting topology changes). We establish that such s tates are branching bisim ilar, and consequently a set of properties such as ACTLX [DV90] ar e preserved. The proposed reduction techniques makes our framework scalable to verify some important properties of MANET protocol, e.g., loop freedom, in the presence of mobility in a uniÔ¨Åed model (cf. generatin g a model for each mobility scenario). The contributions of this paper can be summarized as follows: ‚Ä¢We extend the computation model of the actor model, in particular R ebeca, with the concepts of MANETs, i.e., asynchronous reliable local broadcast/multicast/unic ast, topology, and topology changes; ‚Ä¢Weapply the counterabstractioninpresenceoftopologyasapart ofsemanticstates toreducestatespace substantially: actors with the same neighbors, i.e., topological situa tions, and local states are counted together in the counter abstraction technique; ‚Ä¢We show that the soundness of the counter abstraction techniqu e is not preserved in presence of mobility, and propose another technique to reduce the state space. ‚Ä¢We provide a tool that supports both reduction techniques and ex amines invariant properties automat ically. We illustrate the scalability of our approach through the speciÔ¨Å cation and veriÔ¨Åcation of two MANET protocols, namely Ô¨Çooding and AODV. ‚Ä¢We present a complete and accurate model of the core functionalit ies of a recent version of AODVv2 protocol (version 11), abstracting from its timing issues, and inve stigate its loop freedom property. We detectscenariosoverwhichthepropertyisviolatedduetomaintain ingmultipleunconÔ¨Årmednexthopsfor a route without checking them to be loop free. We have communicate d this scenario to the AODV group and they have conÔ¨Årmed that it can occur in practice. In response , their route information evaluation was modiÔ¨Åed, published in version 13 of the draft.1Furthermore, we verify the monotonic increase of sequence numbers and packet delivery properties using existing mo del checkers. Our framework can also be applied to Wireless Mesh Networks (WMNs) . Unlike MANETs, WSNs have a backbone of dedicated mesh routers along with mesh clients. Henc e, they provide Ô¨Çexibility in terms of mobility: in contrastto MANETs, the clients mobility has limited eÔ¨Äect on the overallnetworkconÔ¨Åguration, as the mesh routers are Ô¨Åxed [MKKAR06]. The paper is structured as follows. Section 2 brieÔ¨Çy introduces bRe beca, explain the idea behind the counter abstraction technique and its relation to symmetry reduc tion technique, and explains equivalence relations that validate our reduction techniques. Section 3 addres sesthe main modeling challengesof wireless networks. Section 4 presents our extension to bRebeca for mode ling MANETs. In Section 5, we generate the statespacecompactlywith the aim ofeÔ¨Écient modelchecking.Toillus tratethe applicabilityofourapproach, we specify the core functionalities of AODVv211 in Section 6. Then, in Section 7, we discuss the eÔ¨Éciency of our statespace generation over two cases studies: the AODV and the Ô¨Çoodingbased routing protocol. We illustrate our tool and possible analysis over the models through a ve riÔ¨Åcation of AODV. Finally, we review some related work in Section 8 before concluding the paper. 2. Preliminaries 2.1. bRebeca Rebeca [SMSdB04] is an actorbasedmodeling languageproposed fo r modeling and veriÔ¨Åcationof concurrent and distributed systems. It has a Javalike syntax familiar to softw are developers and it is also supported by a tool via an integrated modeling and veriÔ¨Åcation environment [afr b]. Due to its design principle it is possible to extend the core language based on the desired domain [SJ 11]. For example, diÔ¨Äerent extensions 1https://tools.ietf.org/html/draftietfmanetaodvv2 134 Behnaz YouseÔ¨Å, Fatemeh Ghassemi, Ramtin Khosravi 1reactiveclass MNode 2{ 3statevars 4{ 5 intmyi; 6 boolean done; 7} 9msgsrv initial (intj,boolean starter) 10 { 11 my i = j; 12 if(starter) { 13 done = true; 14 send(my i); 15 }else 16 done = false; 17 } 19 msgsrvsend(inti)20 { 21 if(i<myi){ 22 if(!done) { 23 done = true; 24 send(my i); 25 } 26 }else{ 27 my i = i; 28 done = true; 29 } 30 } 31} 32main 33{ 34 MNode n1(1, false); 35 MNode n2(2, false); 36 MNode n3(3, true); 37 MNode n4(4, false); 38} Fig. 1. An example in bRebeca: Maxalgorithm with 4 nodes have been introduced in various domains such as probabilistic system s [VK12], realtime systems [RSA+14], software product lines [SK13], and broadcasting environment [YGK1 5]. As in this paper we intend to extend bRebeca, we brieÔ¨Çy review its syntax and semantics. In bRebeca as well as in Rebeca, actors are the computation units o f the system, called rebecs (short for reactive objects), which are instances of the deÔ¨Åned reactive classes in the model. Rebecs communicate with each other only through broadcasting me ssage which is asynchronous. Every sent message eventually will be received and processed by its potential receivers. In Rebeca, the rebecs deÔ¨Åned as the known rebecs of a sender, the sender itself using the ‚Äúself‚Äù keyword, or the sen der of the message currently processed using the keyword ‚Äúsender‚Äù are co nsidered as the potential receivers. However, in bRebeca, it is assumed the network is fully connected and therefo re, all rebecs of a model constitute the potential receivers. In other words, a broadcast message is rec eived by all the nodes to which a sender has a (onehop/multihop) path. So, unlike Rebeca, there is no need for declaring the known rebecs in the reactive class deÔ¨Ånition. Due to unpredictability of multihop communications, the arrival order of messages must be considered arbitrary. Therefore, as the second diÔ¨Äerence wit h Rebeca, received messages are stored in an unordered bagin each node. Every reactive class has two major parts, Ô¨Årst the state variables to maintain the state of the rebec, and second the message servers to indicate the reactions of the rebec on received messages. The lo cal state of a rebec is deÔ¨Åned in terms of its state variables together with its mess age bag. Whenever a rebec receives a messagewhich hasno correspondingmessageservertorespond t o, it simply discardsthe message.Eachrebec has at least one message server called ‚Äúinitial‚Äù, which acts like a const ructor in objectoriented languages and performs the initialization tasks. A rebec is said to be enabledif and only if it has at least one message in its bag. The computation tak es place by removing a message from the bag and executing its corresp onding message server atomically, after which the rebec proceeds to process the other messages in its bag (if any). Processing a message may have the following consequences: ‚Ä¢it may modify the value of the state variables of the executing rebec , or ‚Ä¢some messages may be broadcast to other rebecs. Each bRebeca model consists of two parts, the reactive classes part and the mainpart. In the mainpart the instances of the reactive classes are created initially while their lo cal variables are initialized. As an example, Fig. 1 illustrates a simple max Ô¨Ånding algorithm modeled in b Rebeca, referred to as ‚ÄúMaxAlgorithm‚Äù [DK86]. Every node in a network contains an integer value and they intend to Ô¨Ånd the maximum value of all nodes in a distributed manner. The initial message server has a parameter, named starter. The rebec with the starter valuetrueinitiates the algorithm by broadcasting the Ô¨Årst message. Whenever a node receives a value from others, it compares this valu e with its current value and one of the following scenarios happens:Modeling and EÔ¨Écient VeriÔ¨Åcation of Wireless Ad hoc Network s 5 ‚Ä¢if it has not broadcast its value yet and its value is greater than the r eceived one, it broadcasts its value to others; ‚Ä¢if its current value is less than the received one, it gives up broadcas ting its value and updates its current value to the received one; ‚Ä¢if it has already sent its value, it only checks whether it must updates its value. This protocol does not work on MANETs as nodes give up to rebroad cast their value after their Ô¨Årst broadcast. The MaxAlgorithm should Ô¨Ånd the maximum value among t he connected nodes in MANETs. To this aim, if a node moves and connects to new nodes, it has to res end its value as its value may be the maximum value in the currently connected nodes. 2.2. Counter Abstraction Since model checking is the main approach of veriÔ¨Åcation in Rebeca, w e need to overcome statespace explosion, where the state space of a system grows exponentially a s the number of components in the system increases. One way to tackle this wellknown problem is through apply ing reduction techniques such as symmetry reduction [CEJS98] and counter abstraction [BMWK09, P XZ02, ET99]. Counter abstraction is indeed a form of symmetry reduction and, in case of full symmetry, it can be used to avoid the constructive orbit problem , according to which Ô¨Ånding a unique representative of each state is NPhard [CEJS98]. The idea of using counters and counter abstraction in model checking w as Ô¨Årst introduced in [ET99]. However, the term of counter abstraction was Ô¨Årst presented in [PXZ02] for the veriÔ¨Åcation of parameterize d systems and further used in diÔ¨Äerent studies such as [BMWK09, Kat11]. The idea of counter abstraction is to record the global state of a s ystem as a vector of counters, one per local state. Each counter denotes the number of component s currently residing in the corresponding local state. In our work, by‚Äúcomponents‚Äù we mean the actors of the system. This technique turns a model with an exponential size in n, i.e.mn, into one of a size polynomial in n, i.e./parenleftbigg n+m‚àí1 m/parenrightbigg , wherenandm denote the number of components and local states, respectively . Two global states SandS‚Ä≤are considered identical up to permutation if for every local state s, the number of components residing in sis the same in the two states SandS‚Ä≤, as permutation only changes the order of elements. For example, consider a system which consists of three components that each have only on e variable viof boolean type. Three global states (true,true,false), (false,true,true), and (true,false,true) are equivalent and can be abstracted into one global state represented as ( true: 2,false: 1). 2.3. Semantic Equivalence Strong bisimilarity [Plo81] is used as a veriÔ¨Åcation tool to validate the c ounting abstraction reduction technique on labeled transition systems. A labeled transition system (LTS), is deÔ¨Åned by the quadruple /a\}bracketle{tS,‚Üí,L,s0/a\}bracketri}htwhereSis a set of states, ‚Üí‚äÜS√óL√óSa set of transitions, La set of labels, and s0the initial state. Let sŒ±‚àí ‚Üítdenote (s,Œ±,t)‚àà‚Üí. DeÔ¨Ånition 2.1 (Strong Bisimilarity). A binary relation R ‚äÜS√óSis called a strong bisimilation if and only if, for any s1, s‚Ä≤ 1, s2, ands‚Ä≤ 2andŒ±‚ààL, the following transfer conditions hold: ‚Ä¢s1Rs2‚àßs1Œ±‚àí ‚Üís‚Ä≤ 1‚áí(‚àÉs‚Ä≤ 2‚ààS:s2Œ±‚àí ‚Üís‚Ä≤ 2‚àßs‚Ä≤ 1Rs‚Ä≤ 2), ‚Ä¢s1Rs2‚àßs2Œ±‚àí ‚Üís‚Ä≤ 2‚áí(‚àÉs‚Ä≤ 1‚ààS:s1Œ±‚àí ‚Üís‚Ä≤ 1‚àßs‚Ä≤ 1Rs‚Ä≤ 2). Twostates sandtarecalledstrongbisimilar,denotedby s‚àºt,ifandonlyifthereexistsastrongbisimulation relatingsandt. As explained in Section 1, mobility is addressed through random chang es of underlying topology at each semantic state, modeled by œÑtransitions. We propose to remove such transitions while the beha vior of each semantic state is explored for all possible topologies. We exploit bran ching bisimilarity [vGW96] to establish the reduced semantic is branching bisimilar to the original one. LetœÑ‚àí ‚Üí‚àóbe reÔ¨Çexive and transitive closure ofœÑtransitions:6 Behnaz YouseÔ¨Å, Fatemeh Ghassemi, Ramtin Khosravi ‚Ä¢tœÑ‚àí ‚Üí‚àót; ‚Ä¢tœÑ‚àí ‚Üí‚àós, andsœÑ‚àí ‚Üír, thentœÑ‚àí ‚Üí‚àór. DeÔ¨Ånition 2.2 (Branching Bisimilarity). A binary relation R ‚äÜS√óSis called a branching bisimilation if and only if, for any s1, s‚Ä≤ 1, s2, ands‚Ä≤ 2andŒ±‚ààL, the following transfer conditions hold: ‚Ä¢s1Rs2‚àßs1Œ±‚àí ‚Üís‚Ä≤ 1‚áí((Œ±=œÑ‚àßs‚Ä≤ 1Rs2)‚à®(‚àÉs‚Ä≤ 2,s‚Ä≤‚Ä≤ 2‚ààS:s2œÑ‚àí ‚Üí‚àós‚Ä≤‚Ä≤ 2Œ±‚àí ‚Üís‚Ä≤ 2‚àßs1Rs‚Ä≤‚Ä≤ 2‚àßs‚Ä≤ 1Rs‚Ä≤ 2)), ‚Ä¢s1Rs2‚àßs2Œ±‚àí ‚Üís‚Ä≤ 2‚áí((Œ±=œÑ‚àßs1Rs‚Ä≤ 2)‚à®(‚àÉs‚Ä≤ 1,s‚Ä≤‚Ä≤ 1‚ààS:s1œÑ‚àí ‚Üí‚àós‚Ä≤‚Ä≤ 1Œ±‚àí ‚Üís‚Ä≤ 1‚àßs‚Ä≤‚Ä≤ 1Rs2‚àßs‚Ä≤ 1Rs‚Ä≤ 2)). Two states sandtare called branching bisimilar, denoted by s‚âÉbrt, if and only if there exists a branching bisimulation relating sandt. 3. Modeling Topology and Mobility In this section, we discuss issues brought up by extending bRebeca to model and verify MANETs, and our solutions to overcome these challenges. We assume that the numbe r of nodes is Ô¨Åxed (to make the state space Ô¨Ånite as explained in [DSZ11]). 3.1. Network Topology and Mobility Every rebec represents a node in the MANET model. A node can comm unicate only with those located in its communication range, socalled connected . bRebeca does not deÔ¨Åne a ‚Äútopology‚Äù concept as the network graph is considered to be connected, all nodes are globally connect ed. Mobility is the intrinsic characteristic of MANET nodes. Furthermore , network protocols have no control over the movement of MANET nodes, and hence, topology changes cannot be speciÔ¨Åed as a part of the speciÔ¨Åcation. Additionally, to verify a protocol with respect to any mobility scenario, we need to consider all possible topology changes while constructing the state space. To t his end, we consider the topology as a part of the states and randomly change the underlying topology at the s emantic level. To this aim, a topology is modeled as an n√ónmatrix in each (global) state of the semantic model, where nis the number of nodes in the network. Each element of this matrix, denoted by ei,j, indicates whether nodeiisconnected tonodej (ei,j= 1) or not ( ei,j= 0). As the communication ranges of all nodes are assumed to be eq ual, connectivity is a bidirectional concept, and hence, the resulting matrix will be sym metric. The main diagonal elements are always 1 to make it possible for nodes to unicast messages to themse lves. (However, in the case of broadcast, our semantic rules prevent a node from receiving its own message, s ee Section 4.2). Changing the topology is considered an unobservable action, modeled by a œÑtransition, which alters the topology matrix. Hence, eachœÑtransition represents a set of (bidirectional) link setups/breakd owns in the underlying topology. To set up the initial topology of the network, the knownrebecs deÔ¨Ånitions, provided by the Rebeca language, is extended to address the connectivity of rebecs. Fig. 2a shows the communication range of the nodes in a simple network. To conÔ¨Ågure the initial topology of this net work,knownrebecs of each rebec should be deÔ¨Åned as shown in Fig. 2b during its instantiation (cf. Fig. 1 ). The corresponding semantic representation (as a part of the initial state) is shown in Fig. 2c. The connectivity matrix has n√ónelements which can be either 0 or 1, and since on the main diagonal we will exclusively have 1s, we have 2((n√ón)‚àín)/2possible topologies. For example, in a network of 4 nodes, we have 2(16‚àí4)/2= 26possible topologies. Considering all these topologies may lead to a sta tespace explosion. Hence, we provide a mechanism to limit the possible topologies by applyin g somenetwork constraints to characterize the set of topologies in terms of (dis)connectivity re lations to (un)pin a set of the links among the nodes. We use the notations con(i,j) or !con(i,j) to show that two nodes iandjare connected or disconnected, respectively, and and(C1,C1) to denote both C1andC2hold. For example, ! con(n1,n2) speciÔ¨Åes thatn1(n2) never gets connected to n2(n1), in other words, n1never enters into n2‚Äôs communication range, and vice versa. Therefore a topology Œ≥is called validfor the network constraint C, denoted as Œ≥/satisfiesC, if: Œ≥/satisfiescon(i,j)‚áîŒ≥i,j= 1 Œ≥/satisfiesand(C1,C2)‚áîŒ≥/satisfiesC1‚àßŒ≥/satisfiesC2 Œ≥/satisfies!con(i,j)‚áîŒ≥i,j= 0 Œ≥/satisfiestrue whereŒ≥i,jrepresents the element ei,jof the corresponding semantic model of Œ≥, andtruecharacterizes all possible topologies.Modeling and EÔ¨Écient VeriÔ¨Åcation of Wireless Ad hoc Network s 7 n3n2 n4 n1 (a) The networkMNoden1(n2,n3,n4) : (1,false) MNoden2(n1,n4) : (2,false) MNoden3(n1,n4) : (3,true) MNoden4(n2,n3,n1) : (4,false) (b)Syntactic deÔ¨Ånition duringinstantiationÔ£´ Ô£¨Ô£≠1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1Ô£∂ Ô£∑Ô£∏ (c) Semantic representation Fig. 2. A sample of an initial topology and its corresponding syntactic and semantic representations If the only valid topology of a network constraint is equal to the initia l topology, then the underlying topology will be static. This case can be useful for modeling WMNs with stable mesh routers with no mesh clients. 3.2. Restricted Delivery Guarantee The nature of communications in the wireless networks is based on br oadcast. The aim of the current paper is to provide a framework to detect malfunctions of a MANET protoc ol caused by conceptual mistakes in the protocol design, rather than by an unreliable communication. Therefore, we consider the wireless communications in our framework, namely local broadcast, multicas t, and unicast, to be asynchronous and reliable in order to abstract the data link layer services. In this way, we abstract the issues related to contention management and collision detection following the approac h of [KLN11]. This work abstracts the services of data link layer2with the aim to design/analyze MANET protocols irrespective to the n etwork radio model that implements them (its eÔ¨Äect is captured by three de lays functions). It provides reliable local broadcast communication, with timing guarantees on the wors tcase amount of time for a message to be delivered to all its recipients, total amount of time the sender receives its acknowledgment, and the amount of time for a receiver to receive some message among those currently being transmitted by its neighbors, expressed by delay functions . Therefore, our approach to specify protocols relying on the abs tract data link layer simpliÔ¨Åes the study of such protocols, and is valid as its r eal implementation with such reliable services exists [Pen08, SL04]. In these implementations, a no de can broadcast/multicast/unicast a message successfully only to the nodes within its communication ran ge. Therefore, message delivery is guaranteed for the connected nodes to the sender.In the caseof unicast, if the sender is located in the receiver communication range, it will be notiÔ¨Åed, otherwise it assumes that th e transmission was unsuccessful so it can react appropriately. Therefore, we extended bRebeca with conditional unicast so that it enables the model to react accordingly based on the status of underlying topo logy (which deÔ¨Ånes the delivery status in reliable communications). Sinceweonlyconsideronehopcommunications(incontrasttotheb roadcastinbRebeca),theassumption about the unpredictability of multihop communications (with diÔ¨Äeren t delays) is not valid anymore, and message storages in wRebeca are modeled by queues instead of bag s. 2Data link layer (the second layer of Open Systems Interconne ction (OSI) model) is responsible for transferring data acr oss the physical link. It consists of two sublayers: Logical Lin k Control sublayer (LLC) and Media Access Control sublayer ( MAC). LLC is mainly responsible for multiplexing packets to their protocol stacks identiÔ¨Åed by their IP addresses, while MAC m anages accesses to the shared media.8 Behnaz YouseÔ¨Å, Fatemeh Ghassemi, Ramtin Khosravi Model::= ReactiveClass+Main Main::=main{RebecDecl+ConstraintPart } List(X)::=/a\}bracketle{tX,/a\}bracketri}ht‚àóX|«´ RebecDecl ::=C R(List(R)) : (List( V)); ConstraintPart ::=constraint {Constraint } Constraint ::= ConstrainDec |! ConstrainDec |and(Constraint ,Constraint) ConstrainDec ::=con(R , R)|true ReactiveClass ::=reactiveclass C{StateVars MsgServer‚àó} StateVars ::=statevars {VarDecl‚àó} MsgServer ::=msgsrvM(List(T V)){Statement‚àó} VarDecl ::=T V; Statement ::= VarDecl |Assign|Conditional |Loop|Broadcast |Multicast |Unicast|break; Assign::=V=Expr; Conditional ::=if(Expr) BlockelseBlock Block::= Statement | {Statement‚àó} Loop::=while(Expr) Block Broadcast ::=M(List(Expr)); Multicast ::=multicast (V ,M(List(Expr))); Unicast::=unicast( Rec,M(List(Expr)))succ: Blockunsucc: Block Rec::=self|V Fig. 3. wRebeca language syntax: Angle brackets ( /a\}bracketle{t /a\}bracketri}ht) are used as metaparentheses. Superscript * indicates zero or more times repetition. The symbols C,R,T,M, andVdenote the set of classes, rebec names, types, method and variable names, respectively. The symbol Exprdenotes an expression, which can be an arithmetic or a boolean expression. 4. wRebeca: Syntax and Semantics In this section, we extend the syntax of bRebeca, introduced in Se ction 2.1, with conditional unicast and multicast,topologyconstraint,andknownrebecstosetuptheinit ialtopology.Next,weprovidethesemantics of wRebeca models in terms of LTSs. 4.1. Syntax The grammar of wRebeca is presented in Fig. 3. It consists of two ma jor parts: reactive classes and main part. The deÔ¨Ånition of reactive classes is almost similar to the one in bR ebeca. However, the main part is augmented with the ConstraintPart, where constraints are intr oduced to reduce all possible topologies in the network. The instances of the declared reactive classes are deÔ¨Åned in the main part, before the ConstraintPart, by indicating the name of a reactive class and an ar bitrary rebec name along with two sets of parenthesesdivided by the character:. The Ô¨Årst couple of pare nthesesis used to deÔ¨Åne the neighbors ofthe rebec in the initial topology. The second couple of parentheses is us ed to pass values to the initial message server. Rebecs here communicate through broadcast, multicast , and unicast. In the broadcast statement, we simply use the message server name along with its parameters with out specifying the receivers of a message. In contrast, when unicasting/multicasting a message, w e also need to specify the receiver/receivers of the message. However, there is no delivery guarantee, depend ing on the location of the receiver. In case of unicasting, the sender can react based on the delivery status. Letunicast(Rec,M(List(Expr))) indicate unicast(Rec,M(List(Expr)))succ:{}unsucc:{}when the delivery status has no eÔ¨Äect on the rebec behavior. In addition to communication statements, there are assignment, c onditional, and loop statements. TheModeling and EÔ¨Écient VeriÔ¨Åcation of Wireless Ad hoc Network s 9 1reactiveclass Node 2{ 3statevars 4{ 5 intIP; 6} 8msgsrv initial (boolean source,intip) 9{ 10 IP=ip ; 11 if(source== true) 12 relay packet(55,0,3); 13 } 15 msgsrvrelaypacket(intdata,inthopNum, int destination) 16 { 17 if(IP==destination) 18 unicast( self, deliver packet(data)); 19 else if(hopNum <3) 20 { 21 hopNum++;22 relay packet(data,hopNum,destination); 23 } 24 } 25 msgsrvdeliverpacket(intdata) 26 { 28 } 29} 31main 32{ 33 Node node0 (node1):( true,0); 34 Node node1 (node0,node2,node3):( false,1); 35 Node node2 (node1,node3):( false,2); 36 Node node3 (node1,node2):( false,3); 38 constraint 39 { 40 and( con(node0,node1),! con(node0,node2)) 41 } 42} Fig. 4. Flooding protocol in a network consisting of four nodes Ô¨Årst one is used to assign a value to a variable. The second is used to b ranch based on the evaluation of an expression: if the expression evaluates to true, then the ifpart, and otherwise the elsepart will be executed. Let if(Expr) Block denote if(Expr) Blockelse{ }. Finally, the third is used to execute a set of statements iteratively as long as the loop condition, i.e., the boolean e xpression Expr, holds. Furthermore, breakcan be used to terminate its nearest enclosing loop statement and t ransfer the control to the next statement. For the sake of readability, we use for(T x=Expr1;Expr2;Expr3){Statement‚àó}to denote T x=Expr1;while(Expr2){Statement‚àóExpr3}. A variable can be deÔ¨Åned in the scope of message servers as a statement similar to programming languages. A given wRebeca model is called wellformed if no state variable is redeÔ¨Åned in the scope of a message server, no two state variables, message servers or rebec classe s have identical names, identiÔ¨Åers of variables, message servers and classes do not clash, and all rebec instance a ccesses, message communications and variable accesses occur over declared/speciÔ¨Åed ones and the num ber and type of actual parameters correctly match the formal ones in their corresponding message server spe ciÔ¨Åcations. Each breakshould occur within a loop statement. Furthermore, the initial topology should satisfy the network constraint and be symmetric, i.e., ifn1is the known rebec of n2, thenn2should be the known rebec of n1. By default, the network constraint is trueif no network constraint is deÔ¨Åned, and all the nodes are disconnec ted if no initial topology is deÔ¨Åned. Example: The Ô¨Çooding protocol is one of the earliest methods used for routin g in wireless networks. The Ô¨Çooding protocol modeled in wRebeca is presented in Fig. 4. Every no de upon receiving a packet checks whether it is the packet‚Äôs destination. If so it processes the messa ge, otherwise it broadcasts the message to its neighbors. To reduce the number of transferred messages,e ach message contains a counter, called hopNum, which shows how many times it has been rebroadcast. If the hopNumis more than the speciÔ¨Åed bound, it quits rebroadcasting. 4.2. Semantics The formal semantics of a wellformed wRebeca is expressed as an L TS. In the following, we formally deÔ¨Åne thestates,transitions,andinitialstatesofthesemanticmodelg eneratedforagivenwRebecaspeciÔ¨Åcation.To this aim, the given speciÔ¨Åcation is decomposed into its constituent co mponents, i.e., rebec instances, reactive classes, initial topology, and network constraint represented by the wRebeca model M. The topology is implicitly changed as long as the given network constraint is satisÔ¨Åed. As explained in Section 1, message server executions are atomic and their statements are not interle aved. Intuitively, the global state of a10 Behnaz YouseÔ¨Å, Fatemeh Ghassemi, Ramtin Khosravi wRebeca model is deÔ¨Åned by the local states of its rebecs and the u nderlying topology. Consequently, a state transition occurs either upon atomic execution of a message server (i.e., when a rebec processes its corresponding message in its queue), or at a random change in the t opology (modeled through unobservable œÑtransitions). LetVdenote the set of variables ranged over by x, andValdenote the set of all possible values for the variables, ranged over by e. Furthermore, we assume that the set of types Tconsists of the integer and boolean data types, i.e., T={int,bool}. We consider the default value 0 ‚ààValfor the integer and boolean variables since the boolean values trueandfalsecan be modeled by 1 and 0 in the semantics, respectively. The variable assignment in each scope can be modeled by the valuation function V‚ÜíValranged over by Œ∏. An assignment can be extended by writing Œ∏‚à™{y/mapsto‚Üíe}. To monitor value assignments regarding scope management, we specify the set of all environments as Env=Stack(V‚ÜíVal), ranged over by œÖ. Let upd(œÖ,{y/mapsto‚Üíe}) extend the variable assignments of the current scope, i.e, the to p of the stack, by {y/mapsto‚Üíe} if the stack is not empty. Assume Stack() denotes an empty environment. By entering into a scope, the environment œÖis updated by push(Œ∏,œÖ) where Œ∏is empty if the scope belongs to a block (which will be extended by the declarations in the block). Upon exiting from the sc ope, it is updated by pop(œÖ) which removes the top of the stack. Let eval(expr,œÖ) denote the value of the expression exprin the context of environment œÖ, andœÖ[x:=e] the environment identical to œÖexcept that xis assigned to e. AssumeSeq(D) denotes the set of all sequences of elements in D; we use notations /a\}bracketle{td1...dn/a\}bracketri}htand«´for a nonempty and empty sequence, respectively. Note that the ele ments in a sequence may be repeated. A FIFO queue of elements of Dcan be viewed as a Seq(D). For instance, /a\}bracketle{t2 3 2 4/a\}bracketri}ht ‚ààSeq(N) denotes a FIFO queue of natural numbers where its head is 2. For a given FIFO queu ef:Seq(D), assume f ‚ä≤ddenotes the sequence obtained by appending dto the end of f, whiled‚ä≤fdenotes the sequence with head dand tailf. A wRebeca model is deÔ¨Åned through a set of reactive classes, rebe c instances, an initial topology, and a network constraint. Let Cdenote the set of all reactive classes in the model ranged over by c,Rthe set of rebec instances ranged over by r, andCthe set of network constraints ranged over by C. Assume Œì is the set of all possible topologies ranged over by Œ≥. Each reactive class cis described by a tuple c=/a\}bracketle{tVc,Mc/a\}bracketri}ht, where Vcis the set of class state variables and Mcthe set of message types ranged over by mthat its instances can respond to. We assume that for each class c, we have the state variable self‚ààVc, andc‚ààMcwhich can be seen as its constructor in objectoriented languages. For the sa ke of simplicity, we assume that messages are parameterized with one argument, so Msgc, whereMc=Val‚ÜíMsgcdeÔ¨Ånes the set of all messages that rebec instances of the reactive class ccan respond to. The formal parameter of a message can be acces sed byfm:Mc‚ÜíV. LetStatement denote the set of statements ranged over by œÉ,Œ¥(we useœÉ‚àó,Œ¥‚àóto denote a sequence of statements), and body:Mc‚ÜíSeq(Statement ) specify the sequence of statements executed by a message server. A block, denoted by Œ≤, is either deÔ¨Åned by a statement or a sequence of statements surrounded by braces. A rebec instance ris speciÔ¨Åed by the tuple /a\}bracketle{tc,e0/a\}bracketri}htwherec‚ààCis its reactive class, and e0deÔ¨Ånes the value passed to the message cwhich is initially put in the rebec‚Äôs queue. We assume a unique identiÔ¨Åer is assigned to each rebec instance. Let I={1...n}denote a Ô¨Ånite set of all rebec identiÔ¨Åers ranged over by i andj. Furthermore, we use rito denote the rebec instance rwith the assigned identiÔ¨Åer i. As explained in Section 2.1, a rebec in wRebeca, like Rebeca, holds its received messa ges in a FIFO queue (unlike bRebeca, in which messages are maintained in a bag). All rebecs of the model form a closed model, denoted by M=/a\}bracketle{t/bardbli‚ààIri,C,Œ≥0,C/a\}bracketri}ht, whereri=/a\}bracketle{tc,ei 0/a\}bracketri}htfor somec‚ààCandC ‚ààC. By default, C=trueand‚àÄi,j‚â§n(Œ≥0i,i= 1‚àß(i/\e}atio\slash=j‚áíŒ≥0i,j= 0)) if no network constraint and initial topology were deÔ¨Åned. The (global) state of t heMis deÔ¨Åned in terms of rebec‚Äôs local states and the underlying topology. DeÔ¨Ånition 4.1. The semantics of a wRebeca model M=/a\}bracketle{t/bardbli‚ààIri,C,Œ≥0,C/a\}bracketri}htis expressed by the LTS /a\}bracketle{tS,L,‚Üí ,s0/a\}bracketri}htwhere ‚Ä¢S‚äÜS1√ó...√óSn√óŒìisthe setofglobalstatessuchthat ( s1,...,s n,Œ≥)‚ààSiÔ¨ÄŒ≥/satisfiesC,andSi=Env√óFIFOi is the set of local states of rebec ri=/a\}bracketle{tc,ei 0/a\}bracketri}htwhereFIFOi=Seq(Msgc) models a FIFO queue of messages sent to the rebec ri. Therefore, each sican be denoted by the pair ( ŒΩi,fi). We use the dot notations si.ŒΩ andsi.fto access the environment and FIFO queue of the rebec i, respectively. ‚Ä¢L=Act‚à™{œÑ}is the set of labels, where Act=/uniontext c‚ààCMsgc; ‚Ä¢The transition relation ‚Üí‚äÜS√óL√óSis the least relation satisfying the semantic rules in Table 1; ‚Ä¢s0isthe initial state which isdeÔ¨Åned by the combinationofinitial stateso frebecsand the initial topology,Modeling and EÔ¨Écient VeriÔ¨Åcation of Wireless Ad hoc Network s 11 Table 1. wRebeca natural semantic rules Term:ŒΩi,f1,...,f n,«´‚ùÄŒ≥ŒΩi,f1,...,f n,‚ä§ Assign:ŒΩi,f1,...,f n,x:=expr;‚ùÄŒ≥ŒΩi[x:=eval(expr,ŒΩi)],f1,...,f n,‚ä§ VDecl:ŒΩi,f1,...,f n,T x;‚ùÄŒ≥upd(ŒΩi,{x/mapsto‚Üí0}),f1,...,f n,‚ä§ Block:push(‚àÖ,ŒΩi),f1,...,f n,œÉ‚àó‚ùÄŒ≥ŒΩ‚Ä≤ i,f‚Ä≤ 1,...,f‚Ä≤ n,Œ∂ ŒΩi,f1,...,f n,{œÉ‚àó}‚ùÄŒ≥pop(ŒΩ‚Ä≤ i),f‚Ä≤ 1,...,f‚Ä≤ n,Œ∂ Cond1:eval(expr,ŒΩi) =trueŒΩi,f1,...,f n,Œ≤1‚ùÄŒ≥ŒΩ‚Ä≤ i,f‚Ä≤ 1,...,f‚Ä≤ n,Œ∂ ŒΩi,f1,...,f n,if exprŒ≤1elseŒ≤2‚ùÄŒ≥ŒΩ‚Ä≤ i,f‚Ä≤ 1,...,f‚Ä≤ n,Œ∂ Cond2:eval(expr,ŒΩi) =falseŒΩi,f1,...,f n,Œ≤2‚ùÄŒ≥ŒΩ‚Ä≤ i,f‚Ä≤ 1,...,f‚Ä≤ n,Œ∂ ŒΩi,f1,...,f n,if exprŒ≤1elseŒ≤2‚ùÄŒ≥ŒΩ‚Ä≤ i,f‚Ä≤ 1,...,f‚Ä≤ n,Œ∂ Loop1:eval(expr,ŒΩi) =true ŒΩi,f1,...,f n,Œ≤‚ùÄŒ≥ŒΩ‚Ä≤ i,f‚Ä≤ 1,...,f‚Ä≤ n,‚ä§ ŒΩ‚Ä≤ i,f‚Ä≤ 1,...,f‚Ä≤ n,while(expr)Œ≤‚ùÄŒ≥ŒΩ‚Ä≤‚Ä≤ i,f‚Ä≤‚Ä≤ 1,...,f‚Ä≤‚Ä≤ n,‚ä§ ŒΩi,f1,...,f n,while(expr)Œ≤‚ùÄŒ≥ŒΩ‚Ä≤‚Ä≤ i,f‚Ä≤‚Ä≤ 1,...,f‚Ä≤‚Ä≤ n,‚ä§ Loop2:eval(expr,ŒΩi) =true ŒΩi,f1,...,f n,Œ≤‚ùÄŒ≥ŒΩ‚Ä≤ i,f‚Ä≤ 1,...,f‚Ä≤ n,‚ä• ŒΩi,f1,...,f n,while(expr)Œ≤‚ùÄŒ≥ŒΩ‚Ä≤ i,f‚Ä≤ 1,...,f‚Ä≤ n,‚ä§ Loop3:eval(expr,ŒΩi) =false ŒΩi,f1,...,f n,while(expr)Œ≤‚ùÄŒ≥ŒΩi,f1,...,f n,‚ä§ BCast:ŒΩi,f1,...,f n,m(expr);‚ùÄŒ≥ŒΩi,f‚Ä≤ 1,...,f‚Ä≤ n,‚ä§, where‚àÄk‚â§n(k/ne}ationslash=i‚àß(Œ≥i,k== 1)‚áí [f‚Ä≤ k=fk‚ä≤m(eval(expr,vi))][f‚Ä≤ k=fk]) MCast:ŒΩi,f1,...,f n,multicast (rcvs,expr);‚ùÄŒ≥ŒΩi,f‚Ä≤ 1,...,f‚Ä≤ n,‚ä§, where‚àÄk‚â§n(k‚ààrcvs‚àß(Œ≥i,k== 1)‚áí [f‚Ä≤ k=m(eval(expr,vi))‚ä≤fk][f‚Ä≤ k=fk]) UCast 1:(Œ≥i,j== 1) f‚Ä≤ j=fj‚ä≤m(eval(expr,vi))‚àß‚àÄk/\e}atio\slash=j(f‚Ä≤ k=fk) ŒΩi,f‚Ä≤ 1,...,f‚Ä≤ n,Œ≤1‚ùÄŒ≥ŒΩ‚Ä≤ i,f‚Ä≤‚Ä≤ 1,...,f‚Ä≤‚Ä≤ n,Œ∂ ŒΩi,f1,...,f n,unicast(j,m(expr))succ:Œ≤1unsucc:Œ≤2‚ùÄŒ≥ŒΩ‚Ä≤ i,f‚Ä≤‚Ä≤ 1,...,f‚Ä≤‚Ä≤ n,Œ∂ UCast 2:(Œ≥i,j== 0) ŒΩi,f1,...,f n,Œ≤2‚ùÄŒ≥ŒΩ‚Ä≤ i,f‚Ä≤ 1,...,f‚Ä≤ n,Œ∂ ŒΩi,f1,...,f n,unicast(j,m(expr))succ:Œ≤1unsucc:Œ≤2‚ùÄŒ≥ŒΩ‚Ä≤ i,f‚Ä≤ 1,...,f‚Ä≤ n,Œ∂ Seq1:ŒΩi,f1,...,f n,œÉ1‚ùÄŒ≥ŒΩ‚Ä≤ i,f‚Ä≤ 1,...,f‚Ä≤ n,‚ä§ŒΩ‚Ä≤ i,f‚Ä≤ 1,...,f‚Ä≤ n,œÉ‚àó 2‚ùÄŒ≥ŒΩ‚Ä≤‚Ä≤ i,f‚Ä≤‚Ä≤ 1,...,f‚Ä≤‚Ä≤ n,Œ∂ ŒΩi,f1,...,f n,œÉ1œÉ‚àó 2‚ùÄŒ≥ŒΩ‚Ä≤‚Ä≤ i,f‚Ä≤‚Ä≤ 1,...,f‚Ä≤‚Ä≤ n,Œ∂ Seq2:ŒΩi,f1,...,f n,break;œÉ‚àó‚ùÄŒ≥ŒΩi,f1,...,f n,‚ä• Handle:si.f=m(e)‚ä≤fi‚àß‚àÄk/\e}atio\slash=i(fk=sk.f) ŒΩi=push({fm(m)/mapsto‚Üíe},si.ŒΩ) ŒΩi,f1,...,f n,body(m)‚ùÄŒ≥ŒΩ‚Ä≤ i,f‚Ä≤ 1,...,f‚Ä≤ n,‚ä§ (s1,...,s n,Œ≥)m(e)‚àí ‚àí‚àí ‚Üí(s‚Ä≤ 1,...,s‚Ä≤ n,Œ≥), where‚àÄk/ne}ationslash=i(s‚Ä≤ k= (sk.ŒΩ,f‚Ä≤ k))‚àßs‚Ä≤ i= (pop(ŒΩ‚Ä≤ i),f‚Ä≤ i) Mov (s1,...,s n,Œ≥)œÑ‚àí ‚Üí(s1,...,s n,Œ≥‚Ä≤), whereŒ≥‚Ä≤|=C12 Behnaz YouseÔ¨Å, Fatemeh Ghassemi, Ramtin Khosravi i.e.,s0={(s1 0,...,sn 0,Œ≥0)},whereforthe rebec ri=/a\}bracketle{tc,ei 0/a\}bracketri}ht,si 0= (push(Œ∏0,stack()),/a\}bracketle{tc(ei 0)/a\}bracketri}ht) whichdenotes that the class variables (i.e., Vc) are initialized to the default value, denoted by Œ∏0, and its queue includes only the message c(ei 0), andŒ≥0/satisfiesC. To describe the semantics of transitions in wRebeca in Table 1, we exp loit an auxiliary transition rela tion‚ùÄŒ≥‚äÜ(Env√óFIFO1√ó...√óFIFOn√óSeq(Statement ))‚Üí(Env√óFIFO1√ó...√óFIFOn√ó{‚ä§,‚ä•}) to address the eÔ¨Äect of statement executions on the given environm ent of the rebec (which executes the state ments) and the queue of all rebecs. Upon execution, the stateme nts are either successfully terminated, denoted by ‚ä§, or abnormally terminated, denoted by ‚ä•. LetŒ∂range over {‚ä§,‚ä•}. RuleTermexplains that an empty statement terminates successfully. The eÔ¨Äect of an ass ignment statement, i.e., x:=expr;, is that the value of variable xis updated by eval(expr,ŒΩi) inŒΩias explained by the rule Assign. The variable declaration T x; extends the variable valuation corresponding to the current sco pe by the value assignment x/mapsto‚Üí0, where 0 is the default value for the types of T, as explained in the rule VDecl. The behavior of a block is expressed by the rule Block, based on the behavior of the statements (in its scope) on the env ironment push(‚àÖ,ŒΩi), where the empty valuation function may be extended by the decla rations in the scope (by rule VDecl). Thereafter, to Ô¨Ånd the eÔ¨Äect of the block, the last scope is pop ped from the environment. Rules Cond1,2specify the eÔ¨Äect of the ifstatement: If eval(expr,ŒΩi) evaluates to true, its eÔ¨Äect is deÔ¨Åned by the eÔ¨Äect of executing the ifpart, otherwise the elsepart. Rules Loop1‚àí3explain the eÔ¨Äect of the while statement; If the loop condition evaluates to true, the eÔ¨Äect of the whilestatement is deÔ¨Åned in terms of the eÔ¨Äect of its body by the rules Loop1,2, otherwise it terminates immediately as speciÔ¨Åed by the rule Loop3. If the body of the whilestatement terminates successfully, the eÔ¨Äect of the whilestatement is deÔ¨Åned in terms of the eÔ¨Äect of the whilestatement on the resulting environment and queues of its body exe cution as explained by Loop1. RuleLoop2expresses that if the body of the whilestatement terminates abnormally (due to a breakstatement) while its condition evaluates to true, then it terminates successfully while taking the eÔ¨Äect of its body execution into account. The eÔ¨Äect of a seque nce of statements is speciÔ¨Åed by the rules Seq1,2. Upon successful execution of a statement, the eÔ¨Äect of its nex t statements is considered (rule Seq1). Abreakstatement makes all its next statements be abandoned (rule Seq2). The expression b‚áí[C1][C2] in the postconditions of rules BCastandMCastabbreviates ( b‚áíC1)‚àß (¬¨b‚áíC2). The eÔ¨Äects of broadcast and multicast communications are spe ciÔ¨Åed by the rules BCastand MCast, respectively: the message m(eval(expr,ŒΩi)) is appended to the queue of all connected nodes to the sender in case of broadcast, and all connected nodes among t he speciÔ¨Åed receivers (i.e., rcvs) in case of multicast. Rules UCast 1,2express the eÔ¨Äect of unicast communication upon its delivery statu s. If the communication was successful (i.e., the sender was connected to t he receiver), the message is appended to the queue of the receiver while the eÔ¨Äect of the succpart is also considered (rule UCast 1), otherwise only the eÔ¨Äect of the unsuccpart is considered (rule UCast 2). The rule Handleexpresses that the execution of a wRebeca model progresses wh en a rebec processes the Ô¨Årst message of its queue. In this rule, the message m(e) is processed by the rebec riassi.f=m(e)‚ä≤fi. To process this message, its corresponding message server, i.e. body(m) is executed. The eÔ¨Äect of its execution is captured by the transition relation ‚ùÄŒ≥on the environment of ri, updated by the variable assignment {fm/mapsto‚Üíe}for the scope of the message server of m, and the queue of all rebecs while message m(e) is removed from the queue of ri. Finally, the rule MovspeciÔ¨Åes that the underlying topology is implicitly changed at the semantic level, and the new topology satisÔ¨Åes C. Example: Consider the global state ( s0,s1,s2,s3,Œ≥) such that s0= (({{IP/mapsto‚Üí0}},/an}bracketle{trelaypacket(55,0,3)/an}bracketri}ht),s1= ({{IP/mapsto‚Üí1}},«´),s2= ({{IP/mapsto‚Üí2}},«´),s3= ({{IP/mapsto‚Üí3}},«´), andŒ≥:Ô£´ Ô£¨Ô£≠1 1 0 0 1 1 1 1 0 1 1 0 0 1 0 1Ô£∂ Ô£∑Ô£∏)for the wRebeca model in Fig. 4 where{{IP/mapsto‚Üíi}}denotespush({IP/mapsto‚Üíi},Stack()). Regarding our rules, the following transition is derived: ŒΩ2,«´,«´,«´,«´, hopNum ++‚ùÄŒ≥ŒΩ3,«´,«´,«´,«´, ‚ä§ŒΩ3,«´,«´,«´,«´, rel(data,...)‚ùÄŒ≥ŒΩ3,«´,/an}bracketle{trel(55,1,3)/an}bracketri}ht,«´,«´,‚ä§ Seq1ŒΩ2,«´,«´,«´,«´, hopNum ++;rel(data,...)‚ùÄŒ≥ŒΩ3,«´,/an}bracketle{trel(55,1,3)/an}bracketri}ht,«´,«´,‚ä§ BlockŒΩ1,«´,«´,«´,«´, {hopNum ++;rel(data,...)}‚ùÄŒ≥ŒΩ4,«´,/an}bracketle{trel(55,1,3)/an}bracketri}ht,«´,«´,‚ä§: (‚àó) The following inference tree uses the result of the Ô¨Årst tree, deno ted by (‚àó), as a part of its premise to derive the transition.Modeling and EÔ¨Écient VeriÔ¨Åcation of Wireless Ad hoc Network s 13 eval(IP==des,ŒΩ1) =falseeval(hopNum <3,ŒΩ1) =true (‚àó) Cond 1ŒΩ1,«´,«´,«´,«´, if(hopNum <3)...‚ùÄŒ≥ŒΩ4,«´,/an}bracketle{trel(55,1,3)/an}bracketri}ht,«´,«´,‚ä§ Cond 2ŒΩ1,«´,«´,«´,«´, if(IP==...‚ùÄŒ≥ŒΩ‚Ä≤ 1,«´,/an}bracketle{trel(55,1,3)/an}bracketri}ht,«´,«´,‚ä§ Handle (s0,s1,s2,s3,Œ≥)rel(55,0,3)‚àí ‚àí‚àí‚àí‚àí‚àí‚àí‚àí ‚Üí (s‚Ä≤ 0,s‚Ä≤ 1,s2,s3,Œ≥) whereŒΩ1=push({data/mapsto‚Üí55,hopNum /mapsto‚Üí0,des/mapsto‚Üí3},{{IP/mapsto‚Üí0}}),ŒΩ2=push(‚àÖ,ŒΩ1),ŒΩ3=ŒΩ2[hopNum := 1], ŒΩ4=pop(ŒΩ3),ŒΩ‚Ä≤ 1=pop(ŒΩ4),s‚Ä≤ 0= ({{IP/mapsto‚Üí0}},«´), ands‚Ä≤ 1= ({{IP/mapsto‚Üí1}},/a\}bracketle{trel(55,1,3)/a\}bracketri}ht). Note that des denotesdestination ,andrelrefers torelaypacketmessage. By the rule Handle, the message rel(55,0,3) in the queue of node0is processed. To this aim, the body of its message server,i.e., if(IP==...is executed. Sinceeval(IP==des,ŒΩ1) =false, by the rule Cond2, theelsepart (i.e., if(hopNum <3)...) is executed. Due toeval(hopNum <3,ŒΩ1) =true, by the rule Cond1, theifpart is executed. 5. StateSpace Reduction We extend application of the counter abstraction technique to wRe beca models when the topology is static. Tothisend, thelocalstatesofrebecsandtheirneighborhoodsar econsidered.Later,weinspect thesoundness of the counter abstraction technique in the presence of mobility. A s a consequence, we propose a reduction technique based on removal of œÑtransitions. Recall that the topology is static when the only valid to pology of the network constraint is equal to the initial topology. 5.1. Applying Counter Abstraction AssumeScistheset oflocalstatesthatthe instancesofthe reactiveclass ccantake(i.e., Sc=Envc√óFIFOc) andIis the set of rebec identiÔ¨Åers. To apply counter abstraction, rebe cs with an identical local state and neighborsthatare topologically equivalent arecountedtogether.Twonodes i,j‚ààIaresaidtobetopologically equivalent, denoted by i‚âàŒ≥j, iÔ¨Ä‚àÄk‚ààI\{i,j}(Œ≥ik=Œ≥jk). Intuitively, two topologically equivalent nodes have the same neighbors (except themselves). So if either one bro adcasts, the same set of nodes (except themselves) will receive, and if they are also connected to each oth er, their counterpart (that is symmetric to the sender) will receive. Nodes in N ‚äÜIare called topologically equivalent iÔ¨Ä ‚àÄi,j‚àà N(i‚âàŒ≥j). This deÔ¨Ånition implies that all topologically equivalent nodes should be eit her all connected to each other, or disconnected, while they should have the same neighbors (excep t themselves). Therefore, topologically equivalent nodeswill aÔ¨Äect the samenodes when either one broadca sts.Hence, topologicallyequivalent nodes with an identical local state can be aggregated.To this aim, nodes o f the underlying topology are partitioned into the maximal sets of topologically equivalent nodes, denoted by N1,...,N‚Ñì. We deÔ¨Åne the set of distinct local states asSd=/uniontext c‚ààCSc, and the set of topology equivalence classes as T={N1,...,N‚Ñì}. Consequently, each global state ( s1,...,s n,Œ≥) is abstracted into a vector of elements ( sd i,Ni) :ciwheresd i‚ààSd,Ni‚ààT, andciis the number of nodes in the topology equivalence class Nithat reside in the very local state sd i. The reduced global state, called abstract global state , is presented as follows, where nandmdonate the number of all rebecs and distinct local states (i.e., m=/vextendsingle/vextendsingleSd/vextendsingle/vextendsingle), respectively: S= ((sd 1,N1) :c1,...,(sd k,Nk) :ck),‚àÄi‚â§k(ci>0‚àßNi‚ààT),k/summationdisplay i=1ci=n, k‚â§n For instance, nodes n1, n4, andn2, n3in Fig. 2a have the same neighbors, so if their state variables and queue contents are the same, then they can be counted togethe r. Recall that when the underlying topologyis static, a global state ma y only changeupon processinga mes sage by a rebec, since in wRebeca the bodies of message servers ex ecute atomically. Thus, its corresponding abstract global state may also only change upon processing a mess age by a rebec. Counting abstraction is beneÔ¨Åcial when the reactive classes do not have a variable that will be assigned uniquely to its instances, such as ‚Äúunique address‚Äù as a state varia ble. (Note that at the semantics, rebecs have identiÔ¨Åers which are not a part of their local states.) For exam ple, counter abstraction is not eÔ¨Äective on the speciÔ¨Åcation of the Ô¨Çooding protocol given in Fig. 4, since its nodes are identiÔ¨Åed uniquely by their IP addresses, and hence their state variables can not be collapsed. T herefore, to take beneÔ¨Åt of this abstraction, we revise the example in the way that nodes are not distinguished by t heir IP addresses. To this aim, the14 Behnaz YouseÔ¨Å, Fatemeh Ghassemi, Ramtin Khosravi 1reactiveclass Node 2{ 3statevars 4{ 5 boolean destination; 6} 8msgsrv initial (boolean source,boolean dest) 9{ 10 destination=dest; 11 if(source== true) 12 relay packet(55,1); 13 } 16 msgsrvrelaypacket(intdata,inthopNum) 17 { 18 if(destination== true) 19 unicast( self, deliver packet(data)); 20 else if(hopNum <2)21 { 22 hopNum++; 23 relay packet(data,hopNum); 24 } 25 } 26 msgsrvdeliverpacket(intdata) 27 { 29 } 30} 32main 33{ 34 Node node0 (node1):( true,false); 35 Node node1 (node0,node2,node3):( false,false); 36 Node node2 (node1,node3):( false,false); 37 Node node3 (node1,node2):( false,true); 39} Fig. 5. The revised version of the Ô¨Çooding protocol to make counte r abstraction applicable in a network consisting of four nodes (({{i/mapsto‚Üí1}},«´), ({{i/mapsto‚Üí2}},/a\}bracketle{tmsg/a\}bracketri}ht), ({{i/mapsto‚Üí1}},«´), ({{i/mapsto‚Üí0}},«´),Ô£´ Ô£¨Ô£≠1 1 0 1 1 1 1 0 0 1 1 1 1 0 1 1Ô£∂ Ô£∑Ô£∏) (a) Before applying counter abstraction((({{i/mapsto‚Üí1}},«´),{1,3}):{1,3}, (({{i/mapsto‚Üí2}},/a\}bracketle{tmsg/a\}bracketri}ht),{2,4}) :{2}, (({{i/mapsto‚Üí0}},«´),{2,4}):{4}) (b) After applying counter abstraction Fig. 6. An abstract global state and its corresponding transpose d global state: assume {{i/mapsto‚Üíe}}denotes push({i/mapsto‚Üíe},Stack()) . IPvariable is replaced by the boolean variable destination which identiÔ¨Åes the sink node, while the last parameter of the relaypacketmessage server is removed. The revised version is shown in Fig. 5. The reduction takes place ontheÔ¨Çy while constructing the state space. To this end, each global state (s1,...,s n,Œ≥) is transformed into the form (( sd 1,N1) :n1,(sd 2,N2) :n2,...,(sd k,Nk) :nk) such that ni‚äÜ Ni is the set of node identiÔ¨Åers that are topologically equivalent with the local state equal to sd i, whereNi‚ààT. This new presentation of the global state is called transposed global state . The sets niare leveraged to update the states of the potential receivers (known by the underlying to pology) when a communication occurs. To generate the abstract global states, each transposed global s tate is processed by taking an arbitrary node from the set assigned to a distinct local state and a topology equiva lence class if the distinct local state consists of a nonempty queue. The next transposed global stat e is computed by executing the message handler of the head message in the queue. This is repeated for all th e pairs of a distinct local state and a topology equivalence class of the transposed global state. After generating all the next transposed global states of a transposed state, the transposed state is transfo rmed into its corresponding abstract global state by replacing each niby|ni|. A transposed global state is processed only if its corresponding a bstract global state has not been previously computed. During statespace gen eration, only the abstract global states are stored. Fig. 6 illustrates a global state and its corresponding tran sposed global state. It is assumed that the network consists of four nodes of the reactive class with only one s tate variable iand message server msg. Each row in Fig. 6a represents a local state, i.e., valuation of the loca l state variable and message queue, while each row in Fig. 6b represents a distinct local state and a set of topologically equivalent identiÔ¨Åers together with those nodes of the set that reside in that distinct loc al state. As the topology is static, it can be removed from the abstract/transposed global states. Furthe rmore, each topology equivalence class of nodes can be represented by its unique representative, e.g., the one with the minimum identiÔ¨Åer. The following theorem states that applying counter abstraction pr eserves semantic properties of the model modulo strong bisimilarity. To this aim, we prove that states th at are counted together are strongModeling and EÔ¨Écient VeriÔ¨Åcation of Wireless Ad hoc Network s 15 N1({{des/mapsto‚ÜíF}},«´) N2({{des/mapsto‚ÜíF}},/a\}bracketle{trel/a\}bracketri}ht) N3({{des/mapsto‚ÜíF}},/a\}bracketle{trel/a\}bracketri}ht) N4 ({{des/mapsto‚ÜíT}},«´) (a) Topology 1N1({{des/mapsto‚ÜíF}},«´) N2 ({{des/mapsto‚ÜíF}},/a\}bracketle{trel/a\}bracketri}ht)N3({{des/mapsto‚ÜíF}},/a\}bracketle{trel/a\}bracketri}ht) N4 ({{des/mapsto‚ÜíT}},«´) (b) Topology 2and(con(N1,N2),and(con(N1,N3), and(con(N3,N4),and(!con(N1,N2), !con(N2,N3))))) (c) An example of network topology constraint Fig. 7. Two possible topologies for the given constraint on the Ô¨Çoodin g protocol bisimilar. For instance, the global state similar to the one in Fig. 6a exc ept that the distinct local states of nodes 2 and 4 are swapped, is mapped into the same abstract global state that corresponds to Fig. 6b. Theorem 5.1 (Soundness of Counter Abstraction). Assume two global states S1andS2such that for all pair of sd‚ààSdandN ‚ààT, the number of topologically equivalent nodes of Nthat have the distinct local state sdare the same in S1andS2. Then they are strongly bisimilar. Proof.Since the topologyis static, the onlytransitionsthese states have arethe result ofprocessingmessages in their rebec queues. Suppose S1m(e)‚àí ‚àí‚àí ‚ÜíS‚Ä≤ 1since there is a node iwith the local state ( ŒΩi,fi) in the topology equivalence class N, wherem(e) is the head of fiusing the semantic rule Handlein Table 1. Assume that i belongstothe topologicallyequivalentnodes N1‚äÜ N, where(( ŒΩi,fi),N) :N1isanelementofthe transposed global state corresponding to S1. Due to the assumption, there exist topologically equivalent nodes N2‚äÜ N inS2with the distinct local state ( ŒΩi,fi) where |N1|=|N2|. We choose an arbitrary node jinN2and prove that it triggers the same transition as i. We claim that ‚àÄ(sd k,N‚Ä≤), the number of nodes in the topology equivalence class N‚Ä≤that are a neighbor of i, denoted by nbi, and reside in the local state sd kis the same to the number of the nodes in the topology equivalence class N‚Ä≤that are a neighbor of j, denoted by nbj, with the local state sd k. Assume for the arbitrary transposed global state element ( sd l,N‚Ä≤‚Ä≤) this does not hold, and we consider the case where nbihas more topologically equivalent nodes than nbjin (sd l,N‚Ä≤‚Ä≤). As the links are bidirectional, due to the deÔ¨Ånition of abstract/transposed glo bal states, iis the neighbor of nodes in N‚Ä≤‚Ä≤. Furthermore, as the topology is the same for S1andS2andi,j‚àà N, thenjis also the neighbor of nodes inN‚Ä≤‚Ä≤. However, due to the assumption, the number of topologically equiv alent nodes of N‚Ä≤‚Ä≤inS1andS2 that have the distinct local state sd lare the same. So there are some topologically equivalent nodes of N‚Ä≤‚Ä≤ with the local state sd lthat are not in nbj, which contradicts to fact that jis the neighbor of nodes in N‚Ä≤‚Ä≤. As both iandjhandle the same message, they execute the same message server , and consequently the eÔ¨Äects on their own local state and their neighbors will be the same. Therefore, S2m(e)‚àí ‚àí‚àí ‚ÜíS‚Ä≤ 2while‚àÄ(sd o,N‚àó) the number of topologically equivalent nodes from the equivalence cla ssN‚àóinS‚Ä≤ 2that have the distinct local statesd ois the same to S‚Ä≤ 1. A similar argumentation holds when S2m(e)‚àí ‚àí‚àí ‚ÜíS‚Ä≤ 2while the inequality between nbiandnbjgoes the other way. As mentioned before, the reduction is only applicable if the network is static. This is due to the fact that if node neighborhoods may change, then nodes which are in the same equivalence class in some state may no longer be equivalent in the next state. Consider the Ô¨Çooding protoc ol (Fig. 5) for the two topologies shown in Fig. 7a and Fig. 7b (satisfying the network constraint in Fig. 7c). B y applying counter abstraction, nodes N2andN3are considered equivalent under topology 1, but not under topolog y 2. To illustrate that counter abstraction is not applicable to systems w ith a dynamic topology, Fig. 8 shows a part of the state space of the Ô¨Çooding protocol with a change in t he underlying topology (from Fig. 7a to Fig. 7b) with/without applying counter abstraction, where only t hese two topologies are possible. As predicted, the reduced state space is not strong bisimilar (see Sec tion 2.3 for the deÔ¨Ånition) to its original state space. During transposed global state generation, the ne xt state is only generated for node 2 with the distinct local state ( {{des/mapsto‚ÜíF}},/a\}bracketle{trel/a\}bracketri}ht) from the equivalence class {2,3}. Therefore, it is obvious that the next states in the left LTS of Fig. 8 can be matched to the states wit h the solid borders in the right LTS. However, the solid bordered states are not strong bisimilar to the d otted ones in the right LTS. As explained in Section 1, the reduced LTS should be strong bisimilar to its original o ne to preserve all properties of its original model.16 Behnaz YouseÔ¨Å, Fatemeh Ghassemi, Ramtin Khosravi (({{des/mapsto‚ÜíF}},«´), ({{des/mapsto‚ÜíF}},/a\}bracketle{trel/a\}bracketri}ht), ({{des/mapsto‚ÜíF}},/a\}bracketle{trel/a\}bracketri}ht), ({{des/mapsto‚ÜíT}},«´),Ô£´ Ô£¨Ô£≠1 1 1 0 1 1 0 1 1 0 1 1 0 1 1 1Ô£∂ Ô£∑Ô£∏) (({{des/mapsto‚ÜíF}},/a\}bracketle{trel/a\}bracketri}ht), ({{des/mapsto‚ÜíF}},«´), ({{des/mapsto‚ÜíF}},/a\}bracketle{trel/a\}bracketri}ht), ({{des/mapsto‚ÜíT}},/a\}bracketle{trel/a\}bracketri}ht),Ô£´ Ô£¨Ô£≠1 1 1 0 1 1 0 1 1 0 1 1 0 1 1 1Ô£∂ Ô£∑Ô£∏) (({{des/mapsto‚ÜíF}},/a\}bracketle{trel/a\}bracketri}ht), ({{des/mapsto‚ÜíF}},«´), ({{des/mapsto‚ÜíF}},/a\}bracketle{trel/a\}bracketri}ht), ({{des/mapsto‚ÜíT}},/a\}bracketle{trel/a\}bracketri}ht),Ô£´ Ô£¨Ô£≠1 1 1 0 1 1 0 0 1 0 1 1 0 0 1 1Ô£∂ Ô£∑Ô£∏) (({{des/mapsto‚ÜíF}},/a\}bracketle{trel,rel/a\}bracketri}ht), ({{des/mapsto‚ÜíF}},«´), ({{des/mapsto‚ÜíF}},«´), ({{des/mapsto‚ÜíT}},/a\}bracketle{trel,rel/a\}bracketri}ht),Ô£´ Ô£¨Ô£≠1 1 1 0 1 1 0 0 1 0 1 1 0 0 1 1Ô£∂ Ô£∑Ô£∏)(({{des/mapsto‚ÜíF}},/a\}bracketle{trel/a\}bracketri}ht), ({{des/mapsto‚ÜíF}},/a\}bracketle{trel/a\}bracketri}ht), ({{des/mapsto‚ÜíF}},«´), ({{des/mapsto‚ÜíT}},/a\}bracketle{trel/a\}bracketri}ht),Ô£´ Ô£¨Ô£≠1 1 1 0 1 1 0 1 1 0 1 1 0 1 1 1Ô£∂ Ô£∑Ô£∏) (({{des/mapsto‚ÜíF}},/a\}bracketle{trel/a\}bracketri}ht), ({{des/mapsto‚ÜíF}},/a\}bracketle{trel/a\}bracketri}ht), ({{des/mapsto‚ÜíF}},«´), ({{des/mapsto‚ÜíT}},/a\}bracketle{trel/a\}bracketri}ht),Ô£´ Ô£¨Ô£≠1 1 1 0 1 1 0 0 1 0 1 1 0 0 1 1Ô£∂ Ô£∑Ô£∏) (({{des/mapsto‚ÜíF}},/a\}bracketle{trel,rel/a\}bracketri}ht), ({{des/mapsto‚ÜíF}},«´), ({{des/mapsto‚ÜíF}},«´), ({{des/mapsto‚ÜíT}},/a\}bracketle{trel/a\}bracketri}ht),Ô£´ Ô£¨Ô£≠1 1 1 0 1 1 0 0 1 0 1 1 0 0 1 1Ô£∂ Ô£∑Ô£∏)rel œÑ relrel œÑ rel((({{des/mapsto‚ÜíF}},«´),{1,4}):{1}, (({{des/mapsto‚ÜíF}},/a\}bracketle{trel/a\}bracketri}ht),{2,3}) :{2,3}, (({{des/mapsto‚ÜíT}},«´),{1,4}):{4}) ((({{des/mapsto‚ÜíF}},/a\}bracketle{trel/a\}bracketri}ht),{1,4}) :{1}, (({{des/mapsto‚ÜíF}},«´),{2,3}):{2}, (({{des/mapsto‚ÜíF}},/a\}bracketle{trel/a\}bracketri}ht),{2,3}) :{3}, (({{des/mapsto‚ÜíT}},/a\}bracketle{trel/a\}bracketri}ht),{1,4}) :{4}) ((({{des/mapsto‚ÜíF}},/a\}bracketle{trel/a\}bracketri}ht),{1}) :{1}, (({{des/mapsto‚ÜíF}},«´),{2}) :{2}, (({{des/mapsto‚ÜíF}},/a\}bracketle{trel/a\}bracketri}ht),{3}) :{3}, (({{des/mapsto‚ÜíT}},/a\}bracketle{trel/a\}bracketri}ht),{4}) :{4}) ((({{des/mapsto‚ÜíF}},/a\}bracketle{trel,rel/a\}bracketri}ht),{1}) :{1}, (({{des/mapsto‚ÜíF}},«´),{2}) :{2}, (({{des/mapsto‚ÜíF}},«´),{3}) :{3}, (({{des/mapsto‚ÜíT}},/a\}bracketle{trel,rel/a\}bracketri}ht),{4}) :{4})rel œÑ rel Fig. 8. Comparing a part of the Ô¨Çooding protocol‚Äôs state space with/ without applying counter abstraction in a dynamic network. The two dashed bordered states are not str ong bisimilar since in the right Ô¨Ågure there is a global state in which only one node has two relmessages in its queue while in the left Ô¨Ågure there are two nodes with queues containing two relmessages. Note that T,Fstand for true,false,desdenotes destination ,andrelreferstorelaypacketmessages.Forsimplicity the messageparametersarenot shown in the Ô¨Ågure. To take a better advantage of the reduction technique, the mess age storages can be modeled as bags. However, such an abstraction results in more interleavings of mess ages which do not necessarily happen in reality, and hence, an eÔ¨Äort to inspect if a given trace (of the sema ntic model) is a valid scenario in the reality is needed. This eÔ¨Äort is only tolerable if the state space reduc es substantially. 5.2. Eliminating œÑTransitions Instead of modifying the underlying topology, modeled by œÑtransitions, messages can be processed with respect to all possible topologies (not only to the current underlyin g topology). Therefore, all œÑtransitions are eliminated and only those that correspond to processing of mes sages are kept. The following theorem expresses that removal of œÑtransitions and topology information from the global states pres erves properties of the original model modulo branching bisimulation, such as ACTLX [ DV90]. In fact, by exploiting a result from [DV90] about the correspondence between the equiva lence induced by ACTLX and branching bisimulation, the ACTLX fragments of CACTL [GAFM13], introduced t o specify MANET properties, and ¬µcalculus are also preserved. We show in Section 7.3 that important p roperties of MANET protocols can be still veriÔ¨Åed over reduced state spaces. Theorem 5.2 (Soundness of œÑTransition Elimination). ForthegivenLTS T0‚â° /a\}bracketle{tS√óŒì,‚Üí,L,(s0,Œ≥0)/a\}bracketri}ht, assume that ( s,Œ≥)Œ±‚àí ‚Üí(t,Œ≥‚Ä≤)‚áí(Œ≥=Œ≥‚Ä≤)‚à®(Œ±=œÑ‚àßs=t), and‚àÄŒ≥,Œ≥‚Ä≤‚ààŒì : (s,Œ≥)œÑ‚àí ‚Üí(s,Œ≥‚Ä≤). If T1‚â° /a\}bracketle{tS,‚Üí‚Ä≤,L,s0/a\}bracketri}ht, where‚Üí‚Ä≤={(s,Œ±,t)|((s,Œ≥),Œ±,(t,Œ≥))‚àà‚Üí}, then (s0,Œ≥0)‚âÉbrs0. Proof.Construct R={((s,Œ≥),s)|s‚ààS,Œ≥‚ààŒì}as shown in Figure 9. We show that Ris a branching bisimulation. To this aim, we show that it satisÔ¨Åes the transfer condit ions of DeÔ¨Ånition 2.2. For an arbitrary relation ( s,Œ≥)Rs, assume ( s,Œ≥)Œ±‚àí ‚Üí(t,Œ≥‚Ä≤). IfŒ±=œÑ, then two cases can be distinguished: (1) either Œ≥/\e}atio\slash=Œ≥‚Ä≤, and hence by deÔ¨Ånition of T0,s=tholds which concludes ( t,Œ≥‚Ä≤)Rs, (2) orŒ≥=Œ≥‚Ä≤and by deÔ¨Ånition of T1, sŒ± ‚àí ‚Üí‚Ä≤t, and (t,Œ≥‚Ä≤)Rt. IfŒ±/\e}atio\slash=œÑ, then by deÔ¨Ånition of T0,Œ≥=Œ≥‚Ä≤and hence by deÔ¨Ånition of T1,sŒ± ‚àí ‚Üí‚Ä≤t, andModeling and EÔ¨Écient VeriÔ¨Åcation of Wireless Ad hoc Network s 17 ss‚Ä≤ t rŒ± Œ≤ œás,Œ≥i s,Œ≥j s,Œ≥kœÑ œÑ œÑt,Œ≥jŒ≤s‚Ä≤,Œ≥iŒ± r,Œ≥kœá...œÑ...œÑ...œÑ T0 T1 Fig. 9. Relation Rmatches states ( s,Œ≥) ofT0tosofT1. [h]N1({{}},«´) N2 ({{}},«´)N3 ({{}},/a\}bracketle{tmsg/a\}bracketri}ht) (a) Topology Œ≥1N1({{}},«´) N2 ({{}},«´)N3 ({{}},/a\}bracketle{tmsg/a\}bracketri}ht) (b) Topology Œ≥2N1({{}},«´) N2 ({{}},«´)N3 ({{}},/a\}bracketle{tmsg/a\}bracketri}ht) (c) Topology Œ≥3 Fig. 10. All possible topologies considered during statespace gene ration of Fig. 11 (t,Œ≥‚Ä≤)Rt. Whenever sŒ± ‚àí ‚Üí‚Ä≤t, then by deÔ¨Ånition of T1there exists Œ≥‚Ä≤such that ( s,Œ≥‚Ä≤)Œ±‚àí ‚Üí(t,Œ≥‚Ä≤) and hence, (t,Œ≥‚Ä≤)Rt. Consequently Ris a branching bisimulation relation. We remark that the labeled transitions T0andT1in the Theorem 5.2 specify the state space of wRebeca models before and after elimination of œÑtransitions, respectively. As an example, consider a network whic h consistsofthreenodes,whicharetheinstancesofareactiveclas swithnostatevariableandonlyonemessage, msg. The message server msghas only one statement to broadcast the message msgto its neighbors. We assume that the set of all possible topologies is restricted by a netw ork constraint to the three topologies depicted in Fig. 10. Consider the global state in which only N3has onemsgin its queue. The state space of the above imaginary model before reduction is p resented in Fig. 11a, where transi tions take place by processing messages or changing the topology. Fig. 11b illustrates the state space after eliminating œÑtransitions and topology information. Connectivity information is r emoved from the global states, as in each state its transitions are derived for all possible t opologies. In this approach, transition labels are paired with the topology to denote the topologydepende nt behavior of transitions. The two tran sitions labeled with Œ≥2andŒ≥3can be merged by characterizing the links that make communication f rom N3toN1andN2; i.e., from the sender to the receivers. Such links can be character ized by the network constraints depicted in Fig. 11c. In this model, a state is represent ative of all possible topologies. The re sulting semantic model, called Constrained Labeled Transition System (CLTS), was introduced in [GFM11] as the semantic model to compactly model MANET protocols. Anoth er advantage of a CLTS is its model checker to verify topologydependant behavior of MANETs [GAFM1 3]. The properties in wireless networks are usually preconditioned to existence of a path between two nod es. This model checker takes beneÔ¨Åt of network constraints over transitions and assures a property ho lds if the required paths hold (inferred from the traversed network constraints).18 Behnaz YouseÔ¨Å, Fatemeh Ghassemi, Ramtin Khosravi (({{}},«´), ({{}},«´), ({{}},/a\}bracketle{tmsg/a\}bracketri}ht),/parenleftÔ£¨igg1 1 0 1 1 0 0 0 1/parenrightÔ£¨igg ) (({{}},«´), ({{}},«´), ({{}},/a\}bracketle{tmsg/a\}bracketri}ht),/parenleftÔ£¨igg1 1 1 1 1 1 1 1 1/parenrightÔ£¨igg )(({{}},«´), ({{}},«´), ({{}},/a\}bracketle{tmsg/a\}bracketri}ht),/parenleftÔ£¨igg1 0 1 0 1 1 1 1 1/parenrightÔ£¨igg )(({{}},«´), ({{}},«´), ({{}},«´),/parenleftÔ£¨igg1 1 0 1 1 0 0 0 1/parenrightÔ£¨igg ) (({{}},/a\}bracketle{tmsg/a\}bracketri}ht), ({{}},/a\}bracketle{tmsg/a\}bracketri}ht), ({{}},«´),/parenleftÔ£¨igg1 1 1 1 1 1 1 1 1/parenrightÔ£¨igg )(({{}},/a\}bracketle{tmsg/a\}bracketri}ht), ({{}},/a\}bracketle{tmsg/a\}bracketri}ht), ({{}},«´),/parenleftÔ£¨igg1 0 1 0 1 1 1 1 1/parenrightÔ£¨igg )œÑœÑmsgœÑ msgœÑ œÑ msgœÑ (a) State space before reduction (({{}},«´), ({{}},«´), ({{}},/a\}bracketle{tmsg/a\}bracketri}ht)) (({{}},/a\}bracketle{tmsg/a\}bracketri}ht), ({{}},/a\}bracketle{tmsg/a\}bracketri}ht), ({{}},«´))(({{}},/a\}bracketle{tmsg/a\}bracketri}ht), ({{}},/a\}bracketle{tmsg/a\}bracketri}ht), ({{}},«´))(({{}},«´), ({{}},«´), ({{}},«´))Œ≥2:msgŒ≥1:msgŒ≥3:msg (b) Reduced State space after eliminating œÑtransitions and topology information(({{}},«´), ({{}},«´), ({{}},/a\}bracketle{tmsg/a\}bracketri}ht)) (({{}},/a\}bracketle{tmsg/a\}bracketri}ht), ({{}},/a\}bracketle{tmsg/a\}bracketri}ht), ({{}},«´)) (({{}},«´), ({{}},«´), ({{}},«´))and(con(N3,N1), con(N3,N2)) :msgand(!con(N3,N1), !con(N3,N2)) :msg (c) Reduced state space with labels characterized by networ k constraints Fig. 11. State space before and after applying reduction 6. Modeling the AODVv2 Protocol To illustrate the applicability of the proposed modeling language, the A ODVv23(i.e., version 11) protocol is modeled. The AODV is a popular routing protocol for wireless ad hoc n etworks, Ô¨Årst introduced in [PB99], and later revised several times. Inthis algorithm,routesareconstructeddynamicallywheneverre quested.Everynode hasits own routing table to maintain information about the routes of the received pack ets. When a node receives a packet (whether it is a route discovery or data packet), it updates its own routing table to keep the shortest and freshest path to the source or destination of the received packe t. Three diÔ¨Äerent tables are used to store information about the neighbors, routes and received messages: ‚Ä¢neighbor table: keeps the adjacency states of the node‚Äôs neighbo rs. The neighbor state can be one of the following values: ‚ÄìConÔ¨Årmed: indicates that a bidirectional link to that neigh bor exists. This state is achieved either through receiving a rrep message in response to a previously sent rreq message, or a RREP Ack message as a response to a previously sent rrep message (requ ested an RREP Ack) to that neighbor. ‚ÄìUnknown: indicates that the link to that neighbor is current ly unknown. Initially, the states of the links to the neighbors are unknown. ‚ÄìBlacklisted: indicates that the link to that neighbor is uni directional. When a node has failed to receive the RREP Ack message in response to its rreq message to that neighbour , the neighbor state is changed to blacklisted. Hence, it stops forwarding any message to it for an amount of time, ResetTime. After reaching the ResetTime, the neighbor‚Äôs state will be set to u nknown. ‚Ä¢route table: contains information about discovered routes and th eir status: The following information is maintained for each route: ‚ÄìSeqNum: destination sequence number ‚Äìroutestate: the state of the route to the destination which can hav e one of the following values: 3https://tools.ietf.org/html/draftietfmanetaodvv2 11Modeling and EÔ¨Écient VeriÔ¨Åcation of Wireless Ad hoc Network s 19 ¬∑unconÔ¨Årmed : when the neighbor state of the next hop is unknown; ¬∑active: when the link to the next hop has been conÔ¨Årmed, and the route is currently used; ¬∑idle: when the link to the next hop has been conÔ¨Årmed, but it has not been used in the last AC TIVEINTERVAL; ¬∑invalid: when the link to the next hop is broken, i.e., the neighbor st ate of the next hop is blacklisted. ‚ÄìMetric: indicates the cost or quality of the route, e.g., hop count, the number of hops to the destination ‚ÄìNextHop: IP address of the next hop to the destination ‚ÄìPrecursors (optional feature): the list of the nodes intere sted in the route to the destination, i.e., upstream neighbors. ‚Ä¢route message table, also known as RteMsg Table : contains information about previously received route messages such as rreqandrrep, so that we can determine whether the new received message is wor th processing or redundant. Each entry of this table contains the fo llowing information: ‚ÄìMessageType: which can be either rreq or rrep ‚ÄìOrigAdd: IP address of the originator ‚ÄìTargAdd: IP address of the destination ‚ÄìOrigSeqNum: sequence number of the originator ‚ÄìTargSeqNum: sequence number of the destination ‚ÄìMetric When one node, i.e., source, intends to send a package to another, i.e., destination, it looks up its routing table for a valid route to that destination, i.e., a route of which the ro ute state is not invalid. If there is no such a route, it initiates a route discovery procedure by broadc asting a rreqmessage. The freshness of the requested route is indicated through the sequence number of the destination that the source is aware of. Whenever a node initiates a route discovery, it increases its own seq uence number, with the aim to deÔ¨Åne the freshness of its route request. Every node upon receiving th is message checks its routing table for Ô¨Ånding a route to the requested destination. If there is such a path or th e receiver is in fact the destination, it informs the sender through unicasting a rrepmessage. However, an acknowledgment is requested whenever the neighbor state of the next hop is unconÔ¨Årmed . Otherwise, it rebroadcasts the rreqmessage to examine if any of its neighbors has a valid path. Meanwhile, a reverse forward ing path is constructed to the source over which rrepmessages are going to be communicated later. In case a node receiv es arrepmessage, if it is not the source, it forwards the rrepafter updating its routing table with the received route information . Whenever a node fails to receive a requested RREPAck, it uses a rerrmessage to inform all its neighbors intended to use the broken link to forward their packets. In our model, each node is represented through a rebec (actor), identiÔ¨Åed by an IP address, with a routing table and a sequence number ( sn). In addition, every node keeps track of the adjacency status t o its neighbors by means of a neighbor table, through the neighstatearray, where neighstate[i] =trueindicates that it is adjacent to the node with the IP address i, whilefalseindicates that its adjacency status is either unknown orblacklisted (since timing issues are not taken into account, these two statuse s are considered the same). As the destinations of any two arbitrary rows of a routing t able are always diÔ¨Äerent, the routing table has at most nrows, where nis the number of nodes in the model. Therefore, the routing table is m odeled by a set of arrays, namely, dsn,routestate,hops,nhops, andpres, to represent the SeqNum,routestate, Metric,NextHop , andPrecursors columns of the routing table, respectively. The arrays dsnandroutestate are of size n, while the arrays hops,nhops, andpersare of size n√ón. For instance, dsn[i], keeps the sequence number of the destination with IP address i, whilenhops[i][j] contains the next hop of the jth route to the destination with the IP address i. ‚Ä¢dsn: destination sequence number ‚Ä¢routestate: an integer that refers to the state of the route to the destinat ion and can have one of the following values: ‚Äìroutestate[i] = 0: the route is unconÔ¨Årmed , there may be more than one route to the destination i with diÔ¨Äerent next hops and hop counts;20 Behnaz YouseÔ¨Å, Fatemeh Ghassemi, Ramtin Khosravi ‚Äìroutestate[i] = 1: the route is valid, the link to the next hop has been conÔ¨Årmed, the route state in the protocol is either activeoridle; since we abstract from the timing issues, these two states are depicted as one; ‚Äìroutestate[i] = 2: the route is invalid, the link to the next hop is broken; ‚Ä¢hops: the number of hops to the destination for diÔ¨Äerent routes ‚Ä¢nhop: IP address of the next hop to the destination for diÔ¨Äerent route s ‚Ä¢pres:an arraythatindicates whichofthenodes areinterestedin the ro utestothe destination,forexample pres[i][j] =trueindicates that the node with the IP address jis interested in the routes to the node with the IP address i. Since we have considered a row for each destination in our routing ta ble, to indicate whether the node has any route to each destination until now, we initially set dsn[i] to‚àí1 which implies that the node has never known any route to the node with the IP address i. We refer to the all above mentioned arrays as routing arrays. Initially all integer cells of arrays are set to ‚àí1 and all boolean cells are set to false. To model expunging a route, its corresponding next hop and hop count entr ies in the arrays nhopsandhopsare set to ‚àí1. Since we have only considered one node as the destination and one node as the source, the information inrreqandrrepmessages has no conÔ¨Çict and consequently the route message tab le can be abstracted away. In other words, the routing table information can be used to identif y whether the new received message has been seen before or not, as the stored routes towards the sour ce represent information about rreqs and the routes towards the destination represent rreps. Note that rreqandrrep, i.e., all route messages, carry route information to their source a nd destination, respectively. Therefore, a bidirectional path is constructed while these messages travel through the network. Whenever a node receives a route message, it processes incoming in formation to determine whether it oÔ¨Äers any improvement to its known existing routes. Then, it updates its r outing table accordingly in case of an improvement. The processes of evaluating and updating the routin g table are explained in the following subsections. 6.1. Evaluating Route Messages Every received route message contains a route and consequently is evaluated to check for any improvement. Note that a rreqmessage contains a route to its source while a rrepmessage contains a route to its des tination. Therefore, as the routes are identiÔ¨Åed by their destinat ions (denoted by des), in the former case, the destination of the route is the originator of the message (i.e., des=oip), and in the latter, it is the destination of the message (i.e., des=dip). The routing table must be evaluated if one of the following conditions is realized: 1. no route to the destination has existed, i.e., dsn[des] =‚àí1 2. there are some routes to the destination, but all their route st ates areunconÔ¨Årmed 3. there is a valid or invalid route to the destination in the routing table and one of following conditions holds: ‚Ä¢the sequence number of the incoming route is greater than the exis ting one ‚Ä¢the sequence number of the incoming route is equal to the existing o ne, however the hop count of the incoming route is less than the existing one (the new route oÔ¨Äers a sh orter path and also is loop free) 6.2. Updating the Routing Table The routing table is updated as follows: ‚Ä¢if no route to the destination has existed, i.e., dsn[des] =‚àí1, the incoming route is added to the routing table. ‚Ä¢if the route states of existing routes to the destination are unconÔ¨Årmed , the new route is added to the routing table.Modeling and EÔ¨Écient VeriÔ¨Åcation of Wireless Ad hoc Network s 21 ‚Ä¢the incoming route has a diÔ¨Äerent next hop from the existing one in th e routing table, while the next hop‚Äôs neighbor state of the incoming route is unknown and the route state of the existing route is valid. The new route should be added to the routing table since it may oÔ¨Äer a n improvement in the future and turn into conÔ¨Årmed . ‚Ä¢if the existing route state is invalidand the neighbor state of the next hop of the incoming route is unknown , the existing route should be updated with information of the receiv ed one. ‚Ä¢if the next hop‚Äôs neighbor state of the incoming route is conÔ¨Årmed , the existing route is updated with new information and all other routes with the route state unconÔ¨Årmed are expunged from the routing table. As described earlier, there are three types of route discovery pa ckets:rreq,rrepandrerr. There is a message server for handling each of these packet types: ‚Ä¢recrreqis responsible for processing a route discovery request message; ‚Ä¢recrrephandles a reply request message; ‚Ä¢recrerrupdates the routing table in case an error occurs over a path and in forms the interested nodes about the broken link. There are also two message servers for receiving and sending a dat a packet. All these message servers will be discussed thoroughly in the following subsections. 6.3.rreqMessage Server This message server processes a received route discovery reque st and reacts based on its routing table, shown in Fig. 14. The rreqmessage has the following parameters: hopsandmaxHop as the number of hops and the maximum number of hops, dsnas the destination sequence number, and oip,osn,dip, andsiprespectively refer to the IP address and sequence number of the originator, and the IP address of the destination, and the IP address of the sender. Whenever a node receives a route request, i.e., recrreq(hops,dip,dsn,oip,osn,sip,maxHop ) message, it checks incoming information with the aim to improve the existing route or introduce a new route to the destin ation, and then updates its routing table accordingly (see also Sections 6.1 and 6.2). During processing an rreqmessage, a backward route, from the destination to the originator is built by manipulating the routing array s with the index oip. Similarly, while processing an rrepmessage, it constructs a forwarded route to the destination by a ddressing the routing arrays with the index dip. Therefore, the procedure of evaluating the new route and upda ting the routing table is the same for both rreqandrrepmessages, except for diÔ¨Äerent indices oipanddip, respectively. Updating the routing table: Fig. 12 depicts this procedure which includes both evaluating the inco ming route and updating the routing table (the code is the body of ifpart in the line 7 of Fig. 14). If no route exists to the destination, the received information is used to updat e the routing table and generate discovery packets, lines (110). The route state is set based on the neighbo r status of the sender: if its neighbor status isconÔ¨Årmed , the route state is set to valid, otherwise to unconÔ¨Årmed . The next hop is set to the sender of the message, i.e., nhop[oip][0] =sip. If a route exists to the destination (i.e., oip), one of the following conditions happens: ‚Ä¢the route state is unconÔ¨Årmed , lines (1136): it either updates the routing table if there is a route with a next hop equal to the sender, or adds the incoming route to the Ô¨Å rst empty cells of nhopandhops arrays. If the neighbor status of the sender is conÔ¨Årmed , then all other routes with the same destination are expunged while the route state is set to valid, lines (2130). ‚Ä¢the route state is invalidor it is valid, but the neighbor status of the sender is conÔ¨Årmed , lines (3848): if the incoming message contains a greater sequence number, or an equal sequence number with a lower hop count, then it updates the current route while a new discovery message is generated. ‚Ä¢the route state is validand the neighbor status of the sender is unknown , lines (5066): the incoming route is added to the routing table and a new discovery message is ge nerated if it provides a fresher or shorter path. In these cases, if a new discovery message should be generated (w hen the node has no route as fresh as the route request), the auxiliary boolean variable genmsgis set to true. In Fig. 14, after updating the22 Behnaz YouseÔ¨Å, Fatemeh Ghassemi, Ramtin Khosravi 1if(dsn[oip ]==‚àí1){ 2 dsn[oip ]=osn; 3if(neighstate[sip ]==true) 4 {routestate[oip ]=1;} 5else 6 {routestate[oip ]=0;} 7 hops[oip ][0]=hops ; 8 nhop[oip ][0]=sip ; 9 gen msg =true; 10}else{ 11 if(routestate[oip ]==0){ 12 dsn[oip ]=osn; 13 route num = 0; 14 for(inti=0;i<4;i++) 15 { 16 if(nhop[oip ][i]==‚àí1||nhop[oip ][i]==sip ){ 17 route num = i; 18 break; 19 } 20 } 21 if(neighstate[sip ]==true){ 22 route state[oip ]=1; 23 for(inti=0;i<4;i++) 24 { 25 hops[oip ][ i]=‚àí1; 26 nhop[oip ][i]=‚àí1; 27 } 28 hops[oip ][0]=hops ; 29 nhop[oip ][0]=sip ; 30 } 31 else{ 32 route state[oip ]=0; 33 hops[oip ][routenum]=hops ; 34 nhop[oip ][routenum]=sip ; 35 } 36 } 37 else{ 38 if(routestate[oip ]==2||neighstate[sip ]==true){ 39 /‚àóupdate the existing route ‚àó/ 40 if((dsn[oip ]==osn && hops[oip ][0]>hops)||dsn[oip]<osn){ 41 dsn[oip ]=osn; 42 if(neighstate[sip ]==true) route state[oip ]=1; 43 elseroutestate[oip ]=0; 44 hops[oip ][0]=hops ; 45 nhop[oip ][0]=sip ; 46 gen msg =true; 47 } 48 } 49 else{ 50 route num = 0; 51 for(inti=0;i<4;i++) 52 { 53 if(nhop[oip ][i]==‚àí1||nhop[oip ][i]==sip ) 54 { 55 route num = i; 56 break; 57 } 58 } 59 if((dsn[oip ]==osn && hops[oip ][0]>hops)||dsn[oip]<osn) 60 { 61 dsn[oip ]=osn; 62 hops[oip ][routenum]=hops ; 63 nhop[oip ][routenum]=sip ; 64 gen msg =true; 65 } 66 } 67} 68} Fig. 12. Updating the routing tableModeling and EÔ¨Écient VeriÔ¨Åcation of Wireless Ad hoc Network s 23 1 route state[oip ]=2; 2 dipsqn[oip ]=dsn[oip ]; 3for(intk=0;k<4;k++) 4{ 5if(pre[oip ][k]==true) 6 {aÔ¨Äected neighbours[k]= true;} 7} 8for(intj=0;j<4;j++) 9{ 10 for(intr=0;r<4;r++) 11 { 12 if(nhop[oip ][r]!=‚àí1 && nhop[j][0]==nhop[oip ][r]) 13 { 14 route state [j]= 2; 15 dip sqn[j]=dsn[j]; 16 for(intk=0;k<4;k++) 17 { 18 if(pre[j ][k]== true) 19 {aÔ¨Äected neighbours[k]= true;} 20 } 21 break; 22 } 23 } 24} 25 multicast(aÔ¨Äected neighbours, rec rerr(dip ,ip,dipsqn)); Fig. 13. The error recovery procedure routing table, if a new message should be generated, indicated by if(genmsg=true), it rebroadcasts the rreqmessage with the increased hop count if the node is not the destinat ion, lines (5154). Otherwise, it increases its sequence number and replies to the next hop(s) towa rd the originator of the route request, oip, based on its routing table. Before unicasting rrepmessages, next hops toward the destination, dip, and the sender are set as interested nodes to the route toward the origin ator,oip, lines (1722). It unicasts each rrep message to its next hops one by one until it gets an ack from one, line s (2343); ack reception is modeled implicitly through successful delivery of unicast, i.e., the succpart. If it receives an ack, it updates the route state tovalidand the neighbor status of the next hop to conÔ¨Årmed and stops unicasting rrepmessages. If it doesn‚Äôt receive an RREPAckmessage from the next hop when the route state is valid, it initiates the error recovery procedure. Error Recovery Procedure: The code for this procedure is illustrated in Fig. 13 (its code is the bod y of ifpart in line 46 of Fig. 14). As explained earlier, this procedure is initiat ed when a node doesn‚Äôt receive an RREPAckmessagefromthe next hopofthe routewith state valid. Then,it updates its routestateto invalid and adds the sequence number of the originator to the array of inv alidated sequence numbers, denoted by dipsqn. Furthermore, it adds all the interested nodes in the current rou te to the list of aÔ¨Äected neighbors, denoted by aÔ¨Äectedneighbours , lines (37). It invalidates other valid routes that use the same bro ken next hop as their next hops, adds their sequence numbers to the invalida ted array and sets the nodes interested in those routes as aÔ¨Äected neighbors, lines (824). Finally, it multica sts anrerrmessage which contains the destination IP address, the node IP address, and the invalidated s equence numbers to the aÔ¨Äected neighbors, line 25. 6.4.rrepMessage Server This message server, shown in Fig. 15, processes the received rep ly messages and also constructs the route forward to the destination. At Ô¨Årst, it updates the routing table a nd decides whether the message is worth processing, as previously mentioned for rreqmessages, and constructs the route, but this time to the destina  tion (its code is similar to the one in Fig. 12 except that dipis used instead of oip, and is place at line 6 of Fig. 15). Thismessageissent backwardstill it reachesthe sourcet hroughthe reversedpathconstructed while broadcasting the rreqmessages. When it reaches the source, it can start forwarding da ta to the destination.24 Behnaz YouseÔ¨Å, Fatemeh Ghassemi, Ramtin Khosravi 1msgsrvrecrreq(inthops,intdip,intdsn,intoip,intosn,intsip,intmaxHop) 2{ 3int[] dipsqn=new int[4]; 4introutenum; 5boolean[] aÔ¨Äected neighbours=new boolean[4]; 6boolean genmsg =false; 7if(ip!=oip ) 8{ 9 //evaluate and update the routing table 10 } 11 if(genmsg==true) 12 { 13 if(ip==dip ) 14 { 15 boolean su =false; 16 pre[dip ][ sip]=true; 17 for(inti=0;i<4;i++) 18 { 19 intnh = nhop[dip ][i]; 20 if(nh!=‚àí1) 21 {pre[oip ][nh]=true;} 22 } 23 for(inti=0;i<4;i++) 24 { 25 if(nhop[oip ][i]!=‚àí1) 26 { 27 intnhop = nhop[oip ][i]; 28 sn = sn+1; 29 /‚àóunicast a RREP towards oip of the RREQ ‚àó/ 30 unicast(n hop,rec rrep(0 , dip , sn , oip ,self)) 31 succ: 32 { 33 route state[oip ]=1; 34 neigh state[n hop]=true; 35 su = true; 36 break; 37 } 38 unsucc: 39 { 40 neigh state[n hop]=false; 41 } 42 } 43 } 44 if(su==false&& route state[oip ]==1) 45 { 46 /‚àóerror recovery procedure ‚àó/ 47 } 48 } 49 else{ 50 hops = hops+1; 51 if(hops<maxHop) 52 {recrreq(hops ,dip,dsn,oip,osn,self,maxHop); } 53 } 54 } 55} Fig. 14. The rreq message serverModeling and EÔ¨Écient VeriÔ¨Åcation of Wireless Ad hoc Network s 25 1msgsrvrecrrep(inthops,intdip,intdsn,intoip,intsip){ 2int[] dipsqn=new int[4]; 3boolean[] aÔ¨Äected neighbours=new boolean[4]; 4boolean genmsg =false; 5intnhop,route num; 6/‚àóevaluate and update the routing table ‚àó/ 7if(genmsg==true) 8{ 9 if(ip==oip ) 10 { 11 /‚àóthis node is the originator of the corresponding RREQ ‚àó/ 12 /‚àóa data packet may now be sent ‚àó/ 13 } 14 else{ 15 hops = hops+1; 16 boolean su =false; 17 pre[oip ][ sip]=true; 18 for(inti=0;i<4;i++) 19 { 20 n hop = nhop[oip ][i]; 21 if(nhop!=‚àí1) 22 {pre[oip ][nhop]=true;} 23 } 24 for(inti=0;i<4;i++) 25 { 26 if(nhop[oip ][i]!=‚àí1) 27 { 28 n hop = nhop[oip ][i]; 29 unicast(n hop,rec rrep(hops ,dip,dsn,oip,self)) 30 succ: 31 { 32 route state[oip ]=1; 33 neigh state[n hop]=true; 34 su = true; 35 break; 36 } 37 unsucc: 38 { 39 neigh state[n hop]=false; 40 } 41 } 42 } 43 if(su==false&& route state[oip ]==1) 44 { 45 /‚àóerror recovery procedure ‚àó/ 46 } 47 } 48 } 49} Fig. 15. The rrep message server In case the node is not the originator of the route discovery messa ge, it updates the arrayof interested nodes, lines (1723). Then, it unicasts the message to the next hop(s), o n the reverse path to the originator, lines (2442). Based on the AODVv2 protocol, if connectivity to the nex t hop on the route to the originator is not conÔ¨Årmed yet, the node must request a Route Reply Acknowled gment (RREPAck) from the intended next hop router. If a RREPAckis received, then the neighbor status of the next hop and route st ate must be updated to conÔ¨Årmed andvalid, respectively, lines (3036), otherwise the neighbor status of th e next hop remains unknown , lines (3740). This procedure is modeled through conditional unicast which enables the model to react based on the delivery status of the unicast messag e so that succmodels the part where the RREPACKis received while unsuccmodels the part where it fails to receive an acknowledgment from the next hop. In case the unicast is unsuccessful and the route stat e is valid, the error recovery procedure will be followed, lines (4346).26 Behnaz YouseÔ¨Å, Fatemeh Ghassemi, Ramtin Khosravi 1msgsrvrecrerr(intsource,intsip,int[] riprsn){ 2int[] dipsqn=new int[4]; 3boolean[] aÔ¨Äected neighbours=new boolean[4]; 4if(ip!=source ) 5{ 6 //regenerate rrer for invalidated routes 7 for(inti=0;i<4;i++) 8 { 9 intrsn=rip rsn[i ]; 10 if(routestate[i]==1 && nhop[i][0]==sip && dsn[i] <rsn && rsn!=0) 11 { 12 route state [i]= 2; 13 dip sqn[i]=dsn[i]; 14 for(intj=0;j<4;j++) 15 { 16 if(pre[i ][j]== true) 17 {aÔ¨Äected neighbours[j]= true;} 18 } 19 } 20 } 21 multicast(aÔ¨Äected neighbours, rec rerr(source ,self,dipsqn)); 22 } 23} Fig. 16. The rerr message server 6.5.rerrMessage Server This message server, shown in Fig. 16, processes the received err or messages and informs those nodes that depend on the broken link. When a node receives an rerrmessage, it must invalidate those routes using the broken link as their next hops and sends the rerrmessage to those nodes interested in the invalidated routes. This message has only two parameters: sipwhich indicates the IP address of the sender, and riprsn, which contains the sequence number of those destinations which have be come unaccessible from the sip. For all the validroutes to the diÔ¨Äerent destinations, it examines whether the next hop of the route to the destination is equal to sipand the sequence number of the route is smaller then the received s equence number, line 10. In case the above conditions are satisÔ¨Åed, the rou te is invalidated, lines (1119), and an rerrmessage is sent to the aÔ¨Äected nodes, line 21. 6.6.newpktMessage Server Whenever a node intends to send a data packet, it creates a recnewpktwhich has only two parameters, dataanddip. The code for this message server is shown in Fig. 17. If it is the dest ination of the message, it delivers the message to itself, lines (47). Otherwise, if it has a valid route to the destination, it sends data using that route, lines (1115). If it has no valid route, it incre ases its own sequence number and broadcasts a route request message, lines (1625). In addition, if a route to the destination is not found withinRREQWAITTIME, the node retries to send a new rreqmessage after increasing its own sequence number. Since we abstracted away from time, we model this proced ure through the resendrreqmessage server which attempts to resend an rreqmessage while the node sequence number is smaller than 3 (to make the state space Ô¨Ånite). 7. Evaluation In this section, we will review the results obtained from eÔ¨Éciently con structing the state spaces for the two introduced wRebeca models, the Ô¨Çooding and AODV protocol. Also, w e brieÔ¨Çy introduce our tool and its capabilities. Then, the loop freedom invariant is deÔ¨Åned and one poss ible loop scenario is demonstrated. Finally, two properties that must hold for the AODV protocol are ex pressed that can be checked with regard to the AODV model.Modeling and EÔ¨Écient VeriÔ¨Åcation of Wireless Ad hoc Network s 27 1msgsrvrecnewpkt( intdata ,intdip){ 2int[] dipsqn=new int[4]; 3boolean[] aÔ¨Äected neighbours=new boolean[4]; 4if(ip==dip ) 5 { 6 /‚àóthe DATA packet is intended for this node ‚àó/ 7} 8else{ 9 /‚àóthe DATA packet is not intended for this node ‚àó/ 10 store[dip ]=data; 11 if(routestate[dip ]==1) 12 { 13 /‚àóvalid route to dip ‚àó/ 14 /‚àóforward packet ‚àó/ 15 } 16 else{ 17 /‚àóno valid route to dip ‚àó/ 18 /‚àósend a new rout discovery request ‚àó/ 19 if(sn<3) 20 { 21 sn++; 22 unicast( self,resend rreq(dip )); 23 rec rreq(0,dip ,dsn[dip ],self,sn,self,4); 24 } 25 } 26 } 27} 28msgsrvresendrreq(intdip) 29{ 30 if(sn<3) 31 { 32 sn++; 33 unicast( self,resend rreq(dip )); 34 rec rreq(0,dip ,dsn[dip ],self,sn,self,4); 35 } 36} Fig. 17. The rec newpkt message server 7.1. StateSpace Generation Static Network . Consider a network with a static topology, in other words the netwo rk constraint is deÔ¨Åned so that it leads to only one valid topology. We illustrate the app licability of our counting abstraction technique on the Ô¨Çooding routing protocol. In contrast to the inte rmediate nodes on a path (the ones except the source and destination), the two source and destination node s cannot be aggregated (due to their local states). However, in the case of the AODV protocol, no two nodes can be counted together due to the unique variables of IP and routing table of each node. As the number of inte rmediate nodes with the same neighbors increases, the more reduction takes place. We have precisely chos en four fully connected network topologies to show the power of our reduction technique when the intermediat e nodes increase from one to four. Table 2 illustrates the number of states when running the Ô¨Çooding pr otocol on diÔ¨Äerent networks with diÔ¨Äerent topologies before and after applying counter abstractio n reduction. In the Ô¨Årst, second, third, and fourth topology, there are three nodes with one intermediate, fo ur nodes with two, Ô¨Åve nodes with three, and six with four intermediates, respectively. By applying counter a bstraction reduction, the intermediate nodes are collapsed together as they have the same role in the prot ocol. However, the eÔ¨Äectiveness of this technique depends on the network topology and the modeled proto col. Dynamic network. At these networks, topology is constantly changing, in other word s there are more than one possible topology. The resulting state spaces after and befor e eliminating œÑtransitions are compared for the two case studies while the topology is constantly changing for a n etworks of 4 and 5 nodes, as shown in Table 3. Table 4 depicts the constraints used to generate the sta te spaces and the number of topologies that each constraint results in. Constraints are chosen randomly here, just to show the eÔ¨Äectiveness of our28 Behnaz YouseÔ¨Å, Fatemeh Ghassemi, Ramtin Khosravi Table 2. Comparing the size of state spaces with/without applying co unter abstraction reduction No. of No. of states No. of states No. of transitions No. of tra nsitions intermidate nodes before reduction after reduction before reduction after reduction 1 24 24 36 36 2 226 133 574 276 3 3,689 912 13,197 2,441 4 71,263 6,649 321,419 21,466 Table 3. Comparing the size of state spaces with/without applying œÑtransition elimination reduction No. of No. of valid No. of states No. of transitions No. of stat es No. of transitions nodes topologies before reduction before reduction after r eduction after reduction Ô¨Çooding 4 4 2,119 11,724 541 1,652 protocol 4 8 4,431 42,224 567 1,744 4 16 10,255 179,936 655 2,192 4 32 22,255 747,200 710 2,765 4 64 44,495 2,917,728 710 3,145 AODV 4 4 3,007 16,380 763 1,969 protocol 4 8 12,327 113,480 1,554 3,804 4 16 35,695 610,816 2,245 5,549 4 32 93,679 3,097,792 2,942 7,596 4 64 258,447 16,797,536 4,053 10,629 5 16 >655,441 >11,276,879 165,959 598,342 reduction technique. To this aim, we have randomly removed a (Ô¨Åxed ) link from the network constraints. Nevertheless, constraints can be chosen wisely to limit the network topologies to those which are prone to lead to an erroneous situation, i.e., violation of a correctness prope rty like loop freedom. However, it is also possible to check the model against all possible topologies by not deÔ¨Å ning any constraint. In other words, a modeler at Ô¨Årst can focus on some suspicious network topologies a nd after resolving the raised issues it check the model for all possible topologies. There are also some net works which have certain constraints about how the topology can change, e.g., node 1 can never get into t he communication range of node 2. These restrictions on topology changes can be reÔ¨Çected through constraints too. The sizes of state spaces are compared under diÔ¨Äerent network constraints resulting in diÔ¨Äeren t number of valid topologies. Eliminating œÑtransitions and topology information manifestly reduces the numb er of states and transitions even when all possible topologies are not restricted. Therefore, it makes MAN ET protocol veriÔ¨Åcation possible in an eÔ¨Écient manner. Note that in case the size of the network was incre ased from four to Ô¨Åve, we couldn‚Äôt generate its state space without applying reduction due to the mem ory limitation on a computer with 8GB RAM. 7.2. Tool Support The presented modeling language is supported by a tool (available at [Beh]), providing a number of options to generatethe state space.Ascreenshotofthis tool is givenin Fig.18. This tool supportsboth bRebeca and wRebecamodelscharacterizedbydiÔ¨ÄerentÔ¨Åletypes.After openin gamodel,thetoolextractstheinformation of the reactive classes, such as the state variables and message s ervers, and also the main part including the rebec declarations and the network constraint. Then it generate s several classes in the Java language based Table 4. Applied network constraints No. of No. of valid constraint nodes topologies 4 4 and(and(con(node0,node1),con(node0,node3)), and(con(node2,node3),con(node1,node3))) 4 8 and(and(con(node0,node1), con(node0,node3)),con(node2,node3)) 4 16 and(con(node0,node1),con(node2,node3)) 4 32 con(node0,node1) 5 16 and(and(con(node0,node1),and(con(node0,node3),con(node4,node1))), and(con(node2,node3),and(con(node1,node3),con(node2,node4))))Modeling and EÔ¨Écient VeriÔ¨Åcation of Wireless Ad hoc Network s 29 Fig. 18. A screenshot of the wRebca tool with the compilation info window to conÔ¨Ågure the statespace generator on the obtained information and compiles them together with some ab stract and base classes (common in all models), for example global state andtopology, to build an engine that constructs the model state space upon its execution. Before compiling, a user can decide about rebec s message processing method, in a FIFO manner (queue) or in an arbitrary way (bag), and if the reduction s hould be applied. To take advantage of all hardware capabilities, we have implemented our statespace g eneration algorithm in a multithreaded way to leverage the power of multicore CPUs. During statespace generation, information about the state var iables and transitions are stored as an LTS in theAldebaran format4. This LTS can be evaluated by tools such as the mCRL2toolset [afra]. For example, one can express desired properties in ¬µcalculus [MS03] and verify them. Also, as explained in Section 5, labels are extended with network constraints as deÔ¨Åned in [GFM11] s o that the reduced LTS can be model checked with respect to underlying topology [GAFM13]. 7.3. Model Checking of the AODV Protocol Properties There are diÔ¨Äerent ways to check a given property on a wRebeca mo del. Invariant properties can be eval uated while generating the state space by checking each reached g lobal state against deÔ¨Åned invariants. Furthermore, the resulting state space can be model checked by tools supporting Aldebaran format such as mCRL2 and CLTS model checker. 4http://cadp.inria.fr/man/aldebaran.html30 Behnaz YouseÔ¨Å, Fatemeh Ghassemi, Ramtin Khosravi 1 bool loop freedom(des: int, cur:int, visited :Set <int>){ 2for(inti=0; i<n; i++) 3 if((state.node(cur).nhops[des][i]!= ‚àí1) && (!visited.contains(state.node(cur).nhops[des][i ])) 4 && loop freedom(des,i,visited.add(i))) 5 return true ; 6 else 7 return false ; 8} Fig. 19. Checking loop freedom property on a global state: we have used a dot notation to access the array nhopsof the rebec with the identiÔ¨Åer i, i.e.,state.node(i), where stateis the newly generated global state 7.3.1. Checking the Loop Freedom Invariant Loop freedom is one of the wellknown property which must hold for a ll routing protocols such as the AODV protocol. For example, consider the routes to a destination xin the routing tables of all nodes, where node0 has a route to xwith the next hop node1,node1has a route to xwith the next hop node2, andnode2has a route to xwith the next hop node0. The given example constructs a loop which consists of the three no des, node0,node1, andnode2. A state is considered loop free if the collective routing table entries of all nodes for each pair of a source and destination do not form a loop. As it was mentioned earlier in AODVv211, each route may have more than one next hop when the adjacency s tates of the next hops are unconÔ¨Årmed . Therefore, while the loop freedom of a state is checked, one must t ake into account all next hops stored for each route. Then, for each next hop check whether it leads to a loo p or not. A routing protocol deployed on a network is called loop free if all of its reachable states are loop free. In other words, loop freedom property of a protocol is an invariant (which can be easily speciÔ¨Åed by the ACTLX fragment of ¬µcalculus, and hence, is preserved by the reduced semantic model). However, We have ex tended our statespace generator engine to check invariants (speciÔ¨Åed by functions) over each newly gener ated global state on the Ô¨Çy by calling the functions provided by a user, i.e., the invariants. To this aim, we have speciÔ¨Åed the loop freedom invariant by a recursive function, to inspect for a given global state whether t he next hops in the routing table entries of nodes collectively lead to a loopformation scenario, as shown in Fig. 1 9. Therefore, whenever the statespace generator reaches to a new state, before proceeding any furth er, it checks whether any loop is formed on the forward/backward routes between the source and destination, by calling loopfreedom(4,1,new Set/a\}bracketle{tint/a\}bracketri}ht(1)) andloopfreedom(1,4,new Set/a\}bracketle{tint/a\}bracketri}ht(4)), asnode4andnode1are the destination and source respectively. If the loop freedomcondition isviolated,the loopfreedomfunction returns false, and the stategeneratorengine stops while it returns the path which has led to the global state unde r consideration as a counter example. The function loopfreedomhas three parameters: desrefers to the destination of the route, currefers to the IP address of the current node which is going to be processed and visitedis the list of IP addresses of those nodes which have been processed. Although keeping more than one next hop for each route may increa se the route availability, it compro mises its validity by violating the loop freedom invariant in a network of a t least four nodes with a dynamic topology. Consider the network topology shown in Fig. 2a. The follow ing scenario explains steps that lead to the invariant violation. 1.node2initiates a route discovery procedure for destination node3by broadcasting a rreqmessage. 2.node1andnode4upon receiving the rreqmessage, add a route to their routing tables towards node2and storenode2as their next hop. Since it is the Ô¨Årst time that these nodes have rec eived a message from node2, the neighbor state of node2is set to unconÔ¨Årmed . Therefore, the route state is unconÔ¨Årmed . 3. Asnode1andnode4are not the intended destination of the route request, they rebr oadcast the rreq message. 4.node1receives the rreqmessage sent by node4and since the route to node2isunconÔ¨Årmed it addsnode4 as a new next hop to node2. 5.node4also adds node1as the new next hop towards node2after processing the rreqsent bynode1. At this point a loop is formed between node1andnode4. 6.node3receives the rreqmessage sent by node1and since it is the destination, it sends a rrepmessage towardsnode1.Modeling and EÔ¨Écient VeriÔ¨Åcation of Wireless Ad hoc Network s 31 ‚àÄx,y:N((x >0‚àßx <4‚àßy >0‚àßy < x)‚áí[srcsn(x).true‚àó.srcsn(y)]false) ‚àÄx,y,m,n :N(x‚â•0‚àßx <4‚àßy‚â•0‚àßy <4‚àß m‚â•0‚àßm <4‚àßn‚â•0‚àßn <4‚àß (m < x‚à®n < y))‚áí[true‚àó.infoidsn(x,y).true‚àó.infoidsn(m,n)]false) Fig. 20.¬µcalculus properties veriÔ¨Åed by mCRL2 7.node2moves out of the communication ranges of node1andnode4. 8.node1receives the rrepmessage sent by node3and as the route state towards node2isunconÔ¨Årmed it unicasts the rrepmessage one by one to the existing next hops, node2andnode4, till it gets an ack. Since node2has moved out of the communication ranges of node1, no ack is received from node2andnode2 gets removed from the routing table as the next hop to node2. Then, another rrepis sent to node4. Since node4is adjacent to node1, it receives the message and then sends an ack to node1. Therefore, node1sets the neighbor state of node4toconÔ¨Årmed and subsequently the route state towards node2tovalid. 9.node4by receiving the rrepmessage from node1unicasts it to its next hops node1andnode2similar tonode1. Since it fails to receive an ack from node2and receives one from node1, it updates its routing table by validating node1as its next hop to node2. We have found the scenario in the wRebeca model with the network c onstraint resulting four topologies as indicated in Table 4. However, this scenario was also found for all t he network constraints described in the table. Furthermore, we can generalize the scenario to all netw orks with the same connectivity when the communications occur, and the same mobility scenario. 7.3.2. Checking the Properties by mCRL2 Sequencenumbersareused frequentlybytheAODVprotocoltoe valuatethe freshnessofroutes.Therefore,it is important that each node‚Äôs sequence number increases monoton ically. To this end, we manually conÔ¨Ågured thestategeneratortoaddtwoselfloopstoeachstatewiththela belsrcsn(x)tomonitorthesequencenumber of the source node, where xissnof the source node, and the label infoidsn(y,z) to trace the destination sequence number of routes to the source and destination for eac h nodei(i.e., the backward and forward routes to the destination of our model), where yandzaredsn[src] anddsn[dst] of node i, respectively. These properties are expressed through the ACTLX fragment of ¬µcalculus as shown in Fig. 20. The Ô¨Årst formula asserts a monotonic increase of the source sequence number. Th e second formula assures the destination sequence numbers stored in the routing table of nodeiare increased monotonically, and must hold for the nodes in the model. 7.3.3. Checking Packet Delivery Property by the CLTS Model Check er The CLTS model checker can be used to express and verify interes ting properties of MANET protocols dependent to the underlying topology speciÔ¨Åed in Constrained Actio n Computation Tree Logic (CACTL) [GAFM13], an extension of Action CTL [DV90]. The path quantiÔ¨Åer Allin CACTL is parametrized by a multihop constrain over the topology, which speciÔ¨Åes the precon dition required for paths of a state to be inspected. Therefore, a state satisÔ¨Åes A¬µœïif its paths over which the multihop constraint ¬µholds, also satisfyœï. It also contains the two temporal operators untilandweak until to specify the path formulae œÜœáUœá‚Ä≤œÜ‚Ä≤andœÜœáWœá‚Ä≤œÜ‚Ä≤to denote a path over which states satisfying œÜare met by actions of œáuntil a state satisfying œÜ‚Ä≤is met by actions of œá‚Ä≤(in case of weak until, the state satisfying œÜ‚Ä≤can never be met). The important property of packet delivery in routing or information dissemination protocols in the context of MANETs becomes: if there exists an endtoend route (multihop communication path) between two nodes AandCfor a suÔ¨Éciently long period of time , then packets sent by Awill eventually be received byC[FVGH+13]. To specify such the property, inspired from [FVGH+13] we revised our speciÔ¨Åcation to include data packet handling (to forward the packet to its next hop towards the destination) in addition to the route discovery packets and their corresponding handlers. T herefore, whenever a node, source, discovers a route to an intended destination, it starts forwarding its data pa cket through the next hop speciÔ¨Åed in its routing table. The data packet is forwarded by intermediate nodes to their next hops. When the data packet reaches the intended destination, it delivers the data to itself by un icasting the delivermessage to itself. In32 Behnaz YouseÔ¨Å, Fatemeh Ghassemi, Ramtin Khosravi case an intermediate node fails to forward the message, the error recovery procedure is followed as explained in Section 6. Consequently, using the following formula, we can verify packet delivery property: Atrue(true¬¨recnewpkt(0,4)Wrecnewpkt(0,4)An1/axisshort/axisshort/arrowaxisrightn4‚àßn4/axisshort/axisshort/arrowaxisrightn1(trueœÑUdeliver()true)) It expresses that as long as there is a stable multihop path from n1ton4and vice versa (speciÔ¨Åed by n1/axisshort/axisshort/arrowaxisrightn4‚àßn4/axisshort/axisshort/arrowaxisrightn1), anyrecnewpkt(0,4) message is proceeded by a delivery() message after passing œÑtransitions which abstract away from other message communicat ions. By model checking the resulting CLTS of the AODVv2 model, we found a scenario in which the property does not hold. We explain this scenario in a network of three nodes N1,N2andN3, where node N3is always connected to the nodes N1and N2, while the connection between the nodes N1andN2is transient. Therefore, the mobility of nodes leads to the topologies shown in Fig. 10b and Fig. 10c. Assume the topology is initially as the one in Fig. 10b: ‚Ä¢NodeN1unicasts a recnewpkt(data,N2) to itself, indicating that it wants to send datato nodeN2. ‚Ä¢NodeN1initiates a route discovery procedure by broadcasting an rreqN1,0message to its neighbors, i.e., nodesN3andN2. Note that rreqa,irefers to an rreqmessage received from node awith the hop count ofi. Eachrreqmessage has more parameters but here only these two parameter s are of interest and the other parameters are assumed to be equal for all the rreqmessages, i.e., the destination and source sequence numbers, and the source and destination IP addresses . ‚Ä¢NodeN3processes the rreqN1,0and since it is not the destination and has no route to N2in its routing table, rebroadcasts the rreqN3,1message to its neighbors, nodes N1andN2, after increasing the hop count. At this point, node N2has two messages in its queue, rreqN1,0andrreqN3,1. ‚Ä¢NodeN1moves out of the communication range of node N2, resulting the network topology shown in Fig. 10c. ‚Ä¢NodeN2takesrreqN1,0from the head of its queue and updates its routing table by setting N1as the next hop in the route towards N1. As node N2is the intended destination for the route discovery message, it unicasts an rrepmessage towards the originator, N1, indicating that the route has been built and it can start forwarding the data. Therefore, node N2attempts to unicast an rrepmessage to node N1, i.e., its next hop towards the originator. ‚Ä¢Since the connection between the nodes N1andN2is broken, it fails to receive an ack from N1and marks the route as invalid. ‚Ä¢NodeN2takesrreqN3,1from its queue and since the route state towards N1isinvalid, it evaluates the received route to determine whether it is loop free. Updating the ro uting table with the received route is said to be ‚Äúloop free‚Äù, if the received message cost, e.g., the hop c ount is less than or equal to the existing route cost. Since the hop count of the received message is greater than the existing one, it does not update the existing route and the message is discarded. Although the route through node N3to nodeN1seems to be valid, the protocol refuses to employ it to prevent possible loop formation in the future. 8. Related Work "
396,Stability Analysis of Complementarity Systems with Neural Network Controllers.txt,"Complementarity problems, a class of mathematical optimization problems with
orthogonality constraints, are widely used in many robotics tasks, such as
locomotion and manipulation, due to their ability to model non-smooth phenomena
(e.g., contact dynamics). In this paper, we propose a method to analyze the
stability of complementarity systems with neural network controllers. First, we
introduce a method to represent neural networks with rectified linear unit
(ReLU) activations as the solution to a linear complementarity problem. Then,
we show that systems with ReLU network controllers have an equivalent linear
complementarity system (LCS) description. Using the LCS representation, we turn
the stability verification problem into a linear matrix inequality (LMI)
feasibility problem. We demonstrate the approach on several examples, including
multi-contact problems and friction models with non-unique solutions.","Due to recent advancements in deep learning, there has been an increasing interest in using neural networks (NNs) to stabilize dynamical systems. For instance, neural networks have been used to approximate model predictive control policies through supervised learning [22, 23, 31, 41], or rein forcement learning [9]. Although neural network controllers can achieve satisfactory performance under less restrictive assumptions about the model of the dynamical system or the environment it operates in, they lack guarantees. This drawback limits the application of neural networks in safety critical systems, in which simpler control strategies, although potentially inferior to deep neural networks in performance, do have performance guarantees. Therefore, it is critical to develop tools that can provide useful certicates of stability, and robustness for NNdriven systems. Many important robotics systems are nonsmooth and researchers have shown the eectiveness of NN policies [18, 39, 42] on such systems without providing formal guarantees. The goal of this paper is to introduce a method for stability analysis of nonsmooth systems in feedback loops with NN controllers. Our framework is inspired by complementarity systems [21], dierential equations coupled with the solution of a linear complementarity problem. Complementarity problems are a class of mathematical optimization problems with orthogonality constraints [11]. Linear comple mentarity problems, in particular, are widely used in computational nonsmooth mechanics with unilateral contacts and friction [6], and more generally, in applications involving quadratic pro gramming [30]. In simple terms, a linear complementarity problem can be stated as the following potentially nonconvex quadratic optimization problem, minimize>(F+q) subject to F+q0; 0: ‚àóDepartment of Electrical and Systems Engineering, University of Pennsylvania. Email: falpayd, morari, posa g@seas.upenn.edu ‚Ä†Mathematical Institute for Data Science, Johns Hopkins University. Email: mahyarfazlyab@jhu.edu 1arXiv:2011.07626v1  [eess.SY]  15 Nov 2020With the objective function being nonnegative, the solutions to the optimization problem satisfy the complementarity condition ( F+q)>= 0. In the context of contact dynamics, for example, one can interpret as a contact force between a robot and a surface, and F+qis a gap function relating the contact force and the distance from the robot to the contact surface. Because of their ability to model setvalued and nonsmooth functions, complementarity problems are widely used within the robotics community, particularly to simulate contact dynamics [19, 38], leveraged in trajectory optimization [33], and stability analysis of rigidbody systems with contacts [2,7,34]. 1.1 Related Work "
91,Fairify: Fairness Verification of Neural Networks.txt,"Fairness of machine learning (ML) software has become a major concern in the
recent past. Although recent research on testing and improving fairness have
demonstrated impact on real-world software, providing fairness guarantee in
practice is still lacking. Certification of ML models is challenging because of
the complex decision-making process of the models. In this paper, we proposed
Fairify, an SMT-based approach to verify individual fairness property in neural
network (NN) models. Individual fairness ensures that any two similar
individuals get similar treatment irrespective of their protected attributes
e.g., race, sex, age. Verifying this fairness property is hard because of the
global checking and non-linear computation nodes in NN. We proposed sound
approach to make individual fairness verification tractable for the developers.
The key idea is that many neurons in the NN always remain inactive when a
smaller part of the input domain is considered. So, Fairify leverages whitebox
access to the models in production and then apply formal analysis based
pruning. Our approach adopts input partitioning and then prunes the NN for each
partition to provide fairness certification or counterexample. We leveraged
interval arithmetic and activation heuristic of the neurons to perform the
pruning as necessary. We evaluated Fairify on 25 real-world neural networks
collected from four different sources, and demonstrated the effectiveness,
scalability and performance over baseline and closely related work. Fairify is
also configurable based on the domain and size of the NN. Our novel formulation
of the problem can answer targeted verification queries with relaxations and
counterexamples, which have practical implications.","ArtiÔ¨Åcial intelligence (AI) based software are increasingly being used in critical decision making such as criminal sentencing, hiring employees, approving loans, etc. Algorithmic fairness of these software raised signiÔ¨Åcant concern in the recent past [ 1‚Äì8]. Several studies have been conducted to measure and mitigate algorithmic fairness in software [ 9‚Äì18]. However, providing formal guarantee of fairness properties in practice is still lacking. Fairness veriÔ¨Åcation in ML models is difÔ¨Åcult given the complex decision making process of the algorithms and the speciÔ¨Åcation of the fairness properties [ 19‚Äì22]. Our goal in this paper is to enable the veriÔ¨Åcation in realworld development and guarantee fairness in critical domains. Albarghouthi et al. and Bastani et al. proposed probabilistic techniques to verify group fairness [20,22]. Group fairness property ensures that the protected groups (e.g., malevsfemale, youngvsold, etc.) get similar treatment in the prediction. On the other hand, individual fairness states that any two similarindividuals who differ only in their protected attribute get similar treatment [ 21,23]. Galhotra et al. argued that group fairness property might not detect bias in scenarios when same amount of discrimination is made for any two groups [ 23], which led to the usage of individual fairness property in many recent works [ 1,8,23‚Äì25]. John et al. proposed individual fairness veriÔ¨Åcation for two ML classiÔ¨Åers, i.e., linear classiÔ¨Åer and 2) kernelized classiÔ¨Åer e.g., support vector machine [ 21], which is not applicable to neural networks. We propose Fairify , the technique to verify individual fairness of NN models in production. Both abstract inter pretation [ 26‚Äì30] and satisÔ¨Åability modulo theories (SMT) based techniques [ 31‚Äì33] have shown success in verifying different properties of NN such as robustness. However, fairness veriÔ¨Åcation of NN on realworld models has received little attention. We adopted SMT based veriÔ¨Åcation since it enables practical beneÔ¨Åts, e.g., solving arbitrary veriÔ¨Åcation query and providing counterexamples. Urban et al. proposed Libra, an abstract interpretation based dependency fairness certiÔ¨Åcation for NN [ 27]. The approach can not check relaxation of fairness queries and does not provide counterexamples in case of a violation. Fairify on the other hand provides conÔ¨Ågurable options to the developers enabling fairness veriÔ¨Åcation of NN in practice. Verifying a property in NN is challenging mainly because of the presence of nonlinear computation nodes i.e., activation functions [ 27,32]. With the size of the NN, the veriÔ¨Åcation task becomes harder and often untractable [ 34,35]. Many studies have been conducted to verify NN for different local robustness properties [ 29,31,36]. However, the individual fairness property requires global checking which makes the veriÔ¨Åcation task even harder and existing local property veriÔ¨Åers can not be used [ 37,38]. To that end, we propose a novel technique that can verify fairness, i.e., provide satisÔ¨Åability (SAT) with counterexample, or show UNSAT in a tractable time and available computational resource. Fairify takes a trained NN and the veriÔ¨Åcation query as input. If the veriÔ¨Åer can verify within the given timeout period, the output should be SAT (violation) or UNSAT (certiÔ¨Åcation). When the veriÔ¨Åer is unable to show any proof within the timeout, the result is UNK (unknown). Our evaluation shows that using stateof theart SMT solver, we cannot verify the fairness property of the NN models in days; however, Fairify can verify most of the veriÔ¨Åcation queries within an hour. Fairify makes the 1arXiv:2212.06140v2  [cs.LG]  14 Dec 2022veriÔ¨Åcation task tractable and scalable by combining input partitioning and pruning approach. Our key insight is that the activation patterns of the NN used in practice are sparse when we consider only a smaller part of the input region. Therefore, we perform input partitioning to a certain point and divide the problem into multiple subproblems which result into splitqueries. To show the problem as UNSAT, all the splitqueries have to be UNSAT. On the other hand, if any of the splitqueries gives SAT, the whole problem becomes SAT. Because of this construction of the problem, Fairify is able to provide certiÔ¨Åcation or counterexample for each partition which has further value in fairness defect localization. The input partitioning allowed us to perform static analysis on the network for the given partition and identify inactive neurons. We applied interval arithmetic to compute bounds of the neurons. In addition, we run individual veriÔ¨Åcation query on each neuron to identify the ones that are always inactive. Since the inactive neurons do not impact the decision, removing those neurons gives a pruned version of the network that can be veriÔ¨Åed for the given partition. This sound pruning is lightweight, sound, and achieves high pruning ratio, which makes the veriÔ¨Åcation task tractable. We further improve the efÔ¨Åciency of the approach by ana lyzing activation heuristics. We conduct lightweight simulation to proÔ¨Åle the network and Ô¨Ånd candidate neurons that remain almost always inactive but could not be removed through sound pruning. Thereby, we propose layerwise heuristics that suggest inactive nodes; if necessary given the time budget. Although this pruning is based on heuristics, our evaluation shows that a conservative approach provides much improvement in the veriÔ¨Åcation with negligible loss of accuracy. Another novelty in this idea is that the developer can choose to deploy the pruned (and veriÔ¨Åed) version of the NN. Thus, the pruned NN would provide sound fairness guarantee with little loss of accuracy. After partitioning and reducing the complexity of the problem, we leverage a constraint solver to verify the split queries on the pruned networks. Then we accumulate the results for each partition to provide veriÔ¨Åcation for the original query. We evaluated Fairify on 25 different NN models collected from four different sources. We collected appropriate realworld NNs from Kaggle [ 39] which are built for three popular fairness critical tasks and took the NNs used in three prior works in the area [ 8,24,27]. Our results show signiÔ¨Åcant improvement over the baseline with respect to utility, scalability, and performance. The main contributions of our work are as follows. 1)Fairify is the Ô¨Årst to solve the individual fairness veriÔ¨Åcation problem for already trained NN using SMT based technique. 2)Our formulation of the problem enables veriÔ¨Åcation of different relaxation of the fairness property. Then we proposed two novel NN pruning methods designed to solve those queries effectively. 3)The approach can be integrated in the development pipeline and provides practical beneÔ¨Åts for the developers i.e., certiÔ¨Åcation or counterexample for each input partition and targeted fairness certiÔ¨Åcation.4)We implemented Fairify using Python and openly available constraint solver Z3. We also created a benchmark of NN models for fairness veriÔ¨Åcation. The code, models, benchmark datasets, and results are available in the self contained GitHub repository [ 40]1that can be leveraged by future research. The rest of the paper is organized as follows: ¬ßII describes the background and ¬ßIII introduces fairness veriÔ¨Åcation problem in NN. ¬ßIV provides detailed description of the approach. ¬ßV describes the results and answers the research questions. Finally, ¬ßVII describes the related work, ¬ßVI discusses threats to validity, and ¬ßVIII concludes. II. P RELIMINARIES Neural Networks (NN). We consider NN as a directed acyclic graph (DAG), where the nodes hold numeric values that are computed using some functions, and edges are the data Ô¨Çow relations. The nodes are grouped into layers: one input layer, one or more hidden layers, and one output layer. More formally, a NN model M:Rn!Rmis a DAG with klayers: L1;L2;:::;LkwhereL1is the input layer and Lkis the output layer. The size of each layer Liis denoted by siand layerLi has the nodes v1 i;v2 i;:::;vsi i. Therefore, s1=n(number of inputs) andsk=m(number of output classes). In this paper, we consider the fully connected networks because of its success in realworld tasks [ 8,41,42], where the value of a node is given byvj i=NL(twi"
7,Evolving Self-taught Neural Networks: The Baldwin Effect and the Emergence of Intelligence.txt,"The so-called Baldwin Effect generally says how learning, as a form of
ontogenetic adaptation, can influence the process of phylogenetic adaptation,
or evolution. This idea has also been taken into computation in which evolution
and learning are used as computational metaphors, including evolving neural
networks. This paper presents a technique called evolving self-taught neural
networks - neural networks that can teach themselves without external
supervision or reward. The self-taught neural network is intrinsically
motivated. Moreover, the self-taught neural network is the product of the
interplay between evolution and learning. We simulate a multi-agent system in
which neural networks are used to control autonomous agents. These agents have
to forage for resources and compete for their own survival. Experimental
results show that the interaction between evolution and the ability to teach
oneself in self-taught neural networks outperform evolution and self-teaching
alone. More specifically, the emergence of an intelligent foraging strategy is
also demonstrated through that interaction. Indications for future work on
evolving neural networks are also presented.","Evolution and learning are two forms of adaptation. The former is a change at genotypic level of a population, also called phylogenetic adaptation. The latter is a change at phenotypic level of an individual as a result of experience with its environment during lifetime. Thus, learning is a form of lifetime or ontogenetic adaptation. Reasonably, lifetime adaptation takes place at a quicker pace than evolution, preparing the organism for increasingly uncertain environments which may require some survival skill that the slower evolutionary process could not fully offer. Interestingly, evolution and learning can complement each other through the phenomenon called the Baldwin Effect [ 1], which was Ô¨Årst demonstrated computationally by Hinton and Nowlan (henceforth H&N) [ 5]. Following this success, there have been quite a few important studies studying the interaction between learning and evolution, notably in evolving neural networks [ 13], [14], and in the NKLandscape [ 10]. Regardless of the problem domain and how learning is implemented, most studies focus on how learning and evolution are combined to solve an individual problem in a sortof singleagent environment. This means each agent has its own problem (though they are copies of each other) to solve. There is no interactive effect between the agents and their solutions to each other. This differs greatly in the case of a multiagent environment in which agents live in the same environment and may have to compete and cooperate in solving their own problems or problems shared with others. Although there should possibly be a mixture of Ô¨Çavour, this paper aims at two main things. First, we present a technique called evolving selftaught neural networks, or neural networks that can teach themselves without external supervisory Independent Researcher, Hanoi, Vietnam, email: namlehai90@gmail.com yNatural Computing Research & Applications, University College Dublin, Dublin, Ireland, email: nam.lehai@ucdconnect.ie 3Preprint AISB‚Äô19, 16th April 2019, AISB 2019 SymposiumarXiv:1906.08854v1  [cs.NE]  4 Apr 2019APREPRINT  JUNE 24, 2019 signals. This is an important aspect of this contribution. Second, we simulate a multiagent foraging world to test the performance of our proposed method and see the effect of interest. More speciÔ¨Åcally, we shall be seeing how evolution and the ability of selfteaching interact with each other in creating more adaptive and autonomous foraging agents, those that have little knowledge about the world. In the remainder of this paper, we initially present some prior research relating to the Baldwin Effect, including some review on learning and evolution in neural networks. We then describe the detail of the neural network and the simulation undertaken. The results from these experiments are analysed and discussed, and Ô¨Ånally, conclusions and several interesting future research opportunities are proposed. 2 Related Work "
140,Distributed Consistent Network Updates in SDNs: Local Verification for Global Guarantees.txt,"While SDNs enable more flexible and adaptive network operations, (logically)
centralized reconfigurations introduce overheads and delays, which can limit
network reactivity. This paper initiates the study of a more distributed
approach, in which the consistent network updates are implemented by the
switches and routers directly in the data plane. In particular, our approach
leverages concepts from local proof labeling systems, which allows the data
plane elements to locally check network properties, and we show that this is
sufficient to obtain global network guarantees. We demonstrate our approach
considering three fundamental use cases, and analyze its benefits in terms of
performance and fault-tolerance.","Given the increasingly stringent requirements on the dependability and performance of communication networks, it becomes important that networks be able to Ô¨Çexibly adapt to their context, e.g., react to failures or to changes in the demand, in an automated manner. SoftwareDeÔ¨Åned Networks (SDNs) provide such Ô¨Çexibilities by allowing to update network conÔ¨Ågurations programmatically, disburdening human operators from their most complex tasks and signiÔ¨Åcantly improving reaction times. Indeed, over the last years, the algorithmic problem of how to update networks consistently has received much attention [1]. However, while outsourcing and consolidating the control over switches and routers provides great Ô¨Çexibilities, indirection via (remote) controllers comes with overheads in terms of communication and computation costs, and can hence lead to delays. In fact, it is known that updating routes in a network while providing even simple transient properties such as loopfreedom, requires many interactions with the SDN controller in the worst case [ 2,3], unless one resorts to packet header rewriting. Given that the control plane can operate orders of magnitude slower than the data plane [4], this is problematic. This paper investigates opportunities to overcome these overheads and hence further improve network reactivity. To this end, we explore a more distributed approach to updating routes in networks, reducing interactions with the control plane without sacriÔ¨Åcing Ô¨Çexibility and consistency. This is challenging, as without a (logically) centralized network view, switches and routers need to be able to check certain network properties locally . We propose and investigate the use of distributed mechanisms based on local proof labeling systems [ 5], to propagate and implement network updates entirely in the data plane . In particular, we present a solution which allows switches and routers to check locally if a certain network property is fulÔ¨Ålled and whether a rule update can be safely applied. Consequently, a controller (or multiple controllers, in case of distributed SDN control planes) can simply submit update requests to the network, which are then propagated and implemented by the data plane autonomously. To demonstrate our approach, we consider two fundamental properties, both related to connectivity. Blackhole freedom: There is always a matching rule forwarding a packet to the next hop switch or router. Loop freedom: The forwarding rules never contain a loop. We also evaluate the beneÔ¨Åts of our approach analytically and investigate potential speed ups and faulttolerance. Contributions. This paper presents a distributed approach to operate and consistently update software deÔ¨Åned networks, by relying on local proof labeling systems. We show the feasibility and beneÔ¨Åts of our approach on two case studies, demonstrating that using our approach, simple local veriÔ¨Åcation is sufÔ¨Åcient to provide global correctness guarantees. We also show that our approach can lead to faster and faulttolerant network updates. Overview. The remainder of this paper is organized as follows. After introducing our model and preliminaries in Sections 2, we present our main approach in Section 3. We discuss our two case studies in Section 4 (considering efÔ¨Åcient updates limited to the affected routes) and Section 5 (removing the need for packet tagging), and then examine potential speed up and faulttolerance aspects (Section 6). After reviewing related work in Section 7, we conclude in Section 8. 2 Model and Preliminaries We follow standard assumptions [ 5,6,7] in our work, both regarding the network and the local veriÔ¨Åcation model. 2Network model. The considered networks are modeled as connected graphs G= (V;E )withnnodes (switches, routers) with unique identiÔ¨Åers and mfullduplex links. The network is equipped with a logically centralized controller that can collect the network state and send out conditional network updates to the nodes, e.g., changing a forwarding rule once a certain local condition is met [7]. Local VeriÔ¨Åcation. We will also leverage a connection [ 5] between proof labeling schemes [ 8,9] and the SDN model [ 1], see Section 3. A proof labeling scheme can be characterized by a proververiÔ¨Åerpair (P;V) as follows: Given some property Sthat the network state could uphold after updates ( e.g., loop freedom), the proverPsends new labels to the nodes. The veriÔ¨Åer Vis a distributed algorithm, running on each node v, that can collect the labels from all neighbors N(v). It outputs YESif propertySholds and the labels are from P, but at least one node must output NO, if the property Sis violated. 3 Approach and Main Idea This section presents how to leverage proof labeling schemes in the context of consistent updates for SDNs, both from a methodological and an implementation point of view. Methodology. Many consistency properties are inherently global, e.g., long loops cannot be detected by considering the forwarding rules in the local neighborhood. Even locally detectable problems can have an impact on nodes far away, such as, e.g., a blackhole downstream from the packet source. We thus utilize the power of proof labeling schemes to allow for local veriÔ¨Åcation of consistency properties, also supporting distributed consistent network updates. In our approach, the controller acts as the proverP. Nodes which are aware of the current label state of their neighbors, can now check them in the time intervals deemed necessary. In the simplest case, a node informs all its neighbors once its label state changes. Once being informed about label state changes, nodes can run the veriÔ¨Åer Vto check if the (global) propertySis still correct, respectively ring an alarm ( e.g., to the controller) if not. The main idea of our approach is that a node will not immediately apply a new label received from the controller, but rather Ô¨Årst check if the property Sstill holds from its point of view after applying said label to itself. As such, we do not need the large overhead of constantly communicating with the centralized controller regarding the updated network state, but can decide completely locally when to update. The challenge we undertake in this paper is to actually develop approaches that fulÔ¨Åll these criteria for common consistency properties, i.e.,generating distributed consistent network updates that can be veriÔ¨Åed locally. Implementation. Our approach is timely and can be implemented in OpenFlow and P4based programmable networks. The implementation of the controller is simple as it only precomputes the information needed by the switches later, during the network update (reducing communication and computation overheads). Furthermore, our approach does not rely on tight clock synchronization protocols while providing the same beneÔ¨Åts [ 10]. In the dataplane, we can use the approach by ezSegway [ 7], leveraging perswitch local controllers to manipulate dataplane state (via OpenFlow). 4 EfÔ¨Åcient CertiÔ¨Åcation Limited to Involved Routes We Ô¨Årst present a solution for efÔ¨Åcient certiÔ¨Åcation which only involves the nodes along routes that are actually updated (rather than allnodes in the network). We start with a case study on the blackhole freedom property. A socalled blackhole occurs when a node has no matching rule for a packet, i.e.,the packet is dropped (into a blackhole). A simple scheme to avoid blackholes for a speciÔ¨Åc network Ô¨Çow is to ensure that new labels for a node valways contain a matching 3rule for the Ô¨Çow destination d, where an update is rejected otherwise. However, whereas this scheme is easy to verify and apply, it suffers from the downside that every node in the network must have a forwarding rule for said Ô¨Çow, even if its packets only traverse a small subset of the nodes. A more efÔ¨Åcient solution would supply forwarding rules only to those nodes actually en route, as performed e.g., in [7] for network Ô¨Çows. The authors propose a distributed version of the 2phase update scheme by e.g., Reitblatt et al. [11]1: the routing path for Ô¨Çow Fis updated in reverse, where the destination informs its predecessor on the path to update its rules for F0, which in turn informs its predecessor, and so on. Eventually, the packet source will be reached, which then knows it is safe to send packets out tagged with F0. Providing veriÔ¨Åable blackhole freedom can be directly achieved in this setting if every node vwith a new rule forF0only updates if its successor won the path has been updated. Notwithstanding, what cannot be veriÔ¨Åed so far is the problem of reachability, i.e.,will the packets in F0actually reach their target? In the proververiÔ¨Åer framework, if each node is informed about its successor, a node wcould be successor of two nodesu;v, which in turn can lead to a forwarding loop. We can resolve this problem with a construction borrowed from reachability in the context of proof labeling schemes [ 9], by specifying both predecessors and successors of all nodes (besides source and destination). Then, by a connectivity argument, the packets of F0cannot loop and will reach the destination when starting from the source. While we now have veriÔ¨Åable blackhole freedom for the nodes en route, we cannot use the above scheme to actually deploy a new path for F0. Assume that the path has at least two nodes besides the source and the destination, then no further node en route can actually deploy the rules for F0under common asynchrony [ 1] assumptions‚Äîboth a successor and predecessor along the route is needed. Moreover, from a structural point of view, such a predecessorsuccessor construction does not remove unnecessary forwarding loops in the network, e.g., a loop disconnected from source/destination cannot be locally detected. While such disconnected loops might not seem as harmful from a routing point of view, they can hinder future updates and also highlight another downside of the above scheme, namely that it is not suitable for purely destinationbased schemes, where routing is performed along a forwarding tree. We investigate such scenarios in the next section, but Ô¨Årst show how to Ô¨Åx our proposed scheme. To this end, we replace the predecessorsuccessor relationship with a distance labeling scheme, as described in, e.g., [8,9]. Each node along the path of F0also obtains its distance to the destination as part of the label, measured in hops along F0. Then, a node will only update if its successor has already updated and its distance is exactly one less. A countingtozero argument can be used to show the correctness of this scheme w.r.t. blackhole and loop freedom, as a)only the destination may have a distance of zero and b)the source only starts to utilize F0once the path has been established. Theorem 1. The reverse update scheme in [ 7] for Ô¨Çows can be made locally veriÔ¨Åable for both blackhole and loop freedom by enhancing it with distance labelings. 5 Removing the Need for Packet Tagging It is sometimes possible to remove the need for packet tagging (as required by the approach above), and hence also reduce the number of rules to be stored by the nodes (as they are often pertag), by slightly relaxing the notion of consistency. Observe that in the previous section, our approach moreover guaranteed socalled perpacket consistency [ 11], where a packet will either take the old For the newF0path, but never a mix of both. However, such stronger guarantees are not needed in order to guarantee blackhole and loop freedom. 1The 2phase commit scheme in [ 11] updates the forwarding for a Ô¨Çow FtoF0as follows: The new Ô¨Çow rules for F0are distributed in the network, and once ack‚Äôed to the controller, the controller informs the packet source to from now on tag all Ô¨Çow packets with F0, instead of the previous tag of F. 4We assume as such that routing is to be performed destinationbased along forwarding trees, which in turn have to be blackhole/loopfree. It was already observed in [ 6] that consistency in this setting can be veriÔ¨Åed and consistently updated by including the depth of the node vin the forwarding tree in its label. As such, specifying the parent and the depth sufÔ¨Åces. In a nutshell, a node vwaits until its parent wupdates, and then only updates if DEPTH (v)=DEPTH (w) + 1 is satisÔ¨Åed. A downside of the above scheme is that it only speciÔ¨Åes a single transition from old to new forwarding rules. In order for a second and further updates to be performed, the controller needs to again collect acknowledgments that all nodes have switched, inducing unnecessary overhead. In the previous section and in 2phase commit schemes in general, one can just create a new tag to avoid such issues, e.g., transitioning fromFtoF0toF00and so on. Even if F0is never fully implemented, the packet source can transition to F00 once its path is fully provisioned. It seems at Ô¨Årst as if the trick of adding increasing version numbers cannot be directly applied to forwarding trees. In network Ô¨Çows, there is a single node (the source) from which the trafÔ¨Åc along the new path originates, whereas in forwarding trees, all nodes can act as sources, potentially sending across combinations of different forwarding trees (in [6]: just 2 trees). However, instead of waiting for the last update to be completed, we can actually mix different subsequent updates, as long as in each intermediate possible timestep the forwarding is performed along a forwarding tree.2As such, we add version numbers to each label and observe that we only need to obey a largerthan relationship: as long as any of v‚Äôs neighbors wis a parent in some larger version number x,vmay switch to its label (tree) with version xifDEPTH x(v)=DEPTH x(w) + 1 . Observe that a node can also skip intermediate labels. Correctness is guaranteed by the invariant that a node will never switch to a smaller version number.3 Nodes using the largest version number form a correct forwarding tree, as they will not forward to nodes in other trees and in each step reduce the distance to the destination. Next, observe that for all other forwarding trees (version numbers), the next routing hop will decrease the distance in the label of the parent, respectively switch to a higher version number. Hence, the packet will reach the destination eventually and loops in the current forwarding state can be locally detected as well: Assume for the sake of contradiction that the forwarding graph contains some loop with no node ringing an alarm (outputting NO). As every node outputs YES, we can follow the routing loop starting from some node u, where in each step, we increase the version number or reduce the distance. However, when we reach uagain4,umust either have a smaller depth or a higher version number than itself, a contradiction. Theorem 2. By augmenting the update scheme from [ 6] with version numbers, s.t. a node vmay update to larger version numbers x, if its respective parent winxis also in version number xand DEPTH x(v)=DEPTH x(w)+ 1, we obtain a locally veriÔ¨Åable scheme which preserves blackhole and loopfreedom. 6 Discussion: Speed Up and FaultTolerance Potential speed up gains. Nguyen et al. [7] showed in their evaluations that decentralized consistent updates can speed up updates by up to 45% at the median, in realistic scenarios. We brieÔ¨Çy analyze what sort of theoretical speed up is possible in extreme cases, from the viewpoint of message propagation delay, where we assume one hop to take unit time. Consider the scenario analogously to [ 12, Fig. 2], shown in Figure 1. The task is to update from the old (solid) to the new (dashed) forwarding rules for the destination din a loopfree fashion. In a centralized 2Note that loop freedom is a structural property of the forwarding graph. 3For practical purposes, an appropriate circular ordering could be deÔ¨Åned. 4As we study a structural property, we assume no updates in the meantime. 5Figure 1: Network with old (solid) and new (forwarding) rules which requires l"
412,Tiramisu: Fast and General Network Verification.txt,"Today's distributed network control planes support multiple routing
protocols, filtering mechanisms, and route selection policies. These protocols
operate at different layers, e.g. BGP operates at the EGP layer, OSPF at the
IGP layer, and VLANs at layer 2. The behavior of a network's control plane
depends on how these protocols interact with each other. This makes network
configurations highly complex and error-prone. State-of-the-art control plane
verifiers are either too slow, or do not model certain features of the network.
In this paper, we propose a new multilayer hedge graph abstraction, Tiramisu,
that supports fast verification of the control plane. Tiramisu uses a
combination of graph traversal algorithms and ILPs (Integer Linear Programs) to
check different network policies. We use Tiramisu to verify policies of various
real-world and synthetic configurations. Our experiments show that Tiramisu can
verify any policy in < 0.08 s in small networks (~35 devices) and < 0.12 s in
large networks (~160 devices), and it is 10-600X faster than state-of-the-art
without losing generality.","Many networks, including university, enterprise, ISP and data center networks, employ complex distributed control planes running atop rich underlying network structures. The control planes run a variety of routing protocols, such as RIP, OSPF, and BGP, which are conÔ¨Ågured in intricate ways to exchange routing information both within and across protocols. In some cases, the protocols are assisted byother protocols (e.g., iBGP assisting in distributing BGP information throughout a network). Networks also employ techniques to virtualize the control plane, such as virtual routing and forwarding (VRF), as well as tech niques to virtualize multiple network links into different broadcast domains (VLANs). Bugs can easily creep into such networks, e.g., through errors in the detailed conÔ¨Ågurations that many of the protocols need. Often, bugs may not be immediately apparent, and the network may be running ‚Äújust Ô¨Åne‚Äù un til a failure causes a latent bug to be triggered. When bugs do manifest, a variety of catastrophic outcomes can arise: the network may suffer from blackholes; services with restricted access may be rendered wide open; crit ical applications can no longer be isolated from other services/applications, and so on. VeriÔ¨Åcation tools and their tradeoffs. A variety oftools attempt to verify if networks are violating, or could potentially violate, policies of the above kind. Data plane veriÔ¨Åers [ 13,10,11] analyze the current forwarding ta bles and check for blackholes, loops, or broken path iso lation. Unfortunately, these tools don‚Äôt have the means to analyze if the network‚Äôs new data plane that materialized upon reacting to a failure, can satisfy relevant policies or not. To overcome this issue, a variety of control plane ana lyzers were developed [ 5,2,16,4,6]. These proactively analyze the network against various environments, e.g., failures or external advertisements. While a signiÔ¨Åcant step forward in network veriÔ¨Åcation, control plane tools today make tradeoffs between performance and general ity. On the one hand are ‚Äúgraphbased‚Äù tools such as ARC [ 6]. ARC encodes all paths that may manifest in a network under various failures into a series of weighted digraphs. This abstraction enables analyzing the network under many potential environments at once by running very fast polynomial time graph algorithms; e.g., check ing if two hosts are always blocked amounts to check ing if they are in different graph connected components. Unfortunately, ARC ignores many network design con structs, including modeling the intricacies of BGP and iBGP, and the existence of VLANs, and VRFs. On the other hand are ‚ÄúSMTbased‚Äù tools such as Bag pipe [ 16] and Minesweeper [ 2]. These tools create a detailed model of the control plane by symbolically en coding routing information exchange, route selection logic, and the environment (e.g., failures) using logical constraints/variables. By asking for a satisfying assign ment for a SMT formula that encodes the network and the property of interest, they can identify a concrete en vironment that leads to property violation. These tools offer much better coverage of control plane protocols than graphbased ones, but their veriÔ¨Åcation performance is very poor, especially when exploring failures ( ¬ß6), despite many internal SMTspeciÔ¨Åc optimizations. Decoupling encoding and properties. We ask if it is possible to design a veriÔ¨Åcation tool that marries the speed of graphs with the generality of an SMTbased encoding. We start by noting that today the tradeoff between per formance and generality in tools, arises from a coupling between the control plane encoding used in the tools and how properties are veriÔ¨Åed. In graphbased tools, thearXiv:1906.02043v1  [cs.NI]  5 Jun 2019weighted graph control plane model requires graph al gorithms to verify properties. In SMTbased tools, the detailed constraintbased control plane encoding requires a general constraint solver to be used for all properties. Our framework, Tiramisu, decouples the encoding from the property: it uses a sufÔ¨Åciently rich encoding for the network that models various control plane features and network design constructs. But then, it permits the use of custom algorithms that offer the best performance to verify a property of interest. Richer graphs. Our framework starts with graphs as the basis for modeling networks, because graphbased control plane analysis has been shown to be fast [ 6]. We then embellish the graph model with richer graph constructs, such as hierarchical layering, the notion of hedges [ 7] (edges that fail together), and rich, multi attribute edge and node labels. Our resulting graph can model all aspects we observe used in real world networks and conÔ¨Ågurations. Given the graph structure, we then develop a suite of custom techniques that help verify various properties of interest. Avoiding path enumeration. First, we note that some properties of interest do not require the computation of the actual path that the network would induce on a certain failure; they care mostly about whether paths exist or not. An example is whether two hosts are always blocked from each other. For such properties, we develop two techniques that avoid path enumeration altogether: a modiÔ¨Åed depth Ô¨Årst search graph traversal algorithm, and a simple integer linear program (ILP) formulation that computes graph cuts. Importantly, graph traversal runs in polynomial time. And, for a given property, the sim pliÔ¨Åed propertyspeciÔ¨Åc ILP can be solved much faster than a general SMTencoding in SMTbased tools. This is because the former explores symbolically only the variables that are relevant to the property being veri Ô¨Åed, whereas the SMT solver for the general encoding searches through a much larger search space. DomainspeciÔ¨Åc path computation. For the remain ing properties that require computation of paths, we run a modiÔ¨Åed path vector protocol atop our richer graph ab straction. Here, we leverage foundational work by GrifÔ¨Ån et. al which showed that various routing protocols can be modeled as instances of the stable paths problem [ 8] (this insight was used in Minesweeper), and that a ‚Äúsimple path vector protocol‚Äù (SPVP) [ 8] emulates the compu tation of a solution to this problem. In our version of SPVP, each node consumes the multidimensional at tributes of incoming edges and neighboring vertices, and uses simple arithmetic operations that encode existingprotocols‚Äô logic to select among multiple paths available at the moment. Importantly, in simple networks (e.g., those that use a single routing protocol) our protocol naturally devolves to being similar to distance vector protocol, which runs in polynomial time (being based on the BellmanFord algorithm). For more general net works, we empirically Ô¨Ånd that our protocol can quickly compute the paths that are relevant to verifying speciÔ¨Åc properties. The performance is faster than SMTbased tools, because our approach essentially uses a highly domainspeciÔ¨Åc approach to Ô¨Ånding paths, compared to a SMTbased general search strategy; for instance, even for simple networks, a SMTbased strategy would invoke the solver to Ô¨Ånd a satisfying assignment. Prototype and evaluation. We implemented Tiramisu in Java (7K LOC) and evaluated it with many real data center and university networks, as well as networks from the topology zoo [ 12]. We Ô¨Ånd that Tiramisu‚Äôs rich multilayered graphs can be computed from conÔ¨Ågurations in a few ms per trafÔ¨Åc class. Using Tiramisu‚Äôs custom algorithms, various properties can be checked for complex networks in 380ms per trafÔ¨Åc class. Compared to Minesweeper that uses a general encod ing with an SMT solver, Tiramisu offers speed of up to 600X for reachability policy veriÔ¨Åcation and 1050X for boundedlength and path preference policies (both under failures). Tiramisu‚Äôs algorithmic approach renders it sub stantially faster even when verifying properties under no failures. Finally, Tiramisu scales well, providing veriÔ¨Å cation results in100ms per trafÔ¨Åc class for networks with160 routers. 2 Motivation Given the signiÔ¨Åcant performance beneÔ¨Åts of graph ab stractions [ 6], we use graphs as the basis to encode con trol plane computation in Tiramisu. However, the ab straction we use is signiÔ¨Åcantly different from ARC [ 6]. In what follows, we provide an overview of ARC‚Äôs graph based approach for veriÔ¨Åcation. We then identify its key drawbacks which motivate Tiramisu‚Äôs graph design. 2.1 ARC ARC (Abstract representation for control plane [ 6]) is a stateoftheart control plane veriÔ¨Åer. It models a net work‚Äôs control plane using a collection of directed graphs. There is one directed graph per trafÔ¨Åc class which models the forwarding behavior of packets belonging to that traf Ô¨Åc class. In ARC, nodes represent routing processes, and directed edges represent possible Ô¨Çow of trafÔ¨Åc enabled by exchange of route advertisements between routing processes. Using a single attribute edgeweight, ARC can model OSPF costs and AS path length. Finally, ARC 2Policy class Graph characteristics P1: srcanddstare always blocksrcanddstare in separate compo nents P2:All paths from srctodst traverses a waypointafter removing the waypoint, src anddstare in separate components P3:srccan reach dstwhen there are <K link failuresmincut of src"
230,Interval Universal Approximation for Neural Networks.txt,"To verify safety and robustness of neural networks, researchers have
successfully applied abstract interpretation, primarily using the interval
abstract domain. In this paper, we study the theoretical power and limits of
the interval domain for neural-network verification.
  First, we introduce the interval universal approximation (IUA) theorem. IUA
shows that neural networks not only can approximate any continuous function $f$
(universal approximation) as we have known for decades, but we can find a
neural network, using any well-behaved activation function, whose interval
bounds are an arbitrarily close approximation of the set semantics of $f$ (the
result of applying $f$ to a set of inputs). We call this notion of
approximation interval approximation. Our theorem generalizes the recent result
of Baader et al. (2020) from ReLUs to a rich class of activation functions that
we call squashable functions. Additionally, the IUA theorem implies that we can
always construct provably robust neural networks under $\ell_\infty$-norm using
almost any practical activation function.
  Second, we study the computational complexity of constructing neural networks
that are amenable to precise interval analysis. This is a crucial question, as
our constructive proof of IUA is exponential in the size of the approximation
domain. We boil this question down to the problem of approximating the range of
a neural network with squashable activation functions. We show that the range
approximation problem (RA) is a $\Delta_2$-intermediate problem, which is
strictly harder than $\mathsf{NP}$-complete problems, assuming
$\mathsf{coNP}\not\subset \mathsf{NP}$. As a result, IUA is an inherently hard
problem: No matter what abstract domain or computational tools we consider to
achieve interval approximation, there is no efficient construction of such a
universal approximator.","Neural networks and approximation. Over the past decade, machine learning with neural networks has revolutionized a vast array of tasks‚Äîfrom computer vision (Krizhevsky et al ., 2012), to naturallanguage processing (Mikolov et al ., 2013), to programanalysis tasks (Raychev et al ., 2015), and beyond. While these advances are recent, it has been wellknown that neural networks are a powerful class of models: The universal approximation theorem (Hornik et al ., 1989; Cybenko, 1989) states that neural networks can approximate any continuous function with arbitrary precision. Moreover, we only need a single hidden layer of neurons to realize this theorem. By adding more neurons, one gets a more and more precise approximation. The intuition is that each neuron can encode a step function. So, by adding more neurons, one gets a Ô¨Ånergrained, steplike approximation of a continuous function (see Nielsen (2015, Ch.4) for an interactive visualization). Abstract interpretation of neural networks. With the wide adoption of neural networks, new safety and security concerns arose. The most prominent property of study has been robustness (Good fellow et al ., 2015): small perturbations to the input of a network should not change the prediction. For example, a small change to an image of a stop sign should not cause a classiÔ¨Åer to think it is a speedlimit sign. A number of researchers have proposed the use of abstract interpretation (Cousot and Cousot, 1977) techniques to prove robustness of neural networks to small perturbations (Gehr et al., 2018; Wang et al ., 2018; Anderson et al ., 2019) and to train robust models (Mirman et al ., 2018; Gowal et al., 2018; Huang et al., 2019). Suppose we want to verify robustness of a neural network to small changes in the brightness of an image. We can represent a large set of images, with varying brightness, as an element of some abstract domain, and propagate it through the network, eÔ¨Äectively ‚Äúexecuting‚Äù the network on an intractably large number of images. If all images lead to the same prediction, then we have a proof that the network is robust on the original image. The simplest abstract domain that leads to practical veriÔ¨Åcation results in this setting is the interval domain. In our example above, if each pixel in a monochrome image is a real number r, then the pixel can be represented as an interval [r"
83,PROVEN: Certifying Robustness of Neural Networks with a Probabilistic Approach.txt,"With deep neural networks providing state-of-the-art machine learning models
for numerous machine learning tasks, quantifying the robustness of these models
has become an important area of research. However, most of the research
literature merely focuses on the \textit{worst-case} setting where the input of
the neural network is perturbed with noises that are constrained within an
$\ell_p$ ball; and several algorithms have been proposed to compute certified
lower bounds of minimum adversarial distortion based on such worst-case
analysis. In this paper, we address these limitations and extend the approach
to a \textit{probabilistic} setting where the additive noises can follow a
given distributional characterization. We propose a novel probabilistic
framework PROVEN to PRObabilistically VErify Neural networks with statistical
guarantees -- i.e., PROVEN certifies the probability that the classifier's
top-1 prediction cannot be altered under any constrained $\ell_p$ norm
perturbation to a given input. Importantly, we show that it is possible to
derive closed-form probabilistic certificates based on current state-of-the-art
neural network robustness verification frameworks. Hence, the probabilistic
certificates provided by PROVEN come naturally and with almost no overhead when
obtaining the worst-case certified lower bounds from existing methods such as
Fast-Lin, CROWN and CNN-Cert. Experiments on small and large MNIST and CIFAR
neural network models demonstrate our probabilistic approach can achieve up to
around $75\%$ improvement in the robustness certification with at least a
$99.99\%$ confidence compared with the worst-case robustness certificate
delivered by CROWN.","Despite the recent advances and successes of deep neural networks in many machine learning tasks, it has been shown that adversarial examples exist and can be easily crafted, spanning from image classiÔ¨Åcation [ 1] to speech recogni tion [ 2] to malware detection [ 3] and sparse regression [ 4], just to name a few. Although deep neural networks have achieved unprecedented performance in these applications, their lack of robustness against adversarial perturbations [5,6] has raised serious concerns and has drawn a great deal of attention by the machine learning communities, as many safetycritical tasks cannot afford the potential risks incurred by adversarial examples. While there is a growing interest in crafting adversarial ex amples with stronger attacks under various settings (e.g., whitebox/greybox/blackbox attacks) and in developing effective defense strategies against adversarial attacks, the topic of assessing and verifying robustness properties of neu ral networks is equally important and challenging. Given a welltrained neural network model, we are interested in measuring its robustness on an arbitrary natural example x0by examining if the neighborhood of x0has the same prediction results; this serves as a robustness proxy for eval uating the ease with which one can turn x0into adversarial examples via adversarial manipulations. Conventionally, the concept of neighborhood is characterized by an `pball centered at x0with radiusfor anyp1, where larger  indicates greater robustness. Ideally, for robustness evalua tion, we would like to Ô¨Ånd the smallest adversarial distortion imposed on x0that will change the model prediction, which is known as the minimum adversarial distortion . Unfor tunately, it has been shown that computing the minimum adversarial distortion on neural networks with ReLU activa tions is an NPcomplete problem [ 7,8], and hence formal veriÔ¨Åcation methods such as Reluplex [ 7] and Planet [ 9] are computationally demanding and cannot scale to large realistic networks. As an alternative to minimum adversarial distortion, the concept of solving for a (nontrivial) lower bound on min imum distortion as a certiÔ¨Åed robustness metric has been recently proposed in [ 10,11,12,13,14,15,16,17] and aparXiv:1812.08329v2  [cs.LG]  7 Jan 2019Manuscript under review Table 1: Table of Notation Notation DeÔ¨Ånition Notation DeÔ¨Ånition K number of output classes CDF cumulative distribution function f:Rn0!RKneural network classiÔ¨Åer pdf probability density function x02Rn0 original input vector FX CDF of a random variable X c= argminifi(x0) predicted class of input x0fX pdf of a random variable X gt(x) =fc(x)"
470,Complete Verification via Multi-Neuron Relaxation Guided Branch-and-Bound.txt,"State-of-the-art neural network verifiers are fundamentally based on one of
two paradigms: either encoding the whole verification problem via tight
multi-neuron convex relaxations or applying a Branch-and-Bound (BaB) procedure
leveraging imprecise but fast bounding methods on a large number of easier
subproblems. The former can capture complex multi-neuron dependencies but
sacrifices completeness due to the inherent limitations of convex relaxations.
The latter enables complete verification but becomes increasingly ineffective
on larger and more challenging networks. In this work, we present a novel
complete verifier which combines the strengths of both paradigms: it leverages
multi-neuron relaxations to drastically reduce the number of subproblems
generated during the BaB process and an efficient GPU-based dual optimizer to
solve the remaining ones. An extensive evaluation demonstrates that our
verifier achieves a new state-of-the-art on both established benchmarks as well
as networks with significantly higher accuracy than previously considered. The
latter result (up to 28% certification gains) indicates meaningful progress
towards creating verifiers that can handle practically relevant networks.","Recent years have witnessed substantial interest in methods for certifying properties of neural net works, ranging from stochastic approaches (Cohen et al., 2019) which construct a robust model from an underlying base classiÔ¨Åer to deterministic ones (Gehr et al., 2018; Katz et al., 2017; Xu et al., 2020) that analyze a given network as is (the focus of our work). Key Challenge: Scalable and Precise NonLinearity Handling Deterministic veriÔ¨Åcation meth ods can be categorized as complete or incomplete. Recent incomplete veriÔ¨Åcation methods based on propagating and reÔ¨Åning a single convex region (M√ºller et al., 2022; Dathathri et al., 2020; Tjan draatmadja et al., 2020) are limited in precision due to fundamental constraints imposed by convex relaxations. Traditional complete veriÔ¨Åcation approaches based on SMT solvers (Ehlers, 2017) or a single mixedinteger linear programming encoding of a property (Tjeng et al., 2019; Katz et al., 2017) suffer from worstcase exponential complexity and are often unable to compute sound bounds in reasonable timeframes. To address this issue, a BranchandBound approach (Bunel et al., 2020) has been popularized recently: anytimevalid bounds are computed by recursively splitting the prob lem domain into easier subproblems and deriving bounds on each of these via cheap and less precise methods (Xu et al., 2021; Wang et al., 2021; Palma et al., 2021; Henriksen & Lomuscio, 2021). This approach has proven effective on (smaller) networks where there are relatively few unstable activations and splitting a problem simpliÔ¨Åes it substantially. However, for larger networks or those not regularized to be amenable to certiÔ¨Åcation this strategy becomes increasingly ineffective as the larger number of unstable activations makes individual splits less effective, which is exacerbated by the relatively loose underlying bounding methods. This Work: BranchandBound guided by MultiNeuron Constraints In this work, we propose a novel certiÔ¨Åcation method and veriÔ¨Åer, called MultiNeuron Constraint Guided BaB (MNB AB), which aims to combine the best of both worlds: it leverages the tight multineuron constraints pro posed by M√ºller et al. (2022) within a BaB framework to yield an efÔ¨Åcient GPUbased dual method. 1arXiv:2205.00263v1  [cs.LG]  30 Apr 2022Published as a conference paper at ICLR 2022 The key insight is that the signiÔ¨Åcantly increased precision of the underlying bounding method substantially reduces the number of domain splits (carrying exponential cost) required to certify a property. This improvement is especially pronounced for larger and less regularized networks where additional splits of the problem domain yield diminishing returns. We release all code and scripts to reproduce our experiments at https://github.com/ethsri/mnbab . Main Contributions : ‚Ä¢ We present a novel veriÔ¨Åcation framework, MNB AB, which leverages tight multineuron constraints and a GPUbased dual solver in a BaB approach. ‚Ä¢ We develop a novel branching heuristic, ACS, based on information obtained from analyz ing our multineuron constraints. ‚Ä¢ We propose a new class of branching heuristics, CAB, applicable to all BaBbased veri Ô¨Åers, that correct the expected bound improvement of a branching decision for the incurred computational cost. ‚Ä¢ Our extensive empirical evaluation demonstrates that we improve on the state of the art in terms of certiÔ¨Åed accuracy by as much as 28% on challenging networks. 2 B ACKGROUND In this section, we review the necessary background for our method (discussed next). 2.1 N EURAL NETWORK VERIFICATION The neural network veriÔ¨Åcation problem can be deÔ¨Åned as follows: given a network f:X!Y , an input regionDX , and a linear property PY over the output neurons y2Y, provef(x)2P; 8x2D. We instantiate this problem with the challenging `1norm bounded perturbations and set Dto the`1ball around an input point x0of radius:D(x0) =fx2Xjjjx"
411,ArCOV19-Rumors: Arabic COVID-19 Twitter Dataset for Misinformation Detection.txt,"In this paper we introduce ArCOV19-Rumors, an Arabic COVID-19 Twitter dataset
for misinformation detection composed of tweets containing claims from 27th
January till the end of April 2020. We collected 138 verified claims, mostly
from popular fact-checking websites, and identified 9.4K relevant tweets to
those claims. Tweets were manually-annotated by veracity to support research on
misinformation detection, which is one of the major problems faced during a
pandemic. ArCOV19-Rumors supports two levels of misinformation detection over
Twitter: verifying free-text claims (called claim-level verification) and
verifying claims expressed in tweets (called tweet-level verification). Our
dataset covers, in addition to health, claims related to other topical
categories that were influenced by COVID-19, namely, social, politics, sports,
entertainment, and religious. Moreover, we present benchmarking results for
tweet-level verification on the dataset. We experimented with SOTA models of
versatile approaches that either exploit content, user profiles features,
temporal features and propagation structure of the conversational threads for
tweet verification.","In addition to being a medium for the spread and consumption of news, Twitter has been shown to capture the dynamics of realworld events includ ing the spread of diseases such as the seasonal inÔ¨Çuenza (Kagashe et al., 2017) or more severe epidemics like Ebola (Roy et al., 2020). Since the Ô¨Årst reported case of the Novel Coronavirus (COVID19) in China, in November 2019, the COVID19 topic has drawn the interest of many Arab users over Twitter. Their interest, reÔ¨Çected in the Arabic content on the platform, has reached a peak after two months when the Ô¨Årst case was reported in the United Arab Emirates late in January 2020. This ongoing pandemic has, unsur prisingly, spiked discussions on Twitter covering a wide range of topics such as general information about the disease, preventive measures, procedures and newlyenforced decisions by governments, up todate statistics of the spread in the world, and even the change in our daily habits and work styles. With the great importance and spread of COVID19 information, misinformation and fake news have in fected the Twitter stream. An early study quantify ing COVID19 medical misinformation on Twitter found that 25% of collected tweets contained mis information (Kouzy et al., 2020). During COVID 19 pandemic, we observed that misinformation stretched beyond spreading fake and potentially harmful medical information, to information that can have adverse negative political effects (exam ple: ‚Äú In light of the unresponsiveness of Yemeni government to requests of evacuation from Yemeni students in Wuhan, Sultan of Oman orders their evacuation .‚Äù) and economical effects too (example: ‚ÄúKuwaitis boycott AlMarai Saudi dairy company after reports on Coronavirus infected employees. ‚Äù). Combating the spread of such claims and verifying them becomes essential during this sensitive time. In this work, we aim to facilitate research on misinformation detection on social media during this complex and historical period of our time by introducing a manuallyannotated Arabic dataset, ArCOV19 Rumors , that covers tweets spreading COVID19 related claims. To construct ArCOV19 Rumors , we start from an existing COVID19 Ara bic dataset (Haouari et al., 2021), ArCOV19, that is the Ô¨Årst Arabic COVID19 Twitter dataset with propagation networks. Our proposed ArCOV19 Rumors includes a set of 138 COVID19 veriÔ¨Åed claims and 9.4K corresponding relevant tweets that were manuallyannotated to support both claim level andtweetlevel veriÔ¨Åcation tasks. Claimlevel veriÔ¨Åcation is deÔ¨Åned as follows: given a shortarXiv:2010.08768v2  [cs.CL]  13 Mar 2021Dataset # Tweets # Annotated Labels Multitask Conversations Manual Annot. Elhadad et al. (2020a) 220K 220K misleading, real    Alsudias and Rayson (2020) 1M 2K false, true, unrelated   Mubarak and Hassan (2020) 30M 8K rumor, info, advice, . . .   Alqurashi et al. (2021) 4.5M 8.8K misinformation, other   ArCOV19 Rumors 1M 9.4K false, true, other Table 1: Comparison between ArCOV19 Rumors and existing Arabic COVID19 datasets for veriÔ¨Åcation over tweets. freetext claim (in 1 or 2 sentences) and its corre sponding relevant tweets, predict whether the claim is true or false . Tweetlevel veriÔ¨Åcation is deÔ¨Åned as follows: given a tweet containing a claim, detect whether it is true or false . To our knowledge, ArCOV19 Rumors is the only Arabic dataset made available to support both claimlevel and tweetlevel veriÔ¨Åcation tasks in Twitter given the propagation networks of the tweets in general and on COVID19 in particu lar. Some related Twitter datasets were recently released by Alqurashi et al. (2021), Mubarak and Hassan (2020), Alsudias and Rayson (2020), and Elhadad et al. (2020a). None of these datasets has the propagation networks of the tweets, and they either support the tweet veriÔ¨Åcation task (El hadad et al., 2020a; Alsudias and Rayson, 2020), misinformation detection (Alqurashi et al., 2021) or multiclass categorization including rumors as one category (Mubarak and Hassan, 2020). Dif ferently from ArCOV19 Rumors , Elhadad et al. (2020a) used an automatic approach to annotate tweets, while Alsudias and Rayson (2020) only cover COVID19 healthoriented claims. Start ing from some health misinformation reported by the Ministry of Health in Saudi Arabia and the World Health Organization (WHO), Alqurashi et al. (2021) annotated COVID19 tweets as mis information or not. Differently, our dataset covers in addition to health, other types of claims that were inÔ¨Çuenced by COVID19, namely, social, pol itics, sports, entertainment, and religious. Table 1 demonstrates the differences between ArCOV19 Rumors and the aforementioned datasets. The contribution of this paper is threefold: ‚Ä¢We construct and release1the Ô¨Årst Arabic dataset for misinformation detection over Twitter, covering both claim and tweet ver iÔ¨Åcation tasks. It contains 138 COVID19 ver iÔ¨Åed claims that scale to 9.4K labeled relevant 1https://gitlab.com/bigirqu/ArCOV19/ /tree/master/ArCOV19Rumorstweets along with their propagation networks. ‚Ä¢We suggest and motivate several research tasks that can be addressed using our labeled dataset for misinformation detection. ‚Ä¢We present benchmark results on tweetlevel veriÔ¨Åcation using SOTA models that either exploit content, user proÔ¨Åles, or the temporal features and the propagation structure of the conversational threads. Results offer baselines for future research on the problem. The remainder of the paper is organized as fol lows. We present studies related to COVID19 misinformation analysis and datasets in Section 2. The construction of ArCOV19 Rumors is presented in Section 3. Several use cases supported by our dataset are discussed in Section 4. Our benchmarks and their performances are presented in Section 5. We detail the released components of the dataset in Section 6, and conclude in Section 7. 2 Related Work "
155,Deep Speaker: an End-to-End Neural Speaker Embedding System.txt,"We present Deep Speaker, a neural speaker embedding system that maps
utterances to a hypersphere where speaker similarity is measured by cosine
similarity. The embeddings generated by Deep Speaker can be used for many
tasks, including speaker identification, verification, and clustering. We
experiment with ResCNN and GRU architectures to extract the acoustic features,
then mean pool to produce utterance-level speaker embeddings, and train using
triplet loss based on cosine similarity. Experiments on three distinct datasets
suggest that Deep Speaker outperforms a DNN-based i-vector baseline. For
example, Deep Speaker reduces the verification equal error rate by 50%
(relatively) and improves the identification accuracy by 60% (relatively) on a
text-independent dataset. We also present results that suggest adapting from a
model trained with Mandarin can improve accuracy for English speaker
recognition.","Speaker recognition algorithms seek to determine the identity of a speaker from audio. Two common recognition tasks are speaker ver iÔ¨Åcation (determining whether a speaker‚Äôs claimed identity is true or false) and speaker identiÔ¨Åcation (classifying the identity of an unknown voice among a set of speakers). VeriÔ¨Åcation and identi Ô¨Åcation algorithms may require the speaker to utter a speciÔ¨Åc phrase (textdependent recognition) or be agnostic to the audio transcript (textindependent recognition). In all these subtasks, embedding methods can be used to map utterances into a feature space where distances correspond to speaker similarity. Though many algo rithms have pushed the stateoftheart over the past couple years [1][2][3][4][5][6][7], speaker recognition is still a challenging task. The traditional speaker recognition approach entails using i vectors [3] and probabilistic linear discriminant analysis (PLDA) [5]. This framework can be decomposed into three stages [4]: Step 1 Collect sufÔ¨Åcient statistics Step 2 Extract speaker embeddings (ivector) Step 3 Classify (PLDA) SufÔ¨Åcient statistics (also known as BaumWelch statistics) are com puted from a Gaussian Mixture ModelUniversal Background Model (GMMUBM), which is optimized using a sequence of feature vec tors (e.g., melfrequency cepstral coefÔ¨Åcients (MFCC) [3]. Recently, deep neural network (DNN) acoustic models have also been used to extract sufÔ¨Åcient statistics [4]. The highdimensional statistics are converted into a single lowdimensional ivector that encodes speaker identity and other utterancelevel variability. A PLDA model is then used to produce veriÔ¨Åcation scores by comparing ivectors from different utterances [5]. equally contributed to this workThe three steps of an ivector system are traditionally trained on subtasks independently, not jointly optimized. An alternative DNN based approach uses a classiÔ¨Åcation layer [8], combining both Step 1 andStep 2 . The intermediate bottleneck layer in the DNN provides a framelevel embedding, which can be used for speakers not included in the training set. During prediction, additional steps are required to aggregate framelevel representations and to perform veriÔ¨Åcation. This approach suffers from at least two major issues: (1) Step 1 and Step 2 are not directly optimized with respect to speaker recognition, and (2) there‚Äôs a mismatch between training and test. The training labels are given at the framelevel, while utterancelevel predictions are made in testing. [6] and [7] introduced endtoend neural speaker veriÔ¨Åcation systems, combining all three steps. [6] used the last frame output of a long shortterm memory (LSTM) [9] model as an utterancelevel speaker embedding, while [7] used a networkinnetwork (NIN) [10] nonlinearity followed by an utterancelevel pooling layer to aggre gate framelevel representations. Both [6] and [7] were trained using the same distance metric. In this paper, we extend the endtoend speaker embedding sys tems proposed in [6] and [7]. First, a deep neural network is used to extract framelevel features from utterances. Then, pooling and length normalization layers generate utterancelevel speaker embed dings. The model is trained using triplet loss [11], which minimizes the distance between embedding pairs from the same speaker and maximizes the distance between pairs from different speakers. Pre training using a softmax layer and crossentropy over a Ô¨Åxed list of speakers improves model performance. More speciÔ¨Åcally, we test convolutional neural network (CNN) based and recurrent neural network (RNN)based architectures for framelevel feature extraction, and present results both for speaker veriÔ¨Åcation and speaker identiÔ¨Åcation. CNNs are effective for reduc ing spectral variations and modeling spectral correlations in acous tic features [12]. CNNs have also recently been applied to speech recognition with good results [12][13][14][15]. Since deep networks can better represent long utterances than shallow networks [15], we propose a deep residual CNN (ResCNN), inspired by residual net works (ResNets) [16]. We also investigate stacked gated recurrent unit (GRU) [17] layers as an alternative for framelevel feature ex traction, since they have proven to be effective for speech processing applications [18][19]. Like [7], we use a distancebased loss function to discriminate between samespeaker and differentspeaker utterance pairs. How ever, unlike the PLDAlike loss function in [7], we train our networks so that cosine similarity in the embedding space directly corresponds to utterance similarity. We also select hard negative examples at each iteration by checking candidate utterances globally, not just in the same minibatch. This approach provides faster training conver gence. Finally, we evaluate our proposed Deep Speaker system on three different datasets, for textindependent and textdependent speaker 1arXiv:1705.02304v1  [cs.CL]  5 May 2017Figure 1: Diagram of the Deep Speaker architecture recognition tasks in both Mandarin and English. We also investi gate the effects of softmax pretraining, system combination, train ing dataset size, and enrollment utterance count. The experiments indicate Deep Speaker can signiÔ¨Åcantly improve over DNNbased ivector textindependent speaker recognition systems. In the text dependent task, Deep Speaker can match a DNN ivector baseline system, and improve upon it if Ô¨Ånetuned after textindependent training. In particular, two interesting results are shown: (1) Deep Speaker leverages big data well (performance boosts when trained on as many as 250,000 speakers), and (2) Deep Speaker can transfer well across spoken languages that are vastly different, i.e., Mandarin and English. 2 Related Work "
505,End-to-End Residual CNN with L-GM Loss Speaker Verification System.txt,"We propose an end-to-end speaker verification system based on the neural
network and trained by a loss function with less computational complexity. The
end-to-end speaker verification system in this paper consists of a ResNet
architecture to extract features from utterance, then produces utterance-level
speaker embeddings, and train using the large-margin Gaussian Mixture loss
function. Influenced by the large-margin and likelihood regularization,
large-margin Gaussian Mixture loss function benefits the speaker verification
performance. Experimental results demonstrate that the Residual CNN with
large-margin Gaussian Mixture loss outperforms DNN-based i-vector baseline by
more than 10% improvement in accuracy rate.","Speaker veriÔ¨Åcation (SV) aims to determine whether an utterance comes from the claimed identity or not. VeriÔ¨Åcation algorithm may require the speaker to utter a speciÔ¨Åc phrase (textdependent) or be agnostic to the audio transcript (text independent). In textindependent SV , no prior constraints are considered for the spoken phrases by the speaker, which makes it challenging compared to textdependent scenario. The conventional speaker veriÔ¨Åcation approach entails using ivectors [3] and probabilistic linear discriminant analysis (PLDA) [2]. As a supervised learning method, ivector requires sufÔ¨Åcient statistics which are computed from a Gaussian Mixture ModelUniversal Background Model (GMMUBM), followed by a PLDA model to produce veriÔ¨Åcation scores [3]. Recently, inspired by using deep neural network in Automatic Speech Recognition(ASR) [5], other research efforts have been conducted on the application of DNN in speaker veriÔ¨Åcation. DNN was used to extract abundant statistics and convert them from high dimension to a lowdimension vector, followed by a PLDA or SVM model trained to provide a classiÔ¨Åcation score. Recently, [10] introduced an endtoend system trained to discriminate between samespeaker and differentspeaker utterance pairs. First, a deep neural network is used to ex tract framelevel features from utterances. Then, pooling and length normalization layers generate utterancelevel speaker embedding, followed by a classiÔ¨Åer to give the different predictions to the utterances. The model to generate embed ding is trained with triplet loss [13], which minimizes the distance between embedding pairs from the same speaker and Corresponding authormaximizes the distance between pairs from different speakers. Based on the deep Residual CNN (ResNet) [14] and triplet loss [13], it outperformed the ivector speaker veriÔ¨Åcation system. Nevertheless, triplet loss is still not effective enough because the cosine distance among triplet features are added as additional loss at each time. It inevitably results in slow convergence and instability. By carefully selecting the image triplets, the problem may be partially alleviated. But it signiÔ¨Å cantly increases the computational complexity and the training procedure becomes inconvenient [16]. To circumvent the drawbacks of triplet loss, [16] introduced the center loss by minimizing the Euclidean distance between the features and the corresponding class centroid. However, the main drawback of Euclidean distance is that will result in the inconsistency of distance measurements in the feature space. The largemargin Gaussian Mixture (LGM) loss [15] was proposed to solve the drawbacks of center loss [16]. L GM loss adopted the Mahalanobis distance to measure the distance between extracted features and the feature centroid of ground truth class, which contributed LGM loss has a better performance in interclass dispension and intraclass compactness. In this paper, we extend the endtoend speaker embedding systems proposed in [10], but replace the triplet loss with largemargin Gaussian Mixture (LGM) loss [15] to get a bet ter performance in the computational complexity and accuracy. We use LGM loss under the assumption that the embeddings of speaker utterances follow a Gaussian mixture distribution approximately. Finally, we evaluate our speaker veriÔ¨Åcation system on dataset V oxCeleb [12] to investigate the performance. In the best case (=1) of ResNet + LGM loss system performs better than DNNbased ivector system, which improves the accuracy of veriÔ¨Åcation by more than 10%. We review the different methods for speaker veriÔ¨Åcation tasks in Section II and discuss the performance of them. In Section III, we propose the structure of the speaker veriÔ¨Åcation system in this paper and elaborate the LGM loss mathemati cally. The Experiments compared with the baseline are shown in Section IV . II. R ELATED WORK "
331,A Tale of Two Approximations: Tightening Over-Approximation for DNN Robustness Verification via Under-Approximation.txt,"The robustness of deep neural networks (DNNs) is crucial to the hosting
system's reliability and security. Formal verification has been demonstrated to
be effective in providing provable robustness guarantees. To improve its
scalability, over-approximating the non-linear activation functions in DNNs by
linear constraints has been widely adopted, which transforms the verification
problem into an efficiently solvable linear programming problem. Many efforts
have been dedicated to defining the so-called tightest approximations to reduce
overestimation imposed by over-approximation. In this paper, we study existing
approaches and identify a dominant factor in defining tight approximation,
namely the approximation domain of the activation function. We find out that
tight approximations defined on approximation domains may not be as tight as
the ones on their actual domains, yet existing approaches all rely only on
approximation domains. Based on this observation, we propose a novel
dual-approximation approach to tighten over-approximations, leveraging an
activation function's underestimated domain to define tight approximation
bounds. We implement our approach with two complementary algorithms based
respectively on Monte Carlo simulation and gradient descent into a tool called
DualApp. We assess it on a comprehensive benchmark of DNNs with different
architectures. Our experimental results show that DualApp significantly
outperforms the state-of-the-art approaches with 100% - 1000% improvement on
the verified robustness ratio and 10.64% on average (up to 66.53%) on the
certified lower bound.","Deep neural networks (DNNs) are the most crucial components in AIempowered software systems. They must be guaranteed reliable and secure when the hosting system is safetycritical. Robustness is central to their safety and reliability, ensuring that neural net works can function correctly even under environmental perturba tions and adversarial attacks [ 9,39,47]. Studying the robustness of DNNs from both training and engineering perspectives attracts researchers from both AI and SE communities [ 9,16,24,29,39,56]. More recently, the emerging formal verification efforts on the ro bustness of neural networks aim at providing certifiable robustness guarantees for the neural networks [ 15,23,45]. Certified robustness of neural networks is necessary for guaranteeing that the hosting software system is both safe and secure. It is particularly crucial to those safetycritical applications such as autonomous drivings [ 1,3], medical diagnoses [40], and face recognition [38]. Formally verifying the robustness of neural networks is compu tationally complex and expensive due to the high nonlinearity and nonconvexity of neural networks. The problem has been proved NPcomplete even for the simplest fullyconnected networks with the piecewise linear activation function ReLU [ 17]. It is signifi cantly more difficult for those networks that contain differentiable Scurve activation functions such as Sigmoid, Tanh, and Arctan [ 53]. To improve scalability, a practical solution is to overapproximate the nonlinear activation functions by using linear upper and lower bounds. The verification problem is then transformed into an ef ficiently solvable linear programming problem. The linear over approximation is a prerequisite for other advanced verification approaches based on abstraction [ 6,33,36], interval bound propa gation (IBP) [13], and convex optimization [35, 46]. As overapproximations inevitably introduce overestimation, the corresponding verification approaches sacrifice completeness and may fail to prove or disprove the robustness of a neural network [ 23]. Consequently, we cannot conclude that a neural network is notarXiv:2305.16998v1  [cs.LG]  26 May 2023ISSTA ‚Äô23, July 17‚Äì21, 2023, Seattle, WA, United States Zhiyi Xue, Si Liu, Zhaodi Zhang, Yiting Wu, and Min Zhang robust when we fail to prove its robustness via overapproximation. An ideal approximation must be as tight as possible to resolve such uncertainties. Intuitively, an approximation is tighter if it introduces less overestimation to the robustness verification result. Considerable efforts have been devoted to finding tight over approximations for precise verification results [ 21,22,41,48,53]. The definition of tightness can be classified into two categories: neuronwise and networkwise. An approximation method based on networkwise tightness is dedicated to defining a linear approx imation so that the output for each neuron in the neural network is tight. An approximation method based on neuronwise tightness only guarantees that the approximation is tight on the current neu ron, while it does not consider the tightness of networks widely. Lyu et al. [25] and Zhang et al. [55] claim that computing the tightest approximation is essentially a networkwise nonconvex optimization problem, and thus almost impractical to solve directly due to high computational complexity. Hence, approximating each individual activation function separately is still an effective and practical solution. Experimental results have shown that existing tightness characterizations of neuronwise overapproximations do not always imply precise verification results [ 35,55]. It is therefore desirable to explore missing factors in defining tighter neuronwise approximations. In this paper we report a new, crucial factor for defining tight overapproximation, namely approximation domain of an activation function, which is missed by all existing approximation approaches. An approximation domain refers to an interval of ùë•, on which an activation function ùúé(ùë•)is overapproximated by upper and lower linear bounds. Through both theoretical and experimental analyses, we identify that existing approaches rely only on the approxima tion domain of an activation function to define linear lower and upper bounds, yet the bound that is tight on the approximation domain may not be tight on the activation function‚Äôs actual domain . The actual domain of ùúé(ùë•)must be enclosed by the approximation domain to guarantee the soundness of the overapproximation. Un fortunately, computing the actual domain of an activation function on each neuron of a DNN is as difficult as the verification problem, thus impractical. Towards estimating the actual domain, we propose a novel dual approximation approach which, unlike existing approaches, lever ages the underestimated domain , i.e., an interval that is enclosed by the actual domain of an activation function, to define a tight linear approximation. We first devise two underapproximation algorithms to compute the underestimated domain based on Monte Carlo simulation and gradient descent, respectively. In the Monte Carlo algorithm, we select a number of samples from the perturbed input region and feed them into a DNN, recording the maximum and minimum of each neuron as the underestimated domain. For the gradientbased algorithm, we feed the image into a DNN to obtain the gradient of each neuron relative to the input. Based on this, we finetune the input value and feed them into the DNN again to get the underestimated domain. We then use both underestimated and approximation domains to define tight linear bounds for the activation function. Specifically, we define a linear overapproximation bound on the underestimated domain and check if it is valid on the approximation domain. In a valid case, we approximate the activation function using the bound;otherwise, we define a bound on the original approximation domain. The underestimated domain is an inner approximation of the actual domain, which guarantees tightness, whereas the approximation domain guarantees soundness. Through an extensive analysis on a wide range of benchmarks and datasets, we demonstrate that our dualapproximation approach can produce tighter linear approxi mation than the stateoftheart approaches that claim to provide the tightest approximation. In particular, our approach achieves 100%‚àí1000% improvement on the verified robustness ratio and 10.64%on average (up to 66.53%) on the certified lower bound. Overall, we make three main contributions: (1)We identify a crucial factor, called approximation domain , in defining tight overapproximation for the DNN robustness verification by a thorough study of the stateoftheart over approximation methods. (2)We propose two underapproximation algorithms for comput ing underestimated domains, together with a dualapproximation approach to defining tight overapproximation for the DNN ro bustness verification. (3)We implement our approach into a tool called DualApp and demonstrate its outperformance over the stateoftheart tools on a wide range of benchmarks. We also experimentally explore the optimal parameter settings for computing more precise underestimated approximation domains. 2 PRELIMINARIES 2.1 Deep Neural Networks A deep neural network (DNN) is a network of nodes called neurons connected end to end as shown in Figure 1, which implements a mathematical function ùêπ:Rùëõ‚ÜíRùëö, e.g.,ùëõ=3andùëö=2for the 2hiddenlayer DNN in Figure 1. Neurons except input ones are also functionsùëì:Rùëò‚ÜíRin the form of ùëì(ùë•)=ùúé(ùëäùë•+ùëè), whereùëòis the dimension of input vector ùë•,ùúé(¬∑)is called an activation function , ùëäa matrix of weights and ùëèa bias. During calculation, a vector ofùëõnumbers is fed into the neural network from the input layer and propagated layer by layer through the internal hidden layers after being multiplied by the weights on the edges, summed at the successor neurons with the bias and then computed by the neurons using the activation function. The neurons on the output layer compute the output values, which are regarded as probabilities of classifying an input vector to every label. The input vector can be an image, a sentence, a voice, or a system state, depending on the application domains of the deep neural network. Given anùëôlayer neural network, let ùëä(ùëñ)be the matrix of weights between the ùëñth and(ùëñ+1)th layers, and ùëè(ùëñ)the biases on the corre sponding neurons, where ùëñ=1,...,ùëô‚àí1. The function ùêπ:Rùëõ‚ÜíRùëö implemented by the neural network can be defined by: ùêπ(ùë•)=ùëä(ùëô‚àí1)ùúé(ùëß(ùëô‚àí1)(ùë•)), (Network Function) whereùëß(ùëñ)(ùë•)=ùëä(ùëñ)ùúé(ùëß(ùëñ‚àí1)(ùë•))+ùëè(ùëñ)(Layer Function) andùëß(0)(ùë•)=ùë• (Initialization) forùëñ=1,...,ùëô‚àí1. For the sake of simplicity, we use ÀÜùëß(ùëñ)(ùë•)to denoteùúé(ùëß(ùëñ)(ùë•))andŒ¶(ùë•)=arg max‚Ñì‚ààùêøùêπ(ùë•)to denote the label ‚Ñìsuch that the probability ùêπ‚Ñì(ùë•)of classifying ùë•to‚Ñìis larger than those to other labels, where ùêørepresents the set of all labels. TheTightening OverApproximation for DNN Robustness Verification via UnderApproximation ISSTA ‚Äô23, July 17‚Äì21, 2023, Seattle, WA, United States x1 x2 x3Input layerHidden layerHidden layer y1 y2Output layer W(1) b(1) b(2) W(2) W(3) Figure 1: A 4layer feedforward DNN with two hidden layers. activation function ùúéusually can be a Rectified Linear Unit (ReLU), ùúé(ùë•)=ùëöùëéùë•(ùë•,0)), a Sigmoid function ùúé(ùë•)=1 1+ùëí‚àíùë•, a Tanh func tionùúé(ùë•)=ùëíùë•‚àíùëí‚àíùë• ùëíùë•+ùëí‚àíùë•, or an Arctan function ùúé(ùë•)=ùë°ùëéùëõ‚àí1(ùë•). As ReLU neural networks have been comprehensively studied [ 23], we focus on the networks with only Scurved activation functions, i.e., Sigmoid, Tanh, and Arctan. Given a training dataset, the task of training a DNN is to finetune the weights and biases so that the trained DNN achieves desired precision on test sets. Although a DNN is a precise mathematical function, its correctness is very challenging to guarantee due to the lack of formal specifications and the inexplicability of itself. Unlike programmercomposed programs, the machinetrained models are almost impossible to assign semantics to the internal computations. 2.2 Neural Network Robustness Verification Despite the challenge in verifying the correctness of DNNs, formal verification is still useful to verify their safetycritical properties. One of the most important properties is robustness , stating that the prediction of a neural network is still unchanged even if the input is manipulated under a reasonable range: Definition 1 (Neural Network Robustness). A neural net workùêπ:Rùëõ‚ÜíRùëöis called robust with respect to an input ùë•0and an input region Œ©aroundùë•0if‚àÄùë•‚ààŒ©,Œ¶(ùë•)=Œ¶(ùë•0)holds. Usually, input region Œ©around input ùë•0is defined by a ‚Ñìùëùnorm ball aroundùë•0with a radius of ùúñ, i.e.Bùëù(ùë•0,ùúñ)={ùë•|‚à•ùë•‚àíùë•0‚à•ùëù‚â§ùúñ}. In this paper, we focus on the infinity norm and verify the robustness of the neural network in B‚àû(ùë•0,ùúñ)on image classification tasks. A corresponding robust verification problem is to compute the largest ùúñ0s.t. neural network ùêπis robust in B‚àû(ùë•0,ùúñ0). The largest ùúñis called a certified lower bound , which is a metric for measuring both the robustness of neural networks and the precision of robustness verification approaches. Another problem is to compute the ratio of pictures that can be classified correctly when given a fixed ùúñ, and that is called a verified robustness ratio. Assuming that the output label of ùë•0isùëê, i.e.Œ¶(ùë•0)=ùëê, proving ùêπ‚Äôs robustness in Definition 1 is equivalent to showing ‚àÄùë•‚ààŒ©,‚àÄ‚Ñì‚àà ùêø/{ùëê},ùêπùëê(ùë•)‚àíùêπ‚Ñì(ùë•)>0holds. Thus, the verification problem is equivalent to solving the following optimization problem: min ùë•‚ààŒ©(ùêπùëê(ùë•)‚àí max ‚Ñì‚ààùêø/{ùëê}(ùêπ‚Ñì(ùë•))) (1) We can conclude that ùêπis robust in Œ©if the result is positive. Oth erwise, there exists some input ùë•‚Ä≤inŒ©and‚Ñì‚Ä≤inùêø/{ùëê}such that x1 x2y1 y2 ["
