This paper presents McNetKAT, a new tool for reasoning about probabilistic network programs written in the guarded and historyfree fragment of Probabilistic NetKAT (ProbNetKAT). The fragment is a restriction of the full language, but it is expressive enough to encode a wide range of practical network models. The fragment is based on Kleene Algebra with Tests, and it is capable of modeling a variety of probabilistic behaviors and properties including randomized routing, uncertainty about demands, and failures. We first reformulate the fragment in terms of Markov chains, using
Financial deep learning has been explored for a wide range of different financial services applications, including credit card default prediction, exchange rate prediction, and anti-money laundering. However, one particular question that often arises as a barrier to adopting deep learning for financial services in realworld practice is whether the developed financial deep learning models are fair in their predictions. This is particularly crucial in light of strong governance and regulatory compliance requirements in the financial services industry, as well as the socioeconomic context. In this study, we explore the feasibility and utility of multiscale trust quantification metrics for financial deep learning to gain insights into the fairness
This paper presents a novel technique for modular verification of control planes. We leverage the inherent modularity of the control plane to cut a monolithic network into multiple fragments to be verified independently. We do this by leveraging the Stable Routing Problem (SRP) model, which is a general model for distributed routing. We then implement the technique as an extension to the NV network verification language and tool. We also introduce a new model for a distributed routing protocol, called “open SRPs”. This model is a network is a single fragments of nodes.
ASV, which verifies and compares the speaker identity of an input utterance with enrollment data, is an extensively used biometric method. With the development of deep learning, deep neural networks (DNN) have been successfully applied to both text-dependent and text-independent ASV tasks. In this paper, we propose a novel approach to extract utterance-level speaker representative vectors (also called speaker embeddings) from the hidden layer of a DNN. The frontend speaker encoder mainly consists of a frame-level feature extractor, a pooling layer
In this paper, we propose a novel approach to the segmentation of handwritten signatures on images. We use a Fully Convolutional Network (FCN) for this task, which is able to get around the problems presented during the capture of signature images in different identification documents in noisy environments. Our approach is based on the use of a fully convolutional network (FCN) with refinement layers for the alpha channel of the image. The proposed system is able to segment handwritten signatures with greater fidelity in the strokes, preserving the graphic characteristics of the signatures.
In this paper, we verify the security of the protocol of the Lightning Network, a payment channel network for Bitcoin. The Lightning Network is a protocol between two users that enables them to perform multi-hop transactions without writing to the blockchain. The security model for payment channels requires that honest parties retrieve at least their correct balance even if all other users behave adversarially. To avoid financial loss caused by design flaws in a payment channel protocol, it should be verified that the protocol is secure. To verify the security properties of the protocol, we formalize the protocol specification of the ideal functionality of a payment
Network policy enforcement has been and continues to be a challenging and error-prone task. Recent efforts on network testing and verification (e.g., [26,42,43,44]) offer a promising alternative to existing expensive and manual debugging efforts. However, there are fundamental gaps between the intent of network operators and the capabilities of existing network checking mechanisms. Specifically, there are fundamental gaps between the intent of network operators and the capabilities of existing network checking mechanisms on two fronts: (1) data plane elements are complex and stateful (e.
In fingerprint recognition, domain-specific prior knowledge has played the dominant role in determining the representation scheme, leading to mostly hand-designed features. With the advent of deep learning and its tremendous success in various applications, the concept of data-driven representation learning has come to the fore. In this work, we propose a novel ensemble learning approach to improve the performance of a state-of-the-art deep neural network based fingerprint recognition model called DeepPrint (DP). We propose a novel ensemble learning approach to learn five fingerprint representations from a single image using a deep neural network architecture
In this paper, we propose a novel Random Number Generator (LRNG) based on lin-ear feedback shift registers (LFSRs). LFSRs are widely used in wireless communication such as Bluetooth, where they are used to encrypt frequency hopping spread spectrum systems to protect against signal jamming kind of attacks. LRNGs are easily implementable on low-power, low-cost, field-programmable gate array (FPGA) boards. The LRNG bit stream is implemented on FPGA boards suitable for BB84 protocol. It is implemented on low-cost
The Beacon Chain is the backbone component of Ethereum 2.0. It coordinates the whole network of stakers and shards. The reference implementation of the Beacon Chain is written in Python and provides a detailed operational description of the state machine each Beacon Chain's network participant (node) must implement. The reference implementation is written in a Pythonlike language. As a result, inaccuracies, ambiguities, or bugs in it could badly impact the network. As a result,
In this paper, we present a proof production mechanism for search-based DNN verifiers. The proof certificate is produced using a constructive version of Farkas’ lemma, which guarantees the existence of a witness to the unsatisfiability of a set of linear equations. The proof certificate is checked using simple, external checkers. The proof certificate is produced using a constructive version of Farkas’ lemma, which guarantees the existence of a witness to the unsatisfiability of a given set of linear equations. The proof certificate is easily
Quantum and quantuminspired machine learning algorithms have been gaining increasing interest in the real-world problems, which are, however, less known so far. In this work, we study the applicability of quantum and quantuminspired machine learning algorithms to stock return prediction, which is a principal problem in nance. We use a set of stocks in the Japanese stock market to conduct a backtesting experiment on the performance of quantum neural network, tensor network, standard linear regression, and neural network. We observe that the quantum neural network model outperforms the classical neural network model in the back
Deep neural networks (DNNs) have been used in many complex tasks. However, they are also vulnerable to adversarial attacks. As a result, DNNs are vulnerable to many attacks, including a malicious user. To enable robustness against adversarial attacks, we need to overestimate the computation of DNNs. To achieve this, we need to use a program reasoning framework that can overestimate the computation of DNNs. We propose a symbolic reasoning framework that can be used to verify DNNs with non-linear perturbations and unconventional architectures. We will demonstrate
In this paper, we study the problem of reachable set estimation and safety verification for closed-loop systems equipped with neural network controllers. The reachable set estimation problem is a computationally challenging problem, especially for neural networks with rectified linear unit activation functions. In particular, a mixed-integer linear programming (MILP) based approach is developed for the verification of neural networks with rectified linear unit activation functions. In particular, a simulation-based approach is developed for the verification of neural networks with rectified linear unit (R eLU) activation functions. The reachable set
In this work, we propose a novel method for monitoring hypofractionated lung radiotherapy. The method is based on the principle of averaging the irradiation field apertures in cine mode. The method is based on a novel template matching technique based on cross-correlation coefficients. The proposed method was validated on 5 patients with non-small cell lung cancer and one patient with metastasis. The proposed method was validated on 5 patients with non-small cell lung cancer and one patient with metastas
Graph neural networks (GNNs) are generalizations of neural networks that operate on graph structured data, typically in the form of an adjacency matrix or graph laplacian, and feature vectors defined for the nodes. Recently, recent theoretical work has elucidated properties on their depth (Oono & Suzuki (2019)), architectural alignment with algorithms (Xu et al. (2019)), and their discriminative power (Xu et al. (2018)). In this paper, we extend this framework for GNNs, and introduce a novel method to
In this work we consider control systems where the plant model is given as a nonlinear ordinary differential equation (ODE) and the controller is implemented by a neural network. We call such systems neuralnetwork control systems (NNCS). In principle, reachability analysis for NNCS can be implemented by chaining two off-the-shelf tools for analyzing the ODE and the neural network. The output set of one tool is the input set to the other, and this process is repeated for each control cycle. While correct, this approach often yields sets that are too conservative to be useful
Deep Neural Networks (DNNs) have emerged as an effective approach for solving challenging real-world problems. However, they can have “bugs”, e.g., producing unexpected results on inputs that are different from those in training data, and be attacked, e.g., small perturbations to the inputs by a malicious adversary or even sensorial imperfections result in misclassification. To address this question, researchers have developed a variety of techniques and tools to verify DNNs (e.g., SAT) solvers (SMT) solvers
Deep neural networks (DNNs) have been developed for a variety of tasks, including malware detection, abnormal network activity detection, and self-driving cars. While the accuracy of neural networks has greatly improved, they are susceptible to adversarial examples, which pose chal lenges for self-driving cars, where neural network solutions have been proposed for tasks such as end-to-end steering, road segmentation, and trac sign classi cation. In this paper, we propose a novel game-based approach for robustness verification of DNNs. We consider two point
In this paper, we revisit the verification-based defenses against model stealing. In particular, we focus on the case of watermarking, which is a defense against model stealing. We show that the defenses fail to meet all the requirements of effectiveness and harmlessness. Specifically, effectiveness requires that it can accurately identify whether the suspicious model is stolen from the victim model, no matter what model stealing is adopted; Harmlessness ensures that the model trained with the watermarked dataset has similar prediction behaviors to the one trained with the benign dataset. We show that the defenses fail to meet all the requirements
In this paper, we propose a novel approach to the generic reachability problem, which, for a given deep neural network, computes the upper and lower bounds over the values of a generic function over the outputs of the network. The function is generic, with the only requirement that it is Lipschitz continuous. Existing approaches to this problem are based on constraint satisfaction techniques, which are able to achieve guarantees, but suffer from two major weaknesses. Firstly, they can only work with layers conducting linear transformations (such as ReLU) and they cannot work with other important layers, such
Deep neural networks (DNNs) have become one of the most widely used tools for dealing with complex and challenging problems in numerous domains, such as image classification, function approximation, and natural language translation. However, DNNs possess complex nonlinear characteristics, which make their safety and robustness challenging. In this paper, we introduce the NNV (Neural Network Veri cation) tool, which is a software framework that performs set-based verification for DNNs and learning-enabled CPS, known collotopes, which are a DNN
Spinal fusion surgery is a high-risk surgery with high economic burden. Despite substantial improvements in operative technique, the number of misplaced pedicle screws remains high. Currently, intraoperative 3D conebeam CT (CBCT) imaging using mobile and robotic systems is not being used for spinal fusion. Compared to CT, CBCT images suffer from substantially stronger metal artifacts around the highlyattenuating titanium implants. This compromises the value of intraoperative CBCT for assessing cort.
This paper presents two new fault injection (FI) frameworks for TensorFlow. InjectTF for TensorFlow 1 and InjectTF2 for TensorFlow 2. The frameworks allow the user to model soft errors during the execution of a neural network, analyze the effects of such errors, and identify the most critical parts of the network. The results show which erroneous operations or layers have the largest impact on the accuracy, allowing the introduction of efficient selective fault protection mechanisms. The results show which errone
Topology design optimization is a branch of design optimization that aims to optimize the initial design of a part without a meaningful initial design. Currently, topology design optimization algorithms are trained using convolutional neural networks (CNNs) and require large data sets to achieve the best results. However, the training process of the CNNs is an inverse problem that emphasizes the existence, uniqueness, and efficiency of the results. In this paper, we present a new constrained topology optimization approach based on a conditional Wasserstein generative adversarial generative adversarial network (
Face anti-spoofing has been a promising topic in computer vision research, which is regarded as a very challenging problem in remote scenarios. However, face anti-spoofing methods mainly rely on the use of depth sensors, which increases the system cost. In this paper, we propose a simple, fast yet effective face anti-spoofing system termed Aurora Guard (AG). Its principle is using light reflection to disentangle two auxiliary information, i.e., depth and material, to consolidate the liveness judgment.
Deep Neural Network (DNN) is a powerful tool for machine learning, image processing, and data mining. However, the training process of DNN requires a large amount of training data, which often increases monotonically with the volume of training data. To protect both the valuable training data and the trained DNN models from being illegally copied, redistributed or misused, it becomes a compelling need that motivates our research work reported in this article. In this paper, we propose a unified framework called FedIPR which consists of two separate processes:
In recent years, Convolutional neural networks (CNNs) have already surpassed humans’ abilities on several benchmarks. In the field of face verification, CNNs have already surpassed humans’ abilities on several benchmarks. In this paper, we demonstrate that feature normalization is a crucial step to get good performance during testing. To illustrate this, we performed an experiment which compared the face features without normalization, i.e.using the unnormalized inner product or Euclidean distance as the similarity measure. The results are listed in Table 1.
In this work, we propose a novel loss function called octuplet loss that leverages the advantages of the widespread triplet loss concept to capture the relationships between high and low-resolution images and identity labels. We fine-tune an existing network to improve its robustness against image resolution while maintaining its performance in controlled scenarios. Our approach is based on a novel metric learning approach called octuplet loss finetuning. This approach can be easily applied to existing networks to improve their robustness against image resolution while maintaining comparable performance on high-quality images. We demonstrate that
Deep neural networks (DNNs) are a powerful tool to identify patterns in large amounts of data and to make predictions on new, previously unseen data. Due to the increased hardware capabilities, DNNs can be run even on small, battery powered hardware and can be trained in performance-optimized GPUs. Moreover, the introduction of high level APIs such as tf.keras (see tensorflow.org) allows even software engineers with no previous experience in artificial intelligence to define, train, and to DNNs. In this paper, we propose that DLS
In this work, we propose a hybrid quantum-classical algorithm for certifying the robustness of neural networks. The hybrid algorithm is based on a hybrid of quantum-classical and gate-based QC. The hybrid algorithm is based on a hybrid of quantum-classical and gate-based QC. The hybrid algorithm is a hybrid of a quadratic unconstrained binary optimization (QUBO) and a linear program (LP). The LP generates cuts for the QUBO which is solved by a quantum computer. We derive bounds for the minimum
Convex-based convolutional neural networks (CCNNs) are a class of convex-based neural networks that are trained by solving a non-convex optimization problem. This problem is known to be NP-hard, and is commonly used to train CNNs. However, the rate of convergence of CNNs is slow due to non-convexity, and the statistical properties of CCNNs are difficult to understand. In this paper, we propose a new class of convex-based neural networks (CCNNs) convex-based convex
Deep Learning (DL) is a class of machine learning models that are increasingly used in many industries. The training process for these models requires a substantial quantity of computational resources, which traditional CPUs are unable to fulfill. At the same time, the DL model building process is increasingly outsourced to the cloud. This is natural, as applying cloud services (e.g., Amazon EC2, Microsoft Azure or Google Cloud) for DL model training can be more fiscally palatable for companies by enabling them to focus on the software. To address these limitations, we introduce GOAT (See Figure
In this paper, we propose a novel approach to the safety evaluation of neural network controlled systems. In this paper, we propose a novel approach to the safety evaluation of neural network controlled systems, based on the principle of a probabilistic approach. The proposed approach is based on the principle of probabilistic approach, which is based on the assumption that the neural network controlled system is safe. In this paper, we propose a probabilistic approach to the safety evaluation of neural network controlled systems, based on the principle of probabilistic approach.
Face aging has raised considerable attentions in computer vision and machine learning communities recently. However, the synthesized results in these previous approaches are still far from perfect due to various challeng ing factors, such as heredity, living styles, etc. In this paper, we propose a novel approach to synthesize faces at older ages, i.e. age progression, or younger ages, i.e. age regression or deaging. In this paper, we propose a novel approach to synthesize faces at older
In the field of image fusion, the existing image fusion methods have paid little attention to the characteristics of human visual perception system. In this paper, we propose a cross-modal image fusion method based on the human brain image fusion mechanism. Our method is more consistent with the human brain image fusion mechanism. We use the enhanced vision system (EVS) and synthetic vision system (SVS) images in CVS image fusion data set to do qualitative comparison experiments. We show that our method has a good fusion effect for image details. In order to narrow the gap between
Recurrent neural networks (RNNs) are widely used to model long-term dependencies in lengthy sequential signals. However, certifying the robustness of recurrent architectures is critical for their safe deployment. As a result, current certification solutions do not scale beyond simple models and datasets, which limits their practical applicability. Further, there has been no work on verifying real-world use cases of RNNs. In this paper, we present the first precise and scalable verifier for RNNs based on abstract interpretation (Prover)
In this paper, we propose three novel reachability algorithms: APNM, PAPNM, and EPNM. The algorithms compute an overapproximation for the output, while EPNM computes the exact map ping. The algorithms are highly parallelizable and can be applied to large models. The algorithms are based on the use of a formal verification procedure, which is a formal procedure that aims to verify that the model behaves as expected under some circumstances or within a speci ed domain region. The proposed algorithms are highly paralleliz
Full-waveform inversion (FWI) is a widely used inversion method in seismic exploration. It is a PDE-constrained optimization problem that solves the wave equation to predict seismic waves based on the velocity model. The objective function of FWI is nonlinear and suffers from cycle skipping, a L2norm loss, and noise in real seismic recording. In this paper, we propose a novel approach to improve the stability of FWI by using deep learning to solve the wave equation. We propose a novel approach to formulate FWI as a PDE-
Handwriting verification is a task of forensic document examiners (FDE) to provide explanations for the decision made by the system. The FDE's are still unconvinced with the handwriting verification systems because: (1) The output of such systems is difficult to interpret because the system does not provide explanations for the decision. (2) The system is opaque and the innerworking of the system is unclear. In this paper, we propose an explanation based handwriting verification system which generates comprehensible reports for the task of
In this paper, we propose a novel Bottom-Up Pattern Matching (BUPM) based veri cation network for identifying fake news. BUPM is based on a novel bottom-up pattern matching (BUPM) approach, which directly compares a query image and a reference image collected from a claimed GPS location. BUPM is a novel BUPM-based veri cation network, which is based on a novel bottom-up pattern matching (BUPM) algorithm.
The pedestrian reidentification (reID) is a common image retrieval problem, which matches pedestrians from different cameras. The reidentification is usually viewed as an image retrieval problem, which matches pedestrians from different cameras. Recently, the convolutional neural network (CNN) has shown potential for learning state-of-the-art feature embeddings or deep metrics. As shown in Fig. 1, there are two major types of CNN structures, i.e.,verification models and identification models. The two major drawback of the
Deep neural networks (DNNs) have been widely used in various domains such as natural language processing, image classification, and game playing. However, DNNs have been found lacking robustness. For example, it is possible to add a small, or even imperceptible, perturbation to a correctly classified input and make it misclassified. Such adversarial examples have raised serious concerns on the safety of DNNs. In this paper, we propose a novel symbolic propagation technique to enhance the precision of abstract interpretation based on the use of a new abstract domain specially for DNN
Recent advances in deep neural networks (DNNs) have improved the performance of speaker verification (SV) systems, including shortduration and farfield scenarios. However, SV systems are vulnerable to various presentation attacks, such as replay attacks, voice conversion, and speech synthesis. These vulnerabilities have inspired research into presentation attack detection (PAD), which classifies given utterances as spoofed or not spoofed. In this paper, we propose two spoofing-aware frameworks for the ISV task, which is a single DNN architecture. We use a light
Face verification in unconstrained settings is a challenging problem. Despite the excellent performance of recent face verification systems on datasets like Labeled Faces in the Wild (LFW), it is still difficult to achieve similar accuracy on faces with extreme variations in viewpoints, resolution, occlusion and image quality. Existing face recognition training datasets contain large amount of high quality and frontal faces, whereas the unconstrained and difficult faces occur rarely. Using the softmax loss function for training face verification system has its own advantages and disadvantages. On the other hand, it is biased to the sample
In this paper, we propose a novel loss function named Git loss to enhance the discriminative power of deeply learned face features. The proposed loss function simultaneously minimizes intraclass variations and maximizes interclass distances. The proposed loss function is based on two common Git commands, "push" and "pull", which are semantically similar to the aim of this work: push away features of different identities while pulling together features belonging to the same identity. The proposed loss function is easily implementable with standard CNN architectures. We evaluate the proposed loss function on available datasets. We demonstrate state-of the
The lack of a prescribed, analytical process has implications on the accuracy and reliability of energy savings. This is less of an issue in residential and commercial applications as the nature of the energy systems in place are more simplistic. In contrast, industrial buildings contain complex energy systems with many variables impacting on energy consumption. The lack of a prescribed, analytical process has implications on the accuracy and reliability of energy savings. This has created a need for a machine learning supported methodology to overcome these challenges. This paper proposes a machine learning supported methodology to overcome these challenges
Handwriting recognition is the process of translating handwritten text images into strings of characters. Handwriting recognition traditionally involves two steps: optical character recognition and linguistic processing. Linguistic processing aims at combining the characters hypotheses together so as to provide the most likely sequence of words in accordance with some high level linguistic rules. There is currently no efficient alternative to the use of lexicon driven approaches, either for isolated characters or for text recognition. In this work, we propose a new recognition paradigm that improves handwriting recognition state of the current
In this paper, we propose a novel deep neural network-based system for text-independent speaker verification (TISV). TISV is a task where the utterances are recorded and analyzed by a deep neural network (DNN). The DNN is trained on a large amount of utterances and generates correlating speaker embeddings. Then, the two speaker embeddings are fed into a backend model, such as probabilistic linear discriminant analysis (PLD A) or probabilistic linear similarity score. The similarity score is computed
Authorship Veri cation (AV) is a branch of forensic authorship analysis. It is a branch of forensic authorship analysis that aims to verify the identity of the users by comparing their writing styles. Traditionally, the AV problem considered a closed and limited set of authors and a closed set of documents written by those authors. During the training step some of these documents were observed. Then, the problem was to identify whether the authors of a pair of documents from the rest of the document set were identical. In this paper, we propose two different schemas to
Face recognition networks have been used in a large number of applications. However, face recognition networks are biased against sensitive attributes such as gender, race and skintone. This has raised concerns about bias against sensitive attributes such as age, gender and race. In this paper, we propose two novel know-edge distillation-based techniques called D&D and D&D++ to mitigate bias with respect to sensitive attributes. Our methods are able to incrementally learn different categories of a given sensitive attribute while significantly reducing bias with respect to that attribute. We show that our methods can be used to reduce bias with respect to the
Deep learning has been achieving top performance on many tasks such as object recognition, speech recognition, natural language processing, and so on. However, deep learning models are treated as valuable intellectual properties. In such a situation, some malicious model user might redistribute licensed models illegally or provide a prediction service using the licensed model without permission. Also, some model user might leak the architecture and weight parameters of the licensed model in public unintentionally. To deal with such leakage, we require a method that allows us to verify the ownership of the model owner
Face Recognition is a challenging problem in image processing. Currently, there is no standard approach for face recognition. In this paper, we propose a novel approach to face recognition using deep learning. We propose a novel approach to face recognition using deep learning. We present a novel approach to face recognition using deep learning. We present a novel approach to face recognition using deep learning. We present a novel approach to face recognition using deep learning. We present a novel approach to face recognition using deep learning.