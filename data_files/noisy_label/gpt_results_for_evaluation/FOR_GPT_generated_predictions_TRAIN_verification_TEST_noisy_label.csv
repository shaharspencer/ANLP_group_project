Unnamed: 0,titles,abstract,introduction,prediction,result
464,Using Trusted Data to Train Deep Networks on Labels Corrupted by Severe Noise.txt,"The growing importance of massive datasets used for deep learning makes
robustness to label noise a critical property for classifiers to have. Sources
of label noise include automatic labeling, non-expert labeling, and label
corruption by data poisoning adversaries. Numerous previous works assume that
no source of labels can be trusted. We relax this assumption and assume that a
small subset of the training data is trusted. This enables substantial label
corruption robustness performance gains. In addition, particularly severe label
noise can be combated by using a set of trusted data with clean labels. We
utilize trusted data by proposing a loss correction technique that utilizes
trusted examples in a data-efficient manner to mitigate the effects of label
noise on deep neural network classifiers. Across vision and natural language
processing tasks, we experiment with various label noises at several strengths,
and show that our method significantly outperforms existing methods.","Robustness to label noise is set to become an increasingly important property of supervised learning models. With the advent of deep learning, the need for more labeled data makes it inevitable that not all examples will have highquality labels. This is especially true of data sources that admit automatic label extraction, such as web crawling for images, and tasks for which highquality labels are expensive to produce, such as semantic segmentation or parsing. Additionally, label corruption may arise in data poisoning [9, 23]. Both natural and malicious label corruptions tend to sharply degrade the performance of classiÔ¨Åcation systems [29]. Most prior work on label corruption robustness assumes that all training data are potentially corrupted. However, it is usually the case that a number of trusted examples are available. Trusted data are gathered to create validation and test sets. When it is possible to curate trusted data, a small set of trusted data could be created for training. We depart from the assumption that all training data are potentially corrupted by assuming that a subset of the training is trusted. In turn we demonstrate that having some amount of trusted training data enables signiÔ¨Åcant robustness gains. To leverage the additional information from trusted labels, we propose a new loss correction and empirically verify it on a number of vision and natural language datasets with label corruption. SpeciÔ¨Åcally, we demonstrate recovery from extremely high levels of label noise, including the dire case when the untrusted data has a majority of its labels corrupted. Such severe corruption can occur in adversarial situations like data poisoning, or when the number of classes is large. In comparison to Equal contribution. 32nd Conference on Neural Information Processing Systems (NIPS 2018), Montr√©al, Canada.arXiv:1802.05300v4  [cs.LG]  28 Jan 2019loss corrections that do not employ trusted data [17], our method is signiÔ¨Åcantly more accurate in problem settings with moderate to severe label noise. Relative to a recent method which also uses trusted data [10], our method is far more dataefÔ¨Åcient and generally more accurate. These results demonstrate that systems can weather label corruption with access only to a small number of gold standard labels. Experiment code is available at https://github.com/mmazeika/glc. 2 Related Work","We demonstrate that having some amount of trusted training data enables significant robustness gains. To leverage the additional information from trusted labels, we propose a new loss correction and empirically verify it on a number of vision and natural language datasets with label corruption. We demonstrate recovery from extremely high levels of label noise, including the dire case when the untrusted data has a majority of its labels corrupted. Relative to a recent method which also uses trusted data, our method is far more dataefficient and generally more accurate. Our results demonstrate that systems can weather label corruption with access to a small number","85,100"
481,Joint Negative and Positive Learning for Noisy Labels.txt,"Training of Convolutional Neural Networks (CNNs) with data with noisy labels
is known to be a challenge. Based on the fact that directly providing the label
to the data (Positive Learning; PL) has a risk of allowing CNNs to memorize the
contaminated labels for the case of noisy data, the indirect learning approach
that uses complementary labels (Negative Learning for Noisy Labels; NLNL) has
proven to be highly effective in preventing overfitting to noisy data as it
reduces the risk of providing faulty target. NLNL further employs a three-stage
pipeline to improve convergence. As a result, filtering noisy data through the
NLNL pipeline is cumbersome, increasing the training cost. In this study, we
propose a novel improvement of NLNL, named Joint Negative and Positive Learning
(JNPL), that unifies the filtering pipeline into a single stage. JNPL trains
CNN via two losses, NL+ and PL+, which are improved upon NL and PL loss
functions, respectively. We analyze the fundamental issue of NL loss function
and develop new NL+ loss function producing gradient that enhances the
convergence of noisy data. Furthermore, PL+ loss function is designed to enable
faster convergence to expected-to-be-clean data. We show that the NL+ and PL+
train CNN simultaneously, significantly simplifying the pipeline, allowing
greater ease of practical use compared to NLNL. With a simple semi-supervised
training technique, our method achieves state-of-the-art accuracy for noisy
data classification based on the superior filtering ability.","Convolutional Neural Networks (CNNs) have led to great improvements in many supervised tasks. However, CNNs‚Äô performance relies heavily on the quality of labels, and accurately labeling a huge amount of data is expen sive and timeconsuming. Furthermore, accurate labeling is done by hand, which can eventually lead to mismatched labeling. Therefore, the robust training of CNNs with noisy data is of great practical importance. There are many ap proaches regarding this issue. For example, there are methods that design noiserobust loss [4, 3, 29, 18], use two neu ral networks to select clean labels [6, 33, 30], and utilize label correction [22, 31]. These existing approaches com monly use the given labels in a direct manner, i.e., ‚Äúinput image belongs to this label‚Äù ( Positive Learning; PL ). This behavior carries the risk of providing faulty information to the CNNs when noisy labels are involved. Motivated by this reason, Negative Learning for Noisy Labels; NLNL [12], which is an indirect learning method for training CNNs, has been proposed recently. Negative Learning (NL) uses randomly chosen complementary la bels and trains the CNN that ‚Äúinput image does not belong to this complementary label,‚Äù reducing the risk of providing the wrong information because of the high chance of not selecting a true label as a complementary label. Addition ally, NLNL proposed threestage pipeline for Ô¨Åltering noisy data from training data (Figure 1 (a)). Each stage is com posed of NL!NL while discarding data of low conÔ¨Ådence (Selective NL; SelNL )!PL while only retaining data of high conÔ¨Ådence ( Selective PL; SelPL ), enabling more con vergence after NL. However, the fundamental problem that NL loss function causes underÔ¨Åtting to the overall training data still remains. This is the reason that NL requires an additional sequential step, SelNL. Furthermore, the three stage pipeline for Ô¨Åltering noisy data is quite inefÔ¨Åcient, ex tending the time for training CNNs. In this study, we propose a novel version of NLNL: Joint Negative Learning and Positive Learning; JNPL which has a uniÔ¨Åed singlestage pipeline for Ô¨Åltering noisy data (Fig ure 1 (b)). JNPL is composed of two losses to train CNN, NL+ and PL+ losses, dedicated to Ô¨Åltering noisy data from training data. Each is developed from NL and PL loss func tions, respectively. Firstly, our paper focuses on analyzing the NL loss function to understand the cause for underÔ¨Åt ting. Then we develop a new loss function NL+ that re solves the issue, which produces a gradient appropriate for convergence on a noisy training dataset. Our study demon strates the effectiveness of NL+, showing improved conver gence across various label noise types and noise rates. Sec ondly, while we utilize PL to aid in training with noisy data, PL+ loss function is also newly designed to enable fasterarXiv:2104.06574v1  [cs.LG]  14 Apr 2021NL selNL selPL JNPL NL selNL selPL JNPL (a) NLNL (b) JNPL Figure 1: Comparison between Negative Learning for Noisy Labels (NLNL) and Joint Negative and Positive Learning (JNPL) for Ô¨Åltering noisy data from training data, demonstrated with histograms showing the distribution of noisy training data . (a): NLNL is a 3stage pipeline (NL !SelNL!SelPL). (b): JNPL is a singlestage pipeline, in which two loss functions (NL+ and PL+) train CNN simultaneously. training with expectedtobeclean data. Our paper shows the effectiveness of the PL+ loss function compared to the previous PL loss function. Finally, as both loss functions of our method (NL+ and PL+) jointly train the model through asingle stage , it is simple and easier to use than NLNL. Our experiments show that JNPL successfully Ô¨Ålters noisy data in a single stage, thereby providing signiÔ¨Åcantly faster train ing of CNN as well as better Ô¨Åltering compared to NLNL. After Ô¨Åltering noisy data from the training data we per form pseudolabeling for noisy data classiÔ¨Åcation. We achieve stateoftheart accuracy across various settings in CIFAR10, CIFAR100 [13], and Clothing1M [31] datasets, proving the superior Ô¨Åltering ability of JNPL. The main contributions of this paper are as follows: We propose an improved version of NLNL, named ‚ÄúJoint Negative and Positive Learning (JNPL), ‚Äù featuring a singlestage pipeline for Ô¨Åltering noisy data, therefore enabling easier usage compared to NLNL. Two novel loss functions are newly designed, each named NL+ loss and PL+ loss. NL+ solves the underÔ¨Åtting problem of the NL loss, and provides better convergence on various types and ratios of label noises in the training data. Moreover, PL+ enables faster training compared to the previous PL loss function. Our method Ô¨Ålters noisy data, more robust across differ ent types and ratios of noise than NLNL. Our method also achieves stateoftheart noisy data classiÔ¨Åcation re sults when used along with pseudolabeling. Prior knowledge of the type or number of noisy data is not required for our method. It does not require any hyperparameter tuning that depend on prior knowledge, allowing our method to be applicable in practice. The remainder of this paper is organized as follows. Sec tion 3 describes NLNL method in depth, which is targeted throughout the whole paper, and discusses the cause of the underÔ¨Åtting problem of the method. Section 4 describes our proposed method, JNPL, and explains in detail on NL+ loss and PL+ loss terms. Section 5 demonstrates the overallcomparison between JNPL and NLNL, showing the distinct advantages of JNPL over NLNL. Section 6 discusses the evaluations of our method in comparison to baseline meth ods. Finally, we summarize and conclude in Section 7. 2. Related works","Negative Learning for Noisy Labels (NLNL) is an indirect learning method for training CNNs. NLNL trains the CNN that ‚Äúinput image does not belong to this complementary label‚Äù and requires an additional sequential step, SelNL. Furthermore, NLNL proposes a three-stage pipeline for filtering noisy data from training data. In this paper, we propose a novel version of NLNL: Joint Negative and Positive Learning (JNPL). JNPL is composed of two loss functions, NL+ and PL+, which solve the issue.","90,80"
13,Bayesian graph convolutional neural networks for semi-supervised classification.txt,"Recently, techniques for applying convolutional neural networks to
graph-structured data have emerged. Graph convolutional neural networks (GCNNs)
have been used to address node and graph classification and matrix completion.
Although the performance has been impressive, the current implementations have
limited capability to incorporate uncertainty in the graph structure. Almost
all GCNNs process a graph as though it is a ground-truth depiction of the
relationship between nodes, but often the graphs employed in applications are
themselves derived from noisy data or modelling assumptions. Spurious edges may
be included; other edges may be missing between nodes that have very strong
relationships. In this paper we adopt a Bayesian approach, viewing the observed
graph as a realization from a parametric family of random graphs. We then
target inference of the joint posterior of the random graph parameters and the
node (or graph) labels. We present the Bayesian GCNN framework and develop an
iterative learning procedure for the case of assortative mixed-membership
stochastic block models. We present the results of experiments that demonstrate
that the Bayesian formulation can provide better performance when there are
very few labels available during the training process.","Novel approaches for applying convolutional neural net works to graphstructured data have emerged in recent years. Commencing with the work in (Bruna et al. 2013; Henaff, Bruna, and LeCun 2015), there have been numer ous developments and improvements. Although these graph convolutional neural networks (GCNNs) are promising, the current implementations have limited capability to handle uncertainty in the graph structure, and treat the graph topol ogy as groundtruth information. This in turn leads to an in ability to adequately characterize the uncertainty in the pre dictions made by the neural network. In contrast to this past work, we employ a Bayesian framework and view the observed graph as a realization from a parametric random graph family. The observed ad jacency matrix is then used in conjunction with features and labels to perform joint inference. The results reported in this These authors contributed equally to this work. Copyright c 2019, Association for the Advancement of ArtiÔ¨Åcial Intelligence (www.aaai.org). All rights reserved.paper suggest that this formulation, although computation ally more demanding, can lead to an ability to learn more from less data, a better capacity to represent uncertainty, and better robustness and resilience to noise or adversarial attacks. In this paper, we present the novel Bayesian GCNN framework and discuss how inference can be performed. To provide a concrete example of the approach, we focus on a speciÔ¨Åc random graph model, the assortative mixed mem bership block model. We address the task of semisupervised classiÔ¨Åcation of nodes and examine the resilience of the derived architecture to random perturbations of the graph topology. 2 Related work","Convolutional neural networks have emerged as promising approaches for graph-structured data. However, the current implementations have limited capability to handle uncertainty in the graph structure, and treat the graph topology as groundtruth information. In this paper, we employ a Bayesian framework and view the observed graph as a realization from a parametric random graph family. The observed adjacency matrix is then used in conjunction with features and labels to perform joint inference. To provide a concrete example of the approach, we focus on a specific random graph model, the assortative mixed memembership","80,90"
286,Noisy Student Training using Body Language Dataset Improves Facial Expression Recognition.txt,"Facial expression recognition from videos in the wild is a challenging task
due to the lack of abundant labelled training data. Large DNN (deep neural
network) architectures and ensemble methods have resulted in better
performance, but soon reach saturation at some point due to data inadequacy. In
this paper, we use a self-training method that utilizes a combination of a
labelled dataset and an unlabelled dataset (Body Language Dataset - BoLD).
Experimental analysis shows that training a noisy student network iteratively
helps in achieving significantly better results. Additionally, our model
isolates different regions of the face and processes them independently using a
multi-level attention mechanism which further boosts the performance. Our
results show that the proposed method achieves state-of-the-art performance on
benchmark datasets CK+ and AFEW 8.0 when compared to other single models.","Automatic facial expression recognition from images/videos has many applica tions such as humancomputer interaction (HCI), bodily expressed emotions, hu man behaviour understanding, and has thus gained a lot of attention in academia and industry. Although there has been extensive research on this subject, facial expression recognition in the wild remains a challenging problem because of sev eral factors such as occlusion, illumination, motion blur, subjectspecic facial variations, along with the lack of extensive labelled training datasets. Following a similar line of research, our task aims to classify a given video in the wild to one of the seven broad categorical emotions. We propose an ecient model that addresses the challenges posed by videos in the wild while tackling the issue of labelled data inadequacy. The input data used for facial expression recognition can be multimodal, i.e. it may have visual information as well as audio informa tion. However, the scope of this paper is limited to emotion classication using only visual information. ?equal contributionarXiv:2008.02655v2  [cs.CV]  24 Feb 20212 V. Kumar et al. Most of the recent research on the publiclyavailable AFEW 8.0 (Acted Facial Expressions in the Wild) [1] dataset has focused on improving accuracy without regard to computational complexity, architectural complexity, energy & policy considerations, generality, and training eciency. Several stateoftheart meth ods [2,3,4] on this dataset have originated from the EmotiW [5] challenge with no clear computationalcost analysis. Fan et al. [2] achieved the highest validation accuracy based on visual cues, but they used a fusion of ve dierent architec tures with more than 300 million parameters. In contrast, our proposed method uses a single model with approximately 25 million parameters and comparable performance. While previous work focused on improving performance by increasing model capacity, our method focuses on better preprocessing, feature selection, and adequate training. Prior research [6,7,8,9] uses simple aggregation or averaging operation on features from multiple frames to form a xeddimensional feature vector. However, such methods do not account for the fact that a few principal frames in a video can be used to identify the target emotion, while the rest of the frames have a negligible contribution. Frameattention has been used [10] for selectively processing frames in a video, but it can further be coupled with spatialattention which could identify the most discriminative regions in a particular frame. We use a threelevel attention mechanism in our model: a) spatialattention block that helps to selectively process feature maps of a frame, b) channelattention block that focuses on the face regions at a local and a global level, i.e. eyes region (upper face), mouth region (lower face) and whole face, and c) frameattention block that helps to identify the most important frames in a video. AFEW 8.0 [1] has several limitations (Sec. 2) that restricts the generalization capabilities of deep learning models. To overcome these limitations, we use an unlabelled subset of the BoLD dataset [11] for semisupervised learning. Inspired by Xie et al. [12], we use a teacherstudent learning method where the training process is iterated by using the same student again as the teacher. During the training of the student, noise is injected into the student model to force it to generalize better than the teacher. Results show that the student performs better with each iteration, hence improving the overall accuracy on the validation set. The rest of the paper is organized as follows. Sec. 3 explains the datasets (AFEW 8.0 [1], CK+ [13] and BoLD [11]) that are used for training our model along with the preprocessing pipeline used for face detection, alignment and illumination correction. Sec. 4.1 explains the backbone network and covers the three types of attention and its importance in detail. Sec. 4.2 covers the use of the BoLD dataset for iterative training and the experimental results of semi supervised learning. Sec. 5.3 compares the results of our methods to other state oftheart methods on the AFEW 8.0 dataset. Additionally, we use another benchmark dataset CK+ [13] (posed conditions) as well as perform ablation studies (Sec. 5.4) to prove the validity of our model and training procedure.Noisy Student Training Improves Facial Expression Recognition 3 2 Related Work","We propose a novel method for automatic facial expression recognition in the wild. Our method uses a single model with approximately 25 million parameters and comparable performance. Our model is trained using an unlabelled subset of the BoLD dataset. To overcome these limitations, we use a teacher-student learning method where the training process is iterated by using the same student again as the teacher. During the training of the student model, noise is injected into the student model to force it to generalize better than the teacher. Results show that the student model generalize better with each iteration.","50,70"
250,"aschern at SemEval-2020 Task 11: It Takes Three to Tango: RoBERTa, CRF, and Transfer Learning.txt","We describe our system for SemEval-2020 Task 11 on Detection of Propaganda
Techniques in News Articles. We developed ensemble models using RoBERTa-based
neural architectures, additional CRF layers, transfer learning between the two
subtasks, and advanced post-processing to handle the multi-label nature of the
task, the consistency between nested spans, repetitions, and labels from
similar spans in training. We achieved sizable improvements over baseline
fine-tuned RoBERTa models, and the official evaluation ranked our system 3rd
(almost tied with the 2nd) out of 36 teams on the span identification subtask
with an F1 score of 0.491, and 2nd (almost tied with the 1st) out of 31 teams
on the technique classification subtask with an F1 score of 0.62.","The proliferation of disinformation online, commonly known as ‚Äúfake news‚Äù, has given rise to a lot of research on automatic fake news detection. However, most of the efforts have focused on checking whether a piece of information is factually correct, and little attention has been paid to the propaganda techniques that malicious actors use to spread their message. SemEval2020 Task 11 (Da San Martino et al., 2020a) aims to bridge this gap. It focused on detecting the use of propaganda techniques in news articles,1creating a dataset that extends (Da San Martino et al., 2019b), and offering two subtasks: span identiÔ¨Åcation (SI): detecting the propaganda spans in an article; technique classiÔ¨Åcation (TC): detecting the type of propaganda used in a given text span. Below, we describe the systems we built for these two subtasks. At the core of our systems is RoBERTa (Liu et al., 2019), a pretrained model based on the Transformer architecture (Vaswani et al., 2017). However, we improved over RoBERTa by adding extra layers in the neural network architecture, and we further added some postprocessing steps. We further applied transfer learning between the two subtasks, and Ô¨Ånally, we combined different models into an ensemble.2 2 Related Work","SemEval2020 Task 11 aims to bridge this gap by detecting the use of propaganda techniques in news articles. We describe the systems we built for these two subtasks. At the core of our systems is RoBERTa, a pretrained model based on the Transformer architecture. However, we improved over RoBERTa by adding extra layers in the neural network architecture, and we further added some post-processing steps. Finally, we combined different models into an ensemble. We describe the systems we built for these two subtasks.","80,90"
419,Semi-Supervised Music Tagging Transformer.txt,"We present Music Tagging Transformer that is trained with a semi-supervised
approach. The proposed model captures local acoustic characteristics in shallow
convolutional layers, then temporally summarizes the sequence of the extracted
features using stacked self-attention layers. Through a careful model
assessment, we first show that the proposed architecture outperforms the
previous state-of-the-art music tagging models that are based on convolutional
neural networks under a supervised scheme.
  The Music Tagging Transformer is further improved by noisy student training,
a semi-supervised approach that leverages both labeled and unlabeled data
combined with data augmentation. To our best knowledge, this is the first
attempt to utilize the entire audio of the million song dataset.","Automatic music tagging is a classiÔ¨Åcation task whose ob jective is computational understanding of music seman tics. From a given audio excerpt, a trained music tagging model predicts relevant tags (e.g., genre, mood, instru ment, decade, region) based on its acoustic characteristics. The task has attracted music information retrieval (MIR) researchers due to its wide pragmatic usages in many ap plications. Especially, there is a strong demand from in dustries that have music recommendation services from largescale music libraries. Thanks to the recent advances in deep learning, mostly convolutional neural networks (CNNs) [1], the performances of music tagging models have been signiÔ¨Åcantly enhanced by leveraging largescale data with various deep architectures [2‚Äì5]. However, there still are two limitations in the current music tagging re search: i) chunkbased prediction and ii) a limited amount of labeled data for supervised learning. Music signals are in the form of sequential data. In this sequence, regarding typical tags, some acoustic character istics may appear locally (e.g., instruments) while some others may span over the sequence (e.g., mood, genre). This means a successful music tagging model needs to be ¬© Minz Won, Keunwoo Choi, and Xavier Serra. Licensed under a Creative Commons Attribution 4.0 International License (CC BY 4.0). Attribution: Minz Won, Keunwoo Choi, and Xavier Serra, ‚ÄúSemi Supervised Music Tagging Transformer‚Äù, in Proc. of the 22nd Int. Society for Music Information Retrieval Conf., Online, 2021.able to extract both local and global features. Fully con volutional network [2], one of the very early deep learning models for music tagging, was designed to capture both local and global features by increasing the size of the over all receptive Ô¨Åelds with maxpooling. More recently, how ever, it is shown that training with a smaller hop size with shorter audio chunks is beneÔ¨Åcial for music tagging [6]. This approach has been adopted in many CNNbased mod els [3‚Äì5], where the models are trained with short audio chunks (3 to 5 second long), densely striding maxpooling, and a global pooling layer. To predict music tags of a 3 minute song, for example, the audio is split into multiple short audio chunks, and the model makes predictions on each chunk. Then, the predictions are aggregated through majority vote or global average/maxpooling. This means that on a track level, the current music tagging models are performing like a bagoffeatures model [7] instead of modeling music representation as a sequence. Another limitation of the current music tagging research is a limited amount of labeled data. The Modern deep learning models are datahungry. However, manually la beling music tags is timeconsuming and requires domain expertise. In pursuit of largescale research, the million song dataset (MSD) [8], which literally includes a mil lion songs in it, became popular in music tagging research. Among the million songs, however, only about 24% are labeled with at least one of the top50 music tags. Most of the previous music tagging research has only utilized the labeled data while discarding 76% of the songs in the dataset. This type of setup (i.e., a small labeled dataset along with a large unlabeled dataset) is not limited to the MSD but can be found often in the real world regard less of the domain. To leverage the unlabeled data, self supervised [9‚Äì13] and semisupervised [14‚Äì16] learning have been actively explored in computer vision and natural language processing. In this paper, we present Music Tagging Transformer that is trained with a semisupervised approach. Our main contribution is threefold: ( i) through a careful model as sessment, we show that our Music Tagging Transformer outperforms the previous works, ( ii) we show that we can use unlabeled data to improve music tagging performances via semisupervised learning, ( iii) we provide a new split of the MSD to solve known issues of the previous one. Re producible code is available online.1 1https://github.com/minzwon/semisupervisedmusictagging transformerarXiv:2111.13457v1  [cs.SD]  26 Nov 20212. RELATED WORKS","Music tagging is a classification task whose objective is computational understanding of music semantics. The task has attracted music information retrieval (MIR) researchers due to its wide pragmatic usages in many applications. However, there are still two limitations in the current music tagging research: i) chunk-based prediction and ii) a limited amount of labeled data for supervised learning. In this paper, we present Music Tagging Transformer, a semi-supervised music tagging model trained with a chunk-based approach. The semi-supervised learning approach","80,90"
261,Person Re-Identification by Deep Joint Learning of Multi-Loss Classification.txt,"Existing person re-identification (re-id) methods rely mostly on either
localised or global feature representation alone. This ignores their joint
benefit and mutual complementary effects. In this work, we show the advantages
of jointly learning local and global features in a Convolutional Neural Network
(CNN) by aiming to discover correlated local and global features in different
context. Specifically, we formulate a method for joint learning of local and
global feature selection losses designed to optimise person re-id when using
only generic matching metrics such as the L2 distance. We design a novel CNN
architecture for Jointly Learning Multi-Loss (JLML) of local and global
discriminative feature optimisation subject concurrently to the same re-id
labelled information. Extensive comparative evaluations demonstrate the
advantages of this new JLML model for person re-id over a wide range of
state-of-the-art re-id methods on five benchmarks (VIPeR, GRID, CUHK01, CUHK03,
Market-1501).","Person reidentiÔ¨Åcation (reid) is about matching identity classes in detected person bounding box images from non overlapping camera views over distributed open spaces. This is an inherently challenging task because person visual ap pearance may change dramatically in different camera views from different locations due to unknown changes in human pose, illumination, occlusion, and background clutter [Gong et al. , 2014 ]. Existing person reid studies typically focus on either feature representation [Gray and Tao, 2008; Faren zena et al. , 2010; Kviatkovsky et al. , 2013; Zhao et al. , 2013; Liao et al. , 2015; Matsukawa et al. , 2016a; Ma et al. , 2017 ] or matching distance metrics [Koestinger et al. , 2012; Xiong et al. , 2014; Zheng et al. , 2013; Wang et al. , 2014b; Paisitkri angkrai et al. , 2015; Zhang et al. , 2016; Wang et al. , 2016b; Wang et al. , 2016c; Wang et al. , 2016d; Chen et al. , 2017b ]or their combination in deep learning framework [Liet al. , 2014; Ahmed et al. , 2015; Wang et al. , 2016a; Xiao et al. , 2016; Subramaniam et al. , 2016; Chen et al. , 2017a ]. Regard less, the overall objective is to obtain a view and locationinvariant (crossdomain) representation. We consider that learning any matching distance metric is intrinsically learn ing a global feature transformation across domains (two dis joint camera views) therefore obtaining a ‚Äúnormalised‚Äù fea ture representation for matching. Most reid features are typically handcrafted to encode local topological and/or spatial structural information, by different image decomposition schemes such as horizontal stripes [Gray and Tao, 2008; Kviatkovsky et al. , 2013 ], body parts [Farenzena et al. , 2010 ], and patches [Zhao et al. , 2013; Matsukawa et al. , 2016a; Liao et al. , 2015 ]. These lo calised features are effective for mitigating the person pose and detection misalignment in reid matching. More recent deep reid models [Xiao et al. , 2016; Wang et al. , 2016a; Chen et al. , 2017a; Ahmed et al. , 2015 ]beneÔ¨Åt from the availability of larger scale datasets such as CUHK03 [Liet al., 2014 ]and Market1501 [Zheng et al. , 2015 ]and from lessons learned on other vision tasks [Krizhevsky et al. , 2012; Girshick et al. , 2014 ]. In contrast to local handcrafted fea tures, deep models, in particular Convolutional Neural Net works (CNN) [LeCun et al. , 1998 ], favour intrinsically in learning global feature representations with a few exceptions. They have been shown to be effective for reid. We consider that either local or global feature learning alone is suboptimal. This is motivated by the human vi sual system that leverages both global (contextual) and local (saliency) information concurrently [Navon, 1977; Torralba et al. , 2006 ]. This intuition for joint learning aims to ex tract correlated complementary information in different con text whilst satisfying the same learning constraint1therefore achieving more reliable recognition. To that end, we need to address a number of nontrivial problems: (i) the model learn ing behaviour in satisfying the same label constraint may be different at the local and global levels; (ii) any complemen tary correlation between local and global features is unknown and may vary among individual instances, therefore must be learned and optimised consistently across data; (iii) People‚Äôs appearance in public scenes is diverse in both pattens and conÔ¨Ågurations. This makes it challenging to learn correla tions between local and global features for all appearances . This work aims to formulate a deep learning model for 1In person reid context, the learning constraint refers to the im age person identity label supervision.arXiv:1705.04724v2  [cs.CV]  23 May 2017jointly optimising local and global feature selections concur rently and to improve person reid using only generic match ing metrics such as the L2 distance. We explore a deep learn ing approach for its potential superiority in learning from large scale data [Xiao et al. , 2016; Chen et al. , 2017a ]. For the bounding box image based person reid, we consider the entire person in the bounding box as a global scene context and body parts of the person as local information sources , both are subject to the surrounding background clutter within a bounding box, and potentially also misalignment and partial occlusion from bounding box detection. In this setting, we wish to discover and optimise jointly correlated complemen tary feature selections in the local and global representations, both subject to the same label constraint concurrently. Whilst the former aims to address pose/detection misalignment and occlusion by localised Ô¨Ånegrained saliency information, the latter exploits holistic coarsegrained context for more robust global matching. To that end, we formulate a deep twobranch CNN archi tecture, with one branch for learning localised feature se lection (local branch) and the other for learning global fea ture selection (global branch). Importantly, the two branches are not independent but synergistically correlated and jointly learned concurrently. This is achieved by: (i) imposing inter branch interaction between the local and global branches, and (ii) enforcing a separate learning objective loss function to each branch for learning independent discriminative capabil ities, whilst being subject to the same class label constraint. Under such balancing between interaction and independence, we allow both branches to be learned concurrently for max imising their joint optimal extraction and selection of dif ferent discriminative features for person reid. We call this model the Joint Learning MultiLoss (JLML) CNN model. To minimise poor learning due to inherent noise and potential covariance, we introduce a structured feature selective and discriminative learning mechanism into both the local and global branches subject to a joint sparsity regularisation. The contributions of this work are: (I)We propose the idea of learning concurrently both local and global feature selections for optimising feature discriminative capabilities in different context whilst performing the same person reid tasks. This is currently understudied in the person reid liter ature to our best knowledge. (II)We formulate a novel Joint Learning MultiLoss (JLML) CNN model for not only learn ing both global and local discriminative features in different context by optimising multiple classiÔ¨Åcation losses on the same person label information concurrently, but also utilis ing their complementary advantages jointly in coping with lo cal misalignment and optimising holistic matching criteria for person reid. (III) We introduce a structured sparsity based feature selection learning mechanism for improving multi loss joint feature learning robustness w.r.t. noise and data co variance between local and global representations. Extensive comparative evaluations demonstrate the superiority of the proposed JLML model over a wide range of existing stateof theart reid models on Ô¨Åve benchmark datasets VIPeR [Gray and Tao, 2008 ], GRID [Loyet al. , 2009 ], CUHK01 [Liet al. , 2012 ], CUHK03 [Liet al. , 2014 ], and Market1501 [Zheng et al. , 2015 ].2 Related Works","We consider that either local or global feature learning alone is suboptimal. This is motivated by the human visual system that leverages both global (contextual) and local (saliency) information concurrently. To achieve this, we consider that both local and global feature learning is suboptimal. We address these problems by combining convolutional neural networks (CNNs) with deep learning frameworks. We consider that learning any matching distance metric is intrinsically learn ing a global feature transformation across domains (two disjoint al.","45,70"
613,Centrality and Consistency: Two-Stage Clean Samples Identification for Learning with Instance-Dependent Noisy Labels.txt,"Deep models trained with noisy labels are prone to over-fitting and struggle
in generalization. Most existing solutions are based on an ideal assumption
that the label noise is class-conditional, i.e., instances of the same class
share the same noise model, and are independent of features. While in practice,
the real-world noise patterns are usually more fine-grained as
instance-dependent ones, which poses a big challenge, especially in the
presence of inter-class imbalance. In this paper, we propose a two-stage clean
samples identification method to address the aforementioned challenge. First,
we employ a class-level feature clustering procedure for the early
identification of clean samples that are near the class-wise prediction
centers. Notably, we address the class imbalance problem by aggregating rare
classes according to their prediction entropy. Second, for the remaining clean
samples that are close to the ground truth class boundary (usually mixed with
the samples with instance-dependent noises), we propose a novel
consistency-based classification method that identifies them using the
consistency of two classifier heads: the higher the consistency, the larger the
probability that a sample is clean. Extensive experiments on several
challenging benchmarks demonstrate the superior performance of our method
against the state-of-the-art.","Deep learning has shown transformative power in various realworld applications but is notoriously datahungry[10,11,29,9,21,45]. There are some other alterna tives which try to reduce the cost of human labor for data annotation, such as ‚ãÜCorresponding authors are Guanbin Li and Yizhou Yu.arXiv:2207.14476v1  [cs.CV]  29 Jul 20222 G. Zhao et al. : Decision boundary of IDN : Ground truth class boundary : Samples with different ground truth : Samples with different IDN labels Fig. 1: Example of IDN. The different shapes of the markers represent different ground truth classes. The different colors of the markers represent the noisy (IDN) labels. Different from random noise, IDN samples tend to be distributed near the ground truth class boundary, thus confusing the classifier and leading to overfitted decision boundaries. crawling web images and using machinegenerated labels. However, such data are usually noisy, which impedes the generalization of deep learning models due to overfitting. Addressing the aforementioned issue, Learning with Noisy Labels (LNL) was proposed as a new topic and has attracted increasing attention in both academia and industry. Existing LNL methods mostly focus on the learning with class conditional noise (CCN), which aims to recover a noise transition matrix that contains classdependent probabilities of a clean label flipping into a noisy label. However, CCN is too ideal for realworld LNL as it ignores the dependence of noise on the content of individual images, a.k.a. instancedependent noise (IDN). Unlike random noise or CCN that can be countered by collecting more (noisy) data[4], IDN has some important characteristic that makes it difficult to be tack led. First, classifiers can easily overfit to the IDN because the noisy labels are dependent on sample features. As Fig. 1 shows, mislabeled IDN samples (sam ples with the same shape but with different colors) share similar image features to their mislabeled classes, and thus tend to be distributed near the boundary between their ground truth class and the mislabeled class. As a result, the clas sifier can easily be confused and overfits to IDN samples, leading to specious decision boundaries (red lines in Fig. 1). In addition, the challenge of IDN can be further amplified in the presence of interclass imbalance and differences. Con sider Clothing1M [38], an IDN dataset verified by [3], in which the noise is highly imbalanced and asymmetric. In Clothing1M, the IDN samples are unevenly dis tributed as the samples from similar classes ( e.g. sweater and knitwear) can be extremely ambiguous, while those from other classes ( e.g. shawl and underwear) are easily distinguishable. Such unevenly distributed IDN samples can be further amplified by the class imbalance problem, as there is no guarantee of a balanced dataset due to the absence of ground truth labels.TwoStage Clean Samples Identification for Learning with IDN 3 Shawl(92%),  Knitwear(3%),  Windbreaker(1%), ‚Ä¶‚Ä¶ Sweater(11%),  Knitwear(62%), TShirt(14%), ‚Ä¶‚Ä¶ Vest(46%), Dress(27%), TShirt(9%), ‚Ä¶‚Ä¶‚úî ‚úò ‚úò ‚úî ‚úò ‚úò ‚úî ‚úò ‚úò Fig. 2: The transition matrix of Clothing1M copied from [38]. The distribu tion of noisy labels are highly imbalanced. Some classes are almost clean (e.g. Shawl) while some classes has more mislabeled samples than correct labels (e.g. Sweater). In this paper, we follow DivideMix [17] that formulates LNL as a semi supervised learning problem and propose a novel twostage method to identify clean versus noisy samples in the presence of IDN and the class imbalance prob lem. In the first stage, we employ a classlevel featurebased clustering procedure to identify easily distinguishable clean samples according to their cosine simi larity to the corresponding classwise prediction centers. Specifically, we collect the normalized features of samples belonging to different classes respectively and calculate their classwise centers located on a unit sphere. Then, we ap ply Gaussian Mixture Model (GMM) to binarily classify the samples according to their cosine similarity to their corresponding class centers and identify the ones closer to class centers as clean samples. Notably, we propose to augment the GMM classification by aggregating rare classes based on their prediction entropy, thereby alleviating the impact of the class imbalance problem. In the second stage, we propose a consistencybased classification method to identify the hard clean samples that are mixed with IDN samples around the ground truth class boundaries. Our key insight is that such clean samples can be identi fied by the prediction consistency of two classifiers. Compared to IDN samples, clean samples should produce more consistent predictions. Specifically, we in corporate two regularizers into the training: one applied to the feature extractor to encourage it to facilitate consistent outputs of the two classifiers; one applied to the two classifiers to enforce them generating inconsistent predictions. Af ter training, we use another GMM to binarily classify the samples with smaller GMM means as clean samples. After identifying all clean samples, we feed them into the semisupervised training as labeled samples, thereby implementing our learning with instancedependent noisy labels. In summary, our contributions could be summarized as: ‚ÄìWe propose a method that delving into the instancedependent noise, and design a classlevel feature clustering procedure focusing on the imbalanced and IDN samples detection.4 G. Zhao et al. ‚ÄìWe further propose to identify the hard clean samples around the ground truth class boundaries by measuring the prediction consistency between two independently trained classifiers, and further improves the accuracy of clean versus noisy classification. ‚ÄìOur method achieves stateoftheart performance in some challenging bench marks, and is proved to be effective in different kinds of synthetic IDN. 2 Related Work","Deep learning has shown transformative power in various real-world applications but is notoriously data-hungry. Despite the increasing popularity of deep learning, it is still difficult to generalize deep learning models to real-world applications. Instance-dependent noise (IDN) is a new topic that aims to reduce the cost of human labor for data annotation. Existing methods mostly focus on the learning with class conditional noise (CCN), which ignores the dependence of noise on the content of individual images, a.k.a. In Clothing1M, the IDN samples are unevenly distributed as","90,80"
111,A Novel Ensemble Deep Learning Model for Stock Prediction Based on Stock Prices and News.txt,"In recent years, machine learning and deep learning have become popular
methods for financial data analysis, including financial textual data,
numerical data, and graphical data. This paper proposes to use sentiment
analysis to extract useful information from multiple textual data sources and a
blending ensemble deep learning model to predict future stock movement. The
blending ensemble model contains two levels. The first level contains two
Recurrent Neural Networks (RNNs), one Long-Short Term Memory network (LSTM) and
one Gated Recurrent Units network (GRU), followed by a fully connected neural
network as the second level model. The RNNs, LSTM, and GRU models can
effectively capture the time-series events in the input data, and the fully
connected neural network is used to ensemble several individual prediction
results to further improve the prediction accuracy. The purpose of this work is
to explain our design philosophy and show that ensemble deep learning
technologies can truly predict future stock price trends more effectively and
can better assist investors in making the right investment decision than other
traditional methods.","Many factors may affect stock prices in various ways. The stock prices change by market forces, which means the stock price changes react to supply and demand in the stock market. If more people want to buy a stock (demand) than sell it (supply), then the price moves up. Similarly, if more people want to sell a stock than buy it, there would be greater supply than demand, and the price would fall. Stock supply and demand are affected by many things. Supply factors include company share issues (e.g., releases new shares to the public), share buybacks (e.g., a company buys back its own shares from investors to reduce supply) and sellers (e.g., the investors responsible for pushing shares back into the market, increasing the supply). Demand factors include company news (e.g., a new product launch, missed targets, good performance), economic factors (e.g., interest rate changes), industry trends (e.g., a booming industry), market sentiment (could be psychological and subjective) and unexpected events (e.g., natural disasters or the death of a government leader). Normally, we can get these supply and demand factors from the Ô¨Ånancial news, companies‚Äô newsletters or their annual reports. For instance, when Apple announces a new product, many people would like to purchase it, and its performance usually would be better soon. Thus more people are interested in the Apple stock, then the Apple stock demand increases, which will lead to a rise in the Apple stock price. On the other hand, when COVID19 spreads around the world, many airlines cut their Ô¨Çights, and it is expected their performance would be bad in a short term. Thus, more people want to sell airline stocks; then the airline stock supply will rise, and their price will go down. If the price goes up, the quantity demanded goes down (but demand itself stays the same). If the price decreases, 1arXiv:2007.12620v1  [qfin.ST]  23 Jul 2020quantity demanded increases. This is the Law of Demand. If the quantity demanded decreases, the stock price probably would fall. Also people‚Äôs sentiment or belief plays a role in determining a stock price. Political situations or international affairs may also affect stock prices. Hence, this is a complicated process among the stock supply, demand, and prices. However, there are a few primary factors that affect the stock supply and demand like company news, company performance, industry performance, investor sentiment (e.g., whether in bull or bear market), and other major economic factors described in [2]. If we focus on the major factors, and trace back the historical stock prices, we may be able to predict future stock prices quite accurately. People usually have a short memory about stock factors. Hence, determining a suitable historical window size is important to correctly predict stock prices. If the window size is too large compared with human memory, many factors or news are forgotten by investors and obsolete already and the prediction will not be good. On the other hand, if the window is too short compared with human memory, many news or sentiments outside the window are still remain in people‚Äôs brain, the prediction will also be bad. Hence, a wrong historical window size is detrimental to our successful stock price predictions. Stock price prediction is a series of continuous predictions since the stock price is constantly chang ing to react to timely news and announcements. Therefore, it is very challenging for computer scientists to use ArtiÔ¨Åcial Intelligence to predict future stock movements because it is hard for a computer to receive the latest information and respond immediately. Computer Scientists are cur rently not particularly successful in stock price prediction for several reasons. Most of the previous works[3][4] often used either textual data like news, twitter, or blogs or numerical data like stock price information instead of using both textual information and statistical information[5]. Since the stock price is related to many factors, only considering one or two factors is unable to provide enough information to forecast the stock price trend. Including as much relevant and useful information as possible will guarantee a better prediction. Furthermore, previous works[3][4] only use the target company‚Äôs information on the training model without considering that the target company‚Äôs competitors or the information of companies in re lated industries. These types of information will also affect the target company‚Äôs stock movement. Therefore, the result is not very satisfactory and persuasive because the information provided is insufÔ¨Åcient. Moreover, some of the previous works, which used the textual information, did not consider time series. However, the timeline is a signiÔ¨Åcant factor for stock price prediction. This paper proposes to use sentiment analysis to extract useful information from multiple textual data sources and a blending ensemble deep learning model to predict future stock movement. The blending ensemble model contains two levels. The Ô¨Årst level contains two Recurrent Neural Net works (RNNs), one LongShort Term Memory network (LSTM) and one Gated Recurrent Units network (GRU), followed by a fully connected neural network as the second level model. The RNNs, LSTM, and GRU models can effectively capture the time series events in the input data, and the fully connected neural network is used to ensemble several individual prediction results to further improve the prediction accuracy. 2 Related Work","Stock supply and demand are affected by many things. Supply factors include company share issues (e.g., releases new shares to the public), share buybacks (e.g., sellers responsible for pushing shares back into the market, increasing the supply), and investors (e.g., the sellers responsible for pushing shares back into the market, increasing the supply). Hence, we can get these supply and demand factors from the financial news, companies‚Äô newsletters or their annual reports. However, there are a few primary factors that affect the stock price. Hence, we can predict the","80,60"
447,Adaptive Neural Network Ensemble Using Frequency Distribution.txt,"Neural network (NN) ensembles can reduce large prediction variance of NN and
improve prediction accuracy. For highly nonlinear problems with insufficient
data set, the prediction accuracy of NN models becomes unstable, resulting in a
decrease in the accuracy of ensembles. Therefore, this study proposes a
frequency distribution-based ensemble that identifies core prediction values,
which are expected to be concentrated near the true prediction value. The
frequency distribution-based ensemble classifies core prediction values
supported by multiple prediction values by conducting statistical analysis with
a frequency distribution, which is based on various prediction values obtained
from a given prediction point. The frequency distribution-based ensemble can
improve predictive performance by excluding prediction values with low accuracy
and coping with the uncertainty of the most frequent value. An adaptive
sampling strategy that sequentially adds samples based on the core prediction
variance calculated as the variance of the core prediction values is proposed
to improve the predictive performance of the frequency distribution-based
ensemble efficiently. Results of various case studies show that the prediction
accuracy of the frequency distribution-based ensemble is higher than that of
Kriging and other existing ensemble methods. In addition, the proposed adaptive
sampling strategy effectively improves the predictive performance of the
frequency distribution-based ensemble compared with the previously developed
space-filling and prediction variance-based strategies.","A surrogate model is built to represent the true model with data obtained from a limited number of simulations  or experiments ; thus, predictions for computationally expensive models can be approximated ( Kang et al., 2019) .  Surrogate modeling focuses on input ‚Äìoutput behavior to find a model that approximates the rel ationship between  input and output as accurately as possible. Neural network (NN) is one of the promising surrogate models and i s  known to be a universal function approximator with a good prediction accuracy  (Pan et al. 2014) . Multiple  artificial neurons that mimic the structure and principle of biological neurons constitute NN ; these  artificial  neurons are interconnected to form a network that derives output for given input data  (Basheer and Hajmeer 2000 ).  NN co mprises  layered structures , in which nodes in each layer are connected to nodes in subsequent layers and  information moves in the forward direction.  NN parameters include weights and biases, and weights are given to  connections between nodes ( Eason and Cremaschi 2014) . The weighted sum of inputs from each node is  transferred to the next node through an activation function , and the parameters can be determined through training .  Once a  given data set is split into training and validation data set, the training data set is used to train the NN  model and  the validation data set is used to estimate the accuracy of the trained model . Applying NN as a surrogate  model in  various engineering d omains , such as mechanical engineering ( Chen et al. 2020; Lin et al. 2020 ; Ktari  et al. 2021 ; Schrader and Schauer 2021 ), structural engineering  (Gomes  et al., 2011; de Santana Gomes 2019;  Yƒ±lmaz et al. 2021 ; Freitag  et al. 202 0), aerospace engineering ( Bouhlel et al. 2020 ; Du et al. 2021; Zhang  et al.  2021 ), biomedical engineering ( Lu et al. 2013; Eskinazi and  Fregly 2015), chemical engineering ( Eason and  Cremaschi 2014 ; Moreno P√©rez et al. 2018 ), civil engineering ( Shaw et al. 2017 ; Garc√≠a Segura et al.  2017;  Thrampoulidis et al. 2021 ), and composite structures ( Papadopoulos et al.  2018 ; Yan et al. 2020) , has been recently  attempted.   However, NN has a problem  in that different models are created in accordance with  the selection of training  data sets, initial  parameters , and training algorithms (Zhang 2007) . This condition  results in various prediction  values ; thus, NNs are referred  to have high prediction variance . Ensembles that combine prediction values  obtained from multiple component models have be en developed  to reduce  the prediction variance of NNs  (Sollich  and Krogh 1996) . The basic premise of ensembles is that the errors of a single model can be compensated by the  other models (Sagi and Rokach 2018). Ensembles are generally constructed through two steps: training multiple  component models and combining prediction values  derived from the multiple component models.  Sufficiently  diverse component  models with high predictive performance  are required  for th e ensemble to have high accuracy   (Deng et al. 2013 ). Various component models can be created depending on the combination of training and validation data  sets and the selection of initial parameters.  If the validation error of the model is small, then the  predictive performance can be estimated to be accurate . The accuracy of the ensemble is highly dependent on the  combination of prediction values . Thus,  various methods , such as averag e ensemble ( Opitz and Shavlik 1996 ),  weigh ted ensemble ( Bishop 1995 ), and mode ensemble (Kourentzes  et al. 2014) , which combin e prediction  values ,  have been developed.  Many studies have shown that the prediction accuracy of ensembles combining multiple  component models is higher than that of a single component  model ( Wolper t 1992; Goodfellow et al. 2016 ).  In the case of real engineering applications , the size of the  data set for creating surrogate  models is usually  small because  simulations or experiments (e.g., finite element analysis  and collision test) are time  consuming and  expensive  (Gaspar et al. 2017; Lee et al. 2020 ). For highly nonlinear problems, the prediction accuracy of NN  decreases, and the situation worsens when the size of the  data set is small.  The deviation of prediction values  increases  as the prediction accuracy of component models becomes unstable , resulting in a decrease in the  accuracy of ensembles.  The mode ensemble that can cope well with outliers is suitable  when the deviation of  prediction values is large . In the mode ensemble, kernel density est imation (KDE)  is performed on t he prediction  values , and the value corresponding to the maximum density is identified as a mode  and used as the final prediction  value (Kourentzes  et al. 2014) . The mode is determined on the  basis of the  most frequent valu e; thus, the mode  ensemble is insensitive to outliers compared with average and weighted ensembles . However,  a biased prediction  value can be obtained  in the presence of  multiple high frequency values . In addition to the most frequent value ,  keep ing the possibility open to various prediction values  is also required  considering the unstable prediction  accurac y.  Therefore, this study proposes a frequency distribution based ensemble that explores the range of core  prediction values, which are expected to be close to the true prediction value.  For a given prediction point, various  prediction values obtained from the component models constitute a prediction value distribution , and the  frequency distribution based ensemble performs statistical analysis with a frequency distribution based on the  prediction value  distribution  to identify the core prediction values.  Prediction values belonging to the range  supported by multiple prediction values can be classified into  core prediction values, and the average of the core  prediction values is determined as the final prediction value.  An adaptive  sampling strategy , which  efficiently  improves the accuracy of the frequency distribu tionbased ensemble according to  the variance of core prediction  values , is also proposed.  Various examples are used to verify the proposed frequency distribution based ensemble  and adaptive  sampling strategy .  The rest of this paper is organized as follows.  Section 2  reviews  previous works related to NNs and ensembles.  Section 3 presents the proposed frequency distribution based ensemble  and t he adaptive sampling strategy , which   efficiently improves the predictive performance of the proposed frequenc y distribution based ensemble . Section  4 demonstrates the predictive accuracy of ensemble methods and compares the proposed adaptive sampling  strategy with other existing sampling strategies  through case studies.  Section 5 finally  provides the conclusion  and future directions.     2. Related works","Surrogate modeling is a promising technique for estimating the accuracy of computationally expensive models. Neural network (NN) is a well-known surrogate model with a good prediction accuracy. However, NNs have a problem in that different models are created in accordance with the selection of training data sets, initial parameters, and training algorithms. This condition results in various prediction values; thus, NNs are referred to have high prediction variance. Ensembles have been developed to reduce the prediction variance of NNs. Ensembles are constructed through two steps:","75,90"
285,Neighborhood Collective Estimation for Noisy Label Identification and Correction.txt,"Learning with noisy labels (LNL) aims at designing strategies to improve
model performance and generalization by mitigating the effects of model
overfitting to noisy labels. The key success of LNL lies in identifying as many
clean samples as possible from massive noisy data, while rectifying the wrongly
assigned noisy labels. Recent advances employ the predicted label distributions
of individual samples to perform noise verification and noisy label correction,
easily giving rise to confirmation bias. To mitigate this issue, we propose
Neighborhood Collective Estimation, in which the predictive reliability of a
candidate sample is re-estimated by contrasting it against its feature-space
nearest neighbors. Specifically, our method is divided into two steps: 1)
Neighborhood Collective Noise Verification to separate all training samples
into a clean or noisy subset, 2) Neighborhood Collective Label Correction to
relabel noisy samples, and then auxiliary techniques are used to assist further
model optimization. Extensive experiments on four commonly used benchmark
datasets, i.e., CIFAR-10, CIFAR-100, Clothing-1M and Webvision-1.0, demonstrate
that our proposed method considerably outperforms state-of-the-art methods.","Deep neural networks (DNNs) have achieved significant success in computer vi sion tasks, such as image classification [41,1,22,5,18,52], etc. However, they rely heavily on tremendous quantities of highquality manual annotations. To allevi ate the need for extensive human annotations while improving the generalization capability of deep neural networks, learning with noisy labels (LNL) has been proposed to effectively leverage largescale yet poorlyannotated datasets while mitigating the effects of model overfitting to noisy labels. *Corresponding Authors are Guanbin Li and Yizhou Yu.arXiv:2208.03207v1  [cs.CV]  5 Aug 20222 J. Li et al. B CDA O E Fig. 1. An illustration to exemplify our basic idea. Samples distributed within the dotted circle, including the candidate sample, Point O, and its nearest neighbors, i.e., Point A, B, C, D and E are close to each other in the featurespace neighborhood. Dif ferent colors indicate different labels (either predicted label or given groundtruth label). In the noise verification stage, a given label of the candidate (Point O) is considered noisy if there is a huge inconsistency between the label distributions of the candidate and its nearest neighbors; and otherwise, the candidate is considered as a clean sam ple. Likewise, in the noise correction stage, a noisy sample discards the given noisy label and is relabeled through a neighborhood collective estimation process involving its contrastive neighbors To tackle the challenges imposed by LNL, previous works have proposed massive strategies [10,39,19,32,47], including noisy label correction [3,24], noisy label or sample rejection[19,47,15,14], and noisy sample reweighing [42,35,12]. The mainstream pipeline first uses noise verification strategies to separate the original training set into a clean set and a noisy set, which contain training samples with clean labels and noisy labels respectively, in order to diminish the effect of noisy labels during model training. Then, (un)supervised learning or semisupervised learning (SSL) based techniques are adopted to correct noisy labels and further optimize the classification model by regarding the clean set and noisy set as labeled and unlabeled samples respectively. In this scheme, original noisy labels are simply discarded for their high chances to be incorrect, avoiding the negative effect of noisy label memorization in the trained model. In the context of learning with noisy labels, there may exist classes with imbalanced noisy or clean samples, especially in realworld noisy datasets such as Clothing1M [45] and Webvision1.0 [23]. For instance, there might be a relatively high proportion of noisy labels in some hardtoannotate classes; on the other hand, a trained model may produce lowconfident predictions on a relatively high proportion of hardtolearn clean samples in some classes, making existing noise identification algorithms incorrectly identify them as noisy samples. As a result, noise accumulation may take place implicitly in such classes, making the trained model produce unreliable label predictions. The above scenarios could make an LNL algorithm fall into the socalled confirmation bias [40,2], which causes the algorithm to favor incorrect training labels that have been confirmed with predicted labels in earlier training iterations. In this context, relying too much on the potentially biased label predictions for individual training samples would increase the risk of incorrectly identifying noisy labels in the noise verification stage. Moreover, confirmation bias also exists in the subsequent noise correction stage, where SSL or other methods, such as labelguessing [19,30,51] and labelNeighborhood Collective Estimation 3 reassignment [47], construct pseudolabels for unlabeled samples in the noisy set using potentially biased label predictions. Apparently, model training in the optimization stage would strengthen this bias as more confident but incorrect predictions would defy new changes, and subsequently even deteriorate model performance in high noise ratio scenarios. We are inspired by the premise of contrastive learning that samples from the same class should have higher similarity in the feature space than those from dif ferent classes [29,31,9]. Therefore, we approach learning with noisy labels from a different perspective and propose Neighborhood Collective Estimation (NCE), in which we reestimate the predictive reliability of a candidate sample by contrast ing it against its featurespace nearest neighboring samples. Herein, we borrow the concept from contrastive learning, and then name such neighboring samples of the candidate as contrastive neighbors. Leveraging contrastive neighbors en riches the predictive information associated with the candidate and also makes such information relatively unbiased, thereby improving the accuracy of noisy label identification and correction. Fig. 1 displays the basic idea of the proposed method. Specifically, to abide by the mainstream LNL pipeline, we divide our method into two steps: 1) Neighborhood Collective Noise Verification (NCNV) to sep arate all training samples into a clean set and a noisy set, 2) Neighborhood Collective Label Correction (NCLC) to relabel noisy samples. In the NCNV stage, a candidate sample is considered noisy when there is a huge inconsistency between the onehot vector of the given label of the candidate and the label dis tributions of its contrastive neighbors predicted using the trained model. In the NCLC stage, we only relabel noisy samples whose predicted label distribution is sufficiently similar to the given labels of neighboring clean samples, and the cor rected label of a noisy sample is related to a weighted combination of the given labels of neighboring clean samples. Once we have identified clean samples and relabeled noisy ones, we leverage offtheshelf and wellestablished techniques, such as mixup regularization [50] and consistency regularization [36], to perform further SSLbased model training. In summary, the main contributions are as follows. ‚ÄìWe propose Neighborhood Collective Estimation for learning with noisy la bels, which leverages contrastive neighbors to obtain richer and relatively unbiased predictive information for candidate samples and thus mitigates confirmation bias. ‚ÄìConcretely, we design two steps called Neighborhood Collective Noise Verifi cation and Neighborhood Collective Label Correction to identify clean sam ples and relabel noisy ones respectively. ‚ÄìWe evaluate our method on four widely used LNL benchmark datasets, i.e., CIFAR10 [16], CIFAR100 [16], Clothing1M [45] and Webvision1.0 [23], and the results demonstrate that our proposed method considerably outper forms stateoftheart LNL methods.4 J. Li et al. 2 Related Work","Deep neural networks (DNNs) have achieved significant success in computer vision tasks, such as image classification, but they rely heavily on extensive manual annotations. To address this problem, learning with noisy labels (LNL) has been proposed to effectively leverage large-scale yet poorly-annotated datasets while mitigating the effects of model overfitting to noisy labels. In the mainstream pipeline, noise verification strategies are adopted to separate the original training set into a clean set and a noisy set, which contain training samples with clean labels and noise correction strategies are adopted to correct the model. In the noise detection",cool!
107,Real-time Localized Photorealistic Video Style Transfer.txt,"We present a novel algorithm for transferring artistic styles of semantically
meaningful local regions of an image onto local regions of a target video while
preserving its photorealism. Local regions may be selected either fully
automatically from an image, through using video segmentation algorithms, or
from casual user guidance such as scribbles. Our method, based on a deep neural
network architecture inspired by recent work in photorealistic style transfer,
is real-time and works on arbitrary inputs without runtime optimization once
trained on a diverse dataset of artistic styles. By augmenting our video
dataset with noisy semantic labels and jointly optimizing over style, content,
mask, and temporal losses, our method can cope with a variety of imperfections
in the input and produce temporally coherent videos without visual artifacts.
We demonstrate our method on a variety of style images and target videos,
including the ability to transfer different styles onto multiple objects
simultaneously, and smoothly transition between styles in time.","Color stylization plays a critical role in modern cine matography and video storytelling. It has the powerful abil ity to grab audience attention, elicit emotions, and convey implicit mood. For example, red usually evokes ideas of ac tion, adventure, and strength; orange can represent joy, cre ativity and stimulation; and green signiÔ¨Åes envy and health. In additional to applying color styles globally to the entire video, modern Ô¨Ålmmakers often utilize localized color tone changes; i.e., distinct color palettes applied to certain seg mented objects in the scene, as a powerful tool in video storytelling. Some wellknown examples include the Ô¨Ålm Schindler‚Äôs List [14], in which the famous scene of a girl in a red coat becomes the most memorable symbol of the Ô¨Ålm. Similarly, the Ô¨Ålm Sin City [15] uses high saturation (such as in red and yellow) to colorize certain characters or clothes, contrasting with the Ô¨Ålm‚Äôs classic blackandwhite noir theme. While color stylization is critical to video production, color style creation and editing today is still a labor intensive and timeconsuming process even with the use of professional editing software. Many operations are still manual in the editing process, such as rotoscoping, reÔ¨Åne 1arXiv:2010.10056v1  [cs.CV]  20 Oct 2020ment of segmentation masks, ensuring temporal consistency from frame to frame, and carefully Ô¨Ånetuning color tones. An automatic approach would be incredibly helpful. To automatically apply color styles to videos, a num ber of methods have recently been introduced based on ad vances in deep learning. For instance, several methods have explored the transfer of artistic styles to images or videos [9, 16, 23, 13, 35, 8, 40]. However, due to their nature asartistic style transfer methods, they all introduce unde sirable painterly spatial distortions. Another line of work [28, 24, 22, 45, 43] focuses on photorealistic style trans fer, which requires the output to maintain ‚Äúphotorealism‚Äù; i.e., the output should look as if it was taken by a real cam era (like most stylized Ô¨Ålms). However, since they primar ily target still photography, existing methods often generate visible Ô¨Çicker artifacts when they are applied to videos. To reduce temporal instability, several methods have tried min imizing an optical Ô¨Çow warping loss [12, 11] or sequentially propagating intermediate features [20]. To our knowledge, there is no existing work that can successfully perform pho torealistic localized style transfer on videos with reasonably good runtime speed. In this paper, we present a novel approach that simulta neously addresses three major challenges in localized pho torealistic video style transfer: 1) spatial and temporal style coherence over time, 2) robustness against imperfect seg mentation masks, and 3) highspeed processing. To achieve highspeed performance, we extend our approach from the recent work of Xia et al. [43], which learns local edgeaware afÔ¨Åne transforms from lowresolution content and style in puts, with the results sliced out from a compact transform representation at the full resolution. To minimize spatial ar tifacts and improve the temporal coherence, we propose a novel spatiotemporal feature transfer layer (STAdaIN) that is able to transfer style to local regions and generate tem porally coherent stylized videos. To handle imperfect seg mentation masks, our algorithm learns an enhancement net work to improve the boundaries of masks. Moreover, we compose foreground and background color transform coef Ô¨Åcients in the grid space, resulting in high quality results even if segmentation masks are inaccurate. Experimental results demonstrate that our model generates stylized videos with fewer visual artifacts and better temporal coherence than existing photorealistic style transfer methods. In summary, our contributions in this work are threefold: ‚Ä¢ A differentiable spatiotemporal style transfer layer (STAdaIN) to match the feature statistics of local re gions, generating temporally coherent stylized results (Section 3.2). ‚Ä¢ Mask enhancement and gridspace blending algo rithms that can render natural style transitions between objects given noisy selection masks (Section 3.3). ‚Ä¢ A deep neural network for photorealistic video styletransfer that runs in realtime (26.5 Hz at 10241024 resolution). 2. Related Work","Color stylization is a powerful tool in video storytelling. However, it is still labor-intensive and time-consuming to create and apply color styles to videos. Existing methods for photorealistic style transfer to videos introduce visible flicker artifacts. To reduce temporal instability, several methods have tried minimizing optical flow warping loss or sequentially propagating intermediate features. To address these challenges, we propose a novel spatiotemporal feature transfer layer (STAdaIN) that is able to transfer style to local regions and generates stylized videos with better temporally coherent results. To",cool!
103,Language Identification Using Deep Convolutional Recurrent Neural Networks.txt,"Language Identification (LID) systems are used to classify the spoken
language from a given audio sample and are typically the first step for many
spoken language processing tasks, such as Automatic Speech Recognition (ASR)
systems. Without automatic language detection, speech utterances cannot be
parsed correctly and grammar rules cannot be applied, causing subsequent speech
recognition steps to fail. We propose a LID system that solves the problem in
the image domain, rather than the audio domain. We use a hybrid Convolutional
Recurrent Neural Network (CRNN) that operates on spectrogram images of the
provided audio snippets. In extensive experiments we show, that our model is
applicable to a range of noisy scenarios and can easily be extended to
previously unknown languages, while maintaining its classification accuracy. We
release our code and a large scale training set for LID systems to the
community.","Intelligent assistants like Siri1or the Google Assistant2rely on ASR. Current ASR systems require users to manually specify the system‚Äôs correc t input lan guage to work properly. However, as a sensible preprocessing st ep we can infer the spoken language using an automatic LID system. Traditional LI D systems utilize domainspeciÔ¨Åc expert knowledge in the Ô¨Åeld of audio signal pro cessing for extracting handcrafted features from the audio samples. L ately, deep learn ing and artiÔ¨Åcial neural networks have become the stateofthe art for many pattern recognition problems. Deep Neural Networks (DNNs) have become the best performing method for a range of computer vision tasks, suc h as image classiÔ¨Åcation [17,18], or object detection and recognition [14,15]. In this paper, we address the problem of language identiÔ¨Åcation fro m a com puter vision perspective. We extract the target language of a give n audio sam ple by utilizing a hybrid network constructed of a Convolutional Neural Net work (CNN) combined with an Recurrent Neural Network (RNN) . Our contri butionscanbesummarizedasfollows:(1)weproposeahybridCRNN, combining ‚ãÜequal contribution 1https://www.apple.com/ios/siri/ 2https://assistant.google.com/the descriptive powers of CNNs with the ability to capture temporal features of RNNs. (2) We perform extensive experiments with our proposed ne twork and show its applicability to a range of scenarios and its extensibility to new lan guages. (3) We release our code and a large scale training set for LI D systems to the community3. Thepaperisstructuredinthefollowingway:Insection2weintroduc erelated work in the Ô¨Åeld of LID systems. We showcase our system in section 3 and evaluate it on extensive experiments in section 4. We conclude our wo rk in section 5. 2 Related Work",We propose a hybrid network constructed of a Convolutional Neural Network (CNN) combined with a Recurrent Neural Network (RNN). We perform extensive experiments with our proposed network and demonstrate its applicability to a range of scenarios and its extensibility to new languages. We release our code and a large scale training set for LI D systems to the community. We showcase our system in section 3 and evaluate it on extensive experiments in section 4. We release our code and a large scale training set for LI D systems to the,cool!
608,Dynamic Label Graph Matching for Unsupervised Video Re-Identification.txt,"Label estimation is an important component in an unsupervised person
re-identification (re-ID) system. This paper focuses on cross-camera label
estimation, which can be subsequently used in feature learning to learn robust
re-ID models. Specifically, we propose to construct a graph for samples in each
camera, and then graph matching scheme is introduced for cross-camera labeling
association. While labels directly output from existing graph matching methods
may be noisy and inaccurate due to significant cross-camera variations, this
paper proposes a dynamic graph matching (DGM) method. DGM iteratively updates
the image graph and the label estimation process by learning a better feature
space with intermediate estimated labels. DGM is advantageous in two aspects:
1) the accuracy of estimated labels is improved significantly with the
iterations; 2) DGM is robust to noisy initial training data. Extensive
experiments conducted on three benchmarks including the large-scale MARS
dataset show that DGM yields competitive performance to fully supervised
baselines, and outperforms competing unsupervised learning methods.","Person reidentiÔ¨Åcation (reID), a retrieval problem in it s essence [ 39,33,38], aims to search for the queried person from a gallery of disjoint cameras. In recent years, im pressive progress has been reported in video based reID [34,20,37], because video sequences provide rich visual and temporal information and can be trivially obtained by tracking algorithms [ 11,12] in practical video surveillance applications. Nevertheless, the annotation difÔ¨Åculty lim its the scalability of supervised methods in largescale camer a networks, which motivates us to investigate an unsupervise d solution for video reID. The difference between unsupervised learning and su pervised learning consists in the availability of labels. C on sidering the good performance of supervised methods, an 1Code is available at www.comp.hkbu.edu.hk/%7emangye/Labels Data  Graphs Matching Learn  Re ID  Labels Data  Graphs Matching Reweighting  fLearn  ReID  Metric Learn Update  Figure 1. Pipeline Illustration. Graph matching is conduct ed af ter constructing a graph for samples in each camera to obtain the intermediate labels. Instead of using the labels directly, label re weighting is introduced to handle the noisy intermediate la bels. Iteratively, the graph is updated, labels are estimated, an d distance metrics are learnt. intuitive idea for unsupervised learning is to estimate re ID labels as accurately as possible. In previous works, part from directly using handcrafted descriptors [ 30,14,19, 16], some other unsupervised reID methods focus on Ô¨Ånd ing shared invariant information (saliency [ 36] or dictionary [9,22]) among cameras. Deviating from the idea of esti mating labels, these methods [ 36,9,22] might be less com petitive compared with the supervised counterparts. Mean while, these methods also suffer from large crosscamera variations. For example, salient features are not stable du e to occlusions or viewpoint variations. Different from the existing unsupervised person reID methods, this paper is based on a more customized solution, i.e., crosscamera label estimation. In other words, we aim to mine the la bels (matched or unmatched video pairs) across cameras. With the estimated labels, the remaining steps are exactly the same with supervised learning. To mine labels across cameras, we leverage the graph matching technique ( e.g., [28]) by constructing a graph for samples in each camera for label estimation. Instead of es timating labels independently, the graph matching approac h has shown good property in Ô¨Ånding correspondences by minimize the globally matching cost with intragraph rela tionship. Meanwhile, label estimation problem for reID task is to link the same person across different cameras, which perfectly matches the graph matching problem by treating each person as a graph node. However, labels di rectly estimated by existing graph matching are very likelyto be inaccurate and noisy due to the signiÔ¨Åcant appearance changes across cameras. So a Ô¨Åxed graph constructed in the original feature space usually does not produce satisfying results. Moreover, the assumption that the assignment cost or afÔ¨Ånity matrix is Ô¨Åxed in most graph matching methods may be unsuitable for reID due to large crosscamera vari ations [ 13,4,2,28]. In light of the above discussions, this paper proposes a dynamic graph matching (DGM) method to improve the label estimation performance for unsupervised video reID (the main idea is shown in Fig. 1). SpeciÔ¨Åcally, our pipeline is an iterative process. In each iteration, a bipartite grap h is established, labels are then estimated, and then a discrim inative metric is learnt. Throughout this procedure, label s gradually become more accurate, and the learnt metric more discriminative. Additionally, our method includes a label reweighting strategy which provides soft labels instead o f hard labels, a beneÔ¨Åcial step against the noisy intermediat e label estimation output from graph matching. The main contributions are summarized as follows: ‚Ä¢We propose a dynamic graph matching (DGM) method to estimate crosscamera labels for unsupervised re ID, which is robust to distractors and noisy initial train ing data. The estimated labels can be used for further discriminative reID models learning. ‚Ä¢Our experiment conÔ¨Årms that DGM is only slightly in ferior to its supervised baselines and yields competi tive reID accuracy compared with existing unsuper vised reID methods on three video benchmarks. 2. Related Work","Unsupervised person reidentification (reID) is a retrieval problem involving the search for a person from a gallery of disjoint cameras. Despite the good performance of supervised methods, the annotation difficulty limits the scalability of supervised methods in large-scale cameras. In this paper, we propose a dynamic graph matching (DGM) method to estimate cross-camera labels for unsupervised reID. The proposed method is an iterative process, where a bipartite graph is established, labels are estimated, and then learned distance metrics are learn",cool!
65,Learning from Multiple Expert Annotators for Enhancing Anomaly Detection in Medical Image Analysis.txt,"Building an accurate computer-aided diagnosis system based on data-driven
approaches requires a large amount of high-quality labeled data. In medical
imaging analysis, multiple expert annotators often produce subjective estimates
about ""ground truth labels"" during the annotation process, depending on their
expertise and experience. As a result, the labeled data may contain a variety
of human biases with a high rate of disagreement among annotators, which
significantly affect the performance of supervised machine learning algorithms.
To tackle this challenge, we propose a simple yet effective approach to combine
annotations from multiple radiology experts for training a deep learning-based
detector that aims to detect abnormalities on medical scans. The proposed
method first estimates the ground truth annotations and confidence scores of
training examples. The estimated annotations and their scores are then used to
train a deep learning detector with a re-weighted loss function to localize
abnormal findings. We conduct an extensive experimental evaluation of the
proposed approach on both simulated and real-world medical imaging datasets.
The experimental results show that our approach significantly outperforms
baseline approaches that do not consider the disagreements among annotators,
including methods in which all of the noisy annotations are treated equally as
ground truth and the ensemble of different models trained on different label
sets provided separately by annotators.","Computeraided diagnosis (CAD) systems for medical imaging analysis are getting more and more successful thanks to the availability of largescale labeled datasets and the advances of supervised learning algorithms [ 1,2]. To reach expertlevel performance, those algorithms usually require highquality label sets, commonly scarce because of the costly and intensive labeling procedures. A typical label collection process in medical imaging is ‚Äú repeatedlabeling ‚Äù, where multiple clinical experts annotate each data instance to overcome human biases [3,4,5]. However, becauseofthediÔ¨ÄerencesfromannotatorbiasesandproÔ¨Åciency, annotations from the repeatedlabeling process often suÔ¨Äer from high interreader variability [ 6,7,8], which could reduce leaning performance if we treat them as groundtruth. Many prior works have been done to mitigate interreader variations in anno tations, which can be categorized into two main groups: (i) onestage approach and (ii) twostage approach. The Ô¨Årst group learns the model, annotators‚Äô proÔ¨Å ciency, and latent true labels jointly. Meanwhile, the second group Ô¨Årst estimates the true label of each instance from its multiple label sets [ 9]. This process is known as ‚Äú truth inference ‚Äù. After that, a supervised learning model is trained on the estimated true labels. All of those approaches show impressive results on both classiÔ¨Åcation and segmentation problems [10, 11]. This work aims at addressing a fundamental question ‚Äú How to train a deep learningbased detector eÔ¨Äectively from a set of possibly noisy labeled data pro vided by multiple annotators? ‚Äù [12]. To this end, we introduce a novel approach that learns from multiple expert annotators to improve the performance of a deep neural network in detecting abnormalities from chest Xray images. The proposed approach, as visualized in Figure 1, consists of two stages. The Ô¨Årst one is truth inference using Weighted Boxes Fusion (WBF) algorithm [ 13] to estimate the true labels and their conÔ¨Ådence scores. The second stage is to train 2an object detector on estimated labels with a reweighted loss function using implicit annotators‚Äô agreement, which is represented by the estimated conÔ¨Ådence scores. For evaluation, we Ô¨Årst simulate and test the proposed approach on a multipleexpertsdetection dataset from MNIST [ 14] called MEDMNIST. We then validate our approach on a realworld chest Xray dataset with radiologist‚Äôs annotations. Experiments on those scenarios demonstrate that the proposed approach provides better detection performance in terms of mAP scores than the baseline of treating multiple annotations as ground truth and the ensemble of models supervised by individual expert annotations. In summary, our main contributions in this work are twofolds: ‚Ä¢First, we introduce a simple yet eÔ¨Äective method that allows a deep learning network to learn from multiple annotators to improve its performance in detecting abnormalities from medical images. The proposed approach aims at estimating the true annotations from multiple experts with conÔ¨Ådence scores and uses these annotations to train a deep learningbased detector. This helps remove uncertainty in the learning process and provides higher label quality to train predictive models. ‚Ä¢Second, the proposed approach demonstrates its eÔ¨Äectiveness on both simulated and real medical imaging datasets by surpassing current state oftheart methods on the context of learning with multiple annotators. In particular, our method is simple and can be applied for a wide range of applications in medical imaging and object detection in general. The codes used in the experiments are available on our Github page at https:// github.com/huyhieupham/learningfrommultipleannotators . We also have made the dataset used in this study available for public access on our project‚Äôs webpage at https://vindr.ai/datasets/cxr . The rest of the paper is organized as follows. Related works on learning from multiple annotators and weighted training techniques are reviewed in Section 2. Section 3 presents the details of the proposed method with a focus on how to 3estimate the ground truth annotations from multiple experts. Section 4 provides comprehensive experiments on a simulated object detection dataset and a real world chest Xray dataset. Section 5 discusses the experimental results, some key Ô¨Åndings, and limitations of this work. Finally, Section 6 concludes the paper. 2. Related works",We introduce a novel approach to learn from multiple expert annotations to improve the performance of a deep neural network in detecting abnormalities from chest Xray images. The proposed approach aims at estimating the true labels from multiple experts with confidence scores and uses these annotations to train a deep learning-based detector. The proposed approach is simple and can be applied for a wide range of applications in medical imaging and object detection in general. The proposed approach is validated on a simulated and real-world chest Xray dataset with radiologist‚Äôs annotations. The proposed approach is simple and,cool!
520,Predicting Ground-Level Scene Layout from Aerial Imagery.txt,"We introduce a novel strategy for learning to extract semantically meaningful
features from aerial imagery. Instead of manually labeling the aerial imagery,
we propose to predict (noisy) semantic features automatically extracted from
co-located ground imagery. Our network architecture takes an aerial image as
input, extracts features using a convolutional neural network, and then applies
an adaptive transformation to map these features into the ground-level
perspective. We use an end-to-end learning approach to minimize the difference
between the semantic segmentation extracted directly from the ground image and
the semantic segmentation predicted solely based on the aerial image. We show
that a model learned using this strategy, with no additional training, is
already capable of rough semantic labeling of aerial imagery. Furthermore, we
demonstrate that by finetuning this model we can achieve more accurate semantic
segmentation than two baseline initialization strategies. We use our network to
address the task of estimating the geolocation and geoorientation of a ground
image. Finally, we show how features extracted from an aerial image can be used
to hallucinate a plausible ground-level panorama.","Learningbased methods for pixellevel labeling of aerial imagery have long relied on manually annotated training data. Unfortunately, such data is expensive to create. Fur thermore, its value is limited because a method trained on one dataset will typically not perform well when applied to another source of aerial imagery. The difÔ¨Åculty in ob taining datasets of sufÔ¨Åcient scale for all modalities has hampered progress in applying deep learning techniques to aerial imagery. There have been a few notable excep tions [21, 23], but these have all used fairly coarse grained semantic classes, covered a small spatial area, and are lim ited to modalities in which human annotators are able to manually assign labels. We propose a novel strategy for obtaining semantic la Cross Entropy Loss  Label Extract  Transform Transfer  Semantics Figure 1. We learn to predict the groundimage segmentation di rectly from an aerial image of the same location, thereby transfer ring the semantics from the ground to the aerial image domain. bels for aerial image segmentation. See Figure 1 for a schematic overview of the approach. Our idea is to use existing methods for semantic image segmentation, which are tailored for ground images, and apply these to a large dataset of geotagged ground images. We use these seman tically labeled images as a form of weak supervision and attempt to predict these semantic labels from an aerial im age centered around the location of the ground image. We do not use a parametric transformation between the aerial and groundlevel viewpoints. Instead, we use a dense rep resentation, similar in spirit to the general representation, dubbed Ô¨Ålter Ô¨Çow, described by Seitz and Baker [26]. There has been signiÔ¨Åcant interest recently in predicting ground image features from aerial imagery for the task of 1arXiv:1612.02709v1  [cs.CV]  8 Dec 2016ground image geolocalization [33]. Our work is unique in that it is the Ô¨Årst to attempt to predict a dense pixellevel seg mentation of the ground image. We demonstrate the value of this approach in several ways. Main Contributions: The main contributions of this work are: (1) a novel convolutional neural network (CNN) architecture that relates the appearance of a aerial image ap pearance to the semantic layout of a ground image of the same location, (2) demonstrating the value of our training strategy for pretraining a CNN to understand aerial im agery, (3) extensions of the proposed technique to the tasks of ground image localization, orientation estimation, and synthesis, and (4) an extensive evaluation of each of these techniques on large, realwold datasets. Together these rep resent an important step in enabling deep learning tech niques to be extended to the domain of aerial image under standing. 2. Related Work","We propose a novel strategy for obtaining semantic labels for aerial imagery. Existing methods for semantic image segmentation are tailored for ground images. We apply these methods to a large dataset of geotagged ground images. We use these images as a form of weak supervision and attempt to predict the semantic labels from an aerial image of the same location. We demonstrate the value of this approach in several ways. First, we demonstrate the value of our training strategy for pre-training a convolutional neural network (CNN) to understand aerial imagery. Second, we demonstrate the value of our approach on large, real-world",cool!
477,Investigating the Effect of Intraclass Variability in Temporal Ensembling.txt,"Temporal Ensembling is a semi-supervised approach that allows training deep
neural network models with a small number of labeled images. In this paper, we
present our preliminary study on the effect of intraclass variability on
temporal ensembling, with a focus on seed size and seed type, respectively.
Through our experiments we find that (a) there is a significant drop in
accuracy with datasets that offer high intraclass variability, (b) more seed
images offer consistently higher accuracy across the datasets, and (c) seed
type indeed has an impact on the overall efficiency, where it produces a
spectrum of accuracy both lower and higher. Additionally, based on our
experiments, we also find KMNIST to be a competitive baseline for temporal
ensembling.","Deep neural networks have seen broad applications across vision speech and language in recent times. Yet this success is contingent on acquiring a large number of labeled datasets, which is expensive and timeconsuming. Further, labeling is mostly manual, done by humans, due to its higher meticulousness. Recently, to address this concern of manual labeling variety of approaches have been designed, including SemiSupervised learning algorithms (Gordon and Hern ¬¥andezLobato, 2017; Laine and Aila, 2017; Lee, 2013), which typically proffer with higher results with a small number of labeled examples (seeds). Notable among this is the Temporal Ensembling (Laine and Aila, 2017), which uses an ensemble of the earlier outputs of a neural network as an unsupervised target label and achieved high accuracy on SVHN and CIFAR10 with just 500 and 4000 labeled samples with both naturally offering lower intraclass variances. Besides, to the best of our knowledge, there is no explicit study of temporal ensembling in the context of datasets with large intraclass variability. As such, in this work, we attempt to investigate this gap by answering the following research questions. ‚ÄìRQ1: Does intraclass variability impact the accuracy of temporal ensembling? Here the intention is to check (a) how accuracy varies and (b) if there is any unique observable behavior with temporal ensembling under different intraclass variances. The assumption here being that the intraclass variability is a spectrum with a range of low to high intraclass variation. To this end, we experiment on datasets of FashionMNIST (Xiao et al., 2017) and KMNIST (Clanuwat et al., 2018) to Ô¨Ånd that there is a sheer drop in performance when using temporal ensembling. ‚ÄìRQ2: Under settings of intraclass variability, how does seed size impact temporal ensembling?. Here we hypothesize and verify that upon increasing seed size, there is an improvement in performance. ‚ÄìRQ3: What‚Äôs the effect of seed selection on temporal ensembling? More speciÔ¨Åcally, we see if the diversity of seeds have an impact on results. The preliminary experimental results show that performance is lower with some category of seeds over others. The rest of the paper is organized as follows. In section 2, we review related research in semisupervised learning. In section 3, we introduce the temporal ensembling approach in brief. In section 4, we present dataset, experimental setup, and answer each of the research questions with analysis in section 5. Finally, we conclude in section 6 with possible implication on future works. Work performed while interning at Hitachi R&D IndiaarXiv:2008.08956v2  [cs.CV]  21 Aug 20202 Related Work","Temporal Ensembling is a semi-supervised learning approach that uses an ensemble of the earlier outputs of a neural network as an unsupervised target label. However, there is no explicit study of temporal ensembling in the context of datasets with large intraclass variability. In this work, we investigate this gap by answering the following research questions. First, we investigate whether there is any unique observable behavior with temporal ensembling under different intraclass variances. Second, we investigate the effect of seed selection on performance. Third,",cool!
518,Structured Label Inference for Visual Understanding.txt,"Visual data such as images and videos contain a rich source of structured
semantic labels as well as a wide range of interacting components. Visual
content could be assigned with fine-grained labels describing major components,
coarse-grained labels depicting high level abstractions, or a set of labels
revealing attributes. Such categorization over different, interacting layers of
labels evinces the potential for a graph-based encoding of label information.
In this paper, we exploit this rich structure for performing graph-based
inference in label space for a number of tasks: multi-label image and video
classification and action detection in untrimmed videos. We consider the use of
the Bidirectional Inference Neural Network (BINN) and Structured Inference
Neural Network (SINN) for performing graph-based inference in label space and
propose a Long Short-Term Memory (LSTM) based extension for exploiting activity
progression on untrimmed videos. The methods were evaluated on (i) the Animal
with Attributes (AwA), Scene Understanding (SUN) and NUS-WIDE datasets for
multi-label image classification, (ii) the first two releases of the YouTube-8M
large scale dataset for multi-label video classification, and (iii) the
THUMOS'14 and MultiTHUMOS video datasets for action detection. Our results
demonstrate the effectiveness of structured label inference in these
challenging tasks, achieving significant improvements against baselines.","VISUAL content is a rich source of highdimensional structured data, with a wide range of interacting com ponents at varying levels of abstractions. With the prolif eration of largescale image [1], [2], [3], [4] and video [5], [6], [7] datasets, advances in visual understanding were fa cilitated for the exploration and enhancement of intelligent reasoning techniques for modelling structured concepts. In this paper, we exploit these rich structures for modelling concept interactions in a number of different tasks and levels of complexity: multilabel image classiÔ¨Åcation, multi label video classiÔ¨Åcation and action detection in untrimmed videos. Standard image classiÔ¨Åcation is a fundamental problem in computer vision ‚Äì assigning category labels to images. It can serve as a building block for many different computer vision tasks including object detection, visual segmentation, scene parsing and concept localization. Successful deep learning approaches [8], [9], [10], [11] typically assume labels to be semantically independent and adapt either a multiclass or binary classiÔ¨Åer to target labels. In recent work [12], [13], deep learning methods that take advantage of label relations have been proposed to improve classiÔ¨Åca tion performance. However, in realistic settings, these label relationships could form a complicated graph structure. Take Figure 1 as an example. Various levels of interpretation could be formed to represent such visual content. This image of a baseball scene could be described as an outdoor image at coarse level, or with a more concrete concept such assports Ô¨Åeld , or with even more Ô¨Ånegrained labels such as batter‚Äôs box and objects such as grass ,bat,person . Models that incorporate semantic label relationships could be utilized to generate better classiÔ¨Åcation results. Fig. 1: This image example has visual concepts at various levels, from sports Ô¨Åeld at a high level to baseball and person at lower levels. Our model leverages label relations and jointly predicts layered visual labels from an image using a structured inference neural network. In the graph, colored nodes correspond to the labels associated with the image, and red edges encode label relations. The desiderata for these models include the ability to model labellabel relations such as positive or negative correlation, respect multiple concept layers obtainable from sources such as WordNet, and to handle partially observed label data given a subset of accurate labels for this image, infer the remaining missing labels.arXiv:1802.06459v1  [cs.CV]  18 Feb 2018IEEE TRANSACTIONS ON PATTERN ANAL YSIS AND MACHINE INTELLIGENCE, VOL. X, NO. Y , MONTH Z 2 In our previous work [14], we developed a structured inference neural network that permits modeling complex re lations between labels, ranging from hierarchical to within layer dependencies. We achieve this by deÔ¨Åning a network in which a node is activated if its corresponding label is present in an image. We introduce stacked layers among these label nodes. These encode layerwise connectivity among label classiÔ¨Åcation scores, representing dependencies from toplevel coarse labels to bottomlevel Ô¨Ånegrained labels. Activations are propagated bidirectionally and asyn chronously on the label relation graph, passing information about the labels within or across concept layers to reÔ¨Åne the labeling for the entire image. The similarity between multilabel classiÔ¨Åcation on im ages and videos suggests exploitation of structured data to be beneÔ¨Åcial for both tasks. As demonstrated in [15], our method extends beyond its applicability on images and is robust to higher dimensional structured data such as videos. A more challenging problem than multilabel video classiÔ¨Å cation consists of handling a sequential input of frames and inferring the corresponding sequence of dense annotations. Our exploration of this setting for the task of dense action detection [7] is twofold: performing static frame structured inference and spatiotemporal structured inference. The static frame inference can be reduced to a standard image classiÔ¨Åcation problem. However, spatiotemporal structured inference requires modelling crosstemporal re lationships between labels. A natural way of extending [15] to support this feature is allowing communication between concept layers in the hierarchical structure for forward prop agating learned label correlations and exploring labels‚Äô pro gression on untrimmed videos. We achieve this by enriching the hidden state of Long ShortTerm Memory (LSTM) [16] units with extracted information from our structured infer ence method along the frame sequences. The contribution of this paper is binding together the proposed model presented in [14] for performing hierarchi cal inference on image datasets (AwA [3] and SUN397 [4]) and its video extension previously implemented in [15]. In addition, we include novel results for the two recent releases of Youtube8M [5], including partially observed labels and propose a temporal extension for the bidirectional and struc tured inference models, demonstrating that adding cross temporal information in label space (i.e. propagation across concept layers) provides superior performance against a tra ditional technique for incorporating temporal dependencies (i.e. LSTM). The validation of the proposed models was carried out on THUMOS [6] and MultiTHUMOS [7] for the task of action detection. This paper is organized as follows. Section 2 presents prior knowledge, covering previous related work. In Sec tion 3, we bind together the bidirectional and structured inference models formulated in [14] with its video exten sion presented in [15] and derive the proposed formulation for temporal extension of our bidirectional and structured inference methods. Sections 4 and 5 present the work done on multilabel image and video classiÔ¨Åcation respectively. Section 6 describes the work done on the action detection task. We conclude in Section 7 with a brief discussion.2 R ELATED WORK","In this paper, we explore the use of structured inference neural networks for modelling concept interactions in a number of different tasks and levels of complexity. We exploit label relations to model multi-label image classification, multi-label video classification and action detection in untrimmed videos. We exploit these rich structures for modelling concept interactions in a number of different tasks and levels of complexity. In particular, we explore the use of structured inference neural networks for performing spatiotemporal structured inference on untrimmed videos. We exploit the hidden state of Long Short-term Memory units with extracted information from our model for performing hierarch",cool!
257,Essence Knowledge Distillation for Speech Recognition.txt,"It is well known that a speech recognition system that combines multiple
acoustic models trained on the same data significantly outperforms a
single-model system. Unfortunately, real time speech recognition using a whole
ensemble of models is too computationally expensive. In this paper, we propose
to distill the knowledge of essence in an ensemble of models (i.e. the teacher
model) to a single model (i.e. the student model) that needs much less
computation to deploy. Previously, all the soften outputs of the teacher model
are used to optimize the student model. We argue that not all the outputs of
the ensemble are necessary to be distilled. Some of the outputs may even
contain noisy information that is useless or even harmful to the training of
the student model. In addition, we propose to train the student model with a
multitask learning approach by utilizing both the soften outputs of the teacher
model and the correct hard labels. The proposed method achieves some surprising
results on the Switchboard data set. When the student model is trained together
with the correct labels and the essence knowledge from the teacher model, it
not only significantly outperforms another single model with the same
architecture that is trained only with the correct labels, but also
consistently outperforms the teacher model that is used to generate the soft
labels.","Automatic speech recognition (ASR), especially nearÔ¨Åeld speech recognition, has achieved great progress in recent years [1, 2]. But the problem of lowresource (i.e. limited training data) speech recognition is ubiquitous since a large amount of annotated data is not available for most languages used in the world. How to train an accurate model with limited training data remains a challenging problem. Various methods have been proposed to fully utilize the limited training data to improve the recognition accuracy of the speech recognition system trained on it. Data augmentation has been shown to be an simple yet ef fective approach to increase the quantity and diversity of the data [3]. It has almost become part of the standard pipeline in data preprocessing for speech recognition. Corrupting clean data with noise [4], vocal tract length perturbation (VTLP [5]), speedperturbation [6] have been widely adopted to improve the performance. Model fusion is another technique to combine information at the other level of the acoustic modeling pipeline. By combin ing neural networks with distinct, complementary architectures [7, 8, 9], the whole system is able to capitalize on each archi tectures strengths to improve the system accuracy. However, usually it is impossible to deploy such a fused model to a large # Both authors contribute equally to this work.number of users since the computation is too expensive, espe cially if the individual models are large and complicated neural nets such as Long ShortTerm Memory (LSTM [10]) and Con volutional LSTM Deep Neural Networks (CLDNN [11]). An effective method to deal with this problem is Knowledge Distil lation (KD [12]). Knowledge Distillation (KD) is a special transfer learning technology. It involves training a new model which is usu ally called the student orstudent model . The knowledge in a welltrained model (the teacher model , usually an ensemble of models) is compressed and transferred to the student model. This student model can be trained on a separate transfer data set without correct labels or on the original training data set where correct labels are available. Various strategies have been proposed to compress and dis till the knowledge of the teacher model to the student model. In the simplest form, the knowledge from the teacher model is distilled to the student model by training it with soften output probabilities produced by the teacher model [12, 13]. Instead of combining the outputs of individual teacher model from an ensemble, Fukuda et.al. [9] proposed to update the parame ters of the student by randomly switching teacher labels at the minibatch level, or to train the student model on multiple output labels from various teacher models. Huang et.al. [14] proposed to use sequencelevel knowledge distillation instead of frame level knowledge distillation. Similar sequencelevel distillation was also explored in [15]. In the above research, none of the dis tilled student models are able to outperform their corresponding teacher models. There are still a big gap between the teacher models and the student models in terms of recognition accu racy. In our opinion, one of the reasons is that only the outputs of the teacher model are used to train the student model. The other reason might be that the student model is driven to learn everything from the teacher model, including not only valuable information that is beneÔ¨Åcial to the generalization of the student model but also garbage information that is noisy and harmful. To deal with this problem, we propose to train the student model with a multitask learning approach in order to utilize the correct hard labels. In addition, we propose to only dis till the essence knowledge of the teacher model to the student model. One obvious problem is how to select the knowledge produced by the teacher model? We propose a simple yet ef fective method to select valuable information from the outputs of the teacher model. The student model is trained with cor rect labels and the selected knowledge from the teacher model. Surprisingly, the student model (with much less model param eters than the teacher model) trained with the proposed method consistently outperforms the teacher model. The rest of this paper is organized as follows: Section 2 introduces the technologies used in our experiments, includ ing data augmentation, model fusion and knowledge distilla tion. We introduce a method to select salient information forarXiv:1906.10834v1  [cs.CL]  26 Jun 2019the outputs of the teacher model. The experimental setup and results are presented in Section 3. Finally, a simple conclusion is drawn in Section 4. 2. Methodology","Knowledge distillation (KD) is a special transfer learning technology. It involves training a new model, called the student model, on a separate transfer data set without correct labels or on the original transfer data set where correct labels are available. In the above research, none of the compressed student models are able to outperform their corresponding teacher models. In this paper, we propose a simple yet effective method to select salient information from the outputs of the teacher model. The student model is trained with a multitask learning approach. We introduce a simple yet effective method to select salient information",cool!
578,Combining data assimilation and machine learning to emulate a dynamical model from sparse and noisy observations: a case study with the Lorenz 96 model.txt,"A novel method, based on the combination of data assimilation and machine
learning is introduced. The new hybrid approach is designed for a two-fold
scope: (i) emulating hidden, possibly chaotic, dynamics and (ii) predicting
their future states. The method consists in applying iteratively a data
assimilation step, here an ensemble Kalman filter, and a neural network. Data
assimilation is used to optimally combine a surrogate model with sparse noisy
data. The output analysis is spatially complete and is used as a training set
by the neural network to update the surrogate model. The two steps are then
repeated iteratively. Numerical experiments have been carried out using the
chaotic 40-variables Lorenz 96 model, proving both convergence and statistical
skill of the proposed hybrid approach. The surrogate model shows short-term
forecast skill up to two Lyapunov times, the retrieval of positive Lyapunov
exponents as well as the more energetic frequencies of the power density
spectrum. The sensitivity of the method to critical setup parameters is also
presented: the forecast skill decreases smoothly with increased observational
noise but drops abruptly if less than half of the model domain is observed. The
successful synergy between data assimilation and machine learning, proven here
with a low-dimensional system, encourages further investigation of such hybrids
with more sophisticated dynamics.","GeophysicalÔ¨Çuiddynamicsisadomainofscienceinwhichthephysicalanddynamicallawsgoverningthesystems arereasonablywellknown. ThisknowledgeisexpressedbypartialdiÔ¨Äerentialequationsthatarethendiscretisedinto numerical models (Randall et al., 2007). However, due to the misrepresentation of unresolved smallscales features or to neglected physical processes, parts of the numerical models have to be represented by empirical submodels or parameterizations. Earth observations are thus needed for two tasks: Ô¨Årst for model tuning and selection (best realism of the model; i.e. estimating/selecting the best possible parameterizations; see e.g. Metref et al., 2019) and then for data assimilation (best accuracy of the model; i.e. estimating the system state; see e.g. Carrassi et al., 2018). Sometimesthesamedataareusedforbothtasks. Inthelastdecades,thevolumeandqualityofEarthobservationshave increased dramatically, particularly thanks to remote sensing (see, e.g., Kuenzer et al., 2014). At the same time, new developmentsinmachinelearning(ML),particularlydeeplearning(Lecunetal.,2015),havedemonstratedimpressive skillsinreproducingcomplexspatiotemporalprocesses(seee.g.Tranetal.,2015,forvideoprocessing)byeÔ¨Éciently using a huge amount of data, thus paving the path for their use in Earth system science (Reichstein et al., 2019). ForecastingandsimulatingaretwodiÔ¨ÄerentobjectivesthatcanbothbeachievedusingML.VariousMLalgorithms have been already applied to produce surrogate models of fully observed loworder chaotic systems and then used for forecastingpurposes;examplesincludereservoirmodeling(Pathaketal.,2017,2018),residualneuralnetwork(Fablet etal.,2018)andrecurrentnetworks(ParkandYanZhu,2002;Park,2010). Machinelearninghasalsobeenappliedfor <Corresponding author julien.brajard@nersc.no, julien.brajard@sorbonneuniversite.fr (J. Brajard) https://jbrlod.loceanipsl.upmc.fr/website/index.html (J. Brajard) ORCID(s):0000000306341482 (J. Brajard); 0000000307225600 (A. Carrassi); 0000000326750347 (M. Bocquet); 0000000212207207 (L. Bertino) J. Brajard et al.: Preprint submitted to Elsevier Page 1 of 18Combining data assimilation and machine learning nowcastingbasedonrealobservations,suchasseasurfacetemperature(deBezenacetal.,2017)orprecipitation (Shi etal.,2015,2017). AlongwiththeseadvancementsinML,theissueofdeterminingasurrogatemodelofanunknown underlyingprocessbasedonobservationshasalsobeenaddressedusingsparseregression(Bruntonetal.,2017;Zhang and Lin, 2018) and, more recently, data assimilation (Bocquet et al., 2019). Diverse numerical results have proven the eÔ¨Äectiveness of ML to reconstruct dynamics under the condition that the ML algorithm is trained on noisefree and complete observations of the system (i.e. when the system state is fully observed). Nevertheless, these circumstances are almost never encountered in practice and certainly not in the geosciences. In the case of partial and noisy observations, one can use a nearestneighbour or an analogue approach: it consists in Ô¨Ånding similar past data (if available) as a forecast (Lguensat et al., 2018). Machine learning techniques havebeenalsoappliedinsituationswhereonlyadenseportionofthesystemisobserved(e.g.deBezenacetal.,2017; Lu et al., 2017) or when the observations are subsampled in time (Nguyen et al., 2019). MostoftheMLalgorithmsusedintheaforementionedstudiesarenotsuitedtorealisticcasesofnoisyandsparse observations. By‚Äúsparse‚Äù,wemeanherethatthestateofthesystemisnotdenselyobserved,andfurthermorethatthe locations and the number of these sparse observations may vary in space and time. Data assimilation (DA) is a natural framework to deal with this observational scenario: it is designed to estimate the state of a system given noisy, unevenly distributed, observations and a dynamical model (Carrassi et al., 2018). The output of DA depends explicitly on the uncertainties in the numerical model (Harlim, 2017), which has led to developing techniques for taking into account model errors in the DA process. This can be done by a parametrization of the model error embedded in the model equations (Aster et al., 2005; Carrassi and Vannitsem, 2011; Bocquet, 2012)orinformofastochasticnoiseaddedtothedeterministicmodel(e.g.Tr√©molet,2006;Ruizetal.,2013;Raanes et al., 2015; Sakov et al., 2018). In any case, a dynamical model must be at disposal and its presence and use are key in DA. In Bocquet et al. (2019) though, this constraint is relaxed to the point that only the general form of the diÔ¨Äerential equations, representing the model, is speciÔ¨Åed. Notably, and a key to the present study, it was shown that the optimization problem solved by DA in the presence of a model error is equivalent to a ML problem. A similar equivalence was also shown by Abarbanel et al. (2018), starting from the point of view of a ML problem. A pure DA approach, however, does not leverage on recent ML developments, that bring Ô¨Çexibility and facilitate parallel calculations. By including explicit or implicit regularization processes, ML algorithms make possible optimizing in highdimension without the need for additional information under the form of an explicit prior. This paper stands at the crossroads of DA and ML, and focuses on the cases where both the system state and its dynamical model have to infer based on noisy and sparse observations. The proposed hybrid algorithm relies on DA to estimate the state of the system and on ML to emulate the surrogate model. Thepaperisorganisedasfollows. Insection2,weformulatetheproblemanddetailhowDAandMLarecombined. Insection3,wepresenttheexperimentalsetupwhereassection4describesthenumericalresultsusingdiÔ¨Äerentmetrics anddiscussesthealgorithmsensitivitytothenumberofobservationsandtheirnoisestatisticsaswellastoothercontrol parameters. Conclusions and perspective are drawn in section 5. 2. Methodology","In the last decade, the volume and quality of Earth observations have increased dramatically, particularly thanks to remote sensing. At the same time, new developments in machine learning (ML) have demonstrated impressive skills in producing complex spatio-temporal processes by efficiently using a huge amount of data. In this paper, we propose a novel approach to predict the system state based on observations, using a surrogate model of an unknown underlying process. The surrogate model is trained on noise-free and complete observations of the system (i.,",cool!
66,KCP: Kernel Cluster Pruning for Dense Labeling Neural Networks.txt,"Pruning has become a promising technique used to compress and accelerate
neural networks. Existing methods are mainly evaluated on spare labeling
applications. However, dense labeling applications are those closer to real
world problems that require real-time processing on resource-constrained mobile
devices. Pruning for dense labeling applications is still a largely unexplored
field. The prevailing filter channel pruning method removes the entire filter
channel. Accordingly, the interaction between each kernel in one filter channel
is ignored.
  In this study, we proposed kernel cluster pruning (KCP) to prune dense
labeling networks. We developed a clustering technique to identify the least
representational kernels in each layer. By iteratively removing those kernels,
the parameter that can better represent the entire network is preserved; thus,
we achieve better accuracy with a decent model size and computation reduction.
When evaluated on stereo matching and semantic segmentation neural networks,
our method can reduce more than 70% of FLOPs with less than 1% of accuracy
drop. Moreover, for ResNet-50 on ILSVRC-2012, our KCP can reduce more than 50%
of FLOPs reduction with 0.13% Top-1 accuracy gain. Therefore, KCP achieves
state-of-the-art pruning results.","Deep learning based algorithms have been evolving to achieve signiÔ¨Åcant results in solving complex and vari ous computer vision applications, such as image classiÔ¨Å cation [14, 20, 35], stereo matching [41, 2], and seman tic segmentation [27, 3, 37]. However, real world appli cations often require the deployment of these algorithms on resourcelimited mobile/edge devices. Owing to over parameterization and high computational cost, it is difÔ¨Å cult to run those cumbersome models on small devices [40], thereby hindering the fruits of those stateoftheart (SOTA) intelligent algorithms from beneÔ¨Åting our lives. Neural net work pruning is a technique to strike the balance between accuracy (performance) and cost (efÔ¨Åciency). Filter level Figure 1. KCP benchmarked on CIFAR10. Points that is lo cated near upper left are preferred because they achieved bet ter accuracyFLOPs tradeoff. Baseline points are the original ResNet. Lines are the envelopes of points from different depth ResNet. Our method achieves better efÔ¨Åciency than previous state ofthearts, namely, FPGM [17], LFPC [15], and HRank [24]. Model pruned by KCP are closer to the upper left corner, and our envelope is decently above that of all other works. Figure 2. Results of KCP on pruning dense labeling networks. The upper row show the results of depth estimation; the predicted depth are samples from KITTI2015 [30, 31] generated by the orig inal PSMNet [2] and the KCP processed 50% sparsity model. The lower row shows the result of semantic segmentation; the predicted class label are samples from Cityscapes [5] generated by original HRNet [37] and KCP processed 50% sparsity model. KCP maintains the model performance both quantitatively and qualitatively. 1arXiv:2101.06686v1  [cs.CV]  17 Jan 2021pruning has been proven to be an effective [23, 29, 17, 24, 10, 15] and favorable method because it could result in a more structural model. Despite the numerous Ô¨Ålter pruning algorithms that have been proposed, previous works are mostly evaluated on a sparse labeling classiÔ¨Åcation task. In a practical scenario, dense labeling problems often require realtime processing in real world problems. Hence, the compression of a dense labeling neural network is crucial and demanding, yet this Ô¨Åeld is still quite unexplored. Moreover, Ô¨Ålter channel prun ing removes the entire output channel, which can sometimes lead to suboptimal results in terms of accuracy preserving. A single Ô¨Ålter channel often contains several kernels; thus, the information density is still high. If one removes the en tire channel, the interactions between each kernels are ne glected. In such a situation, each kernel in one Ô¨Ålter may contribute differently to the Ô¨Ånal prediction. Pruning at the level of the channel is equivalent to aggregating the inÔ¨Çu ence of an individual kernel, which dilutes the uniqueness of each kernel. We propose kernel cluster pruning (KCP) to address the issues and Ô¨Åll the gap in dense labeling pruning. The main concept of KCP is to identify the least representational ker nels in each layer and subsequently remove them. The smallest target to be pruned in KCP is the kernel instead of the Ô¨Ålter. First, the cluster center of kernels in each layer are calculated. Thereafter, the kernels that are closest to the cluster center are considered to carry less information and are removed. Because every pixel in the prediction is assigned a label, dense labeling networks are more vulner able to change in parameter than sparse labeling networks. Kernel pruning enables us to compress dense labeling net works more delicately while still maintaining the network structure after pruning. Experiments showed that we not only successfully compressed the dense labeling network but also achieved SOTA results on CIFAR10 [19] and Im ageNet (ILSVRC2012) [34]. Our main contributions are summarized as follows: ‚Ä¢ A novel kernel pruning method, KCP, is proposed. This method can identify the kernels with least rep resentativeness in each layer then prune those kernels without breaking the original network structure. ‚Ä¢ Thorough evaluations of dense labeling neural network pruning are presented. The results show that KCP can effectively prune those networks and retain the accu racy. To the best of our knowledge, this is the Ô¨Årst work that has investigated structured Ô¨Ålter pruning on dense labeling applications. ‚Ä¢ The experiment on benchmark datasets demonstrates the effectiveness of KCP. KCP achieves new SOTA re sults for ResNet on CIFAR10 (c.f. Fig 1, Table 1) and ImageNet (c.f. Table 2).2. Related Works",Kernel cluster pruning (KCP) is a novel kernel-based filter pruning method for dense labeling neural networks. The main concept of KCP is to identify the kernels with least representationalness in each layer and subsequently remove them. The smallest target to be pruned in KCP is the kernel instead of the filter. The results show that KCP can effectively prune dense labeling neural networks without breaking the original network structure. The KCP method can identify the kernels with least representationalness in each layer and subsequently remove them.,cool!
207,General audio tagging with ensembling convolutional neural network and statistical features.txt,"Audio tagging aims to infer descriptive labels from audio clips. Audio
tagging is challenging due to the limited size of data and noisy labels. In
this paper, we describe our solution for the DCASE 2018 Task 2 general audio
tagging challenge. The contributions of our solution include: We investigated a
variety of convolutional neural network architectures to solve the audio
tagging task. Statistical features are applied to capture statistical patterns
of audio features to improve the classification performance. Ensemble learning
is applied to ensemble the outputs from the deep classifiers to utilize
complementary information. a sample re-weight strategy is employed for ensemble
training to address the noisy label problem. Our system achieves a mean average
precision (mAP@3) of 0.958, outperforming the baseline system of 0.704. Our
system ranked the 1st and 4th out of 558 submissions in the public and private
leaderboard of DCASE 2018 Task 2 challenge. Our codes are available at
https://github.com/Cocoxili/DCASE2018Task2/.","Audio tagging task is a task to predict the presence or ab sence of certain acoustic events in an audio recording, and it has drawn lots of attention during the last several years. Audio tagging has widely applications, such as surveillance, monitoring, and health care [1]. Historically, audio tagging has been addressed with different handcrafted features and shallowarchitecture classiÔ¨Åers including Gaussian mixture models (GMMs) [2] and nonnegative matrix factorizations (NMFs) [3]. Recently, deep learning approaches such as convolutional neural networks (CNNs) have achieved state oftheart performance for the audio tagging task [4, 5]. Corresponding author.DCASE 2018 Task 2 launched a competition for the gen eral audio tagging task [1] to attract research interests for the audio tagging problem. However, due to the limited size of data and noisy labels [1], general audio tagging remains as a challenge and falls short of accuracy and robustness. The cur rent general audio tagging systems are confronted with sev eral challenges: (1) There are a large amount of event classes in [1] compared with previous audio classiÔ¨Åcation tasks [3, 6]. (2) The imbalance problem could make the model emphasize more on the classes with more training samples and difÔ¨Åcult to learn from the classes with less samples. (3) The data qual ity varies from class to class. For example, some audio clips are manually veriÔ¨Åed in [1] but others are not. Designing su pervised deep learning algorithms that can learn from data sets with noisy labels is an important problem, especially, when the data set is small. In this paper, we aim to build scalable ensemble ap proach with taking the noisy label into account. The pro posed method achieves a stateoftheart performance on the DCASE 2018 Task 2 dataset. The contributions of the pa per are summarized as below: (1) A quantitative comparison is investigated using different convolutional neural network (CNN) architectures inspired from computer vision. These CNN architectures are further deployed for the ensemble learning. (2) We propose to employ statistical features in cluding the skewness and kurtosis of framewise MFCC to improve the performance. (3) A scalable ensemble approach is used to utilize the complementary information of different deep architectures and handcrafted features. (4) A samples reweight strategy is proposed for the ensemble learning to solve the noisy label problem in the dataset. The paper is organized as follows: Section 2 describes the proposed CNNs, statistical features, ensemble learning and sample reweight methods. Section 3 shows experimental re sults. Section 4 concludes and forecasts future work.arXiv:1810.12832v1  [cs.CV]  30 Oct 20182. METHODOLOGY","Audio tagging task is a challenging task to predict the presence or absence of certain acoustic events in an audio recording. Traditionally, audio tagging has been addressed with different handcrafted features and shallow-architecture classifiers. Recently, deep learning approaches such as convolutional neural networks (CNNs) have achieved state-of-the-art performance for the audio tagging task. However, due to the limited size of data and noisy labels, general audio tagging systems are confronted with several challenges. In this paper, we aim to build scalable ensemble approach",cool!
293,CNN-Based Real-Time Parameter Tuning for Optimizing Denoising Filter Performance.txt,"We propose a novel direction to improve the denoising quality of
filtering-based denoising algorithms in real time by predicting the best filter
parameter value using a Convolutional Neural Network (CNN). We take the use
case of BM3D, the state-of-the-art filtering-based denoising algorithm, to
demonstrate and validate our approach. We propose and train a simple, shallow
CNN to predict in real time, the optimum filter parameter value, given the
input noisy image. Each training example consists of a noisy input image
(training data) and the filter parameter value that produces the best output
(training label). Both qualitative and quantitative results using the widely
used PSNR and SSIM metrics on the popular BSD68 dataset show that the
CNN-guided BM3D outperforms the original, unguided BM3D across different noise
levels. Thus, our proposed method is a CNN-based improvement on the original
BM3D which uses a fixed, default parameter value for all images.","Image denoising refers to the process of removing noise from a distorted image to recover the clean image. During acquisition, compression or transmission, images and videos often get corrupted by noise. Thus, when the corruption occurs at a particular stage of the processing pipeline, there is a degradation in quality of output of subsequent steps, ultimately aecting the nal visualization. This necessitates the image denoising [21] step for signal processing and transmission applications. In the real world, accurately predicting the result of noise contamination of a clean signal is dicult, as theoretically, there are innumerable possible noise patterns that can contaminate a clean signal. However, most realworld noise patterns can be approximated by Additive White Gaussian Noise (AWGN), and thus it is commonly discussed in the literature. Consequently, traditional denos ing approaches try to model image priors and solve optimization problems, e.g., nonlocal selfsimilarity (NSS) models [4,9], sparse representations models [13,20] ?Supported by NSERC Discovery Grant and DND Supplement.arXiv:2001.06961v1  [eess.IV]  20 Jan 20202 S. Mukherjee et al. and gradientbased models [26,31]. However, these traditional approaches to denoising are slow due to the optimization process, and thus often unt for realtime applications. Also, complex and diverse scene content often cannot be denoised eectively using such handcrafted image priors. The recent breakthroughs in image denoising come from deep neural networks (DNNs), and especially deep Convolutional Neural Networks (CNNs), which use a discriminative denoising model, e.g., MLP [5], REDNet [21] and DnCNN [34]. Their superior performance in many instances is mainly due to the modeling capability of CNNs and the computational capacity of modern GPUs for training progressively deeper and deeper networks. These discriminative models based on deep learning often demonstrate better performance that the traditional model based methods. However, their performance on unseen data (during inference) often varies depending on the type of data they were trained on. If training data for a particular type of application is not representative enough and the model cannot generalize well enough, the denoising performance will suer, which is an inherent issue with all learningbased approaches. For natural images, if the test image has been signicantly distorted with high noise level, causing most structures and ne details in the original image to get visually obfuscated, the discriminative learning approaches often prove insucient. This paper proposes and validates a \middle ground"" between the above two approaches. It uses the GPUbased implementation of a stateoftheart modelbased approach (namely, the Block Matching 3D lter, BM3D [9]) whose parameter is tuned by our proposed CNN in real time, depending on the charac teristics of the noisy input image. This approach is \bestofbothworlds"" in the sense that its denoising work ow has a wellunderstood theoretical basis and is thus, fully explainable (BM3D algorithm) unlike endtoend trained CNNs. At the same time, it optimizes denoising quality by tuning the model parameter us ing a CNN, which can capture more complex characteristics of the input image than what is possible using traditional handcrafted methods. In this paper, we consider a \nonblind"" denoising scenario like section 5.2.1 of [35], where the noise is assumed to be AWGN with known standard deviation. 1.1 Motivation As discussed earlier, over the last few decades, the various challenges posed by the denoising problem has been analyzed thoroughly by many researchers and a lot of interesting solutions have been proposed. In the nonlearningbased cate gory, one of the greatest and recent breakthroughs was achieved by BM3D. Very recently, researchers have found that BM3D outperforms even deep learning based methods for realworld, nonAWGN noise, e.g. in photographs captured by consumer cameras [24]. Moreover, ecient GPU implementation of BM3D has signicantly improved its time performance [17]. BM3D has a lot of input parameters which need to be tuned, though most published denoising methods (learning and nonlearning based) compare their performance with BM3D using its default parameter values, as mentioned in the original BM3D paper [9].Title Suppressed Due to Excessive Length 3 In recent years, researchers have experimentally proved that BM3D perfor mance is, in fact, sensitive to its parameter settings and further, that changing some parameter values in uence its denoising performance signicantly more than changing values of other parameters [19,2]. We repeated those experiments and came to the same conclusion as the researchers that the 3Dis one of the few parameters which cause signicant dierence in BM3D's denoising performance. In BM3D, after grouping of similar (correlated) image blocks (patches), a 3D decorrelating unitary transform is applied to each 3D stack of grouped similar blocks. Enhanced denoising and image detail preservation can only be ensured by choosing a suitable threshold value ( 3D) for applying a hard thresholding operator on the transform coecients. This explains why the 3Dparameter has signicant in uence on BM3D denoising quality. Recently, researchers have tried to adapt the BM3D parameter 3Dto the statistical characteristics of the input image and noise [14] using the Noise Inval idation Denoising (NIDe) technique [3]. However, the parameter used in NIDe for noise condence interval estimation has been xed to the constant value 3, and the suitability of the method [14] for realtime performance has not been dis cussed. Researchers have also attempted to adaptively set the distance threshold for grouping similar image blocks, based on the ratio of the mean and standard deviation and the estimated noise intensity [11]. Motivated by the observation that the Human Vision System is locally adaptive, in another work [12] re searchers have tried to vary BM3D parameters according to local perceptual im age characteristics in a manner determined by extensive subjective experiments. In yet another work, researchers have tried to incorporate locallyadaptive patch shapes and Principal Component Analysis (PCA) in the 3D transform to improve denoising quality, but at the cost of increasing time complexity manyfold, as well as rendering their algorithm unsuitable for realtime GPU implementation (due to adaptiveshape patches) [10]. Other researchers [2] have used traditional learning algorithms like Naive Bayes, Support Vector Machine (SVM), K Nearest Neighbors (kNN) and Random Forest to train numerous classiers to set the 3D value for each block based on the block's texture. However, blockwise prediction of3Dis expected to increase the BM3D time complexity signicantly. Yet, the authors did not report the time performance of their proposed method. Also, they used 77 sized blocks for classication, but did not report or discuss the possible eects of choosing other block sizes. Lastly, even a very recent attempt at replacing parts of the BM3D pipeline with a CNN did notshow potential for realtime performance, even using the fastest GPUs available in the market [32]. In this work, we design a Convolutional Neural Network (CNN) that can pre dict the3Dparameter value which best denoises a noisy image. We compare the performance of our method by comparing the denoising performance of BM3D (using our CNNestimated parameter value) against the denoising performance of BM3D using the default value for the 3Dparameter, as recommended in the original BM3D paper [9].4 S. Mukherjee et al. 1.2 Our Contribution To the best of our knowledge, we are the rst to propose a simple, shallow CNNbased realtime solution to predict optimum parameter values for a lter ing based denoising algorithm. In this paper, we consider such a stateoftheart algorithm, BM3D as a use case to demonstrate and validate this proposal. We propose a method that is readily implementable on GPUs and (for our use case) enhances the denoising capability of the recent GPUbased BM3D implementa tion without signicantly increasing the overall time complexity. The rest of this paper is organized as follows: Related work is given in Sec tion 2. We present our proposed method in Section 3. Experimental results and analysis are in Section 4. In Section 5, we give the conclusion and future work. 2 Related Work","Image denoising refers to the process of removing noise from a distorted image to recover the clean image. In the real world, noise is a major problem, and it is often difficult to predict the result of noise contamination of a clean signal. Consequently, traditional image denoising approaches try to model image priors and solve optimization problems, e.g., non-local selfsimilarity models (NSS), sparse representations models (SRM) models, gradient-based models (GRM), and gradient-based models (CNNs) models based on deep",cool!
607,Group-aware Label Transfer for Domain Adaptive Person Re-identification.txt,"Unsupervised Domain Adaptive (UDA) person re-identification (ReID) aims at
adapting the model trained on a labeled source-domain dataset to a
target-domain dataset without any further annotations. Most successful UDA-ReID
approaches combine clustering-based pseudo-label prediction with representation
learning and perform the two steps in an alternating fashion. However, offline
interaction between these two steps may allow noisy pseudo labels to
substantially hinder the capability of the model. In this paper, we propose a
Group-aware Label Transfer (GLT) algorithm, which enables the online
interaction and mutual promotion of pseudo-label prediction and representation
learning. Specifically, a label transfer algorithm simultaneously uses pseudo
labels to train the data while refining the pseudo labels as an online
clustering algorithm. It treats the online label refinery problem as an optimal
transport problem, which explores the minimum cost for assigning M samples to N
pseudo labels. More importantly, we introduce a group-aware strategy to assign
implicit attribute group IDs to samples. The combination of the online label
refining algorithm and the group-aware strategy can better correct the noisy
pseudo label in an online fashion and narrow down the search space of the
target identity. The effectiveness of the proposed GLT is demonstrated by the
experimental results (Rank-1 accuracy) for Market1501$\to$DukeMTMC (82.0\%) and
DukeMTMC$\to$Market1501 (92.2\%), remarkably closing the gap between
unsupervised and supervised performance on person re-identification.","Person reidentiÔ¨Åcation (ReID) is the important task of matching person images captured from nonoverlapping camera networks, which is widely used in practical appli *Equal contribution ‚Ä†Corresponding author 1Full codes are available in https://github.com/zkcys001/ UDAStrongBaseline and https://github.com/JDAICV/fastreid Network  Network Label  Refinery  Groupaware Label T ransfer Conventional Methods Our Method  Figure 1. Illustration of conventional methods and our group aware label transfer method. In our method, each instance is as signed to multiple prototypes with different granularity f or gen erating multigroup pseudo labels, and then its noisy multi group pseudo labels are online reÔ¨Åned. By learning the reÔ¨Åning mul ti group pseudo labels, our GLT method can learn an embedding space that encodes the semantic multigranularity structu re of data. cations such as automatic surveillance, contentbased re trieval, and behavior analysis [ 17,32,39,5]. It has been proved that existing approaches can achieve remarkable performance when the training and testing data are collecte d from the same application scenario but often fail to gener alize well to other scenarios due to the inevitable domain gaps. Therefore, it is necessary for both academia and in dustry to study the Unsupervised Domain Adaptive (UDA) person reidentiÔ¨Åcation (ReID) problem. Existing UDAReID approaches [ 10,24,34,40] typi cally include three steps: feature pretraining with label ed source domain data, clusteringbased pseudolabel predic  tion for the target domain data, and feature representation learning/Ô¨Ånetuning with the pseudolabels. The last two steps are usually iteratively conducted to strengthen or pr o mote each other. However, the Ô¨Årst problem is that the pseudolabels assigned through clustering usually contai n incorrect labels due to the divergence/domain gap between 1the source and target data, and the imperfect nature of the clustering algorithm. Such noisy labels may mislead the feature learning and harm the domain adaptation perfor mance. Although the label reÔ¨Åning objective in clustering is tractable, it is an ofÔ¨Çine timeconsuming scheme as it re quires a pass over the entire dataset. Therefore, online re Ô¨Åning those incorrect samples when training can help model learn more robust and accurate representation. Another problem is that the target domain lacks ID infor mation, so it is difÔ¨Åcult to cluster the person images accord  ing to human identity. However, in the real world, each per son has their own characteristics in his or her appearance. There may be common appearances shared by a group of people but they are not the same identity (e.g. two men with the same red coats and similar black pants as shown in Fig. 1). Therefore, groupbased description [ 15] that in volves common characteristics in a pseudo group, can be useful to narrow down the set of candidates and beneÔ¨Åcial to identify the exact persons. This groupaware strategy ca n cluster a person into multigroup clustering prototypes, a nd is able to efÔ¨Åciently embed a signiÔ¨Åcant number of people and brieÔ¨Çy describe an unknown person. Inspired by this, as shown in Fig. 1, combining the online label reÔ¨Åning al gorithm with the groupaware strategy may be beneÔ¨Åcial to the success of domain adaptation. In this paper, we propose a Groupaware Label Trans fer (GLT) algorithm that facilitates the online interactio n and mutual promotion of the pseudo labels prediction and feature learning. SpeciÔ¨Åcally, our method simultaneously uses pseudo labels to train the data while online reÔ¨Åning the pseudo labels via the label transfer algorithm. This label transfer algorithm regards the resulting label reÔ¨Åning pro b lem as optimal transport, which explores the minimum cost for assigning M samples to N pseudo labels. This prob lem can therefore be solved by the SinkhornKnopp algo rithm [ 4] of linear programming in polynomial time. Mean while, the label transfer algorithm is scalable, which can b e trained with several batches or the whole dataset and can scale to unlimited amounts of data. More importantly, we introduce a groupaware strategy to assign implicit attrib ute group IDs to samples. Explicit grouping requires manual annotation. Therefore, we adopt a groupaware clustering algorithm to generate multigroup pseudo labels. By adopt ing the concept of grouping, the ReID network can reduce the search space and Ô¨Çexibly embed a signiÔ¨Åcant number of identities into an embedding feature. As shown in Fig. 1, we combine the online label reÔ¨Åning algorithm with the multi group pseudo labels. The combination of the online label reÔ¨Åning algorithm and the groupaware strategy can better correct the noisy pseudo label online and narrow down the search space of the target identity and predict more accurat e pseudo labels. In addition, we design a target instance mem ory bank combined with weighted contrastive loss [ 25] tomake the model more powerful for features representation. The proposed GLT framework achieves stateoftheart per formance on MarkettoDuke, DuketoMarket, Marketto MSMT, and DuketoMSMT with unsupervised domain adaptation, and in particular the i.e. DuketoMarket per formances (92.2 Rank1 and 79.5 mAP) are almost com parable with the supervised learning performances (94.1 Rank1 and 85.7 mAP). Our method signiÔ¨Åcantly closes gap between unsupervised and supervised performance on per son reidentiÔ¨Åcation, i.e., 92.2 vs. 94.1 top1 accuracy in DukeMTMC to Market1501 transfer. The main contributions of this paper can be summarized in four aspects: ‚Ä¢ We make the Ô¨Årst attempt towards integrating clus tering and feature learning in a uniÔ¨Åed framework through the label transfer method for UDAReID. It can online reÔ¨Åne the predicted pseudo labels to im prove the feature representation ability of the model on the target domain. ‚Ä¢ We propose a groupaware feature learning strategy based on label transfer to reÔ¨Åne multigroup pseudo la bels, which provides good latent pseudolabel groups for improving the quality of representation learning. ‚Ä¢ The GLT framework achieves signiÔ¨Åcant performance improvements compared to stateoftheart approaches on Market‚ÜíDuke, Duke‚ÜíMarket, Market‚ÜíMSMT, Duke‚ÜíMSMT ReID tasks. Even for the supervised learning methods, our algorithm is remarkably closing the gap. 2. Related Work","Person reidentification (ReID) is an important task in unsupervised domain-adaptive (UDA) person reidentification (ReID). Existing approaches mainly focus on the training and testing of the ReID network, which includes feature pre-training, clustering-based pseudo-label prediction for the target domain data, and feature representation learning/finetuning with the pseudo-labels. However, the clustering-based pseudo-labels usually contain incorrect labels due to the divergence/domain gap between the source and the target domain gaps between the source and the",cool!
501,Hand Pose Estimation via Multiview Collaborative Self-Supervised Learning.txt,"3D hand pose estimation has made significant progress in recent years.
However, the improvement is highly dependent on the emergence of large-scale
annotated datasets. To alleviate the label-hungry limitation, we propose a
multi-view collaborative self-supervised learning framework, HaMuCo, that
estimates hand pose only with pseudo labels for training. We use a two-stage
strategy to tackle the noisy label challenge and the multi-view ``groupthink''
problem. In the first stage, we estimate the 3D hand poses for each view
independently. In the second stage, we employ a cross-view interaction network
to capture the cross-view correlated features and use multi-view consistency
loss to achieve collaborative learning among views. To further enhance the
collaboration between single-view and multi-view, we fuse the results of all
views to supervise the single-view network. To summarize, we introduce
collaborative learning in two folds, the cross-view level and the multi- to
single-view level. Extensive experiments show that our method can achieve
state-of-the-art performance on multi-view self-supervised hand pose
estimation. Moreover, ablation studies verify the effectiveness of each
component. Results on multiple datasets further demonstrate the generalization
ability of our network.","3D hand pose estimation is essential in various applica tion scenarios, from action recognition and sign language translation to AR/VR [25, 26]. Hand pose estimation has achieved a signiÔ¨Åcant improvement in recent years. How ever, the progress heavily relies on the emergence of many hand pose datasets with accurate 3D annotations. Acquir ing labeled datasets is quite timeconsuming and laborious, exposing a realistic challenge for deep learning models to learn with limited and noisy data. Selfsupervised learning is an emerging solution to the challenge posed by manual annotation. Though worth ex ploring, selfsupervised pose estimation with RGB hand im ages is a challenging and relatively unexplored area with only one pioneering method, S2HAND [13]. S2HAND aims to conduct 3D hand reconstruction from a single RGB image with the noisy offtheshell 2D hand pose estima tion results (OpenPose) for supervision. Unfortunately, S2HAND still suffers from a dilemma that the performance is highly restricted by the quality of the pseudo label in a speciÔ¨Åc view when handling an illposed problem. This observation motivates us to exploit multiview in formation to improve selfsupervised learning due to com plementary multiview observations can alleviate the am biguity of pose estimation. There is some literature using multiview data for selfsupervised human body estimation, including EpiporlarPose [35] and CanonPose [62]. How 1arXiv:2302.00988v1  [cs.CV]  2 Feb 2023ever, these approaches only adopt a singleview network to process isolated views, which makes them not feasible for selfsupervised hand pose estimation, whose utilized 2D pseudo labels generated by the offtheshell 2D hand pose estimator are relatively inaccurate. To our knowledge, no previous work discussed the potential of multiview in self supervised hand pose estimation. In this paper, we push along this direction via multiview collaborative learning. As mentioned in [32], naively enforcing multiview con sistency is prone to generate degenerated solutions. At the early training stage, it may be hamstrung by the majority as ‚Äúthe blind lead the blind‚Äù. To summarize, there are sev eral challenges seldom addressed by previous methods, (1) noisy pseudo labels, (2) limited information from cluttered observations, and (3) earlystage divergence. To this end, we propose a novel twostage strategy to tackle noisy pseudo label and unreliable multiview ‚Äúgroup think‚Äù issues. Formally, we name the pipeline HaMuCo, which stands for Ha nd Mu ltiview Co llaborative learn ing. The core insight is to decouple the initial results from the singleview estimation and the updated predic tions after crossview interaction and fusion. SpeciÔ¨Åcally, HaMuCo has (1) the singleview stage and (2) the multi view stage. The singleview stage provides initial predic tions and visual cues from a simple modelbased network with the MANO [53] hand model as the decoder. Us ing a parametric model provides hand priors to regularize irrational anatomy when guided by noisy pseudo labels. Themultiview stage is an essential part of our framework, which conducts crossview interaction, fusion, and distilla tion. In this stage, we design a crossview interaction net work consisting of a (1) multiview graph feature extraction module to gather useful information from all views, a (2) dualbranch crossview interaction module to capture joint level dependencies across all views, and a (3) parameters re gression module. This network is permutationequivalence and can work with variable input views. To solve the chal lenge of updating the pose effectively towards consistent results without early divergence, we introduce multiview collaborative learning in two folds. On the one hand, we design a dualbranch consistency for crossview level col laborative learning to guide all the views to learn from each other. On the other hand, we achieve selfdistillation by fus ing the results of all views into a Ô¨Ånal prediction and using it to supervise the singleview estimations. This procedure further enhances the collaboration between singleview and multiview networks. We conduct comprehensive experiments to demonstrate that HaMuCo is simple, effective, and versatile. Abun dant experiments on the HanCo [72] dataset validate the efÔ¨Åcacy of each component and analyze our model from different aspects. Meanwhile, our method achieves state oftheart performance both in single and multiview 3Dhand pose estimation, under multiview selfsupervised set tings. As shown in Fig. 1, our model can generalize well to other datasets [37, 74] and inthewild images. Further more, our method can also obtain plausible selfsupervised performance on the Assembly101 [54] dataset. In summary, our contributions are the following: ‚Ä¢ We present the Ô¨Årst multiview selfsupervised learn ing framework for 3D hand pose estimation, which can achieve accurate single and multiview estima tions without any manual annotations for training. ‚Ä¢ We propose a crossview interaction network and su pervise it with dualbranch consistency loss and multi view distillation loss to achieve collaborative learning at a crossview level and multi to singleview level. ‚Ä¢ We experimentally validate the efÔ¨Åcacy of our method on benchmarks and achieve stateoftheart perfor mance both in single and multiview 3D hand pose estimation under multiview selfsupervised settings. 2. Related Work","Self-supervised hand pose estimation with RGB hand images is a challenging and relatively unexplored area. To this end, we propose a novel two-stage strategy to tackle noisy pseudo labels, limited information from cluttered observations, and early-stage divergence. Formally, we name the pipeline HaMuCo, which stands for Hand Multiview Collaborative Learning. The single-view stage provides initial predictions and visual cues from a simple model-based network with the MANO hand model as the decoder",cool!
425,Reconstructing a dynamical system and forecasting time series by self-consistent deep learning.txt,"We introduce a self-consistent deep-learning framework which, for a noisy
deterministic time series, provides unsupervised filtering, state-space
reconstruction, identification of the underlying differential equations and
forecasting. Without a priori information on the signal, we embed the time
series in a state space, where deterministic structures, i.e. attractors, are
revealed. Under the assumption that the evolution of solution trajectories is
described by an unknown dynamical system, we filter out stochastic outliers.
The embedding function, the solution trajectories and the dynamical systems are
constructed using deep neural networks, respectively. By exploiting the
differentiability of the neural solution trajectory, the neural dynamical
system is defined locally at each time, mitigating the need for propagating
gradients through numerical solvers. On a chaotic time series masked by
additive Gaussian noise, we demonstrate the filtering ability and the
predictive power of the proposed framework.","Time series analysis and time series forecasting have been studied to extract information about the data and the underlying dynamics, and to predict the future of observables from past measurements. The Ô¨Årst systematic modeling of time series dates back to 1927 when Yule [1927] introduced a linear autoregression model to reveal the dynamics of sunspot numbers. The model which writes as u(k+ 1) =m","Time series analysis and time series forecasting have been studied to extract information about the data and the underlying dynamics, and to predict the future of observables from past measurements. The first systematic modeling of time series dates back to 1927 when Yule introduced a linear autoregression model to reveal the dynamics of sunspot numbers. The model which writes as u(k+ 1) =m is a linear autoregression model which has been studied for over a century. The first systematic modeling of time series dates back to 1927 when Yule introduced a linear autoregression model to reveal the",cool!
23,Adversarial Training with Stochastic Weight Average.txt,"Adversarial training deep neural networks often experience serious
overfitting problem. Recently, it is explained that the overfitting happens
because the sample complexity of training data is insufficient to generalize
robustness. In traditional machine learning, one way to relieve overfitting
from the lack of data is to use ensemble methods. However, adversarial training
multiple networks is extremely expensive. Moreover, we found that there is a
dilemma on choosing target model to generate adversarial examples. Optimizing
attack to the members of ensemble will be suboptimal attack to the ensemble and
incurs covariate shift, while attack to ensemble will weaken the members and
lose the benefit from ensembling. In this paper, we propose adversarial
training with Stochastic weight average (SWA); while performing adversarial
training, we aggregate the temporal weight states in the trajectory of
training. By adopting SWA, the benefit of ensemble can be gained without
tremendous computational increment and without facing the dilemma. Moreover, we
further improved SWA to be adequate to adversarial training. The empirical
results on CIFAR-10, CIFAR-100 and SVHN show that our method can improve the
robustness of models.","Although DNN shows great performance and generaliza tion ability, it has been found that convolutional neural net works (CNNs) are susceptible to designed adversarial attack, even if the attack is imperceptibly small. As the modern computer vision technology heavily relies on CNN, the vul nerability becomes a great threat. To mitigate such threat, many algorithms have been proposed to make network to be robust to adversarial attack (Xie et al. 2018; Song et al. 2018; Papernot et al. 2016; Madry et al. 2017). However, it has been found that many of these methods are not robust indeed; many proposed defense algorithms rely on obfus cated gradient which gives robustness against particular at tacks only, and can be circumvented by adaptively designed attack (Athalye, Carlini, and Wagner 2018; Tram `er et al. 2017). Among the methods compared in the paper, the only defense method that is believed to provide true robustness is training network with strong adversarial examples such as projected gradient descent (PGD) (Madry et al. 2017). Copyright c 2021, Association for the Advancement of ArtiÔ¨Åcial Intelligence (www.aaai.org). All rights reserved.Hence, adversarial training is considered as the most reli able defense paradigm so far. However, adversarial training is prone to overÔ¨Åt ting (Schmidt et al. 2018). In robust training, adversarial loss on test set increases substantially after a certain point while training error decrease continuously. This overÔ¨Åtting phenomenon brings large generalization gap on adversarial accuracy and limits robustness. To explain such susceptibil ity, Schmidt (Schmidt et al. 2018) provide theoretical analy sis that concludes the overÔ¨Åtting is due to the lack of train ing data. According to the analysis, the sample complexity required to generalize robustness is signiÔ¨Åcantly lager than that for standard generalization. In traditional machine learning, one way to relieve overÔ¨Åt ting is adopting ensemble methods (Dietterich 2000). When the hypothesis space is too large to explore for limited train ing data, there may be several different hypotheses giving similar accuracy on the training data, and combining the hy potheses can reduce the risk to choose wrong hypotheses. Therefore, to alleviate the overÔ¨Åtting, one can easily con sider naive ensemble method which combines the results of adversarial trained model (Grefenstette et al. 2018). However, adopting naive ensemble method faces two problems. First and trivial problem is computation cost in crements. Adversarial training is already expensive due to multiple gradient computation required in generating ad versarial examples. Training multiple networks to ensemble with adversarial examples will multiply the expense accord ingly and the overall training becomes overburden. The other problem not yet discussed much is dilemma on choosing models to generate adversarial examples with respect to. The adversarial characteristic of an example is deÔ¨Åned by the corresponding network model. In naive en semble method, there can be two options on which model the adversarial example should be generated with respect to; individual members or whole ensemble system. If adversar ial examples are generated with respect to each member, the whole system is trained with suboptimal attack. If adversar ial examples are generated with respect to the whole ensem ble system, the members of ensembles are trained weakly and are likely to become less diverse. We illustrate the idea in Ô¨Ågure 1 and name it as dilemma of decoupling. Further elaboration is dealt in proposed method section in detail. The main purpose of this paper is to introduce the enarXiv:2009.10526v1  [cs.LG]  21 Sep 2020Adv Generating Stage Training Stage ùíéùüè Ensemble ùë¨ Ensemble ùë¨ ùíôùíÇùíÖùíó=ùêöùê´ùê†ùê¶ùêöùê± ùíô‚ààùìëùìõ(ùíô,ùíö,ùíéùüè) ùíôùíÇùíÖùíó=ùêöùê´ùê†ùê¶ùêöùê± ùíô‚ààùìëùìõ(ùíô,ùíö,ùíéùüê) ùíôùíÇùíÖùíó=ùêöùê´ùê†ùê¶ùêöùê± ùíô‚ààùìëùìõ(ùíô,ùíö,ùë¨) nat image ùíô ùíéùüêùíôùíÇùíÖùíó‚â†ùêöùê´ùê†ùê¶ùêöùê± ùíô‚ààùìëùìõ(ùíô,ùíö,ùë¨) ùíôùíÇùíÖùíó‚â†ùêöùê´ùê†ùê¶ùêöùê± ùíô‚ààùìëùìõ(ùíô,ùíö,ùë¨) nat image ùíô ùíôùíÇùíÖùíó‚â†ùêöùê´ùê†ùê¶ùêöùê± ùíô‚ààùìëùìõ(ùíô,ùíö,ùíéùüê)ùíôùíÇùíÖùíó‚â†ùêöùê´ùê†ùê¶ùêöùê± ùíô‚ààùìëùìõ(ùíô,ùíö,ùíéùüè)ùíéùüè ùíéùüê(a) (b)Figure 1: Dilemma of decoupling. Adversarial training with naive ensemble faces dilemma on choosing target model for generating adversarial examples. (a) Adversarial examples generated with respect to each member are suboptimal attack to whole ensemble and less useful to minimize empirical risk. (b) Adversarial examples generated with respect to whole ensemble are suboptimal to members and make them weak and less diverse, which in consequence loses beneÔ¨Åt of ensemble. semble method which can improve the adversarial training further. In this paper, we propose stochastic weight averag ing method(SWA)(Izmailov et al. 2018) based adversarial training(SWAAT) that defense whitebox attack effectively. During adversarial training, weight states on training trajec tory are aggregated to the average and the aggregated weight state is updated periodically. This makes it possible to have an ensemble effect while it does not suffer from the down side of ensemble we discussed previously. The adversarial examples generated during the proposed method is optimal to the members and nearly optimal to overall ensemble. This is a special beneÔ¨Åt of adopting SWA in adversarial training which does not belong to SWA in standard training. More over, due to the original characteristic of SWA, additional computation cost can be remained negligible. As a result, SWA enables one to train models with stronger robustness efÔ¨Åciently. The contributions of this paper we claim are as follows: We point out a dilemma of decoupling that arises when using ensemble method in adversarial training. The dilemma is concerning about which model to choose when generating adversarial examples to train. We propose a SWAAT without the drawbacks of conven tional ensembling methods. The proposed method pro vides not only effective ensembling strategy, but also fast batch normalization method in weight averaging pro cess of SWA and diversiÔ¨Åcation of member models by memberspeciÔ¨Åc data selection stage. Extensive experiments which are conducted using CIFAR10 and CIFAR100 datasets show that the proposed method signiÔ¨Åcantly improves performance in de fending designed adversarial attacks. 2 Related work","Convolutional neural net works (CNNs) are susceptible to designed adversarial attack, even if the attack is imperceptibly small. To mitigate such threat, many algorithms have been proposed to make network to be robust to adversarial attack. However, many of these algorithms rely on opaque gradient which gives robustness against particular attacks only, and can be circumvented by adaptively designed attack. In this paper, we propose a novel naive ensemble method to overcome the overfitting problem. The first problem is the ensemble method. The second problem is dilemma on choosing",cool!
440,Multi-object tracking with self-supervised associating network.txt,"Multi-Object Tracking (MOT) is the task that has a lot of potential for
development, and there are still many problems to be solved. In the traditional
tracking by detection paradigm, There has been a lot of work on feature based
object re-identification methods. However, this method has a lack of training
data problem. For labeling multi-object tracking dataset, every detection in a
video sequence need its location and IDs. Since assigning consecutive IDs to
each detection in every sequence is a very labor-intensive task, current
multi-object tracking dataset is not sufficient enough to train
re-identification network. So in this paper, we propose a novel self-supervised
learning method using a lot of short videos which has no human labeling, and
improve the tracking performance through the re-identification network trained
in the self-supervised manner to solve the lack of training data problem.
Despite the re-identification network is trained in a self-supervised manner,
it achieves the state-of-the-art performance of MOTA 62.0\% and IDF1 62.6\% on
the MOT17 test benchmark. Furthermore, the performance is improved as much as
learned with a large amount of data, it shows the potential of self-supervised
method.","MultiObject Tracking(MOT) is one of the fundamental challenges of computer vision and is widely used in in dustrial Ô¨Åelds such as surveillance image processing. many MOT studies have been conducted on pedestrians tracking, because the mainly used benchmark of MOT, the MOT chal lenge benchmark (Milan et al. 2016) is focused on pedestri ans tracking. In MOT, the detection by tracking paradigm has been dominated for a long time. It is a method of obtaining de tection results in each frame of video using offtheshelf de tection algorithm such as FasterRCNN (Ren et al. 2015), DPM (Felzenszwalb et al. 2009) , and organically associ ating the detection results of the previous frame with the detection results of the current frame and form tracks. The MOT algorithm can be divided into online method and batch method, which is the difference between whether future in formation is used to form tracks of the current frame. Online method that does not use future information is more suitable Copyright ¬© 2021, Association for the Advancement of ArtiÔ¨Åcial Intelligence (www.aaai.org). All rights reserved.for practical application, a lot of research has been done with the online method. There are various approaches in MOT algorithms, but the most of them deals with how to associate the track of the previous frame with the detection of the current frame. Among them, we approach by reidentifying detection re sults through appearance model. we train feature extraction network with appearance information of detection patches and associate tracks with detection patches using its feature. However this approach has two drawbacks. First, a lot of computation is required because all detection patches have to pass through the feature extraction network and proceed matching with tracks using those features. Second, the lack of learning data. Labeling MOT dataset is very labor inten sive task. The MOT dataset consists of video sequence and a detection bounding box of each frame and its ID. To label this ID, a detection bounding box with an ID of all video se quence must be tracked and labeled by a human supervision. But each video sequence consists of many frames and also there are so many people per frame, it takes a lot of labor to label them. This is the one of the biggest problems in MOT. Therefore, we try to solve this problem by applying self supervised learning to MOT. Unsupervised learning or self supervised learning has been proposed to solve the lack of training data problem in image classiÔ¨Åcation or segmenta tion (Doersch, Gupta, and Efros 2015; Gidaris, Singh, and Komodakis 2018; V ondrick et al. 2018), but it has rarely been applied to MOT. We closely analyze the MOT to Ô¨Ånd a new pretext which is suitable for the MOT task and pro pose the selfsupervised associating tracker(SSAT) which is a tracking algorithm that train the feature extraction net work without data constraints by a selfsupervised manner, and utilize it directly to reidentify targets to track without a seperate downstream tasks. 2. Related work","Multi-Object Tracking(MOT) is one of the fundamental challenges of computer vision. The most common MOT paradigm is the detection by tracking, which is a method of obtaining detection results in each frame of video using off-the-shelf detection algorithm such as FasterRCNN, DPM, and so on, and organically associating the detection results of the previous frame with the detection results of the current frame and form tracks. There are various approaches in MOT algorithms, but the most of them deals with how to associate the detection patches with the current frame",cool!
41,QFCNN: Quantum Fourier Convolutional Neural Network.txt,"The neural network and quantum computing are both significant and appealing
fields, with their interactive disciplines promising for large-scale computing
tasks that are untackled by conventional computers. However, both developments
are restricted by the scope of the hardware development. Nevertheless, many
neural network algorithms had been proposed before GPUs become powerful enough
for running very deep models. Similarly, quantum algorithms can also be
proposed as knowledge reserves before real quantum computers are easily
accessible. Specifically, taking advantage of both the neural networks and
quantum computation and designing quantum deep neural networks (QDNNs) for
acceleration on Noisy Intermediate-Scale Quantum (NISQ) processors is also an
important research problem. As one of the most widely used neural network
architectures, convolutional neural network (CNN) remains to be accelerated by
quantum mechanisms, with only a few attempts have been demonstrated. In this
paper, we propose a new hybrid quantum-classical circuit, namely Quantum
Fourier Convolutional Network (QFCN). Our model achieves exponential speed-up
compared with classical CNN theoretically and improves over the existing best
result of quantum CNN. We demonstrate the potential of this architecture by
applying it to different deep learning tasks, including traffic prediction and
image classification.","Existing works [ 1,2] have attempted to incorporate the classical machine learning algorithms and quantum computation techniques, which yields quantum machine learning frameworks. It is also promising for deep convolutional neural network (CNN) to be leveraged with quantum methods towards achieving quantum convolutional models, thanks to the following reasons. First, CNNs manipulate data in the manner of performing matrix operations in high dimensional vector space, while quantum computation also conducts matrix operations in high dimensional vector space [ 1]. Second, most of the deep CNN models require large datasets for parameter optimization, and often need heavy computation for both the training and testing. Meanwhile, based on special quantum information properties named entanglement and superposition, quantum computers can make exponential number of calculations in parallel. This mechanism, known as quantum speedup, can accelerate some learning algorithms to surpass their classical counterparts based on mathematical proofs [3, 4, 5, 6]. Two decades ago, scientists began to implement quantum algorithms on real quantum machines. With the continuous development of quantum hardware, scientists suggest that human beings will live in Noisy IntermediateScale Quantum (NISQ) era in the future, and everyone is expected to have a quantum computer with 50100 qubits, which could be used to perform some special tasks that surpass the capabilities of today‚Äôs classical computers [7, 8]. Recently, deep neural networks become quite popular and have been widely applied in computer vision, natural language processing, and many other areas, thanks to the advancement of deep learning techniques [ 9,10,11]. As one of the most important deep learning techniques, the convolution module has been used in many network architectures, and many stateofart models for handling different types of tasks contain convolutional layers [12, 13, 14, 15].arXiv:2106.10421v1  [quantph]  19 Jun 2021APREPRINT  JUNE 22, 2021 Given the aforementioned background of quantum computation and Ô¨Çourish CNN Ô¨Åelds, it becomes natural that we get interested in integrating the potentials and advantages of these two kinds of techniques, i.e., quantum computing and CNNs, to handle speciÔ¨Åc convolutionbased learning tasks that need continuously increasing computation capabilities. However, the direct convolution of quantum state has been shown to be inaccessible by previous studies [ 16]. In this paper, we propose a hybrid circuit with quantum Fourier transform to achieve deep convolutional models with quantum. The major blocks in CNNs are the convolutional operations, i.e., the product of the kernel and the input data that can have various dimensions. This process often accounts for a large proportion of the computation cost and time consumption in the whole network. Another approach that can be used to efÔ¨Åciently implement the convolutional operation is transforming the kernel and data to Fourier basis and then performing inverse transform based on their product. Some of the classical networks like graph convolutional networks (GCNs) have used the approximation of this method to implement convolution [ 17,18,19]. Inspired by this, to achieve quantum convolution, here we propose a novel quantum Fourier convolutional network (QFCN) to speedup the CNN with quantum Fourier transform (QFT), which could be exponentially faster than the classical Fourier transform for convolutions. We circumvent the inaccessibility issue [ 16] by adopting part quantum circuit of windowed Fourier transform [ 20]. We also propose a hybrid quantumclassical circuit to avoid some of the quantum noise and also to take advantage of classical computers that are able to perform rapid iterations for model optimization. We demonstrate the potential of our network on the trafÔ¨Åc prediction task with spatiotemporal graph convolutional models and the image classiÔ¨Åcation task with 2D convolutional networks. Motivations and contributions. We all know the importance of convolution to the deep learning Ô¨Åeld. If we want to speed up the training of nowadays‚Äô networks which mostly build upon a bunch of convolutional layers, the quantum convolutional layer and its optimization will be inevitable problems. There are only two architectures of convolutional layer being proposed[ 21,22] . However, due to the horriÔ¨Åc time assumption of quantum stimulation, the results of these two papers are based on toy experiments and their network only contain two quantum convolutional layers. Unfortunately, with the increase of the layer number, the gradient of these two structures may lead to Barren plateaus [ 23] in training. So, it is essential to proposed another quantum convolution method rather than simply transferring conventional multiply accumulation (MAC) to quantum mechanism like previous works. The contributions of this paper are summarized below. To the best of our knowledge, we are the Ô¨Årst to propose a hybrid quantumclassical circuit to speed up CNN with a parametric quantum circuit (PQC), and exploit quantum Fourier transform for the trainable convolution models. SpeciÔ¨Åcally, our PQC can be inserted into different deep networks to replace the convolutional layers. Besides, we also introduce the quantum optimization algorithm (backpropagation) for our designed network. 2 Related Work","We propose a novel quantum Fourier convolutional network (QFCN) to speed up the convolutional layer of deep neural networks. The QFCN is a quantum-classical circuit based on a parametric quantum circuit (PQC), which is able to exploit the quantum-classical circuit to avoid some of the quantum noise and also to take advantage of classical computers that are able to perform rapid iterations for model optimization. We demonstrate the potential of our network on the traffic prediction task with spatiotemporal graph convolutional networks and the image classification task with 2D con",cool!
135,Learning from Multiple Annotators by Incorporating Instance Features.txt,"Learning from multiple annotators aims to induce a high-quality classifier
from training instances, where each of them is associated with a set of
possibly noisy labels provided by multiple annotators under the influence of
their varying abilities and own biases. In modeling the probability transition
process from latent true labels to observed labels, most existing methods adopt
class-level confusion matrices of annotators that observed labels do not depend
on the instance features, just determined by the true labels. It may limit the
performance that the classifier can achieve. In this work, we propose the noise
transition matrix, which incorporates the influence of instance features on
annotators' performance based on confusion matrices. Furthermore, we propose a
simple yet effective learning framework, which consists of a classifier module
and a noise transition matrix module in a unified neural network architecture.
Experimental results demonstrate the superiority of our method in comparison
with state-of-the-art methods.","The success of supervised learning applications often relies on largescale welllabeled datasets. Unfortunately, obtaining highquality annotations from experts can be costly in terms of time and money. Alternatively, crowdsourcing provides an inexpensive approach to data labeling by hiring worldwide annotators on public platforms like Amazon Mechanical Turk (AMT). However, crowdsourced labels are usually noisy due to the existence of inexperienced or malicious annotators. Us ing these noisy labels in supervised learning may result in an inaccurate classiÔ¨Åer. A straightforward way to solve this problem is redundant labeling, i.e.,obtaining multiple labels for each instance from multiple annotators. Hence this raises one fundamental problem termed as Learning from Crowds (LFC) [Rodrigues and Pereira, 2018 ]:‚ÄúHow can we learn a good classiÔ¨Åer from a set of possibly noisy labeled data pro vided by multiple annotators?‚Äù To address the above issue, a twostage approach is com monly adopted. First, in answer aggregation stage [Zheng et True label : highway Annotation: streetTrue label: highway Annotation: forest xn tn yn(r)P(r)œâ NR v(r)True label: highway Annotation: coast Figure 1: Top: An example describes various incorrect annotations. The Ô¨Årst randomly Ô¨Çips the true label to one of other classes; the sec ond is that the true label is corrupted to the relevant class according to a Ô¨Åxed probability; the third is that the true label is corrupted to the irrelevant class due to the inÔ¨Çuence of instance features. Bottom: The factor graph of LFC xrepresents the correlation of the instance xn, the true label tn, and crowdsourced labels yn. The annotation depends not only on the true label but also on instance features. al., 2017; Sheng and Zhang, 2019; Jin et al. , 2020 ], the latent true labels are estimated. Then, a classiÔ¨Åer is trained based on the estimated true labels. Alternatively, the onestage ap proach [Raykar et al. , 2009; Tanno et al. , 2019 ]has been shown to be a promising direction that presents a maximum likelihood estimator that jointly learns the classiÔ¨Åer, abilities of multiple annotators, and the latent true labels. Among various research efforts on LFC, the probability transition process from latent true labels to observed crowdsourced la bels is usually modeled with confusion matrices of annota tors, which represents classlevel probability transition. This means that the annotator‚Äôs performance is consistent across different instances within the same class, i.e.,the transition from classjto classlis independent of instance features. However, in the real world, the difÔ¨Åculty of labeling can vary among instances within the same class and the instance fea tures themselves will affect annotators‚Äô performance. Con sider a concrete instantiation of LabelMe dataset [Rodrigues et al. , 2017 ]in Figure 1.(Top), which illustrates various cases of incorrect annotations given the true label ‚Äúhighway‚Äù.arXiv:2106.15146v1  [cs.LG]  29 Jun 2021The Ô¨Årst indicates an inexperienced/malicious annotator who gives a random label ‚Äúcoast‚Äù; the second indicates an annota tor have biased understanding on different classes, preferring to label ‚Äúhighway‚Äù as ‚Äústreet‚Äù, because there is a strong cor relation between those two classes. In both cases, the class level confusion matrix of annotator can be used to character ize their varying abilities and own biases. Nevertheless, the third depicts one instance in class ‚Äúhighway‚Äù contains related visual features of other classes, misleading annotators label it as ‚Äúforest‚Äù, although these two classes are irrelevant. We ar gue that the classlevel confusion matrices cannot completely characterize the performance of multiple annotators across different instances within the same class. This would limit the ability to estimate latent true labels, resulting in suboptimal performance of the classiÔ¨Åer. It is necessary to consider the inÔ¨Çuence of instance features in the process of characterizing performance of multiple annotators for LFC. To address the aforementioned deÔ¨Åciency, this work aims at proposing a novel LFC framework, LFC x, which can learn a classiÔ¨Åer directly from crowdsourced labels provided by multiple annotators. In particular, beyond confusion matrices, LFCxmodels the probability transition process with noise transition matrices by combining the confusion matrices and instance features. To this end, we need to deal with two prac tical challenges. One is how to quantify the inÔ¨Çuence of in stance features on the performance of annotators in order to construct the noise transition matrix, the other is how to incor porate the noise transition matrix into LFC method. To cope with these challenges, Ô¨Årst, we model the correlation among instance features, latent true labels and crowdsourced labels in the probabilistic graphical model to construct the noise transition matrix. Furthermore, the LFC xconsists of two modules: the noise transition matrix module and the classiÔ¨Åer module. These two modules are integrated into an endtoend neural network system through a principled combination for maximizing a likelihood function. The graphical model of the LFCxis presented in Figure 1.(bottom). 2 Related Work","The success of supervised learning applications often relies on large-scale well-labeled datasets. However, obtaining high-quality annotations from experts can be costly in terms of time and money. Alternatively, crowdsourcing provides an inexpensive approach to data labeling by hiring worldwide annotators on public platforms like Amazon Mechanical Turk (AMT). However, using these noisy labels in supervised learning may result in an inaccurate classifier. To address this issue, a two-stage approach has been proposed. First, in answer aggregation stage, the latent true labels are estimated. Then,",cool!
0,Regularization in network optimization via trimmed stochastic gradient descent with noisy label.txt,"Regularization is essential for avoiding over-fitting to training data in
network optimization, leading to better generalization of the trained networks.
The label noise provides a strong implicit regularization by replacing the
target ground truth labels of training examples by uniform random labels.
However, it can cause undesirable misleading gradients due to the large loss
associated with incorrect labels. We propose a first-order optimization method
(Label-Noised Trim-SGD) that uses the label noise with the example trimming in
order to remove the outliers based on the loss. The proposed algorithm is
simple yet enables us to impose a large label-noise and obtain a better
regularization effect than the original methods. The quantitative analysis is
performed by comparing the behavior of the label noise, the example trimming,
and the proposed algorithm. We also present empirical results that demonstrate
the effectiveness of our algorithm using the major benchmarks and the
fundamental networks, where our method has successfully outperformed the
state-of-the-art optimization methods.","The neural networks learning is a large scale problem that is characterized by large size dataset with large model. The neural network model con sists of a number of ‚àóCorresponding author: ByungWoo Hong Preprint submitted to Journal of Neurocomputing May 4, 2022layers that is known to approximate linear and nonlinear fu nctions. Due to its high degree of freedom, however, the network network model is alw ays at the risk of over Ô¨Åtting to the training examples that degenerates the genera lization, or the estimation performance for unknown data Thus, regularization is requi red in the training process of the neural networks for better generalization. The neural network model is trained using the stochastic gra dient descent (SGD) and its variants in combination with explicit and implicit r egularization methods. The explicit regularization restricts the model parameters wi th a prior knowledge, e.g., weightdecay adds the regularization term into the object f unction, assuming the model parameters should follow a L2ball. Dropout may assume that the model is an ensem ble of sparse networks. In contrast, the implicit methods of fer regularization effect independent to the model structure. SGD is actually an impli cit regularization that updates the model using a subset of the training examples in a n iterative manner that imposes the stochastic noise into the optimization process . Early stopping is also an implicit regularization. The label noise [1, 2] is an implic it method that replaces the target label of randomlyselected examples by random unifo rm labels. The label noise is simple and computationally efÔ¨Åcient, yet it provides a st rong regularization effect [2] in the classiÔ¨Åcation problems. However, we Ô¨Ånd that the labe l noise also cause outliers with high loss values that can degenerate the model training . We propose a Ô¨Årstorder optimization algorithm, called Lab elNoised TrimSGD, that intendedly uses the label noise with the example trimmi ng in order to obtain an implicit regularization effect. Our algorithm imposes the label noise and then removes data with low and high loss values using an exampletrimming in order to remove outlier examples. This enables us to apply a large amount of l abel noise than the naive labelnoise method, resulting in an improvement of ge neralization of the network model. Different with the data trimming algorithms, we inte ntionally use the label noise in order to improve generalization of model. We relate our method to prior works in Section 2 and present th e naive algorithms of the label noise and the example trimming in Section 3, foll owed by our proposed algorithm in Section 4. The effectiveness of our algorithm i s demonstrated by experi mental results in Section 5 and we conclude in Section 6. 22. Related works","The neural network model is trained using the stochastic gradient descent (SGD) and its variants in combination with explicit and implicit regularization methods. The explicit regularization restricts the model parameters with a prior knowledge, e.g., weightdecay adds the regularization term into the object function. The implicit regularization updates the model using a subset of the training examples in an iterative manner that imposes the stochastic noise into the optimization process. The label noise is an implicit regularization that replaces the target label of randomly selected examples by random unifo",cool!
411,Unsupervised Domain Adaptation in Person re-ID via k-Reciprocal Clustering and Large-Scale Heterogeneous Environment Synthesis.txt,"An ongoing major challenge in computer vision is the task of person
re-identification, where the goal is to match individuals across different,
non-overlapping camera views. While recent success has been achieved via
supervised learning using deep neural networks, such methods have limited
widespread adoption due to the need for large-scale, customized data
annotation. As such, there has been a recent focus on unsupervised learning
approaches to mitigate the data annotation issue; however, current approaches
in literature have limited performance compared to supervised learning
approaches as well as limited applicability for adoption in new environments.
In this paper, we address the aforementioned challenges faced in person
re-identification for real-world, practical scenarios by introducing a novel,
unsupervised domain adaptation approach for person re-identification. This is
accomplished through the introduction of: i) k-reciprocal tracklet Clustering
for Unsupervised Domain Adaptation (ktCUDA) (for pseudo-label generation on
target domain), and ii) Synthesized Heterogeneous RE-id Domain (SHRED) composed
of large-scale heterogeneous independent source environments (for improving
robustness and adaptability to a wide diversity of target environments).
Experimental results across four different image and video benchmark datasets
show that the proposed ktCUDA and SHRED approach achieves an average
improvement of +5.7 mAP in re-identification performance when compared to
existing state-of-the-art methods, as well as demonstrate better adaptability
to different types of environments.","Person reidentiÔ¨Åcation (reID) attempts to match an individual from one camera view across other, non overlapping camera views [15]. The most successful meth ods [45, 50, 21] leverage deep learning via a supervised learning approach. Such supervised learning driven ap Figure 1. Iterative adaptation to unlabelled target domain using the proposed ktCUDA approach. Result on test set after each iteration of adaptation on the unlabelled training set. Starting with direct knowledge transfer from the proposed SHRED source domain on the Ô¨Årst row. Query on the left and the top5 search result with green for correct match and blue for incorrect match. Image from Market1501 [52] (left) and DukeMTMCreID [16] (right). proaches assume the availability of a large, manually labelled dataset of individuals across multiple cameras in the deployment environment (referred as the target domain). This assumption inherently limits the widespread adoption of person reID because of the cost and logistics needed for manually annotating data from the target domain, which is not practical in many realworld scenarios. To overcome the reliance on a large, manuallylabelled dataset from the target domain, two approaches have been proposed in recent literature: a pure unsupervised ap proach [27], and the more popular unsupervised domain adaptation approach [2, 61, 11, 31, 49]. Both approaches rely on an unlabelled dataset from the target domain which is easily obtained by running tracking on the target domain. Furthermore, the unsupervised domain adaptation approach assumes the availability of a manuallylabelled dataset from an independent source domain [11, 31, 49], whereas the pure unsupervised approach does not require a manually labelled source domain dataset. Without an independent source domain, the pure unsu pervised approaches cannot function at all in a new target domain until they have learned the new environment. FromarXiv:2001.04928v1  [cs.CV]  14 Jan 2020a practical point of view, this is undesirable as the system is not able to function at all upon deployment. The unsuper vised domain adaption methods on the other hand are pre trained on an independent source domain and can function upon deployment by directly transferring models learned on the source domain (we refer to this as direct transfer). Start ing from the direct transfer results, the system simply gets better as it adapts to the target domain (Fig. 1). The abil ity for immediate usage upon deployment makes such an unsupervised domain transfer approach very attractive from a practical point of view, but only if direct transfer perfor mance is good and unsupervised domain adaptation can fur ther improve the performance of the system. There are two key limitations to existing unsupervised domain adaptation approaches [2, 61, 11, 31, 49]. The Ô¨Årst limitation is that the domain adaptation component of ex isting approaches either: i) only considers environmental style transfer between source and target domains [2, 61] and do not explicitly learn suitable features and distance metric for the target domain, or ii) directly transfer distance metric (typically Euclidean distance) [11, 31, 49] learned on the source domain to target domain for obtaining pseudolabels on the target domain. Pseudolabels are then used to learn suitable features and distance metric on the target domain. However, direct transfer of distance metric is not optimal due to differences in the source domain environment and target domain environment. The second limitation of existing unsupervised domain adaptation approaches is that they rely heavily on a limited realworld source domain. Typically, a single independent environment is used as a source domain [27, 42, 38, 13, 60] which doesn‚Äôt capture enough variations in environments needed for domain adaptation. Some methods have at tempted to augment the source domain with thousands of synthetic data with varying illuminations [2], but other en vironmental variations outside of illumination are not cap tured. Finally, there are few works [49, 2, 34] that com bine few different datasets in the source domain to obtain some variability. However, their performance before and after adaptation is generally noticeably lower as compared to the latest unsupervised person reID techniques [27]. In this work, we address the two aforementioned limita tions of the current domain adaptation methods. First, we explore how to better leverage distance metrics that have been learned on the source domain to the target domain. Recently, kreciprocal reranking [58] has become a pop ular postprocessing step for all supervised reID methods, where the kreciprocal nearest neighbours are ranked higher than neighbours that minimize a distance metric and result in better performance. It was shown in [58] to boost per formance by10% on the mean average precision (mAP). Motivated by the effectiveness of such an approach within the realm of supervised reID, we propose a kreciprocaltracklet Clustering method for Unsupervised Domain Adap tation (ktCUDA), where kreciprocal neighbours are used to assign pseudolabels to the target domain. Second, we investigate the construction of a source do main that captures large environmental variations i.e., large number of identities and environmental conditions to ensure the best results for direct transfer of source domain to tar get domain. To this end, we constructed the Synthesized Heterogeneous REid Domain (SHRED), the largest source domain used in domain adaptation person reID literature. We show that the proposed SHRED performs very well for the direct transfer scenario. When combined with the pro posed ktCUDA, we show that stateoftheart performance can be achieved for unsupervised domain transfer on several test datasets. The main contributions of this paper are: ktCUDA , a novel kreciprocal tracklet clustering algo rithm for obtaining unsupervised pseudolabels on the target domain. SHRED , a synthesized largescale heterogeneous source domain that captures a wide set of environmen tal variations. A comprehensive analysis using both image and video datasets to show the performance of the proposed ktCUDA and SHRED, with full experimental results for direct transfer of knowledge from source domain to target domain as well as experimental results after domain adaptation. 2. Related Works","Person reidentification (reID) is a popular deep learning-based task that attempts to match an individual from one camera view across other, non-overlapping camera views. Most supervised reID methods leverage deep learning via a supervised learning approach. However, this approach requires a large, manually labelled dataset from the target domain, which is not practical in many real-world scenarios. To overcome this limitation, two approaches have been proposed in recent literature: a pure unsupervised approach and the more popular unsupervised domain adaptation approach. In this paper, we explore how to leverage distance metrics that have",cool!
59,Learning Noise-Aware Encoder-Decoder from Noisy Labels by Alternating Back-Propagation for Saliency Detection.txt,"In this paper, we propose a noise-aware encoder-decoder framework to
disentangle a clean saliency predictor from noisy training examples, where the
noisy labels are generated by unsupervised handcrafted feature-based methods.
The proposed model consists of two sub-models parameterized by neural networks:
(1) a saliency predictor that maps input images to clean saliency maps, and (2)
a noise generator, which is a latent variable model that produces noises from
Gaussian latent vectors. The whole model that represents noisy labels is a sum
of the two sub-models. The goal of training the model is to estimate the
parameters of both sub-models, and simultaneously infer the corresponding
latent vector of each noisy label. We propose to train the model by using an
alternating back-propagation (ABP) algorithm, which alternates the following
two steps: (1) learning back-propagation for estimating the parameters of two
sub-models by gradient ascent, and (2) inferential back-propagation for
inferring the latent vectors of training noisy examples by Langevin Dynamics.
To prevent the network from converging to trivial solutions, we utilize an
edge-aware smoothness loss to regularize hidden saliency maps to have similar
structures as their corresponding images. Experimental results on several
benchmark datasets indicate the effectiveness of the proposed model.","Visual saliency detection aims to locate salient regions that attract human atten tion. Conventional saliency detection methods [59,46] rely on human designed features to compute saliency for each pixel or superpixel. The deep learning revolution makes it possible to train endtoend deep saliency detection models in a datadriven manner [19,54,41,55,40,7,25,30,38,21,35,34,33,51], outperform ing handcrafted featurebased solutions by a wide margin. However, the success ?Work was done while Jing Zhang was an intern mentored by Jianwen Xie.arXiv:2007.12211v1  [cs.CV]  23 Jul 20202 Jing Zhang, Jianwen Xie, and Nick Barnes Fig. 1. An illustration of our framework. Representation: Each noisy label Yis rep resented as a sum of a clean saliency Sand a noise map . The clean saliency S is predicted from an image Xby an encoderdecoder network f1, and the noise is produced from a Gaussian noise vector Zby a generator network f2. Training: given the observed image Xand the corresponding noisy label Y, (i) the latent vector Z is inferred by MCMC and (ii) the parameters f1;2gof the encoderdecoder f1and the generator f2are updated by the gradient ascent for maximum likelihood. Testing: once the model is learned, the disentangled salicey predictor f1is the desired model for salicey prediction. of deep models mainly depends on a large amount of accurate human labeling [31,3,15], which is typically expensive and timeconsuming. To relieve the burden of pixelwise labeling, weakly supervised [17,31,52] and unsupervised saliency detection models [53,50,24] have been proposed. The for mer direction focuses on learning saliency from cheap but clean annotations, while the latter one studies learning saliency from noisy labels, which are typi cally obtained by conventional handcrafted featurebased methods. In this paper, we follow the second direction and propose a deep latent variable model that we call the noiseaware encoderdecoder to disentangle a clean saliency predictor from noisy labels. In general, a noisy label can be (1) a coarse saliency label generated by algorithmic pipelines using handcrafted features, (2) an imper fect humanannotated saliency label, or even (3) a clean label, which actually is a special case of noisy label, in which noise is none. Aiming at unsupervised saliency prediction, our paper assumes noisy labels to be produced by unsu pervised handcrafted featurebased saliency methods, and places emphasis on disentangled representation of noisy labels by the noiseaware encoderdecoder. Given a noisy dataset D=f(Xi;Yi)gn i=1ofnexamples, where XandY are image and its corresponding noisy saliency label, we intend to disentangle noiseand clean saliency Sfrom each noisy label Y, and learn a clean saliency predictorf1:X!S. To achieve this, we propose a conditional latent variable model, which is a disentangled representation of noisy saliency Y. See Figure 1NoiseAware EncoderDecoder for Saliency Detection 3 for an illustration of the proposed model. In the context of the model, each noisy label is assumed to be generated by adding a specic noise or perturbation  to its clean saliency map Sthat is dependent on its image X. Specically, the model consists of two submodels: (1) saliency predictor f1: an encoderdecoder network that maps an input image Xto a latent clean saliency map S, and (2) noise generator f2: a topdown neural network that produces a noise or error  from a lowdimensional Gaussian latent vector Z. As a latent variable model, the rigorous maximum likelihood learning (MLE) typically requires to compute an intractable posterior distribution, which is an inference step. To learn the latent variable model, two algorithms can be adopted: variational autoencoder (VAE) [13] or alternating backpropagation (ABP) [9,44,60]. VAE approximates MLE by minimizing the evidence lower bound with a separate inference model to approximate the true posterior, while ABP directly targets MLE and computes the posterior via Markov chain Monte Carlo (MCMC). In this paper, we generalize the ABP algorithm to learn the proposed model, which alternates the following two steps: (1) learning back propagation for estimating the parameters of two submodels, and (2) inferential backpropagation for inferring the latent vectors of training examples. As there may exist innite combinations of Sandsuch thatS+perfectly matches the provided noisy label Y, we further adopt the edgeaware smoothness loss [37] to serve as a regularization to force each latent saliency map Sto have a similar structure as its input image X. The learned disentangled saliency predictor f1 is the desired model for testing. Our solution is dierent from existing weak or noisy labelbased saliency approaches [53,50,24,18] in the following aspects: Firstly, unlike [53], we don't assume the saliency noise distribution is a Gaussian distribution. Our noise gen erator parameterized by a neural network is  exible enough to approximate any forms of structural noises. Secondly, we design a trainable noise generator to ex plicitly represent each noise as a nonlinear transformation of lowdimensional Gaussian noise Z, which is a latent variable that need to be inferred during training, while [53,50,24,18] have no noise inference process. Thirdly, we have no constraints on the number of noisy labels generated from each image, while [53,50,24] require multiple noisy labels per image for noise modeling or pseudo la bel generation. Lastly, our edgeaware smoothness loss serves as a regularization to force the produced latent saliency maps to be well aligned with their input images, which is dierent from [18], where object edges are used to produce pseudo saliency labels via multiscale combinatorial grouping (MCG) [1]. Our main contributions can be summarized as follows: {We propose to learn a clean saliency predictor from noisy labels by a novel latent variable model that we call noiseaware encoderdecoder, in which each noisy label is represented as a sum of the clean saliency generated from the input image and a noise map generated from a latent vector. {We propose to train the proposed model by an alternating backpropagation (ABP) algorithm, which rigorously and eciently maximizes the data like lihood without recruiting any other auxiliary model.4 Jing Zhang, Jianwen Xie, and Nick Barnes {We propose to use an edgeaware smoothness loss as a regularization to prevent the model from converging to a trivial solution. {Experimental results on various benchmark datasets show the stateofthe art performances of our framework in the task of unsupervised saliency de tection, and also comparable performances with the existing fullysupervised saliency detection methods. 2 Related Work","Deep learning has made it possible to train end-to-end deep saliency detection models in a data-driven manner. However, the success of these models is limited by the large amount of accurate human labeling. In this paper, we propose a deep latent variable model that we call the noiseaware encoderdecoder to disentangle a clean saliency predictor from noisy labels. In general, a noisy label can be (1) a coarse saliency label generated by algorithmic pipelines using handcrafted features, (2) an imperfect human-annotated sali",cool!
318,Distributed learning of deep neural network over multiple agents.txt,"In domains such as health care and finance, shortage of labeled data and
computational resources is a critical issue while developing machine learning
algorithms. To address the issue of labeled data scarcity in training and
deployment of neural network-based systems, we propose a new technique to train
deep neural networks over several data sources. Our method allows for deep
neural networks to be trained using data from multiple entities in a
distributed fashion. We evaluate our algorithm on existing datasets and show
that it obtains performance which is similar to a regular neural network
trained on a single machine. We further extend it to incorporate
semi-supervised learning when training with few labeled samples, and analyze
any security concerns that may arise. Our algorithm paves the way for
distributed training of deep neural networks in data sensitive applications
when raw data may not be shared directly.","Deep neural networks have become the new state of the art in classication and prediction of high dimensional data such as images, videos and biosensors. Emerging technologies in domains such as biomedicine and health stand to benet from building deep neural networks for prediction and inference by automating the human involvement and reducing the cost of operation. However, training of deep neural nets can be extremely data intensive requiring preparation of large scale datasets collected from multiple entities [1, 2]. A deep neural network typically contains millions of parameters and requires tremendous computing power for training, making it dicult for individual data repositories to train them. Corresponding author Email address: otkrist@mit.edu (Otkrist Gupta) Preprint submitted to Journal of L ATEX Templates October 16, 2018arXiv:1810.06060v1  [cs.LG]  14 Oct 2018Suciently deep neural architectures needing large supercomputing resources and engineering oversight may be required for optimal accuracy in real world applications. Furthermore, application of deep learning to such domains can sometimes be challenging because of privacy and ethical issues associated with sharing of deanonymized data. While a lot of such data entities have vested interest in developing new deep learning algorithms, they might also be obligated to keep their user data private, making it even more challenging to use this data while building machine learning pipelines. In this paper, we attempt to solve these problems by proposing methods that enable training of neural networks using multiple data sources and a single supercomputing resource. 2. Related Work","Deep neural networks have become the new state of the art in classi cation and prediction of high dimensional data such as images, videos and biosensors. However, training of deep neural networks can be extremely data intensive requiring preparation of large scale datasets collected from multiple entities. Furthermore, deep neural networks require large supercomputing resources and engineering oversight for optimal accuracy in real world applications. In this paper, we propose methods that enable training of neural networks using multiple data sources and a single supercomputing resource. We propose a method that enables training of neural networks using multiple data sources and",cool!
554,Meta-Learning via Feature-Label Memory Network.txt,"Deep learning typically requires training a very capable architecture using
large datasets. However, many important learning problems demand an ability to
draw valid inferences from small size datasets, and such problems pose a
particular challenge for deep learning. In this regard, various researches on
""meta-learning"" are being actively conducted. Recent work has suggested a
Memory Augmented Neural Network (MANN) for meta-learning. MANN is an
implementation of a Neural Turing Machine (NTM) with the ability to rapidly
assimilate new data in its memory, and use this data to make accurate
predictions. In models such as MANN, the input data samples and their
appropriate labels from previous step are bound together in the same memory
locations. This often leads to memory interference when performing a task as
these models have to retrieve a feature of an input from a certain memory
location and read only the label information bound to that location. In this
paper, we tried to address this issue by presenting a more robust MANN. We
revisited the idea of meta-learning and proposed a new memory augmented neural
network by explicitly splitting the external memory into feature and label
memories. The feature memory is used to store the features of input data
samples and the label memory stores their labels. Hence, when predicting the
label of a given input, our model uses its feature memory unit as a reference
to extract the stored feature of the input, and based on that feature, it
retrieves the label information of the input from the label memory unit. In
order for the network to function in this framework, a new memory-writingmodule
to encode label information into the label memory in accordance with the
meta-learning task structure is designed. Here, we demonstrate that our model
outperforms MANN by a large margin in supervised one-shot classification tasks
using Omniglot and MNIST datasets.","Deep learning is heavily dependent on big data. Traditional gradient based neural networks require extensive and itera tive training using large datasets. In these models, training occurs through a continuous update of weight parameters in order to optimize the loss function during training. However, when there is only a little data to learn from, deep learning is prone to poor performance because traditional networks will not acquire enough knowledge about the speciÔ¨Åc taskvia weight updates, and hence, they fail to make accurate predictions when tested. Previous works have approached the task of learning from few samples using different methods such as prob abilistic models based on Bayesian learning (FeiFei, Fer gus, and Perona 2006), generative models using probability density functions (Lake et al. 2011; Rezende et al. 2016), Siamese neural networks (Koch 2015), and metalearning based memory augmented models (Santoro et al. 2016; Vinyals et al. 2016). In this work, we revisited the problem of metalearning using memory augmented neural networks. Metalearning is a twotiered learning framework in which an agent learns not only about the speciÔ¨Åc task, for instance, image clas siÔ¨Åcation, but also about how the task structure varies across target domains (Christophe, Ricardo, and Pavel 2004; Santoro et al. 2016). Neural architectures with an external memory such as Neural Turing Machines (NTMs) (Graves, Wayne, and Danihelka 2014) and memory networks (We ston, Chopra, and Bordes 2014) have shown the ability of metalearning. Recent memory augmented neural networks for meta learning such as MANN (Santoro et al. 2016) use a plain memory matrix as an external memory. In these models, in put data samples and their labels are bound together in the same memory locations.In models such as the MANN, the input data samples and their appropriate labels from previ ous step are bound together in the same memory locations. This often leads to memory interference when performing a task as they have to retrieve a feature of an input from a certain memory location and read only the label information bound to that location. Our primary contribution in this work is designing a different version of NTM (Graves, Wayne, and Danihelka 2014) by splitting the external memory into feature and label memories to avoid any catastrophic interference. The fea ture memory is used to store input data features and the la bel memory is used to encode the label information of the inputs. Therefore, during testing, ideal performance in our model requires using the feature memory as a reference to accurately retrieve the stored feature of an input image and effectively reading the corresponding label information from the label memory. In order to accomplish this, we designed a new memory writing module based on the metalearningarXiv:1710.07110v1  [cs.LG]  19 Oct 2017  Shuffle:   Labels   Classes   Samples    ... ...  (x1,0) (x2,y1) (xt,yt1) (ùë•2,ùë¶1)   (ùë•1,0)   (ùë•ùë°,ùë¶ùë°‚àí1)   (ùë•ùë°+1,ùë¶ùë°)   Class Prediction    (a) Task setup                    ...  ùë•ùë°:  ùë¶ùë°‚àí1: 4 ùë•ùë°+1:  ùë¶ùë°: 2  ùë•ùë°+2:  ùë¶ùë°+1: 3  2       3  ùë•ùë°+ùëõ:  ùë¶ùë°+ùëõ‚àí1: 5    2  3 2 Feature   Memory    Label   Memory    Feature   Memory    Label   Memory     Backpropagation    2  2  (b) Encoding and Retrieving Figure 1: Metalearning task structure. (a) Omniglot images , xt, are presented along with labels in a temporally offset manner. At time step t, the network sees an input image xtwith a label yt","Metalearning is a two-tiered learning framework in which an agent learns not only about the specific task, for instance, image classification, but also about how the task structure varies across target domains. In memory augmented neural networks, the input data samples and their labels are bound together in the same memory locations. This often leads to memory interference when performing a task as they have to retrieve a feature of an input from a certain memory location and read only the label information bound to that location. In this work, we design a new memory writing module based on the metalearning architecture.",cool!
349,Multi-Representational Learning for Offline Signature Verification using Multi-Loss Snapshot Ensemble of CNNs.txt,"Offline Signature Verification (OSV) is a challenging pattern recognition
task, especially in presence of skilled forgeries that are not available during
training. This study aims to tackle its challenges and meet the substantial
need for generalization for OSV by examining different loss functions for
Convolutional Neural Network (CNN). We adopt our new approach to OSV by asking
two questions: 1. which classification loss provides more generalization for
feature learning in OSV? , and 2. How integration of different losses into a
unified multi-loss function lead to an improved learning framework? These
questions are studied based on analysis of three loss functions, including
cross entropy, Cauchy-Schwarz divergence, and hinge loss. According to
complementary features of these losses, we combine them into a dynamic
multi-loss function and propose a novel ensemble framework for simultaneous use
of them in CNN. Our proposed Multi-Loss Snapshot Ensemble (MLSE) consists of
several sequential trials. In each trial, a dominant loss function is selected
from the multi-loss set, and the remaining losses act as a regularizer.
Different trials learn diverse representations for each input based on
signature identification task. This multi-representation set is then employed
for the verification task. An ensemble of SVMs is trained on these
representations, and their decisions are finally combined according to the
selection of most generalizable SVM for each user. We conducted two sets of
experiments based on two different protocols of OSV, i.e., writer-dependent and
writer-independent on three signature datasets: GPDS-Synthetic, MCYT, and
UT-SIG. Based on the writer-dependent OSV protocol, we achieved substantial
improvements over the best EERs in the literature. The results of the second
set of experiments also confirmed the robustness to the arrival of new users
enrolled in the OSV system.","Despite impressive advances in computer vision and pattern recognition, several classic  problems such as  Offline Signature Verification (OSV) remains challenging (Hafemann, Sabourin, & Oliveira, 2017b; E. Zois,  Tsourounis, Theodorakopoulos, Kesidis, & Economou, 2019) . The OSV system aims to distinguish whether  a given signature image is produced by the claimed author (genuine) or by an impostor (forgery). There are  three types of forgeries, including random, simple and skilled  forgeries. Random forgeries refer to the ca ses  when forger signs without information about the user. In the case of simple forgeries, forger knows the  user‚Äôs name while the user‚Äôs signature is not available. In the worst case, forger  has ac cess to  both the  user‚Äôs name and his signature and carefull y attempts to forge the signature. In this case, skilled forgeries  show high similarity with the user‚Äôs signature, and thus are harder to verify. The problem of OSV becomes  challenging in the presence of skilled forgeries. This challenge is further aggrava ted in the real scenario of OSV when a few genuine signatures and no skilled forgeries are available for training (Hafemann et al.,  2017b) .  Recently, howe ver, automatic feature learning by deep Convolutional Neural Networks (CNNs) has shown  its potential to tackle the challenges of OSV (Dey et al., 2017; Hafemann, Sabourin, & Oliveira, 2017a) . Due  to the small  training size, the power  of Deep CNNs may not be effectively leveraged  in the problem of OSV  unless seriously considering regularization . Choosing a suitable loss function is one of most  effective  learning parameters in the generalization  of CNNs  (Janocha & Czarnecki, 2017) . Substantial need for the  generalization in OSV lead researchers to examine different loss functions for CNNs to find which one  promotes more generalization.   Two main categories of loss functions were studied  for OSV, including metric learning losses and  classification (identification) losses. In the first category, several studies  (Berkay Yilmaz & Ozturk, 2018; Dey  et al., 2017; Rantzsch, Yang, & Meinel, 2016; Soleimani, Araabi, & Fouladi, 2016; Xing, Yin, Wu, & L iu, 2018)   suggested several metric learning losses for feature learning in CNNs and a threshold based verification  was then used to classify whether an input signature is genuine or forgery. While the second category  includes the studies (Hafemann, Sabourin, & Oliveira, 2016b; Hafemann et al., 2017b; Souza, Oliveira, &  Sabourin, 2018)  employing classification loss function for feature learning in CNNs and verificati on is then  performed using SVM as a binary classifier.  These two categories competed to achieve better accuracy,  while the works in the second category mostly obtained more accuracy compared to the first one.   In addition to OSV, these two categories of loss functions were also studied  for different classification tasks,  and the similar comparative results were reported  (Horiguchi, Ikami, & Aizawa, 2016; Janocha & Czarnecki,  2017) . The work (Horiguchi et al., 2016)  confirmed this result by performing a fair comparison  between  Cross Entropy  (CE) loss as a classification loss and several state oftheart metric learning losses.  Furthermore, another study (Janocha & Czarnecki, 2017)  obtained similar  results, however, proposed that  other classification losses rather than CE also have their merits. Due to the superiority  of classification  losses, we follow the approach of the second  category in this research. In OSV literature, a few studies  employed CE loss function for feature learning in CNNs. However, as the best of our knowledge, an  interesting question on ‚Äú which classification loss leads to m ore generalization in OSV? ‚Äù has not been yet  studied in OSV.   From another point  of view, different loss functions have complementary advantages and limitations  (Janocha & Czarnecki, 2017; C. Xu et al., 2016) . Ensemble learning (Masoudnia & Ebrahimpour, 2012)  can  provid e a framework for combining the  advantages of different loss functions. Moreover, the ensemble   framework brings more diversity and regularization  and thus more generalization  for OSV(Berkay Yilmaz &  Ozturk, 2018; Yƒ±lmaz & Yanƒ±koƒülu, 2016) . However, why  diversity in terms of  different loss functions in the  ensemble can also improve  the OSV?   The OSV can benefit from employing different loss functions by which diverse feature sets are learn ed from  signature images. Thanks to these diverse repre sentations , the discrimination  power of the OSV  can be  improved. This is because features that discriminate between genuine  signature s of a user and his/her skilled forgeries are different from  the features required to discriminate genuine  and skilled forgeries  of  another user.   The diverse representations learn ed by different classification losses also provide another advantage for  the OSV. The methods in the second category employ a CNN trained with a classification loss on the  signature identification task. H owever, the learn ed representation is then used  for signature  verification.  In the signature application, the identification is simpler  than the verification, while the learn ed features  should be transferred  to the harder  task. These learned features do no t necessarily include fine features  required for the verification of genuine vs. skilled forgery signatures. Using diverse multi representation  set learned by different loss functions may address this issue since it extends the feature set for the  verifica tion. Moreover, the learn ed diverse feature sets may capture infrequent features (Xie, Deng, & Xing,  2015) .  The need for diversity and regularization in the OSV lead us to ensemble approaches. However, the  ensemble o f CNNs in which each network is independently trained  on a different loss function brings heavy   computational burden. We attempt to address this limitation using a multi loss function which eliminate s  the need for learning each of loss functions from scrat ch.   In this study, we aim to fill the gap in the literature by examining different loss functions and proposing a  novel framework for using a dynamic multi loss function in CNNs. We adopt  a new approach to the OSV  problem by asking two questions: 1. which classification loss function provides more generalization for  feature learning in OSV? , and  2. How  may an integration of different loss functions into a dynamic multi  loss function  lead to an improved learning framework?   These questions are studied in the remaining of this paper as follows: The related works on the literature   of OSV are reviewed  in the following section. Our approach to the first question is presented  in section 3.  Section 4 and 5 explains our proposed mul tiloss ensemble approach for feature learning and the  verification method in OSV, respectively. The experimental results are provided  in section 6. We finally  conclude the results and propose future research directions in the last section.      2. Related Works","Offline Signature Verification (OSV) is a challenging problem in computer vision and pattern recognition. Despite impressive advances in computer vision and pattern recognition, several classic problems such as OSV remain challenging. In this paper, we study the generalization of Convolutional Neural Networks (CNNs) for Offline Signature Verification (OSV) using Cross Entropy (CE) loss function for feature learning in CNNs. In the first category, we studied several metric learning losses for feature learning in CNNs and a threshold-based verification was used to classifying whether an input signature is genuine",cool!
224,Interpretable and Accurate Fine-grained Recognition via Region Grouping.txt,"We present an interpretable deep model for fine-grained visual recognition.
At the core of our method lies the integration of region-based part discovery
and attribution within a deep neural network. Our model is trained using
image-level object labels, and provides an interpretation of its results via
the segmentation of object parts and the identification of their contributions
towards classification. To facilitate the learning of object parts without
direct supervision, we explore a simple prior of the occurrence of object
parts. We demonstrate that this prior, when combined with our region-based part
discovery and attribution, leads to an interpretable model that remains highly
accurate. Our model is evaluated on major fine-grained recognition datasets,
including CUB-200, CelebA and iNaturalist. Our results compare favorably to
state-of-the-art methods on classification tasks, and our method outperforms
previous approaches on the localization of object parts.","Deep models are tremendously successful for visual recognition, yet their results are oftentimes hard to explain. Consider the examples in Fig. 1. Why does a deep model recognize the bird as ‚ÄúYellowheaded Blackbird‚Äù or con sider the person ‚ÄúSmiling‚Äù? While the interpretation of a model can happen at multiple facets, we believe that at least one way of explaining the model is to segment meaningful regions of object parts (e.g., the eyes, mouth, cheek, fore head and neck of a face), and further identify their contri butions towards the decision (e.g., the mouth region is more discriminative for smiling). How can we design an inter pretable deep model that learns to discover object parts and estimates their importance for visual recognition? It turns out that part discovery, i.e., learning object parts without explicit supervision of part annotations, is by itself Input ImagePart Assignment MapPart Attention MapYellowheaded Blackbird Smiling Figure 1. Why does a deep model recognize the bird as ‚ÄúYellow headed Blackbird‚Äù or consider the person ‚ÄúSmiling‚Äù ? We present an interpretable deep model for Ô¨Ånegrained recognition. Given an input image (left), our model is able to segment object parts (middle) and identify their contributions (right) for the decision. Results are from our model trained using only imagelevel labels . a challenging problem. As a baby step, we focus on the task of Ô¨Ånegrained recognition, where the parts belonging to the same super category share common visual patterns. For ex ample, most tails of birds have a similar shape. Our key observation is that features from a convolutional network can be used to group pixels into a set of visually coherent regions [28, 25], from which a subset of discriminative seg ments can be selected for recognition [33, 32, 11]. With only object labels as the guidance , we hope that the group ing will help to Ô¨Ånd visually distinct parts, and the selection process will identify their contributions for classiÔ¨Åcation. A major challenge for our regionbased part discovery is that there is no explicit supervisory signal to deÔ¨Åne part regions. Therefore, prior knowledge about object parts must be incorporated to facilitate the learning. A core innovation of our work is the exploration of a simple prior about object parts: given a single image, the occurrence of a part follows a Ushaped distribution. For example, the head of a bird is likely to occur in most bird images while the legs of a bird might only appear in some images. Surprisingly, we demonstrate that this simple prior, when combined with ourarXiv:2005.10411v1  [cs.CV]  21 May 2020regionbased part discovery, leads to the identiÔ¨Åcation of meaningful object parts. More importantly, the resulting interpretable deep model remains highly accurate. Several recent methods have been developed for discovering parts in Ô¨Ånegrained classiÔ¨Åcation, yet none of them considered the prior we use. To this end, we present our interpretable deep model for Ô¨Ånegrained classiÔ¨Åcation. SpeciÔ¨Åcally, our model learns a dictionary of object parts, based on which a 2D feature map can be grouped into ‚Äúpart‚Äù segments. This is done by com paring pixel features to part representations in a learned dic tionary. Moreover, regionbased features are pooled from the result segments, followed by an attention mechanism to select a subset of segments for classiÔ¨Åcation. Importantly, during training, we enforce a Ushaped prior distribution for the occurrence of each part. This is done by minimiz ing the Earth Mover‚Äôs Distance between our prior and the empirical distribution of part occurrence. During training, our model is only supervised by object labels with our pro posed regularization term. During testing, our model jointly outputs the segments of object parts, the importance of the segmented parts, and the predicted label. The interpretation of our model is thus granted by the part segmentation and the contribution of each part for classiÔ¨Åcation. To evaluate our model, we conduct extensive experi ments using three Ô¨Ånegrained recognition datasets for both interpretability and accuracy. To quantify interpretability, we compare the output region segments from our model to the annotated object parts. For accuracy, we report standard metrics for Ô¨Ånegrained classiÔ¨Åcation. On smaller scale datasets, such as CUB200 [36] and CelebA [56], our model is shown to Ô¨Ånd parts of the birds and faces with low local ization error, while at the same time compares favorably to stateoftheart methods in terms of accuracy. On the more challenging iNaturalist dataset [55], our model improves the accuracy of a strong baseline network (ResNet101) by 5.7% , reduces the object localization error, and demon strates promising qualitative results for part discovery. 2. Related Work","We present an interpretable deep model for fine-grained recognition. Our model learns a dictionary of object parts, based on which a 2D feature map can be grouped into ‚Äúpart‚Äù segments. This is done by comparing pixel features to part representations in a learned dictionary. Moreover, a region-based attention mechanism is used to select a subset of segments for classification. Our model is highly interpretable, as the output segments of the segmented parts are interpreted by the input label. Our model is highly accurate for fine-grained recognition.",cool!
148,Graph convolutional networks for learning with few clean and many noisy labels.txt,"In this work we consider the problem of learning a classifier from noisy
labels when a few clean labeled examples are given. The structure of clean and
noisy data is modeled by a graph per class and Graph Convolutional Networks
(GCN) are used to predict class relevance of noisy examples. For each class,
the GCN is treated as a binary classifier, which learns to discriminate clean
from noisy examples using a weighted binary cross-entropy loss function. The
GCN-inferred ""clean"" probability is then exploited as a relevance measure. Each
noisy example is weighted by its relevance when learning a classifier for the
end task. We evaluate our method on an extended version of a few-shot learning
problem, where the few clean examples of novel classes are supplemented with
additional noisy data. Experimental results show that our GCN-based cleaning
process significantly improves the classification accuracy over not cleaning
the noisy data, as well as standard few-shot classification where only few
clean examples are used.","Stateoftheart deep learning methods require a large amount of manually la beled data. The need for supervision may be reduced by decoupling represen tation learning from the end task and/or using additional training data that is unlabeled, weakly labeled (with noisy labels), or belong to dierent domains or classes. Example approaches are transfer learning [39], unsupervised representa tion learning [39], semisupervised learning [42], learning from noisy labels [16] and fewshot learning [33]. However, for several classes, only very few or even no clean labeled exam ples might be available at the representation learning stage. Fewshot learning severely limits the number of labeled samples on the end task, while the repre sentation is learned on a large training set of dierent classes [12,33,38]. Nev ertheless, in many situations, more data with noisy labels can be acquired or is readily available for the end task. One interesting mix of fewshot learning with additional largescale data is the work of Douze et al. [5], where labels are propagated from few clean labeled examples to a largescale collection. This collection is unlabeled and actuallyarXiv:1910.00324v3  [cs.CV]  24 Aug 20202 A. Iscen et al. 2. Minimize  Lossclean + Œª Lossnoisy  classify as  negatives classify as  positives  1. Adjacency graph  per class  3. Relevance score output  1.00 1.00 0.01 0.92 0.01  Labeled example  Additional data Class relevance prediction  with GCN  Use for  classiÔ¨Åer  training  0.97 0.97 0.90  0.05  0.80 Query by admiral  Fig. 1. Overview of our cleaning approach for 1shot learning with noisy examples. We use the class name admiral to crawl noisy images from the web and create an adjacency graph based on visual similarity. We then assign a relevance score to each noisy example with a graph convolutional network (GCN). Relevance scores are displayed next to the images. contains data for many more classes than the end task. Their method overall improves the classication accuracy, but at an additional computational cost. It is a transductive method, i.e., instead of learning a parametric classier, the largescale collection is still necessary at inference. In this work, we learn a classier from a few clean labeled examples and additional weakly labeled data, while the representation is learned on dier ent classes, similarly to fewshot learning. We assume that the class names are known, and we use them to search an existing large collection of images with textual description. The result is a set of images with novel class labels, but potentially incorrect (noisy). As shown in Figure 1, we clean this data using agraph convolutional network (GCN) [17], which learns to predict a class rele vance score per image based on connections to clean images in the graph. Both the clean and the noisy images are then used to learn a classier, where the noisy examples weighted by relevance. Unlike most existing work, our method operates independently per class and applies when clean labeled examples are few or even only one per class. We make the following contributions: 1. We learn a classier on a largescale weaklylabeled collection jointly with only a few clean labeled examples. 2. To our knowledge, we are the rst to use a GCN to clean noisy data: we cast a GCN as a binary classier which learns to discriminate clean from noisy data, and we use its inferred \clean"" probabilities as a relevance score per example. 3. We apply our method to two fewshot learning benchmarks and show sig nicant improvement in accuracy, outperforming the method by Douze et al. [5] using the same largescale collection of data without labels.Title Suppressed Due to Excessive Length 3 2 Related work","We use the class name admiral to crawl an existing large collection of images with textual description. The result is a set of images with novel class labels, but potentially incorrect (noisy). We clean this data using a graph convolutional network (GCN), which learns to predict a class relevance score per image based on connections to clean images in the graph. The clean and the noisy images are then used to learn a classifier, where the noisy examples weighted by relevance. We show that our method outper classifiers.",cool!
197,Self-supervised Neural Architecture Search.txt,"Neural Architecture Search (NAS) has been used recently to achieve improved
performance in various tasks and most prominently in image classification. Yet,
current search strategies rely on large labeled datasets, which limit their
usage in the case where only a smaller fraction of the data is annotated.
Self-supervised learning has shown great promise in training neural networks
using unlabeled data. In this work, we propose a self-supervised neural
architecture search (SSNAS) that allows finding novel network models without
the need for labeled data. We show that such a search leads to comparable
results to supervised training with a ""fully labeled"" NAS and that it can
improve the performance of self-supervised learning. Moreover, we demonstrate
the advantage of the proposed approach when the number of labels in the search
is relatively small.","Recently there has been an increasing interest in Neural Architecture Search (NAS). NAS algorithms emerge as a powerful platform for discovering superior network architectures, which may save time and effort of humanexperts. The discovered architectures have achieved stateoftheart results in several tasks such as image classiÔ¨Åcation [1, 2] and object detection [3]. The existing body of research on NAS investigated several common search strategies. Reinforcement learning [ 4] and evolutionary algorithms [ 5,6] were proven to be successful but required many computational resources. Various recent methods managed to reduce search time signiÔ¨Åcantly. For example, Liu et al. [ 7] suggested relaxing the search space to be continuous. This allowed them to perform a differentiable architecture search (DARTS), which led to novel network models and required reasonable resources (few days using 14 GPUs). NAS methods learn from labeled data. During the search process, various architectures are considered and their value is estimated based on their performance on annotated examples. However, acquiring large amounts of humanannotated data is expensive and timeconsuming, while unlabeled data is much more accessible. As current NAS techniques depend on annotations availability, their performance deteriorates when the number of annotations per each class becomes small. This remains an open problem for NAS, where research till now has focused on the supervised learning approach. The dependency on labeled data is not unique only to NAS but is a common problem in deep learning. Largescale annotated datasets play a critical role in the remarkable success of many deep neural networks, leading to stateoftheart results in various computer vision tasks. Considering how expensive it is to acquire such datasets, a growing body of research is focused on relieving the need for such extensive annotation effort. One promising lead in this direction is selfsupervised learning (SSL) [ 8,9,10]. Selfsupervised methods learn visual features from unlabeled data. The unlabeled data is used to automatically generate pseudo labels for a pretext task. In the course of training to solve the pretext task, the network learns visual features that can be transferred to solving other tasks with little to no labeled data. Contrastive SSL is a subclass of SSL that has recently gained Preprint. Under review.arXiv:2007.01500v1  [cs.LG]  3 Jul 2020Figure 1: The SSNAS framework. We perform network architecture search in an unsupervised manner (with no data labels) by using a contrastive loss that enforces similarity between two different augmentations of the same input image. Both augmentations pass through the same network (i.e., the weights are shared). attention thanks to its promising results [ 11,12,13,14,15]. This family of techniques contrasts positive samples and negative samples to learn visual representations. Contribution. Inspired by the success of SSL for learning good visual representations, we propose to apply selfsupervision in NAS to rectify its limitation with respect to the availability of data annotations. We propose a SelfSupervised Neural Architecture Search (SSNAS), which unlike conventional NAS techniques, can Ô¨Ånd novel architectures without relying on data annotations. Instead of using selfsupervision to learn visual representations, we employ it to learn the architecture of deep networks (see Figure 1). We apply our new strategy with the popular DARTS [ 7] method. We adopt their differentiable search, which allows using gradientbased optimization, but replace their supervised learning objective with a contrastive loss that requires no labels to guide the search. In particular, we adopt the method used in the SimCLR framework [ 11]. This approach for learning visual representations has recently achieved impressive performance in image classiÔ¨Åcation. We adapt their approach to the architecture search process. We perform a composition of transformations on the inputs, which generates augmented images and look for the model that maximizes the similarity between the representations of the augmented images that originate from the same input image. As the focus of this work is on efÔ¨Åcient search, we limit the used batch sizes to be the ones that can Ô¨Åt a conventional GPU memory. This allows SSNAS to efÔ¨Åciently learn novel network models without using any labeled data. We demonstrate that our selfsupervised approach for NAS achieves results comparable to the ones of its equivalent supervised approach. Moreover, we show that SSNAS not only achieves the same results as supervised NAS, but it also succeeds in some scenarios where the supervised method struggles. SpeciÔ¨Åcally, SSNAS can learn good architectures from data with a small number of annotated examples available for each class. We also demonstrate the potential of using NAS to improve unsupervised learning. We show some examples where SSL applied with the learned architectures generates visual representations that lead to improved performance. Thus, this work shows that SSL can both improve NAS and be improved by it. 22 Related work","Neural Architecture Search (NAS) is a powerful platform for discovering superior network architectures. NAS algorithms have achieved state-of-the-art results in several computer vision tasks. However, acquiring large amounts of labeled data is expensive and time-consuming. One promising lead in this direction is self-supervised learning (SSL). SSL learns visual representations from unlabeled data. We propose a Self-Supervised Neural Architecture Search (SSNAS), which unlike conventional NAS techniques, can find novel network architectures without rely on labeled data. We apply SSL to",cool!
47,PARS: Pseudo-Label Aware Robust Sample Selection for Learning with Noisy Labels.txt,"Acquiring accurate labels on large-scale datasets is both time consuming and
expensive. To reduce the dependency of deep learning models on learning from
clean labeled data, several recent research efforts are focused on learning
with noisy labels. These methods typically fall into three design categories to
learn a noise robust model: sample selection approaches, noise robust loss
functions, or label correction methods. In this paper, we propose PARS:
Pseudo-Label Aware Robust Sample Selection, a hybrid approach that combines the
best from all three worlds in a joint-training framework to achieve robustness
to noisy labels. Specifically, PARS exploits all training samples using both
the raw/noisy labels and estimated/refurbished pseudo-labels via self-training,
divides samples into an ambiguous and a noisy subset via loss analysis, and
designs label-dependent noise-aware loss functions for both sets of filtered
labels. Results show that PARS significantly outperforms the state of the art
on extensive studies on the noisy CIFAR-10 and CIFAR-100 datasets, particularly
on challenging high-noise and low-resource settings. In particular, PARS
achieved an absolute 12% improvement in test accuracy on the CIFAR-100 dataset
with 90% symmetric label noise, and an absolute 27% improvement in test
accuracy when only 1/5 of the noisy labels are available during training as an
additional restriction. On a real-world noisy dataset, Clothing1M, PARS
achieves competitive results to the state of the art.","Deep neural networks rely on largescale training data with human annotated labels for achieving good performance (Deng et al., 2009; Everingham et al., 2010). Collecting millions or billions of labeled training data instances is very expensive, requires signiÔ¨Åcant human time and effort, and can also compromise user privacy (Zheng et al., 2020; Bonawitz et al., 2017). Hence, there has been a paradigm shift in the interests of the research community from largescale supervised learning (Krizhevsky et al., 2017; He et al., 2016a; Huang et al., 2017) to Learning with Noisy Labels (LNL) (Natarajan et al., 2013; Goldberger & BenReuven, 2016; Patrini et al., 2017; Tanno et al., 2019) and/or unlabeled data (Berthelot et al., 2019b;a; Sohn et al., 2020). This is largely due to the abundance of raw unlabeled data with weak user tags (Plummer et al., 2015; Xiao et al., 2015) or caption descriptions (Lin et al., 2014). However, it is not trivial to build models that are robust to these noisy labels as the deep convolutional neural networks (CNNs) trained with crossentropy loss can quickly overÔ¨Åt to the noise in the dataset, harming generalization (Zhang et al., 2016). Most of the existing approaches on LNL can be divided into three main categories. First, several noise robust loss functions (Ghosh et al., 2017; Wang et al., 2019a; Zhang & Sabuncu, 2018) were proposed that are inherently tolerant to label noise. Second, sample selection methods (also referred to as loss correction in some literature) (Han et al., 2018; Yu et al., 2019; Arazo et al., 2019) are a popular technique that analyzes the persample loss distribution and separates the clean and noisy samples. The identiÔ¨Åed noisy samples are then reweighted so that they contribute less in the loss computation. A challenge in this direction is to design a reliable criterion for separation and hence prevent overÔ¨Åtting to highly conÔ¨Ådent noisy samples, a behavior known as selfconÔ¨Årmation bias . Third, label correction methods attempt to correct the noisy labels using classprototypes (Han et al., Work done during internship at Amazon, Alexa Shopping 1arXiv:2201.10836v1  [cs.CV]  26 Jan 20222019) or pseudolabeling techniques (Tanaka et al., 2018; Yi & Wu, 2019). However, in order to correct noisy labels, we typically need an extra (usually small) set of correctly labeled validation labels. In particular, these methods can fail when the noise ratio is high and estimating correct labels or highquality pseudolabels is nontrivial. More recently, the success of several stateoftheart LNL methods is attributed to leveraging Semi Supervised Learning (SSL) based approaches (Li et al., 2020; Kim et al., 2019). Typically, a sample selection technique is applied to separate clean and noisy labels in the training data, then the noisy labels are deemed unreliable and hence treated as unlabeled in a SSL setting. Following the recent SSL literature (Lee et al., 2013; Arazo et al., 2020), estimated pseudolabels are usually used to replace the Ô¨Åltered noisy labels during training. These approaches have shown to be highly tolerant to labelnoise. However, the noisy labels are always discarded in favor of pseudolabels in all the existing literature, but they may still contain useful information for training. Pseudolabeling is in turn only applied to the Ô¨Åltered noisy subset while the rest of the raw labels are typically used as is, which makes it sensitive to the quality of the Ô¨Åltering algorithm. In particular, motivated by a simple principle of making the most of the signal contained in the noisy training data, we design PARS, short for PseudoLabel Aware Robust Sample Selection. Our contributions are as follows: 1.PARS proposes a novel, principled training framework for LNL. It trains on both the original labels and pseudolabels. Unlike previous works, instead of Ô¨Åltering and then discarding the lowconÔ¨Ådent noisy labels, PARS uses the entire set of original labels, and applies selftraining with pseudolabeling and data augmentation for the entire dataset (rather than the Ô¨Åltered noisy data only). 2.PARS is able to learn useful information from all the available data samples through labeldependent noiseaware loss functions. SpeciÔ¨Åcally, in order to prevent overÔ¨Åtting to inaccurate original labels (or inaccurate pseudolabels), PARS performs a simple conÔ¨Ådence based Ô¨Åltering technique by setting a high threshold on their predicted conÔ¨Ådence, and applies robust/negative learning (or positive/negative learning) accordingly. 3.We perform extensive experiments on multiple benchmark datasets i.e.noisy CIFAR10, noisy CIFAR100 and Clothing1M. Results demonstrate that PARS outperforms previous stateoftheart methods by a signiÔ¨Åcant margin, in particular when high level of noise is present in the training data. We also conduct sufÔ¨Åcient ablation studies to validate the importance of our contributions. 4.We design a novel lowresource semisupervised LNL setting where only a small subset of data is weakly labeled (Section 4.3). We show signiÔ¨Åcant gains over stateoftheart approaches using PARS. This setting is particularly interesting when it is hard to obtain largescale noisy labeled data. In particular, we Ô¨Ånd that surprisingly none of the existing LNL methods outperform a baseline SSL model (FixMatch) (Sohn et al., 2020) that is not even designed to handle label noise, and yet PARS can achieve up to an absolute 27% improvement in test accuracy in a controlled highnoise lowresource setting. 2 R ELATED WORK","Deep convolutional neural networks (CNNs) are increasingly being trained with noisy labels. However, the label noise in the training data is often too high and can harm generalization. Hence, it is important to build models that are robust to noisy labels. Most of the existing approaches on LNL can be divided into three main categories. First, several noise-tolerant loss functions (Ghosh et al., 2017; Wang et al., 2019a; Sabuncu, 2018) were proposed that are inherently tolerant to label noise. Second, sample selection methods (also referred",cool!
85,Supervised Anomaly Detection via Conditional Generative Adversarial Network and Ensemble Active Learning.txt,"Anomaly detection has wide applications in machine intelligence but is still
a difficult unsolved problem. Major challenges include the rarity of labeled
anomalies and it is a class highly imbalanced problem. Traditional unsupervised
anomaly detectors are suboptimal while supervised models can easily make biased
predictions towards normal data. In this paper, we present a new supervised
anomaly detector through introducing the novel Ensemble Active Learning
Generative Adversarial Network (EAL-GAN). EAL-GAN is a conditional GAN having a
unique one generator vs. multiple discriminators architecture where anomaly
detection is implemented by an auxiliary classifier of the discriminator. In
addition to using the conditional GAN to generate class balanced supplementary
training data, an innovative ensemble learning loss function ensuring each
discriminator makes up for the deficiencies of the others is designed to
overcome the class imbalanced problem, and an active learning algorithm is
introduced to significantly reduce the cost of labeling real-world data. We
present extensive experimental results to demonstrate that the new anomaly
detector consistently outperforms a variety of SOTA methods by significant
margins. The codes are available on Github.","ANOMALIES nomalies (also known as outliers, novel ties, or faults) refer to the data points that deviate signiÔ¨Åcantly from the majority of available data [1]. Due to the valid, interesting and potentially valuable patterns they often represent, detecting such data could provide valuable knowledge in various realworld applications, such as Ô¨Å nance fraud detection [2], intrusion detection [3], rare in formation detection in healthcare [4], [5] and video analysis [6], [7]. Three substantial challenges in these applications are: (i) It is very difÔ¨Åcult to obtain sufÔ¨Åcient anomalies and their groundtruths to train an anomaly detector due to the prohibitive cost of collecting and labeling such data. (ii) Anomalies often exhibit very different anomalous behav iors, as a result, training an anomaly detector could be quite a challenge for the commonlyused optimization techniques, which generally assume that data within the same class should be similar to each other [8]. (iii) The available data could present a highly skewed distribution due to the rarity of anomalies. Consequently, most supervised models can easily make biased predictions to the normal data. To address these challenges, researchers generally adopt a twostep unsupervised learning procedure to isolate the Zhi Chen, Jiang Duan and Li Kang are with the School of Economic Infor mation Engineering, Southwestern University of Finance and Economics, Chengdu, China, 611130. Jiang Duan is the corresponding author Email:fchenzhi;duanj t;kanglig@swufe.edu.cn Guoping Qiu is with the College of Electronics and Information Engineer ing, Guangdong Key Laboratory for Intelligent Information Processing, and Shenzhen Institute of ArtiÔ¨Åcial intelligence and Robotics for Society, Shenzhen University, Shenzhen 518060, China, and also with the School of Computer Science, University of Nottingham, Nottingham NG8 1BB, UK. Email: guoping.qiu@nottingham.ac.ukanomalies from normal data: They Ô¨Årst learn to represent all the available data with new representations, e.g., distance metric spaces in [9], [10], [11], representations in a projected space [12], [13], [14], [15], [16], or latent spaces in generative adversarial networks (GANs) [4], [17], [18], [19]. And then, the data which signiÔ¨Åcantly deviates from the established normal proÔ¨Åles will be identiÔ¨Åed as potential anomalies. In most of these unsupervised methods, representation learn ing and anomaly detector training are separated into two independent procedures, therefore, such methods may yield suboptimal representations or representations irrelevant to the anomaly detection task [8]. To avoid this problem, some works have incorporated traditional anomaly scoring metrics into the representation learning objective to improve the quality of learned representations [20]. However, these methods mainly focus on unsupervised solutions, so they share the common shortcoming of unsupervised learning, often identify anomalies that are merely uninteresting data or noise. In recent years, deep learning has gained remark able success in various applications and has also shown promising potential in anomaly detection. However, most existing deep anomaly detectors [21], [22], [23] are unsuper vised methods, therefore they also suffer from the inherent limitations of such methods. Conditional generative adversarial networks (cGANs) [24], [25] have demonstrated exceptional ability in generat ing labeled samples indistinguishable from real world data. It therefore offers an appealing prospect of overcoming the problem of lack of labelled data in supervised anomaly detection by conditionally generating class balanced data. However, despite the promising performance of cGANs in modeling various conditional distributions, the perfor mances of standard cGANs heavily depends on the sizearXiv:2104.11952v1  [cs.LG]  24 Apr 20212 of labeled training data [26]. Very importantly, a standard cGAN is never designed for the class imbalanced scenarios. In anomaly detection, labeled anomalies are rarities and the distribution of the available data is highly skewed. Therefore anomaly detection presents major challenges for a common cGAN. In this paper, we present a supervised anomaly detection method through designing a cGAN featuring an ensemble of discriminators that are trained based on a novel ensemble active learning strategy. At the heart of our new method is the ensemble active learning generative adversarial network (EALGAN) which has the following novel features and advantages: Unique Network Architecture . EALGAN is a conditional GAN featuring a unique one generator vs.multiple discriminators architecture. Each discriminator consists of two classiÔ¨Åers simultaneously performs two classiÔ¨Å cation tasks: (i) An adversarial classiÔ¨Åer performs real and generated data classiÔ¨Åcation, and (ii) an auxiliary classiÔ¨Åer performs anomaly and normal data classiÔ¨Åca tion. An ensemble learning algorithm is developed to train the multiple discriminators to overcome the class imbalanced issue. The auxiliary classiÔ¨Åer acts as an active learning sampler as well as the anomaly detector. Novel Ensemble Learning Loss function . A novel ensemble learning loss function is designed to ensure that the ensemble of discriminators complementing each other. Each discriminator adaptively focuses on the samples wrongly classiÔ¨Åed by the others thus overcoming the problem of bias classiÔ¨Åcation towards the classes with larger number of samples. Active Ensemble Learning Reduces the Cost of Labeling Data . An active sampling strategy is incorporated into the EALGAN framework. The active sampling strategy progressively selects the data carrying the most infor mation but accounting for relatively small proportion of the available real data to not only optimize the discriminator ensemble, but also guide the generator to produce sufÔ¨Åciently balanced fake data. The selected real data and the generated fake data are used to train the discriminators thus signiÔ¨Åcantly reducing the cost of annotating anomaly data for training a fully supervised detector. Empirical results show that in a batchwise training procedure, EALGAN can provide stateoftheart performance by only labeling 5% of the real data in each batch. MultiDiscriminator Ensemble Learning Enhances Regular ization and Generalization . In the proposed EALGAN framework, the discriminator is designed as a multi task neural network. By effectively incorporating mul tiple discriminators into one ensemble with a novel ensemble learning loss function, the EALGAN shows enhanced capability to resist overÔ¨Åtting. This makes it easily to obtain an anomaly detector with optimal generalization or determine the stop node of GAN training by choosing the model with the best empirical performance (please see Fig. 2 and Section 3.3) The EALGAN is a High Quality cGAN . The unique ar chitecture and innovative ensemble learning algorithm have ensured that EALGAN is a highquality condi tional data generator. This is demonstrated by the factthat anomaly detectors trained with only the generated data can be as good as those trained with the real data and that mixing generated data with the real data can further improve performances. State of the Art Performances . Extensive experiments have been carried out on 20 widely used real world anomaly detection benchmark datasets and a variety of synthetic datasets. Performances are compared to 9 stateofthe art anomaly detection methods from 6 categories in the literature. The new EALGAN method consistently outperforms the best methods available, often by signif icant margins, achieving AUC performance improve ments range from 5.7% over the best deep learning detector, to 16.4% over the best traditional detector, and to 16.8% over the best ensemble detector; and achieving Gmean performance improvements range from 37.9% over the best deep learning detector, to 49.2% over the best ensemble detector, and to 52.5% over the best traditional detector. 2 R ELATED WORK","Anomalies are rare data points that are not labeled, and their detection is a challenging task for supervised models. In this paper, we propose a novel supervised anomaly detection method based on conditional generative adversarial networks (cGANs) that is trained based on an ensemble active learning strategy. The discriminators are trained based on a novel ensemble active learning strategy, and the discriminators are trained based on a novel ensemble active learning strategy. The discriminators are trained based on a",cool!
306,What Do Neural Networks Learn When Trained With Random Labels?.txt,"We study deep neural networks (DNNs) trained on natural image data with
entirely random labels. Despite its popularity in the literature, where it is
often used to study memorization, generalization, and other phenomena, little
is known about what DNNs learn in this setting. In this paper, we show
analytically for convolutional and fully connected networks that an alignment
between the principal components of network parameters and data takes place
when training with random labels. We study this alignment effect by
investigating neural networks pre-trained on randomly labelled image data and
subsequently fine-tuned on disjoint datasets with random or real labels. We
show how this alignment produces a positive transfer: networks pre-trained with
random labels train faster downstream compared to training from scratch even
after accounting for simple effects, such as weight scaling. We analyze how
competing effects, such as specialization at later layers, may hide the
positive transfer. These effects are studied in several network architectures,
including VGG16 and ResNet18, on CIFAR10 and ImageNet.","Overparameterization helps deep neural networks (DNNs) to generalize better in reallife appli cations [ 8,24,30,54], despite providing them with the capacity to Ô¨Åt almost any set of random labels [ 55]. This phenomenon has spawned a growing body of work that aims at identifying funda mental differences between real and random labels, such as in training time [ 4,19,20,56], sharpness of the minima [ 28,40], dimensionality of layer embeddings [ 3,11,35], and sensitivity [ 4,41], among other complexity measures [ 6,7,39,40]. While it is obvious that overparameterization helps DNNs to interpolate any set of random labels, it is not immediately clear what DNNs learn when trained in this setting. The objective of this study is to provide a partial answer to this question. There are at least two reasons why answering this question is of value. First, in order to understand how DNNs work, it is imperative to observe how they behave under ‚Äúextreme‚Äù conditions, such as ?Equal contribution. yWork completed during the Google AI Residency Program. Preprint. Accepted, NeurIPS 2020.arXiv:2006.10455v2  [stat.ML]  11 Nov 20201. Pretraining helps (real labels)2. Pretraining helps (random labels)3. Pretraining hurts (real labels)4. Pretraining hurts (random labels) 50 1500 3000 Training Iterations0.00.20.40.60.81.0Accuracypretrained (train) pretrained (test) from scratch (train) from scratch (test) 50 10000 20000 Training Iterations0.00.20.40.60.81.0Accuracy pretrained (train) from scratch (train) 50 1500 3000 Training Iterations0.00.20.40.60.81.0Accuracypretrained (train) pretrained (test) from scratch (train) from scratch (test) 50 10000 20000 Training Iterations0.00.20.40.60.81.0Accuracy pretrained (train) from scratch (train) Figure 1: Pretraining on random labels may exhibit both positive ( 1 & 2 ) and negative ( 3 & 4 ) effects on the downstream Ô¨Ånetuning depending on the setup. VGG16 models are pretrained on CIFAR10 examples with random labels and subsequently Ô¨Ånetuned on the fresh CIFAR10 examples with either real labels (1 & 3) or 10 random labels (2 & 4) using different hyperparameters. when trained with labels that are entirely random. Since the pioneering work of [ 55], several works have looked into the case of random labels. What distinguishes our work from others is that previous works aimed to demonstrate differences between real and random labels, highlighting the negative side of training on random labels. By contrast, this work provides insights into what properties of the data distribution DNNs learn when trained on random labels. Second, observing DNNs trained on random labels can explain phenomena that have been previously noted, but were poorly understood. In particular, by studying what is learned on random labels, we offer new insights into: (1) why DNNs exhibit critical stages [ 1,17], (2) how earlier layers in DNNs generalize while later layers specialize [ 3,4,10,53], (3) why the Ô¨Ålters learned by DNNs in the Ô¨Årst layer seem to encode some useful structure when trained on random labels [ 4], and (4) why pretraining on random labels can accelerate training in downstream tasks [ 42]. We show that even when controlling for simple explanations like weight scaling (which was not always accounted for previously), such curious observations continue to hold. The main contributions of this work are: ‚Ä¢We investigate DNNs trained with random labels and Ô¨Ånetuned on disjoint image data with real or random labels, demonstrating unexpected positive and negative effects. ‚Ä¢We provide explanations of the observed effects. We show analytically for convolutional and fully connected networks that an alignment between the principal components of the network parameters and the data takes place. We demonstrate experimentally how this effect explains why pretraining on random labels helps. We also show why, under certain conditions, pretraining on random labels can hurt the downstream task due to specialization at the later layers. ‚Ä¢We conduct experiments verifying that these effects are present in several network architectures, including VGG16 [ 46] and ResNet18v2 [ 22], on CIFAR10 [ 31] and ImageNet ILSVRC2012 [ 14], across a range of hyperparameters, such as the learning rate, initialization, number of training iterations, width and depth. In this work, we do not use data augmentation as it provides a (weak) supervisory signal. Moreover, we use the terms ‚Äúpositive‚Äù and ‚Äúnegative‚Äù to describe the impact of what is learned with random labels on the downstream training, such as faster/slower training. The networks reported throughout the paper are taken from a big set of experiments that we conducted using popular network architectures, datasets, and wide hyperparameter ranges. Experimental details are provided in Appendix A and B. We use boldface for random variables, small letters for their values, and capital letters for matrices. 1.1 Motivating example Figure 1 shows learning curves of the VGG16 architecture [ 46] pretrained on 20k CIFAR10 exam ples [ 31] with random labels (upstream) and Ô¨Ånetuned on a disjoint subset of 25k CIFAR10 examples with either random or real labels (downstream). We observe that in this setup, pretraining a neural network on images with random labels accelerates training on a second set of images, both for real and random labels (positive effect). However, in the same setting but with a different initialization scale and number of random classes upstream, a negative effect can be observed downstream: training 2becomes slower. We also observe a lower Ô¨Ånal test accuracy for real labels in both cases, which we are not explicitly investigating in this paper (and which has been observed before, e.g. in [17]). The fact that pretraining on random labels can accelerate training downstream has been observed previously, e.g. in [ 42]. However, there is a ‚Äúsimple‚Äù property that can explain improvements in the downstream task: Because the crossentropy loss is scalesensitive, training the network tends to increase the scale of the weights [ 40], which can increase the effective learning rate of the downstream task (see the gray curve in Figure 5). To eliminate this effect, in all experiments we rescale the weights of the network after pretraining to match their `2norms at initialization. We show that even after this correction, pretraining on random labels positively affects the downstream task. This holds for both VGG16 and ResNet18 trained on CIFAR10 and ImageNet (see Appendix B). We show experimentally that some of the positive transfer is due to the secondorder statistics of the network parameters. We prove that when trained on random labels, the principal components of weights at the Ô¨Årst layer are aligned with the principal components of data. Interestingly, this alignment effect implies that the model parameters learned at the Ô¨Årst layer can be summarized by a onedimensional mapping between the eigenvalues of the data and the eigenvalues of the network parameters. We study these mappings empirically and raise some new open questions. We also analyze how, under certain conditions, a competing effect of specialization at the later layers may hide the positive transfer of pretraining on random labels, which we show to be responsible for the negative effect demonstrated in Figure 1. To the best of our knowledge, the alignment effect has not been established in the literature before. This paper proves the existence of this effect and studies its implications. Note that while these effects are established for training on random labels, we also observe them empirically for real labels. 1.2 Related work","Overparameterization helps deep neural networks (DNNs) to generalize better in real-life applications, despite providing them with the capacity to fit almost any set of random labels. However, it is not immediately clear what DNNs learn when trained on random labels. This study aims to provide a partial answer to this question. First, it is imperative to observe how DNNs behave under ‚Äúextreme‚Äù conditions, such as Equal contribution. Second, observing DNNs trained on random labels can provide insights into phenomena that have previously not fully connected networks.",cool!
274,Detecting changes in dynamic social networks using multiply-labeled movement data.txt,"The social structure of an animal population can often influence movement and
inform researchers on a species' behavioral tendencies. Animal social networks
can be studied through movement data; however, modern sources of data can have
identification issues that result in multiply-labeled individuals. Since all
available social movement models rely on unique labels, we extend an existing
Bayesian hierarchical movement model in a way that makes use of a latent social
network and accommodates multiply-labeled movement data (MLMD). We apply our
model to drone-measured movement data from Risso's dolphins (Grampus griseus)
and estimate the effects of sonar exposure on the dolphins' social structure.
Our proposed framework can be applied to MLMD for various social movement
applications.","For many species, analyzing social networks is necessary for understanding an imal behavior (e.g., Couzin et al., 2005). The underlying social network of an animal population can strongly in uence movement (Scharf et al., 2016, 2018) and provide researchers with information on the behavioral characteristics of a species. Such information is benecial to various ecological applications, includ ing determining the eects of anthropogenic activities, landscape fragmentation, or pollutants on the collective behavior of an animal population. Many marine mammals, including Risso's dolphins ( Grampus griseus ), are highly social with closeknit relationships (Lusseau David, 2004; Hartman et al., 2008; Weiss et al., 2021; Whitehead and Rendell, 2021). With such an anity for social interactions, they may be expected to exhibit a collective behavioral re sponse when exposed to changes in their environment. For example, G. Griseus 1arXiv:2204.00542v2  [stat.ME]  1 Nov 2022Z. Boulil et al./Dynamic social networks using multiplylabeled movement data 2 are commonly exposed to midfrequency active sonar due to their high abun dance in nearcoastal navy training areas (Carretta et al., 2019; Rice et al., 2020). Nonetheless, there is a sparsity of data on how dolphins respond to sonar and uncertainty about the consequences of exposure (Durban et al., 2022). Thus, our motivating application is studying G. Griseus exposed to sonar o Catalina Island in Southern California in a controlled exposure experiment (CEE), de signed to ll these key data gaps. Currently available social movement models that account for social interac tions between individuals require unique identication of animals and assume a closed, fully observed population throughout the study period (e.g., Langrock et al., 2014; Scharf et al., 2016, 2018; Niu et al., 2020; Scharf and Buderman, 2020; Milner et al., 2021). Movement data of terrestrial and marine animals have been conventionally obtained by tracking individuals singularly, often with telemetry tags. However, drones now oer the ability to track multiple individ uals simultaneously (Durban et al., 2022). While this new source of movement data can achieve a high spatial precision (Dawson et al., 2017; Durban et al., 2015, 2022), it sometimes introduces complex labeling issues due to the obser vation process. When animals that cannot be uniquely identied disappear out of a drone's active eld of view for sustained intervals of time, they are typically assigned a new label upon reappearance. The lack of identication leads to prob lematic \multilabeling"" as well as varying numbers of animals in view at a given time point. Thus, new methods are needed that allow for social network infer ence from multiplylabeled movement data (MLMD) such as those obtained via drones. We extend existing methodology for animal movement to estimate the eects of sonar exposure on an unobserved social network of dolphins through the use of dronemeasured movement data. Our modeling approach allows us to infer social connections between dolphins directly from the dronemeasured movement data. We adopt a Bayesian approach through the implementation of a discrete time continuousspace Gaussian Markov Random Field (GMRF; Rue and Held, 2005) with an underlying dynamic social network. The two main behavioral components motivating the model are attraction and alignment, both of which are directly related to social structure. Attraction represents an individual's inclination toward the mean position of connected individuals, while alignment represents an individual's tendency to move in parallel with the trajectories of connected individuals (Bode et al., 2012). The model also allows for repulsive and/or antialigning behavior by allowing negative values of relevant parameters, however, such behaviors are unlikely to occur in our motivating application. Thus, we limit our framework to modeling the positive behaviors of attraction and alignment. As social structure is expected to play a role in the movement of animals in relation to one another, the attraction and alignment mechanisms are motivating elements in uencing animal movement. Additionally, the model captures the overall stability of the social network and measures the density of social connections as it varies with time. We incorporate generalized linear models (GLMs) on certain parameters of interest as an extension to the model introduced in Scharf et al. (2016). TheZ. Boulil et al./Dynamic social networks using multiplylabeled movement data 3 GLMs provide information on the direct impact of external sources on the be havioral characteristics of a population, which allow for assessing the eect of environmental covariates on social structure. By including GLMs in the mod eling framework, we provide a deeper understanding of how external sources might in uence the collective movement of a population. While the closely related model from Scharf et al. (2016) provides a tractable likelihood for individuals with unique labels, the multiplylabeled nature of MLMD makes calculating the likelihood infeasible. To accommodate the in tractability of the exact likelihood, we develop an implementation scheme based on a proxy likelihood, which we evaluate through a simulation study. We detail our inference of social networks when analyzing MLMD in Section 2 and 3 and validate our approach using an approximate likelihood through a simulation study in Section 4. We apply our methodology to dronemeasured movement data following many Risso's dolphins simultaneously as they are ex posed to sonar in Section 5. We found that during periods of sonar exposure, dolphins are more likely to exhibit an inclination towards the mean position of connected individuals, less likely to move in parallel with connected individuals, and tend to have fewer social connections. We close with potential for future directions in Section 6 including applying our model to subsets of a population when analyzing data sets with a large number of individuals. 2. Methods","We extend existing methodology for animal movement to estimate the effects of sonar exposure on an unobserved social network of dolphins through the use of dronemeasured movement data. We model the behavior of dolphins through the use of a discrete time continuousspace Gaussian Markov Random Field (GMRF) with an underlying dynamic social network. The two main behavioral components motivating the model are attraction and alignment, both of which are directly related to social structure. We limit our model to modeling the positive behaviors of attraction and alignment. We also allow for repulsive and/anti-al",cool!
509,Detecting malicious PDF using CNN.txt,"Malicious PDF files represent one of the biggest threats to computer
security. To detect them, significant research has been done using handwritten
signatures or machine learning based on manual feature extraction. Those
approaches are both time-consuming, require significant prior knowledge and the
list of features has to be updated with each newly discovered vulnerability. In
this work, we propose a novel algorithm that uses an ensemble of Convolutional
Neural Network (CNN) on the byte level of the file, without any handcrafted
features. We show, using a data set of 90000 files downloadable online, that
our approach maintains a high detection rate (94%) of PDF malware and even
detects new malicious files, still undetected by most antiviruses. Using
automatically generated features from our CNN network, and applying a
clustering algorithm, we also obtain high similarity between the antiviruses'
labels and the resulting clusters.","1.1 Malware in PDF Malware programs are still making newspapers' headlines. They are used by criminal organizations, governments, and industries to steal money, spy, or other unwanted activities. As millions of new malicious samples are discovered every day, spotting them before they harm a computer or a network remains one of the most important challenges in cybersecurity. During the last two decades, hackers kept nding new attack vectors, giving malware multiple forms. Some use the macros in Microsoft Oce documents while others exploit browser's vulnerabilities with javascript les. This diversity raises the need for new automated solutions. Portable Document Format (PDF) is one of the most popular types of documents. Despite the lack of awareness of the population, it also became an important attack vector (AV) for computer systems. Dozens of vulnerabilities are discovered every year on Adobe Reader, the most popular software for reading PDF les [1], allowing hackers to take control of the victim's computer. PDF malware can be segmented into three main categories: (i) exploits, (ii) phishing, and (iii) misuse of PDF capabilities. Exploits operate by taking advantage of a bug in the API of a PDF reader application, which allows the attacker to execute code on the victim's computer. This is usually done via JavaScript code embedded in the le. In phishing attacks, the PDF itself does not have any malicious behavior but attempts to convince the user to click on a malicious link. Such campaigns have been discovered recently [2] and are, by nature, much harder to identify. The last category 1arXiv:2007.12729v2  [cs.CR]  2 Aug 2020exploits some regular functionality of PDF les such as running a command or launching a le. All those attacks can lead to devastating consequences, such as downloading a malicious executable or stealing credentials from a website. Regardless of recent work in machine learning for malware detection, antivirus companies are still largely focusing on handwritten signatures to detect malicious PDF. This not only requires signicant human resources but is also rarely ecient at detecting unknown variants or zeroday attacks [3]. Another popular solution is the dynamic analysis by running the les in a controlled sandboxed environment [4]. Such approaches increase signicantly the chance of detecting new malware, but take much longer and require access to a sandbox virtual machine. They also still require a human to dene the detection rules according to the le behavior. 1.2 Classical antivirus models for PDF les Antivirus vendors use a few dierent approaches to detect malware in PDF: Signaturebased detection It is the most basic and common method used to identify malicious les [6]. Security analyst manually inspects a malicious le and extract one or several patterns from the byte code, the ""signatures"", that they store in a database. When analyzing a new le, they try to match their code segments with the one in the database. If a match occurs, the le is blocked. Static Analysis Another rudimentary technique commonly used by antivirus is static anal ysis. In consists of applying heuristicbased rules on the content of a le to nd potentially malicious action. The easiest approach is the search for keywords like /JavaScript, /Open Action, or /GoTo which are related to an action that can be harmful to the computer. In absence of those tags, an analyst can condently say that the le is benign [21] (although some attacks are managing to inject javascript code without requiring a javascript tag). Dynamic Analysis It is a more expensive but potentially stronger method for detecting malicious behavior. It consists of running the le in a controlled environment (sandbox) and evaluates and retrieve the API calls and the network activity produced by the possible malware. Then, a program can apply heuristics on top of the activity logs like connecting to a malicious website or launching a subprocess [21]. 1.3 Contribution In this work, we are using an ensemble of Convolutional Neural Network (CNN) in order to detect any type of malicious PDF les. Without any preprocessing of the les, our classier succeeds to detect 94% of the malicious samples of our test set while keeping a False Positive Rate (FPR) at 0.5%. Our classier outperforms most of the antiviruses (AV) vendors available in the VirusTotal website.We also show that our CNN can successfully group more than 75% of the malware into dierent families. Finally, we will present some examples on which we were able to detect an attack before the AV (zeroday). To the best of our knowledge, this is the rst paper using Neural Network to classify PDF malware. It is also the rst one that investigates the ability to automatically classify malicious PDF into dierent families. Finally, as an attempt to build a baseline for detecting PDF malware, we opensourced the list of the les used for the research. They are all downloadable from VirusTotal. 2Paper organization: We rst present the related research in machine learning for detecting malicious PDF and the usage of Deep Learning applied to Malware Detection in executable les (Section 2). We describe how we built our data set in Section 3, and describe our model in Section 4. We show our results on the data sets in Section 5. We investigate the capability of our network to dierentiate between malware types in Section 6. Our conclusion is in Section 7. 2 Related work","Portable Document Format (PDF) is one of the most popular types of documents. Despite the lack of awareness of the population, it also became an important attack vector (AV) for computer systems. Despite recent work in machine learning for malware detection, antivirus companies are still largely focusing on handwritten signatures to detect malicious PDF. This requires significant human resources and is rarely efficient at detecting unknown variants or zero-day attacks. In this work, we are using an ensemble of Convolutional Neural Network (CNN) in order to detect any type of PDF",cool!
314,Accurate 3D Cell Segmentation using Deep Feature and CRF Refinement.txt,"We consider the problem of accurately identifying cell boundaries and
labeling individual cells in confocal microscopy images, specifically, 3D image
stacks of cells with tagged cell membranes. Precise identification of cell
boundaries, their shapes, and quantifying inter-cellular space leads to a
better understanding of cell morphogenesis. Towards this, we outline a cell
segmentation method that uses a deep neural network architecture to extract a
confidence map of cell boundaries, followed by a 3D watershed algorithm and a
final refinement using a conditional random field. In addition to improving the
accuracy of segmentation compared to other state-of-the-art methods, the
proposed approach also generalizes well to different datasets without the need
to retrain the network for each dataset. Detailed experimental results are
provided, and the source code is available on GitHub.","Accurate cell boundary detection from 3D confocal imagery is critical in many applications including modeling of cell morphogenesis [1] and plant growth [2]. A typical cell seg mentation workÔ¨Çow consists of the following steps: (i) im age preprocessing to enhance the signaltonoise ratio, (ii) a segmentation method that then partitions the cells, and (iii) a Ô¨Ånal reÔ¨Ånement step. Typical preprocessing methods includ ing morphological operations, edge enhancement methods, and denoising are widely used in the recent cell segmenta tion tasks [3, 4, 5, 6]. This preprocessing stage is often data dependent and requires parameter tuning to avoid under or oversegmentation. For membranetagged images, segmen tation is usually carried out with either 3D watershed based methods [2, 4] or 3D level sets [7]. Some methods work on individual 2D images and then fuse the results to get a 3D segmentation [3, 8]. Finally, postprocessing using cell vol ume or shape heuristic is usually applied. For this traditional This work was supported by NSF MCB Grant No. 1121893 to D.B.S. and NSF MCB Grant No. 1715544 to B.S.M. 1https://github.com/UCSBVRL/Purdue3DCellworkÔ¨Çow of cell segmentation, preprocessing is subjective, and its parameters are highly dependent on the data. During the past few years, there has been much interest in the use of deep learning for the cell segmentation problems, and the UNet in particular has been widely explored [9, 10]. UNet is a fully convolutional network which consists of en coder and decoder parts. The encoder part uses context infor mation to encode raw images into feature maps, and the de coder part uses the produced feature maps to localize objects and generate the segmentation. UNet based method gives fairly good cell boundary segmentation accuracy on the sim ilar dataset but its performance drops in generalizing to other datasets. Besides, UNet is not guaranteed to generate closed cell surfaces. A  B Fig. 1 . (A) Intercellular spaces and (B) Protrusion are indi cated by red arrows. Best viewed in color. In this paper, we aim to solve the problem of accurately identifying cell boundaries and labeling individual cells in confocal microscopy image stacks. The goal is to generate closed cell surfaces in the 3D image stack while being able to accurately delineate features of interest such as the inter cellular spaces and protrusions , see Ô¨Åg. 1. The Ô¨Årst step is to generate a membrane probability map where voxels that are likely to belong to a cell membrane have higher values than those that are not on the cell membrane. This is achieved by a 3D UNet architecture which is trained on a large, public data. This is followed by a watershed method that labels individual cells. One challenge for watershed algorithm is automated seeding of the cells, and this is achieved using a simple dis tance transform of the membrane probability map. The water shed based approach is sensitive to the image signal and likelyarXiv:1902.04729v1  [cs.CV]  13 Feb 2019to smooth out the boundaries and also miss smaller features that are signiÔ¨Åcant in modeling cell morphogenesis. For this purpose, we introduce a Ô¨Ånal processing step based on condi tional random Ô¨Åelds (CRFs). The CRF reÔ¨Ånes the watershed boundaries taking into account the probability map and local voxel boundary information. As demonstrated through the ex tensive experiments, this would help the overall approach to be sensitive to local boundary perturbation, including detect ing salient boundary features. The proposed method is vali dated in two datasets, and the experimental results shows that our segmentation method outperforms the current cell seg mentation methods [2, 11, 12] with less computation time. In addition, we also demonstrate that the proposed method gen eralizes well to different datasets without addition retraining or Ô¨Åne tuning the parameters of the neural network. To summarize, the main contributions of this paper in clude (i) a method that is sensitive to local image features, for accurate detection and localization of boundaries in 3D confocal stacks; (ii) and show that the method is capable of generalizing to other datasets without further training. 2. MATERIAL AND METHODS 2.1. Dataset Two 3D confocal image stack datasets of Ô¨Çuorescenttagged plasmamembrane cells are used in this paper. In both datasets, only the plasmamembrane signal is available and is represented by voxels with high intensity values. The Ô¨Årst dataset contains 124 image stacks of cells in the shoot api cal meristem of 6 Arabidopsis thaliana [13]. In each image stack, there are 150 to 300 slices containing of 3 layers of cells: outer layer (L1), middle layer (L2), and deep layer (L3), and the size of each slice is 512512. The available resolution of each image in x and y direction are 0.22 mand in z is about 0.27 m. We should note that as we go from L1 towards L3, the image quality degrades progressively due to scattering of light. This condition makes the segmenta tion problem challenging in L3. In this dataset, the ground truth voxelwise cell labels are provided, and each cell has a unique label. The second dataset [1] consists of a longterm timelapse from A. thaliana‚Äôs leaf epidermal tissue that spans over a 12 hour period with a xyresolution of 0.212 mand 0.5mthick optical sections. There are 20 image stacks in this dataset. In each image stack, there are 15 to 30 slices containing one layer of cell, and the size of each slice is 512512. The ground truth cell labels are not provided in this dataset. 2.2. Method","Cell boundary segmentation is critical in many applications including modeling of cell morphogenesis and plant growth. Traditionally, cell segmentation is performed by pre-processing, which is often data dependent and requires parameter tuning. For membrane-tagged images, segmentation is usually carried out with either 3D watershed based methods or 3D level sets. For this problem, the UNet is a fully convolutional network which consists of encoder and decoder parts. The encoder part uses context information to encode raw images into feature maps, and then generate the segmentation. The watershed method is sensitive",cool!
147,Deep Neural Network Ensembles.txt,"Current deep neural networks suffer from two problems; first, they are hard
to interpret, and second, they suffer from overfitting. There have been many
attempts to define interpretability in neural networks, but they typically lack
causality or generality. A myriad of regularization techniques have been
developed to prevent overfitting, and this has driven deep learning to become
the hot topic it is today; however, while most regularization techniques are
justified empirically and even intuitively, there is not much underlying
theory. This paper argues that to extract the features used in neural networks
to make decisions, it's important to look at the paths between clusters
existing in the hidden spaces of neural networks. These features are of
particular interest because they reflect the true decision making process of
the neural network. This analysis is then furthered to present an ensemble
algorithm for arbitrary neural networks which has guarantees for test accuracy.
Finally, a discussion detailing the aforementioned guarantees is introduced and
the implications to neural networks, including an intuitive explanation for all
current regularization methods, are presented. The ensemble algorithm has
generated state-of-the-art results for Wide-ResNets on CIFAR-10 (top 5 for all
models) and has improved test accuracy for all models it has been applied to.","Consider a simple feed forward neural network. Dene a hidden space corre sponding to a hidden layer of a neural network as the space containing the outputs of the hidden nodes at that hidden layer for some input. All hidden spaces are composed of perceptrons with respect to the previous layer, each of which has a hyperplane decision boundary. Points in the previous space are mapped to a constant function of their distance to this plane, and depending on the activation function, compressed or stretched. This stretching and compress ing naturally leads to clustering in hidden spaces. The process is repeated for each perceptron comprising the hidden space, where adding a perceptron adds a dimension to the hidden space by projecting the points into a new dimension depending on their distances from the hyperplane of the new perceptron and the activation function. Dene a feature to be a measurable characteristic which a neural network uses to make its classication decision. Unfortunately, these clusters are not features in and of themselves but rather mixtures of features.arXiv:1904.05488v2  [cs.LG]  13 Aug 20192 Sean Tao To extract individual features, then, cluster paths should be examined, where a path is dened per individual input point as the sequence of clusters in the neural network the point belongs to, starting from cluster it belongs to in the input space, then the clusters it belongs to in each hidden space, and nally the cluster it belongs to in the output space. Intuitively, paths represent features because each path denes a region of the input space which will eventually end up at the same cluster in the output space via the same logic pathway used by the neural network. Thus, it immediately follows that a point on a path must be classied similarly as other points on that path, assuming all points in the output space are classied by cluster. This is another way of stating that points on the same path are indistinguishable from each other to the neural network, and since points in dierent paths were dierentiated in some layer, paths separate out features of neural networks. This process is formalized in the algorithm described below. However, besides merely nding the features in a neural network, the paths serve an even more important purpose{they separate the input into regions of condence with respect to the output classication. In particular, paths represent specic features, some of which were found because they are truly useful and others due to overtting. The process of determining \good"" and \bad"" data points, formally dened below, attempts to separate data into these two categories. Informally, \good"" data come from paths that contain many points that are classied correctly, since these are likely not due to random chance and thus are real features. An ensemble algorithm can then be created to combine dierent models, where models only vote on their \good"" data points. This is equivalent to querying neural networks for points where they are condent in their predictions. Points where the model is unsure can then be classied by other models. 2 Related Work","In a feed forward neural network, hidden spaces correspond to the space containing the outputs of the hidden nodes at the previous layer for some input. Each hidden space is composed of perceptrons with respect to the previous layer, each of which has a hyperplane decision boundary. Points in the previous space are mapped to a constant function of their distance to this plane, and depending on the activation function, compressed or stretched. This stretching and compressing naturally leads to clustering in hidden spaces. To extract individual features, then, paths should be examined, where each path is de a",cool!
236,An Effective Label Noise Model for DNN Text Classification.txt,"Because large, human-annotated datasets suffer from labeling errors, it is
crucial to be able to train deep neural networks in the presence of label
noise. While training image classification models with label noise have
received much attention, training text classification models have not. In this
paper, we propose an approach to training deep networks that is robust to label
noise. This approach introduces a non-linear processing layer (noise model)
that models the statistics of the label noise into a convolutional neural
network (CNN) architecture. The noise model and the CNN weights are learned
jointly from noisy training data, which prevents the model from overfitting to
erroneous labels. Through extensive experiments on several text classification
datasets, we show that this approach enables the CNN to learn better sentence
representations and is robust even to extreme label noise. We find that proper
initialization and regularization of this noise model is critical. Further, by
contrast to results focusing on large batch sizes for mitigating label noise
for image classification, we find that altering the batch size does not have
much effect on classification performance.","Deep Neural Networks (DNNs) have led to sig niÔ¨Åcant advances in the Ô¨Åelds of computer vi sion (He et al., 2016), speech processing (Graves et al., 2013) and natural language processing (Kim, 2014; Young et al., 2018; Devlin et al., 2018). To be effective, supervised DNNs rely on large amounts of carefully labeled training data. However, it is not always realistic to assume that example labels are clean. Humans make mistakes and, depending on the complexity of the task, there may be disagreement even among expert la belers. To support noisy labels in data, we neednew training methods that can be used to train DNNs directly from the corrupted labels to sig niÔ¨Åcantly reduce human labeling efforts. Zhu and Wu (2004) perform an extensive study on the ef fect of label noise on classiÔ¨Åcation performance of a classiÔ¨Åer and Ô¨Ånd that noise in input features is less important than noise in training labels. In this work, we add a noise model layer on top of our target model to account for label noise in the training set, following (Jindal et al., 2016; Sukhbaatar et al., 2014). We provide extensive experiments on several text classiÔ¨Åcation datasets with artiÔ¨Åcially injected label noise. We study the effect of two different types of label noise; Uni form label Ô¨Çipping (Uni) , where a clean label is swapped with another label sampled uniformly at random; and Random label Ô¨Çipping (Rand) where a clean label is swapped with another label from the given number of labels sampled randomly over a unit simplex. We also study the effect of different initializa tion, regularization, and batch sizes when training with noisy labels. We observe that proper initial ization and regularization helps the noise model learn to be robust to even extreme amounts of noise. Finally, we use lowdimensional projec tions of the features of the training examples to understand the effectiveness of the noise model. The rest of the paper is organized as follows. Section 2 discusses the various approaches in lit erature to handle label noise. In Section 3, we describe the problem statement along with the proposed approach. We describe the experimen tal setup and datasets in Section 4. We empiri cally evaluate the performance of the proposed ap proach along with the discussion in Section 5 and Ô¨Ånally conclude our work in Section 6.arXiv:1903.07507v1  [cs.LG]  18 Mar 20192 Related Work","Deep Neural Networks (DNNs) have been shown to be effective in many domains, including computer vision, speech processing, and natural language processing. However, label noise in training data can lead to inaccurate classification results. In this work, we introduce a noise model layer on top of our target model to account for label noise in the training set. We study the effect of two different types of label noise; Uniform label flipping (Uni) where a clean label is swapped with another label sampled uniformly at random; and Random label flipping (Rand) where a clean label",cool!
179,Large Loss Matters in Weakly Supervised Multi-Label Classification.txt,"Weakly supervised multi-label classification (WSML) task, which is to learn a
multi-label classification using partially observed labels per image, is
becoming increasingly important due to its huge annotation cost. In this work,
we first regard unobserved labels as negative labels, casting the WSML task
into noisy multi-label classification. From this point of view, we empirically
observe that memorization effect, which was first discovered in a noisy
multi-class setting, also occurs in a multi-label setting. That is, the model
first learns the representation of clean labels, and then starts memorizing
noisy labels. Based on this finding, we propose novel methods for WSML which
reject or correct the large loss samples to prevent model from memorizing the
noisy label. Without heavy and complex components, our proposed methods
outperform previous state-of-the-art WSML methods on several partial label
settings including Pascal VOC 2012, MS COCO, NUSWIDE, CUB, and OpenImages V3
datasets. Various analysis also show that our methodology actually works well,
validating that treating large loss properly matters in a weakly supervised
multi-label classification. Our code is available at
https://github.com/snucml/LargeLossMatters.","Multilabel classification aims to find all existing objects or attributes in a single image. It is gaining attention since the real world is made up of a scene with multiple objects in it [29,37]. Moreover, some of the singlelabel datasets, also called multiclass datasets, actually have images containing multiple objects [35, 58]. However, the multilabel classi fication task has some fundamental difficulties in making a dataset because it requires annotators to label all categories‚Äô existence/absence for every image. As the number of cate gories and images in the dataset increase, annotation cost becomes tremendous [20]. *Equal contribution. 0 500 1000 1500 2000 2500 Iteration0.000.020.040.060.080.100.12LossEarly learning phase Memorization phaseTrue negative False negativeFigure 1. Memorization in WSML. When training ResNet50 model on PASCAL VOC dataset with partial label, we set all un observed labels as negative. These labels are composed of true negative and false negative. We observe that the model first fits into true negative label (learning), and then fits into false negative (memorization). To alleviate these issues, weakly supervised learning ap proach in multilabel classification task (WSML) has been taken into consideration [2, 18, 38, 52]. In a WSML setting, labels are given as a form of partial label, which means only a small amount of categories is annotated per image. This setting reflects the recently released largescale multilabel datasets [12,20] which provide only partial label. Thus, it is becoming increasingly important to develop learning strate gies with partial labels. There are two naive approaches to train the model with partial labels. One is to train the model with observed labels only, ignoring the unobserved labels. The other is to assume all unobserved labels are negative and incorporate them into training because majorities of labels are negative in a multi label setting [33]. As the second one has a limitation that this assumption produces some noise in a label which ham pers the model learning, previous works [7,9,16,22] mostly follow the first approach and try to explore the cue of un observed labels using various techniques such as bootstrap ping or regularization. However, these approaches include 1heavy computation or complex optimization pipeline. We hypothesize that if label noise can be handled prop erly, the second approach could be a good starting point be cause it has the advantage of incorporating many true neg ative labels into model training. Therefore, we try to look at the WSML problem from the perspective of noisy label learning. Our key observation is about the memorization effect [1] in a noisy label learning literature. It is known that when training a model with a noisy label, the model fits into clean labels first and then starts memorizing noisy labels. Al though previous work showed the memorization effect only in a noisy multiclass classification scenario, we found for the first time that this same effect also happens in a noisy multilabel classification scenario. As shown in Figure 1, during training, the loss value from the clean label (true neg ative) decreases from the beginning while the loss from the noisy label (false negative) decreases from the middle. Based on this finding, we borrow the idea from noisy multiclass literature [13, 17, 24] which selectively trains the model with samples having small loss and adapt this idea into a multilabel scenario. Specifically, by assigning the unknown labels as negative in a WSML setting, label noise appears in the form of false negative. Then we de velop the three different schemes to prevent false negative labels from being memorized into the multilabel classifi cation model by rejecting or correcting large loss samples during training. Our method is light and simple, yet effective. It involves negligible computation overhead and does not require com plex optimization for model training. Nonetheless, our method surpasses the weakly supervised multilabel classi fication performance compared to the stateoftheart meth ods in Pascal VOC 2012 [10], MS COCO [25], NUSWIDE [6], CUB [44], and OpenImages V3 [20] datasets. More over, while some existing methods are only effective in spe cific partial label setting [7, 9, 16], our method is broadly applicable in both artificially created and real partial label datasets. Finally, we provide some analysis about the rea son why our methods work well from various perspectives. To sum up, our contributions are as follows; 1) We empirically show for the first time that the memo rization effect occurs during noisy multilabel classification. 2) We propose a novel scheme for weakly supervised multilabel classification that explicitly utilizes a learning technique with noisy label. 3) Although light and simple, our proposed method achieves stateoftheart classification performance on vari ous partial label datasets. 2. Related Works","Multi-label classification is a challenging task that requires annotators to label all existing categories in a single image. However, the annotation cost becomes tremendous as the number of categories and images in the dataset increases. To alleviate these issues, weakly supervised learning approach in multi-label classification task (WSML) has been taken into consideration. In this paper, we propose a novel approach to train a model with partial labels. We set all unobserved labels as negative and observe that the model first fits into true negative and then starts to memorizing false negative labels. We observe that the",cool!
160,"A Systematic Review of Machine Learning Techniques for Cattle Identification: Datasets, Methods and Future Directions.txt","Increased biosecurity and food safety requirements may increase demand for
efficient traceability and identification systems of livestock in the supply
chain. The advanced technologies of machine learning and computer vision have
been applied in precision livestock management, including critical disease
detection, vaccination, production management, tracking, and health monitoring.
This paper offers a systematic literature review (SLR) of vision-based cattle
identification. More specifically, this SLR is to identify and analyse the
research related to cattle identification using Machine Learning (ML) and Deep
Learning (DL). For the two main applications of cattle detection and cattle
identification, all the ML based papers only solve cattle identification
problems. However, both detection and identification problems were studied in
the DL based papers. Based on our survey report, the most used ML models for
cattle identification were support vector machine (SVM), k-nearest neighbour
(KNN), and artificial neural network (ANN). Convolutional neural network (CNN),
residual network (ResNet), Inception, You Only Look Once (YOLO), and Faster
R-CNN were popular DL models in the selected papers. Among these papers, the
most distinguishing features were the muzzle prints and coat patterns of
cattle. Local binary pattern (LBP), speeded up robust features (SURF),
scale-invariant feature transform (SIFT), and Inception or CNN were identified
as the most used feature extraction methods.","The demand for e cient traceability and identiÔ¨Åcation systems for livestock is growing due to biosecurity and food safety requirements in the supply chain. The advanced technologies of machine learning and computer vision have been applied in precision livestock management, including critical disease detection, vaccination, production management, tracking, health monitoring, and animal wellbeing monitoring (Awad, 2016). ‚ÄòCattle identiÔ¨Åcation‚Äô refers to ‚Äòcattle detection‚Äô and ‚Äòcattle recognition‚Äô (Mahmud et al., 2021). Cattle identiÔ¨Åcation systems start from manual identiÔ¨Åcation to automatic identiÔ¨Åcation with the help of image processing. Traditional cattle identiÔ¨Åcation systems such as ear tagging (Awad, 2016), ear notching (Neary and Yager, 2002), and electronic devices (RuizGarcia and Lunadei, 2011) have been used for individual identiÔ¨Åcation in cattle farming. Disadvantages of these individual identiÔ¨Åcation methods include the possibility of losses, duplication, electronic device malfunctions, and fraud of the tag number (Rossing, 1999; Roberts, 2006). These are the issues and challenges for cattle identiÔ¨Åcation in livestock farm management. With the advent of computervision technology, cattle visual features have gained popularity for cattle identiÔ¨Å cation (Kusakunniran and Chaiviroonjaroen, 2018; Andrew et al., 2016, 2017; de Lima Weber et al., 2020). Visual feature based cattle identiÔ¨Åcation systems are used to detect and classify di erent breeds or individuals based on a set of unique features. In recent years, machine learning (ML) and deep learning (DL) approaches have been widely used for automatic cattle identiÔ¨Åcation using visual features (Andrew et al., 2016; Tharwat et al., 2014b; Andrew et al., 2019; Qiao et al., 2019; Li et al., 2021b). ML and DL are subÔ¨Åelds of artiÔ¨Åcial intelligence that can solve complex problems for automatic decisionmaking. ML is mainly divided into two approaches, such as supervised learning and unsupervised learning. The supervised ML approach is deÔ¨Åned by its use of labelled datasets, whereas the unsu pervised learning uses ML algorithms to analyse and cluster unlabeled datasets. An unsupervised ML approach can detect hidden patterns in data without human supervision (Janiesch et al., 2021). DL approaches are useful in areas with large and highdimensional datasets. Thus, DL models are usually outperformed over traditional ML models in the area of text, speech, image, video, and audio data processing (LeCun et al., 2015). There are two main steps in the development of ML and DL models. In the Ô¨Årst step, a training dataset is used to train the model, and in the second, the model is validated using a separate validation dataset. Thus, a trained model is created that is later used on the test dataset to determine its performance based on the test dataset. The dataset used for ML models includes the features and their corresponding outcomes or labels. The features are extracted from the input data using a feature extraction method. DL algorithms can automatically extract highlevel features from the dataset and learn from these features. Although the implementation of the ML and DL models is straightforward, there are some challenges with selecting algorithms, tuning parameters, and features for better prediction accuracy (Janiesch et al., 2021). Several important review studies have been completed in livestock farm management. Some recent literature re lzheng@csu.edu.au (Lihong Zheng), dave.swain@terracipher.com (Dave L. Swain), shmcgrath@csu.edu.au (Shawn McGrath), jmedway@csu.edu.au (Jonathan Medway) iiviews have addressed various research challenges in livestock farming, such as identiÔ¨Åcation, tracking, and health monitoring, using tagbased, ML, and DL approaches. Recently, Awad (2016) and Kumar and Singh (2020) reviewed the literature on using di erent classical and visual biometrics methods for cattle identiÔ¨Åcation and tracking. Li et al. (2021a) reviewed the deep learningbased approaches for classiÔ¨Åcation, object detection and segmentation, pose es timation, and tracking for di erent kinds of animals such as cattle, pigs, sheep, and poultry. A systematic literature review based on applying ML and DL approaches in precision livestock farming by Garcia et al. (2020) focused on grazing and animal health. Qiao et al. (2021) summarised the ML and DL approaches in precision cattle farming for cattle identiÔ¨Åcation, body condition score evaluation, and live weight estimation. They reviewed a small number of articles (n =13) related to cattle identiÔ¨Åcation using ML and DL approaches. Mahmud et al. (2021) conducted a systematic literature review showing the recent progress of DL applications for cattle identiÔ¨Åcation and health mon itoring. Their review included only a few articles related to cattle identiÔ¨Åcation. Moreover, these review articles focused on the combination of di erent types of challenges (e.g., tracking, pose estimation, weight estimation, identi Ô¨Åcation, and detection) solved by tagbased, ML, and DL methods in precision livestock farming. Thus, they lack in providing a comprehensive review on cattle identiÔ¨Åcation. Also, the existing review articles lack information on ML and DL applications combined for cattle identiÔ¨Åcation as they cover partly either ML or DL for cattle identiÔ¨Åcation. Moreover, the details of the cattle dataset for identiÔ¨Åcation are not discussed. In this context, an extensive systematic literature review is needed, particularly for the challenge of cattle identiÔ¨Åcation addressed by ML and DL approaches. Also, the details of the dataset used in the relevant articles need to be discussed, and the current trend of using ML and DL techniques in cattle identiÔ¨Åcation and future research opportunities with challenges need to be identiÔ¨Åed. This systematic literature review (SLR) aims to summarise and analyse the ML and DL applications used exten sively in cattle identiÔ¨Åcation. A total of 55 articles for cattle identiÔ¨Åcation and detection have been selected for this SLR. The reviewed articles are Ô¨Årst summarised, and then the datasets used in the selected articles are discussed. We then analyse the reviewed articles for trends in using ML and DL approaches for cattle identiÔ¨Åcation in recent years before presenting the feature extraction methods and performance evaluation metrics extracted from the reviewed articles. Finally, the challenges and future research directions in this Ô¨Åeld are discussed. 2. Methodology","Cattle identification systems are used for individual identification of cattle. However, these systems are not suitable for large-scale livestock farming. In this paper, we propose a novel approach for automatic cattle identification using deep learning and machine learning approaches. The proposed approach is based on deep learning and machine learning techniques. The proposed approach is based on a novel deep learning approach based on deep learning. The proposed approach is based on a novel deep learning approach based on deep learning. The proposed approach is based on a novel deep learning approach. The",cool!
247,Attended Temperature Scaling: A Practical Approach for Calibrating Deep Neural Networks.txt,"Recently, Deep Neural Networks (DNNs) have been achieving impressive results
on wide range of tasks. However, they suffer from being well-calibrated. In
decision-making applications, such as autonomous driving or medical diagnosing,
the confidence of deep networks plays an important role to bring the trust and
reliability to the system. To calibrate the deep networks' confidence, many
probabilistic and measure-based approaches are proposed. Temperature Scaling
(TS) is a state-of-the-art among measure-based calibration methods which has
low time and memory complexity as well as effectiveness. In this paper, we
study TS and show it does not work properly when the validation set that TS
uses for calibration has small size or contains noisy-labeled samples. TS also
cannot calibrate highly accurate networks as well as non-highly accurate ones.
Accordingly, we propose Attended Temperature Scaling (ATS) which preserves the
advantages of TS while improves calibration in aforementioned challenging
situations. We provide theoretical justifications for ATS and assess its
effectiveness on wide range of deep models and datasets. We also compare the
calibration results of TS and ATS on skin lesion detection application as a
practical problem where well-calibrated system can play important role in
making a decision.","Deep Neural Networks (DNNs) show dramatically ac curate results on challenging tasks such as computer vision [14, 39] speech recognition [12] and medical diagnosis [2]. However, in realworld decisionmaking applications, accu racy is not the only element considered and the conÔ¨Ådence of the network is also essential for having a secure and re liable system. In DNNs, conÔ¨Ådence usually corresponds to the output of a softmax layer, which is typically interpreted as the likeliness (probability) of different class occurrence. Label = DermatoÔ¨Åbroma Pred. = DermatoÔ¨Åbroma ConÔ¨Ådence = 0.99 Calib. ConÔ¨Ådence = 0.98 Label = BCC Pred. = BCC ConÔ¨Ådence = 0.99 Calib. ConÔ¨Ådence = 0.99 Label = Melanocytic nevus Pred. = Melanocytic nevus ConÔ¨Ådence = 0.99 Calib. ConÔ¨Ådence = 0.98 Label = Melanoma Pred. = Bowen ConÔ¨Ådence = 0.91 Calib. ConÔ¨Ådence = 0.54 Label = Bowen Pred. = BCC ConÔ¨Ådence = 0.90 Calib. ConÔ¨Ådence = 0.46 Label = Benign keratosis Pred. = Bowen ConÔ¨Ådence = 0.89 Calib. ConÔ¨Ådence = 0.48 Figure 1: Output of the medical assistant system for skin anomaly detection (more details in Section 6.2). Before calibration, the conÔ¨Ådence of the system is high for both correctly and misclassiÔ¨Åed samples. After applying calibra tion, the network keeps the conÔ¨Ådence of correctly classi Ô¨Åed samples high while decrease the conÔ¨Ådence of misclas siÔ¨Åed samples. Most of the time, this value is far from the true probability of each class occurrence, with a tendency to get overconÔ¨Å dent (i.e., output of one class close to 1 and other classes close to 0). In such case, we usually consider the DNN not to be wellcalibrated. Calibration in DNNs is a recent challenge in machine learning community which was not an issue previously for shallow neural networks [35]. Gua et al. [13] studies the role of different parameters which makes a neural network uncalibrated. They show a deep network 1arXiv:1810.11586v3  [cs.LG]  8 May 2019which Ô¨Ånds the optimal weights by minimizing Negative Log Likelihood (NLL) [10] loss function, can reach to the higher accuracy when it gets overÔ¨Åtted to NLL. However, the side effect of overÔ¨Åtting to NLL is to make the network overconÔ¨Ådent. Having calibrated network is important for realworld applications. In a selfdriving car [5] deciding about trans ferring the control of the car to the human observer is taken regarding to the conÔ¨Ådence of the detected objects. In med ical care systems [17], the deadly diseases can be missed when they are wrongly detected as a nonproblematic case with high conÔ¨Ådence. Calibration adds more information to the system which consequences reliability. Figure 1 com pares the output of an overconÔ¨Ådent system and calibrated one for misclassiÔ¨Åed and correctly classiÔ¨Åed samples in a skin lesion detection system. The calibrated networks de crease the conÔ¨Ådence in the case of wrongly detected sam ples while preserves the conÔ¨Ådence for most of correctly classiÔ¨Åed ones. Calibration methods for DNNs are widely investigated in recent literature and can be categorized into two main directions: 1probabilistic approaches 2measure based approaches. Probabilistic approaches generally in clude approximated Bayesian formalism [29, 32, 27, 4]. In practice, the quality of predictive uncertainty in Bayesian based methods relies heavily on the accuracy of sampling approximation and correctly estimated prior distribution. Despite of signiÔ¨Åcant achievements in distribution estima tion, these approaches are complex and suffer from a signif icant computational burden, time and memory complexity. Comparatively, measurebased approaches are more practical. They are generally postprocessing methods that do not need to retrain the network to make it cali brated. Temperature Scaling (TS) [13] is the stateofthe art measurebased approach that comparing to the others, achieves better calibration with minimum computational complexity (optimizing only one parameter Tto soften the softmax) which makes it the most appealing method in prac tice. It also preserves the accuracy rate of the network that can be degraded during the calibration phase. In TS, the best Tparameter is found by minimizing NLL loss with respect ing toTon validation set. One big challenge in real scenar ios to apply TS is gathering enough number of samples for validation set and labeling them by an expert to calibrate an already pretrained model. Asking nonprofessional ex perts to label the samples for decreasing the expenses, may bring labeling noise to the validation set, especially in med ical applications. Therefore being robust to the noise and size of validation set is a rising need in calibration appli cations. Despite of TS interesting results, when the DNN is highly accurate, or the validation set is small or contains noisy labels, TS cannot calibrate the DNN successfully. Contribution: In this paper, we propose a new TS fam ily method which is called Attended Temperature Scaling(ATS) to make a better adjustment of conÔ¨Ådence in DNNs. Comparing to TS algorithm, ATS preserves the time and memory complexity advantage of classic TS as well as intact accuracy while it brings better calibration. It spe cially works properly in the case of smallsize validation set, highly accurate DNNs and validation set with labeling noise in which TS is not functioning well. We analyze the oretically ATS and demonstrate why it works better in these situations. 2. Related Works","Deep Neural Networks (DNNs) show dramatic accuracy on challenging tasks such as computer vision, speech recognition, and medical diagnosis. However, in real-world decision-making applications, the confidence of the network is also important for having a secure and reliable system. In this paper, we propose a novel temperature-scaled calibration method for DNNs. Temperature-scaled calibration is a measure-based approach that optimizes the weights by minimizing Negative Log Likelihood (NLL) loss function. Temperature-scaled calibration is the network calibration method. The temperature-",cool!
312,Multi-Dialect Arabic BERT for Country-Level Dialect Identification.txt,"Arabic dialect identification is a complex problem for a number of inherent
properties of the language itself. In this paper, we present the experiments
conducted, and the models developed by our competing team, Mawdoo3 AI, along
the way to achieving our winning solution to subtask 1 of the Nuanced Arabic
Dialect Identification (NADI) shared task. The dialect identification subtask
provides 21,000 country-level labeled tweets covering all 21 Arab countries. An
unlabeled corpus of 10M tweets from the same domain is also presented by the
competition organizers for optional use. Our winning solution itself came in
the form of an ensemble of different training iterations of our pre-trained
BERT model, which achieved a micro-averaged F1-score of 26.78% on the subtask
at hand. We publicly release the pre-trained language model component of our
winning solution under the name of Multi-dialect-Arabic-BERT model, for any
interested researcher out there.","The term Arabic language is better thought of as an umbrella term, under which it is possible to list hundreds of varieties of the language, some of which are not even mutually comprehensible. Nonetheless, such varieties can be grouped together with varying levels of granularity, all of which correspond to the various ways the geographical extent of the Arab world can be divided, albeit loosely. Despite such diversity, up until recently, such varieties were strictly conÔ¨Åned to the spoken domains, with Modern Standard Arabic (MSA) dominating the written forms of communication all over the Arab world. However, with the advent of social media, an explosion of written content in said varieties have Ô¨Çooded the internet, attracting the attention and interest of the wide Arabic NLP research community in the process. This is evident in the number of held workshops dedicated to the topic in the last few years. In this paper we present and discuss the strategies and experiments we conducted to achieve the Ô¨Årst place in the Nuanced Arabic Dialect IdentiÔ¨Åcation (NADI) Shared Task 1 [ 1], which is dedicated to dialect identiÔ¨Åcation at the country level. In section 2 we discuss related work. This is followed by section 3 in which we discuss the data used to develop our model. Section 4 discusses the most signiÔ¨Åcant models we tested and tried in our experiments. The details and results of said experiments can be found in section 5. The analysis and discussion of the results can be obtained in section 6 followed by our conclusions in section 7. 2 Related Work","Arabic is a language with hundreds of varieties, some of which are not even mutually comprehensible. Despite such diversity, up until recently, such varieties were strictly confined to the spoken domains, with Modern Standard Arabic (MSA) dominating the written forms of communication all over the Arab world. However, with the advent of social media, an explosion of written content in said varieties have flooded the internet, attracting the attention and interest of the wide Arabic NLP research community in the process. In this paper we present and discuss the strategies and experiments we conducted to achieve the first place in the Nu",cool!
403,Speaker attribution with voice profiles by graph-based semi-supervised learning.txt,"Speaker attribution is required in many real-world applications, such as
meeting transcription, where speaker identity is assigned to each utterance
according to speaker voice profiles. In this paper, we propose to solve the
speaker attribution problem by using graph-based semi-supervised learning
methods. A graph of speech segments is built for each session, on which
segments from voice profiles are represented by labeled nodes while segments
from test utterances are unlabeled nodes. The weight of edges between nodes is
evaluated by the similarities between the pretrained speaker embeddings of
speech segments. Speaker attribution then becomes a semi-supervised learning
problem on graphs, on which two graph-based methods are applied: label
propagation (LP) and graph neural networks (GNNs). The proposed approaches are
able to utilize the structural information of the graph to improve speaker
attribution performance. Experimental results on real meeting data show that
the graph based approaches reduce speaker attribution error by up to 68%
compared to a baseline speaker identification approach that processes each
utterance independently.","Speaker diarization is the problem of ‚Äúwho spoke when‚Äù, i.e., grouping the segments of a long audio recording into speaker homogeneous clusters. The conventional speaker diarization task assumes no prior knowledge of speakers‚Äô identities, so it is basically a clustering problem without speaker identiÔ¨Åcation. However, there are scenarios, such as meeting transcription, where voice proÔ¨Åles of speakers are available and the identi Ô¨Åcation of speakers is required. This task is called ‚Äòspeaker attribution‚Äô in this paper. A straightforward approach is to build a multiclass classiÔ¨Åer from the speaker proÔ¨Åles, and then clas sify the test segments onebyone. A drawback of this approach is treating test segments independently without considering the context when making predictions. For example, those test seg ments that are similar to each other should be assigned to the same speaker. Instead of predicting the speaker label for each speech segment independently, we propose to use graphbased semi supervised learning methods that use the structural information among speech segments within a session. Each speech seg ment, either from proÔ¨Åle audio or test audio, is represented as a node on a graph for each session. The feature of each *Work done by the Ô¨Årst author during internship at Microsoft. (a) Extract dvectors  (b) Build a graph (c) Add proÔ¨Åle segments  (d) Label prediction Figure 1: Overview of the proposed method: (a) extract d vectors of audio segments with a pretrained speaker embed ding model; (b, c) build a graph of audio segments based on pairwise similarities of the corresponding dvectors, using both proÔ¨Åle and test audio segments; (d) predict labels for test audio segments by graphbased semisupervised learning meth ods. node is represented by a Ô¨Åxeddimensional speaker embedding, e.g., dvectors [1, 2, 3, 4, 5, 6, 7], extracted from the corre sponding speech segment. Segments from the proÔ¨Åle audio are treated as labeled nodes while those from the test audio are un labeled nodes. The speaker attribution task can then be solved as a graphbased semisupervised learning problem, which can now utilize the structural information of the graph in order to improve the accuracy of classifying the test nodes. The intu ition is that if two nodes are similar to each other and share common neighbors on the graph, they are likely to have the same speaker label. Recently, graphbased methods have also been successfully applied on the conventional speaker diariza tion problem [8]. An overview of the proposed method is shown in Figure 1. First, we apply a pretrained speaker embedding model to ex tract dvectors for speech segments, which are obtained by uni formly segmenting the audio of one session after applying voice activity detection (V AD). Then a graph is built with both speech segments from proÔ¨Åle audio and test audio as shown in Fig ure 1(c), on which each node is a speech segment whose average dvector is used as the feature vector of the node. The weight of each edge represents the similarity between the correspondarXiv:2102.03634v1  [eess.AS]  6 Feb 2021ing segment pair. The proÔ¨Åle segments are labeled nodes on the graph, while test segments are unlabeled. To classify the unla beled nodes, we apply two graphbased semisupervised learn ing methods: a graph Laplacian regularizationbased approach (label propagation) and a graph embeddingbased approach by GNNs. Experiments show that both of these two methods sig niÔ¨Åcantly outperform the classiÔ¨Åcationbased methods on real multiparty meetings and present great potential for realworld applications. Our contributions can be summarized as: ‚Ä¢ we propose the Ô¨Årst solution to speaker attribution with speaker proÔ¨Åles through graphbased semisupervised learning methods; ‚Ä¢ we study two graphbased methods ‚Äì label propagation and GNNbased ‚Äì and their applications on a speaker attribution pipeline; and ‚Ä¢ we evaluate the proposed methods on real meeting data. Results show that the graphbased methods signiÔ¨Åcantly outperform the baseline method and present great poten tial for realworld applications. 2. Related work","We propose a graph-based semi-supervised learning method for speaker attribution, which uses the structural information among speech segments within a session. The graph-based semi-supervised learning method is based on a graph-based regularization approach (label propagation) and a graph embedding-based approach by GNNs. The graph-based semi-supervised learning method uses the structural information among speech segments within a session to improve the accuracy of classifying the test segments. The graph-based semi-supervised learning method is a graph-based regularization-based approach (label propag",cool!
90,Neural Ensemble Search via Bayesian Sampling.txt,"Recently, neural architecture search (NAS) has been applied to automate the
design of neural networks in real-world applications. A large number of
algorithms have been developed to improve the search cost or the performance of
the final selected architectures in NAS. Unfortunately, these NAS algorithms
aim to select only one single well-performing architecture from their search
spaces and thus have overlooked the capability of neural network ensemble
(i.e., an ensemble of neural networks with diverse architectures) in achieving
improved performance over a single final selected architecture. To this end, we
introduce a novel neural ensemble search algorithm, called neural ensemble
search via Bayesian sampling (NESBS), to effectively and efficiently select
well-performing neural network ensembles from a NAS search space. In our
extensive experiments, NESBS algorithm is shown to be able to achieve improved
performance over state-of-the-art NAS algorithms while incurring a comparable
search cost, thus indicating the superior performance of our NESBS algorithm
over these NAS algorithms in practice.","Recent years have witnessed a surging interest in design ing wellperforming architectures for different tasks. These architectures are typically manually designed by human experts, which requires numerous trials and errors during this manual design process and therefore is prohibitively costly. Consequently, the increasing demand for develop ing wellperforming architectures in different tasks makes this manual design infeasible. To avoid such human efforts, Zoph and Le [2017] have introduced neural architecture search (NAS) to help automate the design of architectures.Since then, a number of NAS algorithms [Pham et al., 2018, Liu et al., 2019, Chen et al., 2019] have been developed to improve the search efÔ¨Åciency (i.e., search cost) or the search effectiveness (i.e., generalization performance of their Ô¨Ånal selected architectures) in NAS. However, conventional NAS algorithms aim to select only one single architecture from their search spaces and have thus overlooked the capability of other candidate architec tures from the same search spaces in helping improve the performance achieved by their Ô¨Ånal selected single architec ture. That is, neural network ensembles are widely known to be capable of achieving an improved performance com pared with a single neural network in practice [Cortes et al., 2017, Gal and Ghahramani, 2016, Lakshminarayanan et al., 2017]. This naturally begs the question: How to select best performing neural network ensembles with diverse archi tectures from a NAS search space in order to improve the performances achieved by existing NAS algorithms? To the best of our knowledge, only limited efforts (e.g., [Zaidi et al., 2021]) have been devoted to this problem in the NAS lit erature. Unfortunately, the neural ensemble search (NES) algorithm based on random search or evolutionary algorithm in [Zaidi et al., 2021] requires excessive search costs to se lect their Ô¨Ånal neural network ensembles, which will not be affordable in resourceconstrained scenarios. To this end, this paper introduces a novel algorithm, namely neural ensemble search via Bayesian sampling (NESBS), to effectively and efÔ¨Åciently select the wellperforming neural network ensemble with diverse architectures from a search space. We Ô¨Årstly represent the search space as a supernet fol lowing conventional oneshot NAS algorithms and then use the model parameters inherited from this supernet after its model training to estimate the singlemodel performances and also the ensemble performance of independently trained architectures (Sec. 3.1). Next, since both singlemodel per formances and diverse model predictions affect the Ô¨Ånal en semble performance according to [Zhou, 2012], we propose to use a variational posterior distribution of architectures based on a trained supernet to characterize these two factors, Accepted for the 38thConference on Uncertainty in ArtiÔ¨Åcial Intelligence (UAI 2022).arXiv:2109.02533v2  [cs.LG]  17 Jun 2022i.e., singlemodel performances and diverse model predic tions (Sec. 3.2). We then introduce two novel Bayesian sampling algorithms based on the posterior distribution of architectures, i.e., Monte Carlo sampling (MC Sampling) andStein Variational Gradient Descent with regularized di versity (SVGDRD), to effectively and efÔ¨Åciently select en sembles with both competitive singlemodel performances and compelling diverse model predictions (Sec. 3.3), which is also guaranteed to be able to achieve impressive ensem ble performances [Zhou, 2012]. Lastly, we use extensive experiments to show that our NESBS algorithm is indeed able to select wellperforming neural network ensembles effectively and efÔ¨Åciently in practice (Sec. 4). 2 RELATED WORKS & BACKGROUND","This paper introduces a novel neural ensemble search via Bayesian sampling (NESBS) algorithm to effectively and efficiently select the well-performing neural network ensembles with diverse architectures from a search space. We firstly represent the search space as a supernet based on conventional oneshot NAS algorithms and then use the model parameters inherited from this supernet to estimate the single-model performances and the ensemble performance of independently trained architectures. Next, we use a variational posterior distribution of architectures based on a trained supernet to characterize the ensemble performance of",cool!
482,On Multi-head Ensemble of Smoothed Classifiers for Certified Robustness.txt,"Randomized Smoothing (RS) is a promising technique for certified robustness,
and recently in RS the ensemble of multiple deep neural networks (DNNs) has
shown state-of-the-art performances. However, such an ensemble brings heavy
computation burdens in both training and certification, and yet under-exploits
individual DNNs and their mutual effects, as the communication between these
classifiers is commonly ignored in optimization. In this work, starting from a
single DNN, we augment the network with multiple heads, each of which pertains
a classifier for the ensemble. A novel training strategy, namely Self-PAced
Circular-TEaching (SPACTE), is proposed accordingly. SPACTE enables a circular
communication flow among those augmented heads, i.e., each head teaches its
neighbor with the self-paced learning using smoothed losses, which are
specifically designed in relation to certified robustness. The deployed
multi-head structure and the circular-teaching scheme of SPACTE jointly
contribute to diversify and enhance the classifiers in augmented heads for
ensemble, leading to even stronger certified robustness than ensembling
multiple DNNs (effectiveness) at the cost of much less computational expenses
(efficiency), verified by extensive experiments and discussions.","Deep neural networks (DNNs) have been widely applied in various Ô¨Åelds [1, 2], but at the same time showed devas tating vulnerability to adversarial samples. That is, images crafted with maliciouslydesigned perturbations, namely adversarial examples, can easily mislead welltrained DNNs into wrong predictions [3, 4]. To resist adversarial ex amples, there has been a series of empirical defenses against adversarial attacks, e.g., adversarial training and its variants[5, 6, 7]. Besides, various methods for certiÔ¨Åed robustness [8, 9, 10] have also attracted increasing atten tion in recent years, where the robustness of DNNs for images perturbed by Gaussian noises N(0;2I)is focused. A certiÔ¨Åablyrobust classiÔ¨Åer guarantees that for any input x, the predictions are kept constant within its perturbed neighborhood bounded commonly by the `2norm. Randomized smoothing [11, 12, 13] (RS) is considered as one of the most effective `2norm certiÔ¨Åablyrobust defenses. With RS, any base classiÔ¨Åer (DNN) can be formulated into a smoothed and certiÔ¨Åablyrobust one by giving the most probable prediction over the Gaussian corruptions of the input. Cohen et al. [12] Ô¨Årstly proved a tight robustness guarantee of RS and achieved stateoftheart results on largescale DNNs and complex datasets. Various related works have been developed for a more robust base classiÔ¨Åer with RS. These works can be mainly categorized as two types: extra regularization terms [14, 15, 16] and enhanced data augmentation techniques [17, 18]. Recently, the ensemble of multiple DNNs being the base classiÔ¨Åer in RS has shown great potentials in certiÔ¨Åed robust ness. The weighted logit ensemble of several DNNs trained from different random seeds [19] or maxmargin ensemble of Ô¨Ånetuning multiple pretrained DNNs with extra constraints [20] have achieved signiÔ¨Åcant improvements in higher certiÔ¨Åed accuracy on the predictions for N(x;2I). However, such an ensemble scheme demands considerably higher computational sources to train multiple large DNNs. In particular, the resulting computational burden becomes more pronounced in the certiÔ¨Åcation phase, because certifying each sample xcan even require tens of thousands of samarXiv:2211.10882v1  [cs.LG]  20 Nov 2022(ùê∑ùëí1,ùê∑‚Ñé1) backbone, ùëî head, ‚Ñé1 head, ‚Ñé2 head, ‚Ñé3 head, ‚Ñé4 head, ‚Ñé5forward propagation in a 5head DNN communication flow in our circular teaching (large certified radii) (small certified radii) Head‚Ñéùëò+1istaught by ‚Ñéùëòwith via  selfpaced learning based on smoothed losses . (ùê∑ùëí2,ùê∑‚Ñé2) (ùê∑ùëí3,ùê∑‚Ñé3) (ùê∑ùëí4,ùê∑‚Ñé5) (ùê∑ùëí5,ùê∑‚Ñé5) ùê∑ùëí:easy samples  ùê∑‚Ñé: hard samples  (ùê∑ùëíùëò,ùê∑‚Ñéùëò) top1 top2top1 top2Figure 1: An illustration on the proposed SPACTE on a 5head DNN. In our efÔ¨Åcient structure for the ensemble, a common backbone gis shared by the augmented 5 heads h1;;h5, which are trained to be mutually orthogonal to each other for diversiÔ¨Åed classiÔ¨Åers. In the novel training with circular communication Ô¨Çow between classiÔ¨Åers, the augmented head hk+1are optimized via the circularteaching by its peer classiÔ¨Åer hkwith easy and hard samples in relation to the certiÔ¨Åed radii ( h0:=h5). plings withinN(x;2I)[12], resulting in numerous inferences in forward propagation. In this case, such certiÔ¨Åcation time gets exacerbated approximately by the number of ensembled DNNs. Apart from the sacriÔ¨Åce of efÔ¨Åciency, these ensemble methods also ignore a straightforward and yet crucial fact that the current training of ensembled DNNs underexploits the potentials of each individual DNN at hand and omits the mutual effects of each other in promoting the certiÔ¨Åed robustness. Starting from an individual DNN, we in this paper augments the standard DNN with multiple heads. On such a multihead structure basis we propose a novel ensemble training scheme, namely the SelfPAced CircularTEaching (SPACTE) , where multiple classiÔ¨Åers through mutuallyorthogonal heads get ensembled and trained jointly with the common backbone coupling all heads. In the proposed circular teaching scheme, all heads are simultaneously opti mized and meanwhile communicate with each other, instead of the separate training of individual DNNs in ensem ble [19]. To be speciÔ¨Åc, during the joint training, each augmented head teaches its next neighboring head with selected samples by our modiÔ¨Åed selfpaced learning , which progresses the optimization from ‚Äúeasy‚Äù samples to ‚Äúhard‚Äù ones with speciÔ¨Åc considerations to certiÔ¨Åed robustness. In the following, the proposed SPACTE is elaborated: ‚Ä¢ In the modelling, our mutuallyorthogonal heads leverage the essential idea of inducing diversity among classiÔ¨Åers for variance reduction as in the classic ensemble [21, 22, 23], but manage to greatly alleviate computational burdens both in storage and time expenses. ‚Ä¢ The concept of communication between ensembled classiÔ¨Åers is introduced in a joint optimization, enabling information exchange to exploit potentials of individual classiÔ¨Åers and providing a novel perspective on the interaction in ensemble training. ‚Ä¢ In the optimization, each head selects the minibatch of samples to teach its next neighboring head to update. The sample selection in such a circularteaching scheme is conducted with selfpaced learning [24, 25], which proceeds the optimization from ‚Äúeasy‚Äù samples to ‚Äúhard‚Äù ones, speciÔ¨Åcally deÔ¨Åned in relation to the proposed smoothed loss for certiÔ¨Åed robustness. Rather than the ensemble after the separate training of multiple DNNs, the proposed method instead considers a novel ensemble based training method for a single DNN with augmented heads. On the one hand, the common highlevel features are expected to be exploited by all classiÔ¨Åers in the ensemble; such highlevel feature learning can be reÔ¨Çected in the shared backbone in our multihead structure. On the other hand, classiÔ¨Åers in ensemble methods are designed to be diverse from each other and are capable of learning different subtle features, for the sake of greater reliability and variance reduction [19]; in our method, such diversity is embodied from two folds: (i) the parameters of the augmented heads are imposed to be mutually orthogonal, and (ii) the optimization of each head is conducted via the minibatch samples that are taught by the selfpaced learning of its neighboring head, not by itself. SPACTE is compatible with all singlemodelbased methods, which can be plugged into SPACTE via regularization [14, 15, 16] or data augmentation [17, 18]. Extensive experiments demonstrate that the proposed SPACTE greatly improves the certiÔ¨Åed robustness over the stateoftheart (SOTA) methods with much less computation overhead than the existing 2ensemble methods. SPACTE acts as an efÔ¨Åcient and effective ensemble method, which successfully exempliÔ¨Åes a bridge connecting the methods of improving single models and integrating multiple models for certiÔ¨Åed robustness. In the following, Sec. 2 outlines related works. Section 3 introduces the proposed SPACTE, in terms of the multihead structure and its optimization. Section 4 presents extensive experiments on the certiÔ¨Åed robustness from different aspects. Section 5 brieÔ¨Çy concludes the paper. 2 Related work","Deep neural networks (DNNs) have been widely applied in various fields, but at the same time showed a significant vulnerability to adversarial samples. To resist adversarial attacks, various empirical defenses against adversarial samples have attracted increasing attention in recent years, where the robustness of DNNs for images perturbed by Gaussian noises N(0;2I)is focused. Randomized smoothing (RS) is considered as one of the most effective 2norm certifiably robust defense. However, the ensemble of multiple DNNs being the base class",cool!
371,Joint Noise-Tolerant Learning and Meta Camera Shift Adaptation for Unsupervised Person Re-Identification.txt,"This paper considers the problem of unsupervised person re-identification
(re-ID), which aims to learn discriminative models with unlabeled data. One
popular method is to obtain pseudo-label by clustering and use them to optimize
the model. Although this kind of approach has shown promising accuracy, it is
hampered by 1) noisy labels produced by clustering and 2) feature variations
caused by camera shift. The former will lead to incorrect optimization and thus
hinders the model accuracy. The latter will result in assigning the intra-class
samples of different cameras to different pseudo-label, making the model
sensitive to camera variations. In this paper, we propose a unified framework
to solve both problems. Concretely, we propose a Dynamic and Symmetric
Cross-Entropy loss (DSCE) to deal with noisy samples and a camera-aware
meta-learning algorithm (MetaCam) to adapt camera shift. DSCE can alleviate the
negative effects of noisy samples and accommodate the change of clusters after
each clustering step. MetaCam simulates cross-camera constraint by splitting
the training data into meta-train and meta-test based on camera IDs. With the
interacted gradient from meta-train and meta-test, the model is enforced to
learn camera-invariant features. Extensive experiments on three re-ID
benchmarks show the effectiveness and the complementary of the proposed DSCE
and MetaCam. Our method outperforms the state-of-the-art methods on both fully
unsupervised re-ID and unsupervised domain adaptive re-ID.","Person reidentiÔ¨Åcation (reID) attempts to Ô¨Ånd matched pedestrians of a query in a nonoverlapping camera sys *Equal contribution: yangfx@stu.xmu.edu.cn ‚Ä†Corresponding author: fzhiming.luo, szligg@xmu.edu.cn (a)InitialState(c)w/MetaCam(b)w/oMetaCam(1)(2)(3)(4)Figure 1. Illustration of camera variations in person reID (a) and the comparison between methods trained without or with the pro posed MetaCam ((b) and (c), respectively). Different colors rep resent different identities and different shapes indicate different camera IDs. At the initial state, samples under different cameras may suffer from appearance changes of viewpoints ((1) & (2)), il lumination ((3) & (4)), and other factors. Without considering this factor, the trained model may be sensitive to camera variations and may wrongly split intraclass features to different centers. Our proposed MetaCam enables the model to learn camerainvariant features by explicitly considering crosscamera constraint. tem. Recent CNNbased works [31, 35] have achieved impressive accuracies, but their success is largely depen dent on sufÔ¨Åcient annotated data that require a lot of label ing cost. In contrast, it is relatively easy to obtain a large collection of unlabeled person images, fostering the study of unsupervised reID. Commonly, unsupervised reID can be divided into two categories depending on whether us ing an extra labeled data, i.e., unsupervised domain adap tation (UDA) [37, 49, 7] and fully unsupervised reID (FU) [19, 20, 42]. In UDA, we are given a labeled source domain and an unlabeled target domain. The data of two domains have different distributions and are used to train a model that generalizes well on the target domain. The fully unsupervised reID is more challenging since only un labeled images are provided to train a deep model. In this study, we will mainly focus on this setting, and call it as unsupervised reID for simplicity. 1arXiv:2103.04618v1  [cs.CV]  8 Mar 2021Recent popular unsupervised reID methods [19, 34, 20, 42] mainly adopt clustering to generate pseudolabel for un labeled samples, enabling the training of the model in a su pervised manner. Pseudolabel generation and model train ing are applied iteratively to train an accurate deep model. Despite their effectiveness, existing methods often ignore two important factors during this process. (1) Noisy labels brought by clustering . The clustering algorithm cannot en sure intrasamples to be assigned with the same identity, which inevitably will introduce noisy labels in the labeling step. The errors of noisy labels will be accumulated during training, thereby hindering the model accuracy. (2) Feature variations caused by camera shifts . As shown in Fig. 1, intraclass samples under different cameras may suffer from the changes of viewpoint ( e.g., (1) and (2) in Fig. 1), illu mination ( e.g., (3) and (4) in Fig. 1), and other environmen tal factors. At the start of unsupervised learning (‚Äúinitial state‚Äù in Fig. 1), these signiÔ¨Åcant variations will cause large gaps between the intraclass features of different cameras. In such a situation, it is difÔ¨Åcult for the clustering algorithm to cluster samples with the same identity from all cameras into the same cluster. Consequently, training with the sam ples mined by the clustering will lead to unexpected sep aration for intraclass samples (‚Äúw/o MetaCam‚Äù in Fig. 1) and the model might be sensitive to camera variations dur ing testing. In this paper, we attempt to solve the above two crucial problems for robust unsupervised reID. For the Ô¨Årst issue , we try to adopt the technique of learn ing with noisy labels (LNL) for robust training. LNL is wellstudied in image classiÔ¨Åcation, however, most of the existing methods cannot be directly applied to our sce nario. This is because the centers and pseudolabel will change after each clustering step. To overcome this difÔ¨Å culty, this paper proposes a dynamic and symmetric cross entropy loss (DSCE) for unsupervised reID. We maintain a feature memory to store all image features, which enables us to dynamically build new class centers and thus to be adaptable to the change of clusters. With the dynamic cen ters, a robust loss function is proposed for mitigating the negative effects caused by noisy samples. For the second issue , we attempt to explicitly consider camerainvariant constraint during training. Indeed, person reID is a crosscamera retrieval process, aiming to learn a model that can well discriminate samples under different cameras. If a model trained with samples from some of the cameras can also generalize to distinguish samples from the rest of the cameras, then, we could obtain a model that can extract the intrinsic feature without cameraspeciÔ¨Åc bias and is robust to camera changes. Inspired by this, this paper in troduces a cameraaware metalearning (MetaCam), which aims to learn camerainvariant representations by simulat ing the crosscamera reidentiÔ¨Åcation process during train ing. SpeciÔ¨Åcally, MetaCam separates the training data intometatrain and metatest, ensuring that they belong to en tirely different cameras. We then enforce the model to learn camerainvariant features under both camera settings by up dating the model with metatrain and validating the updated model with metatest. Along with learning from different meta divisions, the model is gradually optimized to gener alize well under all cameras. As shown in Fig. 1, Meta Cam gathers intraclass features of different cameras into the same cluster, which is beneÔ¨Åcial for mining pseudo label and learning camerainvariant features. In summary, our main contributions can be summarized in three aspects: ‚Ä¢ We propose a dynamic and symmetric loss (DSCE), which enables the model to be robust to noisy labels during training in the context of changes of clusters and thus promotes the model performance. ‚Ä¢ We propose a cameraaware metalearning algorithm (MetaCam) for adapting the shifts caused by cameras. By simulating the crosscamera searching process dur ing training, MetaCam can effectively improve the ro bustness of the model to camera variations. ‚Ä¢ We introduce a uniÔ¨Åed framework that can jointly take advantage of the proposed DSCE and MetaCam, en abling us to learn a more robust reID model. Extensive experiments on three largescale datasets demonstrate the advantages of our DSCE and MetaCam for the fully unsupervised reID. Besides, further experiments on the UDA setting show that our method can also achieve state of the art. 2. Related Work","Unsupervised person reidentification (reID) is a popular problem in deep learning. Despite its effectiveness, existing methods often ignore two crucial issues. (1) Noisy labels brought by clustering. The clustering algorithm cannot ensure that intrasamples with the same identity from all cameras are assigned to the same cluster. Consequently, the model will be sensitive to camera variations during training. In this paper, we propose a dynamic and symmetric cross entropy loss (DSCE) for unsupervised reID. The proposed MetaCam enables the model to learn camera-invari",cool!
505,Tracking e-cigarette warning label compliance on Instagram with deep learning.txt,"The U.S. Food & Drug Administration (FDA) requires that e-cigarette
advertisements include a prominent warning label that reminds consumers that
nicotine is addictive. However, the high volume of vaping-related posts on
social media makes compliance auditing expensive and time-consuming, suggesting
that an automated, scalable method is needed. We sought to develop and evaluate
a deep learning system designed to automatically determine if an Instagram post
promotes vaping, and if so, if an FDA-compliant warning label was included or
if a non-compliant warning label was visible in the image. We compiled and
labeled a dataset of 4,363 Instagram images, of which 44% were vaping-related,
3% contained FDA-compliant warning labels, and 4% contained non-compliant
labels. Using a 20% test set for evaluation, we tested multiple neural network
variations: image processing backbone model (Inceptionv3, ResNet50,
EfficientNet), data augmentation, progressive layer unfreezing, output bias
initialization designed for class imbalance, and multitask learning. Our final
model achieved an area under the curve (AUC) and [accuracy] of 0.97 [92%] on
vaping classification, 0.99 [99%] on FDA-compliant warning labels, and 0.94
[97%] on non-compliant warning labels. We conclude that deep learning models
can effectively identify vaping posts on Instagram and track compliance with
FDA warning label requirements.","The proportion of the U.S. high school students who report using ecigarettes (aka vaping devices) declined in 2020 during the COVID19 pandemic. In 2020, 19.6% of high school students (3.02 million) reported current ecigarette use, compared to 27.5% (4.11 million) of high students who reported using ecigarettes in 2019 (Wang, NeÔ¨Ä, et al. 2020). However, despite this recent decline, during 2019  2020, the use of youthappealing, lowpriced disposable ecigarette devices increased approximately 1,000% (from 2.4% to 26.5%) among high school current ecigarette users (ibid.). In addition, more than eight in 10 teenage ecigarette users reported consuming Ô¨Çavored ecigarettes (ibid.). Ecigarettes can harm the adolescent brain and increase susceptibility to tobacco addic tion (Health et al. 2016; Fraga 2019; Wang, Gentzke, et al. 2019). As a result, youth who use ecigarettes are more likely to subsequently try combustible cigarettes (The U.S. Food and Drug Administration 2018). Beyond addiction, ecigarettes pose a risk of breathing diÔ¨Éculties, inÔ¨Çamma tory reactions, lowered defense against pathogens and lung diseases (RedÔ¨Åeld 2019; The U.S. Food and Drug Administration 2019). Exposure to visual posts featuring ecigarette products on social media, including promotional images and videos, has been associated with increased ecigarette use among U.S. adolescents (Wang, Gentzke, et al. 2019; King et al. 2016; Maloney et al. 2016; Pokhrel et al. 2018; Kim et al. 2019). Instagram, one of the most popular social media platforms among adolescents, is considered the largest source of ecigarette social media advertisements (cite). Ecigarette stores, distributors and social media inÔ¨Çuencers  users with large followings who post vaping content on behalf of ecigarette brands  promote ENDS (Electronic Nicotine Delivery Sys tems) products on Instagram and other social media (Vassey et al. 2020). In August 2018, the U.S. Food & Drug Administration (FDA) introduced a requirement that e cigarette advertisements, including social media imagery, contain a prominent warning label that reminds consumers that nicotine is addictive. The FDA requires that the warning statement ap pears on the upper portion of the advertisement, occupies at least 20 percent of the advertisement area, and be printed in in conspicuous and legible at least 12point sans serif (e.g. Helvetica or Arial bold) font size (The U.S. Food and Drug Administration 2020). Several studies (Vassey et al. 2020; Laestadius et al. 2020) evaluated compliance with the 2018 FDA requirements for warning labels on Instagram. Vassey et al. (2020) manually reviewed 2,000 images posted in 2019 and found that only 7% included FDAmandated warning statements. Posts uploaded from locations within the 1arXiv:2102.04568v1  [cs.SI]  8 Feb 2021U.S. had the highest prevalence of warning labels, while posts uploaded from other countries were less likely to include warnings. Most of the international posts featured vaping products distributed in the U.S. and would therefore still be subject to compliance with the FDA warninglabel regula tions (Vassey et al. 2020). Laestadius et al. (2020) manually reviewed 1,000 posts collected in late 2018early 2020 and found that only 13% included warning statements. Both studies (Vassey et al. 2020; Laestadius et al. 2020) conducted qualitative analysis to assess the presence of warning statements on a small sample size of Instagram posts and used binary classiÔ¨Åcation (presence or absence of a warning statement) without reporting warning labels that were too small or in the wrong place, which would constitute a partial compliance with the FDA requirements. This study addresses the limitation of prior research by developing an automated deep learning image classiÔ¨Åcation capable of quickly and accurately measuring compliance with the FDA requirements for warning labels on a large sample size. i.e. thousands of images. We tested whether advanced deep learning techniques could provide an eÔ¨Äective, automated method to track vapingrelated posts on Instagram and evaluate compliance with FDA warning label requirements. 2 Related work","In 2018, the FDA required that e-cigarette advertisements, including social media imagery, contain a prominent warning label that reminds consumers that nicotine is addictive. Several studies evaluated compliance with the FDA requirements for warning labels on Instagram. However, these studies used binary classification to assess the presence of warning statements on a small sample size of Instagram posts and used binary classification without reporting warning labels that were too small or in the wrong place, which would constitute a partial compliance with the FDA requirements. This study addresses the limitation of prior research by developing an automated deep learning techniques capable of quickly and accurately",cool!
201,Learning from Noisy Labels with Distillation.txt,"The ability of learning from noisy labels is very useful in many visual
recognition tasks, as a vast amount of data with noisy labels are relatively
easy to obtain. Traditionally, the label noises have been treated as
statistical outliers, and approaches such as importance re-weighting and
bootstrap have been proposed to alleviate the problem. According to our
observation, the real-world noisy labels exhibit multi-mode characteristics as
the true labels, rather than behaving like independent random outliers. In this
work, we propose a unified distillation framework to use side information,
including a small clean dataset and label relations in knowledge graph, to
""hedge the risk"" of learning from noisy labels. Furthermore, unlike the
traditional approaches evaluated based on simulated label noises, we propose a
suite of new benchmark datasets, in Sports, Species and Artifacts domains, to
evaluate the task of learning from noisy labels in the practical setting. The
empirical study demonstrates the effectiveness of our proposed method in all
the domains.","With the recent advancements in deep convolutional neural networks (CNN) [ 11], learning from a clean large scale dataset, e.g., ImageNet [ 17], has been very successful in various visual recognition tasks. However, collecting such datasets is time consuming and expensive. Recent efforts, therefore, have been focused on building and learn ing from an Internetscale dataset with noisy labels such as YFCC100M [ 20] and YouTube8M1. These datasets have the potential of leveraging a seemingly inÔ¨Ånite amount of images and videos on the Internet. But labels in those datasets are noisy in terms of visual correlation and hence challenging for the learning process. Previous approaches tried to circumvent the problem of learning from noisy samples by treating them as statistical outliers and discarding them using some variants of outlier detection methods [ 16,12,18]. However, in practice, it is typical that noisy samples are not statistical outliers but rather some form of signiÔ¨Åcant mass. Existing approaches have shown to produce inferior results on these cases. For ex 1https://research.google.com/youtube8m/ Knowledge	Graph	  Large	Noisy	Dataset	 Bird	 Vertebrate	 Mammal	 Rabbit	Lagomorph	 Leporidae	phylum	 class	 order	 family	Fish	 Impala	 Beetle	Arthropod	 phylum	 Figure 1: Overview of the proposed system to learn from noisy labels by leveraging a knowledge graph. The left panel shows the large scale noisy dataset, out of which we collect a small set of images with clean labels to guide the learning process. On the right panel, we demonstrate the knowledge graph on the species domain constructed from DBpediaWikipedia. ample, images collected by searching polysemy words, such asapple , will show a multimodal distribution of visual con cepts, in which case statistical outlier detection techniques will fail to Ô¨Ågure out which concept to be associated with. Another example, images labeled with basketball on Flickr may contain a signiÔ¨Åcant amount of group shots, selÔ¨Åes, and photos taken before or after the game ‚Äì these are less visually relevant to the event itself but regardless forming a signiÔ¨Åcant mass; statistically, they are not outliers. Recently, Hinton et al. [9] introduced the concept of ‚Äúdis tillation‚Äù to transfer the knowledge learned from one model (expert or teacher model) to another (a lightweight student model), by treating the prediction results produced from the Ô¨Årst model (usually more expensive to train) as the ‚Äúsoft target‚Äù labels for training the second light model (usually trained in a more constrained setting). Inspired by this, we propose a new technique that uses a similar distillation pro cess to learn from noisy datasets. In our scenario, we assume that we have a small clean dataset and a large noisy dataset. The small clean dataset can either be an existing public dataset or labeled from part of the noisy data. Our goal is to use the large amount of noisy data to augment the small 1 arXiv:1703.02391v2  [cs.CV]  7 Apr 2017clean dataset to learn a better visual representation and clas siÔ¨Åer. Concretely, we distill the knowledge learned the small clean dataset to facilitate learning a better model from the entire noisy dataset. This is different from Hinton et al. [9], where distillation is used to transfer knowledge from a better model (e.g., an ensemble model) to guide learning a light but typically inferior model. Furthermore, we propose to integrate a knowledge graph to guide the distillation process, where rich relational information among labels are explicitly encoded in the learning process. This helps the algorithm to disambiguate noisy labels by, e.g., knowing that apple can either be a fruit category or a company name. To evaluate our technique, we collect a suite of new datasets on three topics: sports ,species , and artifacts . Our dataset contains a total of 480K images from 780 class cat egories and exhibit the realworld labeling noise we men tioned above. We build a textual knowledge graph on top of these three topics based on Wikipedia, where labels are related by their deÔ¨Ånitions. We show that, our proposed dis tillation process, as well as leveraging the knowledge graph to guide the distillation process, can achieve the best results on our datasets compared with competing methods. In summary, we make the following contributions: ‚Ä¢We propose a novel algorithm based on a distillation process to learn from noisy data, with a theoretical analysis under some conditions. ‚Ä¢We leverage a knowledge graph to guide the distillation process to further ‚Äúhedge the risk‚Äù of learning from noisy labels. ‚Ä¢We collect several new benchmark datasets with real world labeling noises. We extensively compare with different baselines and show that our proposed algo rithm achieves the best results2. 2. Related Work","We propose a novel method to learn from noisy datasets by leveraging a knowledge graph. In this paper, we propose a distillation process to transfer the knowledge learned from a better model to a lighter model. We use the knowledge learned from the small clean dataset to augment the large noisy dataset to learn a better visual representation and classification. Furthermore, we leverage a knowledge graph to guide the distillation process, where rich relational information among labels is explicitly encoded in the learning process. We show that, our proposed distillation process can achieve the best results on our datasets, compared with competing",cool!
533,Convolutional Neural Associative Memories: Massive Capacity with Noise Tolerance.txt,"The task of a neural associative memory is to retrieve a set of previously
memorized patterns from their noisy versions using a network of neurons. An
ideal network should have the ability to 1) learn a set of patterns as they
arrive, 2) retrieve the correct patterns from noisy queries, and 3) maximize
the pattern retrieval capacity while maintaining the reliability in responding
to queries. The majority of work on neural associative memories has focused on
designing networks capable of memorizing any set of randomly chosen patterns at
the expense of limiting the retrieval capacity. In this paper, we show that if
we target memorizing only those patterns that have inherent redundancy (i.e.,
belong to a subspace), we can obtain all the aforementioned properties. This is
in sharp contrast with the previous work that could only improve one or two
aspects at the expense of the third. More specifically, we propose framework
based on a convolutional neural network along with an iterative algorithm that
learns the redundancy among the patterns. The resulting network has a retrieval
capacity that is exponential in the size of the network. Moreover, the
asymptotic error correction performance of our network is linear in the size of
the patterns. We then ex- tend our approach to deal with patterns lie
approximately in a subspace. This extension allows us to memorize datasets
containing natural patterns (e.g., images). Finally, we report experimental
results on both synthetic and real datasets to support our claims.","The ability of neuronal networks to memorize a large set of patterns and reliably retrieve them in the presence of noise, has attracted a large body of research over the past three decades to design artiÔ¨Åcial neural associative memories with sim ilar capabilities. Ideally, a perfect neural associative memory should be able to learn patterns, have a large pattern retrieval capacity and be noisetolerant . This problem, called ‚Äùassociative memory"", is in spirit very similar to reliable informa tion transmission faced in communication systems where the goal is to efÔ¨Åciently decode a set of transmitted patterns over a noisy channel. Despite this similarity and common methods deployed in both Ô¨Åelds (e.g., graphical models, iterative algorithms, to name a few), we have witnessed a huge gap between the efÔ¨Åciency achieved by them. More speciÔ¨Åcally, by deploying mod ern coding techniques, it was shown that the number of reliably transmitted patterns over a noisy channel can be made exponential inn, the length of the patterns. This was particularly achieved by imposing redundancy among transmitted patterns. In contrast, the maximum number of patterns that can be reliably memorized by most current neural networks scales linearly in the size of the patterns. This is due to the common assumption that a neural network should be able to memorize anysubset of patterns drawn randomly from the set of all possible vectors of length n(see, for example HopÔ¨Åeld, 1982, Venkatesh and Psaltis, 1989, Jankowski et al., 1996, Muezzinoglu et al., 2003). Recently, Kumar et al. (2011) suggested a new formulation of the problem where only a suitable set of patterns was considered for storing. To enforce the set of constraints, they formed a bipartite graph (as opposed to a complete graph considered in the earlier work) where one layer feeds the patterns to the network and the other takes into account the inherent structure. The role of bipartite graph is indeed similar to the Tanner graphs used in modern coding techniques (Tanner, 1981). Using this model, Kumar et al. (2011) provided evidence that the resulting network can memorize an exponential number of patterns at the expense of cor recting only a single error during the recall phase. By introducing a multilayer 2structure, Salavati and Karbasi (2012) could further improve the error correction performance to constant number of errors. In this paper, similar to the model considered by Kumar et al. (2011), we only consider a set of patterns with weak minor components, i.e., patterns that lie in a subspace. By making use of this inherent redundancy We introduce the Ô¨Årst convolutional neural associative network with prov ably exponential storage capacity. We prove that our architecture can correct a linear fraction of errors. We develop an online learning algorithm with the ability to learn patterns as they arrive. This property is speciÔ¨Åcally useful when the size of the dataset is massive and patterns can only be learned in a streaming manner. We extend our results to the case where patterns lie approximately in a sub space. This extension in particular allows us to efÔ¨Åciently memorize datasets containing natural patterns. We evaluate the performance of our proposed architecture and the learning algorithm through numerical simulations. We provide rigorous analysis to support our claims. The storage capacity and error correction performance of our method is informationtheoretically order optimum, i.e., no other method can signiÔ¨Åcantly improve the results (except for constants). Our learning algorithm is an extension of the subspace learning method proposed by Oja and Kohonen (1988), with an additional property of imposing the learned vectors to be sparse . The sparsity is essential during the noiseelimination phase. The remainder of this paper is organized as follows. In Section 2 we provide an overview of the related work in this area. In Section 3 we introduce our notation and formally state the problems that is the focus of this work, namely, learning phase, recall phase, and storage capacity. We present our learning algorithm in Section 4 and our error correction method in Section 5. Section 6 is devoted to the pattern retrieval capacity. We then report our experimental results on synthetic and natural datasets in Section 7. Finally, all the proofs are provided in Section 8. 2 Related Work","The ability of neural networks to learn patterns and reliably retrieve them in the presence of noise has attracted a large body of research over the past three decades to design artificial neural associative memories with similar capabilities. However, the efficiency achieved by most current neural networks scales linearly in the size of the patterns. In this paper, we introduce the first convolutional neural associative network with a proven exponential storage capacity. We prove that our architecture can correct a linear fraction of errors. We develop an online learning algorithm with the ability to learn patterns as they arrive. This property is particularly useful when the size",cool!
120,Semantic scene synthesis: Application to assistive systems.txt,"The aim of this work is to provide a semantic scene synthesis from a single
depth image. This is used in assistive aid systems for visually impaired and
blind people that allow them to understand their surroundings by the touch
sense. The fact that blind people use touch to recognize objects and rely on
listening to replace sight, motivated us to propose this work. First, the
acquired depth image is segmented and each segment is classified in the context
of assistive systems using a deep learning network. Second, inspired by the
Braille system and the Japanese writing system Kanji, the obtained classes are
coded with semantic labels. The scene is then synthesized using these labels
and the extracted geometric features. Our system is able to predict more than
17 classes only by understanding the provided illustrative labels. For the
remaining objects, their geometric features are transmitted. The labels and the
geometric features are mapped on a synthesis area to be sensed by the touch
sense. Experiments are conducted on noisy and incomplete data including
acquired depth images of indoor scenes and public datasets. The obtained
results are reported and discussed.","In order to accomplish daily tasks, people involve their Ô¨Åve senses, namely sight, hearing, taste, smell and touch. Being deprived of one of these senses will complicate the pro cess of a given task; it will reduce human autonomy, independence and even privacy; the visually impaired Ô¨Ånd di fÔ¨Åculties in their daily life. With the limitations of the classical aid systems such as whi te canes, guide dogs and personal assistants; and with the evolution of technology, many commercial and noncommer cial aid systems were proposed in the last decades. Generally, these latter rely on image processing, artiÔ¨Åcia l intelligence techniques and external sensors in order to o ffer help for the visually impaired and blind people to improve th eir independence in many applications. To transmit instructions, scene description or any other ge nerated output, most of the assistive systems use audiobas ed or vibrationbased output devices. It turns out that these l atter hold hearing and are not too informative. Hence, the necessity of providing a semantic labeling for scene unders tanding that can be exploited by the touch sense. In this work, we propose a framework for semantic scene synth esis. From the depth image, the 3D scene is down scaled and semantically mapped into a synthesis area using t he computed labels and the extracted geometric features of the input point cloud. Two main modules are proposed: the c lassiÔ¨Åcation module and the semantic labeling module. The Ô¨Årst module is based on a deep learning architecture to cl assify depth image segments into seven semantic classes.APREPRINT  APRIL 22, 2021 The semantic labeling is inspired from Braille and Kanji sys tems. This latter is mapped into a touchbased synthesis area that can be used for many applications such as in assisti ve systems for visually impaired and blind people. The remaining sections are structured as follows: in sectio n 2, we present related works to objects classiÔ¨Åcation, scen es understanding and semantic labeling for assistive systems . An overview of the proposed system is presented in section 3. In sections 4 and 5, we describe our approaches for the clas siÔ¨Åcation and the semantic labeling module respectively. Conducted experiments are reported and discussed in sectio n 6. Finally, we conclude with the future works (section 7) and a conclusion (section 8). 2 Related Works","In this work, we propose a framework for semantic scene synthesis. From the depth image, the 3D scene is down scaled and semantically mapped into a synthesis area using the computed labels and the extracted geometric features of the input point cloud. The semantic labeling is inspired from Braille and Kanji systems. The semantic labeling is mapped into a touch-based synthesis area that can be used for many applications such as in assistive systems for visually impaired and blind people. The semantic labeling is based on the computed labels and the extracted geometric features of the input point cloud",cool!
448,Random Occlusion-recovery for Person Re-identification.txt,"As a basic task of multi-camera surveillance system, person re-identification
aims to re-identify a query pedestrian observed from non-overlapping multiple
cameras or across different time with a single camera. Recently, deep
learning-based person re-identification models have achieved great success in
many benchmarks. However, these supervised models require a large amount of
labeled image data, and the process of manual labeling spends much manpower and
time. In this study, we introduce a method to automatically synthesize labeled
person images and adopt them to increase the sample number per identity for
person re-identification datasets. To be specific, we use block rectangles to
randomly occlude pedestrian images. Then, a generative adversarial network
(GAN) model is proposed to use paired occluded and original images to
synthesize the de-occluded images that similar but not identical to the
original image. Afterwards, we annotate the de-occluded images with the same
labels of their corresponding raw images and use them to augment the number of
samples per identity. Finally, we use the augmented datasets to train baseline
model. The experiment results on CUHK03, Market-1501 and DukeMTMC-reID datasets
show that the effectiveness of the proposed method.","Person re identification (ReID ) is an important task in many computer vision systems, such as  behavioral understanding, threat detection and video surveillance. Given a query person image, it aims  to reidentify the person observed by non overlapping multiple cameras or across differen t time with a  single camera. The task has drawn significant attention in computer vision community. So far, it is still a  challenge issue for the appearance of a person may suffer dramatic change under different camera views.  Traditional hand craft methods  address the person ReID issue through either finding discriminative  feature representations [14] or exploiting a suitable dis tance metric function  [57]. When feature  representations are obtained, a distance metric function is applied to estimate whet her the paired inputs  are the same pedestrian or not. Recently, enlightened by the success of deep learning technology, a large   number  of works introduce  the technology to address the person ReID issue and achieve  many promising  performances. Most of recent state oftheart person ReID models are based on deep learning technology.  Both the training processes of the models require a large amount of labeled data. However, existing  available public person ReID dataset s are limited in their scale s, especially for  the number of images per identity. For example, the average numbers of images  per identity for large scale ReID datasets like  CUHK03 [8], Market 1501 [9] and DukeMTMC ReID [10] are only 9.6, 17.2 and 23.5, respectively.  Using such scale datasets to train the deep models may lead to over fitting issue and affect the robustness  of them. Moreover, r ely on human annotating is expensive and time consuming, for one not only needs  to draw a bounding box for pedestrians, but also nee ds to assign each of them an ID . Recently , several  GAN based data augmentation approaches [11, 12] have been introduced to alleviate this issue.  However,  due to the appearances and backgrounds of the generated samples are far away from their original  identities , most of approaches above have to assign the generated sample a new label. Therefore, the  number of images per identity cannot  be increased. In order to solve th e above problem, our motivation  is to generate sample s that similar enough but not identic al to their original images and to annotate them   with their original label information , thus the number of images per identity can be increased.   To this end, as shown in Figure 2, firstly, we use block rectangles to randomly occlude the original  ReID training images. Secondly, we use the paired occluded images and their ground truths to train a de occluding  GAN model. Then the trained GAN model is used to generate the de occluded images with  the same labels of their corresponding ground truths. Finally , these generated images are combined with  the original ReID training images to train the baseline model  together .  In summary, we make the following contributions:   (1) We introduce a data augmentation  method  that can generate person images which similar  enough but not identical to the original pedestrian  images;   (2) We attempt to assign the original annotation information to the generated pedestrian  images,  thus increasing the sample number per identity;   (3) We show that the proposed data augmentation method with original annotation information  improved the person ReID accuracy with the baseline mo del.   2. Related work","Person re identification (ReID) is an important task in many computer vision systems, such as behavioral understanding, threat detection and video surveillance. However, the accuracy of ReID is still low compared to the baseline model. In this paper, we introduce a data augmentation method that can generate person images similar enough but not identical to the original pedestrian images and to annotate them with their original label information. We use block rectangles to randomly occlude the original ReID training images, then use the paired occluded images and their ground truths to train a de-occluded model",cool!
368,Opportunities and Challenges of Deep Learning Methods for Electrocardiogram Data: A Systematic Review.txt,"Background:The electrocardiogram (ECG) is one of the most commonly used
diagnostic tools in medicine and healthcare. Deep learning methods have
achieved promising results on predictive healthcare tasks using ECG signals.
Objective:This paper presents a systematic review of deep learning methods for
ECG data from both modeling and application perspectives. Methods:We extracted
papers that applied deep learning (deep neural network) models to ECG data that
were published between Jan. 1st of 2010 and Feb. 29th of 2020 from Google
Scholar, PubMed, and the DBLP. We then analyzed each article according to three
factors: tasks, models, and data. Finally, we discuss open challenges and
unsolved problems in this area. Results: The total number of papers extracted
was 191. Among these papers, 108 were published after 2019. Different deep
learning architectures have been used in various ECG analytics tasks, such as
disease detection/classification, annotation/localization, sleep staging,
biometric human identification, and denoising. Conclusion: The number of works
on deep learning for ECG data has grown explosively in recent years. Such works
have achieved accuracy comparable to that of traditional feature-based
approaches and ensembles of multiple approaches can achieve even better
results. Specifically, we found that a hybrid architecture of a convolutional
neural network and recurrent neural network ensemble using expert features
yields the best results. However, there are some new challenges and problems
related to interpretability, scalability, and efficiency that must be
addressed. Furthermore, it is also worth investigating new applications from
the perspectives of datasets and methods. Significance: This paper summarizes
existing deep learning research using ECG data from multiple perspectives and
highlights existing challenges and problems to identify potential future
research directions.","The electrocardiogram (ECG/EKG) is one of the most commonly used noninvasive diagnostic tools for recording thephysiologicalactivitiesoftheheartoveraperiodoftime. ECG data can aid in the diagnosis of many cardiovascular abnormalities, such as premature contractions of the atria (PAC) or ventricles (PVC), atrial Ô¨Åbrillation (AF), myocar dial infarction (MI), and congestive heart failure (CHF). In recent years, we have witnessed the rapid development of portableECGmonitorsinthemedicalÔ¨Åeld,suchastheHolter monitor [129], and wearable devices in various healthcare areas, such as the Apple Watch. As a result, the amount of ECG data requiring analysis has grown too rapidly for human cardiologists to keep up. Therefore, analyzing ECG dataautomaticallyandaccuratelyhasbecomeahotresearch topic. Additionally, many emerging applications, such as biometrichumanidentiÔ¨Åcationandsleepstaging,canbeim plemented based on ECG data. sdhong1503@gmail.com (S. Hong); joy_yuxi@pku.edu.cn (Y. Zhou); sjy1203@pku.edu.cn (J. Shang); cao.xiao@iqvia.com (C. Xiao); jimeng.sun@gmail.com (J. Sun) ORCID(s):Traditionally, automatic ECG analysis has relied on di agnostic golden rules. As shown in the top of Figure 1, this is a twostage method that requires human experts to engi neer useful features based on raw ECG data, which are re ferredtoas‚Äúexpertfeatures‚Äù,andthendeploydecisionrules or other machine learning methods to generate Ô¨Ånal results. Expert features can be categorized [69] into statistical fea tures(suchasheartratevariability[19],sampleentropy[3], and coeÔ¨Écients of variation and density histograms [172]), frequencydomainfeatures[151,106],andtimedomainfea tures (such as the Philips 12 lead ECG Algorithm [139]). Inpractice,expertfeaturesareautomaticallyextractedusing computerbased algorithms. However, they are still insuf Ô¨Åcient because they are limited by data quality and human expert knowledge [157, 161, 50]. Recently, deep learning methods have achieved promis ingresultsinmanyapplicationareas,suchasspeechrecogni tion,computervision,andnaturallanguageprocessing[89]. The main advantage of deep learning methods is that they do not require an explicit feature extraction step using hu man experts, as shown in the bottom of Figure 1. Instead, feature extraction is performed automatically and implicitly bydeeplearningmodelsbasedontheirpowerfuldatalearn Shenda Hong et al.: Preprint submitted to Elsevier Page 1 of 16arXiv:2001.01550v3  [eess.SP]  30 Apr 2020Opportunities and Challenges of Deep Learning for ECG Data Results ResultsExpert FeaturesTraditionalMethodsDeep LearningMethodsExpertMachine Learning Models Deep Neural Networks ECG	Data Figure 1: Comparisons between traditional methods and deep learning methods. ing capabilities and Ô¨Çexible processing architectures. Some studieshaveexperimentallydemonstratedthatdeeplearning features are more informative than expert features for ECG data [67, 69]. The performance of deep learning methods isalsosuperiortothatoftraditionalmethodsonmanyECG analysistasks,suchasdiseasedetection[30]andsleepstag ing [42]. Although some papers have reviewed machine learning methodsforECGdata[121](2019),cardiacarrhythmiade tection using deep learning [136] (2019), and deep learn ing methods for ECG data [135] (2018), there have no sys tematic reviews focusing on deep learning methods, which weconsidertobepromisingmethodsforminingECGdata. Therefore, we believe it is crucial to conduct a systematic reviewofexistingdeeplearningmethodsforECGdatafrom theperspectivesofmodelarchitecturesandapplicationtasks. Challengesandproblemsrelatedtothecurrentresearchsta tus are discussed, which should provide inspiration and in sights for future work. 2. Method","The electrocardiogram (ECG/EKG) is one of the most commonly used non-invasive diagnostic tools for recording the physiological activities of the heart. However, the amount of ECG data requiring analysis has grown too rapidly for human cardiologists to keep up. Therefore, analyzing ECG dataautomatically and accurately has become a hot research topic. In this paper, we review existing deep learning methods for ECG data, which we consider to be promising methods for ECG data. We also discuss challenges and opportunities for future research. In this paper, we review,",cool!
353,Establishment of Neural Networks Robust to Label Noise.txt,"Label noise is a significant obstacle in deep learning model training. It can
have a considerable impact on the performance of image classification models,
particularly deep neural networks, which are especially susceptible because
they have a strong propensity to memorise noisy labels. In this paper, we have
examined the fundamental concept underlying related label noise approaches. A
transition matrix estimator has been created, and its effectiveness against the
actual transition matrix has been demonstrated. In addition, we examined the
label noise robustness of two convolutional neural network classifiers with
LeNet and AlexNet designs. The two FashionMINIST datasets have revealed the
robustness of both models. We are not efficiently able to demonstrate the
influence of the transition matrix noise correction on robustness enhancements
due to our inability to correctly tune the complex convolutional neural network
model due to time and computing resource constraints. There is a need for
additional effort to fine-tune the neural network model and explore the
precision of the estimated transition model in future research.","Deep learning has led to signiÔ¨Åcant breakthroughs in computer vision and image processing and has been applied to a variety of applications, including handwriting recognition [4], satellite image classiÔ¨Åcation [12], IoT crowdsourcing [24], and medical picture classiÔ¨Åcation for illness detection [27]. In the majority of applications, the existence of label noise in the training datasets is one of the primary obstacles to training these deep learning models. Label noise is the presence of labels for classiÔ¨Åcation data in which the labels do not precisely reÔ¨Çect the instance‚Äôs content. Because generating large labelled datasets can be resource heavy and costly, dataset labelling is frequently performed by nonprofessional labellers or automated systems with minimal or no expert supervision [8] [28]. Additionally, in some subject categories, constructing labelled datasets is intrinsically challenging due to the lack of assurance in the image content. For instance, collections of medical photographs frequently exhibit signiÔ¨Åcant observer variability and, consequently, substantial instancedependent label noise [10], as images pose a genuine diagnostic difÔ¨Åculty for specialists. In general, there are three types of label noise: classindependent (sometimes known as ‚Äùuniform‚Äù) noise, classdependent noise, and class and instancedependent noise [6]. This research examines classdependent label noise, in which labels are Ô¨Çipped randomly with a probability dependent on the class. This class noise rate will be referred to as the ‚ÄùÔ¨Çip rate‚Äù in the study. Label noise can dramatically impair classiÔ¨Åcation model performance [5]. Deep neural networks can be more susceptible to label noise because they have a larger propensity to memorise noisy labels, which can have a negative impact on their capacity to generalize [26] [1]. Due to the difÔ¨Åculty of 1arXiv:2211.15279v3  [cs.LG]  24 Apr 2023noisy labels, learning from datasets with noisy labels has been the focus of extensive research in recent years. In Section 2 of this research, we Ô¨Årst summarise and compare a variety of label noise techniques described in the literature. In section 3, we will describe the structure of the neural networks we will employ in our own experimental work, and in Section 4, we will provide our own experimental strategy for addressing label noise. Using backwards noise correction and a transition matrix, we analyse the label noise robustness of two distinct neural networks (LeNet and AlexNet) and compare their performance using this method. The experiment is conducted using three datasets; the Ô¨Årst two are grayscale photos from FashionMINIST, each with distinct Ô¨Çip rate and a transition matrix. The third dataset consists of images with unknown Ô¨Çip rates from CIFAR. We independently estimate the transition matrix for the second dataset. There are three label classes in all three datasets. In Section 5, we give a conclusion of the whole research. 2 Related work","Deep neural networks have been extensively studied for their performance in learning from noisy labels. However, the existence of label noise in the training datasets is one of the primary obstacles to training these models. In this research, we investigate the label noise of class-dependent label noise, in which labels are flipped randomly with a probability dependent on the class. We use backwards noise correction and a transition matrix to analyse the label noise robustness of two distinct neural networks (LeNet and AlexNet) and compare their performance using this method. We also provide our own experimental strategy for addressing label noise.",cool!