We demonstrate that having some amount of trusted training data enables significant robustness gains. To leverage the additional information from trusted labels, we propose a new loss correction and empirically verify it on a number of vision and natural language datasets with label corruption. We demonstrate recovery from extremely high levels of label noise, including the dire case when the untrusted data has a majority of its labels corrupted. Relative to a recent method which also uses trusted data, our method is far more dataefficient and generally more accurate. Our results demonstrate that systems can weather label corruption with access to a small number
Negative Learning for Noisy Labels (NLNL) is an indirect learning method for training CNNs. NLNL trains the CNN that “input image does not belong to this complementary label” and requires an additional sequential step, SelNL. Furthermore, NLNL proposes a three-stage pipeline for filtering noisy data from training data. In this paper, we propose a novel version of NLNL: Joint Negative and Positive Learning (JNPL). JNPL is composed of two loss functions, NL+ and PL+, which solve the issue.
Convolutional neural networks have emerged as promising approaches for graph-structured data. However, the current implementations have limited capability to handle uncertainty in the graph structure, and treat the graph topology as groundtruth information. In this paper, we employ a Bayesian framework and view the observed graph as a realization from a parametric random graph family. The observed adjacency matrix is then used in conjunction with features and labels to perform joint inference. To provide a concrete example of the approach, we focus on a specific random graph model, the assortative mixed memembership
We propose a novel method for automatic facial expression recognition in the wild. Our method uses a single model with approximately 25 million parameters and comparable performance. Our model is trained using an unlabelled subset of the BoLD dataset. To overcome these limitations, we use a teacher-student learning method where the training process is iterated by using the same student again as the teacher. During the training of the student model, noise is injected into the student model to force it to generalize better than the teacher. Results show that the student model generalize better with each iteration.
SemEval2020 Task 11 aims to bridge this gap by detecting the use of propaganda techniques in news articles. We describe the systems we built for these two subtasks. At the core of our systems is RoBERTa, a pretrained model based on the Transformer architecture. However, we improved over RoBERTa by adding extra layers in the neural network architecture, and we further added some post-processing steps. Finally, we combined different models into an ensemble. We describe the systems we built for these two subtasks.
Music tagging is a classification task whose objective is computational understanding of music semantics. The task has attracted music information retrieval (MIR) researchers due to its wide pragmatic usages in many applications. However, there are still two limitations in the current music tagging research: i) chunk-based prediction and ii) a limited amount of labeled data for supervised learning. In this paper, we present Music Tagging Transformer, a semi-supervised music tagging model trained with a chunk-based approach. The semi-supervised learning approach
We consider that either local or global feature learning alone is suboptimal. This is motivated by the human visual system that leverages both global (contextual) and local (saliency) information concurrently. To achieve this, we consider that both local and global feature learning is suboptimal. We address these problems by combining convolutional neural networks (CNNs) with deep learning frameworks. We consider that learning any matching distance metric is intrinsically learn ing a global feature transformation across domains (two disjoint al.
Deep learning has shown transformative power in various real-world applications but is notoriously data-hungry. Despite the increasing popularity of deep learning, it is still difficult to generalize deep learning models to real-world applications. Instance-dependent noise (IDN) is a new topic that aims to reduce the cost of human labor for data annotation. Existing methods mostly focus on the learning with class conditional noise (CCN), which ignores the dependence of noise on the content of individual images, a.k.a. In Clothing1M, the IDN samples are unevenly distributed as
Stock supply and demand are affected by many things. Supply factors include company share issues (e.g., releases new shares to the public), share buybacks (e.g., sellers responsible for pushing shares back into the market, increasing the supply), and investors (e.g., the sellers responsible for pushing shares back into the market, increasing the supply). Hence, we can get these supply and demand factors from the financial news, companies’ newsletters or their annual reports. However, there are a few primary factors that affect the stock price. Hence, we can predict the
Surrogate modeling is a promising technique for estimating the accuracy of computationally expensive models. Neural network (NN) is a well-known surrogate model with a good prediction accuracy. However, NNs have a problem in that different models are created in accordance with the selection of training data sets, initial parameters, and training algorithms. This condition results in various prediction values; thus, NNs are referred to have high prediction variance. Ensembles have been developed to reduce the prediction variance of NNs. Ensembles are constructed through two steps:
Deep neural networks (DNNs) have achieved significant success in computer vision tasks, such as image classification, but they rely heavily on extensive manual annotations. To address this problem, learning with noisy labels (LNL) has been proposed to effectively leverage large-scale yet poorly-annotated datasets while mitigating the effects of model overfitting to noisy labels. In the mainstream pipeline, noise verification strategies are adopted to separate the original training set into a clean set and a noisy set, which contain training samples with clean labels and noise correction strategies are adopted to correct the model. In the noise detection
Color stylization is a powerful tool in video storytelling. However, it is still labor-intensive and time-consuming to create and apply color styles to videos. Existing methods for photorealistic style transfer to videos introduce visible flicker artifacts. To reduce temporal instability, several methods have tried minimizing optical flow warping loss or sequentially propagating intermediate features. To address these challenges, we propose a novel spatiotemporal feature transfer layer (STAdaIN) that is able to transfer style to local regions and generates stylized videos with better temporally coherent results. To
We propose a hybrid network constructed of a Convolutional Neural Network (CNN) combined with a Recurrent Neural Network (RNN). We perform extensive experiments with our proposed network and demonstrate its applicability to a range of scenarios and its extensibility to new languages. We release our code and a large scale training set for LI D systems to the community. We showcase our system in section 3 and evaluate it on extensive experiments in section 4. We release our code and a large scale training set for LI D systems to the
Unsupervised person reidentification (reID) is a retrieval problem involving the search for a person from a gallery of disjoint cameras. Despite the good performance of supervised methods, the annotation difficulty limits the scalability of supervised methods in large-scale cameras. In this paper, we propose a dynamic graph matching (DGM) method to estimate cross-camera labels for unsupervised reID. The proposed method is an iterative process, where a bipartite graph is established, labels are estimated, and then learned distance metrics are learn
We introduce a novel approach to learn from multiple expert annotations to improve the performance of a deep neural network in detecting abnormalities from chest Xray images. The proposed approach aims at estimating the true labels from multiple experts with confidence scores and uses these annotations to train a deep learning-based detector. The proposed approach is simple and can be applied for a wide range of applications in medical imaging and object detection in general. The proposed approach is validated on a simulated and real-world chest Xray dataset with radiologist’s annotations. The proposed approach is simple and
We propose a novel strategy for obtaining semantic labels for aerial imagery. Existing methods for semantic image segmentation are tailored for ground images. We apply these methods to a large dataset of geotagged ground images. We use these images as a form of weak supervision and attempt to predict the semantic labels from an aerial image of the same location. We demonstrate the value of this approach in several ways. First, we demonstrate the value of our training strategy for pre-training a convolutional neural network (CNN) to understand aerial imagery. Second, we demonstrate the value of our approach on large, real-world
Temporal Ensembling is a semi-supervised learning approach that uses an ensemble of the earlier outputs of a neural network as an unsupervised target label. However, there is no explicit study of temporal ensembling in the context of datasets with large intraclass variability. In this work, we investigate this gap by answering the following research questions. First, we investigate whether there is any unique observable behavior with temporal ensembling under different intraclass variances. Second, we investigate the effect of seed selection on performance. Third,
In this paper, we explore the use of structured inference neural networks for modelling concept interactions in a number of different tasks and levels of complexity. We exploit label relations to model multi-label image classification, multi-label video classification and action detection in untrimmed videos. We exploit these rich structures for modelling concept interactions in a number of different tasks and levels of complexity. In particular, we explore the use of structured inference neural networks for performing spatiotemporal structured inference on untrimmed videos. We exploit the hidden state of Long Short-term Memory units with extracted information from our model for performing hierarch
Knowledge distillation (KD) is a special transfer learning technology. It involves training a new model, called the student model, on a separate transfer data set without correct labels or on the original transfer data set where correct labels are available. In the above research, none of the compressed student models are able to outperform their corresponding teacher models. In this paper, we propose a simple yet effective method to select salient information from the outputs of the teacher model. The student model is trained with a multitask learning approach. We introduce a simple yet effective method to select salient information
In the last decade, the volume and quality of Earth observations have increased dramatically, particularly thanks to remote sensing. At the same time, new developments in machine learning (ML) have demonstrated impressive skills in producing complex spatio-temporal processes by efficiently using a huge amount of data. In this paper, we propose a novel approach to predict the system state based on observations, using a surrogate model of an unknown underlying process. The surrogate model is trained on noise-free and complete observations of the system (i.,
Kernel cluster pruning (KCP) is a novel kernel-based filter pruning method for dense labeling neural networks. The main concept of KCP is to identify the kernels with least representationalness in each layer and subsequently remove them. The smallest target to be pruned in KCP is the kernel instead of the filter. The results show that KCP can effectively prune dense labeling neural networks without breaking the original network structure. The KCP method can identify the kernels with least representationalness in each layer and subsequently remove them.
Audio tagging task is a challenging task to predict the presence or absence of certain acoustic events in an audio recording. Traditionally, audio tagging has been addressed with different handcrafted features and shallow-architecture classifiers. Recently, deep learning approaches such as convolutional neural networks (CNNs) have achieved state-of-the-art performance for the audio tagging task. However, due to the limited size of data and noisy labels, general audio tagging systems are confronted with several challenges. In this paper, we aim to build scalable ensemble approach
Image denoising refers to the process of removing noise from a distorted image to recover the clean image. In the real world, noise is a major problem, and it is often difficult to predict the result of noise contamination of a clean signal. Consequently, traditional image denoising approaches try to model image priors and solve optimization problems, e.g., non-local selfsimilarity models (NSS), sparse representations models (SRM) models, gradient-based models (GRM), and gradient-based models (CNNs) models based on deep
Person reidentification (ReID) is an important task in unsupervised domain-adaptive (UDA) person reidentification (ReID). Existing approaches mainly focus on the training and testing of the ReID network, which includes feature pre-training, clustering-based pseudo-label prediction for the target domain data, and feature representation learning/finetuning with the pseudo-labels. However, the clustering-based pseudo-labels usually contain incorrect labels due to the divergence/domain gap between the source and the target domain gaps between the source and the
Self-supervised hand pose estimation with RGB hand images is a challenging and relatively unexplored area. To this end, we propose a novel two-stage strategy to tackle noisy pseudo labels, limited information from cluttered observations, and early-stage divergence. Formally, we name the pipeline HaMuCo, which stands for Hand Multiview Collaborative Learning. The single-view stage provides initial predictions and visual cues from a simple model-based network with the MANO hand model as the decoder
Time series analysis and time series forecasting have been studied to extract information about the data and the underlying dynamics, and to predict the future of observables from past measurements. The first systematic modeling of time series dates back to 1927 when Yule introduced a linear autoregression model to reveal the dynamics of sunspot numbers. The model which writes as u(k+ 1) =m is a linear autoregression model which has been studied for over a century. The first systematic modeling of time series dates back to 1927 when Yule introduced a linear autoregression model to reveal the
Convolutional neural net works (CNNs) are susceptible to designed adversarial attack, even if the attack is imperceptibly small. To mitigate such threat, many algorithms have been proposed to make network to be robust to adversarial attack. However, many of these algorithms rely on opaque gradient which gives robustness against particular attacks only, and can be circumvented by adaptively designed attack. In this paper, we propose a novel naive ensemble method to overcome the overfitting problem. The first problem is the ensemble method. The second problem is dilemma on choosing
Multi-Object Tracking(MOT) is one of the fundamental challenges of computer vision. The most common MOT paradigm is the detection by tracking, which is a method of obtaining detection results in each frame of video using off-the-shelf detection algorithm such as FasterRCNN, DPM, and so on, and organically associating the detection results of the previous frame with the detection results of the current frame and form tracks. There are various approaches in MOT algorithms, but the most of them deals with how to associate the detection patches with the current frame
We propose a novel quantum Fourier convolutional network (QFCN) to speed up the convolutional layer of deep neural networks. The QFCN is a quantum-classical circuit based on a parametric quantum circuit (PQC), which is able to exploit the quantum-classical circuit to avoid some of the quantum noise and also to take advantage of classical computers that are able to perform rapid iterations for model optimization. We demonstrate the potential of our network on the traffic prediction task with spatiotemporal graph convolutional networks and the image classification task with 2D con
The success of supervised learning applications often relies on large-scale well-labeled datasets. However, obtaining high-quality annotations from experts can be costly in terms of time and money. Alternatively, crowdsourcing provides an inexpensive approach to data labeling by hiring worldwide annotators on public platforms like Amazon Mechanical Turk (AMT). However, using these noisy labels in supervised learning may result in an inaccurate classifier. To address this issue, a two-stage approach has been proposed. First, in answer aggregation stage, the latent true labels are estimated. Then,
The neural network model is trained using the stochastic gradient descent (SGD) and its variants in combination with explicit and implicit regularization methods. The explicit regularization restricts the model parameters with a prior knowledge, e.g., weightdecay adds the regularization term into the object function. The implicit regularization updates the model using a subset of the training examples in an iterative manner that imposes the stochastic noise into the optimization process. The label noise is an implicit regularization that replaces the target label of randomly selected examples by random unifo
Person reidentification (reID) is a popular deep learning-based task that attempts to match an individual from one camera view across other, non-overlapping camera views. Most supervised reID methods leverage deep learning via a supervised learning approach. However, this approach requires a large, manually labelled dataset from the target domain, which is not practical in many real-world scenarios. To overcome this limitation, two approaches have been proposed in recent literature: a pure unsupervised approach and the more popular unsupervised domain adaptation approach. In this paper, we explore how to leverage distance metrics that have
Deep learning has made it possible to train end-to-end deep saliency detection models in a data-driven manner. However, the success of these models is limited by the large amount of accurate human labeling. In this paper, we propose a deep latent variable model that we call the noiseaware encoderdecoder to disentangle a clean saliency predictor from noisy labels. In general, a noisy label can be (1) a coarse saliency label generated by algorithmic pipelines using handcrafted features, (2) an imperfect human-annotated sali
Deep neural networks have become the new state of the art in classi cation and prediction of high dimensional data such as images, videos and biosensors. However, training of deep neural networks can be extremely data intensive requiring preparation of large scale datasets collected from multiple entities. Furthermore, deep neural networks require large supercomputing resources and engineering oversight for optimal accuracy in real world applications. In this paper, we propose methods that enable training of neural networks using multiple data sources and a single supercomputing resource. We propose a method that enables training of neural networks using multiple data sources and
Metalearning is a two-tiered learning framework in which an agent learns not only about the specific task, for instance, image classification, but also about how the task structure varies across target domains. In memory augmented neural networks, the input data samples and their labels are bound together in the same memory locations. This often leads to memory interference when performing a task as they have to retrieve a feature of an input from a certain memory location and read only the label information bound to that location. In this work, we design a new memory writing module based on the metalearning architecture.
Offline Signature Verification (OSV) is a challenging problem in computer vision and pattern recognition. Despite impressive advances in computer vision and pattern recognition, several classic problems such as OSV remain challenging. In this paper, we study the generalization of Convolutional Neural Networks (CNNs) for Offline Signature Verification (OSV) using Cross Entropy (CE) loss function for feature learning in CNNs. In the first category, we studied several metric learning losses for feature learning in CNNs and a threshold-based verification was used to classifying whether an input signature is genuine
We present an interpretable deep model for fine-grained recognition. Our model learns a dictionary of object parts, based on which a 2D feature map can be grouped into “part” segments. This is done by comparing pixel features to part representations in a learned dictionary. Moreover, a region-based attention mechanism is used to select a subset of segments for classification. Our model is highly interpretable, as the output segments of the segmented parts are interpreted by the input label. Our model is highly accurate for fine-grained recognition.
We use the class name admiral to crawl an existing large collection of images with textual description. The result is a set of images with novel class labels, but potentially incorrect (noisy). We clean this data using a graph convolutional network (GCN), which learns to predict a class relevance score per image based on connections to clean images in the graph. The clean and the noisy images are then used to learn a classifier, where the noisy examples weighted by relevance. We show that our method outper classifiers.
Neural Architecture Search (NAS) is a powerful platform for discovering superior network architectures. NAS algorithms have achieved state-of-the-art results in several computer vision tasks. However, acquiring large amounts of labeled data is expensive and time-consuming. One promising lead in this direction is self-supervised learning (SSL). SSL learns visual representations from unlabeled data. We propose a Self-Supervised Neural Architecture Search (SSNAS), which unlike conventional NAS techniques, can find novel network architectures without rely on labeled data. We apply SSL to
Deep convolutional neural networks (CNNs) are increasingly being trained with noisy labels. However, the label noise in the training data is often too high and can harm generalization. Hence, it is important to build models that are robust to noisy labels. Most of the existing approaches on LNL can be divided into three main categories. First, several noise-tolerant loss functions (Ghosh et al., 2017; Wang et al., 2019a; Sabuncu, 2018) were proposed that are inherently tolerant to label noise. Second, sample selection methods (also referred
Anomalies are rare data points that are not labeled, and their detection is a challenging task for supervised models. In this paper, we propose a novel supervised anomaly detection method based on conditional generative adversarial networks (cGANs) that is trained based on an ensemble active learning strategy. The discriminators are trained based on a novel ensemble active learning strategy, and the discriminators are trained based on a novel ensemble active learning strategy. The discriminators are trained based on a
Overparameterization helps deep neural networks (DNNs) to generalize better in real-life applications, despite providing them with the capacity to fit almost any set of random labels. However, it is not immediately clear what DNNs learn when trained on random labels. This study aims to provide a partial answer to this question. First, it is imperative to observe how DNNs behave under “extreme” conditions, such as Equal contribution. Second, observing DNNs trained on random labels can provide insights into phenomena that have previously not fully connected networks.
We extend existing methodology for animal movement to estimate the effects of sonar exposure on an unobserved social network of dolphins through the use of dronemeasured movement data. We model the behavior of dolphins through the use of a discrete time continuousspace Gaussian Markov Random Field (GMRF) with an underlying dynamic social network. The two main behavioral components motivating the model are attraction and alignment, both of which are directly related to social structure. We limit our model to modeling the positive behaviors of attraction and alignment. We also allow for repulsive and/anti-al
Portable Document Format (PDF) is one of the most popular types of documents. Despite the lack of awareness of the population, it also became an important attack vector (AV) for computer systems. Despite recent work in machine learning for malware detection, antivirus companies are still largely focusing on handwritten signatures to detect malicious PDF. This requires significant human resources and is rarely efficient at detecting unknown variants or zero-day attacks. In this work, we are using an ensemble of Convolutional Neural Network (CNN) in order to detect any type of PDF
Cell boundary segmentation is critical in many applications including modeling of cell morphogenesis and plant growth. Traditionally, cell segmentation is performed by pre-processing, which is often data dependent and requires parameter tuning. For membrane-tagged images, segmentation is usually carried out with either 3D watershed based methods or 3D level sets. For this problem, the UNet is a fully convolutional network which consists of encoder and decoder parts. The encoder part uses context information to encode raw images into feature maps, and then generate the segmentation. The watershed method is sensitive
In a feed forward neural network, hidden spaces correspond to the space containing the outputs of the hidden nodes at the previous layer for some input. Each hidden space is composed of perceptrons with respect to the previous layer, each of which has a hyperplane decision boundary. Points in the previous space are mapped to a constant function of their distance to this plane, and depending on the activation function, compressed or stretched. This stretching and compressing naturally leads to clustering in hidden spaces. To extract individual features, then, paths should be examined, where each path is de a
Deep Neural Networks (DNNs) have been shown to be effective in many domains, including computer vision, speech processing, and natural language processing. However, label noise in training data can lead to inaccurate classification results. In this work, we introduce a noise model layer on top of our target model to account for label noise in the training set. We study the effect of two different types of label noise; Uniform label flipping (Uni) where a clean label is swapped with another label sampled uniformly at random; and Random label flipping (Rand) where a clean label
Multi-label classification is a challenging task that requires annotators to label all existing categories in a single image. However, the annotation cost becomes tremendous as the number of categories and images in the dataset increases. To alleviate these issues, weakly supervised learning approach in multi-label classification task (WSML) has been taken into consideration. In this paper, we propose a novel approach to train a model with partial labels. We set all unobserved labels as negative and observe that the model first fits into true negative and then starts to memorizing false negative labels. We observe that the
Cattle identification systems are used for individual identification of cattle. However, these systems are not suitable for large-scale livestock farming. In this paper, we propose a novel approach for automatic cattle identification using deep learning and machine learning approaches. The proposed approach is based on deep learning and machine learning techniques. The proposed approach is based on a novel deep learning approach based on deep learning. The proposed approach is based on a novel deep learning approach based on deep learning. The proposed approach is based on a novel deep learning approach. The
Deep Neural Networks (DNNs) show dramatic accuracy on challenging tasks such as computer vision, speech recognition, and medical diagnosis. However, in real-world decision-making applications, the confidence of the network is also important for having a secure and reliable system. In this paper, we propose a novel temperature-scaled calibration method for DNNs. Temperature-scaled calibration is a measure-based approach that optimizes the weights by minimizing Negative Log Likelihood (NLL) loss function. Temperature-scaled calibration is the network calibration method. The temperature-
Arabic is a language with hundreds of varieties, some of which are not even mutually comprehensible. Despite such diversity, up until recently, such varieties were strictly confined to the spoken domains, with Modern Standard Arabic (MSA) dominating the written forms of communication all over the Arab world. However, with the advent of social media, an explosion of written content in said varieties have flooded the internet, attracting the attention and interest of the wide Arabic NLP research community in the process. In this paper we present and discuss the strategies and experiments we conducted to achieve the first place in the Nu
We propose a graph-based semi-supervised learning method for speaker attribution, which uses the structural information among speech segments within a session. The graph-based semi-supervised learning method is based on a graph-based regularization approach (label propagation) and a graph embedding-based approach by GNNs. The graph-based semi-supervised learning method uses the structural information among speech segments within a session to improve the accuracy of classifying the test segments. The graph-based semi-supervised learning method is a graph-based regularization-based approach (label propag
This paper introduces a novel neural ensemble search via Bayesian sampling (NESBS) algorithm to effectively and efficiently select the well-performing neural network ensembles with diverse architectures from a search space. We firstly represent the search space as a supernet based on conventional oneshot NAS algorithms and then use the model parameters inherited from this supernet to estimate the single-model performances and the ensemble performance of independently trained architectures. Next, we use a variational posterior distribution of architectures based on a trained supernet to characterize the ensemble performance of
Deep neural networks (DNNs) have been widely applied in various fields, but at the same time showed a significant vulnerability to adversarial samples. To resist adversarial attacks, various empirical defenses against adversarial samples have attracted increasing attention in recent years, where the robustness of DNNs for images perturbed by Gaussian noises N(0;2I)is focused. Randomized smoothing (RS) is considered as one of the most effective 2norm certifiably robust defense. However, the ensemble of multiple DNNs being the base class
Unsupervised person reidentification (reID) is a popular problem in deep learning. Despite its effectiveness, existing methods often ignore two crucial issues. (1) Noisy labels brought by clustering. The clustering algorithm cannot ensure that intrasamples with the same identity from all cameras are assigned to the same cluster. Consequently, the model will be sensitive to camera variations during training. In this paper, we propose a dynamic and symmetric cross entropy loss (DSCE) for unsupervised reID. The proposed MetaCam enables the model to learn camera-invari
In 2018, the FDA required that e-cigarette advertisements, including social media imagery, contain a prominent warning label that reminds consumers that nicotine is addictive. Several studies evaluated compliance with the FDA requirements for warning labels on Instagram. However, these studies used binary classification to assess the presence of warning statements on a small sample size of Instagram posts and used binary classification without reporting warning labels that were too small or in the wrong place, which would constitute a partial compliance with the FDA requirements. This study addresses the limitation of prior research by developing an automated deep learning techniques capable of quickly and accurately
We propose a novel method to learn from noisy datasets by leveraging a knowledge graph. In this paper, we propose a distillation process to transfer the knowledge learned from a better model to a lighter model. We use the knowledge learned from the small clean dataset to augment the large noisy dataset to learn a better visual representation and classification. Furthermore, we leverage a knowledge graph to guide the distillation process, where rich relational information among labels is explicitly encoded in the learning process. We show that, our proposed distillation process can achieve the best results on our datasets, compared with competing
The ability of neural networks to learn patterns and reliably retrieve them in the presence of noise has attracted a large body of research over the past three decades to design artificial neural associative memories with similar capabilities. However, the efficiency achieved by most current neural networks scales linearly in the size of the patterns. In this paper, we introduce the first convolutional neural associative network with a proven exponential storage capacity. We prove that our architecture can correct a linear fraction of errors. We develop an online learning algorithm with the ability to learn patterns as they arrive. This property is particularly useful when the size
In this work, we propose a framework for semantic scene synthesis. From the depth image, the 3D scene is down scaled and semantically mapped into a synthesis area using the computed labels and the extracted geometric features of the input point cloud. The semantic labeling is inspired from Braille and Kanji systems. The semantic labeling is mapped into a touch-based synthesis area that can be used for many applications such as in assistive systems for visually impaired and blind people. The semantic labeling is based on the computed labels and the extracted geometric features of the input point cloud
Person re identification (ReID) is an important task in many computer vision systems, such as behavioral understanding, threat detection and video surveillance. However, the accuracy of ReID is still low compared to the baseline model. In this paper, we introduce a data augmentation method that can generate person images similar enough but not identical to the original pedestrian images and to annotate them with their original label information. We use block rectangles to randomly occlude the original ReID training images, then use the paired occluded images and their ground truths to train a de-occluded model
The electrocardiogram (ECG/EKG) is one of the most commonly used non-invasive diagnostic tools for recording the physiological activities of the heart. However, the amount of ECG data requiring analysis has grown too rapidly for human cardiologists to keep up. Therefore, analyzing ECG dataautomatically and accurately has become a hot research topic. In this paper, we review existing deep learning methods for ECG data, which we consider to be promising methods for ECG data. We also discuss challenges and opportunities for future research. In this paper, we review,
Deep neural networks have been extensively studied for their performance in learning from noisy labels. However, the existence of label noise in the training datasets is one of the primary obstacles to training these models. In this research, we investigate the label noise of class-dependent label noise, in which labels are flipped randomly with a probability dependent on the class. We use backwards noise correction and a transition matrix to analyse the label noise robustness of two distinct neural networks (LeNet and AlexNet) and compare their performance using this method. We also provide our own experimental strategy for addressing label noise.