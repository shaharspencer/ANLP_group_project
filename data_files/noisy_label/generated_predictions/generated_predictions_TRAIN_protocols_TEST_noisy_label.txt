We propose a new loss correction for supervised learning models that leverages the additional information from trusted labels. We empirically verify it on a number of vision and natural language datasets with label corruption. We demonstrate recovery from extremely high levels of label noise, including the dire case when the untrusted data has a majority of its labels corrupted. Our method is significantly more accurate in problem settings with moderate to severe label noise. Relative to a recent method which also uses trusted data, our method is far more dataefficient and generally more accurate.
Convolutional Neural Networks (CNNs) are widely used in many supervised tasks. However, CNNs' performance relies heavily on the quality of labels. Currently, CNNs are trained with noisy labels, which is of great practical importance. In this paper, we propose a novel version of Negative Learning for Noisy Labels (NLNL): Joint Negative and Positive Learning (JNPL). JNPL is composed of two loss functions, NL+ and PL+, dedicated to filtering noisy data. We develop NLNLNLNLNLNLNLNLNL
In this paper, we present a Bayesian GCNN framework that treats the observed graph as a realization from a parametric random graph family. The observed ad jacency matrix is then used in conjunction with features and labels to perform joint inference. The results show that the approach is more robust to noise and adversarial attacks. We also examine the resilience of the derived architecture to random perturbations of the graph topology. To provide a concrete example of the approach, we focus on a specific random graph model, the assortative mixed mem mership block model,
We propose a novel method for automatic facial expression recognition in the wild using the publicly available AFEW 8.0 dataset. Our method is based on a single model with approximately 25 million parameters and comparable performance. Our method uses a three-level attention mechanism where the training process is iterated by using the same student again as the teacher. During the training of the student, noise is injected into the model to force it to generalize better than the teacher. Results show that the student performs better with each iteration. We use a teacher-student learning method to improve the performance of
The proliferation of disinformation online, commonly known as “fake news”, has given rise to a lot of research on automatic fake news detection. However, most of the efforts have focused on checking whether a piece of information is factually correct, and little attention has been paid to the propaganda techniques that malicious actors use to spread their message. SemEval2020 Task 11 aims to bridge this gap. It focused on detecting the use of propaganda techniques in news articles,1creating a dataset that extends (Da San Martino et.
Music tagging is a classification task whose objective is computational understanding of music semantics. Music tagging models are trained on a given audio excerpt and predict relevant tags (e.g., genre, mood, instrument, decade, region) based on its acoustic characteristics. However, the current music tagging models are still limited by two limitations: i) chunk-based prediction and ii) a limited amount of labeled data for supervised learning. In this paper, we present Music Tagging transformer that is trained with a semi
Person reidentification (reid) is about matching identity classes in detected person bounding box images from non overlapping camera views over distributed open spaces. Existing person reid studies typically focus on either feature representation or matching distance metrics. However, deep learning models, in particular Convolutional Neural Net works (CNN), favour intrinsically in learning global feature representations across domains (two dis joint camera views). This is motivated by the human visual system that leverages both global (contextual) and local (saliency) information concurrently. We consider that either local or global feature
Instance-dependent noise (IDN) is a new topic in deep learning, which is characterized by the distribution of noisy labels near the boundary between ground truth classes. Existing methods mostly focus on the learning with class conditional noise (CCN), which aims to recover a noise transition matrix that contains class-dependent probabilities of a clean label flipping into a noisy label. However, CCN is too ideal for real-world LNL as it ignores the dependence of noise on the content of individual images, asymmetric. In this paper, we follow DivideMix
Stock supply and demand are affected by many things. Supply factors include company share issues (e.g., releases new shares to the public), share buybacks (e.g., sellers responsible for pushing shares back into the market, increasing the supply), and investors (e.g., the investors responsible for pushing shares back into the market, increasing the supply). Hence, if we focus on the major factors, and trace back the historical stock prices, we may be able to predict future stock prices quite accurately. However, it is difficult for a computer scientists to
Surrogate modeling is a technique for estimating the predictive performance of a computationally expensive model with a limited number of simulations or experiments. Neural network (NN) is one of the most promising surrogate models and has a good prediction accuracy. However, NNs have a problem in that different models are created in accordance with the selection of training data sets, initial parameters, and training algorithms. Ensembles that combine prediction values obtained from multiple component models have been developed to reduce the prediction variance of NNs. Ensembles that combine the prediction values
Deep neural networks (DNNs) have been widely used in many computer vision applications. However, they rely heavily on manual annotations. To address the challenges imposed by learning with noisy labels (LNL), previous works have proposed massive strategies, such as noisy label correction, noisy label rejection, and noisy sample reweighing. In this context, there may exist classes with imbalanced noisy or clean samples, especially in real-world noisy datasets such as Clothing1M and Webvision1.0. In this paper, we propose a novel approach to reestimate the predictive reliability of a candidate by naming
Color stylization plays a critical role in modern cine matography and video storytelling. In this paper, we present a novel spatiotemporal feature transfer layer (STAdaIN) that is able to transfer style to local regions and generate temporally coherent stylized videos. To achieve high-speed processing, we extend the recent work of Xia et al. [43], which learns local edge-aware affine transforms from low-resolution content and style in puts, with the results aintain
Intelligent assistants like Siri1or the Google Assistant2rely on Artificial Speech Recognition (ASR). Current ASR systems require users to manually specify the system’s correc t input language to work properly. However, as a sensible preprocessing step we can infer the spoken language using an automatic LI D system. In this paper, we address the problem of language identification from a computer vision perspective. We propose a hybrid network constructed of a Convolutional Neural Network (CNN) combined with a Recurrent Neural Network (RNN). We perform extensive experiments with our
Person reidentification (reID) is a retrieval problem in which the person is linked to a gallery of disjoint cameras. In recent years, reID has been widely used in surveillance applications, where the annotation difficulty limits the scalability of supervised methods. In this paper, we propose a new unsupervised method for reID, based on cross-camera label estimation. In other words, we aim to mine the la bels (matched or unmatched video pairs) across cameras. In this paper, we propose a new method to improve the performance
We introduce a novel approach to learn from multiple annotators to improve the performance of a deep neural network in detecting abnormalities from chest Xray images. The proposed approach aims at estimating the true labels from multiple experts with confidence scores and uses these annotations to train a deep learning-based detector. The proposed approach is simple and can be applied for a wide range of applications in medical imaging and object detection in general. The proposed approach is validated on a simulated and real-world chest Xray dataset with radiologist’s annotations. The proposed approach provides better performance
We propose a novel strategy for obtaining semantic labels from aerial imagery. We use existing methods for semantic image segmentation, which are tailored for ground images, and apply these to a large dataset of geotagged ground images. We use these semantic labels as a form of weak supervision and attempt to predict the ground image segmentation diagonally from an aerial image of the same location. We do not use a parametric transformation between the aerial and ground-level viewpoints. Instead, we use a dense representation, similar in spirit to the general representation, similar in spirit to the general representation,
Deep neural networks have seen broad applications across vision speech and language in recent times. However, the labeling of these datasets is mostly manual, done by humans, due to its higher meticulousness. Among these approaches, Temporal Ensembling (Laine and Aila, 2017) is one of the most promising. However, to the best of our knowledge, there is no explicit study of temporal ensembling in the context of datasets with large intraclass variability. In this work, we investigate the following research questions.
In this paper, we explore the use of structured inference neural networks to model complex label relations in a number of different tasks and levels of complexity. We explore the use of structured inference neural networks for multi-label image classification, multi-label video classification and action detection in untrimmed videos. We also explore the use of structured inference neural networks for a number of other tasks and levels of complexity, such as a sequential input of frames and inferring the corresponding sequence of dense annotations. We extend our previous work to perform hierarchical inference on untrimmed videos. We use our
Knowledge distillation (KD) is a special transfer learning technology. It involves training a new model which is usually called the student model. The student model can be trained on a separate transfer data set without correct labels or on the original training data set where correct labels are available. In the above research, none of the dis tilled student models are able to outperform their corresponding teacher models. In this paper, we propose a simple yet effective method to select valuable information from the outputs of the teacher model. We propose a simple yet
Geophysical fluid dynamics is a domain of science in which the physical and dynamical laws governing the systems are reasonably well known. However, due to the misrepresentation of unresolved smallscale features or to neglected physical processes, parts of the numerical models have to be represented by empirical submodels or parameterizations. Earth observations are thus needed for two tasks: first for model tuning and selection (best realism of the model) and then for data assimilation (best accuracy of the model; i.et et
Deep learning based algorithms have been evolving to achieve significant results in solving complex and varied computer vision applications. However, real world applications often require the deployment of these algorithms on resource-limited mobile/edge devices. Neural net work pruning is a technique to strike the balance between accuracy (performance) and cost (efficiency). Despite the numerous filter pruning algorithms that have been proposed, previous works are mostly evaluated on a sparse labeling classification task. In a practical scenario, dense labeling problems often require real-time processing in real world problems. In this paper, we propose kernel cluster pruning (KCP)
Audio tagging is a task to predict the presence or absence of certain acoustic events in an audio recording. Traditionally, audio tagging has been addressed with different handcrafted features and shallow architecture classifiers including Gaussian mixture models (GMMs) and nonnegative matrix factorizations (NMFs). However, due to the limited size of data and noisy labels, general audio tagging remains as a challenge and falls short of accuracy and robustness. In this paper, we aim to build scalable ensemble approach with taking the noisy label into account. The proposed ensemble learning
Image denoising refers to the process of removing noise from a distorted image to recover the clean image. In the real world, noise contamination of a clean signal is a challenging problem, as there are innumerable possible noise patterns that can contaminate a clean signal. Consequently, traditional denoising approaches try to model image priors and solve optimization problems, e.g., non-local selfsimilarity (NSS) models, sparse representations models, gradient-based models, etc. However, these approaches are slow for real-time applications, and
Person reidentification (ReID) is the important task of matching person images captured from non-overlapping camera networks. Existing approaches to ReID usually include three steps: feature pretraining with labeled source domain data, clustering-based pseudo-label prediction for the target domain data, and feature representation learning/finetuning with the pseudo-labels. However, existing approaches often fail to adapt well to other scenarios due to the inevitable domain gaps. Therefore, it is necessary for both academia and industry to study the Unsupervised Domain Adaptive (UDA) person reiding
We propose a novel two-stage pipeline for self-supervised hand pose estimation, which is based on multi-view collaborative learning. In this paper, we propose HaMuCo, which stands for Hand Multi-View Collaborative Learning. The pipeline consists of (1) the singleview stage and (2) the multi-view stage. The singleview stage provides initial predictions and visual cues from a simple model-based network with the MANO hand model as the decoder. The multi-view stage conducts cross-level collaboration between all the views. We demonstrate that HaMuCo
Time series analysis and time series forecasting have been studied to extract information about the data and the underlying dynamics, and to predict the future observables from past measurements. The first systematic modeling of time series dates back to 1927 when Yule [1927] introduced a linear autoregression model to reveal the dynamics of sunspot numbers. The first systematic modeling of time series dates back to 1927 when Yule [1927] introduced a linear autoregression model to reveal the dynamics of sunspot numbers. The first systematic modeling of time series forecasting has been studied to predict the future
In this paper, we propose a novel naive ensemble method for adversarial training. The proposed method combines the results of adversarial trained network with the results of ensemble. The proposed method is based on the principle of decoupling. The proposed method is based on the principle of naive ensemble. The proposed method is based on the principle of naive ensemble. The proposed method is based on the principle of decoupling. The proposed method is based on the principle of nadversarial training data. The proposed method is based on
Multi-Object Tracking(MOT) is one of the fundamental challenges of computer vision. It is widely used in surveillance image processing and is mainly focused on pedestrians tracking. In this paper, we propose a self-supervised associating tracker(SSAT) which is a tracking algorithm that reidentifies detection results of the previous frame with the detection results of the current frame and form tracks. The SSAT is a tracking algorithm that trains the feature extraction network with appearance information of detection patches and associate tracks with detection patches using the self-supervised learning. We propose the self-supervised learning approach
In this paper, we propose a novel quantum Fourier convolutional network (QFCN) to speed up deep convolutional neural networks with quantum Fourier transform (QFT). The QFT is a quantum-based method to implement convolutional operations in CNNs. The QFT is exponentially faster than the classical Fourier transform for convolutions. However, the direct quantum convolution of quantum state has been shown to be inaccessible by previous studies. We also propose a hybrid quantumclassical circuit to avoid some of the quantum stimulation and take advantage of classical computers that are able to
Learning from Crowds (LFC) is a promising direction in machine learning. However, the two-stage approach is usually adopted to learn a classifier from the latent true labels provided by multiple annotators. In particular, confusion matrices of annotators are used to characterize the performance of multiple annotators across different instances within the same class. However, this approach is not able to fully characterize the performance of multiple annotators across different instances within the same class. This would lead to suboptimal performance of the LFC x.
The neural network learning is a large scale problem that is characterized by large size dataset with large model. The neural network model is trained using the stochastic gradient descent (SGD) and its variants in combination with explicit and implicit regularization methods. The explicit regularization restricts the model parameters wiht a prior knowledge, e.g., weightdecay adds the regularization term into the object function, assuming the model parameters should follow a L2ball. Dropout may assume that the model is an ensemble of sparse networks. The implicit regularization
Person reidentification (reID) is a popular task in the field of machine learning. The most successful reID methods leverage deep learning via a supervised learning approach. However, the reliance on a large, manually labelled dataset from the target domain is not practical in many real-world scenarios. To overcome this limitation, two approaches have been proposed in recent literature: a pure unsupervised approach and the more popular unsupervised domain adaptation approach. Both approaches assume the availability of a large, manually labelled dataset of individuals across multiple cameras in the deployment environment. However, the system is not
In this paper, we propose a deep latent variable model that we call the noiseaware encoderdecoder to disentangle a clean saliency predictor from noisy labels. The model is a conditional representation of each noisy label, and is trained by MCMC. The model is trained by MCMC, and the parameters f1;2goof the encoderdecoder and the generator are updated by the gradient ascent for maximum likelihood. The model is trained by MCMC, and the parameters f1 are X, and X, where X
Deep neural networks have become the new state of the art in classi cation and prediction of high dimensional data such as images, videos and biosensors. However, training of deep neural nets can be extremely data intensive requiring preparation of large scale datasets collected from multiple entities. Furthermore, deep neural architectures needing large supercomputing resources and engineering oversight may be required for optimal accuracy in real world applications. In this paper, we propose methods that enable training of neural networks using multiple data sources and a single supercomputing resource. We propose methods that enable training of neural networks using
Deep learning is heavily dependent on big data. Deep learning models are trained using gradient based gradients. However, when there is only a few samples to learn from, deep learning is prone to poor performance because they will not acquire enough knowledge about the specific task via weight updates. In this work, we revisit the problem of metalearning using memory augmented neural networks. Metalearning is a two-tiered learning framework in which an agent learns not only about the specific task, for instance, image classification, but also about how the task structure varies across target domains. In this work, we design
Offline Signature Verification (OSV) is one of the most challenging problems in computer vision. Despite the recent advances in computer vision, the problem of OSV remains challenging. Recently, automatic feature learning by deep Convolutional Neural Networks (CNNs) has shown its potential to tackle the challenges of OSV. However, due to the small training size, the power of Deep CNNs may not be effectively leveraged in the problem of OSV unless seriously considering regularization. In this paper, we investigate which loss function leads to more generalization in OSV. We compare the results with CE loss
Deep learning is a powerful tool for visual recognition, yet it is oftentimes hard to explain the model's results. In this paper, we present an interpretable deep model for fine-grained recognition. Our model learns a dictionary of object parts, based on which a 2D feature map can be grouped into "part" segments. During training, our model is only supervised by object labels with our proposed regularization term. During testing, our model jointly outputs the segments of object parts, the contribution of the segmented, and the segmentation, and the segmentation
Stateoftheart deep learning methods require a large amount of manually labeled data. In many situations, only a few or even no clean labeled examples are available at the representation learning stage. In this work, we use a graph convolutional network (GCN) to clean noisy data, while the representation is learned on different classes, similarly to fewshot learning. We clean the data using a GCN, which learns to predict a class relevance score per image based on connections to clean images in the graph. We use the class name admiral to crawl an existing large collection of
NAS algorithms are a powerful platform for discovering superior network architectures, which may save time and effort of human experts. Several recent methods have been proven to reduce search time significantly. For example, Liu et al. [ 7] suggested relaxing the search space to be continuous, which allowed them to perform a differentiable architecture search (DARTS), which led to novel network models and required reasonable resources (few days using 14 GPUs). However, acquiring large amounts of human-annotated data is expensive and timeconsuming. A growing body of research is focused on relies on
Deep convolutional neural networks (CNNs) are trained on large-scale training data with human annotated labels. However, the training data is often noisy and the network performance is affected by the noise in the training data. Hence, it is important to build models that are robust to noisy labels. In this paper, we propose PARS, short for Pseudo-Label Aware Robust Sample Selection. PARS trains on both the original labels and pseudo-labels. It is based on the principle of making the most of the noise in the training data.
In this paper, we present a novel supervised anomaly detection method through designing a conditional generative adversarial network (cGAN) featuring an ensemble of discriminators that are trained based on a novel ensemble active learning strategy. The discriminators are trained based on a novel ensemble active learning strategy, which is based on a novel ensemble active learning strategy. The ensemble active learning strategy is based on a novel ensemble active learning strategy, which is based on a novel ensemble active learning strategy. The ensemble of discriminators is designed to be trained using a novel ensemble of
Over-parameterization helps deep neural networks (DNNs) to generalize better in real-life applications, despite providing them with the capacity to fit almost any set of random labels. While it is obvious that over-parameterization helps DNNs to generalize better in real-life applications, it is not immediately clear what DNNs learn when trained on random labels. This study aims to provide a partial answer to this question. First, in order to understand how DNNs work, it is imperative to observe how they behave under extreme conditions, such as Equal contribution.
For many species, analyzing social networks is necessary for understanding an imal behavior. The underlying social network of an animal population can strongly in uence movement and provide researchers with information on the behavioral characteristics of a species. For example, many marine mammals, including Risso's dolphins ( Grampus griseus ), are highly social with close-knit relationships. However, there is a sparsity of data on how dolphins respond to sonar due to their high abun dance in nearcoastal navy training area. Thus, our motivating application is studying G.
Portable Document Format (PDF) is one of the most popular types of documents. Despite the lack of awareness of the population, it also became an important attack vector (AV) for computer systems. Despite recent work in machine learning for malware detection, antivirus companies are still largely focusing on handwritten signatures to detect malicious PDF. Another popular solution is the dynamic analysis by running the les in a controlled sandboxed environment. These approaches take much longer and require a human to deduce the detection rules according to the le behavior. We are using an ensemble of Convolutional Neural Network (
In this paper, we propose a method for accurately identifying cell boundaries and labeling individual cells in confocal microscopy image stacks. The goal is to generate closed cell surfaces in the 3D image stack while being able to accurately delineate features of interest such as inter-cellular spaces and protrusions. The proposed method is based on a 3D UNet architecture which is trained on a large, public dataset. The first step is to generate a membrane probability map where voxels that are likely to belong to the cell membrane
In this paper, we propose a method for extracting features from neural networks. In particular, we consider the process of determining good' and bad' data points, where paths are de ned per individual input point as the sequence of clusters in the neural network the point belongs to, starting from the cluster it belongs to in the input space, then the clusters it belongs to in each hidden space, and finally the cluster it belongs to in the output space. The process of determining good' and a path is formalized in the algorithm, where paths are de
Deep Neural Networks (DNNs) are a powerful tool for deep learning. However, it is not always realistic to assume that example labels are clean. Humans make mistakes and, depending on the complexity of the task, there may be disagreement even among expert labellers. In this work, we add a noise model layer on top of our target model to account for label noise in the training set. We provide extensive experiments on several text classification datasets with artificially injected label noise. We study the effect of two different types of label flipping (Uni) where a clean label is swap
Multilabel classification is a classification task that aims to find all existing objects or attributes in a single image. It is becoming increasingly important to develop learning strategies with partial labels. There are two naive approaches to train the model with partial labels. One is to train the model with observed labels only, ignoring the unobserved labels. The other is to assume all unobserved labels are negative and incorporate them into training because majorities of labels are negative in a multi label setting. However, these approaches have a limitation that they are noisy. We hypotheses that if label
In recent years, machine learning (ML) and deep learning (DL) approaches have been widely used for automatic cattle identification using visual features. DL approaches are useful in areas with large and high-dimensional datasets. However, DL models are usually outperformed over traditional ML models in the area of text, speech, image, video, and audio data processing. In this paper, we present a systematic literature review based on applying ML and DL approaches in precision livestock farming. The aim of this paper is to present a systematic review
In recent years, calibration of deep neural networks (DNNs) has been a major challenge in machine learning community. In this paper, we propose a new calibration method for DNNs, namely Temperature Scaling (TS), which is a measure-based approach that achieves better calibration with minimum computational complexity. TS is based on the principle of minimizing the negative log likelihood (NLL) loss function with respect to the network parameters. TS is the state-of-the-art measure-based approach that achieves better calibration with minimum computational complexity and minimal computational complexity.
Arabic is a language with hundreds of varieties, some of which are not even mutually comprehensible. Despite such diversity, up until recently, such varieties were strictly confined to the spoken domains, with Modern Standard Arabic (MSA) dominating the written forms of communication all over the Arab world. However, with the advent of social media, an explosion of written content in said varieties have flooded the internet, attracting the attention and interest of the wide Arabic NLP research community in the process. In this paper we present and discuss the strategies and experiments we conducted to achieve the first place in the Nu
We propose a novel solution to speaker attribution with speaker profiles through graph-based semi-supervised learning methods. The speaker attribution task is a problem of “who spoke when”, i.e., grouping the segments of a long audio recording into speaker homogeneous clusters. The conventional speaker diarization task assumes no prior knowledge of speakers’ identities, so it is basically a clustering problem without speaker identification. In this paper, we propose a graph-based semi-supervised learning method that uses the structural information among speech segments in order to improve the accuracy of classifying the
Recent years have witnessed a surging interest in designing well-performing architectures for different tasks. However, the manual design process is typically prohibitively costly and requires numerous trials and errors during this manual design process. To this end, a number of neural architecture search (NAS) algorithms have been developed to help automate the design of architectures. However, conventional NAS algorithms aim to select only one single architecture from their search spaces and have thus overlooked the capability of other candidate architectures from the same search spaces in helping improve the performance achieved by their final ensemble search.
Deep neural networks (DNNs) have been widely used in various fields, but at the same time showed a severe vulnerability to adversarial samples. In particular, the robustness of DNNs for images perturbed by Gaussian noises N(0;2I) has been a major focus of recent research. Randomized smoothing (RS) is considered as one of the most effective 2norm certifiably robust defenses. Recently, the ensemble of multiple DNNs being the base classifier has shown significant improvements in the certification phase. However, the certification time
Person reidentification (reID) is a class of image classification tasks that aims to find matched pedestrians in a non-overlapping camera system. Currently, there are many unsupervised reID methods that use labeled data to train a deep model. However, these methods often introduce noisy labels and feature variations caused by camera shifts. In this paper, we propose a novel method for robust unsupervised reID. We propose a dynamic and symmetric cross entropy loss (DSCE) for the model. We propose a a DSCE for
In 2018, the FDA required that e-cigarette advertisements, including social media imagery, contain a prominent warning label that reminds consumers that nicotine is addictive. Several studies evaluated compliance with the FDA requirements for warning labels on Instagram. However, these studies used binary classification to assess the presence of warning statements on a small sample size of images. This study addresses the limitation of prior research by developing an automated deep learning image classification capable of quickly and accurately measuring compliance with the FDA requirements for warning labels on a large sample size. We tested whether advanced deep learning techniques could provide an effective,
We propose a novel method to learn from noisy datasets. In this paper, we propose a distillation process to transfer the knowledge learned from a better model to a lighter but typically inferior model. In this process, we use a small clean dataset and a large noisy dataset to augment the small clean dataset to learn a better visual representation and classifier. We leverage a knowledge graph to guide the distillation process, where rich relational information among labels are explicitly encoded in the learning process. We show that, our proposed distillation process achieves better results on our datasets compared with competing
In this paper, we introduce the first convolutional neural associative network with exponential storage capacity. We prove that our architecture can correct a linear fraction of errors. We also develop an online learning algorithm with the ability to learn patterns as they arrive. This property is particularly useful when the size of the dataset is massive and patterns can only be learned in a streaming manner. We also extend our results to the case where patterns lie approximately in a sub space. This extension is particularly useful when the size of the dataset is massive and patterns can only be learned in a streaming manner. We demonstrate that our architecture can reliabl
In this work, we propose a framework for semantic scene synthesis. From the depth image, the 3D scene is down scaled and semantically mapped into a synthesis area using the computed labels and the extracted geometric features of the input point cloud. The semantic labeling is inspired from Braille and Kanji systems. The second module is based on a deep learning architecture to classify depth image segments into seven semantic classes. The semantic labeling is inspired from Braille and Kanji systems. The semantic labeling is mapped into a touch-based synthesis area. The proposed framework is
Person re identification (ReID) is an important task in many computer vision systems, such as behavioral understanding, threat detection and video surveillance. However, the appearance of a person may suffer dramatic change under different camera views. Currently, most of the person ReID models are based on deep learning technology. However, the training processes of the models require a large amount of labeled data. Moreover, existing public person ReID datasets are limited in their scale s, especially for the number of images per identity. In this paper, we introduce a data augmentation method that can generate pedestrian images
In recent years, the amount of ECG data requiring analysis has grown too rapidly for human cardiologists to keep up. Therefore, analyzing ECG dataautomatically and accurately has become a hot research topic. In practice, experts are manually extracted using computer-based algorithms, which are limited by data quality and human expert knowledge. Deep learning methods have achieved promising results in many application areas, such as speech recognition, computer vision, and natural language processing. However, deep learning methods are still insufficient because they are limited by data quality and human expert knowledge. Therefore, we review
Deep learning has been used to train deep neural networks to recognise and classify images. However, the existence of label noise in the training datasets is one of the primary obstacles to training these models. In this paper, we investigate the robustness of two distinct neural networks (LeNet and AlexNet) to label noise. We use a class-dependent label noise technique, in which labels are flipped randomly with a probability dependent on the class. This class noise rate will be referred to as the ”flip rate” in the study. We compare the performance of two distinct neural networks (LeNet and Alex