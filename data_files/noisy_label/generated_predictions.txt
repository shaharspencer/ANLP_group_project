Label corruption is a common problem in deep learning. It is often the case that a small number of trusted examples are available. In this paper, we demonstrate that having access to a small amount of trusted training data enables significant robustness gains. To leverage the additional information from trusted labels, we propose a new loss correction and empirically verify it on a number of vision and natural language datasets with label corruption. We demonstrate recovery from moderate to severe label noise, including the dire case when the untrusted data has a majority of its labels corrupted.
Convolutional Neural Networks (CNNs) are a powerful tool for many supervised tasks. However, the robust training of CNNs with noisy labels is of great practical importance. Several methods have been proposed to address this issue, such as Negative Learning for Noisy Labels (NLNL), which is an indirect learning method for training CNNs. NLNL uses randomly chosen complementary labels and trains the CNN that "input image does not belong to this complementary label." However, the fundamental problem that NLNL causes underfitting to the overall training data still remains. This is the reason
Convolutional neural networks (CNNs) have been proposed to handle graph structure uncertainty. However, the current implementations have limited capability to handle uncertainty in the graph structure, and treat the graph topology as groundtruth information. In this paper, we present a Bayesian GCNN framework and view the observed graph as a realization from a parametric random graph family. The observed adjacency matrix is then used in conjunction with features and labels to perform joint inference. To provide a concrete example, we focus on the assortative mixed memor
We propose a novel method for automatic facial expression recognition from videos in the wild. We use the publicly-available dataset AFEW 8.0 (Acted Facial Expressions in the Wild) to train our model. We use a teacher-student learning method where the training process is iterated by using the same student again as the teacher. During the training of the student, noise is injected into the student model to force it to generalize better than the teacher. Results show that the student performs better than the teacher with each iteration.
SemEval2020 Task 11 aims to detect the use of propaganda techniques in news articles. It focuses on detecting the use of propaganda techniques in news articles. We propose a new neural network architecture for detecting the use of propaganda techniques in news articles. We first built a pre-trained model based on the Transformer architecture, and then we improved over RoBERTa by adding extra layers in the neural network architecture, and we further added some post-processing steps. Finally, we combined different models into an ensemble. We developed a
Music tagging is a classification task whose objective is computational understanding of music semantics. The task has attracted music information retrieval (MIR) researchers due to its wide pragmatic usages in many applications. However, the current music tagging research is limited by two limitations: chunk-based prediction and a limited amount of labeled data. In this paper, we present Music Tagging Transformer, a semi-supervised music tagging model trained with a labeled dataset. We show that our Music Tagging Transformer outperforms the previous works by a
Person re-identification (reid) is about matching identity classes in detected person bounding box images from non-overlapping camera views over distributed open spaces. Existing person re-identification studies typically focus on either feature representation or matching distance metrics. We consider that learning any matching distance metric is intrinsically learning a global feature transformation across domains (two dis joint camera views) therefore obtaining a “normalised” feature representation for matching. We consider that either local or global feature learning alone is suboptimal. This is motivated by the human visual system that leverages both global (context
Instance-dependent noise (IDN) is a new problem in deep learning that is characterized by the dependence of noise on the content of individual images. Existing methods mostly focus on the learning with class conditional noise (CCN), which aims to recover a noise transition matrix that contains class-dependent probabilities of a clean label flipping into a noisy label. However, CCN is too ideal for real-world LNL as it ignores the dependence of noise on the content of individual images, a.k. In this paper, we propose a novel two-stage method to
Stock supply and demand are affected by many things. Normally, we can get these supply and demand factors from the financial news, companies’ newsletters or their annual reports. However, there are a few primary factors that affect the stock supply and demand like company news, company performance, industry trends, investor sentiment, and unexpected events. Hence, if we focus on these factors, and trace back the historical stock prices, we may be able to predict future stock prices quite accurately. However, computer scientists are not particularly successful in stock price prediction because of the
Surrogate modeling focuses on input-output behavior to find a model that approximates the relationship between input and output as accurately as possible. Neural network (NN) is one of the promising surrogate models and has a good prediction accuracy. However, NN has a problem in that different models are created in accordance with the selection of training data sets, initial parameters, and training algorithms. This condition results in various prediction values; thus, NNs are referred to have high prediction variance. Ensembles that combine prediction values obtained from multiple component models are developed to reduce the prediction variance of
Deep neural networks (DNNs) have achieved significant success in computer vision tasks, such as image classification. However, they rely heavily on huge quantities of high-quality manual annotations. To mitigate the effects of model overfitting to noisy labels, learning with noisy labels (LNL) has been proposed to effectively leverage large-scale yet poorly-annotated datasets while mitigating the effects of model overfitting to noisy labels. In this paper, we propose a novel approach to learn with noisy labels, which focuses on a candidate sample's nearest neighbors. We borrow the concept of contrast
Color stylization plays a critical role in modern cine matography and video storytelling. In addition to applying global color styles to the entire video, modern filmmakers often utilize localized color tone changes; i.e., distinct color palettes applied to certain segments in the scene. However, color stylization is still a labor-intensive and time-consuming process even with the use of professional editing software. To our knowledge, there is no existing work that can successfully perform photorealistic localized photorealistic style transfer on videos with reasonably good runtime performance. To achieve high-speed performance, we extend our
In this paper, we address the problem of automatic language identification (LID) from a computer vision perspective. We propose a hybrid network constructed of a Convolutional Neural Network (CNN) combined with an Recurrent Neural Network (RNN). Our proposed network combines the descriptive powers of a Convolutional Neural Network (CNN) with the ability to capture temporal features of a Recurrent Neural Network (RNN). We perform extensive experiments with our proposed network and demonstrate its applicability to a range of scenarios and its extensib
Person re-identification (re-ID) aims to search for the same person across disjoint cameras. The main challenge of unsupervised re-ID is the lack of labels, which limits the scalability of supervised methods. In this paper, we propose a dynamic graph matching (DGM) method to estimate cross-camera labels for unsupervised re-ID. Specifically, our method is an iterative process, where a bipartite graph is established, labels are then estimated, and then a discriminative metric is learnt.
This paper presents a novel method for learning from multiple annotators to improve the performance of a deep neural network in detecting abnormalities from chest X-ray images. The proposed method aims at estimating the ground truth annotations from multiple experts with confidence scores and uses these annotations to train a deep learning-based detector. The proposed method is simple and effective, and can be applied to a wide range of medical imaging applications. In particular, the proposed method is simple and can be applied to a wide range of medical imaging datasets. The proposed method is
We propose a novel strategy for obtaining semantic labels from a large dataset of geotagged ground images. We use these semantic labels as a form of weak supervision and attempt to predict the ground image segmentation diagonally from an aerial image of the same location. We do not use a parametric transformation between the aerial and ground-level viewpoints. Instead, we use a dense representation, similar in spirit to the general representation, dubbed filter flow. We demonstrate the value of this approach in several ways. First, we propose a novel convolutional neural network (CNN) architecture that relates
Temporal Ensembling is a semi-supervised learning approach that uses an ensemble of the earlier outputs of a neural network as an unsupervised target label. It has achieved high accuracy on SVHN and CIFAR10 with just 500 and 4000 labeled examples with both naturally offering lower intraclass variances. However, to the best of our knowledge, there is no explicit study of temporal ensembling in the context of datasets with large intraclass variability. In this work, we attempt to address this gap by answering the following research questions
In this paper, we explore the use of structured inference neural networks for modelling concept interactions in a number of different tasks and levels of complexity. We focus on multi-label image classification, multi-label video classification and action detection in untrimmed videos. We exploit the rich structure of label relations to jointly predict layered visual labels from an image. We achieve this by defining a network in which a node is activated if its corresponding label is present in an image. We introduce stacked layers among these label nodes
Knowledge distillation (KD) is a special transfer learning technology. It involves training a new model which is usually called the student model. The knowledge in a well-trained model (the teacher model) is compressed and transferred to the student model. The student model can be trained on a separate transfer data set without correct labels or on the original training data set where correct labels are available. However, none of the distilled student models are able to outperform their corresponding teacher models. In this paper, we propose a simple yet effective method to select valuable information from the teacher model
In the last decade, the volume and quality of Earth observations have increased dramatically, particularly thanks to remote sensing. At the same time, new developments in machine learning (ML), particularly deep learning, have demonstrated impressive skills in re-producing complex spatio-temporal processes by efficiently using a huge amount of data. In this paper, we propose a new approach to combine data assimilation and ML to predict the state of a low-order chaotic system based on partial and noisy observations. We propose a new approach to predict an unobservation
Deep learning based algorithms have achieved significant results in solving various computer vision problems. However, real world applications often require the deployment of these algorithms on resource-limited mobile/edge devices. Neural network pruning is a technique to strike the balance between accuracy (performance) and cost (efficiency). However, previous works are mostly evaluated on a sparse labeling classification task. In a practical scenario, dense labeling problems often require real-time processing in real world problems. Hence, the compression of a dense labeling neural network is crucial and demanding. In this work, we propose kernel cluster pruning (K
The general audio tagging task is a task to predict the presence or absence of certain acoustic events in an audio recording. Traditionally, audio tagging has been addressed with different handcrafted features and shallow-architecture classifiers. Recently, deep learning approaches such as convolutional neural networks (CNNs) have achieved state-of-the-art performance for the task. However, due to the limited size of data and noisy labels, general audio tagging remains as a challenge and falls short of accuracy and robustness. In this paper, we aim to build scalable ensemble
Image denoising refers to the process of removing noise from a distorted image to recover the clean image. In the real world, the noise is often a non-AWGN noise, which is a common problem in signal processing and transmission applications. The recent breakthroughs in image denoising come from deep neural networks (DNNs), especially deep Convolutional Neural Networks (CNNs). However, these discriminative models often demonstrate better performance than the traditional handcrafted methods, and thus unsuitable for real-time applications. In this paper, we propose and validate
Unsupervised Domain Adaptive (UDA) person re-identification (ReID) is the important task of matching person images captured from non-overlapping camera networks. Existing approaches mainly involve three steps: feature pre-training with labeled source domain data, clustering-based pseudo-label prediction for the target domain data, and feature representation learning/finetuning with the pseudo labels. However, the noisy pseudo labels generated by clustering usually contain incorrect labels due to the divergence/domain gap between the source and the model performance. In this paper, we propose a Groupa
Self-supervised hand pose estimation with noisy pseudo labels is an emerging solution to the challenge posed by manual annotation. However, the performance of this method is limited by the quality of the pseudo label in a specific view when handling an ill-posed problem. To this end, we propose a novel two-stage strategy to tackle noisy pseudo labels and unreliable multi-view "group think". Formally, we name the pipeline HaMuCo, which stands for Hand Multi-view Collaborative Learning. The two-stage strategy aims to achieve consistent results without early diverg
Time series analysis and time series forecasting have been studied to extract information about the data and the underlying dynamics, and to predict the future from past measurements. The first systematic modeling of time series dates back to 1927 when Yule [1927] introduced a linear autoregression model to reveal the dynamics of sunspot numbers. The model which writes as u(k+ 1) =m(k+ 1) =m(k+ 1)) was based on a linear autoregression model which writes as u(k+ 1) =m(k+1) =m(k+1) =m
Convolutional neural networks (CNNs) are susceptible to designed adversarial attack, even if the attack is imperceptibly small. To mitigate such threat, many algorithms have been proposed to make network to be robust to adversarial attack. However, it has been found that many of these methods are not robust indeed; many proposed defense algorithms rely on opaque gradient which gives robustness against particular attacks only, and can be circumvented by adaptively designed attack. In this paper, we propose a novel naive ensemble method to relieve the overfitting
Multi-Object Tracking(MOT) is one of the fundamental challenges of computer vision and is widely used in surveillance image processing. The most common MOT algorithm is the detection by tracking paradigm, which is a method of obtaining detection results in each frame of video using off-the-shelf detection algorithm such as FasterRCNN, and organically associating the detection results of the previous frame with the detection results of the current frame and form tracks. However, the most of them deals with how to associate the track of the previous frame with the detection patches of the
Convolutional neural networks (CNNs) are one of the most important components of deep learning. However, the direct convolution of quantum state has been shown to be inaccessible by previous studies. In this paper, we propose a novel quantum Fourier convolutional network (QFCN) to speed up the CNN with quantum Fourier transform (QFT), which could be exponentially faster than the classical Fourier transform for convolutions. We also propose a hybrid quantumclassical circuit to avoid some of the quantum noise and also to take advantage of classical computers that are able to perform rapid it
Learning from Crowds (LFC) is a fundamental problem in machine learning. Among various research efforts on LFC, the probability transition process from latent true labels to observed crowdsourced labels is usually modeled with confusion matrices of annotators, which represents class-level probability transition. However, in the real world, the difficulty of labeling can vary among instances within the same class and the instance features themselves will affect annotators’ performance. To address this deficiency, this work proposes a novel LFC x, which can learn a classifier directly from crowd
The neural network learning is a large scale problem that is characterized by large size dataset with large model. The neural network model is trained using the stochastic gradient descent (SGD) and its variants in combination with explicit and implicit regularization methods. The explicit regularization restricts the model parameters with a prior knowledge, e.g., weightdecay adds the regularization term into the object function, assuming the model parameters should follow a L2ball. The implicit regularization is independent to the model structure. The stochastic gradient descent (SGD) is an implicit regular
Person re-identification (re-ID) attempts to match an individual from one camera view across other, non-overlapping camera views. The most successful methods leverage deep learning via a supervised learning approach. However, the reliance on a large, manually labelled dataset from the target domain limits the widespread adoption of person re-ID because of the cost and logistics needed for manually annotating data from the target domain. To overcome this limitation, two approaches have been proposed in recent literature: a pure unsupervised approach and the more popular unsupervised domain adaptation approach. In this work, we explore how
Deep learning has made it possible to train end-to-end saliency detection models in a data-driven manner. However, the success of these models mainly depends on a large amount of accurate human labeling, which is typically expensive and time-consuming. In this paper, we follow the second direction and propose a deep latent variable model that we call the noise-aware encoder-decoder to disentangle a clean saliency predictor from noisy labels. In particular, we assume that noisy labels are produced by handcrafted feature-based saliency methods, or even
Deep neural networks have become the new state of the art in classification and prediction of high dimensional data such as images, videos and biosensors. However, training of deep neural networks can be extremely data intensive requiring preparation of large scale datasets from multiple entities. Furthermore, deep neural architectures needing large supercomputing resources and engineering oversight may be required for optimal accuracy in real world applications. In this paper, we propose methods that enable training of neural networks using multiple data sources and a single supercomputing resource. In particular, we propose methods that enable training of neural networks using
Metalearning is a two-tiered learning framework in which an agent learns not only about the specific task, for instance, image classification, but also about how the task structure varies across target domains. Recent memory augmented neural networks such as Neural Turing Machines (NTMs) have shown the ability of metalearning. In this work, we revisit the problem of metalearning using memory augmented neural networks. In this work, we design a new memory writing module based on the metalearning framework to avoid memory interference during testing. We propose a new memory writing module based on
Offline Signature Verification (OSV) is a classic problem in computer vision and pattern recognition. It aims to distinguish between genuine and forgeries by a given signature image. Recent studies have explored different loss functions for CNNs to find which one promotes more generalization. In this paper, we compare Cross Entropy (CE) loss as a classification loss and several state-of-the-art metric learning losses. In addition to OSV, we also study different classification losses for different tasks, and the similar comparative results were obtained in this paper.
Deep learning is a powerful tool for visual recognition, yet it is often difficult to explain its results. In this paper, we present an interpretable deep model for fine-grained recognition. Specifically, our model learns a dictionary of object parts, based on which a 2D feature map can be grouped into "part" segments. Moreover, region-based features are pooled from the result segments, followed by an attention mechanism to select a subset of segments for classification. Importantly, during training, our model is only supervised by object labels with our proposed regularization term.
State-of-the-art deep learning methods require a large amount of manually labeled data. In this work, we propose a few-shot learning approach for learning a classifier from a few clean labeled examples and additional weakly labeled data, while the representation is learned on different classes. We use the class name admiral to crawl an existing large collection of images with textual description, and we create an adjacency graph based on visual similarity. We then assign a relevance score to each image using a graph convolutional network (GCN)
Neural Architecture Search (NAS) is a powerful platform for discovering superior network architectures. NAS algorithms are based on the assumption that the network architectures are based on annotated examples. However, acquiring large amounts of annotated data is expensive and time-consuming, while unlabeled data is much more accessible. A growing body of research is focused on relieving the need for such extensive annotation effort. One promising lead in this direction is self-supervised learning (SSL). SSL learns visual features from unlabeled data. The unlabeled data is used to automatically generate
Deep neural networks (CNNs) are trained on large-scale training data with human annotated labels. However, the large-scale labeled training data is expensive, time-consuming, and can compromise user privacy. Hence, there has been a paradigm shift in the interests of the research community from large-scale supervised learning to Learning with Noisy Labels (LNL). Most of the existing approaches on LNL can be divided into three main categories. First, several noise robust loss functions were proposed that are inherently tolerant to the noisy labels. Second,
In this paper, we propose a novel supervised anomaly detection method through designing a conditional generative adversarial network (cGAN) featuring an ensemble of discriminators that are trained based on a novel ensemble active learning strategy. At the heart of our new method is the ensemble active learning strategy, which is based on a novel ensemble active learning strategy. The ensemble active learning strategy is based on a novel ensemble active learning strategy that is designed to learn the discriminators in a cGAN using a novel ensemble active learning strategy. The ensemble of discriminators is trained using
Over-parameterization helps deep neural networks (DNNs) to generalize better in real-life applications, despite providing them with the capacity to fit almost any set of random labels. While it is obvious that over-parameterization helps DNNs to generalize better in real-life applications, it is not immediately clear what DNNs learn when trained on random labels. This work aims to provide a partial answer to this question. First, in order to understand how DNNs work, it is imperative to observe how they behave under extreme conditions. Second, observing DNNs trained on
We propose a Bayesian approach to infer social connections between dolphins using drone-measured movement data. We extend existing methodology for animal movement to estimate the effects of sonar exposure on an unobserved social network of dolphins. We model the social network using a discrete time continuous-space Gaussian Markov Random Field (GMRF) with an underlying dynamic social network. The two main behavioral components motivating the model are attraction and alignment, both of which are directly related to social structure. We also model the repulsive and/anti-aligning behavior by allowing
Portable Document Format (PDF) is one of the most popular types of documents. It is a popular attack vector for hackers to take control of computer systems. Despite recent work in machine learning for malware detection, antivirus vendors are still largely focusing on handwritten signatures to detect malicious PDF. These approaches require significant human resources and are rarely effective at detecting unknown variants or zero-day attacks. In this work, we propose an ensemble of Convolutional Neural Network (CNN) in order to detect any type of malicious PDF. Without any preprocessing of the les, our classifier succeeds to
Cell boundary detection from 3D confocal microscopy images is critical in many applications including modeling of cell morphogenesis and plant growth. Currently, cell segmentation is usually performed by preprocessing, segmentation, and post-processing. In this paper, we propose a novel method for accurately identifying cell boundaries and labeling individual cells in confocal microscopy image stacks. The proposed method is based on a 3D UNet architecture which is trained on a large, public dataset. The first step is to generate a membrane probability map where vox
In a feed forward neural network, hidden spaces are composed of perceptrons with respect to the previous layer, each of which has a hyperplane decision boundary. Points in the previous space are mapped to a constant function of their distance to this plane, and depending on the activation function, compressed or stretched. This stretching and compressing naturally leads to clustering in hidden spaces. To extract individual features, then, cluster paths should be examined, where a path is denoted per individual input point as the sequence of clusters in the neural network the
Deep Neural Networks (DNNs) rely on large amounts of carefully labeled training data. However, it is not always realistic to assume that example labels are clean. To support noisy labels in data, we need new training methods that can be used to train DNNs directly from the corrupted labels to significantly reduce human labeling efforts. In this work, we add a noise model layer on top of our target model to account for label noise in the training set. We perform extensive experiments on several text classification datasets with artificially injected label noise. We observe that proper initialization and regular
Multi-label classification aims to find all existing objects or attributes in a single image. However, it is a challenging task to make a dataset because it requires annotators to label all categories’ existence/absence for every image. To alleviate these issues, weakly supervised learning approach in multi-label classification task (WSML) has been taken into consideration. However, these approaches involve heavy computation or complex optimization pipeline. In this paper, we try to look at the WSML problem from the perspective of noisy label learning. We observe that the model first fits into clean labels, and then
Cattle identification is a critical aspect of precision livestock management. The demand for e-traceability and identification systems for livestock is growing due to biosecurity and food safety requirements in the supply chain. In recent years, machine learning (ML) and deep learning (DL) approaches have been widely used for automatic cattle identification using visual features. ML and DL approaches are mainly divided into two approaches, such as supervised learning and unsupervised learning. DL approaches are useful in areas with large and high-dimensional datasets. ML models are
Deep Neural Networks (DNNs) show dramatic accuracy on challenging tasks such as computer vision, speech recognition, and medical diagnosis. However, in real-world decision-making applications, the confidence of the network is also essential for having a secure and reliable system. Calibration in DNNs is a recent challenge in machine learning community which was not an issue previously for shallow neural networks. In this paper, we propose a measure-based approach to calibrate DNNs. Temperature Scaling (TS) is the state-of-of-of-based approach that achieves better calibration with
Arabic is a language with hundreds of varieties, some of which are not even mutually comprehensible. Despite such diversity, up until recently, such varieties were strictly confined to the spoken domains, with Modern Standard Arabic (MSA) dominating the written forms of communication all over the Arab world. However, with the advent of social media, an explosion of written content in said varieties have flooded the internet, attracting the attention and interest of the wide Arabic NLP research community in the process. In this paper we present and discuss the strategies and experiments we conducted to achieve the first place in the Nu
Speaker diarization is the problem of “who spoke when”, i.e., grouping the segments of a long audio recording into speaker homogeneous clusters. Conventional speaker diarization assumes no prior knowledge of speakers’ identities, so it is basically a clustering problem without speaker identification. In this paper, we propose a graph-based semi-supervised learning method for speaker attribution, which uses the structural information among speech segments within a session. Each speech segment, either from profile audio or test audio, is represented as a node on the graph. The feature vector
This paper presents a novel neural ensemble search via Bayesian sampling (NESBS) algorithm to effectively and efficiently select the well-performing neural network ensemble with diverse architectures from a search space. NESBS is based on a variational posterior distribution of architectures based on a trained supernet and uses the model parameters inherited from this supernet to estimate the single-model performances and also the ensemble performance of independently trained architectures. Next, we use a variational posterior distribution of architectures based on a trained supernet to characterize the single-model performances and ensemble performances of
Deep neural networks (DNNs) have been widely used in various fields, but at the same time showed a severe vulnerability to adversarial samples. To resist such attacks, various methods for certified robustness have attracted increasing attention in recent years. Randomized smoothing (RS) is considered as one of the most effective 2norm certifiably robust defenses. However, the ensemble of multiple DNNs being the base classifier in RS has shown great potentials in certified robustness. In particular, the certification time becomes a
Unsupervised person re-identification (re-ID) attempts to find matched pedestrians of a query in a non-overlapping camera system. Recent unsupervised re-ID methods mainly adopt clustering to generate pseudo-label for un labeled samples, enabling the training of a deep model in a simplified manner. However, these methods often ignore two crucial issues during this process: (1) Noisy labels brought by clustering, which inevitably will introduce noisy labels in the labeling step, thereby hindering the model accuracy. (2) Feature variations caused by camera
In 2018, the FDA required that e-cigarette advertisements on social media include a prominent warning label reminding consumers that nicotine is addictive. Several studies evaluated compliance with the FDA requirements for warning labels on Instagram. However, these studies only assessed compliance on a small sample size of images and used binary classification (presence or absence of a warning statement) without reporting warning labels that were too small or in the wrong place, which would constitute a partial compliance with the FDA requirements. In this study, we tested whether advanced deep learning techniques could provide an effective,
Recent efforts have focused on learning from large-scale datasets with noisy labels, such as YFCC100M and YouTube8M1. However, in practice, noisy labels are not statistical outliers but rather some form of significant mass. Existing approaches have shown to produce inferior results on these cases. In this paper, we propose a new technique that uses a similar distillation process to learn from noisy datasets. In our scenario, we assume that we have a small clean dataset and a large noisy dataset. The small clean dataset can either be labeled from part of the noisy dataset, or
The ability of neural networks to reliably memorize a large set of patterns and reliably retrieve them in the presence of noise has attracted a large body of research over the past three decades to design artificial neural associative memories with similar capabilities. This problem, called ”associative memory”, is in spirit very similar to reliable information transmission faced in communication systems where the goal is to efficiently decode a set of transmitted patterns over a noisy channel. However, the maximum number of reliably memorized patterns by most current neural networks scale linearly in the size of the length of the length of
In this work, we propose a framework for semantic scene synthesis. From the depth image, the 3D scene is down scaled and semantically mapped into a synthesis area using the computed labels and the extracted geometric features of the input point cloud. The semantic labeling is inspired from Braille and Kanji systems. The semantic labeling is mapped into a touch-based synthesis area that can be used for many applications such as in assistive systems for visually impaired and blind people. The semantic labeling is based on the computed labels and the extracted geometric features of the input point cloud
Person re-identification (Re-ID) is an important task in many computer vision systems, such as behavioral understanding, threat detection and video surveillance. The task aims to re-identify the person observed by non-overlapping multiple cameras or across differen t time with a single camera. However, the appearance of a person may suffer dramatic change under different camera views. Currently, most of the state-of-the-art person Re-ID models are based on deep learning technology. However, existing available public person Re-ID datasets are limited in their scale. For example,
The electrocardiogram (ECG/EKG) is one of the most commonly used noninvasive diagnostic tools for recording the physiological activities of the heart over a period of time. Traditionally, automatic ECG analysis has relied on a two-stage method that requires human experts to extract useful features based on raw ECG data, which are then used to train machine learning models. However, these methods are still insufficient because they are limited by data quality and human expert knowledge. Recently, deep learning methods have achieved promising results in many application areas, such as speech recognition, computer vision, language processing, and speech
Label noise is the presence of labels for classification data in which the labels do not precisely reflect the instance's content. Label noise is a common problem in computer vision and image processing applications, as it can dramatically impair the performance of deep neural networks. In this work, we investigate class-dependent label noise, in which labels are flipped randomly with a probability dependent on the class. We propose a novel experimental strategy for addressing label noise, which combines backwards noise correction and a transition matrix. We compare the label noise robustness of two distinct neural networks (LeNet and AlexNet) using